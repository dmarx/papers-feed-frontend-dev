<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">BRIDGING THE DATA PROVENANCE GAP ACROSS TEXT, SPEECH, AND VIDEO</title>
				<funder>
					<orgName type="full">Mozilla Data Futures Lab Infrastructure Fund</orgName>
				</funder>
				<funder>
					<orgName type="full">Data Provenance Initiative</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-12-19">19 Dec 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shayne</forename><surname>Longpre</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nikhil</forename><surname>Singh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Manuel</forename><surname>Cherep</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kushagra</forename><surname>Tiwary</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Joanna</forename><surname>Materzynska</surname></persName>
						</author>
						<author>
							<persName><forename type="first">William</forename><surname>Brannon</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Robert</forename><surname>Mahari</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Manan</forename><surname>Dey</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mohammed</forename><surname>Hamdy</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nayan</forename><surname>Saxena</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ahmad</forename><forename type="middle">Mustafa</forename><surname>Anis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Emad</forename><forename type="middle">A</forename><surname>Alghamdi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Minh</forename><surname>Vu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Naana</forename><surname>Chien</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Da</forename><surname>Obeng-Marnu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kun</forename><surname>Yin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yizhi</forename><surname>Qian</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Minnie</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">An</forename><surname>Liang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shrestha</forename><surname>Dinh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Deividas</forename><surname>Mohanty</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tobin</forename><surname>Mataciunas</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jianguo</forename><surname>South</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ariel</forename><forename type="middle">N</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Campbell</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Christopher</forename><surname>Lund</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Damien</forename><surname>Klamm</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Diganta</forename><surname>Sileo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Enrico</forename><surname>Misra</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kevin</forename><surname>Shippole</surname></persName>
						</author>
						<author>
							<persName><surname>Klyman</surname></persName>
						</author>
						<author>
							<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Lester</surname></persName>
						</author>
						<author>
							<persName><surname>Miranda</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Niklas Muennighoff</orgName>
								<address>
									<addrLine>Seonghyeon Ye Seungone Kim Vivek Sharma, Xuhui Zhou Caiming Xiong Luis Villa Stella Biderman Alex Pentland Sara Hooker Jad Kabbara The Data Provenance Initiative</addrLine>
									<settlement>Vipul Gupta</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">NC/Acad | Restricted NC/Acad | Unspecified NC/Acad | Unrestricted Unspecified | Restricted Unspecified | Unspecified Unspecified | Unrestricted Commercial | Restricted Commercial</orgName>
								<address>
									<addrLine>1T 713 23 534 60 502 21 395 50 SPEECH 95 775k 51 16 124 29 260 36 18 19 VIDEO 104 1.13M 44 24 101 23 - - 33 11 TOTAL 3916 - 798 83 659 67 608 37 443 55</addrLine>
									<country>Unspecified</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">BRIDGING THE DATA PROVENANCE GAP ACROSS TEXT, SPEECH, AND VIDEO</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-12-19">19 Dec 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">46F6AEB9E9C214184DA943E04B57F764</idno>
					<idno type="arXiv">arXiv:2412.17847v1[cs.AI]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-02-21T16:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Progress in AI is driven largely by the scale and quality of training data. Despite this, there is a deficit of empirical analysis examining the attributes of well-established datasets beyond text. In this work we conduct the largest and first-of-its-kind longitudinal audit across modalities-popular text, speech, and video datasetsfrom their detailed sourcing trends and use restrictions to their geographical and linguistic representation. Our manual analysis covers nearly 4000 public datasets between 1990-2024, spanning 608 languages, 798 sources, 659 organizations, and 67 countries. We find that multimodal machine learning applications have overwhelmingly turned to web-crawled, synthetic, and social media platforms, such as YouTube, for their training sets, eclipsing all other sources since 2019. Secondly, tracing the chain of dataset derivations we find that while less than 33% of datasets are restrictively licensed, over 80% of the source content in widelyused text, speech, and video datasets, carry non-commercial restrictions. Finally, counter to the rising number of languages and geographies represented in public AI training datasets, our audit demonstrates measures of relative geographical and multilingual representation have failed to significantly improve their coverage since 2013. We believe the breadth of our audit enables us to empirically examine trends in data sourcing, restrictions, and Western-centricity at an ecosystem-level, and that visibility into these questions are essential to progress in responsible AI. As a contribution to ongoing improvements in dataset transparency and responsible use, we release our entire multimodal audit, allowing practitioners to trace data provenance across text, speech, and video.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The capabilities and flaws of multimodal foundation models are often directly attributable to their training data <ref type="bibr">[66]</ref>, <ref type="bibr">[74]</ref>, <ref type="bibr">[75]</ref>, <ref type="bibr">[90]</ref>, <ref type="bibr">[91]</ref>, <ref type="bibr">[117]</ref>, <ref type="bibr">[130]</ref>. While the importance of data measurement has been widely established by prior work <ref type="bibr">[118]</ref>, so has a prevailing absence of data documentation <ref type="bibr">[10]</ref>, <ref type="bibr">[39]</ref>, transparency <ref type="bibr">[73]</ref>, and detailed understanding <ref type="bibr">[34]</ref>, <ref type="bibr">[37]</ref>, <ref type="bibr">[47]</ref>-especially for modalities other than text. A lack of thorough data analysis has led to significant challenges, including privacy issues <ref type="bibr">[107]</ref>, retracting datasets with harmful content <ref type="bibr">[35]</ref>, <ref type="bibr">[80]</ref>, adversarially bypassing safety filters <ref type="bibr">[66]</ref>, facial recognition bias with respect to gender and skin type <ref type="bibr">[11]</ref>, gender bias in hiring <ref type="bibr">[77]</ref>, benchmark contamination from overlapping train and test sets <ref type="bibr">[87]</ref>, and challenges in copyright <ref type="bibr">[84]</ref>. Understanding data provenance can aid mitigation attempts to reduce model bias and toxicity <ref type="bibr">[50]</ref>, <ref type="bibr">[102]</ref> address representation in data <ref type="bibr">[51]</ref>, contamination <ref type="bibr">[81]</ref>, and quality <ref type="bibr">[59]</ref>, <ref type="bibr">[95]</ref>, as well as practical challenges with identifying copyright-free and permissively licensed sets <ref type="bibr">[96]</ref>. modalities <ref type="bibr">[70]</ref>. As such, we focus our analysis on datasets that represent one or a pair of these modalities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Annotation Features &amp; Methodology</head><p>In particular, we analyze data trends for the state of data permissions (licenses and terms), sourcing (the web, human annotation, and synthetic generation), and representation (of tasks, organizations, languages, and countries). We adopt Longpre, Mahari, Chen, et al. <ref type="bibr">[123]</ref>'s methodology, including the license annotation taxonomy and process, to manually audit these features precisely and rigorously. We go beyond prior work, which considers dataset licenses, by extending the taxonomy to consider the terms of use of the sources of the dataset, either from models used to generate synthetic data (e.g. OpenAI's non-compete clause 1 or Meta's acceptable use policy for Llama 3.1 2 ), or the source's policy on content restrictions, which can be conveyed in the form of a license, terms of use, or content policy on a website <ref type="bibr">[119]</ref>. For each dataset, the source terms are annotated as Unrestricted, Unspecified, Source Closed or Model Closed, as defined in Table <ref type="table">2</ref>. For Figure <ref type="figure">2</ref> we combine Source Closed and Model Closed into Restricted.</p><p>As with prior work <ref type="bibr">[123]</ref>, <ref type="bibr">[124]</ref>, we engage domain experts for these annotation tasks-AI researchers whose work pertains to the modality and topic. Because many datasets are iteratively re-packaged before they appear in their final form and often shared on popular dataset marketplaces like Hugging-Face, Papers with Code or Github, prior work has found that relevant licensing terms or sourcing information for AI training data is frequently omitted <ref type="bibr">[123]</ref>. To ensure we collect this information, we require a full trace of metadata back to their original sources (sometimes a chain of github repositories, websites, or academic papers). This search can be onerous, especially for terms and licenses, but ensures rigor in the results. Table <ref type="table">1</ref> enumerates the full statistics of our audit. All annotations and analysis code will be made publicly available on release.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scope &amp; Dataset Selection</head><p>For each modality, we define the scope of the audit (detailed separately below), then aggregate resources to distill a list of relevant datasets. The scope is focused on (a) publicly available datasets, (b) widely used tasks in the context of general-purpose model development, and (c) relevance to generative tasks. However, we do consider classification-based datasets in text, speech, and video that can and are frequently re-purposed for generative uses (e.g. instruction tuning). Within the defined audit scope, we use a mix of the HuggingFace Datasets platform, survey papers, survey repositories, workshop proceedings, and expert review to accumulate relevant datasets. More detail about the dataset selection and collection process is given for each modality below. Each modality requires its own independent process, by virtue of their community dataset ecosystems being unique (discussed in Section 4). Note that text has a wider heterogeneity of published publicly available datasets than speech or video. Typically those datasets have been aggregated into large, standardized text-to-text collections, and as such we trace both these Text (Collections) and their constituent Text (Datasets). All datasets are described, linked, and attributed in Appendix D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">TEXT</head><p>Scope We focus on providing an extensive audit for post-training datasets, used in training language models. We include single and multi-turn formats, encompassing both datasets typically used for instruction finetuning (SFT) and preference alignment <ref type="bibr">[105]</ref>. This scope reflects the prominent role of general-purpose language models, which benefit from multi-task training on heterogeneous collections that span a variety of linguistic, reasoning, and knowledge intensive tasks like question answering, coding, tool use, translation, and classification <ref type="bibr">[49]</ref>, <ref type="bibr">[64]</ref>.</p><p>Dataset Selection We expand the study conducted by the Data Provenance Collection <ref type="bibr">[123]</ref>, from 44 dataset collections (of 1858 supervised text datasets) to a superset of 108 collections of 3717 datasets, prioritizing recent, popular publicly available HuggingFace Datasets introduced between 2022 and April 2024. Our collection sourced popular datasets from recent survey papers <ref type="bibr">[114]</ref>, <ref type="bibr">[121]</ref> and tools <ref type="bibr">[122]</ref>. We additionally reviewed HuggingFace Datasets' most downloaded datasets every month, from April to July 2024, under the Natural Language Processing category, as well as the SFT/DPO datasets associated with popular open model releases. We also drew from major multilingual data repositories, including the SEACrowd Catalogue <ref type="bibr">[126]</ref>, the Masader Arabic Data Catalogue <ref type="bibr">[52]</ref>, AI4Bharat <ref type="bibr">[27]</ref>, and the Aya Collection <ref type="bibr">[134]</ref>. Lastly, our list of datasets was reviewed and supplemented by language model experts to fill in notable omissions. In total, we trace 1 OpenAI Terms of Use 2 Llama 3.1 Acceptable Use Policy the provenance and features of 3713 text datasets from 108 collections, covering 395 popular tasks, spanning from 1994 to 2024.</p><p>2.2 SPEECH Scope We audit speech datasets for which automatic speech recognition (ASR) was noted as a primary task. We focus on ASR datasets because: (1) ASR is fundamental to many speech technologies, including dictation tools, voice assistants, and chatbots <ref type="bibr">[32]</ref>, <ref type="bibr">[68]</ref>; (2) large-scale speech datasets are typically designed for ASR <ref type="bibr">[89]</ref>; (3) ASR data follows standardized formats, making comparisons easier (e.g., corpus of audio clips paired with text); and (4) ASR data can often be reused for other tasks like text to speech (TTS) <ref type="bibr">[7]</ref> or language identification <ref type="bibr">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset Selection</head><p>To curate a representative sample of popular ASR datasets, we relied on a combination of survey repositories <ref type="foot" target="#foot_0">3</ref> , and HuggingFace Datasets using the "Automatic Speech Recognition" and "Text-to-Speech" task tags. We expanded coverage to well-documented datasets on the OpenSLR<ref type="foot" target="#foot_1">foot_1</ref> platform, even if they were newer or less widely used. We expect this might reflect datasets that could be adopted more widely in the future. Finally, we included datasets related to low-resource languages and other languages not well-covered by our initial searches. Speech recognition models are increasingly highly multilingual <ref type="bibr">[33]</ref>, <ref type="bibr">[104]</ref>, <ref type="bibr">[131]</ref>, and datasets serving different communities of builders and end-users around the world are a priority for making speech recognition technologies more inclusive. In total, we trace the provenance and features of 95 speech datasets, covering 18 popular ASR tasks, spanning from 1990 to 2024.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">VIDEO</head><p>Scope Early video understanding models primarily focused on video classification, detection and action recognition, where short clips were categorized into predefined classes <ref type="bibr">[30]</ref>, <ref type="bibr">[69]</ref>. More advanced tasks such as temporal action segmentation, video question answering, and video captioning were later introduced to build upon these foundational tasks <ref type="bibr">[63]</ref>, <ref type="bibr">[111]</ref>. Recently, following the success in the field of image generation, video generation from text has become a new task that has shown promising results <ref type="bibr">[72]</ref>, <ref type="bibr">[82]</ref>, <ref type="bibr">[115]</ref>, <ref type="bibr">[140]</ref>. Given the scarcity of datasets for text-to-video and the often undocumented sources of data used in recent video generation models <ref type="bibr">[127]</ref>, we take a broader approach to our collection of video datasets. We focus on annotating popular video tasks and limit our scope to datasets corresponding to video tasks that are either published, highly cited, or have 100+ downloads on HuggingFace. This approach is justified by three key factors: (1) the usefulness of video data to the research community stems from its collection and presentation in peer-reviewed work, (2) datasets can often be repurposed between different tasks, allowing for applicability to new tasks such as video generation from text, and (3) focusing on highly cited datasets ensures that datasets' quality and relevance has been validated by the research community.</p><p>Dataset Selection We include datasets tagged with "Video Classification", "Text-to-Video", and "Video-Text-to-Text" from HuggingFace Datasets. We augmented this with datasets tagged by "Video Understanding" or "Video Generation" in PapersWithCode, as well as datasets listed in a popular Github survey repository. We also consulted the proceedings of recent video workshops: the Large Scale Video Understanding and Egocentric Vision workshops. We separately consulted a committee of non-author video experts to supplement the list with relevant datasets published at CVPR, ICCV, ECCV, and IJCV. In total, we trace the provenance and features of 104 video datasets, covering 33 popular video tasks, spanning from 2009 to 2024.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head><p>We discuss three key results related to (1) the rising use of web, social media and synthetic sources, (2) inconsistent and opaque restrictions on data use, and (3) a lack of improvement in geographical or linguistic representation. Each of these findings holds across modalities, at the ecosystem level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">RISING USE OF WEB, SOCIAL MEDIA &amp; SYNTHETIC DATA</head><p>The need for scale, and heterogeneity have driven rising use of data from web-crawled, social media, and synthetic data sources. Developers have sought out ever larger and conveniently Figure <ref type="figure">1</ref>: The cumulative size of data (log-scale tokens for text, hours for speech/video) from each source category, across modalities. The source categories in the legend are ordered by descending quantity. Speech and video sources are increasingly dominated by internet videos and YouTube. Whereas text is predominantly web or encyclopedia-based (wiki) sources, synthetic text is rising in popularity.</p><p>accessible sources of training data <ref type="bibr">[24]</ref>, <ref type="bibr">[57]</ref>. While small, human-curated datasets are often sufficient and sometimes preferred due to higher quality, these sources often do not scale to present demands <ref type="bibr">[24]</ref>, <ref type="bibr">[26]</ref>. In Figure <ref type="figure">1</ref>, we empirically measure the rising use of web crawling and social media (or "forum") websites that provide some of the most scalable and fresh content. While web-sourced data was always prominent, the balance of sources becomes much more skewed after 2018-note the use of the y-axis log scale. We find for Speech and Video that by far the most prominent source of data has become internet videos, and specifically YouTube. Nearly 1M hours each of Speech and Video data from this source far outstrips the next most common sources, which comprise less than 100K hours. For Speech, the primary data sources used to be Calling Platforms (pre-2017), content manually collected with Human Participation, and Audiobooks, but since 2018 internet videos have supplanted these other sources. For Video, since 2013, YouTube, synthetic, and general web data sources all constitute a significantly larger portion of data used in prominent video datasets, outstripping the use of Movies, Flickr, Getty, or human curated sources. Among text post-training datasets, we see a similar trend with general or news web-based sources, including encyclopedic sources (mainly Wikipedia), providing the majority of tokens over time. Encyclopedic sources alone now contribute over 1T tokens in total.</p><p>Synthetic data sources are rising the most rapidly. Within the video modality, the introduction of VidProm <ref type="bibr">[138]</ref> in 2024, consisting of nearly 7M synthetically generated videos, offered a large shift in the video source distribution. Within the textual modality, from fig. <ref type="figure">1</ref>, synthetic data represented &lt;0.1% of the quantity of Web Encyclopedia data in 2020, but is now 10% its proportion in 2024, making up the 5th largest source of tokens. The top models used in generating datasets are mainly from OpenAI. The top 5 consist of ChatGPT, version unspecified (15.0% of synthetic datasets), GPT-4 (14.4%), BART (10.1%), GPT-3 (8.3%) and GPT-3.5-Turbo (4.9%). The average synthetic dataset also has notably longer turns (in tokens) than the average natural dataset: 1,756 tokens vs 1,065. The task distribution of textual synthetic datasets is shifted towards longer form, open-generation and creative tasks. For example, 88.1% of natural datasets contain classification tasks, compared to only 66.3% of synthetic datasets. Natural data is also more likely to cover translation than synthetic data (72.4% of datasets vs only 22.9% of synthetic datasets).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">INCONSISTENT USE RESTRICTIONS</head><p>In the United States, creators of a work automatically have a copyright interest that gives them exclusive rights to make copies and derivatives of the work (17 U.S.C. ¬ß 106). Licenses are legal documents through which the owners of a work express how others may use their work. By contrast, Terms of Service express a contract between a platform and its users to spell out how a platform and its content may be used <ref type="bibr">[28]</ref>. For simplicity, we use "Licenses" to refer to dataset restrictions, and "Terms" to refer to restrictions on the sources of datasets. There remain open questions about whether certain data licenses are enforceable, but these licenses signal the intention of data creators and therefore warrant consideration as the data creators may be best positioned to understand the sensitivities of the data (privacy, copyright, representation, etc.), and the most impacted by its downstream use <ref type="bibr">[88]</ref>, <ref type="bibr">[93]</ref>, <ref type="bibr">[94]</ref>, <ref type="bibr">[97]</ref>. The extent to which a practitioner adheres to dataset licenses or source terms remains Figure <ref type="figure">2</ref>: The distribution of restrictions from dataset licenses and their sources' terms. We break this down by the count of datasets (top), as well as total tokens or hours (bottom). Each license is categorized as Non-commercial/Academic (NC/Acad), Unspecified, or Commercially licensed. Each dataset may also have terms from the source: Restricted to non-commercial use, Unspecified restrictions, or Unrestricted. Two main findings across modalities emerge: (1) Commercially licensed datasets represent a larger set of tokens and hours, relative to number of datasets; however, (2) the vast majority of those commercially licensed tokens/hours bare restrictions from their sources. Tables <ref type="table" target="#tab_3">3</ref> and <ref type="table">4</ref> in the appendix provide detailed numbers.</p><p>an open question, and may depend on jurisdiction or the desired model's use cases <ref type="bibr">[88]</ref>. This work does not propose one standard for all developers. For these reasons we restrict our treatment and discussion here to tracing the lineage and distribution of licenses and terms for a given modality.</p><p>Data source terms are much more restrictive than the dataset's documented license restrictions. In Figure <ref type="figure">2</ref>, we find only 25%, 33%, and 32% of text/speech/video datasets are licensed noncommercially. This value is even lower if we consider the proportion of tokens or hours, with 21%, 26%, and 33% of text/speech/video quantities carrying license restrictions. However, a staggering 99.8%, 78%, and 99% of those quantities carry some form of non-commercial restriction on one of their sources. For text, these restrictions are frequently from being generated by OpenAI or other models with a non-compete clause, while for speech and videos this is often since the datasets are derived from web or social media sources.</p><p>Inconsistencies between dataset licenses and their source's restrictions pose challenges to practitioners. A large amount of datasets have permissive or unspecified licenses, but some set of their sources carry non-commercial restrictions. This inconsistency is measurable-representing 79% of tokens in text datasets, 55% of speech hours, and 65% of video hours. Additionally, 19%, 14%, and 36% of text, speech, and video datasets have no license or intended use documentation (from our audit of the datasets' documentation on Hugging Face Datasets, GitHub, and Papers with Code). A lack of centralized documentation around these restrictions means it can be misleading to developers who are attempting to source data according to their own legal standards for copyright and privacy. Furthermore, lack of documentation can hamper developers following best practices around data preparation and transparency <ref type="bibr">[39]</ref>, <ref type="bibr">[73]</ref>.</p><p>Large quantities of commercially licensed text datasets are locked in collections without clear information to separate them from restrictive datasets. In Figure <ref type="figure">2</ref> (top and bottom), we see the number of datasets and number of tokens without restrictions is significantly higher for Text (Datasets) than Text (Collections). Specifically, 60% more Datasets (or 75% more tokens) are commercially licensed, than for Collections. This demonstrates that many collections contain significant amounts of commercially licensed data. While our audit traces licenses for all datasets within a collection, most collections do not aggregate or expose this documentation. As a result, practitioners may be left without easy access to filter for the subsets appropriate for their sourcing standards.</p><p>3.3 GEOGRAPHICAL &amp; LINGUISTIC REPRESENTATION IS NOT IMPROVING AFRICA ASIA EUROPE N AMERICA OCEANIA S AMERICA By Count TEXT 0.3 13.4 24.0 61.5 0.7 0.2 SPEECH 3.6 35.7 30.4 30.4 0.0 0.0 VIDEO 0.0 25.2 24.4 48.0 0.8 1.6 By Tokens or Hours TEXT 0.0 6.1 55.4 38.4 0.1 0.0 SPEECH 0.1 38.8 18.8 42.4 0.0 0.0 VIDEO 0.0 23.1 22.0 38.2 16.7 0.1 Figure 3: The geographical distribution of countries (world maps) and continents (table) represented by dataset creators. Despite some differences in European, Russian, and Middle Eastern representation, creators are heavily concentrated in the US, China, and Western Europe, with little to no representation in South America or Africa, across modalities. The current Gini coefficient for (Text, Speech, Video) = (0.92, 0.86, 0.74), where higher values indicate more concentration.</p><p>The importance and progress of representation in AI training data. Diversity and representation in training datasets, and among their creators, are widely acknowledged as essential to building AI models that are less biased, more useful, and more equitable <ref type="bibr">[6]</ref>, <ref type="bibr">[18]</ref>, <ref type="bibr">[25]</ref>, <ref type="bibr">[31]</ref>, <ref type="bibr">[61]</ref>, <ref type="bibr">[101]</ref>, <ref type="bibr">[112]</ref>, <ref type="bibr">[113]</ref>, <ref type="bibr">[134]</ref>, <ref type="bibr">[137]</ref>. Prior work has measured the diversity of languages in data along with cultural, ideological, and geographical imbalances <ref type="bibr">[8]</ref>, <ref type="bibr">[14]</ref>, <ref type="bibr">[41]</ref>, <ref type="bibr">[55]</ref>, <ref type="bibr">[62]</ref>. These studies have exposed significant flaws, often in the form of bias and discrimination, stemming directly from poor representation in data <ref type="bibr">[12]</ref>, <ref type="bibr">[35]</ref>. As this problem has now been widely acknowledged for decades, recent efforts have foregrounded sourcing data multilingually and multi-culturally, from native speakers and creators (e.g. ROOTS <ref type="bibr">[60]</ref>, the Aya Dataset <ref type="bibr">[134]</ref>, the SEACrowd Catalogue <ref type="bibr">[126]</ref>, the Masader Catalogue <ref type="bibr">[52]</ref>, Common Voice <ref type="bibr">[13]</ref>, Causal Conversations V2 <ref type="bibr">[101]</ref> or Moments in Time <ref type="bibr">[18]</ref>).</p><p>Measuring geographical and linguistic representation. Naturally, we aim to use our audit to measure the progress of these efforts on geographical and linguistic representation in the AI ecosystem. We measure the progress of two forms of representation: (1) language diversity of text and speech data, and (2) geographical diversity of the creators, in all three modalities. For languages, we use the ISO 639-1 and 639-3 language codes and categories of language families from Glottolog 5.0. <ref type="foot" target="#foot_2">5</ref> In Figure <ref type="figure" target="#fig_0">4</ref>(a, c) we display the cumulative sum of unique languages and countries present across all audited datasets, at each time period since 2013. While these measurements illustrate the absolute rise in diversity, we also hope to measure the relative dispersion, or equality of languages and countries in the distribution. In Figure <ref type="figure" target="#fig_0">4</ref>(b, d), we use the Gini Index <ref type="bibr">[1]</ref>, <ref type="bibr">[2]</ref>, a traditional measure of statistical dispersion, frequently used to quantify inequality. This allows us to understand if the distributions of languages and creators are more representative of the international community over the last decade, or equally concentrated despite apparent efforts at the margins.</p><p>Inequality in geographical representation remains very high, with few organizations creating datasets from the Global South. For every dataset, our audit recorded the organizational affiliations of each creator of the dataset. <ref type="foot" target="#foot_3">6</ref> These organizations were then manually mapped to the country in which they are headquartered. Occasionally, organizations like BigScience, BigCode, or Masakhane have international or continental representation, and were counted as such. In Figure <ref type="figure">3</ref>, we measure the current state of diversity among these creator organizations-where a Gini coefficient of 1 indicates highest concentration, and lower values more broad representation. Without taking up the normative question of what a truly "fair" score would be, these values provide useful comparisons across modalities and over time. We find that Text dataset developers are particularly homogeneous, with a Gini-coefficient of 0.92; followed by Speech, at 0.86 and Video at 0.74, which remain high, but are meaningfully less concentrated. Figure <ref type="figure">3</ref> also illustrates that even this limited diversity is still concentrated in North America, Europe, East Asia, and less so in the Global South.</p><p>In Figure <ref type="figure">3</ref>, we also compare the distribution of datasets, and of tokens or hours by continent. Dataset creators affiliated with African or South American organizations account for fewer than 0.2% of all tokens or hours, in each modality. In contrast, Asian affiliated organizations represent large proportions of the data, particularly for speech (39% of hours, attributed predominantly to YODAS <ref type="bibr">[89]</ref>). Much of this driven by Chinese, Indian, Russian, and Saudi Arabian creators. Most prominently, the combination of North American and European datasets comprises 93% of text tokens, 61% of speech hours, and 60% of video hours. Geographical representation has not significantly improved for over a decade. In Figure <ref type="figure" target="#fig_0">4</ref>(c), we measure the total unique number of countries represented across all dataset creator organizations.</p><p>While individual creators will have varying ethnic and national affiliation, we treat this as an estimate for the influence of each locale in dataset development. We find that while the number of represented countries has risen steadily each year, for each modality, this represents only an illusion of progress. Empirically, the Gini coefficient for each modality has not significantly changed since the start of the period we examine in 2013. Geographic diversity has increased only among Video datasets, and these increases are not significant at the ùëù = 0.05 level. Text and Speech geographical representations appear to remain stable over the last decade of AI development.</p><p>Multilingual representation has not improved by most measures. Similar to geographical representation, we measure the cumulative number of ISO 639-1 languages and language families over time, as well as the per-modality Gini-coefficient. Figure <ref type="figure" target="#fig_0">4</ref>(a) shows significant increases in the number of languages available for speech and text, especially in 2019, and 2023, with the introduction of large sets like Flores <ref type="bibr">[56]</ref>, xP3x <ref type="bibr">[98]</ref>, Common Voice <ref type="bibr">[13]</ref>, and the Aya Collection <ref type="bibr">[134]</ref>. However, once again, when measuring the cumulative dispersion of these datasets in Figure <ref type="figure" target="#fig_0">4</ref>(b), only Text language families demonstrate any improvement from pre-2013 to the present. Improvements in the Gini coefficient appear to be largely driven by individual large-scale projects like xP3x and Common Voice, both introduced in 2019. Subsequently, newer datasets remain predominantly monolingual, causing measures of concentration in text languages, speech languages, and language families to remain consistently high. 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% Text Speech Video 47.3 6.0 7.1 15.2 10.3 8.2 6.0 16.4 16.9 15.7 15.4 15.1 10.6 9.3 71.1 5.5 8.5 10.4 Academic Research Group Industry Lab Corporation Startup Other Government Unspecified Creator Category Academia, research non-profits, and industry labs continue to drive public dataset development.</p><p>As well as understanding the geographic associations of the organizations creating popular datasets, we manually categorize them into: Academic Organization (e.g., universities), Research Groups (e.g., non-profits such as BigScience, EleutherAI or AI2), Industry Labs (e.g., Cohere For AI, Google DeepMind), Corporations (e.g. Google, Meta), Startups (e.g., OpenAI, Anthropic), Governments, Unspecified (datasets where owner affiliation is not shared), or Other. When a dataset is released in collaboration between organizations, we record each organization. In Figure <ref type="figure" target="#fig_1">5</ref>, we find that universities and other academic organizations account for 16%, 47%, and 71% of all recorded dataset releases, across Text, Speech, and Video respectively. Research groups, industry labs and even corporations are also significant contributors, especially for Text datasets, where ecosystem contributors are far more distributed. The significant role of academic organizations in Video and Speech may suggest that the risk profile of releasing Text datasets differs somewhat from Video and Speech datasets, which may have more distinct privacy concerns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION</head><p>The rise of web-based, social media, and synthetic datasets may pose greater risks to privacy, copyright, and bias. Section 3.1 discusses the rise of web-based sources and particularly social media as primary sources for speech and video. Figure <ref type="figure">1</ref> shows these sources now exceed more traditional, curated sources such as movies, audiobooks, radio, TV, or content hand-crafted by human participants-by at least one order of magnitude. These websites made of mostly user-generated content are a natural choice, given that they scale in the quantity, freshness, and heterogeneity that is best suited to train general-purpose models <ref type="bibr">[70]</ref>, <ref type="bibr">[92]</ref>. However, prior work suggests that crowd-sourced, user-generated web content also introduces more challenges than curated content, particularly for privacy, copyright, bias, harm, and factuality.</p><p>Web-based and particularly user-generated content is disproportionately likely to include personally identifiable information (PII) <ref type="bibr">[40]</ref>, <ref type="bibr">[81]</ref>, <ref type="bibr">[107]</ref>, and copyrighted content <ref type="bibr">[16]</ref>, <ref type="bibr">[88]</ref>. These can be reproduced in the outputs of AI models <ref type="bibr">[53]</ref>, <ref type="bibr">[78]</ref>, creating privacy and copyright concerns <ref type="bibr">[110]</ref>. Open datasets being used to train GPAI often attempt to filter-but frequently miss-PII and copyrighted data <ref type="bibr">[107]</ref>, <ref type="bibr">[136]</ref> (although not all do <ref type="bibr">[99]</ref>). Social media, in particular, is also known to have bias, toxicity and factuality issues <ref type="bibr">[19]</ref>, which can manifest in trained models, even after alignment <ref type="bibr">[85]</ref>. Lastly, while synthetic data can help reduce the prevalence of PII, copyright, or bias in data, it comes with its own challenges <ref type="bibr">[86]</ref>, <ref type="bibr">[120]</ref>.</p><p>Social Media websites have become one of the most prominent data sources, but their Terms often restrict crawling or commercial use. We find that 71% of Video data and 69% of Speech data is from YouTube which has become a prominent source of data, given its scale, freshness, and multimodality (containing videos, speech, images, and text) <ref type="bibr">[4]</ref>, <ref type="bibr">[9]</ref>, <ref type="bibr">[22]</ref>, <ref type="bibr">[79]</ref>, <ref type="bibr">[89]</ref>, <ref type="bibr">[109]</ref>. However, YouTube is a social media platform owned by Google and its Terms of Service<ref type="foot" target="#foot_4">foot_4</ref> prohibit third parties from crawling YouTube. While content creators maintain their ownership rights in the material they upload to YouTube, the YouTube Terms of Service also grant Google a license to reproduce, modify, display, and use the content for purposes connected to YouTube's "business", which may include building machine learning models; even if the copyright holder has selected a permissive license, YouTube's Terms disallow external parties from crawling that data. Model developers such as Nvidia and OpenAI have been sued in the U.S. by content creators who allege that they unlawfully trained on YouTube videos <ref type="bibr">[116]</ref>, <ref type="bibr">[135]</ref>. Large social media platforms and forums have also adopted restrictive terms in recent years, including Reddit and StackOverflow. <ref type="foot" target="#foot_5">8</ref> As these data sources become critical to scaling AI systems, access has been made exclusive, which may hamper academic, non-profit, or open source model development-to the extent that social media platforms can enforce their terms against third party developers. <ref type="foot" target="#foot_6">9</ref>Ambiguous and poorly documented use restrictions may significantly inhibit model developers adhering to cautious legal and ethical data sourcing standards. In Section 3.2. we find that a significant amount of data carry non-commercial restrictions in their sources, rather than on the final dataset, which can contain no license or a permissive one. For text and video, these restrictions can equate to 99% of all tokens and hours. These inconsistencies are the result of datasets being iteratively re-packaged and re-licensed, without carrying on documentation <ref type="bibr">[123]</ref>. While not every developer will employ the same filtering standards, our work shows that the challenges to separate and identify appropriate datasets remain difficult across these modalities. Without continued audits and documentation, practitioners may be forced to forego large collections of partially viable data, hampering data scaling laws <ref type="bibr">[26]</ref>, or take on avoidable risk. We hope this released audit will provide greater tools for practitioners to apply their own standards, to make informed decisions on training data use.</p><p>The limitations of measures of geographical and linguistic representation. It is important to note that measures of geographical and linguistic representation are imperfect. We are limited by partial information about the developers' identities (including for privacy reasons), limited transparency into how frequently these datasets are used, and the extent to which proprietary datasets may fill in representation gaps behind closed doors. Nonetheless, we believe the breadth and rigour of the audit make this the best available empirical measure of representation in publicly documented datasets. Further, we propose the goal of measuring representation in AI data as essential to understanding progress, or its absence, towards AI systems that fairly serve the broader community of users. Figure <ref type="figure">3</ref> and Figure <ref type="figure" target="#fig_0">4</ref> demonstrate that despite the absolute rise of geographical and linguistic representation, the relative western-centric concentration persists, across thousands of surveyed datasets. We release all audit materials for transparency and replicability, and for further use by the research community.</p><p>Conducting representative analyses of an ecosystem comes with assumptions. First, an ecosystem for AI is by nature, not centralized or organized. Widely used datasets for Text are often hosted on Hugging Face, but this is frequently not the case for Speech or Video. Similarly, while Text data undergoes frequent dataset re-packaging for general-purpose post-training, this is not true to the same extent for other modalities. As such, the scope and dataset selection process need to be designed for each modality, rather than a single, simple protocol, which inevitably will not accurately represent one modality at its ecosystem-level. Similarly, we chose a subset of modalities of interest to foundation model development <ref type="bibr">[104]</ref>, <ref type="bibr">[115]</ref>, but note there are many other left for future work (e.g., images, 3D representations, tabular, time series, graphs, and geospatial data).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LABEL DEFINITION MODEL CLOSED</head><p>A model used to generate part or all of the dataset prohibits using its outputs commercially, to develop a competing AI model, or in general. SOURCE CLOSED The source has a license or terms that prohibits use of the data, either commercially, from being crawled, to develop AI, or in general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>UNSPECIFIED</head><p>No information can be found relevant to restrictions, or lack thereof, for this source.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>UNRESTRICTED</head><p>The source has a commercially permissive license, such as CC BY, or explicitly states the data is open for broad use.</p><p>Table 2: The taxonomy used to determine use restrictions on each dataset source. Each source in a dataset is examined and fit into one of these categories. The dataset Terms are then labelled according to the strictest terms across the sources, with Model Closed and Source Closed considered stricter than Unspecified which is in turn stricter than Unrestricted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A EXTENDED RELATED WORK</head><p>Progress in machine learning across modalities from speech <ref type="bibr">[104]</ref> to vision <ref type="bibr">[38]</ref> to text <ref type="bibr">[21]</ref>, <ref type="bibr">[49]</ref> has benefited from advancements in large pre-training and fine-tuning corpora. The development of multimodal corpora has also been key to several recent advances, as with CLIP in the image/text domain <ref type="bibr">[45]</ref>, CLAP for audio/text settings <ref type="bibr">[54]</ref>, and a number of other models involving both text and images, audio or video <ref type="bibr">[65]</ref>, <ref type="bibr">[67]</ref>, <ref type="bibr">[104]</ref>, <ref type="bibr">[132]</ref>.</p><p>The datasets powering these advances are not, however, always well-documented, despite the existence of standards and frameworks for recording and annotating dataset metadata that range from 'data statements' <ref type="bibr">[10]</ref> to 'datasheets for datasets' <ref type="bibr">[39]</ref> and others <ref type="bibr">[17]</ref>. The key problem is not a deficiency of any particular framework, but rather inconsistent adoption and fragmentation <ref type="bibr">[125]</ref>. Much prior work has argued for the need to document and audit these datasets <ref type="bibr">[44]</ref>, <ref type="bibr">[46]</ref>, motivated by concerns from reproducibility <ref type="bibr">[58]</ref> to interpretability <ref type="bibr">[92]</ref> to bias and fairness problems that may stem from problematic content in training data <ref type="bibr">[35]</ref>.</p><p>There have been several attempts to carry out such audits, with prior work examining pretraining data <ref type="bibr">[124]</ref>, general web corpora <ref type="bibr">[23]</ref>, <ref type="bibr">[37]</ref>, instruction fine-tuning datasets <ref type="bibr">[123]</ref>, and the documentation fields of the HuggingFace Datasets platform in particular <ref type="bibr">[139]</ref>. For speech and vision, there has been less work, with many discussions of datasets in the aggregate occurring in survey papers <ref type="bibr">[3]</ref>, <ref type="bibr">[106]</ref>, research aimed directly at improving model performance <ref type="bibr">[83]</ref> or close examinations of questions like bias in small groups of datasets <ref type="bibr">[12]</ref>, <ref type="bibr">[133]</ref>.</p><p>Prior work has also examined the identities, affiliations and national origin of paper authors <ref type="bibr">[128]</ref> in AI, but an analogous look at the producers of datasets is lacking. We aim to carry out such analyses: replicating those for pretraining and text finetuning datasets in video and audio domains, and surveying provenance and legal status. Finally, there has also been significant recent attention to legal questions in the collection and use of AI training data <ref type="bibr">[29]</ref>, <ref type="bibr">[84]</ref>. The complex process involved in preparing these datasets <ref type="bibr">[88]</ref>, and the ambiguous licensing of inputs, can make understanding the legal status of the final output quite difficult.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B DATASET LICENSES &amp; TERMS</head><p>Detailed taxonomy We code the legal restrictions placed on use of datasets along two axes. First, we identify whether a dataset's license permits commercial use ("Commercial" in Table <ref type="table" target="#tab_3">3</ref>), only non-commercial / academic use ("NC / Acad"), or does not clearly specify what is permitted ("Unspecified"). The latter category includes datasets for which we were unable to locate a license. Datasets which are in the public domain and not subject to a license are counted as commercially usable. Second, we annotate the contractual or terms-of-use restrictions placed on dataset use by the source of each dataset. There are four levels, defined in Table <ref type="table" target="#tab_3">3</ref>. Note that the Model Closed status can only apply to datasets that are AI-generated, at least in part. Some datasets can carry both Model Closed and Source Closed status, but we count the Model Closed first for simplicity.</p><p>Detailed breakdown Tables <ref type="table" target="#tab_3">3</ref> and <ref type="table">4</ref> present crosstabs of these two dimensions, according to respectively the total amount of content and the number of datasets. The most notable finding, as discussed in the main text, is the frequency of clashing restriction status between licenses and terms. By amount of content, fully 73.0% of text content, 55.0% of speech content, and 21.6% of video content is subject to a license permitting commercial use but also to terms restrictions forbidding it, or the reverse. The absolute level of restrictions is also high, with &lt; 0.1% of text content, 5.4% of speech content, and 0.6% of video content usable for commercial purposes under both licenses and terms. Table  <ref type="table">4</ref>: A breakdown of the percentage of license and terms restrictions by dataset count. The much higher frequency of restrictions at the collection level is because we consider a collection's license or terms status to be the most restrictive of those for its datasets. Note that percentages may not add to exactly 100% because of rounding. over other, increasingly prominent tasks like generation and reasoning. Given our selection criteria, all datasets for speech are for ASR tasks, but other tasks like speaker identification and translation are also represented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LICENSE / TERMS RESTRICTED UNSPECIFIED UNRESTRICTED TOTAL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D DATASETS</head><p>This section provides a detailed overview of the datasets we have collected and analyzed. Table <ref type="table" target="#tab_6">5</ref> summarizes the text datasets, Table <ref type="table" target="#tab_7">6</ref> the audio datasets, and Table <ref type="table" target="#tab_9">7</ref> the video datasets. Each of these tables lists broad collections of data, sorted in chronological order, and provides information about their properties, sizes, sources and permissions. Each collection can include multiple datasets, and</p><p>0% 5% 10% 15% 20% 25% Classification Q&amp;A Generation Reasoning Creativity Code Summarization Bias Detection Translation Resp. Ranking Text 0% 20% 40% 60% 80% 100% Recognition Speaker ID Translation Language ID Text-To-Speech Bias Detection Keyword Spotting Query by Ex Speech Synthesis Speech 0% 10% 20% 30% 40% 50% Classification Captioning Segmentation Summarization Localization Action Recognition Q&amp;A Action Detection Pose Estimation Object Detection Video they generally reflect the ways dataset creators have grouped their datasets (such as in the same paper). Because of the large number of datasets, we provide detailed information about their licenses and original published papers, where applicable, in the supplementary Attribution Card in Appendix F.</p><p>Annotation Details: Text For post-training text datasets it is common to package many together as collections, such as Flan <ref type="bibr">[49]</ref> or P3 <ref type="bibr">[48]</ref>. This practice is not common to the same extent for speech or video datasets. For much of the text analysis, where possible, we chose to analyze statistics at the collection-level, since practitioners are more likely to adopt a collection for general-purpose posttraining, than an individual dataset within the collection. Also, in dataset-level statistics, metadata for a single collection with many datasets can get repeated and overwhelm the statistics unfairly (e.g. the dataset aggregator/creator being repeated hundreds of times). Consequently, our collection-level analysis of the text modality is reflected in Figure <ref type="figure">1</ref>, Figure <ref type="figure">3</ref>, Figure <ref type="figure" target="#fig_1">5</ref>, Figure <ref type="figure" target="#fig_0">4</ref>, Figure <ref type="figure" target="#fig_3">7</ref>, and Figure <ref type="figure" target="#fig_2">6</ref>. However, for Figure <ref type="figure">2</ref> we draw the distinction between collection and dataset metrics, as practitioners may wish to unpack collections to extract only commercially licensed data. In that case a Collection inherits the most restrictive license and terms of its constituent datasets.</p><p>For annotating creator organizations, we follow prior work's instructions <ref type="bibr">[123]</ref>. For each dataset they record the affiliations listed on the academic paper or GitHub or HuggingFace object in which the dataset was released. This does not include the organizations who created or owned the sources from which the data was derived. For instance, the SQuAD dataset <ref type="bibr">[5]</ref> would be associated with Stanford (the authors' affiliation), but not Wikipedia, which the data was partially derived from. For a dataset that has authors affiliated with multiple organizations, the dataset will be counted towards each organization.</p><p>Annotation Details: Speech In many cases, multiple versions of a dataset exist due to datasets being expanded or updated. In these scenarios, we used the release date from the initial version (since release dates for subsequent versions were not always clear), but used metadata from the most recently released version for which information was available to offer an overview of the current landscape of data. However, if the dataset versions could not be meaningfully aggregated (e.g. different licenses), or did not appear to be cumulatively designed (non-overlapping or otherwise semantically disjoint data), we maintained separate records. We kept only datasets for which ASR was noted as a primary task. For example, if a dataset was primarily intended for text-to-speech or speaker recognition, we did not keep it even if it could conceivably be repurposed for ASR. When computing hours, we excluded any hours without supervisory transcripts/scripts (unlabeled data), but kept hours with "weak supervision" (e.g. model-generated transcripts from speech audio). We recognize the difficulty in comprehensively covering all relevant datasets. Annotation Details: Video In video, a single dataset can be re-purposed and annotated to address different tasks <ref type="bibr">[18]</ref>, <ref type="bibr">[43]</ref>. We consider these as two different datasets even if they have the same video source since now they can be used for different computer vision tasks. Table <ref type="table" target="#tab_6">5</ref>: Alignment tuning (text) collections and properties. Collection properties include numbers of datasets, tasks, languages, and text domains. The SOURCE column indicates whether a collection contains human-generated web text ( ), language model outputs ( ) or both (</p><p>). The USE column indicates whether a collection includes data freely usable even for commercial purposes ( ), data usable only for noncommercial purposes or academic research ( ) and data whose license status is not specified precisely enough to allow us to determine commercial use permissions ( ). Note that each collection may have different datasets with one, two, or all three of these statuses. Finally, the OAI column indicates collections which include OpenAI model generations. Datasets are sorted chronologically to highlight trends over time. Table <ref type="table" target="#tab_7">6</ref>: Audio collections and properties. Collection properties include numbers of audio hours (HR), speakers (SPKR), languages (LANG), creator institutions (CREAT), tasks (TASKS), data sources (SRC), and topics (TOPICS). The number of datasets is not listed because all collections include only one dataset, except for M2ASR which has four. The US column indicates datasets from or partly from the United States, the AC column datasets created by academic institutions, and the IND column datasets created by industry. Note that a dataset can have all of these, none of them, or any combination of them. The USE column indicates whether a collection includes data freely usable even for commercial purposes ( ), data usable only for noncommercial purposes or academic research ( ) and data whose license status is not specified precisely enough to allow us to determine commercial use permissions ( ). Note that each collection may have different datasets with one, two, or all three of these statuses. Datasets are sorted chronologically to highlight trends over time. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COLLECTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COLLECTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F ATTRIBUTION CARD</head><p>Here we provide detailed information about the licenses of each data collection and its constituent datasets, and cite all of the papers (455 in all) which introduced datasets we consider. Text datasets are laid out in Table <ref type="table" target="#tab_12">8</ref>, audio datasets in Table <ref type="table" target="#tab_16">9</ref>, and video datasets in Table <ref type="table" target="#tab_19">10</ref>. Because of the large number of references, we include a second bibliography after the tables (named 'Attribution Card References'), with numbered citations in this section referring to that second bibliography. Various <ref type="bibr">[18]</ref>, <ref type="bibr">[34]</ref>, <ref type="bibr">[47]</ref>, <ref type="bibr">[50]</ref>, <ref type="bibr" target="#b299">[152]</ref>, <ref type="bibr" target="#b324">[174]</ref>, <ref type="bibr" target="#b355">[202]</ref>, <ref type="bibr" target="#b363">[210]</ref>, <ref type="bibr" target="#b380">[225]</ref>, <ref type="bibr" target="#b406">[250]</ref>, <ref type="bibr" target="#b503">[337]</ref>, <ref type="bibr" target="#b537">[368]</ref>, <ref type="bibr" target="#b602">[430]</ref>, <ref type="bibr" target="#b603">[431]</ref>, <ref type="bibr" target="#b608">[436]</ref>, [445] KIWI CC BY-SA 4.0 [452] LMSYS-Chat-1M LMSYS-Chat-1M Dataset License, Anthropic, Llama 2 [455] Llama2-MedTuned-Instr. CC BY-NC 4.0 [407] LongAlign-10k Anthropic, Apache License 2.0 [434] Magpie-Pro Meta Llama3 Community License [453] MathDial CC BY-SA 4.0, MIT License [398] MathInstr. MIT License [422] MedInstr. Unspecified [454] Medical Meadow</p><p>Various <ref type="bibr" target="#b385">[230]</ref>, <ref type="bibr" target="#b412">[256]</ref>, <ref type="bibr" target="#b420">[264]</ref>, <ref type="bibr" target="#b561">[391]</ref> Continued on next page </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 4 :</head><label>4</label><figDesc>Figure4: The cumulative totals (left) of languages and countries represented in the data over time, and the 95% confidence intervals of the gini-coefficients over time (right) to measure the representativeness of these variables. Gini-coefficients are a measure of statistical dispersion, frequently used to quantify inequality. A Gini coefficient of 1 indicates highest concentration, and lower values more broad representation. While the number of represented languages and geographies continue to rise (left), the equality of their distribution has in most cases, not significantly changed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The distribution of creator organizations by modality. Most public speech and video datasets are developed by academic organizations, whereas text datasets are developed by a wide mix of academia, non-profit or industry labs, as well as startups.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: The distribution of dataset sizes for each modality. Most text data collections are between 100M-1B tokens. Speech datasets average 100-1k hours, and video datasets are usually the smallest, commonly less than 100 hours.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: The task distribution of datasets, across modalities. Post-training text and video datasets are predominantly based on classification. For text, generation and reasoning are rising categories. All speech datasets are recognition-based, particularly for speaker, language, or in the process of translation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>A breakdown of the percentage of license and terms restrictions across datasets, by total tokens or hours of content. The much higher frequency of restrictions at the collection level is because we consider a collection's license or terms status to be the most restrictive of those for its datasets. Note that percentages may not add to exactly 100% because of rounding.</figDesc><table><row><cell></cell><cell cols="2">Text Collections</cell><cell></cell><cell></cell></row><row><cell>NC/ACAD</cell><cell>96.0</cell><cell>0.0</cell><cell>0.0</cell><cell>96.0</cell></row><row><cell>UNSPECIFIED</cell><cell>2.3</cell><cell>0.1</cell><cell>0.0</cell><cell>2.4</cell></row><row><cell>COMMERCIAL</cell><cell>1.5</cell><cell>0.0</cell><cell>0.0</cell><cell>1.6</cell></row><row><cell>TOTAL</cell><cell>99.8</cell><cell>0.1</cell><cell>0.1</cell><cell></cell></row><row><cell></cell><cell>Text Datasets</cell><cell></cell><cell></cell><cell></cell></row><row><cell>NC/ACAD</cell><cell>21.1</cell><cell>0.0</cell><cell>0.0</cell><cell>21.2</cell></row><row><cell>UNSPECIFIED</cell><cell>5.7</cell><cell>0.1</cell><cell>0.0</cell><cell>5.7</cell></row><row><cell>COMMERCIAL</cell><cell>73.0</cell><cell>0.0</cell><cell>0.0</cell><cell>73.1</cell></row><row><cell>TOTAL</cell><cell>99.8</cell><cell>0.1</cell><cell>0.1</cell><cell></cell></row><row><cell></cell><cell cols="2">Speech Datasets</cell><cell></cell><cell></cell></row><row><cell>NC/ACAD</cell><cell>23.9</cell><cell>1.4</cell><cell>0.8</cell><cell>26.2</cell></row><row><cell>UNSPECIFIED</cell><cell>0.5</cell><cell>0.0</cell><cell>0.4</cell><cell>0.9</cell></row><row><cell>COMMERCIAL</cell><cell>54.2</cell><cell>13.3</cell><cell>5.4</cell><cell>73.0</cell></row><row><cell>TOTAL</cell><cell>78.6</cell><cell>14.7</cell><cell>6.7</cell><cell></cell></row><row><cell></cell><cell cols="2">Video Datasets</cell><cell></cell><cell></cell></row><row><cell>NC/ACAD</cell><cell>33.7</cell><cell>0.0</cell><cell>0.1</cell><cell>33.8</cell></row><row><cell>UNSPECIFIED</cell><cell>43.9</cell><cell>0.1</cell><cell>0.1</cell><cell>44.1</cell></row><row><cell>COMMERCIAL</cell><cell>21.5</cell><cell>0.0</cell><cell>0.6</cell><cell>22.1</cell></row><row><cell>TOTAL</cell><cell>99.1</cell><cell>0.1</cell><cell>0.8</cell><cell></cell></row><row><cell>C ADDITIONAL RESULTS</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">Figures 6 and 7 report the size distributions of the datasets. We measure size differently for different</cell></row><row><cell cols="5">types of datasets: Text datasets are in tokens, and audio/video in hours of content. The lack of standard</cell></row><row><cell cols="5">tokenization or preprocessing schemes for those modalities makes it simplest to report raw dataset</cell></row><row><cell>size.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">Notably, we find quite different size distributions by modality. The distribution of dataset sizes has</cell></row><row><cell cols="5">the thickest right tail for text, followed by speech and then by video. Most video datasets are short in</cell></row></table><note><p>hour terms, with speech datasets tending to be somewhat longer and text datasets having a greater prevalence of both very small and very large datasets relative to the mean size.</p><p>Dataset tasks, meanwhile, reflect traditional approaches and research programs for each modality. Classification is the most common task for both text and video, with the video community's longstanding interest in captioning also visible in its role as the second most common task for video datasets. Q&amp;A occupies a similar role for text, though text datasets have a more balanced distribution LICENSE / TERMS RESTRICTED UNSPECIFIED UNRESTRICTED TOTAL</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Alignment tuning (text) collections and properties.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">PROPERTY COUNTS</cell><cell cols="2">TYPES PERMISSIONS</cell></row><row><cell></cell><cell cols="5">YEAR DATASETS TASKS LANGS DOMAINS SOURCE USE</cell><cell>OAI</cell></row><row><cell>RiddleSense</cell><cell>2021</cell><cell>1</cell><cell>3</cell><cell>1</cell><cell>1</cell></row><row><cell>MathInstr.</cell><cell>2023</cell><cell>1</cell><cell>3</cell><cell>1</cell><cell>1</cell></row><row><cell>No Robots</cell><cell>2023</cell><cell>1</cell><cell>8</cell><cell>1</cell><cell>1</cell></row><row><cell>Nectar</cell><cell>2023</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>2</cell></row><row><cell>MetaMathQA</cell><cell>2023</cell><cell>8</cell><cell>2</cell><cell>1</cell><cell>1</cell></row><row><cell>MegaWika</cell><cell>2023</cell><cell>50</cell><cell>1</cell><cell>50</cell><cell>1</cell></row><row><cell>MedInstr.</cell><cell>2023</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>MathDial</cell><cell>2023</cell><cell>1</cell><cell>2</cell><cell>1</cell><cell>4</cell></row><row><cell>PII-Masking-200k</cell><cell>2023</cell><cell>1</cell><cell>2</cell><cell>4</cell><cell>1</cell></row><row><cell>Pure-Dove</cell><cell>2023</cell><cell>1</cell><cell>4</cell><cell>1</cell><cell>1</cell></row><row><cell>LMSYS-Chat-1M</cell><cell>2023</cell><cell>1</cell><cell>9</cell><cell>5</cell><cell>1</cell></row><row><cell>PygmalionAI-PIPPA</cell><cell>2023</cell><cell>1</cell><cell>3</cell><cell>1</cell><cell>1</cell></row><row><cell>HelpSteer</cell><cell>2023</cell><cell>1</cell><cell>5</cell><cell>1</cell><cell>1</cell></row><row><cell>SeaBench</cell><cell>2023</cell><cell>9</cell><cell>4</cell><cell>9</cell><cell>5</cell></row><row><cell>Open Asst. v2</cell><cell>2023</cell><cell>19</cell><cell>4</cell><cell>19</cell><cell>1</cell></row><row><cell>Feedback Coll.</cell><cell>2023</cell><cell>1</cell><cell>2</cell><cell>1</cell><cell>1</cell></row><row><cell>Glaive Code Asst.</cell><cell>2023</cell><cell>1</cell><cell>2</cell><cell>2</cell><cell>1</cell></row><row><cell>EverythingLM</cell><cell>2023</cell><cell>1</cell><cell>8</cell><cell>2</cell><cell>1</cell></row><row><cell>Bactrian-X</cell><cell>2023</cell><cell>6</cell><cell>4</cell><cell>6</cell><cell>1</cell></row><row><cell>COBRA Frames</cell><cell>2023</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>2</cell></row><row><cell>UltraFeedback Argilla</cell><cell>2023</cell><cell>9</cell><cell>16</cell><cell>1</cell><cell>20</cell></row><row><cell>ExpertQA</cell><cell>2023</cell><cell>1</cell><cell>3</cell><cell>1</cell><cell>1</cell></row><row><cell>ChatDoctor</cell><cell>2023</cell><cell>3</cell><cell>1</cell><cell>1</cell><cell>2</cell></row><row><cell>Capybara</cell><cell>2023</cell><cell>11</cell><cell>17</cell><cell>2</cell><cell>1</cell></row><row><cell>UltraChat-200k</cell><cell>2023</cell><cell>1</cell><cell>7</cell><cell>1</cell><cell>2</cell></row><row><cell>CollectiveCognition</cell><cell>2023</cell><cell>1</cell><cell>6</cell><cell>1</cell><cell>1</cell></row><row><cell>Thai Gen AI</cell><cell>2023</cell><cell>9</cell><cell>11</cell><cell>1</cell><cell>1</cell></row><row><cell>Deita 10K</cell><cell>2023</cell><cell>2</cell><cell>11</cell><cell>1</cell><cell>3</cell></row><row><cell>SelFee</cell><cell>2023</cell><cell>1</cell><cell>5</cell><cell>1</cell><cell>1</cell></row><row><cell>ChatbotArena</cell><cell>2023</cell><cell>1</cell><cell>4</cell><cell>1</cell><cell>1</cell></row><row><cell>OpenGPT Healthcare</cell><cell>2023</cell><cell>3</cell><cell>4</cell><cell>1</cell><cell>1</cell></row><row><cell>Orca-Math</cell><cell>2024</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>3</cell></row><row><cell>OpenMathInstr.-1</cell><cell>2024</cell><cell>2</cell><cell>3</cell><cell>1</cell><cell>3</cell></row><row><cell>WildChat</cell><cell>2024</cell><cell>2</cell><cell>7</cell><cell>10</cell><cell>1</cell></row><row><cell>Magpie-Pro</cell><cell>2024</cell><cell>1</cell><cell>9</cell><cell>1</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Continued on next page</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Audio collections and properties.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="3">PROPERTY COUNTS</cell><cell>CATEGORY PERM</cell></row><row><cell></cell><cell cols="6">YEAR HR SPKR LANG CREAT TASKS SRC TOP US AC IND USE</cell></row><row><cell>TIMIT</cell><cell cols="2">1990 5 630</cell><cell>1</cell><cell>3</cell><cell>3</cell><cell>1 7</cell></row><row><cell>Switchboard</cell><cell cols="2">1992 250 543</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1 70</cell></row><row><cell>African Acc. French</cell><cell cols="2">2003 22 232</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1 7</cell></row><row><cell>CSJ</cell><cell cols="2">2003 661 1k</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1 2</cell></row><row><cell>Fisher</cell><cell cols="2">2004 2k 12k</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1 36</cell></row><row><cell>CSLU 22 Langs.</cell><cell>2005 84</cell><cell>-</cell><cell>21</cell><cell>1</cell><cell>1</cell><cell>1 7</cell></row><row><cell>AMI</cell><cell>2005 100</cell><cell>-</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>2 2</cell></row><row><cell>CSLU 1.2</cell><cell cols="2">2007 25 5k</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1 1</cell></row><row><cell>ALLSSTAR</cell><cell cols="3">2010 86 140 27</cell><cell>1</cell><cell>1</cell><cell>1 3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Continued on next page</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Audio collections and properties.</figDesc><table><row><cell>COLLECTION</cell><cell></cell><cell></cell><cell cols="3">PROPERTY COUNTS</cell><cell>CATEGORY PERM</cell></row><row><cell></cell><cell cols="6">YEAR HR SPKR LANG CREAT TASKS SRC TOP US AC IND USE</cell></row><row><cell>MASC</cell><cell cols="2">2021 1k 14k</cell><cell>1</cell><cell>3</cell><cell>3</cell><cell>1 15</cell></row><row><cell>LaboroTVSpeech</cell><cell>2021 2k</cell><cell>-</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>1 7</cell></row><row><cell>KeSpeech</cell><cell cols="2">2021 2k 27k</cell><cell>2</cell><cell>1</cell><cell>1</cell><cell>1 1</cell></row><row><cell>JTUBESPEECH</cell><cell>2021 1k</cell><cell>-</cell><cell>2</cell><cell>4</cell><cell>4</cell><cell>1 7</cell></row><row><cell>GigaSpeech</cell><cell>2021 10k</cell><cell>-</cell><cell>1</cell><cell>9</cell><cell>9</cell><cell>3 24</cell></row><row><cell>VoxPopuli</cell><cell cols="2">2021 2k 4k</cell><cell>16</cell><cell>1</cell><cell>1</cell><cell>1 1</cell></row><row><cell>SPGISpeech</cell><cell cols="2">2021 5k 50k</cell><cell>1</cell><cell>4</cell><cell>4</cell><cell>1 2</cell></row><row><cell>West Afr. Radio</cell><cell>2021 142</cell><cell>-</cell><cell>10</cell><cell>2</cell><cell>2</cell><cell>1 3</cell></row><row><cell>AISHELL-4</cell><cell cols="2">2021 120 61</cell><cell>1</cell><cell>4</cell><cell>4</cell><cell>2 6</cell></row><row><cell>West Afr. Virt. Asst.</cell><cell>2021 2</cell><cell>49</cell><cell>3</cell><cell>2</cell><cell>2</cell><cell>1 2</cell></row><row><cell>MediaSpeech</cell><cell>2021 40</cell><cell>-</cell><cell>4</cell><cell>5</cell><cell>5</cell><cell>12 1</cell></row><row><cell>People's Speech</cell><cell>2021 30k</cell><cell>-</cell><cell>1</cell><cell>7</cell><cell>7</cell><cell>2 14</cell></row><row><cell>1111 Hours Hindi</cell><cell>2022 108</cell><cell>-</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1 5</cell></row><row><cell>Shrutilipi</cell><cell>2022 6k</cell><cell>-</cell><cell>12</cell><cell>2</cell><cell>2</cell><cell>1 1</cell></row><row><cell>WenetSpeech</cell><cell>2022 10k</cell><cell>-</cell><cell>1</cell><cell>4</cell><cell>4</cell><cell>2 10</cell></row><row><cell>Samromur Children</cell><cell cols="2">2022 131 3k</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1 5</cell></row><row><cell>SDS-200</cell><cell cols="2">2022 200 4k</cell><cell>1</cell><cell>3</cell><cell>3</cell><cell>1 2</cell></row><row><cell>aidatatang</cell><cell cols="2">2022 200 600</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1 7</cell></row><row><cell>Fleurs</cell><cell>2022 1k</cell><cell>-</cell><cell>102</cell><cell>3</cell><cell>3</cell><cell>1 11</cell></row><row><cell>OLKAVS</cell><cell cols="2">2022 1k 1k</cell><cell>1</cell><cell>2</cell><cell>2</cell><cell>1 14</cell></row><row><cell>Norwegian Parl.</cell><cell cols="2">2022 140 267</cell><cell>1</cell><cell>2</cell><cell>2</cell><cell>1 2</cell></row><row><cell>MagicData-RAMC</cell><cell cols="2">2022 180 663</cell><cell>1</cell><cell>4</cell><cell>4</cell><cell>1 15</cell></row><row><cell>Kathbath</cell><cell cols="2">2022 2k 1k</cell><cell>12</cell><cell>2</cell><cell>2</cell><cell>1 3</cell></row><row><cell>Hebrew Kan</cell><cell>2022 9</cell><cell>-</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1 3</cell></row><row><cell>Hebrew Coursera</cell><cell>2022 36</cell><cell>-</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1 7</cell></row><row><cell>Bloom Speech</cell><cell>2022 428</cell><cell>-</cell><cell>56</cell><cell>5</cell><cell>5</cell><cell>1 8</cell></row><row><cell>English-Vietnamese</cell><cell>2022 508</cell><cell>-</cell><cell>2</cell><cell>1</cell><cell>1</cell><cell>1 7</cell></row><row><cell>Earnings-22</cell><cell cols="2">2022 119 125</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>3 2</cell></row><row><cell>YODAS</cell><cell cols="2">2023 370k -</cell><cell>149</cell><cell>3</cell><cell>3</cell><cell>1 1</cell></row><row><cell>AFRISPEECH-200</cell><cell cols="2">2023 200 2k</cell><cell>20</cell><cell>14</cell><cell>14</cell><cell>1 6</cell></row><row><cell>Aalto Finnish Parl.</cell><cell cols="2">2023 3k 449</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1 2</cell></row><row><cell>ReazonSpeech</cell><cell>2023 35k</cell><cell>-</cell><cell>1</cell><cell>2</cell><cell>2</cell><cell>1 1</cell></row><row><cell>EdAcc</cell><cell cols="2">2023 40 120</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1 8</cell></row><row><cell>RixVox</cell><cell>2023 5k</cell><cell>-</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1 2</cell></row><row><cell cols="2">Japanese Anime Speech 2023 110</cell><cell>-</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1 7</cell></row><row><cell>Snow Mountain</cell><cell cols="2">2023 273 11</cell><cell>14</cell><cell>2</cell><cell>2</cell><cell>1 1</cell></row><row><cell>Samromur Milljon</cell><cell cols="2">2023 967 17k</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1 5</cell></row><row><cell>Bud500</cell><cell>2024 500</cell><cell>-</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>2 4</cell></row><row><cell>VibraVox</cell><cell cols="2">2024 18 200</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1 1</cell></row><row><cell>M2ASR</cell><cell cols="2">Mult. 448 655</cell><cell>4</cell><cell>3</cell><cell>3</cell><cell>1 9</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 :</head><label>7</label><figDesc>Video collections and properties. Collection properties include numbers of hours of video, datasets, creator institutions, countries of creator institutions, and data sources. The USE column indicates whether a collection includes data freely usable even for commercial purposes ( ), data usable only for noncommercial purposes or academic research ( ) and data whose license status is not specified precisely enough to allow us to determine commercial use permissions ( ). Note that each collection may have different datasets with one, two, or all three of these statuses. Finally, the AVAIL column indicates whether a dataset is available online ( ) or has been taken down, usually for legal reasons ( ). Datasets are sorted chronologically to highlight trends over time.</figDesc><table><row><cell>COLLECTION</cell><cell></cell><cell></cell><cell></cell><cell cols="2">PROPERTY COUNTS</cell><cell>PERMISSIONS</cell></row><row><cell></cell><cell cols="6">YEAR HOURS DATASETS COUNTRIES CREATORS SOURCES USE AVAIL</cell></row><row><cell>HOLLYWOOD2</cell><cell cols="2">2009 20</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Collective</cell><cell>2009</cell><cell>-</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>HMDB</cell><cell cols="2">2011 7k</cell><cell>1</cell><cell>2</cell><cell>3</cell></row><row><cell>UCF101</cell><cell cols="2">2012 26</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>YouCook</cell><cell cols="2">2013 1k</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>50 Salads</cell><cell cols="2">2013 40</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>StoryGraphs</cell><cell>2014</cell><cell>7</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Hollywood Ext.</cell><cell>2014</cell><cell>9</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Breakfast</cell><cell cols="2">2014 77</cell><cell>1</cell><cell>2</cell><cell>2</cell></row><row><cell>Sports-1M</cell><cell cols="2">2014 106k</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>THUMOS</cell><cell cols="2">2014 254</cell><cell>1</cell><cell>2</cell><cell>4</cell></row><row><cell>VideoStory</cell><cell cols="2">2014 743</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>SumMe</cell><cell>2014</cell><cell>1</cell><cell>1</cell><cell>2</cell><cell>3</cell></row><row><cell>TVSum</cell><cell>2015</cell><cell>4</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Volleyball</cell><cell>2015</cell><cell>-</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>ActivityNet</cell><cell cols="2">2015 849</cell><cell>1</cell><cell>2</cell><cell>2</cell></row><row><cell>MovieQA</cell><cell cols="2">2015 381</cell><cell>1</cell><cell>3</cell><cell>3</cell></row><row><cell>Mars</cell><cell>2016</cell><cell>-</cell><cell>1</cell><cell>1</cell><cell>4</cell></row><row><cell>NTU RGB+D</cell><cell cols="2">2016 74</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>MSR-VTT</cell><cell cols="2">2016 41</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Charades</cell><cell cols="2">2016 82</cell><cell>1</cell><cell>2</cell><cell>4</cell></row><row><cell>VTW</cell><cell cols="2">2016 213</cell><cell>1</cell><cell>2</cell><cell>2</cell></row><row><cell>Youtube-8M</cell><cell cols="2">2016 350k</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell cols="2">Narrated Instr. Vid. 2016</cell><cell>7</cell><cell>1</cell><cell>2</cell><cell>4</cell></row><row><cell>TGIF</cell><cell cols="2">2016 86</cell><cell>1</cell><cell>1</cell><cell>3</cell></row><row><cell>MultiTHUMOS</cell><cell cols="2">2017 30</cell><cell>1</cell><cell>2</cell><cell>3</cell></row><row><cell>ImageNet-Vid</cell><cell>2017</cell><cell>9</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>PKU-MMD</cell><cell cols="2">2017 50</cell><cell>1</cell><cell>1</cell><cell>2</cell></row><row><cell cols="3">20BN-SOMETHING 2017 121</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>YouCook2</cell><cell cols="2">2017 176</cell><cell>1</cell><cell>1</cell><cell>2</cell></row><row><cell>VoxCeleb</cell><cell cols="2">2017 2k</cell><cell>1</cell><cell>2</cell><cell>1</cell></row><row><cell>Davis</cell><cell>2017</cell><cell>-</cell><cell>1</cell><cell>1</cell><cell>2</cell></row><row><cell>QFVS</cell><cell cols="2">2017 20</cell><cell>1</cell><cell>1</cell><cell>2</cell></row><row><cell>DiDeMo</cell><cell cols="2">2018 275</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>SOA</cell><cell cols="2">2018 2k</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Charades-Ego</cell><cell cols="2">2018 69</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>EPIC-KITCHENS</cell><cell cols="2">2018 100</cell><cell>1</cell><cell>3</cell><cell>3</cell></row><row><cell>MovieGraphs</cell><cell cols="2">2018 94</cell><cell>1</cell><cell>1</cell><cell>3</cell></row><row><cell>How2</cell><cell cols="2">2018 2k</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Continued on next page</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>Video collections and properties.</figDesc><table><row><cell>COLLECTION</cell><cell></cell><cell></cell><cell></cell><cell cols="2">PROPERTY COUNTS</cell><cell>PERMISSIONS</cell></row><row><cell></cell><cell cols="6">YEAR HOURS DATASETS COUNTRIES CREATORS SOURCES USE AVAIL</cell></row><row><cell>VLOG</cell><cell cols="2">2018 336</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>VaTeX</cell><cell cols="2">2019 115</cell><cell>1</cell><cell>2</cell><cell>2</cell><cell>1</cell></row><row><cell>20BN-jester</cell><cell cols="2">2019 13</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>HowTo100M</cell><cell cols="2">2019 134k</cell><cell>1</cell><cell>2</cell><cell>4</cell><cell>1</cell></row><row><cell>COIN</cell><cell cols="2">2019 476</cell><cell>1</cell><cell>1</cell><cell>2</cell><cell>1</cell></row><row><cell>MMAct</cell><cell cols="2">2019 100</cell><cell>1</cell><cell>2</cell><cell>2</cell><cell>1</cell></row><row><cell>HACS</cell><cell cols="2">2019 833</cell><cell>1</cell><cell>1</cell><cell>3</cell><cell>1</cell></row><row><cell>CrossTask</cell><cell cols="2">2019 376</cell><cell>1</cell><cell>4</cell><cell>5</cell><cell>1</cell></row><row><cell>Moments in Time</cell><cell cols="2">2019 833</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>11</cell></row><row><cell>TRECVid</cell><cell cols="2">2019 1k</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>2</cell></row><row><cell>MSA</cell><cell cols="2">2019 516</cell><cell>1</cell><cell>2</cell><cell>2</cell><cell>1</cell></row><row><cell>Toyota Smarthome</cell><cell cols="2">2019 269</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>TITAN</cell><cell>2020</cell><cell>3</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>VIOLIN</cell><cell cols="2">2020 582</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>RareAct</cell><cell cols="2">2020 21</cell><cell>1</cell><cell>3</cell><cell>5</cell><cell>1</cell></row><row><cell>TinyVIRAT</cell><cell cols="2">2020 11</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>100DOH</cell><cell cols="2">2020 5k</cell><cell>1</cell><cell>1</cell><cell>2</cell><cell>1</cell></row><row><cell>Oops!</cell><cell cols="2">2020 50</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>OmniSource-Web</cell><cell cols="2">2020 13k</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>3</cell></row><row><cell cols="3">Condensed Movies 2020 1k</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>MovieScenes</cell><cell cols="2">2020 250</cell><cell>1</cell><cell>2</cell><cell>2</cell><cell>1</cell></row><row><cell>EEV</cell><cell cols="2">2020 370</cell><cell>1</cell><cell>1</cell><cell>2</cell><cell>1</cell></row><row><cell>Movie-Net</cell><cell cols="2">2020 3k</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>FineGym</cell><cell cols="2">2020 708</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>HAA500</cell><cell>2020</cell><cell>5</cell><cell>1</cell><cell>2</cell><cell>4</cell><cell>1</cell></row><row><cell>LEMMA</cell><cell cols="2">2020 11</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>2</cell></row><row><cell>HVU</cell><cell cols="2">2020 96k</cell><cell>1</cell><cell>3</cell><cell>5</cell><cell>1</cell></row><row><cell>Apes</cell><cell cols="2">2021 36</cell><cell>1</cell><cell>3</cell><cell>3</cell><cell>1</cell></row><row><cell>WebVid</cell><cell cols="2">2021 13k</cell><cell>1</cell><cell>2</cell><cell>2</cell><cell>1</cell></row><row><cell>VideoLT</cell><cell cols="2">2021 14k</cell><cell>1</cell><cell>2</cell><cell>4</cell><cell>1</cell></row><row><cell>HOMAGE</cell><cell cols="2">2021 30</cell><cell>1</cell><cell>1</cell><cell>2</cell><cell>1</cell></row><row><cell>UAV-Human</cell><cell cols="2">2021 18</cell><cell>1</cell><cell>2</cell><cell>2</cell><cell>1</cell></row><row><cell>HD-VILA-100M</cell><cell cols="2">2021 372</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>M-MiT</cell><cell cols="2">2021 833</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>2</cell></row><row><cell>Mimetics</cell><cell>2021</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Spoken Moments</cell><cell cols="2">2021 417</cell><cell>1</cell><cell>1</cell><cell>3</cell><cell>11</cell></row><row><cell>QuerYD</cell><cell cols="2">2021 207</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>2</cell></row><row><cell>MAD</cell><cell cols="2">2022 1k</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>FERV39k</cell><cell cols="2">2022 16</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>CDAD</cell><cell cols="2">2022 215</cell><cell>1</cell><cell>1</cell><cell>2</cell><cell>1</cell></row><row><cell>MVBench</cell><cell>2023</cell><cell>-</cell><cell>1</cell><cell>1</cell><cell>6</cell><cell>12</cell></row><row><cell>VidProm</cell><cell cols="2">2024 240k</cell><cell>1</cell><cell>2</cell><cell>2</cell><cell>5</cell></row><row><cell>ShareGPT4Video</cell><cell cols="2">2024 3k</cell><cell>1</cell><cell>1</cell><cell>4</cell><cell>5</cell></row><row><cell>OpenVid-1M</cell><cell cols="2">2024 52k</cell><cell>1</cell><cell>1</cell><cell>3</cell><cell>5</cell></row><row><cell>FineVideo</cell><cell cols="2">2024 3k</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Disney Vid. Gen.</cell><cell>2024</cell><cell>7</cell><cell>1</cell><cell>1</cell><cell>-</cell><cell>2</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Continued on next page</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc>Video collections and properties.we break down contributions to this work. Contributors are listed alphabetically, except for team leads who are placed first. ‚Ä¢ Text Datasets Shayne Longpre (lead), Jad Kabbara (lead), Ahmad Anis, Deividas Mataciunas, Diganta Misra, Emad Alghamdi, Enrico Shippole, Jianguo Zhang, Kun Qian, Lester Miranda, Manan Dey, Minnie Liang, Mohammed Hamdy, Nayan Saxena, Niklas Muennighoff, Naana Obeng-Marnu, Robert Mahari, Seonghyeon Ye, Seungone Kim, Shayne Longpre, Shrestha Mohanty, Vipul Gupta, Vivek Sharma, Vu Minh Chien, William Brannon, Xuhui Zhou, Yizhi Li, An Dinh, Caroline Chitongo, Christopher Klamm, Da Yin, Damien Sileo, Ariel Lee ‚Ä¢ Reviewing Text Dataset Metadata Jad Kabbara (lead), Shayne Longpre (lead), Robert Mahari, Damien Sileo, Niklas Muennighoff, William Brannon,</figDesc><table><row><cell>COLLECTION</cell><cell></cell><cell cols="3">PROPERTY COUNTS</cell><cell>PERMISSIONS</cell></row><row><cell></cell><cell cols="5">YEAR HOURS DATASETS COUNTRIES CREATORS SOURCES USE AVAIL</cell></row><row><cell>Kinetics</cell><cell>Mult. 4k</cell><cell>3</cell><cell>1</cell><cell>1</cell><cell>2</cell></row><row><cell>Ego4D</cell><cell>Mult. 5k</cell><cell>2</cell><cell>1</cell><cell>2</cell><cell>1</cell></row><row><cell>MPII</cell><cell>Mult. 110</cell><cell>3</cell><cell>1</cell><cell>2</cell><cell>2</cell></row><row><cell>Project-Aria</cell><cell>Mult. 1k</cell><cell>2</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Ava</cell><cell>Mult. 146</cell><cell>2</cell><cell>1</cell><cell>1</cell><cell>2</cell></row><row><cell>LSMDC</cell><cell>Mult. 316</cell><cell>2</cell><cell>4</cell><cell>10</cell><cell>1</cell></row><row><cell cols="2">E CONTRIBUTIONS</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">‚Ä¢ Data Explorer Features Shayne Longpre (lead), Christopher Klamm, Vu Minh Chien,</cell></row><row><cell cols="6">‚Ä¢ Speech Datasets Nikhil Singh (lead), Manuel Cherep (lead), An Dinh, Minnie Liang,</cell></row><row><cell cols="2">Shrestha Mohanty</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">‚Ä¢ Video Datasets Kush Tiwary (lead), Joanna Materzynska (lead), Vivek Sharma (lead),</cell></row><row><cell cols="6">Shayne Longpre, Robert Mahari, Jad Kabbara, William Brannon, Tobin South, Shrestha</cell></row><row><cell cols="3">Mohanty, Nikhil Singh, Manuel Cherep</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">‚Ä¢ Data Analysis Shayne Longpre (lead), Nikhil Singh (lead), Manuel Cherep (lead), Kush</cell></row><row><cell cols="6">Tiwary (lead), Joanna Materzynska (lead), Naana Obeng-Marnu (lead), William Brannon</cell></row><row><cell>(lead),</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">‚Ä¢ Writing Shayne Longpre (lead), Jad Kabbara (lead), Nikhil Singh, Manuel Cherep, Kush</cell></row><row><cell cols="3">Tiwary, Joanna Materzynska, Robert Mahari</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">‚Ä¢ Legal Analysis Robert Mahari (lead), Luis Villa</cell><cell></cell><cell></cell></row><row><cell cols="6">‚Ä¢ Visualizations &amp; Visual Data Analysis Nikhil Singh (lead), Manuel Cherep (lead), Kush</cell></row><row><cell cols="6">Tiwary (lead), Joanna Materzynska (lead), Naana Obeng-Marnu (lead), William Brannon</cell></row><row><cell cols="6">(lead), Shayne Longpre (lead), Ariel Lee, Hamidah Oderinwale, Campbell Lund</cell></row><row><cell cols="6">‚Ä¢ Senior Advisors Stella Biderman, Sara Hooker, Jad Kabbara, Hanlin Li, Sandy Pentland,</cell></row><row><cell cols="2">Luis Villa, Caiming Xiong</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>Here</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8 :</head><label>8</label><figDesc>References and licenses for alignment-tuning (text) dataset collections presented in this paper. Collections containing material under more than three distinct licenses are marked as having "Various" licenses, and we refer readers to our raw data for the full details. Datasets are sorted alphabetically for ease of dataset lookup.</figDesc><table><row><cell>Collection</cell><cell>Licenses</cell><cell>Cite</cell></row><row><cell>10k Prompt Ranked</cell><cell>Unspecified</cell><cell>-</cell></row><row><cell>AgentInstruct</cell><cell>Unspecified, CC BY 4.0, MIT Li-</cell><cell>[322], [386], [397], [418], [423]</cell></row><row><cell></cell><cell>cense</cell><cell></cell></row><row><cell>Aya</cell><cell>Apache License 2.0</cell><cell>[446]</cell></row><row><cell>Bactrian-X</cell><cell>CC BY-SA 3.0, CC BY-NC 4.0</cell><cell>[393]</cell></row><row><cell>COBRA Frames</cell><cell>BigScience OpenRAIL-M</cell><cell>[429]</cell></row><row><cell>COIG</cell><cell>Various</cell><cell>[424], [433]</cell></row><row><cell>Capybara</cell><cell>Various</cell><cell>-</cell></row><row><cell>ChatDoctor</cell><cell>Unspecified</cell><cell>[395]</cell></row><row><cell>ChatbotArena</cell><cell>CC BY 4.0, CC BY-NC 4.0</cell><cell>[427]</cell></row><row><cell>Cidar</cell><cell>CC BY-NC 4.0</cell><cell>[432]</cell></row><row><cell>CollectiveCognition</cell><cell>MIT License</cell><cell>-</cell></row><row><cell>Conifer</cell><cell>Apache License 2.0</cell><cell>[448]</cell></row><row><cell>Deita 10K</cell><cell cols="2">Apache License 2.0, CC BY-NC 4.0 [440]</cell></row><row><cell>DialogStudio</cell><cell>Various</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 8 :</head><label>8</label><figDesc>References and licenses for alignment-tuning (text) dataset collections presented in this paper. Collections containing material under more than three distinct licenses are marked as having "Various" licenses, and we refer readers to our raw data for the full details. Datasets are sorted alphabetically for ease of dataset lookup.</figDesc><table><row><cell>Collection</cell><cell>Licenses</cell><cell>Cite</cell></row><row><cell>Dynosaur</cell><cell>Various</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 8 :</head><label>8</label><figDesc>References and licenses for alignment-tuning (text) dataset collections presented in this paper. Collections containing material under more than three distinct licenses are marked as having "Various" licenses, and we refer readers to our raw data for the full details. Datasets are sorted alphabetically for ease of dataset lookup.</figDesc><table><row><cell>Collection</cell><cell>Licenses</cell><cell>Cite</cell></row><row><cell>MegaWika</cell><cell>CC BY-SA 4.0</cell><cell>[383]</cell></row><row><cell>MetaMathQA</cell><cell>MIT License</cell><cell>[421]</cell></row><row><cell>Nectar</cell><cell>Various</cell><cell>-</cell></row><row><cell>No Robots</cell><cell>CC BY-NC 4.0</cell><cell>-</cell></row><row><cell>Open Asst. v2</cell><cell>Apache License 2.0</cell><cell>[392]</cell></row><row><cell>Open-Platypus</cell><cell>Various</cell><cell>[269], [363], [385], [387], [396],</cell></row><row><cell></cell><cell></cell><cell>[410], [451]</cell></row><row><cell>OpenGPT Healthcare</cell><cell>Unspecified, OGL 3.0</cell><cell>-</cell></row><row><cell>OpenMathInstr.-1</cell><cell>Custom, MIT License, Apache Li-</cell><cell>[449]</cell></row><row><cell></cell><cell>cense 2.0</cell><cell></cell></row><row><cell>Orca-Math</cell><cell>Various</cell><cell>[443]</cell></row><row><cell>PII-Masking-200k</cell><cell>Non Commercial</cell><cell>-</cell></row><row><cell>PMC-LLaMA Instr.</cell><cell cols="2">Unspecified, Apache License 2.0 [161], [417]</cell></row><row><cell>Pure-Dove</cell><cell>Apache License 2.0</cell><cell>-</cell></row><row><cell>PygmalionAI-PIPPA</cell><cell>Apache License 2.0</cell><cell>[390]</cell></row><row><cell>Reasoning</cell><cell>Apache License 2.0</cell><cell>-</cell></row><row><cell>RiddleSense</cell><cell>MIT License</cell><cell>[307]</cell></row><row><cell>SeaBench</cell><cell>Apache License 2.0</cell><cell>[401]</cell></row><row><cell>SelFee</cell><cell>MIT License</cell><cell>[419]</cell></row><row><cell>Synth.-GSM8K-Refl.</cell><cell cols="2">Meta Llama3 Community License -</cell></row><row><cell>Thai Gen AI</cell><cell>Various</cell><cell>-</cell></row><row><cell>UltraChat-200k</cell><cell>CC BY-NC 4.0</cell><cell>[388]</cell></row><row><cell>UltraFeedback Argilla</cell><cell>Various</cell><cell>-</cell></row><row><cell>WildChat</cell><cell cols="2">AI2 ImpACT License -Low Risk [426]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 9 :</head><label>9</label><figDesc>References and licenses for audio dataset collections presented in this paper. Collections containing material under more than three distinct licenses are marked as having "Various" licenses, and we refer readers to our raw data for the full details. Datasets are sorted alphabetically for ease of dataset lookup.</figDesc><table><row><cell>Collection</cell><cell>Licenses</cell><cell>Cite</cell></row><row><cell>1111 Hours Hindi</cell><cell>Custom</cell><cell>[340]</cell></row><row><cell>120h Spanish Speech</cell><cell>CC0 1.0</cell><cell>-</cell></row><row><cell>AFRISPEECH-200</cell><cell>CC BY-NC-SA 4.0</cell><cell>[402]</cell></row><row><cell>AISHELL-1</cell><cell>Apache 2.0</cell><cell>[67]</cell></row><row><cell>AISHELL-2</cell><cell>Unspecified</cell><cell>[101]</cell></row><row><cell>AISHELL-4</cell><cell>CC BY-SA 4.0</cell><cell>[292]</cell></row><row><cell>ALLSSTAR</cell><cell>CC BY 4.0</cell><cell>[15]</cell></row><row><cell>AMI</cell><cell>CC BY 4.0</cell><cell>[10]</cell></row><row><cell>Aalto Finnish Parl.</cell><cell>Custom</cell><cell>[373]</cell></row><row><cell>African Acc. French</cell><cell>Apache 2.0</cell><cell>-</cell></row><row><cell>Basq., Cat. and Gal.</cell><cell>CC BY-SA 4.0</cell><cell>[235]</cell></row><row><cell>Bloom Speech</cell><cell>Various</cell><cell>[360]</cell></row><row><cell>Bud500</cell><cell>Apache 2.0, CC BY-NC-SA 4.0</cell><cell>-</cell></row><row><cell>CSJ</cell><cell>Custom</cell><cell>[6]</cell></row><row><cell>CSLU 1.2</cell><cell>CSLU Agreement</cell><cell>[11]</cell></row><row><cell>CSLU 22 Langs.</cell><cell>CSLU Agreement</cell><cell>[8]</cell></row><row><cell>ClarinPL</cell><cell>CC BY 4.0</cell><cell>[80]</cell></row><row><cell>CoNASE</cell><cell>Custom</cell><cell>[146]</cell></row><row><cell>CoVoST-2</cell><cell>CC0 1.0</cell><cell>[263]</cell></row><row><cell>Common Voice 17</cell><cell>CC0 1.0</cell><cell>[205]</cell></row><row><cell>Crowd Sourced Speech</cell><cell>CC BY-SA 4.0</cell><cell>[112]</cell></row><row><cell>Czech Parliament</cell><cell>CC BY 4.0</cell><cell>[236]</cell></row><row><cell>DiDiSpeech</cell><cell>Unspecified</cell><cell>[296]</cell></row><row><cell>Earnings-22</cell><cell>Unspecified</cell><cell>[350]</cell></row><row><cell>EdAcc</cell><cell>CC BY-SA 4.0</cell><cell>[409]</cell></row><row><cell>Eng. Acc. in Brit. Isles</cell><cell>CC BY-SA 4.0</cell><cell>[219]</cell></row><row><cell>English-Vietnamese</cell><cell>CC BY-NC-ND 4.0</cell><cell>[366]</cell></row><row><cell>FT SPEECH</cell><cell>Custom</cell><cell>[234]</cell></row><row><cell>Fisher</cell><cell>LDC User Agreement</cell><cell>[7]</cell></row><row><cell>Fleurs</cell><cell>CC BY 4.0</cell><cell>[348]</cell></row><row><cell>GigaSpeech</cell><cell>Apache 2.0</cell><cell>[281]</cell></row><row><cell>Golos</cell><cell>Custom</cell><cell>[302]</cell></row><row><cell>Hebrew Coursera</cell><cell>Unspecified</cell><cell>-</cell></row><row><cell>Hebrew Kan</cell><cell>Unspecified</cell><cell>-</cell></row><row><cell>Highland Puebla Nahuatl</cell><cell>CC BY-NC-SA 3.0</cell><cell>[321]</cell></row><row><cell>JTUBESPEECH</cell><cell>Unspecified</cell><cell>[325]</cell></row><row><cell>Japanese Anime Speech</cell><cell>CC0 1.0</cell><cell>-</cell></row><row><cell>KSC</cell><cell>CC BY 4.0</cell><cell>[303]</cell></row><row><cell>Kathbath</cell><cell>CC0 1.0</cell><cell>[357]</cell></row><row><cell>KeSpeech</cell><cell>Custom</cell><cell>[327]</cell></row><row><cell>KsponSpeech</cell><cell>Unspecified</cell><cell>[208]</cell></row><row><cell></cell><cell></cell><cell>Continued on next page</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 9 :</head><label>9</label><figDesc>References and licenses for audio dataset collections presented in this paper. Collections containing material under more than three distinct licenses are marked as having "Various" licenses, and we refer readers to our raw data for the full details. Datasets are sorted alphabetically for ease of dataset lookup.</figDesc><table><row><cell>Collection</cell><cell>Licenses</cell><cell>Cite</cell></row><row><cell>LJSpeech</cell><cell>Public Domain</cell><cell>[75]</cell></row><row><cell>LaboroTVSpeech</cell><cell>Custom</cell><cell>[273]</cell></row><row><cell>LibriSpeech</cell><cell>CC BY 4.0</cell><cell>[36]</cell></row><row><cell>M-AILABS</cell><cell>Custom</cell><cell>[447]</cell></row><row><cell>M2ASR</cell><cell>Unspecified</cell><cell>[83], [90], [332], [399]</cell></row><row><cell>MAGICDATA</cell><cell>CC BY-NC-ND 4.0</cell><cell>-</cell></row><row><cell>MASC</cell><cell>CC BY 4.0</cell><cell>[389]</cell></row><row><cell>MaSS</cell><cell>Unspecified</cell><cell>[211]</cell></row><row><cell>MagicData-RAMC</cell><cell>CC BY-NC-ND 4.0</cell><cell>[378]</cell></row><row><cell>MediaSpeech</cell><cell>CC BY 4.0</cell><cell>[304]</cell></row><row><cell>Minds14</cell><cell>CC BY 4.0</cell><cell>[294]</cell></row><row><cell>MuST-C</cell><cell>CC BY-NC-ND 4.0</cell><cell>[149]</cell></row><row><cell>Multiling. LibriSpeech</cell><cell>CC BY 4.0</cell><cell>[252]</cell></row><row><cell>Multiling. TEDx</cell><cell>CC BY-NC-ND 4.0</cell><cell>[320]</cell></row><row><cell>NST Danish</cell><cell>CC0 1.0</cell><cell>-</cell></row><row><cell>NST Norwegian</cell><cell>CC0 1.0</cell><cell>-</cell></row><row><cell>NST Swedish</cell><cell>CC0 1.0</cell><cell>-</cell></row><row><cell>Nigerian English</cell><cell>CC BY-SA 4.0</cell><cell>-</cell></row><row><cell>Norwegian Parl.</cell><cell>CC0 1.0</cell><cell>[371]</cell></row><row><cell>Norwegian Parl. Speech</cell><cell>CC0 1.0</cell><cell>[371]</cell></row><row><cell>OLKAVS</cell><cell>Custom</cell><cell>[404]</cell></row><row><cell>OpenSTT</cell><cell>CC BY-NC 4.0</cell><cell>[203]</cell></row><row><cell>People's Speech</cell><cell>Various</cell><cell>[293]</cell></row><row><cell>QASR</cell><cell>Unspecified</cell><cell>[312]</cell></row><row><cell>RTVE</cell><cell>Custom</cell><cell>-</cell></row><row><cell>ReazonSpeech</cell><cell>CDLA-Sharing-1.0</cell><cell>[420]</cell></row><row><cell>Regional Af. Am. Lang.</cell><cell>CC BY-NC-SA 4.0</cell><cell>-</cell></row><row><cell>RixVox</cell><cell>CC BY 4.0</cell><cell>-</cell></row><row><cell>SDS-200</cell><cell>Custom</cell><cell>[367]</cell></row><row><cell>SPGISpeech</cell><cell>Custom</cell><cell>[315]</cell></row><row><cell>Samromur</cell><cell>CC BY 4.0</cell><cell>[245]</cell></row><row><cell>Samromur Children</cell><cell>CC BY 4.0</cell><cell>[354]</cell></row><row><cell>Samromur Milljon</cell><cell>CC BY 4.0</cell><cell>-</cell></row><row><cell>Shrutilipi</cell><cell>CC0 1.0</cell><cell>[341]</cell></row><row><cell>Snow Mountain</cell><cell>CC BY-SA 4.0</cell><cell>[406]</cell></row><row><cell>Spoken Wikipedia</cell><cell>CC BY-SA 4.0</cell><cell>[137]</cell></row><row><cell>Switchboard</cell><cell>LDC User Agreement</cell><cell>[2]</cell></row><row><cell>TED-LIUM3</cell><cell>CC BY-NC-ND 3.0</cell><cell>[109]</cell></row><row><cell>THCHS-30</cell><cell>Apache 2.0</cell><cell>[42]</cell></row><row><cell>THUYG-20</cell><cell>Apache 2.0</cell><cell>[39]</cell></row><row><cell>TIMIT</cell><cell>LDC User Agreement</cell><cell>[3]</cell></row><row><cell></cell><cell></cell><cell>Continued on next page</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 9 :</head><label>9</label><figDesc>References and licenses for audio dataset collections presented in this paper. Collections containing material under more than three distinct licenses are marked as having "Various" licenses, and we refer readers to our raw data for the full details. Datasets are sorted alphabetically for ease of dataset lookup.</figDesc><table><row><cell>Collection</cell><cell>Licenses</cell><cell>Cite</cell></row><row><cell>VCTK</cell><cell>CC BY 4.0</cell><cell>-</cell></row><row><cell>VibraVox</cell><cell>CC BY 4.0</cell><cell>-</cell></row><row><cell>VoxPopuli</cell><cell>CC0 1.0</cell><cell>[329]</cell></row><row><cell>Vystadial</cell><cell>CC BY-SA 3.0</cell><cell>[30]</cell></row><row><cell>WenetSpeech</cell><cell>CC BY 4.0</cell><cell>[379]</cell></row><row><cell>West Afr. Radio</cell><cell>CC BY-SA 4.0</cell><cell>[288]</cell></row><row><cell>West Afr. Virt. Asst.</cell><cell>CC BY-SA 4.0</cell><cell>[288]</cell></row><row><cell>YODAS</cell><cell>CC BY 3.0</cell><cell>[394]</cell></row><row><cell>Zeroth-Korean</cell><cell>CC BY 4.0</cell><cell>-</cell></row><row><cell>aidatatang</cell><cell>CC BY-NC-ND 4.0</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 10 :</head><label>10</label><figDesc>References and licenses for video dataset collections presented in this paper. Collections containing material under more than three distinct licenses are marked as having "Various" licenses, and we refer readers to our raw data for the full details. Datasets are sorted alphabetically for ease of dataset lookup.</figDesc><table><row><cell>Collection</cell><cell>Licenses</cell><cell>Cite</cell></row><row><cell>100DOH</cell><cell>Custom</cell><cell>[258]</cell></row><row><cell>20BN-SOMETHING</cell><cell>Custom</cell><cell>[72]</cell></row><row><cell>20BN-jester</cell><cell>Custom</cell><cell>[170]</cell></row><row><cell>50 Salads</cell><cell>CC BY-NC-SA 4.0</cell><cell>[24]</cell></row><row><cell>ActivityNet</cell><cell>MIT License</cell><cell>[35]</cell></row><row><cell>Apes</cell><cell>Unspecified</cell><cell>[272]</cell></row><row><cell>Ava</cell><cell>CC BY 4.0</cell><cell>[104], [182]</cell></row><row><cell>Breakfast</cell><cell>CC BY 4.0</cell><cell>[31]</cell></row><row><cell>CDAD</cell><cell>Unspecified</cell><cell>[376]</cell></row><row><cell>COIN</cell><cell>Custom</cell><cell>[190]</cell></row><row><cell>Charades</cell><cell>Custom</cell><cell>[60]</cell></row><row><cell>Charades-Ego</cell><cell>Custom</cell><cell>[126]</cell></row><row><cell>Collective</cell><cell>Unspecified</cell><cell>[14]</cell></row><row><cell>Condensed Movies</cell><cell>CC BY 4.0</cell><cell>[207]</cell></row><row><cell>CrossTask</cell><cell>Unspecified</cell><cell>[201]</cell></row><row><cell>Davis</cell><cell>Custom</cell><cell>[55]</cell></row><row><cell>DiDeMo</cell><cell>BSD 2-Clause License</cell><cell>[108]</cell></row><row><cell>Disney Vid. Gen.</cell><cell>Apache 2.0</cell><cell>-</cell></row><row><cell>EEV</cell><cell>CC BY 4.0</cell><cell>[324]</cell></row><row><cell>EPIC-KITCHENS</cell><cell>CC BY-NC 4.0</cell><cell>[100]</cell></row><row><cell>Ego4D</cell><cell>Custom, MIT License</cell><cell>[351]</cell></row><row><cell>FERV39k</cell><cell>CC BY-NC 4.0</cell><cell>[375]</cell></row><row><cell>FineGym</cell><cell>CC BY-NC 4.0</cell><cell>[259]</cell></row><row><cell>FineVideo</cell><cell>CC BY 4.0</cell><cell>-</cell></row><row><cell>HAA500</cell><cell>Unspecified</cell><cell>[283]</cell></row><row><cell>HACS</cell><cell>Custom</cell><cell>[199]</cell></row><row><cell>HD-VILA-100M</cell><cell>Custom</cell><cell>[377]</cell></row><row><cell>HMDB</cell><cell>CC BY 4.0</cell><cell>[19]</cell></row><row><cell>HOLLYWOOD2</cell><cell>Unspecified</cell><cell>[13]</cell></row><row><cell>HOMAGE</cell><cell>Unspecified</cell><cell>[319]</cell></row><row><cell>HVU</cell><cell>Custom</cell><cell>[220]</cell></row><row><cell>Hollywood Ext.</cell><cell>MIT License</cell><cell>[26]</cell></row><row><cell>How2</cell><cell>Various</cell><cell>[123]</cell></row><row><cell>HowTo100M</cell><cell>Unspecified</cell><cell>[171]</cell></row><row><cell>ImageNet-Vid</cell><cell>CC BY-NC 4.0</cell><cell>[41]</cell></row><row><cell>Kinetics</cell><cell>Unspecified</cell><cell>[79], [97], [261]</cell></row><row><cell>LEMMA</cell><cell>Unspecified</cell><cell>[228]</cell></row><row><cell>LSMDC</cell><cell>Custom, MIT License</cell><cell>[57], [260]</cell></row><row><cell>M-MiT</cell><cell>Unspecified</cell><cell>[311]</cell></row><row><cell>MAD</cell><cell>Custom</cell><cell>[372]</cell></row><row><cell>MMAct</cell><cell>Custom</cell><cell>[163]</cell></row><row><cell></cell><cell></cell><cell>Continued on next page</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 10 :</head><label>10</label><figDesc>References and licenses for video dataset collections presented in this paper. Collections containing material under more than three distinct licenses are marked as having "Various" licenses, and we refer readers to our raw data for the full details. Datasets are sorted alphabetically for ease of dataset lookup.</figDesc><table><row><cell>Collection</cell><cell>Licenses</cell><cell>Cite</cell></row><row><cell>MPII</cell><cell>Unspecified, Custom</cell><cell>[38], [58]</cell></row><row><cell>MSA</cell><cell>Unspecified</cell><cell>[193]</cell></row><row><cell>MSR-VTT</cell><cell>Unspecified</cell><cell>[62]</cell></row><row><cell>MVBench</cell><cell>MIT License</cell><cell>[439]</cell></row><row><cell>Mars</cell><cell>Unspecified</cell><cell>[66]</cell></row><row><cell>Mimetics</cell><cell>Unspecified</cell><cell>[330]</cell></row><row><cell>Moments in Time</cell><cell>Custom</cell><cell>[172]</cell></row><row><cell>Movie-Net</cell><cell>Unspecified</cell><cell>[226]</cell></row><row><cell>MovieGraphs</cell><cell>Custom</cell><cell>[130]</cell></row><row><cell>MovieQA</cell><cell>Unspecified</cell><cell>[61]</cell></row><row><cell>MovieScenes</cell><cell>Unspecified</cell><cell>[254]</cell></row><row><cell>MultiTHUMOS</cell><cell>CC BY 4.0</cell><cell>[92]</cell></row><row><cell>NTU RGB+D</cell><cell>Custom</cell><cell>[59]</cell></row><row><cell>Narrated Instr. Vid.</cell><cell>MIT License</cell><cell>[46]</cell></row><row><cell>OmniSource-Web</cell><cell>Apache License 2.0</cell><cell>[221]</cell></row><row><cell>Oops!</cell><cell>CC BY-NC-SA 4.0</cell><cell>[223]</cell></row><row><cell>OpenVid-1M</cell><cell>CC-BY-4.0</cell><cell>[444]</cell></row><row><cell>PKU-MMD</cell><cell>Unspecified</cell><cell>[85]</cell></row><row><cell>Project-Aria</cell><cell>Apache License 2.0</cell><cell>[403], [441]</cell></row><row><cell>QFVS</cell><cell>Unspecified</cell><cell>[89]</cell></row><row><cell>QuerYD</cell><cell>Unspecified</cell><cell>[316]</cell></row><row><cell>RareAct</cell><cell>Unspecified</cell><cell>[244]</cell></row><row><cell>SOA</cell><cell>Unspecified</cell><cell>[220]</cell></row><row><cell>ShareGPT4Video</cell><cell>Attribution-NonCommercial 4.0 In-</cell><cell>[435]</cell></row><row><cell></cell><cell>ternational</cell><cell></cell></row><row><cell>Spoken Moments</cell><cell>Custom</cell><cell>[310]</cell></row><row><cell>Sports-1M</cell><cell>CC BY 3.0</cell><cell>[29]</cell></row><row><cell>StoryGraphs</cell><cell>Unspecified</cell><cell>[32]</cell></row><row><cell>SumMe</cell><cell>Unspecified</cell><cell>[27]</cell></row><row><cell>TGIF</cell><cell>Custom</cell><cell>[52]</cell></row><row><cell>THUMOS</cell><cell>Custom</cell><cell>[74]</cell></row><row><cell>TITAN</cell><cell>Non Commercial</cell><cell>[242]</cell></row><row><cell>TRECVid</cell><cell>CC BY-NC-SA 4.0</cell><cell>[206]</cell></row><row><cell>TVSum</cell><cell>CC BY 3.0</cell><cell>[44]</cell></row><row><cell>TinyVIRAT</cell><cell>Unspecified</cell><cell>[218]</cell></row><row><cell>Toyota Smarthome</cell><cell>Custom</cell><cell>[147]</cell></row><row><cell>UAV-Human</cell><cell>Custom</cell><cell>[306]</cell></row><row><cell>UCF101</cell><cell>Unspecified</cell><cell>[20]</cell></row><row><cell>VIOLIN</cell><cell>Unspecified</cell><cell>[240]</cell></row><row><cell>VLOG</cell><cell>Custom</cell><cell>[71]</cell></row><row><cell>VTW</cell><cell>Unspecified</cell><cell>[64]</cell></row><row><cell>VaTeX</cell><cell>CC BY 4.0</cell><cell>[266]</cell></row><row><cell></cell><cell></cell><cell>Continued on next page</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>The Speech Datasets Collection</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>openslr.org: Open Speech and Language Resources. OpenSLR is a widely used platform in the speech community, dedicated to hosting resources for speech tasks.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2"><p>We use top level Glottolog families.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3"><p>A dataset creator, following[123], is defined as an organization associated with the release of the dataset as created for machine learning-not any of the upstream sources. More details in Appendix D.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4"><p>YouTube Terms of Service.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_5"><p>Reddit User Agreement and StackOverflow Terms of Service.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_6"><p>We treat the enforceability of licenses and terms as an open legal question, beyond the scope of our work.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This research was conducted by the <rs type="funder">Data Provenance Initiative</rs>, a collective of independent and academic researchers volunteering their time to data transparency projects. The Data Provenance Initiative is supported by the <rs type="funder">Mozilla Data Futures Lab Infrastructure Fund</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Table <ref type="table">10</ref>: References and licenses for video dataset collections presented in this paper. Collections containing material under more than three distinct licenses are marked as having "Various" licenses, and we refer readers to our raw data for the full details. Datasets are sorted alphabetically for ease of dataset lookup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Collection</head><p>Licenses </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Untitled review</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Wilson</surname></persName>
		</author>
		<ptr target="http://www.jstor.org/stable/1804762" />
	</analytic>
	<monogr>
		<title level="j">The American Economic Review</title>
		<idno type="ISSN">00028282</idno>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="442" to="444" />
			<date type="published" when="1914">1914</date>
		</imprint>
	</monogr>
	<note>visited on 09/26/2024</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On the measurement of inequality</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Atkinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of economic theory</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="244" to="263" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A survey of video datasets for human action and activity recognition</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Chaquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Carmona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fern√°ndez-Caballero</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cviu.2013.01.013</idno>
		<ptr target="http://dx.doi.org/10.1016/j.cviu.2013.01.013" />
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<idno type="ISSN">1077-3142</idno>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="633" to="659" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Youtube-8m: A large-scale video classification benchmark</title>
		<author>
			<persName><forename type="first">S</forename><surname>Abu-El-Haija</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kothari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.08675</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Squad: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.05250</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Hollywood in homes: Crowdsourcing data collection for activity understanding</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Sigurdsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.01753[cs.CV]</idno>
		<ptr target="https://arxiv.org/abs/1604.01753" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Ito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Johnson</surname></persName>
		</author>
		<ptr target="https://keithito.com/LJ-Speech-Dataset" />
		<title level="m">The LJ Speech Dataset</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">No classification without representation: Assessing geodiversity issues in open data sets for the developing world</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Halpern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Breck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Atwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.08536</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Playing hard exploration games by watching youtube</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Aytar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pfaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Budden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Paine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>De Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Grauman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Cesa-Bianchi</surname></persName>
		</editor>
		<editor>
			<persName><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
	<note>Online]. Available: https : / / proceedings . neurips . cc / paper _ files / paper / 2018 / file / 35309226eb45ec366ca86a4329a2b7c3-Paper.pdf</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Data statements for natural language processing: Toward mitigating system bias and enabling better science</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Friedman</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00041</idno>
		<ptr target="https://aclanthology.org/Q18-1041" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="587" to="604" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Gender shades: Intersectional accuracy disparities in commercial gender classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Buolamwini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gebru</surname></persName>
		</author>
		<ptr target="https://proceedings.mlr.press/v81/buolamwini18a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Conference on Fairness, Accountability and Transparency</title>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Friedler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Wilson</surname></persName>
		</editor>
		<meeting>the 1st Conference on Fairness, Accountability and Transparency</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="77" to="91" />
		</imprint>
	</monogr>
	<note>ser. Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Gender shades: Intersectional accuracy disparities in commercial gender classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Buolamwini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gebru</surname></persName>
		</author>
		<ptr target="https://proceedings.mlr.press/v81/buolamwini18a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Conference on Fairness, Accountability and Transparency</title>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Friedler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Wilson</surname></persName>
		</editor>
		<meeting>the 1st Conference on Fairness, Accountability and Transparency</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="77" to="91" />
		</imprint>
	</monogr>
	<note>ser. Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Common voice: A massively-multilingual speech corpus</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ardila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Davis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.06670</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Does object recognition work for everyone?</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">De</forename><surname>Vries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition workshops</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="52" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Visual to text: Survey of image and video captioning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TETCI.2019.2892755</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Emerging Topics in Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="297" to="312" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Mundane content on social media: Creation, circulation, and the copyright problem</title>
		<author>
			<persName><forename type="first">J</forename><surname>Meese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hagedorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Media+ Society</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">190</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Model cards for model reporting</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zaldivar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on fairness, accountability, and transparency</title>
		<meeting>the conference on fairness, accountability, and transparency</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="220" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Moments in time dataset: One million videos for event understanding</title>
		<author>
			<persName><forename type="first">M</forename><surname>Monfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Andonian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="502" to="508" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Social data: Biases, methodological pitfalls, and ethical boundaries</title>
		<author>
			<persName><forename type="first">A</forename><surname>Olteanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kƒ±cƒ±man</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in big data</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Common voice: A massively-multilingual speech corpus</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ardila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Davis</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2020.lrec-1.520" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth Language Resources and Evaluation Conference</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Calzolari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>B√©chet</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Blache</surname></persName>
		</editor>
		<meeting>the Twelfth Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4218" to="4222" />
		</imprint>
	</monogr>
	<note>English</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper_files/paper/2020/file/1457" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Ranzato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hadsell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Balcan</surname></persName>
		</editor>
		<editor>
			<persName><surname>Lin</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
		</imprint>
	</monogr>
	<note>c0d6bfcb4967418bfb8ac142f64a-Paper.pdf</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Semantic visual navigation by watching youtube videos</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper_files/paper/2020/file/2cd" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Ranzato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hadsell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Balcan</surname></persName>
		</editor>
		<editor>
			<persName><surname>Lin</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="4283" to="4294" />
		</imprint>
	</monogr>
	<note>cde4312ef7-Paper.pdf</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">The pile: An 800gb dataset of diverse text for language modeling</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Black</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00027</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Scaling laws for autoregressive generative modeling</title>
		<author>
			<persName><forename type="first">T</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Katz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.14701[cs.LG]</idno>
		<ptr target="https://arxiv.org/abs/2010.14701" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">The state and fate of linguistic diversity and inclusion in the nlp world</title>
		<author>
			<persName><forename type="first">P</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Santy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Budhiraja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Choudhury</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.09095</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Scaling laws for neural language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Henighan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.08361</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Ai4bharat-indicnlp corpus: Monolingual corpora and word embeddings for indic languages</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kunchukuttan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kakwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Golla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00085</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Beyond &quot;i agree&quot;: Users&apos; understanding of web site terms of service</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social media+ society</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="056" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The new legal landscape for text mining and machine learning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Sag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Copyright Society of the USA</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">A comprehensive study of deep video action recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.06567[cs.CV</idno>
		<ptr target="https://arxiv.org/abs/2012.06567" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Masakhaner: Named entity recognition for african languages</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Adelani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Abbott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1116" to="1131" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">How might we create better benchmarks for speech recognition?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Aks√´nova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Van Esch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Flynn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Golik</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.bppf-1.4</idno>
		<ptr target="https://aclanthology.org/2021.bppf-1.4" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Benchmarking: Past, Present and Future</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Church</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Liberman</surname></persName>
		</editor>
		<editor>
			<persName><surname>Kordoni</surname></persName>
		</editor>
		<meeting>the 1st Workshop on Benchmarking: Past, Present and Future</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="22" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Xls-r: Self-supervised cross-lingual speech representation learning at scale</title>
		<author>
			<persName><forename type="first">A</forename><surname>Babu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tjandra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.09296</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Addressing &quot;documentation debt&quot; in machine learning research: A retrospective datasheet for bookcorpus</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bandy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vincent</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.05241</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Multimodal datasets: Misogyny, pornography, and malignant stereotypes</title>
		<author>
			<persName><forename type="first">A</forename><surname>Birhane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">U</forename><surname>Prabhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kahembwe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.01963</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Quality at a glance: An audit of web-crawled multilingual datasets</title>
		<author>
			<persName><forename type="first">I</forename><surname>Caswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kreutzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.12028</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Documenting large webtext corpora: A case study on the colossal clean crawled corpus</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marasoviƒá</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1286" to="1305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11929[cs.CV</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Datasheets for datasets</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gebru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Morgenstern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vecchione</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="86" to="92" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">What&apos;s in the box? a preliminary analysis of undesirable content in the common crawl corpus</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Luccioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Viviano</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.02732[cs.CL</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Understanding gender and racial disparities in image recognition models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mahadev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chakravarti</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.09211</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Automatic speech recognition: A survey</title>
		<author>
			<persName><forename type="first">M</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mehmood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Makhdoom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multimedia Tools and Applications</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="9411" to="9457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Monfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2105.04489</idno>
		<idno type="arXiv">arXiv:2105.04489</idno>
		<ptr target="http://arxiv.org/abs/2105.04489" />
		<title level="m">Spoken Moments: Learning Joint Audio-Visual Representations from Video Descriptions</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
	<note>cs, eess visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Data and its (dis) contents: A survey of dataset development and use in machine learning research</title>
		<author>
			<persName><forename type="first">A</forename><surname>Paullada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">D</forename><surname>Raji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hanna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Patterns</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Learning transferable visual models from natural language supervision</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hallacy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.00020</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Changing the world by changing the data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rogers</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.170</idno>
		<ptr target="https://aclanthology.org/2021.acl-long.170" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2182" to="2194" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Everyone wants to do the model work, not the data work&quot;: Data cascades in high-stakes AI</title>
		<author>
			<persName><forename type="first">N</forename><surname>Sambasivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kapania</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Highfill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Akrong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Aroyo</surname></persName>
		</author>
		<idno type="DOI">10.1145/3411764.3445518</idno>
		<ptr target="https://doi.org/10.1145/3411764.3445518" />
	</analytic>
	<monogr>
		<title level="m">CHI, ser. CHI &apos;21</title>
		<meeting><address><addrLine>Yokohama, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Multitask prompted training enables zero-shot task generalization</title>
		<author>
			<persName><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2110.08207" />
	</analytic>
	<monogr>
		<title level="m">ICLR 2022</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Finetuned language models are zero-shot learners</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Challenges in detoxifying language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Glaese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uesato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2447" to="2469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Detoxifying language models risks marginalizing minority voices</title>
		<author>
			<persName><forename type="first">A</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gururangan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter</title>
		<meeting>the 2021 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2390" to="2397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Masader: Metadata sourcing for arabic text and speech data resources</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Alyafeai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Masoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghaleb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Al-Shaibani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth Language Resources and Evaluation Conference</title>
		<meeting>the Thirteenth Language Resources and Evaluation Conference</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="6340" to="6351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Quantifying memorization across neural language models</title>
		<author>
			<persName><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jagielski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.07646[cs.LG]</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Clap: Learning audio concepts from natural language supervision</title>
		<author>
			<persName><forename type="first">B</forename><surname>Elizalde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deshmukh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Ismail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.04769</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs.SD</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Dataset geography: Mapping language data to language users</title>
		<author>
			<persName><forename type="first">F</forename><surname>Faisal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anastasopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3381" to="3411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">The flores-101 evaluation benchmark for lowresource and multilingual machine translation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="522" to="538" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Training compute-optimal large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mensch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.15556</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Leakage and the reproducibility crisis in ml-based science</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Narayanan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.07048</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Quality at a glance: An audit of web-crawled multilingual datasets</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kreutzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Caswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="50" to="72" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">The bigscience roots corpus: A 1.6tb composite multilingual dataset</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lauren√ßon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Saulnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper_files/paper/2022/file/ce" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Koyejo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Belgrave</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Oh</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="31" to="809" />
		</imprint>
	</monogr>
	<note>e92e3de2372a4b93353eb7f3dc0bd-Paper-Datasets_and_Benchmarks.pdf</note>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Documenting geographically and contextually diverse data sources: The bigscience catalogue of language data and resources</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mcmillan-Major</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Alyafeai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Biderman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.10066[cs.CL]</idno>
		<ptr target="https://arxiv.org/abs/2201.10066" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Documenting geographically and contextually diverse data sources: The bigscience catalogue of language data and resources</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mcmillan-Major</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Alyafeai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Biderman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.10066</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Moctezuma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ram√≠rez-Delreal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Gonz√°lez-Ch√°vez</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.05976[cs.CV</idno>
		<ptr target="https://arxiv.org/abs/2204.05976" />
		<title level="m">Video captioning: A comparative review of where we are and which could be the route</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Training language models to follow instructions with human feedback</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.02155</idno>
		<ptr target="https://arxiv.org/abs/2203.02155" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Hierarchical Text-Conditional Image Generation with CLIP Latents</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2204.06125</idno>
		<idno type="arXiv">arXiv:arXiv:2204.06125</idno>
		<idno>arXiv: 2204.06125</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Red-teaming the stable diffusion safety filter</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Paleka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lindner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Heim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tram√®r</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.04610</idno>
		<ptr target="https://arxiv.org/abs/2210.04610" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs.AI</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Make-A-Video: Text-to-Video Generation without Text-Video Data</title>
		<author>
			<persName><forename type="first">U</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Polyak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hayes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:arXiv:2209.14792</idno>
		<idno>arXiv: 2209.14792</idno>
		<ptr target="http://arxiv.org/abs/2209.14792" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Bigssl: Exploring the frontier of large-scale semisupervised learning for automatic speech recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Han</surname></persName>
		</author>
		<idno type="DOI">10.1109/JSTSP.2022.3182537</idno>
		<ptr target="http://dx.doi.org/10.1109/JSTSP.2022.3182537" />
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1519" to="1532" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Survey of video object detection algorithms based on deep learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<idno type="DOI">10.1145/3508546.3508622</idno>
		<ptr target="https://doi.org/10.1145/3508546.3508622" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 4th International Conference on Algorithms, Computing and Artificial Intelligence, ser. ACAI &apos;21</title>
		<meeting>the 2021 4th International Conference on Algorithms, Computing and Artificial Intelligence, ser. ACAI &apos;21<address><addrLine>Sanya, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Scaling laws for generative mixed-modal language models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Aghajanyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="265" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Birhane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Prabhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Boddeti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Luccioni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.03449</idno>
		<title level="m">Into the laions den: Investigating hate in multimodal datasets</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Stable video diffusion: Scaling latent video diffusion models to large datasets</title>
		<author>
			<persName><forename type="first">A</forename><surname>Blattmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dockhorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kulal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.15127[cs.CV]</idno>
		<ptr target="https://arxiv.org/abs/2311.15127" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">The foundation model transparency index</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Klyman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Longpre</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.12941[cs.LG]</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Quantifying memorization across neural language models</title>
		<author>
			<persName><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jagielski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tram√®r</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<meeting><address><addrLine>OpenReview</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Extracting training data from diffusion models</title>
		<author>
			<persName><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nasr</surname></persName>
		</author>
		<ptr target="https://www.usenix.org/conference/usenixsecurity23/presentation/carlini" />
	</analytic>
	<monogr>
		<title level="m">32nd USENIX Security Symposium (USENIX Security 23)</title>
		<meeting><address><addrLine>Anaheim, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="5253" to="5270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Cen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hopkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Struckman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Videgaray Caso</surname></persName>
		</author>
		<idno type="DOI">10.2139/ssrn.4789403</idno>
		<ptr target="http://dx.doi.org/10.2139/ssrn.4789403" />
		<imprint>
			<date type="published" when="2023">2023</date>
			<publisher>AI Supply Chains</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Gender bias in hiring: An analysis of the impact of amazon&apos;s recruiting algorithm</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.54254/2754-1169/23/20230367</idno>
	</analytic>
	<monogr>
		<title level="j">Advances in Economics, Management and Political Sciences</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="134" to="140" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Can language models be instructed to protect personal information</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Language and linguistics in a complex world</title>
		<author>
			<persName><forename type="first">S</forename><surname>Coats</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>Dialect corpora from youtube</note>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Ai image training dataset found to include child sexual abuse imagery</title>
		<author>
			<persName><forename type="first">E</forename><surname>David</surname></persName>
		</author>
		<ptr target="https://www.theverge.com/2023/12/20/24009418/generative-ai-image-laion-csam-google-stability-stanford" />
	</analytic>
	<monogr>
		<title level="m">The Verge, 2023, 7:57 AM PST</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">What&apos;s in my big data?</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Elazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhagia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">H</forename><surname>Magnusson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Twelfth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Structure and contentguided video synthesis with diffusion models</title>
		<author>
			<persName><forename type="first">P</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Atighehchian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Granskog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Germanidis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.03011[cs.CV</idno>
		<ptr target="https://arxiv.org/abs/2302.03011" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Datacomp: In search of the next generation of multimodal datasets</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Gadre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ilharco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fang</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper_files/paper/2023/file/56332" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Oh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Naumann</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Globerson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Saenko</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hardt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="92" to="119" />
		</imprint>
	</monogr>
	<note>d41d55ad7ad8024aac625881be7-Paper-Datasets_and_Benchmarks.pdf</note>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Lemley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.15715</idno>
		<title level="m">Foundation models and fair use</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Understanding catastrophic forgetting in language models via implicit inference</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kotha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Springer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raghunathan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.10105</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">Harnessing largelanguage models to generate private synthetic text</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ponomareva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Syed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Macdermed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Terzis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.01684[cs.LG]</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Platypus: Quick, cheap, and powerful refinement of llms</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ruiz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS 2023 Workshop on Instruction Tuning and Instruction Following</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Talkin&quot;bout ai generation: Copyright and the generative-ai supply chain</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Grimmelmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.08133</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Yodas: Youtubeoriented dataset for audio and speech</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Takamichi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Saeki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shiota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Watanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Improved baselines with visual instruction tuning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main">Visual instruction tuning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">A pretrainer&apos;s guide to training data: Measuring the effects of data age, domain coverage, quality, &amp; toxicity</title>
		<author>
			<persName><forename type="first">S</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yauney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Reif</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.13169[cs.CL</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Discit ergo est: Training data provenance and fair use</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mahari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Mahari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shayne</forename><surname>Longpre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Network Law Review</title>
		<editor>
			<persName><forename type="first">Ai (ed. Thibault</forename><surname>Generative</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Volker</forename><surname>Schrepel</surname></persName>
		</editor>
		<editor>
			<persName><surname>Stocker</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2023">2023</date>
			<pubPlace>Winter</pubPlace>
		</imprint>
	</monogr>
	<note>Discit ergo est: Training Data Provenance And Fair Use</note>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title level="m" type="main">Comment to US copyright office on data provenance and copyright</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mahari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shayne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Donewald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">'</forename><surname>Pentland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lipsitz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">When less is more: Investigating data pruning for pretraining llms at scale</title>
		<author>
			<persName><forename type="first">M</forename><surname>Marion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>√úst√ºn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pozzobon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fadaee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hooker</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.04564[cs.CL</idno>
		<ptr target="https://arxiv.org/abs/2309.04564" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Silo language models: Isolating legal risk in a nonparametric datastore</title>
		<author>
			<persName><forename type="first">S</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gururangan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wallace</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS 2023 Workshop on Distribution Shifts: New Frontiers with Foundation Models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Licensed to learn: Mitigating copyright infringement liability of generative ai systems through contracts</title>
		<author>
			<persName><forename type="first">F</forename><surname>Morton-Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Notre Dame Journal on Emerging Technology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">64</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Crosslingual generalization through multitask finetuning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sutawika</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="15" to="991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title level="m" type="main">The RefinedWeb dataset for falcon LLM: Outperforming curated corpora with web data, and web data only</title>
		<author>
			<persName><forename type="first">G</forename><surname>Penedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Malartic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hesslow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.01116[cs.CL</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Reproducing whisper-style training using an open-source toolkit and publicly available data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<title level="m" type="main">The casual conversations v2 dataset</title>
		<author>
			<persName><forename type="first">B</forename><surname>Porgali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Albiero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ryda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Ferrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hazirbas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.04838</idno>
		<ptr target="https://arxiv.org/abs/2303.04838" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs.CV</note>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title level="m" type="main">Adaptive toxicity mitigation with retrieval-augmented models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Pozzobon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ermis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hooker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Goodtriever</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2310.07589</idno>
		<ptr target="https://arxiv.org/abs/2310.07589" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs.AI</note>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">End-to-end speech recognition: A survey</title>
		<author>
			<persName><forename type="first">R</forename><surname>Prabhavalkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schl√ºter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Watanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Robust speech recognition via large-scale weak supervision</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Brockman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mcleavey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="28" to="492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title level="m" type="main">Direct preference optimization: Your language model is secretly a reward model</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rafailov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.18290</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Self-supervised learning for videos: A survey</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Schiappa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Rawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
		<idno type="DOI">10.1145/3577925</idno>
		<ptr target="http://dx.doi.org/10.1145/3577925" />
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">13s</biblScope>
			<biblScope unit="page" from="1" to="37" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Detecting personal information in training corpora: An analysis</title>
		<author>
			<persName><forename type="first">N</forename><surname>Subramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Luccioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Trustworthy Natural Language Processing</title>
		<meeting>the 3rd Workshop on Trustworthy Natural Language Processing<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">TrustNLP 2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<title level="m" type="main">Gemini: A family of highly capable multimodal models</title>
		<author>
			<persName><forename type="first">G</forename><surname>Team</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Borgeaud</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.11805</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Youtube-asl: A large-scale, open-domain american sign language-english parallel corpus</title>
		<author>
			<persName><forename type="first">D</forename><surname>Uthus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tanzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Georg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Oh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Naumann</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Globerson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Saenko</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Hardt</surname></persName>
		</editor>
		<editor>
			<persName><surname>Levine</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="29" to="29" />
		</imprint>
	</monogr>
	<note>Available: https : / / proceedings . neurips . cc / paper _ files / paper / 2023 / file / 5c61452daca5f0c260e683b317d13a3f -Paper -Datasets _ and _ Benchmarks.pdf</note>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<title level="m" type="main">Tag your fish in the broken net: A responsible web framework for protecting online privacy and copyright</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.07915[cs.NI</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<monogr>
		<title level="m" type="main">Deep learning for video-text retrieval: A review</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.12552[cs.CV]</idno>
		<ptr target="https://arxiv.org/abs/2302.12552" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<monogr>
		<title level="m" type="main">The multilingual alignment prism: Aligning global and local preferences to reduce harm</title>
		<author>
			<persName><forename type="first">A</forename><surname>Aakanksha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ahmadian</surname></persName>
		</author>
		<author>
			<persName><surname>Ermis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.18682[cs.CL]</idno>
		<ptr target="https://arxiv.org/abs/2406.18682" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<monogr>
		<title level="m" type="main">Irokobench: A new benchmark for african languages in the age of large language models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Adelani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ojo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">A</forename><surname>Azime</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.03368[cs.CL</idno>
		<ptr target="https://arxiv.org/abs/2406.03368" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
		<title level="m" type="main">A survey on data selection for language models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Albalak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Elazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Xie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.16827</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b114">
	<monogr>
		<title level="m" type="main">Video generation models as world simulators</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Peebles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Holmes</surname></persName>
		</author>
		<ptr target="https://openai.com/research/video-generation-models-as-world-simulators" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<monogr>
		<title level="m" type="main">Nvidia sued for scraping youtube after 404 media investigation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cole</surname></persName>
		</author>
		<ptr target="https://www.404media.co/nvidia-sued-for-scraping-youtube-after-404-media-investigation/" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>404 Media</note>
</biblStruct>

<biblStruct xml:id="b116">
	<monogr>
		<title level="m" type="main">Nvlm: Open frontier-class multimodal llms</title>
		<author>
			<persName><forename type="first">W</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Datacomp: In search of the next generation of multimodal datasets</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Gadre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ilharco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<monogr>
		<title level="m" type="main">Acceptable use policies for foundation models</title>
		<author>
			<persName><forename type="first">K</forename><surname>Klyman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2409.09041[cs.CY]</idno>
		<ptr target="https://arxiv.org/abs/2409.09041" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<monogr>
		<title level="m" type="main">Best practices and lessons learned on synthetic data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2404.07503[cs.CL</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.18041</idno>
		<title level="m">Datasets for large language models: A comprehensive survey</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b121">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Albalak</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.16746</idno>
		<title level="m">The responsible foundation model development cheatsheet: A review of tools &amp; resources</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">A large-scale audit of dataset licensing and attribution in AI</title>
		<author>
			<persName><forename type="first">S</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mahari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.16787</idno>
	</analytic>
	<monogr>
		<title level="m">10/gt8f5p</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="975" to="987" />
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b123">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mahari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2407.14933</idno>
		<title level="m">Consent in crisis: The rapid decline of the ai data commons</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b124">
	<monogr>
		<title level="m" type="main">Data authenticity, consent, &amp; provenance for ai are all broken: What will it take to fix them?</title>
		<author>
			<persName><forename type="first">S</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mahari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Obeng-Marnu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2404.12691</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b125">
	<monogr>
		<title level="m" type="main">Seacrowd: A multilingual multimodal data hub and benchmark suite for southeast asian languages</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lovenia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mahendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Akbar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.10118</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b126">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Mauran</surname></persName>
		</author>
		<idno>28-09-2024</idno>
		<ptr target="https://mashable.com/article/openai-sora-ai-video-generator-training-data" />
		<title level="m">What was Sora trained on? Creatives demand answers</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Topics, authors, and institutions in large language model research: Trends from 17k arxiv papers</title>
		<author>
			<persName><forename type="first">R</forename><surname>Movva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Balachandar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Agostini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pierson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2024 Conference of the North American Chapter</title>
		<meeting>the 2024 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1223" to="1243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<monogr>
		<title level="m" type="main">Hello gpt-4o: We&apos;re announcing gpt-4o, our new flagship model that can reason across audio, vision, and text in real time</title>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<ptr target="https://openai.com/index/hello-gpt-4o/" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<monogr>
		<title level="m" type="main">Data, data everywhere: A guide for pretraining dataset construction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Prabhumoye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jennings</surname></persName>
		</author>
		<idno>2407.06380</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Scaling speech technology to 1,000+ languages</title>
		<author>
			<persName><forename type="first">V</forename><surname>Pratap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tjandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">97</biblScope>
			<biblScope unit="page" from="1" to="52" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<monogr>
		<title level="m" type="main">Anatomy of industrial scale multilingual asr</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Ramirez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chkhetiani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ehrenberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2404.09841</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b132">
	<monogr>
		<title level="m" type="main">Include: Evaluating multilingual language understanding with regional knowledge</title>
		<author>
			<persName><forename type="first">A</forename><surname>Romanou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Foroutan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sotnikova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2411.19799</idno>
		<ptr target="https://arxiv.org/abs/2411.19799" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>cs.CL</note>
</biblStruct>

<biblStruct xml:id="b133">
	<monogr>
		<title level="m" type="main">Aya dataset: An open-access collection for multilingual instruction tuning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vargus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dsouza</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.06619[cs.CL</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<monogr>
		<title level="m" type="main">Openai sued over using youtube videos without creators&apos; consent</title>
		<author>
			<persName><forename type="first">S</forename><surname>Skolnik</surname></persName>
		</author>
		<ptr target="https://news.bloomberglaw.com/litigation/openai-sued-over-using-youtube-videos-without-creators-consent" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>Bloomberg Law</note>
</biblStruct>

<biblStruct xml:id="b135">
	<monogr>
		<title level="m" type="main">Dolma: An open corpus of three trillion tokens for language model pretraining research</title>
		<author>
			<persName><forename type="first">L</forename><surname>Soldaini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kinney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhagia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.00159</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b136">
	<monogr>
		<title level="m" type="main">Aya model: An instruction finetuned open-access multilingual language model</title>
		<author>
			<persName><forename type="first">A</forename><surname>√úst√ºn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Aryabumi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-X</forename><surname>Yong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.07827</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b137">
	<monogr>
		<title level="m" type="main">Vidprom: A million-scale real prompt-gallery dataset for text-to-video diffusion models</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.06098</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b138">
	<monogr>
		<title level="m" type="main">Navigating dataset documentations in ai: A large-scale analysis of dataset cards on hugging face</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.13822[cs.LG]</idno>
		<ptr target="https://arxiv.org/abs/2401.13822" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<monogr>
		<title level="m" type="main">Open-sora: Democratizing efficient video production for all</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
		<ptr target="https://github.com/hpcaitech/Open-Sora" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">The ATIS spoken language systems pilot corpus</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Hemphill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Doddington</surname></persName>
		</author>
		<idno>DOI: 10/cz3442</idno>
		<ptr target="https://aclanthology.org/H90-1021" />
	</analytic>
	<monogr>
		<title level="m">Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley</title>
		<meeting><address><addrLine>Pennsylvania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990">June 24-27,1990. 1990</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">SWITCHBOARD: Telephone speech corpus for research and development</title>
		<author>
			<persName><forename type="first">J</forename><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Holliman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcdaniel</surname></persName>
		</author>
		<ptr target="http://ieeexplore.ieee.org/document/225858/" />
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech, and Signal Processing</title>
		<meeting><address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1992">1992. 1992</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="517" to="520" />
		</imprint>
	</monogr>
	<note>in [Proceedings] ICASSP-92 visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">TIMIT acoustic-phonetic continuous speech corpus</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">S</forename><surname>Garofolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lori</forename><forename type="middle">F</forename><surname>Lamel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">M</forename><surname>Fisher</surname></persName>
		</author>
		<idno type="DOI">10.35111/17GK-BN40</idno>
		<ptr target="https://catalog.ldc.upenn.edu/LDC93S1" />
	</analytic>
	<monogr>
		<title level="m">Artwork Size: 715776 KB Pages: 715776 KB</title>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Can prosody aid the automatic classification of dialog acts in conversational speech?</title>
		<author>
			<persName><forename type="first">E</forename><surname>Shriberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Stolcke</surname></persName>
		</author>
		<idno type="DOI">10.1177/002383099804100410</idno>
	</analytic>
	<monogr>
		<title level="j">Language and Speech</title>
		<idno type="ISSN">0023-8309</idno>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="443" to="492" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
	<note>Pt 3-4</note>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Dialogue act modeling for automatic tagging and recognition of conversational speech</title>
		<author>
			<persName><forename type="first">A</forename><surname>Stolcke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Coccaro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:cs/0006023</idno>
		<ptr target="http://arxiv.org/abs/cs/0006023" />
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<idno type="ISSN">0891-2017</idno>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1530" to="9312" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Corpus of spontaneous japanese: Its design and evaluation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Maekawa</surname></persName>
		</author>
		<idno>MMO2</idno>
		<ptr target="https://www.isca-archive.org/sspr_2003/maekawa03_sspr.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ISCA/IEEE Workshop on Spontaneous Speech Processing and Recognition</title>
		<meeting>the ISCA/IEEE Workshop on Spontaneous Speech Processing and Recognition</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">The fisher corpus: A resource for the next generations of speech-to-text</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Walker</surname></persName>
		</author>
		<ptr target="http://www.lrec-conf.org/proceedings/lrec2004/pdf/767.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC&apos;04</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Lino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Xavier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Ferreira</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Costa</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Silva</surname></persName>
		</editor>
		<meeting>the Fourth International Conference on Language Resources and Evaluation (LREC&apos;04<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA)</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b147">
	<monogr>
		<title level="m" type="main">CSLU: 22 languages corpus</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lander</surname></persName>
		</author>
		<idno type="DOI">10.35111/ZKN2-5X88</idno>
		<ptr target="https://catalog.ldc.upenn.edu/LDC2005S26" />
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>Online visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b148">
	<monogr>
		<title level="m" type="main">Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:cs/0506075</idno>
		<ptr target="http://arxiv.org/abs/cs/0506075" />
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">The AMI meeting corpus: A pre-announcement</title>
		<author>
			<persName><forename type="first">J</forename><surname>Carletta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ashby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bourban</surname></persName>
		</author>
		<idno type="DOI">10.1007/11677482_3</idno>
		<ptr target="http://link.springer.com/10.1007/11677482_3" />
	</analytic>
	<monogr>
		<title level="m">Series Title: Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Renals</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">3869</biblScope>
			<biblScope unit="page" from="28" to="39" />
		</imprint>
	</monogr>
	<note>Machine Learning for Multimodal Interaction visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b150">
	<monogr>
		<title level="m" type="main">Foreign accented english release 1.2, Artwork Size: 1468006 KB Pages: 1468006 KB</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lander</surname></persName>
		</author>
		<author>
			<persName><surname>Cslu</surname></persName>
		</author>
		<idno type="DOI">10.35111/0VWP-XN48</idno>
		<ptr target="https://catalog.ldc.upenn.edu/LDC2007S08" />
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">Measures of semantic similarity and relatedness in the biomedical domain</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V S</forename><surname>Pakhomov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Patwardhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Chute</surname></persName>
		</author>
		<idno>DOI: 10/fghjwr</idno>
		<ptr target="https://www.sciencedirect.com/science/article/pii/S1532046406000645" />
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Informatics</title>
		<idno type="ISSN">1532-0464</idno>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="288" to="299" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b152">
	<analytic>
		<title level="a" type="main">Actions in context</title>
		<author>
			<persName><forename type="first">M</forename><surname>Marszalek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<ptr target="https://ieeexplore.ieee.org/document/5206557/" />
	</analytic>
	<monogr>
		<title level="m">2009 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Miami, FL</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="2929" to="2936" />
		</imprint>
	</monogr>
	<note>d5bs7p. [Online visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">What are they doing? : Collective activity classification using spatio-temporal relationship among people</title>
		<author>
			<persName><forename type="first">Wongun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shahid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<ptr target="http://ieeexplore.ieee.org/document/5457461/" />
	</analytic>
	<monogr>
		<title level="m">2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops</title>
		<meeting><address><addrLine>Kyoto, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1282" to="1289" />
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b154">
	<monogr>
		<title level="m" type="main">ALLSSTAR: Archive of l1 and l2 scripted and spontaneous transcripts and recordings</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bradlow</surname></persName>
		</author>
		<ptr target="https://speechbox.linguistics.northwestern.edu/#!/?goto=allsstar" />
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">Opinosis: A graph based approach to abstractive summarization of highly redundant opinions</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ganesan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/C10-1039" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<editor>
			<persName><forename type="first">C.-R</forename><surname>Huang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</editor>
		<meeting>the 23rd International Conference on Computational Linguistics<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">Coling 2010</date>
			<biblScope unit="page" from="340" to="348" />
		</imprint>
	</monogr>
	<note>Coling 2010 Organizing Committee, 2010 visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">Semantic similarity and relatedness between clinical terms: An experimental study</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pakhomov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Melton</surname></persName>
		</author>
		<ptr target="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3041430/" />
	</analytic>
	<monogr>
		<title level="m">AMIA Annual Symposium Proceedings</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">2010</biblScope>
			<biblScope unit="page" from="572" to="576" />
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">Evaluation of topic identification methods on arabic corpora</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abbas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sma√Øli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Berkani</surname></persName>
		</author>
		<ptr target="https://www.dline.info/fpaper/jdim/v9i5/1.pdf" />
	</analytic>
	<monogr>
		<title level="j">Journal of Digital Information Management</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title level="a" type="main">HMDB: A large video database for human motion recognition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kuehne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Garrote</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Serre</surname></persName>
		</author>
		<ptr target="http://ieeexplore.ieee.org/document/6126543/" />
	</analytic>
	<monogr>
		<title level="m">2011 International Conference on Computer Vision</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2556" to="2563" />
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b159">
	<monogr>
		<title level="m" type="main">UCF101: A dataset of 101 human actions classes from videos in the wild</title>
		<author>
			<persName><forename type="first">K</forename><surname>Soomro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1212.0402</idno>
		<ptr target="http://arxiv.org/abs/1212.0402" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main">A thousand frames in just a few words: Lingual description of videos through latent topics and sparse object stitching</title>
		<author>
			<persName><forename type="first">P</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Doell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Corso</surname></persName>
		</author>
		<ptr target="http://ieeexplore.ieee.org/document/6619184/" />
	</analytic>
	<monogr>
		<title level="m">2013 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Portland, OR, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2634" to="2641" />
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main">Asgard: A portable architecture for multilingual dialogue systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cyphers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Glass</surname></persName>
		</author>
		<idno>DOI: 10/gtsqxn</idno>
		<ptr target="http://ieeexplore.ieee.org/document/6639301/" />
	</analytic>
	<monogr>
		<title level="m">2013 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="8386" to="8390" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b162">
	<monogr>
		<title level="m" type="main">Good debt or bad debt: Detecting semantic orientations in economic texts</title>
		<author>
			<persName><forename type="first">P</forename><surname>Malo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Takala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wallenius</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1307.5336</idno>
		<ptr target="http://arxiv.org/abs/1307.5336" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>cs,q-fin visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main">Combining embedded accelerometers with computer vision for recognizing food preparation activities</title>
		<author>
			<persName><forename type="first">S</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Mckenna</surname></persName>
		</author>
		<idno type="DOI">10.1145/2493432.2493482</idno>
		<ptr target="https://doi.org/10.1145/2493432.2493482" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 ACM international joint conference on Pervasive and ubiquitous computing, ser. UbiComp &apos;13</title>
		<meeting>the 2013 ACM international joint conference on Pervasive and ubiquitous computing, ser. UbiComp &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="729" to="738" />
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b164">
	<monogr>
		<title level="m" type="main">Spatial pattern templates for recognition of objects with regular structure</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tyleƒçek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>≈†√°ra</surname></persName>
		</author>
		<editor>Pattern Recognition, J. Weickert, M. Hein, and B. Schiele</editor>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="364" to="374" />
			<pubPlace>Berlin, Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<monogr>
		<title level="m" type="main">Weakly supervised action labeling in videos under ordering constraints</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lajugie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1407.1208</idno>
		<ptr target="http://arxiv.org/abs/1407.1208" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b166">
	<analytic>
		<title level="a" type="main">Creating summaries from user videos</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gygli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Grabner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Riemenschneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-10584-0_33</idno>
		<ptr target="http://link.springer.com/10.1007/978-3-319-10584-0_33" />
	</analytic>
	<monogr>
		<title level="m">Series Title: Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Fleet</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Pajdla</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Schiele</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="volume">8695</biblScope>
			<biblScope unit="page" from="978" to="981" />
		</imprint>
	</monogr>
	<note>Computer Vision -ECCV visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b167">
	<analytic>
		<title level="a" type="main">VideoStory: A new multimedia embedding for few-example recognition and translation of events</title>
		<author>
			<persName><forename type="first">A</forename><surname>Habibian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Snoek</surname></persName>
		</author>
		<idno type="DOI">10.1145/2647868.2654913</idno>
		<ptr target="https://dl.acm.org/doi/10.1145/2647868.2654913" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM international conference on Multimedia</title>
		<meeting>the 22nd ACM international conference on Multimedia<address><addrLine>Orlando Florida USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">ISBN</biblScope>
			<biblScope unit="page" from="978" to="979" />
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b168">
	<analytic>
		<title level="a" type="main">Large-scale video classification with convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Toderici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shetty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<ptr target="https://ieeexplore.ieee.org/document/6909619" />
	</analytic>
	<monogr>
		<title level="m">2014 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Columbus, OH, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1725" to="1732" />
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b169">
	<analytic>
		<title level="a" type="main">Free english and czech telephone speech corpus shared under the CC-BY-SA 3.0 license</title>
		<author>
			<persName><forename type="first">M</forename><surname>Korvas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Pl√°tek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Du≈°ek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>≈Ωilka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jurƒç√≠ƒçek</surname></persName>
		</author>
		<ptr target="http://www.lrec-conf.org/proceedings/lrec2014/pdf/535_Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Calzolari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Choukri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Declerck</surname></persName>
		</editor>
		<meeting>the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14<address><addrLine>Reykjavik, Iceland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="4423" to="4428" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA) visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b170">
	<analytic>
		<title level="a" type="main">The language of actions: Recovering the syntax and semantics of goal-directed human activities</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kuehne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Arslan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Serre</surname></persName>
		</author>
		<ptr target="https://ieeexplore.ieee.org/document/6909500/" />
	</analytic>
	<monogr>
		<title level="m">2014 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Columbus, OH, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="780" to="787" />
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b171">
	<analytic>
		<title level="a" type="main">StoryGraphs: Visualizing character interactions as a timeline</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tapaswi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bauml</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stiefelhagen</surname></persName>
		</author>
		<ptr target="https://openaccess.thecvf.com/content_cvpr_2014/html/Tapaswi_StoryGraphs_Visualizing_Character_2014_CVPR_paper.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="827" to="834" />
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b172">
	<analytic>
		<title level="a" type="main">Extraction of relations between genes and diseases from text and large-scale data analysis: Implications for translational research</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bravo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pinero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Queralt-Rosinach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rautschka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">I</forename><surname>Furlong</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12859-015-0472-9</idno>
		<idno>12859- 015-0472-9</idno>
		<ptr target="https://doi.org/10.1186/s" />
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<idno type="ISSN">1471-2105</idno>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">55</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b173">
	<analytic>
		<title level="a" type="main">Building large arabic multi-domain resources for sentiment analysis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Elsahar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>El-Beltagy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics and Intelligent Text Processing</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</editor>
		<meeting><address><addrLine>Ed., Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page">58</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b174">
	<analytic>
		<title level="a" type="main">ActivityNet: A large-scale video benchmark for human activity understanding</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C</forename><surname>Heilbron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Escorcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Niebles</surname></persName>
		</author>
		<ptr target="http://ieeexplore.ieee.org/document/7298698/" />
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting><address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="961" to="970" />
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b175">
	<analytic>
		<title level="a" type="main">Librispeech: An ASR corpus based on public domain audio books</title>
		<author>
			<persName><forename type="first">V</forename><surname>Panayotov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Khudanpur</surname></persName>
		</author>
		<ptr target="http://ieeexplore.ieee.org/document/7178964/" />
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting><address><addrLine>South Brisbane, Queensland, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="5206" to="5210" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b176">
	<analytic>
		<title level="a" type="main">Compositional semantic parsing on semi-structured tables</title>
		<author>
			<persName><forename type="first">P</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno>DOI: 10 / gfz98s</idno>
		<ptr target="https://aclanthology.org/P15-1142" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Zong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Strube</surname></persName>
		</editor>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1470" to="1480" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b177">
	<monogr>
		<title level="m" type="main">A dataset for movie description</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1501.02530</idno>
		<ptr target="http://arxiv.org/abs/1501.02530" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b178">
	<analytic>
		<title level="a" type="main">An open/free database and benchmark for uyghur speaker recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rozi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Zheng</surname></persName>
		</author>
		<ptr target="http://ieeexplore.ieee.org/document/7357869/" />
	</analytic>
	<monogr>
		<title level="m">2015 International Conference Oriental COCOSDA held jointly with 2015 Conference on Asian Spoken Language Research and Evaluation (O-COCOSDA/CASLRE)</title>
		<meeting><address><addrLine>Shanghai, China</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="81" to="85" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b179">
	<monogr>
		<title level="m" type="main">A neural attention model for abstractive sentence summarization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.00685</idno>
		<ptr target="http://arxiv.org/abs/1509.00685" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b180">
	<analytic>
		<title level="a" type="main">ImageNet large scale visual recognition challenge</title>
		<author>
			<persName><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11263-015-0816-y</idno>
		<ptr target="https://doi.org/10.1007/s11263-015-0816-y" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<idno type="ISSN">1573- 1405</idno>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b181">
	<monogr>
		<title level="m" type="main">THCHS-30 : A free chinese speech corpus</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.01882</idno>
		<ptr target="http://arxiv.org/abs/1512.01882" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b182">
	<monogr>
		<title level="m" type="main">Towards AI-complete question answering: A set of prerequisite toy tasks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.05698</idno>
		<ptr target="http://arxiv.org/abs/1502.05698" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>cs, stat visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b183">
	<analytic>
		<title level="a" type="main">TVSum: Summarizing web videos using titles</title>
		<author>
			<persName><forename type="first">Yale</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vallmitjana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Stent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jaimes</surname></persName>
		</author>
		<ptr target="http://ieeexplore.ieee.org/document/7299154/" />
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting><address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="5179" to="5187" />
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b184">
	<monogr>
		<title level="m" type="main">YouTube-8m: A large-scale video classification benchmark</title>
		<author>
			<persName><forename type="first">S</forename><surname>Abu-El-Haija</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kothari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.08675</idno>
		<ptr target="http://arxiv.org/abs/1609.08675" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b185">
	<monogr>
		<title level="m" type="main">Unsupervised learning from narrated instruction videos</title>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Alayrac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lacoste-Julien</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.09215</idno>
		<ptr target="http://arxiv.org/abs/1506.09215" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b186">
	<analytic>
		<title level="a" type="main">BRAD 1.0: Book reviews in arabic dataset</title>
		<author>
			<persName><forename type="first">A</forename><surname>Elnagar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Einea</surname></persName>
		</author>
		<ptr target="http://ieeexplore.ieee.org/document/7945800/" />
	</analytic>
	<monogr>
		<title level="m">2016 IEEE/ACS 13th International Conference of Computer Systems and Applications (AICCSA)</title>
		<meeting><address><addrLine>Agadir, Morocco</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b187">
	<monogr>
		<title level="m" type="main">A hierarchical deep temporal model for group activity recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ibrahim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Muralidharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mori</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06040</idno>
		<ptr target="http://arxiv.org/abs/1511.06040" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b188">
	<monogr>
		<title level="m" type="main">SelQA: A new benchmark for selection-based question answering</title>
		<author>
			<persName><forename type="first">T</forename><surname>Jurczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.08513</idno>
		<ptr target="http://arxiv.org/abs/1606.08513" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b189">
	<monogr>
		<title level="m" type="main">El-khair, 1.5 billion words arabic corpus</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">A</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1611.04033</idno>
		<ptr target="http://arxiv.org/abs/1611.04033" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b190">
	<monogr>
		<title level="m" type="main">Neural text generation from structured data with application to the biography domain</title>
		<author>
			<persName><forename type="first">R</forename><surname>Lebret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.07771</idno>
		<ptr target="http://arxiv.org/abs/1603.07771" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b191">
	<monogr>
		<title level="m" type="main">TGIF: A new dataset and benchmark on animated GIF description</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.02748</idno>
		<ptr target="http://arxiv.org/abs/1604.02748" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b192">
	<monogr>
		<title level="m" type="main">The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.08909</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b193">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1506.08909" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b194">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Merity</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.07843</idno>
		<ptr target="http://arxiv.org/abs/1609.07843" />
		<title level="m">Pointer sentinel mixture models</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b195">
	<analytic>
		<title level="a" type="main">A benchmark dataset and evaluation methodology for video object segmentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Perazzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pont-Tuset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mcwilliams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sorkine-Hornung</surname></persName>
		</author>
		<idno>DOI: 10/ggdmmw</idno>
		<ptr target="https://ieeexplore.ieee.org/document/7780454" />
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="724" to="732" />
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b196">
	<monogr>
		<title level="m" type="main">SQuAD: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.05250</idno>
		<ptr target="http://arxiv.org/abs/1606.05250" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b197">
	<monogr>
		<title level="m" type="main">Movie description</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.03705</idno>
		<ptr target="http://arxiv.org/abs/1605.03705" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b198">
	<analytic>
		<title level="a" type="main">Recognizing fine-grained and composite activities using hand-centric features and script data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Regneri</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.06648</idno>
		<ptr target="http://arxiv.org/abs/1502.06648" />
	</analytic>
	<monogr>
		<title level="m">10/f8w6kp</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="1573" to="1405" />
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b199">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Shahroudy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-T</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Rgb+d</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.02808</idno>
		<ptr target="http://arxiv.org/abs/1604.02808" />
		<title level="m">A large scale dataset for 3d human activity analysis</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b200">
	<monogr>
		<title level="m" type="main">Hollywood in homes: Crowdsourcing data collection for activity understanding</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Sigurdsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.01753</idno>
		<ptr target="http://arxiv.org/abs/1604.01753" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b201">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Tapaswi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stiefelhagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.02902</idno>
		<title level="m">MovieQA: Understanding stories in movies through question-answering</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b202">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1512.02902" />
		<imprint/>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b203">
	<analytic>
		<title level="a" type="main">MSR-VTT: A large video description dataset for bridging video and language</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rui</surname></persName>
		</author>
		<idno>DOI: 10/ggv9gj</idno>
		<ptr target="https://ieeexplore.ieee.org/document/7780940" />
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="5288" to="5296" />
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b204">
	<analytic>
		<title level="a" type="main">The value of semantic parse labeling for knowledge base question answering</title>
		<author>
			<persName><forename type="first">W.-T</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Suh</surname></persName>
		</author>
		<idno>DOI: 10/gkz3hq</idno>
		<ptr target="https://aclanthology.org/P16-2033" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Erk</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</editor>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="201" to="206" />
		</imprint>
	</monogr>
	<note>Short Papers visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b205">
	<monogr>
		<title level="m" type="main">Title generation for user generated videos</title>
		<author>
			<persName><forename type="first">K.-H</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Niebles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.07068</idno>
		<ptr target="http://arxiv.org/abs/1608.07068" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b206">
	<monogr>
		<title level="m" type="main">Character-level convolutional networks for text classification</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.01626</idno>
		<ptr target="http://arxiv.org/abs/1509.01626" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b207">
	<analytic>
		<title level="a" type="main">MARS: A video benchmark for large-scale person reidentification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Bie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2016</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Leibe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Matas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Sebe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="868" to="884" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b208">
	<monogr>
		<title level="m" type="main">AISHELL-1: An open-source mandarin speech corpus and a speech recognition baseline</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Na</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.05522</idno>
		<ptr target="http://arxiv.org/abs/1709.05522" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b209">
	<monogr>
		<title level="m" type="main">Fair prediction with disparate impact: A study of bias in recidivism prediction instruments</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chouldechova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.00056</idno>
		<ptr target="http://arxiv.org/abs/1703.00056" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>cs,stat visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b210">
	<analytic>
		<title level="a" type="main">Frames: A corpus for adding memory to goaloriented dialogue systems</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">El</forename><surname>Asri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<idno>DOI: 10/gtsqx4</idno>
		<ptr target="https://aclanthology.org/W17-5526" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Jokinen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Stede</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Devault</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Louis</surname></persName>
		</editor>
		<meeting>the 18th Annual SIGdial Meeting on Discourse and Dialogue<address><addrLine>Saarbr√ºcken, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="207" to="219" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b211">
	<monogr>
		<title level="m" type="main">Key-value retrieval networks for task-oriented dialogue</title>
		<author>
			<persName><forename type="first">M</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.05414</idno>
		<ptr target="http://arxiv.org/abs/1705.05414" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b212">
	<monogr>
		<title level="m" type="main">From lifestyle vlogs to everyday interactions</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Fouhey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-C</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.02310</idno>
		<ptr target="http://arxiv.org/abs/1712.02310" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b213">
	<monogr>
		<title level="m" type="main">The &quot;something something&quot; video database for learning and evaluating visual common sense</title>
		<author>
			<persName><forename type="first">R</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Kahou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michalski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.04261</idno>
		<ptr target="http://arxiv.org/abs/1706.04261" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b214">
	<monogr>
		<title level="m" type="main">A neural representation of sketch drawings</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eck</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.03477</idno>
		<ptr target="http://arxiv.org/abs/1704.03477" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>cs,stat visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b215">
	<analytic>
		<title level="a" type="main">The THUMOS challenge on action recognition for videos &quot;in the wild</title>
		<author>
			<persName><forename type="first">H</forename><surname>Idrees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-G</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.06182</idno>
		<ptr target="http://arxiv.org/abs/1604.06182" />
	</analytic>
	<monogr>
		<title level="m">/f9rwnr</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">155</biblScope>
			<biblScope unit="page" from="1" to="23" />
		</imprint>
	</monogr>
	<note>cs visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b216">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Ito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Johnson</surname></persName>
		</author>
		<ptr target="https://keithito.com/LJ-Speech-Dataset" />
		<title level="m">The LJ Speech Dataset</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b217">
	<monogr>
		<title level="m" type="main">Learning a neural semantic parser from user feedback</title>
		<author>
			<persName><forename type="first">S</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Konstas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.08760</idno>
		<ptr target="http://arxiv.org/abs/1704.08760" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b218">
	<analytic>
		<title level="a" type="main">Search-based neural structured learning for sequential question answering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>-T. Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<idno>DOI: 10/gf6nx8</idno>
		<ptr target="https://aclanthology.org/P17-1167" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M.-Y</forename><surname>Kan</surname></persName>
		</editor>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1821" to="1831" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b219">
	<monogr>
		<title level="m" type="main">TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.03551</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b220">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1705.03551" />
		<imprint/>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b221">
	<monogr>
		<title level="m" type="main">The kinetics human action video dataset</title>
		<author>
			<persName><forename type="first">W</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.06950</idno>
		<ptr target="http://arxiv.org/abs/1705.06950" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b222">
	<monogr>
		<title level="m" type="main">Polish read speech corpus for speech tools and services</title>
		<author>
			<persName><forename type="first">D</forename><surname>Korzinek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Marasek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Brocki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wolk</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.00245</idno>
		<ptr target="http://arxiv.org/abs/1706.00245" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b223">
	<monogr>
		<title level="m" type="main">RACE: Large-scale ReAding comprehension dataset from examinations</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.04683</idno>
		<ptr target="http://arxiv.org/abs/1704.04683" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b224">
	<monogr>
		<title level="m" type="main">Deal or no deal? end-to-end learning for negotiation dialogues</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yarats</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.05125</idno>
		<ptr target="http://arxiv.org/abs/1706.05125" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b225">
	<monogr>
		<title level="m" type="main">Free linguistic and speech resources for tibetan</title>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2017</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b226">
	<monogr>
		<ptr target="http://ieeexplore.ieee.org/document/8282130/" />
		<title level="m">Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)</title>
		<meeting><address><addrLine>Kuala Lumpur</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="733" to="736" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b227">
	<monogr>
		<title level="m" type="main">Program induction by rationale generation : Learning to solve and explain algebraic word problems</title>
		<author>
			<persName><forename type="first">W</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.04146</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b228">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1705.04146" />
		<imprint/>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b229">
	<monogr>
		<title level="m" type="main">PKU-MMD: A large scale benchmark for continuous multi-modal human action understanding</title>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.07475</idno>
		<ptr target="http://arxiv.org/abs/1703.07475" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b230">
	<monogr>
		<title level="m" type="main">Neural belief tracker: Data-driven dialogue state tracking</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mrksic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">O</forename><surname>Seaghdha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.03777</idno>
		<ptr target="http://arxiv.org/abs/1606.03777" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b231">
	<monogr>
		<title level="m" type="main">The e2e dataset: New challenges for end-to-end generation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Novikova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Du≈°ek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Rieser</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.09254</idno>
		<ptr target="http://arxiv.org/abs/1706.09254" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b232">
	<monogr>
		<title level="m" type="main">Get to the point: Summarization with pointer-generator networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.04368</idno>
		<ptr target="http://arxiv.org/abs/1704.04368" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b233">
	<monogr>
		<title level="m" type="main">Query-focused video summarization: Dataset, evaluation, and a memory network based approach</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sharghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Laurel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.04960</idno>
		<ptr target="http://arxiv.org/abs/1707.04960" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b234">
	<analytic>
		<title level="a" type="main">A free kazakh speech database and a speech recognition baseline</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hamdullah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Zheng</surname></persName>
		</author>
		<ptr target="http://ieeexplore.ieee.org/document/8282133/" />
	</analytic>
	<monogr>
		<title level="m">2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)</title>
		<meeting><address><addrLine>Kuala Lumpur</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="745" to="748" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b235">
	<monogr>
		<title level="m" type="main">Crowdsourcing multiple choice science questions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.06209</idno>
		<ptr target="http://arxiv.org/abs/1707.06209" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>cs, stat visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b236">
	<monogr>
		<title level="m" type="main">Every moment counts: Dense detailed labeling of actions in complex videos</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1507.05738</idno>
		<ptr target="http://arxiv.org/abs/1507.05738" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b237">
	<monogr>
		<title level="m" type="main">Seq2sql: Generating structured queries from natural language using reinforcement learning</title>
		<author>
			<persName><forename type="first">V</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.00103</idno>
		<ptr target="http://arxiv.org/abs/1709.00103" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b238">
	<monogr>
		<title level="m" type="main">Towards automatic learning of procedures from web instructional videos</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Corso</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.09788</idno>
		<ptr target="https://arxiv.org/abs/1703.09788v3" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b239">
	<monogr>
		<title level="m" type="main">MS MARCO: A human generated MAchine reading COmprehension dataset</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.09268</idno>
		<ptr target="http://arxiv.org/abs/1611.09268" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b240">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Botha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Alex</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Baldridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.09468</idno>
		<ptr target="http://arxiv.org/abs/1808.09468" />
		<title level="m">Learning to split and rephrase from wikipedia edit history</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b241">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Noland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Banki-Horvath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hillier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.01340</idno>
		<ptr target="http://arxiv.org/abs/1808.01340" />
		<title level="m">A short note about kinetics-600</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b242">
	<monogr>
		<title level="m" type="main">Think you have solved question answering? try ARC, the AI2 reasoning challenge</title>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Cowhey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05457</idno>
		<ptr target="http://arxiv.org/abs/1803.05457" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b243">
	<monogr>
		<title level="m" type="main">Snips voice platform: An embedded spoken language understanding system for private-by-design voice interfaces</title>
		<author>
			<persName><forename type="first">A</forename><surname>Coucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ball</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.10190</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b244">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1805.10190" />
		<imprint/>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b245">
	<monogr>
		<title level="m" type="main">Scaling egocentric vision: The EPIC-KITCHENS dataset</title>
		<author>
			<persName><forename type="first">D</forename><surname>Damen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Doughty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Farinella</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.02748</idno>
		<ptr target="http://arxiv.org/abs/1804.02748" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b246">
	<monogr>
		<title level="m" type="main">AISHELL-2: Transforming mandarin ASR research into industrial scale</title>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Na</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.10583</idno>
		<ptr target="http://arxiv.org/abs/1808.10583" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>visited on 05/31/2024</note>
</biblStruct>

<biblStruct xml:id="b247">
	<monogr>
		<title level="m" type="main">Identifying well-formed natural language questions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.09419</idno>
		<ptr target="http://arxiv.org/abs/1808.09419" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b248">
	<monogr>
		<title level="m" type="main">Ru-mourEval 2019: Determining rumour veracity and support for rumours</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gorrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bontcheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kochkina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liakata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zubiaga</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.06683</idno>
		<ptr target="http://arxiv.org/abs/1809.06683" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b249">
	<monogr>
		<title level="m" type="main">AVA: A video dataset of spatio-temporally localized atomic visual actions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Ross</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.08421</idno>
		<ptr target="http://arxiv.org/abs/1705.08421" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b250">
	<analytic>
		<title level="a" type="main">MMQA: A multi-domain multilingual question-answering framework for english and hindi</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ekbal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/L18-1440" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Calzolari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Choukri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Cieri</surname></persName>
		</editor>
		<meeting>the Eleventh International Conference on Language Resources and Evaluation<address><addrLine>Miyazaki, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA)</publisher>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b251">
	<monogr>
		<title level="m" type="main">Semantic parsing for task oriented dialog using hierarchical representations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mohit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.07942</idno>
		<ptr target="http://arxiv.org/abs/1810.07942" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b252">
	<monogr>
		<title level="m" type="main">Decoupling strategy and generation in negotiation dialogues</title>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.09637</idno>
		<ptr target="http://arxiv.org/abs/1808.09637" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b253">
	<analytic>
		<title level="a" type="main">Localizing moments in video with temporal language</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Russell</surname></persName>
		</author>
		<idno>DOI: 10 / gtsqzq</idno>
		<ptr target="https://aclanthology.org/D18-1168" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Riloff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Chiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hockenmaier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</editor>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1380" to="1390" />
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b254">
	<analytic>
		<title level="a" type="main">TED-LIUM 3: Twice as much data and corpus repartition for experiments on speaker adaptation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghannay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tomashenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Est√®ve</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-99579-3_21</idno>
		<idno type="arXiv">arXiv:1805.04699</idno>
		<ptr target="http://arxiv.org/abs/1805.04699" />
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">11096</biblScope>
			<biblScope unit="page" from="198" to="208" />
			<date type="published" when="2018">2018</date>
			<publisher>Springer</publisher>
			<pubPlace>Cham</pubPlace>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b255">
	<analytic>
		<title level="a" type="main">SciTaiL: A textual entailment dataset from science question answering</title>
		<author>
			<persName><forename type="first">T</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<idno>DOI: 10/grm22d</idno>
		<ptr target="https://ojs.aaai.org/index.php/AAAI/article/view/12022" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="2159" to="5399" />
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b256">
	<monogr>
		<title level="m" type="main">Semantic sentence matching with densely-connected recurrent and co-attentive information</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kwak</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.11360</idno>
		<ptr target="http://arxiv.org/abs/1805.11360" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b257">
	<analytic>
		<title level="a" type="main">Crowd-sourced speech corpora for javanese, sundanese, sinhala, nepali, and bangladeshi bengali</title>
		<author>
			<persName><forename type="first">O</forename><surname>Kjartansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sarin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pipatsrisawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jansche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ha</surname></persName>
		</author>
		<idno>DOI: 10/gtwwbs</idno>
		<ptr target="https://www.isca-archive.org/sltu_2018/kjartansson18_sltu.html" />
	</analytic>
	<monogr>
		<title level="m">6th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2018)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="52" to="55" />
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b258">
	<monogr>
		<title level="m" type="main">Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Baroni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.00350</idno>
		<ptr target="http://arxiv.org/abs/1711.00350" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b259">
	<analytic>
		<title level="a" type="main">Event representations for automated story generation with deep neural nets</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ammanabrolu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.01331</idno>
		<ptr target="http://arxiv.org/abs/1706.01331" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="2159" to="5399" />
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b260">
	<monogr>
		<title level="m" type="main">Can a suit of armor conduct electricity? a new dataset for open book question answering</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.02789</idno>
		<ptr target="http://arxiv.org/abs/1809.02789" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b261">
	<monogr>
		<title level="m" type="main">Multi-source social feedback of online news feeds</title>
		<author>
			<persName><forename type="first">N</forename><surname>Moniz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Torgo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.07055</idno>
		<ptr target="http://arxiv.org/abs/1801.07055" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b262">
	<monogr>
		<title level="m" type="main">Fully statistical neural belief tracking</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mrk≈°iƒá</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Vuliƒá</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.11350</idno>
		<ptr target="http://arxiv.org/abs/1805.11350" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b263">
	<monogr>
		<title level="m" type="main">VoxCeleb: A large-scale speaker identification dataset</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nagrani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="DOI">10.21437/Interspeech.2017-950</idno>
		<ptr target="http://arxiv.org/abs/1706.08612" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b264">
	<monogr>
		<title level="m" type="main">Don&apos;t give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.08745</idno>
		<ptr target="http://arxiv.org/abs/1808.08745" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b265">
	<monogr>
		<title level="m" type="main">XGAN: Unsupervised image-to-image translation for many-to-many mappings</title>
		<author>
			<persName><forename type="first">A</forename><surname>Royer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bousmalis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gouws</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05139</idno>
		<ptr target="http://arxiv.org/abs/1711.05139" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b266">
	<monogr>
		<title level="m" type="main">Interpretation of natural language rules in conversational machine reading</title>
		<author>
			<persName><forename type="first">M</forename><surname>Saeidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bartolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.01494</idno>
		<ptr target="http://arxiv.org/abs/1809.01494" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>cs,stat visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b267">
	<monogr>
		<title level="m" type="main">DuoRC: Towards complex language understanding with paraphrased reading comprehension</title>
		<author>
			<persName><forename type="first">A</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Aralikatte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.07927</idno>
		<ptr target="http://arxiv.org/abs/1804.07927" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b268">
	<monogr>
		<title level="m" type="main">How2: A large-scale dataset for multimodal language understanding</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sanabria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Caglayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Palaskar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.00347</idno>
		<ptr target="http://arxiv.org/abs/1811.00347" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b269">
	<monogr>
		<title level="m" type="main">Building a conversational agent overnight with dialogue self-play</title>
		<author>
			<persName><forename type="first">P</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hakkani-T√ºr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>T√ºr</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.04871</idno>
		<ptr target="http://arxiv.org/abs/1801.04871" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b270">
	<analytic>
		<title level="a" type="main">Unsupervised abstractive meeting summarization with multi-sentence compression and budgeted submodular maximization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<idno>DOI: 10 / gm8jvb</idno>
		<ptr target="https://aclanthology.org/P18-1062" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Miyao</surname></persName>
		</editor>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="664" to="674" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b271">
	<monogr>
		<title level="m" type="main">Actor and observer: Joint modeling of first and third-person videos</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Sigurdsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Alahari</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.09627</idno>
		<ptr target="http://arxiv.org/abs/1804.09627" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b272">
	<monogr>
		<title level="m" type="main">QuaRel: A dataset and models for answering questions about qualitative relationships</title>
		<author>
			<persName><forename type="first">O</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>-T. Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.08048</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b273">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1811.08048" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b274">
	<analytic>
		<title level="a" type="main">The web as a knowledge-base for answering complex questions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<idno>DOI: 10 / gkz2k6</idno>
		<ptr target="https://aclanthology.org/N18-1059" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Walker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Ji</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Stent</surname></persName>
		</editor>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="641" to="651" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b275">
	<monogr>
		<title level="m" type="main">FEVER: A large-scale dataset for fact extraction and VERification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05355</idno>
		<ptr target="http://arxiv.org/abs/1803.05355" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b276">
	<monogr>
		<title level="m" type="main">MovieGraphs: Towards understanding human-centric situations from videos</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vicol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tapaswi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Castrejon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.06761</idno>
		<ptr target="http://arxiv.org/abs/1712.06761" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b277">
	<analytic>
		<title level="a" type="main">AirDialogue: An environment for goal-oriented dialogue research</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<idno>DOI: 10/gf6gq2</idno>
		<ptr target="https://aclanthology.org/D18-1419" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Riloff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Chiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hockenmaier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</editor>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3844" to="3854" />
		</imprint>
	</monogr>
	<note>: Association for Computational Linguistics visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b278">
	<monogr>
		<title level="m" type="main">Constructing datasets for multi-hop reading comprehension across documents</title>
		<author>
			<persName><forename type="first">J</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.06481</idno>
		<ptr target="http://arxiv.org/abs/1710.06481" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b279">
	<monogr>
		<title level="m" type="main">MoleculeNet: A benchmark for molecular machine learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ramsundar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">N</forename><surname>Feinberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.00564</idno>
		<ptr target="http://arxiv.org/abs/1703.00564" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>physics, stat visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b280">
	<monogr>
		<title level="m" type="main">HotpotQA: A dataset for diverse, explainable multi-hop question answering</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.09600</idno>
		<ptr target="http://arxiv.org/abs/1809.09600" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b281">
	<monogr>
		<title level="m" type="main">MathQA: Towards interpretable math word problem solving with operation-based formalisms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Koncel-Kedziorski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.13319</idno>
		<ptr target="http://arxiv.org/abs/1905.13319" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b282">
	<monogr>
		<title level="m" type="main">Constrained decoding for neural NLG from compositional representations in task-oriented dialogue</title>
		<author>
			<persName><forename type="first">A</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Upasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Subba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.07220</idno>
		<ptr target="http://arxiv.org/abs/1906.07220" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b283">
	<analytic>
		<title level="a" type="main">The spoken wikipedia corpus collection: Harvesting, alignment and an application to hyperlistening</title>
		<author>
			<persName><forename type="first">T</forename><surname>Baumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>K√∂hn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hennig</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10579-017-9410-y</idno>
		<idno>DOI: 10/gq5xdf</idno>
		<ptr target="https://doi.org/10.1007/s10579-017-9410-y" />
	</analytic>
	<monogr>
		<title level="j">Language Resources and Evaluation</title>
		<idno type="ISSN">1574-0218</idno>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="303" to="329" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b284">
	<monogr>
		<title level="m" type="main">PIQA: Reasoning about physical commonsense in natural language</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.11641</idno>
		<ptr target="http://arxiv.org/abs/1911.11641" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b285">
	<monogr>
		<title level="m" type="main">Taskmaster-1: Toward a realistic and diverse dialog dataset</title>
		<author>
			<persName><forename type="first">B</forename><surname>Byrne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Krishnamoorthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sankar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.05358</idno>
		<ptr target="http://arxiv.org/abs/1909.05358" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b286">
	<monogr>
		<title level="m" type="main">Named entity disambiguation using deep learning on graphs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cetoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Akbari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bragaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>O'harney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sloan</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-15719-7_10</idno>
		<idno type="arXiv">arXiv:1810.09164</idno>
		<ptr target="http://arxiv.org/abs/1810.09164" />
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11438</biblScope>
			<biblScope unit="page" from="78" to="86" />
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b287">
	<monogr>
		<title level="m" type="main">Neural legal judgment prediction in english</title>
		<author>
			<persName><forename type="first">I</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Aletras</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.02059</idno>
		<ptr target="http://arxiv.org/abs/1906.02059" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b288">
	<monogr>
		<title level="m" type="main">Large-scale multi-label text classification on EU legislation</title>
		<author>
			<persName><forename type="first">I</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fergadiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Malakasiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.02192</idno>
		<ptr target="http://arxiv.org/abs/1906.02192" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b289">
	<monogr>
		<title level="m" type="main">Semantically conditioned dialog response generation via hierarchical disentangled self-attention</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.12866</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b290">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1905.12866" />
		<imprint/>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b291">
	<analytic>
		<title level="a" type="main">Look before you hop: Conversational question answering over knowledge graphs using judicious context expansion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Christmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abujabal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.03262</idno>
		<ptr target="http://arxiv.org/abs/1910.03262" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 28th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="729" to="738" />
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b292">
	<monogr>
		<title level="m" type="main">Exploring the surprising difficulty of natural yes/no questions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><surname>Boolq</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.10044</idno>
		<ptr target="http://arxiv.org/abs/1905.10044" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b293">
	<analytic>
		<title level="a" type="main">A corpus of regional american language from YouTube</title>
		<author>
			<persName><forename type="first">S</forename><surname>Coats</surname></persName>
		</author>
		<ptr target="https://www.semanticscholar.org/paper" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Digital Humanities in the Nordic Countries 5th Conference</title>
		<meeting>the Digital Humanities in the Nordic Countries 5th Conference</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">A -Corpus -of -Regional -American -Language -from -YouTube -Coats</note>
	<note>Online bc428db824d261794a7e081a53c4315b8e02f855 (visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b294">
	<analytic>
		<title level="a" type="main">Toyota smarthome: Real-world activities of daily living</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Koperski</surname></persName>
		</author>
		<ptr target="https://ieeexplore.ieee.org/document/9008135/" />
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting><address><addrLine>Seoul, Korea (South</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="833" to="842" />
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b295">
	<monogr>
		<title level="m" type="main">Quoref: A reading comprehension dataset with questions requiring coreferential reasoning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marasoviƒá</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.05803</idno>
		<ptr target="http://arxiv.org/abs/1908.05803" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b296">
	<analytic>
		<title level="a" type="main">MuST-c: A multilingual speech translation corpus</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Di Gangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cattoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Turchi</surname></persName>
		</author>
		<idno>DOI: 10/ gtsqzk</idno>
		<ptr target="https://aclanthology.org/N19-1202" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Burstein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Doran</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Solorio</surname></persName>
		</editor>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2012" to="2017" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b297">
	<monogr>
		<title level="m" type="main">The second conversational intelligence challenge (ConvAI2)</title>
		<author>
			<persName><forename type="first">E</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Logacheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Malykh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.00098</idno>
		<ptr target="http://arxiv.org/abs/1902.00098" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b298">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.01241</idno>
		<ptr target="http://arxiv.org/abs/1811.01241" />
		<title level="m">Wizard of wikipedia: Knowledge-powered conversational agents</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b299">
	<analytic>
		<title level="a" type="main">SANAD: Single-label arabic news articles dataset for automatic text categorization</title>
		<author>
			<persName><forename type="first">O</forename><surname>Einea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elnagar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Al</forename><surname>Debsi</surname></persName>
		</author>
		<ptr target="https://linkinghub.elsevier.com/retrieve/pii/S2352340919304305" />
	</analytic>
	<monogr>
		<title level="j">Data in Brief</title>
		<idno type="ISSN">23523409</idno>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page">76</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b300">
	<monogr>
		<title level="m" type="main">MultiWOZ 2.1: A consolidated multi-domain dialogue dataset with state corrections and state tracking baselines</title>
		<author>
			<persName><forename type="first">M</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Paul</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.01669</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b301">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1907.01669" />
		<imprint/>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b302">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Fabbri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>She</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.01749</idno>
		<title level="m">Multi-news: A large-scale multi-document summarization dataset and abstractive hierarchical model</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b303">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1906.01749" />
		<imprint/>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b304">
	<analytic>
		<title level="a" type="main">KPTimes: A large-scale dataset for keyphrase generation on news documents</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gallina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Boudin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Daille</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/W19-8617" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Natural Language Generation</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Van Deemter</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Takamura</surname></persName>
		</editor>
		<meeting>the 12th International Conference on Natural Language Generation<address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">64</biblScope>
		</imprint>
	</monogr>
	<note>: Association for Computational Linguistics visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b305">
	<analytic>
		<title level="a" type="main">Predi√ß√£o da complexidade textual de recursos educacionais abertos em portugu√™s</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Gazzola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Leal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Alu√≠sio</surname></persName>
		</author>
		<ptr target="https://repositorio.usp.br/item/002971271" />
	</analytic>
	<monogr>
		<title level="m">Symposium in Information and Human Language Technology -STIL</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b306">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mamidi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.10704</idno>
		<ptr target="http://arxiv.org/abs/1911.10704" />
		<title level="m">Conversational implicatures in english dialogue: Annotated dataset</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b307">
	<monogr>
		<title level="m" type="main">DiscoFuse: A large-scale dataset for discoursebased sentence fusion</title>
		<author>
			<persName><forename type="first">M</forename><surname>Geva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Malmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Szpektor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.10526</idno>
		<ptr target="http://arxiv.org/abs/1902.10526" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b308">
	<analytic>
		<title level="a" type="main">SAMSum corpus: A human-annotated dialogue dataset for abstractive summarization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Gliwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mochol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Biesek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wawer</surname></persName>
		</author>
		<idno>DOI: 10/ gmjqgr</idno>
		<ptr target="https://aclanthology.org/D19-5409" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on New Frontiers in</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Summarization</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">C K</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Cheung</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Carenini</surname></persName>
		</editor>
		<editor>
			<persName><surname>Liu</surname></persName>
		</editor>
		<meeting>the 2nd Workshop on New Frontiers in<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="70" to="79" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b309">
	<monogr>
		<title level="m" type="main">Cosmos QA: Machine reading comprehension with contextual commonsense reasoning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.00277</idno>
		<ptr target="http://arxiv.org/abs/1909.00277" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b310">
	<monogr>
		<title level="m" type="main">PubMedQA: A dataset for biomedical research question answering</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.06146</idno>
		<ptr target="http://arxiv.org/abs/1909.06146" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs,q-bio visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b311">
	<monogr>
		<title level="m" type="main">ViGGO: A video game corpus for data-to-text generation in open-domain conversation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Juraska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Bowden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Walker</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.12129</idno>
		<ptr target="http://arxiv.org/abs/1910.12129" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b312">
	<analytic>
		<title level="a" type="main">MMAct: A large-scale dataset for cross modal human action understanding</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Klinkigt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Murakami</surname></persName>
		</author>
		<idno>DOI: 10/ghfhxx</idno>
		<ptr target="https://ieeexplore.ieee.org/document/9009579" />
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="8657" to="8666" />
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b313">
	<analytic>
		<title level="a" type="main">BillSum: A corpus for automatic summarization of US legislation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kornilova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Eidelman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.00523</idno>
		<ptr target="http://arxiv.org/abs/1910.00523" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on New Frontiers in Summarization</title>
		<meeting>the 2nd Workshop on New Frontiers in Summarization</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="48" to="56" />
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b314">
	<analytic>
		<title level="a" type="main">An evaluation dataset for intent classification and out-of-scope prediction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mahendran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Peper</surname></persName>
		</author>
		<idno>DOI: 10/ gqrfvv</idno>
		<ptr target="https://aclanthology.org/D19-1131" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Inui</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Ng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Wan</surname></persName>
		</editor>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1311" to="1316" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b315">
	<monogr>
		<title level="m" type="main">Neural code search evaluation dataset</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chandra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.09804</idno>
		<ptr target="http://arxiv.org/abs/1908.09804" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b316">
	<monogr>
		<title level="m" type="main">End-to-end trainable non-collaborative dialog system</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.10742</idno>
		<ptr target="http://arxiv.org/abs/1911.10742" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b317">
	<monogr>
		<title level="m" type="main">Reasoning over paragraph effects in situations</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.05852</idno>
		<ptr target="http://arxiv.org/abs/1908.05852" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b318">
	<monogr>
		<title level="m" type="main">Benchmarking natural language understanding services for building conversational agents</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Eshghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Swietojanski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Rieser</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.05566</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b319">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1903.05566" />
		<imprint/>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b320">
	<analytic>
		<title level="a" type="main">The jester dataset: A large-scale video dataset of human gestures</title>
		<author>
			<persName><forename type="first">J</forename><surname>Materzynska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Bax</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Memisevic</surname></persName>
		</author>
		<idno>DOI: 10/gh5k47</idno>
		<ptr target="https://ieeexplore.ieee.org/document/9022297/" />
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)</title>
		<meeting><address><addrLine>Seoul, Korea (South</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2874" to="2882" />
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b321">
	<monogr>
		<title level="m" type="main">HowTo100m: Learning a text-video embedding by watching hundred million narrated video clips</title>
		<author>
			<persName><forename type="first">A</forename><surname>Miech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhukov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Alayrac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tapaswi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.03327</idno>
		<ptr target="http://arxiv.org/abs/1906.03327" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b322">
	<monogr>
		<title level="m" type="main">Moments in time dataset: One million videos for event understanding</title>
		<author>
			<persName><forename type="first">M</forename><surname>Monfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Andonian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.03150</idno>
		<ptr target="http://arxiv.org/abs/1801.03150" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b323">
	<analytic>
		<title level="a" type="main">OpenDialKG: Explainable conversational reasoning with attention-based walks over knowledge graphs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Subba</surname></persName>
		</author>
		<idno>DOI: 10/ggt4wm</idno>
		<ptr target="https://aclanthology.org/P19-1081" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Korhonen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Traum</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>M√†rquez</surname></persName>
		</editor>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="845" to="854" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b324">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Mozannar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hajal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Maamary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hajj</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.05394</idno>
		<ptr target="http://arxiv.org/abs/1906.05394" />
		<title level="m">Neural arabic question answering</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b325">
	<monogr>
		<title level="m" type="main">Generating summaries with topic templates and structured convolutional decoders</title>
		<author>
			<persName><forename type="first">L</forename><surname>Perez-Beltrachini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.04687</idno>
		<ptr target="http://arxiv.org/abs/1906.04687" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b326">
	<analytic>
		<title level="a" type="main">Multi-domain goal-oriented dialogues (MultiDoGO): Strategies toward curating and annotating large scale dialogue data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Peskov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Krone</surname></persName>
		</author>
		<idno>DOI: 10 / gkr9hj</idno>
		<ptr target="https://aclanthology.org/D19-1460" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Inui</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Ng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Wan</surname></persName>
		</editor>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4526" to="4536" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b327">
	<monogr>
		<title level="m" type="main">Language models as knowledge bases?</title>
		<author>
			<persName><forename type="first">F</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rockt√§schel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.01066</idno>
		<ptr target="http://arxiv.org/abs/1909.01066" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b328">
	<analytic>
		<title level="a" type="main">GECOR: An end-to-end generative ellipsis and coreference resolution model for task-oriented dialogue</title>
		<author>
			<persName><forename type="first">J</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Webber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hu</surname></persName>
		</author>
		<idno>DOI: 10/gk3btq</idno>
		<ptr target="https://aclanthology.org/D19-1462" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Inui</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Ng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Wan</surname></persName>
		</editor>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4547" to="4557" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b329">
	<monogr>
		<title level="m" type="main">Explain yourself! leveraging language models for commonsense reasoning</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">F</forename><surname>Rajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.02361</idno>
		<ptr target="http://arxiv.org/abs/1906.02361" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b330">
	<monogr>
		<title level="m" type="main">Towards empathetic open-domain conversation models: A new benchmark and dataset</title>
		<author>
			<persName><forename type="first">H</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-L</forename><surname>Boureau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.00207</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b331">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1811.00207" />
		<imprint/>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b332">
	<monogr>
		<title level="m" type="main">CoQA: A conversational question answering challenge</title>
		<author>
			<persName><forename type="first">S</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.07042</idno>
		<ptr target="http://arxiv.org/abs/1808.07042" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b333">
	<monogr>
		<title level="m" type="main">AVA-ActiveSpeaker: An audio-visual dataset for active speaker detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Klejch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.01342</idno>
		<ptr target="http://arxiv.org/abs/1901.01342" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs, eess visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b334">
	<monogr>
		<title level="m" type="main">WinoGrande: An adversarial winograd schema challenge at scale</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.10641</idno>
		<ptr target="http://arxiv.org/abs/1907.10641" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b335">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lebras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.09728</idno>
		<ptr target="http://arxiv.org/abs/1904.09728" />
		<title level="m">SocialIQA: Commonsense reasoning about social interactions</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b336">
	<monogr>
		<title level="m" type="main">Few-shot dialogue generation without annotated data: A transfer learning approach</title>
		<author>
			<persName><forename type="first">I</forename><surname>Shalyminov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Eshghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Lemon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.05854</idno>
		<ptr target="http://arxiv.org/abs/1908.05854" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b337">
	<monogr>
		<title level="m" type="main">BIGPATENT: A large-scale dataset for abstractive and coherent summarization</title>
		<author>
			<persName><forename type="first">E</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.03741</idno>
		<ptr target="http://arxiv.org/abs/1906.03741" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b338">
	<monogr>
		<title level="m" type="main">QuaRTz: An open-domain dataset of qualitative relationship questions</title>
		<author>
			<persName><forename type="first">O</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.03553</idno>
		<ptr target="http://arxiv.org/abs/1909.03553" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b339">
	<monogr>
		<title level="m" type="main">CommonsenseQA: A question answering challenge targeting commonsense knowledge</title>
		<author>
			<persName><forename type="first">A</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.00937</idno>
		<ptr target="http://arxiv.org/abs/1811.00937" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b340">
	<monogr>
		<title level="m" type="main">reasoning over procedural text</title>
		<author>
			<persName><forename type="first">N</forename><surname>Tandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.04739</idno>
		<ptr target="http://arxiv.org/abs/1909.04739" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>WIQA: A dataset for &quot;what if visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b341">
	<monogr>
		<title level="m" type="main">COIN: A large-scale dataset for comprehensive instructional video analysis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.02874</idno>
		<ptr target="http://arxiv.org/abs/1903.02874" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b342">
	<monogr>
		<title level="m" type="main">GLUE: A multitask benchmark and analysis platform for natural language understanding</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.07461</idno>
		<ptr target="http://arxiv.org/abs/1804.07461" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b343">
	<monogr>
		<title level="m" type="main">TWEETQA: A social media focused question answering dataset</title>
		<author>
			<persName><forename type="first">W</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.06292</idno>
		<ptr target="http://arxiv.org/abs/1907.06292" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b344">
	<monogr>
		<title level="m" type="main">A graph-based framework to bridge movies and synopses</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.11009</idno>
		<ptr target="http://arxiv.org/abs/1910.11009" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b345">
	<monogr>
		<title level="m" type="main">CoSQL: A conversational text-to-SQL challenge towards cross-domain natural language interfaces to databases</title>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Er</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.05378</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b346">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1909.05378" />
		<imprint/>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b347">
	<monogr>
		<title level="m" type="main">Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-SQL task</title>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.08887</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b348">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1809.08887" />
		<imprint/>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b349">
	<analytic>
		<title level="a" type="main">SParC: Cross-domain semantic parsing in context</title>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<idno>DOI: 10 / gj4fwd</idno>
		<ptr target="https://aclanthology.org/P19-1443" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Korhonen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Traum</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>M√†rquez</surname></persName>
		</editor>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4511" to="4523" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b350">
	<monogr>
		<title level="m" type="main">HellaSwag: Can a machine really finish your sentence?</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.07830</idno>
		<ptr target="http://arxiv.org/abs/1905.07830" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b351">
	<monogr>
		<title level="m" type="main">PAWS: Paraphrase adversaries from word scrambling</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Baldridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.01130</idno>
		<ptr target="http://arxiv.org/abs/1904.01130" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b352">
	<monogr>
		<title level="m" type="main">HACS: Human action clips and segments dataset for recognition and temporal localization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Torresani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.09374</idno>
		<ptr target="http://arxiv.org/abs/1712.09374" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Online visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b353">
	<monogr>
		<title level="m" type="main">Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Siow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.03496</idno>
		<ptr target="http://arxiv.org/abs/1909.03496" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs,stat visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b354">
	<monogr>
		<title level="m" type="main">Cross-task weakly supervised learning from instructional videos</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhukov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Alayrac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Cinbis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fouhey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.08225</idno>
		<ptr target="http://arxiv.org/abs/1903.08225" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b355">
	<analytic>
		<title level="a" type="main">Doc2vec: An approach to identify hadith similarities</title>
		<author>
			<persName><forename type="first">A</forename><surname>Abdelghany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Abdelaal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kamr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Elkafrawy</surname></persName>
		</author>
		<idno type="DOI">10.22587/ajbas.2020.14.12.5</idno>
	</analytic>
	<monogr>
		<title level="j">Australian Journal of Basic and Applied Sciences</title>
		<imprint>
			<biblScope unit="page" from="46" to="53" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b356">
	<analytic>
		<title level="a" type="main">Exploration of end-to-end ASR for OpenSTT -russian open speech-to-text dataset</title>
		<author>
			<persName><forename type="first">A</forename><surname>Andrusenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Medennikov</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-60276-5_4</idno>
		<idno type="arXiv">arXiv:2006.08274</idno>
		<ptr target="http://arxiv.org/abs/2006.08274" />
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">12335</biblScope>
			<biblScope unit="page" from="35" to="44" />
			<date type="published" when="2020">2020</date>
			<publisher>Springer</publisher>
			<pubPlace>Cham</pubPlace>
		</imprint>
	</monogr>
	<note>cs, eess visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b357">
	<monogr>
		<title level="m" type="main">Living machines: A study of atypical animacy</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Ardanuy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Nanni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Beelen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.11140</idno>
		<ptr target="http://arxiv.org/abs/2005.11140" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b358">
	<monogr>
		<title level="m" type="main">Common voice: A massively-multilingual speech corpus</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ardila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Davis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.06670</idno>
		<ptr target="http://arxiv.org/abs/1912.06670" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b359">
	<monogr>
		<title level="m" type="main">TRECVID 2019: An evaluation campaign to benchmark video activity detection, video captioning and matching, and video search &amp; retrieval</title>
		<author>
			<persName><forename type="first">G</forename><surname>Awad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Butt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Curtis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.09984</idno>
		<ptr target="http://arxiv.org/abs/2009.09984" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b360">
	<monogr>
		<title level="m" type="main">Condensed movies: Story based retrieval with contextual embeddings</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nagrani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.04208</idno>
		<ptr target="http://arxiv.org/abs/2005.04208" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b361">
	<analytic>
		<title level="a" type="main">KsponSpeech: Korean spontaneous speech corpus for automatic speech recognition</title>
		<author>
			<persName><forename type="first">J.-U</forename><surname>Bang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-H</forename><surname>Kim</surname></persName>
		</author>
		<idno>DOI: 10/ gtwwck</idno>
		<ptr target="https://www.mdpi.com/2076-3417/10/19/6936" />
	</analytic>
	<monogr>
		<title level="m">Number: 19 Publisher: Multidisciplinary Digital Publishing Institute</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">6936</biblScope>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b362">
	<analytic>
		<title level="a" type="main">Beat the AI: Investigating adversarial human annotation for reading comprehension</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bartolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stenetorp</surname></persName>
		</author>
		<idno type="arXiv">ISSN:2307-387X.DOI:10/gjzgwj.arXiv:2002.00293</idno>
		<ptr target="http://arxiv.org/abs/2002.00293" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="662" to="678" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b363">
	<analytic>
		<title level="a" type="main">Arabic reading comprehension benchmarks created semiautomatically</title>
		<author>
			<persName><forename type="first">M</forename><surname>Biltawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Awajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tedmori</surname></persName>
		</author>
		<ptr target="https://ieeexplore.ieee.org/document/9300111/" />
	</analytic>
	<monogr>
		<title level="m">2020 21st International Arab Conference on Information Technology (ACIT)</title>
		<meeting><address><addrLine>Giza, Egypt</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b364">
	<monogr>
		<title level="m" type="main">MaSS: A large and clean multilingual corpus of sentence-aligned spoken utterances extracted from the bible</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Z</forename><surname>Boito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">N</forename><surname>Havard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Garnerin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Ferrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Besacier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.12895</idno>
		<ptr target="http://arxiv.org/abs/1907.12895" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b365">
	<monogr>
		<title level="m" type="main">ProtoQA: A question answering dataset for prototypical common-sense reasoning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Boratko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>O'gorman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00771</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b366">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2005.00771" />
		<imprint/>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b367">
	<monogr>
		<title level="m" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.14165</idno>
		<ptr target="http://arxiv.org/abs/2005.14165" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b368">
	<analytic>
		<title level="a" type="main">Efficient intent detection with dual sentence encoders</title>
		<author>
			<persName><forename type="first">I</forename><surname>Casanueva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Temƒçinas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gerz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Vuliƒá</surname></persName>
		</author>
		<idno type="arXiv">DOI:10/gjhzzs.arXiv:2003.04807</idno>
		<ptr target="https://aclanthology.org/2020" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI</title>
		<editor>
			<persName><forename type="first">T.-H</forename><surname>Wen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Celikyilmaz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</editor>
		<meeting>the 2nd Workshop on Natural Language Processing for Conversational AI</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
	<note>cs nlp4convai-1.5 (visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b369">
	<monogr>
		<title level="m" type="main">Finding friends and flipping frenemies: Automatic paraphrase dataset augmentation using graph theory</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Evans</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.01856</idno>
		<ptr target="http://arxiv.org/abs/2011.01856" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b370">
	<analytic>
		<title level="a" type="main">HybridQA: A dataset of multi-hop question answering over tabular and textual data</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno>DOI: 10/gpmd4x</idno>
		<ptr target="https://aclanthology.org/2020.findings-emnlp.91" />
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Cohn</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</editor>
		<editor>
			<persName><surname>Liu</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1026" to="1036" />
		</imprint>
	</monogr>
	<note>Online: Association for Computational Linguistics visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b371">
	<monogr>
		<title level="m" type="main">Span-ConveRT: Few-shot span extraction for dialog with pretrained conversational representations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Coope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Farghly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gerz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Vuliƒá</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Henderson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.08866</idno>
		<ptr target="http://arxiv.org/abs/2005.08866" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b372">
	<monogr>
		<title level="m" type="main">TinyVIRAT: Low-resolution video action recognition</title>
		<author>
			<persName><forename type="first">U</forename><surname>Demir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Rawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.07355</idno>
		<ptr target="http://arxiv.org/abs/2007.07355" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs, eess visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b373">
	<analytic>
		<title level="a" type="main">Open-source multi-speaker corpora of the english accents in the british isles</title>
		<author>
			<persName><forename type="first">I</forename><surname>Demirsahin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kjartansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gutkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rivera</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2020.lrec-1.804" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth Language Resources and Evaluation Conference</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Calzolari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>B√©chet</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Blache</surname></persName>
		</editor>
		<meeting>the Twelfth Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6532" to="6541" />
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b374">
	<monogr>
		<title level="m" type="main">Large scale holistic video understanding</title>
		<author>
			<persName><forename type="first">A</forename><surname>Diba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fayyaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sharma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.11451</idno>
		<ptr target="http://arxiv.org/abs/1904.11451" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b375">
	<monogr>
		<title level="m" type="main">Omni-sourced webly-supervised learning for video recognition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.13042</idno>
		<ptr target="http://arxiv.org/abs/2003.13042" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b376">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Emelin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.15738</idno>
		<title level="m">Moral stories: Situated reasoning about norms, intents, actions, and their consequences</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b377">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2012.15738" />
		<imprint/>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b378">
	<analytic>
		<title level="a" type="main">Oops! predicting unintentional action in video</title>
		<author>
			<persName><forename type="first">D</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vondrick</surname></persName>
		</author>
		<ptr target="https://ieeexplore.ieee.org/document/9156404/" />
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting><address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="916" to="926" />
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b379">
	<analytic>
		<title level="a" type="main">MAGPIE: A large corpus of potentially idiomatic expressions</title>
		<author>
			<persName><forename type="first">H</forename><surname>Haagsma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nissim</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2020.lrec-1.35" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth Language Resources and Evaluation Conference</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Calzolari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>B√©chet</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Blache</surname></persName>
		</editor>
		<meeting>the Twelfth Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="279" to="287" />
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b380">
	<monogr>
		<title level="m" type="main">XTREME: A massively multilingual multi-task benchmark for evaluating cross-lingual generalization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.11080</idno>
		<ptr target="http://arxiv.org/abs/2003.11080" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b381">
	<monogr>
		<title level="m" type="main">MovieNet: A holistic dataset for movie understanding</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.10937</idno>
		<ptr target="http://arxiv.org/abs/2007.10937" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b382">
	<analytic>
		<title level="a" type="main">ZINC20-a free ultralarge-scale chemical database for ligand discovery</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Irwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Young</surname></persName>
		</author>
		<idno type="DOI">10.1021/acs.jcim.0c00675</idno>
		<idno>DOI: 10/ gmjg8b</idno>
		<ptr target="https://doi.org/10.1021/acs.jcim.0c00675" />
	</analytic>
	<monogr>
		<title level="j">Journal of Chemical Information and Modeling</title>
		<idno type="ISSN">1549-9596</idno>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="6065" to="6073" />
			<date type="published" when="2020">2020</date>
			<publisher>American Chemical Society</publisher>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b383">
	<monogr>
		<title level="m" type="main">LEMMA: A multi-view dataset for learning multi-agent multi-task activities</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-C</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.15781</idno>
		<ptr target="http://arxiv.org/abs/2007.15781" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b384">
	<monogr>
		<title level="m" type="main">HoVer: A dataset for many-hop fact extraction and claim verification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bordia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dognin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.03088</idno>
		<ptr target="http://arxiv.org/abs/2011.03088" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b385">
	<monogr>
		<title level="m" type="main">What disease does this patient have? a large-scale open domain question answering dataset from medical exams</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Oufattole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.13081</idno>
		<ptr target="http://arxiv.org/abs/2009.13081" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b386">
	<monogr>
		<title level="m" type="main">Learning and evaluating contextual embedding of source code</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Maniatis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.00059</idno>
		<ptr target="http://arxiv.org/abs/2001.00059" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b387">
	<monogr>
		<title level="m" type="main">Learning the difference that makes a difference with counterfactually-augmented data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.12434</idno>
		<ptr target="http://arxiv.org/abs/1909.12434" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs,stat visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b388">
	<monogr>
		<title level="m" type="main">QASC: A dataset for question answering via sentence composition</title>
		<author>
			<persName><forename type="first">T</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guerquin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.11473</idno>
		<ptr target="http://arxiv.org/abs/1910.11473" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b389">
	<monogr>
		<title level="m" type="main">FT speech: Danish parliament speech corpus</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kirkedal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stepanoviƒá</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Plank</surname></persName>
		</author>
		<idno type="DOI">10.21437/Interspeech.2020-3164</idno>
		<idno type="arXiv">arXiv:2005.12368</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs , eess</note>
</biblStruct>

<biblStruct xml:id="b390">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2005.12368" />
		<imprint/>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b391">
	<analytic>
		<title level="a" type="main">Open-source high quality speech datasets for basque, catalan and galician</title>
		<author>
			<persName><forename type="first">O</forename><surname>Kjartansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gutkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Butryna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Demirsahin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rivera</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2020.sltu-1.3" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Beermann</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Besacier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Sakti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Soria</surname></persName>
		</editor>
		<meeting>the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="21" to="27" />
		</imprint>
	</monogr>
	<note>European Language Resources association visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b392">
	<analytic>
		<title level="a" type="main">Large corpus of czech parliament plenary hearings</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kratochvil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pol√°k</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bojar</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2020.lrec-1.781" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth Language Resources and Evaluation Conference</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Calzolari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>B√©chet</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Blache</surname></persName>
		</editor>
		<meeting>the Twelfth Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6363" to="6367" />
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b393">
	<analytic>
		<title level="a" type="main">Chia, a large annotated corpus of clinical trial eligibility criteria</title>
		<author>
			<persName><forename type="first">F</forename><surname>Kury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yuan</surname></persName>
		</author>
		<idno>41597-020-00620-0</idno>
		<ptr target="https://www.nature.com/articles/s" />
	</analytic>
	<monogr>
		<title level="j">Scientific Data</title>
		<idno type="ISSN">2052-4463</idno>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">281</biblScope>
			<date type="published" when="2020">2020</date>
			<publisher>Nature Publishing Group</publisher>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b394">
	<monogr>
		<title level="m" type="main">Birds have four legs?! NumerSense: Probing numerical commonsense knowledge of pre-trained language models</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Khanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00683</idno>
		<ptr target="http://arxiv.org/abs/2005.00683" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b395">
	<monogr>
		<title level="m" type="main">CommonGen: A constrained text generation challenge for generative commonsense reasoning</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.03705</idno>
		<ptr target="http://arxiv.org/abs/1911.03705" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b396">
	<monogr>
		<title level="m" type="main">VIOLIN: A large-scale dataset for video-and-language inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.11618</idno>
		<ptr target="http://arxiv.org/abs/2003.11618" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b397">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Radlinski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.03450</idno>
		<ptr target="http://arxiv.org/abs/2010.03450" />
		<title level="m">i&apos;d rather just go to bed&quot;: Understanding indirect answers</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b398">
	<analytic>
		<title level="a" type="main">TITAN: Future forecast using action priors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Malla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dariush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Choi</surname></persName>
		</author>
		<ptr target="https://ieeexplore.ieee.org/document/9156550/" />
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting><address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">193</biblScope>
			<biblScope unit="page" from="978" to="979" />
		</imprint>
	</monogr>
	<note>10/gg99rg Online visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b399">
	<analytic>
		<title level="a" type="main">MuDoCo: Corpus for multidomain coreference resolution and referring expression generation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Poddar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Upasani</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2020.lrec-1.13" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth Language Resources and Evaluation Conference</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Calzolari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>B√©chet</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Blache</surname></persName>
		</editor>
		<meeting>the Twelfth Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="104" to="111" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b400">
	<monogr>
		<title level="m" type="main">RareAct: A video dataset of unusual interactions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Miech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Alayrac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.01018</idno>
		<ptr target="http://arxiv.org/abs/2008.01018" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b401">
	<analytic>
		<title level="a" type="main">Samr√≥mur: Crowd-sourcing data collection for icelandic speech recognition</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Mollberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">H</forename><surname>Jonsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thorsteinsdottir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Steingremsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Magnusdottir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gudnason</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2020.lrec-1.425" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth Language Resources and Evaluation Conference</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Calzolari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Bechet</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Blache</surname></persName>
		</editor>
		<meeting>the Twelfth Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3463" to="3467" />
		</imprint>
	</monogr>
	<note>European Language Resources Association visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b402">
	<monogr>
		<title level="m" type="main">STAR: A schema-guided dialog dataset for transfer learning</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E M</forename><surname>Mosig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kober</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11853</idno>
		<ptr target="http://arxiv.org/abs/2010.11853" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b403">
	<monogr>
		<title level="m" type="main">GLUCOSE: GeneraLized and COntextualized story explanations</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kalyanpur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Moon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.07758</idno>
		<ptr target="http://arxiv.org/abs/2009.07758" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b404">
	<analytic>
		<title level="a" type="main">Conversational scaffolding: An analogy-based approach to response prioritization in open-domain dialogs</title>
		<author>
			<persName><forename type="first">W</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Etchart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Fulda</surname></persName>
		</author>
		<idno type="DOI">http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0008939900690078</idno>
		<ptr target="http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0008939900690078" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Agents and Artificial Intelligence</title>
		<meeting>the 12th International Conference on Agents and Artificial Intelligence<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<publisher>SCITEPRESS -Science and Technology Publications</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="69" to="78" />
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b405">
	<monogr>
		<title level="m" type="main">Adversarial NLI: A new benchmark for natural language understanding</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.14599</idno>
		<ptr target="http://arxiv.org/abs/1910.14599" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b406">
	<analytic>
		<title level="a" type="main">Classical arabic poetry: Classification based on era</title>
		<author>
			<persName><forename type="first">M</forename><surname>Orabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Rifai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elnagar</surname></persName>
		</author>
		<ptr target="https://ieeexplore.ieee.org/document/9316520/" />
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/ACS 17th International Conference on Computer Systems and Applications (AICCSA)</title>
		<meeting><address><addrLine>Antalya, Turkey</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b407">
	<analytic>
		<title level="a" type="main">ToTTo: A controlled table-to-text generation dataset</title>
		<author>
			<persName><forename type="first">A</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<idno>DOI: 10/gm3nmg</idno>
		<ptr target="https://aclanthology.org/2020.emnlp-main.89" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Webber</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Cohn</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</editor>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1173" to="1186" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b408">
	<analytic>
		<title level="a" type="main">MLS: A large-scale multilingual dataset for speech research</title>
		<author>
			<persName><forename type="first">V</forename><surname>Pratap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sriram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.03411</idno>
		<ptr target="http://arxiv.org/abs/2012.03411" />
	</analytic>
	<monogr>
		<title level="m">10/grk6mp</title>
		<imprint>
			<biblScope unit="page" from="2757" to="2761" />
		</imprint>
	</monogr>
	<note>in Interspeech 2020, 2020 cs, eess visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b409">
	<analytic>
		<title level="a" type="main">Storytelling with dialogue: A critical role dungeons and dragons dataset</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rameshkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bailey</surname></persName>
		</author>
		<idno>DOI: 10/gtsqxp</idno>
		<ptr target="https://aclanthology.org/2020.acl-main.459" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Chai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Schluter</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Tetreault</surname></persName>
		</editor>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5121" to="5134" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b410">
	<monogr>
		<title level="m" type="main">A local-to-global approach to multi-modal movie scene segmentation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.02678</idno>
		<ptr target="http://arxiv.org/abs/2004.02678" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b411">
	<monogr>
		<title level="m" type="main">Towards scalable multidomain conversational agents: The schema-guided dialogue dataset</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sunkara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Khaitan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.05855</idno>
		<ptr target="http://arxiv.org/abs/1909.05855" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b412">
	<monogr>
		<title level="m" type="main">Question-driven summarization of answers to consumer health questions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Savery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Abacha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gayen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.09067</idno>
		<ptr target="http://arxiv.org/abs/2005.09067" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b413">
	<monogr>
		<title level="m" type="main">Biomedical concept relatedness -a large EHR-based benchmark</title>
		<author>
			<persName><forename type="first">C</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Levy-Kramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Van Assel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kepes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hammerla</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.16218</idno>
		<ptr target="http://arxiv.org/abs/2010.16218" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b414">
	<monogr>
		<title level="m" type="main">Understanding human hands in contact at internet scale</title>
		<author>
			<persName><forename type="first">D</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Fouhey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.06669</idno>
		<ptr target="http://arxiv.org/abs/2006.06669" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b415">
	<monogr>
		<title level="m" type="main">FineGym: A hierarchical video dataset for finegrained action understanding</title>
		<author>
			<persName><forename type="first">D</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.06704</idno>
		<ptr target="http://arxiv.org/abs/2004.06704" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b416">
	<monogr>
		<title level="m" type="main">Deep multimodal feature encoding for video ordering</title>
		<author>
			<persName><forename type="first">V</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tapaswi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stiefelhagen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.02205</idno>
		<ptr target="http://arxiv.org/abs/2004.02205" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b417">
	<monogr>
		<title level="m" type="main">A short note on the kinetics-700-2020 human action dataset</title>
		<author>
			<persName><forename type="first">L</forename><surname>Smaira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Noland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Clancy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.10864</idno>
		<ptr target="http://arxiv.org/abs/2010.10864" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b418">
	<monogr>
		<title level="m" type="main">Rapidly bootstrapping a question answering dataset for COVID-19</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.11339</idno>
		<ptr target="http://arxiv.org/abs/2004.11339" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b419">
	<monogr>
		<title level="m" type="main">CoVoST 2 and massively multilingual speech-to-text translation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pino</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.10310</idno>
		<ptr target="http://arxiv.org/abs/2007.10310" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs, eess visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b420">
	<monogr>
		<title level="m" type="main">CORD-19: The COVID-19 open research dataset</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chandrasekhar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.10706</idno>
		<ptr target="http://arxiv.org/abs/2004.10706" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b421">
	<monogr>
		<title level="m" type="main">Detecting code clones with graph neural networkand flow-augmented abstract syntax tree</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.08653</idno>
		<ptr target="http://arxiv.org/abs/2002.08653" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b422">
	<monogr>
		<title level="m" type="main">VATEX: A large-scale, high-quality multilingual dataset for video-and-language research</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.03493</idno>
		<ptr target="http://arxiv.org/abs/1904.03493" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b423">
	<monogr>
		<title level="m" type="main">Learning from task descriptions</title>
		<author>
			<persName><forename type="first">O</forename><surname>Weller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.08115</idno>
		<ptr target="http://arxiv.org/abs/2011.08115" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b424">
	<monogr>
		<title level="m" type="main">ANLIzing the adversarial natural language inference dataset</title>
		<author>
			<persName><forename type="first">A</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Thrush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.12729</idno>
		<ptr target="http://arxiv.org/abs/2010.12729" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b425">
	<monogr>
		<title level="m" type="main">ReClor: A reading comprehension dataset requiring logical reasoning</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.04326</idno>
		<ptr target="http://arxiv.org/abs/2002.04326" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b426">
	<monogr>
		<title level="m" type="main">MultiWOZ 2.2 : A dialogue dataset with additional annotation corrections and state tracking baselines</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sunkara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.12720</idno>
		<ptr target="http://arxiv.org/abs/2007.12720" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b427">
	<monogr>
		<title level="m" type="main">Knowledge graph based synthetic corpus generation for knowledge-enhanced language model pre-training</title>
		<author>
			<persName><forename type="first">O</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shakeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.12688</idno>
		<ptr target="http://arxiv.org/abs/2010.12688" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b428">
	<monogr>
		<title level="m" type="main">APES: Audiovisual person search in untrimmed video</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Alcazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Perazzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.01667</idno>
		<ptr target="http://arxiv.org/abs/2106.01667" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b429">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Ando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fujihara</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.14736</idno>
		<ptr target="http://arxiv.org/abs/2103.14736" />
		<title level="m">Construction of a large-scale japanese ASR corpus on TV recordings</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs, eess visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b430">
	<monogr>
		<title level="m" type="main">Program synthesis with large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nye</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.07732</idno>
		<ptr target="http://arxiv.org/abs/2108.07732" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b431">
	<analytic>
		<title level="a" type="main">Redefining absent keyphrases and their effect on retrieval effectiveness</title>
		<author>
			<persName><forename type="first">F</forename><surname>Boudin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gallina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rumshisky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2021.naacl-main.330" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<biblScope unit="page">64</biblScope>
		</imprint>
	</monogr>
	<note>Online: Association for Computational Linguistics, 2021 visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b432">
	<monogr>
		<title level="m" type="main">Controllable open-ended question generation with a new question type ontology</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.00152</idno>
		<ptr target="http://arxiv.org/abs/2107.00152" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b433">
	<monogr>
		<title level="m" type="main">Regulatory compliance through doc2doc information retrieval: A case study in EU/UK legislation where text similarity has limitations</title>
		<author>
			<persName><forename type="first">I</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fergadiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Manginas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Katakalou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Malakasiotis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.10726</idno>
		<ptr target="http://arxiv.org/abs/2101.10726" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b434">
	<monogr>
		<title level="m" type="main">Hierarchical pre-training for sequence labelling in spoken dialog</title>
		<author>
			<persName><forename type="first">E</forename><surname>Chapuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Colombo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Manica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Labeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Clavel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.11152</idno>
		<ptr target="http://arxiv.org/abs/2009.11152" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b435">
	<analytic>
		<title level="a" type="main">CaSiNo: A corpus of campsite negotiation dialogues for automatic negotiation systems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ramirez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Clever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gratch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rumshisky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno>DOI: 10/gtsqxv</idno>
		<ptr target="https://aclanthology.org/2021.naacl-main.254" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3167" to="3185" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b436">
	<analytic>
		<title level="a" type="main">Action-based conversations dataset: A corpus for building more in-depth task-oriented dialogue systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rumshisky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno>DOI: 10/gtsqxt</idno>
		<ptr target="https://aclanthology.org/2021.naacl-main.239" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3002" to="3017" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b437">
	<monogr>
		<title level="m" type="main">GigaSpeech: An evolving, multi-domain ASR corpus with 10,000 hours of transcribed audio</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.06909</idno>
		<ptr target="http://arxiv.org/abs/2106.06909" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs,eess visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b438">
	<analytic>
		<title level="a" type="main">DialogSum: A real-life scenario dialogue summarization dataset</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno>DOI: 10/gtsqxs</idno>
		<ptr target="https://aclanthology.org/2021.findings-acl.449" />
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Zong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="5062" to="5074" />
		</imprint>
	</monogr>
	<note>Online: Association for Computational Linguistics visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b439">
	<analytic>
		<title level="a" type="main">Human-centric atomic action dataset with curated videos</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>-H. Wuu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>-R. Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-W</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-K</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.05224</idno>
		<ptr target="http://arxiv.org/abs/2009.05224" />
	</analytic>
	<monogr>
		<title level="j">HAA</title>
		<imprint>
			<biblScope unit="volume">500</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs , eess visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b440">
	<monogr>
		<title level="m" type="main">Training verifiers to solve math word problems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bavarian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.14168</idno>
		<ptr target="http://arxiv.org/abs/2110.14168" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b441">
	<monogr>
		<title level="m" type="main">Paragraph-level simplification of medical texts</title>
		<author>
			<persName><forename type="first">A</forename><surname>Devaraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Marshall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.05767</idno>
		<ptr target="http://arxiv.org/abs/2104.05767" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b442">
	<monogr>
		<title level="m" type="main">Multi-document summarization of medical studies</title>
		<author>
			<persName><forename type="first">J</forename><surname>Deyoung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Zuylen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kuehl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.06486</idno>
		<ptr target="http://arxiv.org/abs/2104.06486" />
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">2</biblScope>
			<pubPlace>MS</pubPlace>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b443">
	<monogr>
		<title level="m" type="main">CLIMATE-FEVER: A dataset for verification of real-world climate claims</title>
		<author>
			<persName><forename type="first">T</forename><surname>Diggelmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bulian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ciaramita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Leippold</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.00614</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b444">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2012.00614" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b445">
	<monogr>
		<title level="m" type="main">Using radio archives for low-resource speech recognition: Towards an intelligent virtual assistant for illiterate users</title>
		<author>
			<persName><forename type="first">M</forename><surname>Doumbouya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Einstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Piech</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.13083</idno>
		<ptr target="http://arxiv.org/abs/2104.13083" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b446">
	<analytic>
		<title level="a" type="main">ConvoSumm: Conversation summarization benchmark and improved abstractive summarization with argument mining</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fabbri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Rizvi</surname></persName>
		</author>
		<idno>DOI: 10 / gmf9qs</idno>
		<ptr target="https://aclanthology.org/2021.acl-long.535" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Zong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6866" to="6880" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b447">
	<monogr>
		<title level="m" type="main">TWEETSUMM -a dialog summarization dataset for customer service</title>
		<author>
			<persName><forename type="first">G</forename><surname>Feigenblat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gunasekara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sznajder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Konopnicki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Aharonov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.11894</idno>
		<ptr target="http://arxiv.org/abs/2111.11894" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b448">
	<analytic>
		<title level="a" type="main">MultiDoc2dial: Modeling dialogues grounded in multiple documents</title>
		<author>
			<persName><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Joshi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.12595</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">938</biblScope>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b449">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2109.12595" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b450">
	<monogr>
		<title level="m" type="main">AISHELL-4: An open source dataset for speech enhancement, separation, recognition and speaker diarization in conference scenario</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lv</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.03603</idno>
		<ptr target="http://arxiv.org/abs/2104.03603" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs,eess visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b451">
	<monogr>
		<title level="m" type="main">The people&apos;s speech: A large-scale diverse english speech recognition dataset for commercial usage</title>
		<author>
			<persName><forename type="first">D</forename><surname>Galvez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Diamos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ciro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.09344</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs,stat</note>
</biblStruct>

<biblStruct xml:id="b452">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2111.09344" />
		<imprint/>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b453">
	<monogr>
		<title level="m" type="main">Multilingual and cross-lingual intent detection from spoken data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gerz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kusztos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08524</idno>
		<ptr target="http://arxiv.org/abs/2104.08524" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b454">
	<analytic>
		<title level="a" type="main">Beyond i.i.d.: Three levels of generalization for question answering on knowledge bases</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vanni</surname></persName>
		</author>
		<idno type="arXiv">DOI:10/gnnfbt.arXiv:2011.07743</idno>
		<ptr target="http://arxiv.org/abs/2011.07743" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Web Conference</title>
		<meeting>the Web Conference</meeting>
		<imprint>
			<date type="published" when="2021">2021, 2021</date>
			<biblScope unit="page" from="3477" to="3488" />
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b455">
	<monogr>
		<title level="m" type="main">DiDiSpeech: A large scale mandarin speech corpus</title>
		<author>
			<persName><forename type="first">T</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.09275</idno>
		<ptr target="http://arxiv.org/abs/2010.09275" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b456">
	<monogr>
		<title level="m" type="main">Disfl-QA: A benchmark dataset for understanding disfluencies in question answering</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Upadhyay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Faruqui</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.04016</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b457">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2106.04016" />
		<imprint/>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b458">
	<monogr>
		<title level="m" type="main">Text-to-SQL in the wild: A naturally-occurring dataset based on stack exchange data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hazoom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bogin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.05006</idno>
		<ptr target="http://arxiv.org/abs/2106.05006" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b459">
	<monogr>
		<title level="m" type="main">CUAD: An expert-annotated NLP dataset for legal contract review</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ball</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.06268</idno>
		<ptr target="http://arxiv.org/abs/2103.06268" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b460">
	<monogr>
		<title level="m" type="main">Efficient attentions for long document summarization</title>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parulian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.02112</idno>
		<ptr target="http://arxiv.org/abs/2104.02112" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b461">
	<monogr>
		<title level="m" type="main">Neural CRF model for sentence alignment in text simplification</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maddela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.02324</idno>
		<ptr target="http://arxiv.org/abs/2005.02324" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b462">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Karpov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Denisenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Minkin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.10161</idno>
		<ptr target="http://arxiv.org/abs/2106.10161" />
		<title level="m">Golos: Russian dataset for speech research</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b463">
	<monogr>
		<title level="m" type="main">A crowdsourced open-source kazakh speech corpus and initial speech recognition baseline</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Khassanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mussakhojayeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mirzakhmetov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Adiyev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nurpeiissov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Varol</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.10334</idno>
		<ptr target="http://arxiv.org/abs/2009.10334" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs,eess visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b464">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Kolobov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Okhapkina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Omelchishina</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.16193</idno>
		<ptr target="http://arxiv.org/abs/2103.16193" />
		<title level="m">MediaSpeech: Multilanguage ASR benchmark and dataset</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs , eess visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b465">
	<analytic>
		<title level="a" type="main">MTOP: A comprehensive multilingual task-oriented semantic parsing benchmark</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mehdad</surname></persName>
		</author>
		<idno>DOI: 10/gtsqxq</idno>
		<ptr target="https://aclanthology.org/2021.eacl-main.257" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Main Volume</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Merlo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Tiedemann</surname></persName>
		</editor>
		<editor>
			<persName><surname>Tsarfaty</surname></persName>
		</editor>
		<meeting>the 16th Conference of the European Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2950" to="2962" />
		</imprint>
	</monogr>
	<note>Online: Association for Computational Linguistics visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b466">
	<monogr>
		<title level="m" type="main">UAV-human: A large benchmark for human behavior understanding with unmanned aerial vehicles</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.00946</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b467">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2104.00946" />
		<imprint/>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b468">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00376</idno>
		<ptr target="http://arxiv.org/abs/2101.00376" />
		<title level="m">RiddleSense: Reasoning about riddle questions featuring linguistic creativity and commonsense knowledge</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b469">
	<monogr>
		<title level="m" type="main">BiToD: A bilingual multi-domain dataset for taskoriented dialogue modeling</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">I</forename><surname>Winata</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.02787</idno>
		<ptr target="http://arxiv.org/abs/2106.02787" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b470">
	<analytic>
		<title level="a" type="main">DuRecDial 2.0: A bilingual parallel corpus for conversational recommendation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-Y</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Che ; Moens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b471">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Eds</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Punta</forename><surname>Online</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominican</forename><surname>Cana</surname></persName>
		</author>
		<author>
			<persName><surname>Republic</surname></persName>
		</author>
		<idno>DOI: 10 / gtsqxr</idno>
		<ptr target="https://aclanthology.org/2021.emnlp-main.356" />
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="4335" to="4347" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b472">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Monfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2105.04489</idno>
		<idno type="arXiv">arXiv:2105.04489</idno>
		<ptr target="http://arxiv.org/abs/2105.04489" />
		<title level="m">Spoken Moments: Learning Joint Audio-Visual Representations from Video Descriptions</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
	<note>cs, eess visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b473">
	<monogr>
		<title level="m" type="main">Multi-moments in time: Learning and interpreting models for multi-action video understanding</title>
		<author>
			<persName><forename type="first">M</forename><surname>Monfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.00232</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs,eess</note>
</biblStruct>

<biblStruct xml:id="b474">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1911.00232" />
		<imprint/>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b475">
	<monogr>
		<title level="m" type="main">QASR: QCRI aljazeera speech resource -a large scale annotated arabic speech corpus</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hussein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ali</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.13000</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs, eess</note>
</biblStruct>

<biblStruct xml:id="b476">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2106.13000" />
		<imprint/>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b477">
	<analytic>
		<title level="a" type="main">DART: Open-domain structured data record to text generation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Nan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">DOI:10/gnh49f.arXiv:2007.02871</idno>
		<ptr target="https://aclanthology.org/2021.naacl-main.37" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="432" to="447" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b478">
	<analytic>
		<title level="a" type="main">Advanced semantics for commonsense knowledge extraction</title>
		<author>
			<persName><forename type="first">T.-P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Razniewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
		<idno type="arXiv">DOI:10/gnnffn.arXiv:2011.00905</idno>
		<ptr target="http://arxiv.org/abs/2011.00905" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Web Conference</title>
		<meeting>the Web Conference</meeting>
		<imprint>
			<date type="published" when="2021">2021, 2021</date>
			<biblScope unit="page" from="2636" to="2647" />
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b479">
	<monogr>
		<title level="m" type="main">SPGISpeech: 5,000 hours of transcribed financial audio for fully formatted end-to-end speech recognition</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>O'neill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lavrukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Majumdar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.02014</idno>
		<ptr target="http://arxiv.org/abs/2104.02014" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs,eess visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b480">
	<monogr>
		<title level="m" type="main">QuerYD: A video dataset with high-quality text and audio narrations</title>
		<author>
			<persName><forename type="first">A.-M</forename><surname>Oncescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Albanie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.11071</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b481">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2011.11071" />
		<imprint/>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b482">
	<monogr>
		<title level="m" type="main">The world of an octopus: How reporting bias influences a language model&apos;s perception of color</title>
		<author>
			<persName><forename type="first">C</forename><surname>Paik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Aroca-Ouellette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roncone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.08182</idno>
		<ptr target="http://arxiv.org/abs/2110.08182" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b483">
	<monogr>
		<title level="m" type="main">CrowdSpeech and VoxDIY: Benchmark datasets for crowdsourced audio transcription</title>
		<author>
			<persName><forename type="first">N</forename><surname>Pavlichenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stelmakh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ustalov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.01091</idno>
		<ptr target="http://arxiv.org/abs/2107.01091" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs,eess visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b484">
	<monogr>
		<title level="m" type="main">Home action genome: Cooperative compositional action understanding</title>
		<author>
			<persName><forename type="first">N</forename><surname>Rai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ji</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.05226</idno>
		<ptr target="http://arxiv.org/abs/2105.05226" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b485">
	<monogr>
		<title level="m" type="main">The multilingual TEDx corpus for speech recognition and translation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Salesky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wiesner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bremerman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.01757</idno>
		<ptr target="http://arxiv.org/abs/2102.01757" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b486">
	<analytic>
		<title level="a" type="main">Highland puebla nahuatl speech translation corpus for endangered language documentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Amith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dalmia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Watanabe</surname></persName>
		</author>
		<idno>DOI: 10/gtwwcd</idno>
		<ptr target="https://aclanthology.org/2021.americasnlp-1.7" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Mager</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Oncevay</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Rios</surname></persName>
		</editor>
		<meeting>the First Workshop on Natural Language Processing for Indigenous Languages of the Americas</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="53" to="63" />
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b487">
	<monogr>
		<title level="m" type="main">ALFWorld: Aligning text and embodied environments for interactive learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shridhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-A</forename><surname>C√¥t√©</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hausknecht</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.03768</idno>
		<ptr target="http://arxiv.org/abs/2010.03768" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b488">
	<analytic>
		<title level="a" type="main">NLQuAD: A non-factoid long question answering data set</title>
		<author>
			<persName><forename type="first">A</forename><surname>Soleimani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Worring</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2021.eacl-main.106" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, Online: Association for Computational Linguistics</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, Online: Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1245" to="1255" />
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b489">
	<monogr>
		<title level="m" type="main">EEV: A large-scale dataset for studying evoked expressions from video</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Cowen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Prasad</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.05488</idno>
		<ptr target="http://arxiv.org/abs/2001.05488" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b490">
	<monogr>
		<title level="m" type="main">JTubeSpeech: Corpus of japanese speech collected from YouTube for speech recognition and speaker verification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Takamichi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>K√ºrzinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Saeki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shiota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Watanabe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.09323</idno>
		<ptr target="http://arxiv.org/abs/2112.09323" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs, eess visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b491">
	<monogr>
		<title level="m" type="main">MultiModalQA: Complex question answering over text, tables and images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Yoran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Catav</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.06039</idno>
		<ptr target="http://arxiv.org/abs/2104.06039" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b492">
	<analytic>
		<title level="a" type="main">KeSpeech: An open source speech dataset of mandarin and its eight subdialects</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<ptr target="https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks</title>
		<meeting>the Neural Information Processing Systems Track on Datasets and Benchmarks</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>0336dcbab05b9d5 ad24f4333c7658a0e-Abstract-round2.html (visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b493">
	<analytic>
		<title level="a" type="main">Numeracy enhances the literacy of language models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Thawani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pujara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ilievski</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2021.emnlp-main.557" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">M.-F</forename><surname>Moens</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Specia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>-T</surname></persName>
		</editor>
		<editor>
			<persName><surname>Yih</surname></persName>
		</editor>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="6960" to="6967" />
		</imprint>
	</monogr>
	<note>Online and Punta Cana visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b494">
	<monogr>
		<title level="m" type="main">VoxPopuli: A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rivi√®re</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00390</idno>
		<ptr target="http://arxiv.org/abs/2101.00390" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs,eess visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b495">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rogez</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.07249</idno>
		<ptr target="http://arxiv.org/abs/1912.07249" />
		<title level="m">Mimetics: Towards understanding human actions out of context, 2021</title>
		<imprint/>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b496">
	<monogr>
		<title level="m" type="main">VideoLT: Large-scale long-tailed video recognition</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Weng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.02668</idno>
		<ptr target="http://arxiv.org/abs/2105.02668" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b497">
	<analytic>
		<title level="a" type="main">M2asr-MONGO: A free mongolian speech database and accompanied baselines</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<idno>DOI: 10/gtsqzg</idno>
		<ptr target="https://ieeexplore.ieee.org/document/9660401/" />
	</analytic>
	<monogr>
		<title level="m">2021 24th Conference of the Oriental COCOSDA International Committee for the Co-ordination and Standardisation of Speech Databases and Assessment Techniques (O-COCOSDA)</title>
		<meeting><address><addrLine>Singapore, Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="140" to="145" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b498">
	<monogr>
		<title level="m" type="main">QMSum: A new benchmark for query-based multi-domain meeting summarization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.05938</idno>
		<ptr target="http://arxiv.org/abs/2104.05938" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b499">
	<monogr>
		<title level="m" type="main">MediaSum: A large-scale media interview dataset for dialogue summarization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zeng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.06410</idno>
		<ptr target="http://arxiv.org/abs/2103.06410" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b500">
	<monogr>
		<title level="m" type="main">TopiOCQA: Open-domain conversational question answering with topic switching</title>
		<author>
			<persName><forename type="first">V</forename><surname>Adlakha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dhuliawala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Suleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Vries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Reddy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.00768</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b501">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2110.00768" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b502">
	<monogr>
		<title level="m" type="main">Towards tracing factual knowledge in language models back to the training data</title>
		<author>
			<persName><forename type="first">E</forename><surname>Aky√ºrek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bolukbasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.11482</idno>
		<ptr target="http://arxiv.org/abs/2205.11482" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b503">
	<analytic>
		<title level="a" type="main">ArMATH: A dataset for solving arabic math word problems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Alghamdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2022.lrec-1.37" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth Language Resources and Evaluation Conference</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Calzolari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>B√©chet</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Blache</surname></persName>
		</editor>
		<meeting>the Thirteenth Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="351" to="362" />
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b504">
	<monogr>
		<title level="m" type="main">Training a helpful and harmless assistant with reinforcement learning from human feedback</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ndousse</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.05862</idno>
		<ptr target="http://arxiv.org/abs/2204.05862" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b505">
	<monogr>
		<title level="m" type="main">Frozen in time: A joint video and image encoder for end-to-end retrieval</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nagrani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2104.00650</idno>
		<idno type="arXiv">arXiv:2104.00650</idno>
		<ptr target="http://arxiv.org/abs/2104.00650" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/03/2024</note>
</biblStruct>

<biblStruct xml:id="b506">
	<analytic>
		<title level="a" type="main">Gram vaani ASR challenge on spontaneous telephone speech recordings in regional variations of hindi</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bhanushali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bridgman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename></persName>
		</author>
		<idno>DOI: 10/gtsqzn</idno>
		<ptr target="https://www.isca-archive.org/interspeech_2022/bhanushali22_interspeech.html" />
	</analytic>
	<monogr>
		<title level="m">Interspeech 2022, ISCA</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="3548" to="3552" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b507">
	<monogr>
		<title level="m" type="main">Effectiveness of mining audio and text pairs from public data for improving ASR systems for low-resource languages</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Bhogale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Javed</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.12666</idno>
		<ptr target="http://arxiv.org/abs/2208.12666" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs,eess visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b508">
	<monogr>
		<title level="m" type="main">KQA pro: A dataset with explicit compositional programs for complex question answering over knowledge base</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.03875</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b509">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2007.03875" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b510">
	<monogr>
		<title level="m" type="main">Few-shot adaptation works with UnpredicTable data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pieler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Scheurer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Perez</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.01009</idno>
		<ptr target="http://arxiv.org/abs/2208.01009" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b511">
	<analytic>
		<title level="a" type="main">SummScreen: A dataset for abstractive screenplay summarization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<idno>DOI: 10/gtsqxx</idno>
		<ptr target="https://aclanthology.org/2022.acl-long.589" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Muresan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Nakov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Villavicencio</surname></persName>
		</editor>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="8602" to="8615" />
		</imprint>
	</monogr>
	<note>Long Papers visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b512">
	<monogr>
		<title level="m" type="main">KETOD: Knowledgeenriched task-oriented dialogue</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Crook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.05589</idno>
		<ptr target="http://arxiv.org/abs/2205.05589" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b513">
	<monogr>
		<title level="m" type="main">HiTab: A hierarchical table dataset for question answering and natural language generation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.06712</idno>
		<ptr target="http://arxiv.org/abs/2108.06712" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b514">
	<analytic>
		<title level="a" type="main">SalesBot: Transitioning from chit-chat to taskoriented dialogues</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-N</forename><surname>Chen</surname></persName>
		</author>
		<idno>DOI: 10/gtsqxw</idno>
		<ptr target="https://aclanthology.org/2022.acl-long.425" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Muresan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Nakov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Villavicencio</surname></persName>
		</editor>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6143" to="6158" />
		</imprint>
	</monogr>
	<note>Long Papers visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b515">
	<monogr>
		<title level="m" type="main">FLEURS: Few-shot learning evaluation of universal representations of speech, version: 1</title>
		<author>
			<persName><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Khanuja</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.12446</idno>
		<ptr target="http://arxiv.org/abs/2205.12446" />
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
	<note>cs,eess visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b516">
	<analytic>
		<title level="a" type="main">Can transformer be too compositional? analysing idiom processing in neural machine translation</title>
		<author>
			<persName><forename type="first">V</forename><surname>Dankers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Titov</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2022.acl-long.252" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Muresan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Nakov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Villavicencio</surname></persName>
		</editor>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3608" to="3626" />
		</imprint>
	</monogr>
	<note>Long Papers visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b517">
	<monogr>
		<title level="m" type="main">Earnings-22: A practical benchmark for accents in the wild</title>
		<author>
			<persName><forename type="first">M</forename><surname>Del Rio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chandra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.15591</idno>
		<ptr target="http://arxiv.org/abs/2203.15591" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b518">
	<monogr>
		<title level="m" type="main">Ego4d: Around the world in 3,000 hours of egocentric video</title>
		<author>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Westbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Byrne</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.07058</idno>
		<ptr target="http://arxiv.org/abs/2110.07058" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b519">
	<analytic>
		<title level="a" type="main">Domain-specific language model pretraining for biomedical natural language processing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tinn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="arXiv">DOI:10/gnmkjx.arXiv:2007.15779</idno>
		<ptr target="http://arxiv.org/abs/2007.15779" />
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computing for Healthcare</title>
		<idno type="ISSN">2691-1957</idno>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2637" to="8051" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b520">
	<monogr>
		<title level="m" type="main">Pile of law: Learning responsible data filtering from the law and a 256gb open-source legal dataset</title>
		<author>
			<persName><forename type="first">P</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Krass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.00220</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b521">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2207.00220" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b522">
	<analytic>
		<title level="a" type="main">Samr√≥mur children: An icelandic speech corpus</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Hernandez Mena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Mollberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Borsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gudnason</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2022.lrec-1.105" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth Language Resources and Evaluation Conference</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Calzolari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Bechet</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Blache</surname></persName>
		</editor>
		<meeting>the Thirteenth Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="995" to="1002" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b523">
	<monogr>
		<title level="m" type="main">tis but thy name: Semantic question answering evaluation with 11m names for 1m entities</title>
		<author>
			<persName><forename type="first">A</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.13581</idno>
		<ptr target="http://arxiv.org/abs/2202.13581" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b524">
	<monogr>
		<title level="m" type="main">Efficient long-text understanding with short-text models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ivgi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Shaham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.00748</idno>
		<ptr target="http://arxiv.org/abs/2208.00748" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b525">
	<monogr>
		<title level="m" type="main">IndicSU-PERB: A speech processing universal performance benchmark for indian languages</title>
		<author>
			<persName><forename type="first">T</forename><surname>Javed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Bhogale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kunchukuttan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Khapra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.11761</idno>
		<ptr target="http://arxiv.org/abs/2208.11761" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs, eess visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b526">
	<monogr>
		<title level="m" type="main">ProsocialDialog: A prosocial backbone for conversational agents</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.12688</idno>
		<ptr target="http://arxiv.org/abs/2205.12688" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b527">
	<analytic>
		<title level="a" type="main">Internet-augmented dialogue generation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Komeili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<idno>DOI: 10/gr75db</idno>
		<ptr target="https://aclanthology.org/2022.acl-long.579" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Muresan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Nakov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Villavicencio</surname></persName>
		</editor>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="8460" to="8478" />
		</imprint>
	</monogr>
	<note>Long Papers visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b528">
	<monogr>
		<title level="m" type="main">Bloom library: Multimodal datasets in 300+ languages for a variety of downstream tasks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Leong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nemecek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mansdorfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Filighera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Owodunni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Whitenack</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.14712</idno>
		<ptr target="http://arxiv.org/abs/2210.14712" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b529">
	<analytic>
		<title level="a" type="main">Competition-level code generation with AlphaCode</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.07814</idno>
		<ptr target="http://arxiv.org/abs/2203.07814" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<idno type="ISSN">0036-8075</idno>
		<imprint>
			<biblScope unit="volume">378</biblScope>
			<biblScope unit="issue">6624</biblScope>
			<biblScope unit="page" from="1095" to="9203" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b530">
	<monogr>
		<title level="m" type="main">TruthfulQA: Measuring how models mimic human falsehoods</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Evans</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.07958</idno>
		<ptr target="http://arxiv.org/abs/2109.07958" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b531">
	<monogr>
		<title level="m" type="main">Learn to explain: Multimodal reasoning via thought chains for science question answering</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.09513</idno>
		<ptr target="http://arxiv.org/abs/2209.09513" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b532">
	<analytic>
		<title level="a" type="main">ECTSum: A new benchmark dataset for bullet point summarization of long earnings call transcripts</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bohra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
		<idno>DOI: 10 / gtsqxz</idno>
		<ptr target="https://aclanthology.org/2022.emnlp-main.748" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">Z</forename><surname>Goldberg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Kozareva</surname></persName>
		</editor>
		<editor>
			<persName><surname>Zhang</surname></persName>
		</editor>
		<meeting>the 2022 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Abu Dhabi, United Arab Emirates</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">906</biblScope>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b533">
	<analytic>
		<title level="a" type="main">FeTaQA: Free-form table question answering</title>
		<author>
			<persName><forename type="first">L</forename><surname>Nan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Mao</surname></persName>
		</author>
		<idno>DOI: 10/gtsqx3</idno>
		<ptr target="https://aclanthology.org/2022.tacl-1.3" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Roark</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Nenkova</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="35" to="49" />
			<date type="published" when="2022">2022</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b534">
	<monogr>
		<title level="m" type="main">A high-quality and largescale dataset for english-vietnamese speech translation</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">L</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Doan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.04243</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b535">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2208.04243" />
		<imprint/>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b536">
	<monogr>
		<title level="m" type="main">SDS-200: A swiss german speech to standard german text corpus</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pl√ºss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>H√ºrlimann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cuny</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.09501</idno>
		<ptr target="http://arxiv.org/abs/2205.09501" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b537">
	<monogr>
		<title level="m" type="main">Multilingual event linking to wikidata</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pratapa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mitamura</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.06535</idno>
		<ptr target="http://arxiv.org/abs/2204.06535" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b538">
	<analytic>
		<title level="a" type="main">Database search results disambiguation for taskoriented dialog systems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kottur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beirami</surname></persName>
		</author>
		<idno>DOI: 10/gtsqx2</idno>
		<ptr target="https://aclanthology.org/2022.naacl-main.85" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Carpuat</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M.-C</forename><surname>De Marneffe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><forename type="middle">V</forename><surname>Meza Ruiz</surname></persName>
		</editor>
		<meeting>the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Seattle, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1158" to="1173" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b539">
	<monogr>
		<title level="m" type="main">Multitask prompted training enables zero-shot task generalization</title>
		<author>
			<persName><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.08207</idno>
		<ptr target="http://arxiv.org/abs/2110.08207" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b540">
	<analytic>
		<title level="a" type="main">The norwegian parliamentary speech corpus</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Solberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ortiz</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2022.lrec-1.106" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth Language Resources and Evaluation Conference</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Calzolari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>B√©chet</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Blache</surname></persName>
		</editor>
		<meeting>the Thirteenth Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1003" to="1008" />
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b541">
	<monogr>
		<title level="m" type="main">MAD: A scalable dataset for language grounding in videos from movie audio descriptions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Soldan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Alc√°zar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.00431</idno>
		<ptr target="http://arxiv.org/abs/2112.00431" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b542">
	<monogr>
		<title level="m" type="main">Finnish parliament ASR corpus -analysis, benchmarks and statistics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Virkkunen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rouhe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kurimo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.14876</idno>
		<ptr target="http://arxiv.org/abs/2203.14876" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs,eess visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b543">
	<monogr>
		<title level="m" type="main">Adversarial GLUE: A multi-task benchmark for robustness evaluation of language models</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.02840</idno>
		<ptr target="http://arxiv.org/abs/2111.02840" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b544">
	<monogr>
		<title level="m" type="main">FERV39k: A large-scale multi-scene dataset for facial expression recognition in videos</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.09463</idno>
		<ptr target="http://arxiv.org/abs/2203.09463" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b545">
	<analytic>
		<title level="a" type="main">CDAD: A common daily action dataset with collected hard negative samples</title>
		<author>
			<persName><forename type="first">W</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-S</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<ptr target="https://ieeexplore.ieee.org/document/9857185/" />
	</analytic>
	<monogr>
		<title level="m">2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b546">
	<monogr>
		<title level="m" type="main">Advancing high-resolution video-language representation with large-scale video transcriptions</title>
		<author>
			<persName><forename type="first">H</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zeng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.10337</idno>
		<ptr target="http://arxiv.org/abs/2111.10337" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b547">
	<monogr>
		<title level="m" type="main">Open source MagicData-RAMC: A rich annotated mandarin conversational(RAMC) speech dataset</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Luo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.16844</idno>
		<ptr target="http://arxiv.org/abs/2203.16844" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs,eess visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b548">
	<monogr>
		<title level="m" type="main">WenetSpeech: A 10000+ hours multi-domain mandarin corpus for speech recognition</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Guo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.03370</idno>
		<ptr target="http://arxiv.org/abs/2110.03370" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b549">
	<monogr>
		<title level="m" type="main">Are pretrained transformers robust in intent classification? a missing ingredient in evaluation of out-of-scope intent detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.04564</idno>
		<ptr target="http://arxiv.org/abs/2106.04564" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b550">
	<monogr>
		<title level="m" type="main">XLCoST: A benchmark dataset for cross-lingual code intelligence</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ravindran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tipirneni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Reddy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.08474</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b551">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2206.08474" />
		<imprint/>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b552">
	<monogr>
		<title level="m" type="main">ProofNet: Autoformalizing and formally proving undergraduate-level mathematics</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Azerbayev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Piotrowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Avigad</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.12433</idno>
		<ptr target="http://arxiv.org/abs/2302.12433" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b553">
	<monogr>
		<title level="m" type="main">MegaWika: Millions of reports and their sources across 50 diverse languages</title>
		<author>
			<persName><forename type="first">S</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Weller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yuan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.07049</idno>
		<ptr target="http://arxiv.org/abs/2307.07049" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b554">
	<monogr>
		<title level="m" type="main">PLACES: Prompting language models for social conversation synthesis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Papangelis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.03269</idno>
		<ptr target="http://arxiv.org/abs/2302.03269" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b555">
	<monogr>
		<title level="m" type="main">TheoremQA: A theorem-driven question answering dataset</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ku</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.12524</idno>
		<ptr target="http://arxiv.org/abs/2305.12524" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b556">
	<monogr>
		<title level="m" type="main">Mind2web: Towards a generalist agent for the web</title>
		<author>
			<persName><forename type="first">X</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.06070</idno>
		<ptr target="http://arxiv.org/abs/2306.06070" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b557">
	<monogr>
		<title level="m" type="main">QLoRA: Efficient finetuning of quantized LLMs</title>
		<author>
			<persName><forename type="first">T</forename><surname>Dettmers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pagnoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14314</idno>
		<ptr target="http://arxiv.org/abs/2305.14314" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b558">
	<monogr>
		<title level="m" type="main">Enhancing chat language models by scaling high-quality instructional conversations</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14233</idno>
		<ptr target="http://arxiv.org/abs/2305.14233" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b559">
	<analytic>
		<title level="a" type="main">MASC: Massive arabic speech corpus</title>
		<author>
			<persName><forename type="first">M</forename><surname>Al-Fetyani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Al-Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Abandah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alsharkawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dawas</surname></persName>
		</author>
		<ptr target="https://ieeexplore.ieee.org/document/10022652/" />
	</analytic>
	<monogr>
		<title level="m">2022 IEEE Spoken Language Technology Workshop (SLT)</title>
		<meeting><address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1006" to="1013" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b560">
	<monogr>
		<title level="m" type="main">PIPPA: A partially synthetic conversational dataset</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gosling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.05884</idno>
		<ptr target="http://arxiv.org/abs/2308.05884" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b561">
	<monogr>
		<title level="m" type="main">MedAlpaca -an open-source collection of medical conversational AI models and training data</title>
		<author>
			<persName><forename type="first">T</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Papaioannou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.08247</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b562">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2304.08247" />
		<imprint/>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b563">
	<monogr>
		<title level="m" type="main">OpenAssistant conversations -democratizing large language model alignment</title>
		<author>
			<persName><forename type="first">A</forename><surname>K√∂pf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kilcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Von R√ºtte</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.07327</idno>
		<ptr target="http://arxiv.org/abs/2304.07327" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b564">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Koto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Aji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.15011</idno>
		<title level="m">Bactrian-x: Multilingual replicable instruction-following models with low-rank adaptation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b565">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2305.15011" />
		<imprint/>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b566">
	<analytic>
		<title level="a" type="main">Yodas: Youtubeoriented dataset for audio and speech</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Takamichi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Saeki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shiota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Watanabe</surname></persName>
		</author>
		<ptr target="https://ieeexplore.ieee.org/document/10389689/" />
	</analytic>
	<monogr>
		<title level="m">2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</title>
		<meeting><address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b567">
	<monogr>
		<title level="m" type="main">ChatDoctor: A medical chat model fine-tuned on a large language model meta-AI (LLaMA) using medical domain knowledge</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.14070</idno>
		<ptr target="http://arxiv.org/abs/2303.14070" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b568">
	<monogr>
		<title level="m" type="main">Let&apos;s verify step by step</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lightman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Burda</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.20050</idno>
		<ptr target="http://arxiv.org/abs/2305.20050" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b569">
	<monogr>
		<title level="m" type="main">AgentBench: Evaluating LLMs as agents</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.03688</idno>
		<ptr target="http://arxiv.org/abs/2308.03688" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b570">
	<monogr>
		<title level="m" type="main">MathDial: A dialogue tutoring dataset with rich pedagogical properties grounded in math reasoning problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Macina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Daheim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Chowdhury</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14536</idno>
		<ptr target="http://arxiv.org/abs/2305.14536" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b571">
	<analytic>
		<title level="a" type="main">M2asr-KIRGHIZ: A free kirghiz speech database and accompanied baselines</title>
		<author>
			<persName><forename type="first">I</forename><surname>Mamtimin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hamdulla</surname></persName>
		</author>
		<idno>DOI: 10/gtsqzm</idno>
		<ptr target="https://www.mdpi.com/2078-2489/14/1/55" />
	</analytic>
	<monogr>
		<title level="j">Information</title>
		<idno type="ISSN">2078-2489</idno>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">55</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b572">
	<monogr>
		<title level="m" type="main">Lila: A unified benchmark for mathematical reasoning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Finlayson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.17517</idno>
		<ptr target="http://arxiv.org/abs/2210.17517" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b573">
	<monogr>
		<title level="m" type="main">SeaLLMs -large language models for southeast asia</title>
		<author>
			<persName><forename type="first">X.-P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.00738</idno>
		<ptr target="http://arxiv.org/abs/2312.00738" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b574">
	<monogr>
		<title level="m" type="main">AfriSpeech-200: Pan-african accented speech dataset for clinical and general domain ASR</title>
		<author>
			<persName><forename type="first">T</forename><surname>Olatunji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Afonja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yadavalli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.00274</idno>
		<ptr target="http://arxiv.org/abs/2310.00274" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b575">
	<monogr>
		<title level="m" type="main">Aria digital twin: A new benchmark dataset for egocentric 3d machine perception</title>
		<author>
			<persName><forename type="first">X</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Charron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.06362</idno>
		<ptr target="http://arxiv.org/abs/2306.06362" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b576">
	<monogr>
		<title level="m" type="main">OLKAVS: An open large-scale korean audio-visual speech dataset</title>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-W</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.06375</idno>
		<ptr target="http://arxiv.org/abs/2301.06375" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b577">
	<monogr>
		<title level="m" type="main">PiC: A phrase-in-context dataset for phrase understanding and semantic search</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nguyen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.09068</idno>
		<ptr target="http://arxiv.org/abs/2207.09068" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b578">
	<monogr>
		<title level="m" type="main">Snow mountain: Dataset of audio recordings of the bible in low resource languages</title>
		<author>
			<persName><forename type="first">K</forename><surname>Raju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mathew</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.01205</idno>
		<ptr target="http://arxiv.org/abs/2206.01205" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs, eess visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b579">
	<monogr>
		<title level="m" type="main">Exploring the effectiveness of instruction tuning in biomedical language processing</title>
		<author>
			<persName><forename type="first">O</forename><surname>Rohanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nouriborji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Clifton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.00579</idno>
		<ptr target="http://arxiv.org/abs/2401.00579" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b580">
	<monogr>
		<title level="m" type="main">Language modelling with pixels</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Lotz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bugliarello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Salesky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Lhoneux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Elliott</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.06991</idno>
		<ptr target="http://arxiv.org/abs/2207.06991" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b581">
	<monogr>
		<title level="m" type="main">The edinburgh international accents of english corpus: Towards the democratization of english ASR</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sanabria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bogoychev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Markl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Carmantini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Klejch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.18110</idno>
		<ptr target="http://arxiv.org/abs/2303.18110" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs, eess visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b582">
	<monogr>
		<title level="m" type="main">ARB: Advanced reasoning benchmark for large language models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sawada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Paleka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Havrilla</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.13692</idno>
		<ptr target="http://arxiv.org/abs/2307.13692" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b583">
	<monogr>
		<title level="m" type="main">Probing neural language models for understanding of words of estimative probability</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sileo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-F</forename><surname>Moens</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.03358</idno>
		<ptr target="http://arxiv.org/abs/2211.03358" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b584">
	<analytic>
		<title level="a" type="main">CsFEVER and CTKFacts: Acquiring czech data for fact verification</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ullrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Drchal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>R√Ωpar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Vincourov√°</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Moravec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.11115</idno>
		<ptr target="http://arxiv.org/abs/2201.11115" />
	</analytic>
	<monogr>
		<title level="j">Language Resources and Evaluation</title>
		<idno type="ISSN">1574-020X, 1574-0218</idno>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1571" to="1605" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b585">
	<monogr>
		<title level="m" type="main">Generative language models for paragraph-level question generation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ushio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Alva-Manchego</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Camacho-Collados</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.03992</idno>
		<ptr target="http://arxiv.org/abs/2210.03992" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b586">
	<monogr>
		<title level="m" type="main">Self-instruct: Aligning language models with selfgenerated instructions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kordi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mishra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.10560</idno>
		<ptr target="http://arxiv.org/abs/2212.10560" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b587">
	<monogr>
		<title level="m" type="main">HelpSteer: Multi-attribute helpfulness dataset for SteerLM</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zeng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.09528</idno>
		<ptr target="http://arxiv.org/abs/2311.09528" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b588">
	<monogr>
		<title level="m" type="main">BLiMP: The benchmark of linguistic minimal pairs for english</title>
		<author>
			<persName><forename type="first">A</forename><surname>Warstadt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Parrish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.00582</idno>
		<ptr target="http://arxiv.org/abs/1912.00582" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b589">
	<monogr>
		<title level="m" type="main">PMC-LLaMA: Towards building open-source language models for medicine</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.14454</idno>
		<ptr target="http://arxiv.org/abs/2304.14454" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b590">
	<monogr>
		<title level="m" type="main">WebShop: Towards scalable real-world web interaction with grounded language agents</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.01206</idno>
		<ptr target="http://arxiv.org/abs/2207.01206" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b591">
	<monogr>
		<title level="m" type="main">SelFee: Iterative self-revising LLM empowered by self-feedback generation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Seo</surname></persName>
		</author>
		<ptr target="https://kaistai.github.io/SelFee/" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
		<respStmt>
			<orgName>LK Lab</orgName>
		</respStmt>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b592">
	<monogr>
		<title level="m" type="main">ReazonSpeech: A free and massive corpus for japanese ASR</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fujimoto</surname></persName>
		</author>
		<ptr target="https://research.reazon.jp/_static/reazonspeech_nlp2023.pdf" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b593">
	<monogr>
		<title level="m" type="main">MetaMath: Bootstrap your own mathematical questions for large language models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.12284</idno>
		<ptr target="http://arxiv.org/abs/2309.12284" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b594">
	<monogr>
		<title level="m" type="main">MAmmoTH: Building math generalist models through hybrid instruction tuning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.05653</idno>
		<ptr target="http://arxiv.org/abs/2309.05653" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b595">
	<monogr>
		<title level="m" type="main">AgentTuning: Enabling generalized agent abilities for LLMs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.12823</idno>
		<ptr target="http://arxiv.org/abs/2310.12823" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/02/2024</note>
</biblStruct>

<biblStruct xml:id="b596">
	<monogr>
		<title level="m" type="main">Chinese open instruction generalist: A preliminary release</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.07987</idno>
		<ptr target="http://arxiv.org/abs/2304.07987" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b597">
	<monogr>
		<title level="m" type="main">Fengshenbang 1.0: Being the foundation of chinese cognitive intelligence</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.02970</idno>
		<ptr target="http://arxiv.org/abs/2209.02970" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b598">
	<analytic>
		<title level="a" type="main">WildChat: 1m ChatGPT interaction logs in the wild</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hessel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Deng</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=Bl8u7ZRlbM" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth International Conference on Learning Representations</title>
		<meeting>the Twelfth International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b599">
	<monogr>
		<title level="m" type="main">Judging LLM-as-a-judge with MT-bench and chatbot arena</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-L</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.05685</idno>
		<ptr target="http://arxiv.org/abs/2306.05685" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b600">
	<monogr>
		<title level="m" type="main">DocPrompting: Generating code by retrieving the docs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">F</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.05987</idno>
		<ptr target="http://arxiv.org/abs/2207.05987" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b601">
	<monogr>
		<title level="m" type="main">COBRA frames: Contextual reasoning about effects and harms of offensive statements</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yerukola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.01985</idno>
		<ptr target="http://arxiv.org/abs/2306.01985" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b602">
	<monogr>
		<title level="m" type="main">ArabicaQA: A comprehensive dataset for arabic question answering</title>
		<author>
			<persName><forename type="first">A</forename><surname>Abdallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kasem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abdalla</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.17848</idno>
		<ptr target="http://arxiv.org/abs/2403.17848" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b603">
	<monogr>
		<title level="m" type="main">101 billion arabic words dataset</title>
		<author>
			<persName><forename type="first">M</forename><surname>Aloui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chouikhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chaabane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kchaou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dhaouadi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.01590</idno>
		<ptr target="http://arxiv.org/abs/2405.01590" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b604">
	<monogr>
		<title level="m" type="main">CIDAR: Culturally relevant instruction dataset for arabic</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Alyafeai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Almubarak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ashraf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.03177</idno>
		<ptr target="http://arxiv.org/abs/2402.03177" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b605">
	<monogr>
		<title level="m" type="main">COIG-CQIA: Quality is all you need for chinese instruction fine-tuning, version: 1</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.18058</idno>
		<ptr target="http://arxiv.org/abs/2403.18058" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b606">
	<monogr>
		<title level="m" type="main">LongAlign: A recipe for long context alignment of large language models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.18058</idno>
		<ptr target="http://arxiv.org/abs/2401.18058" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b607">
	<monogr>
		<title level="m" type="main">ShareGPT4video: Improving video understanding and generation with better captions</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.04325</idno>
		<ptr target="http://arxiv.org/abs/2406.04325" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b608">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Chouikhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aloui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Hammou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chaabane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kchaou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dhaouadi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2407.02147</idno>
		<title level="m">GemmAr: Enhancing LLMs through arabic instruction-tuning</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b609">
	<monogr>
		<title/>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2407.02147" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b610">
	<monogr>
		<title level="m" type="main">Airavata: Introducing hindi instruction-tuned LLM</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jayakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Husain</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.15006</idno>
		<ptr target="http://arxiv.org/abs/2401.15006" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b611">
	<monogr>
		<title level="m" type="main">Prometheus: Inducing fine-grained evaluation capability in language models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.08491</idno>
		<ptr target="http://arxiv.org/abs/2310.08491" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b612">
	<monogr>
		<title level="m" type="main">MVBench: A comprehensive multi-modal video understanding benchmark</title>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.17005</idno>
		<ptr target="http://arxiv.org/abs/2311.17005" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b613">
	<monogr>
		<title level="m" type="main">What makes good data for alignment? a comprehensive study of automatic data selection in instruction tuning</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.15685</idno>
		<ptr target="http://arxiv.org/abs/2312.15685" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b614">
	<monogr>
		<title level="m" type="main">Aria everyday activities dataset</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Charron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Moulon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.13349</idno>
		<ptr target="http://arxiv.org/abs/2402.13349" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>cs visited on 05/29/2024</note>
</biblStruct>

<biblStruct xml:id="b615">
	<monogr>
		<title level="m" type="main">ExpertQA: Expert-curated questions and attributed answers</title>
		<author>
			<persName><forename type="first">C</forename><surname>Malaviya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sieber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.07852</idno>
		<ptr target="http://arxiv.org/abs/2309.07852" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b616">
	<monogr>
		<title level="m" type="main">Orca-math: Unlocking the potential of SLMs in grade school math</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Khanpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Awadallah</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.14830</idno>
		<ptr target="http://arxiv.org/abs/2402.14830" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b617">
	<monogr>
		<title level="m" type="main">OpenVid-1m: A large-scale high-quality dataset for text-tovideo generation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Nan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2407.02371</idno>
		<ptr target="http://arxiv.org/abs/2407.02371" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b618">
	<monogr>
		<title level="m" type="main">BiMediX: Bilingual medical mixture of experts LLM</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Mullappilly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.13253</idno>
		<ptr target="http://arxiv.org/abs/2402.13253" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b619">
	<monogr>
		<title level="m" type="main">Aya dataset: An open-access collection for multilingual instruction tuning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vargus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dsouza</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.06619</idno>
		<ptr target="http://arxiv.org/abs/2402.06619" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b620">
	<monogr>
		<title level="m" type="main">The m-AILABS speech dataset -caito</title>
		<author>
			<persName><forename type="first">I</forename><surname>Solak</surname></persName>
		</author>
		<ptr target="https://www.caito.de/2019/01/03/the-m-ailabs-speech-dataset/" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b621">
	<monogr>
		<title level="m" type="main">Conifer: Improving complex constrained instruction-following ability of large language models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2404.02823</idno>
		<ptr target="http://arxiv.org/abs/2404.02823" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b622">
	<monogr>
		<title level="m" type="main">OpenMathInstruct-1: A 1.8 million math instruction tuning dataset</title>
		<author>
			<persName><forename type="first">S</forename><surname>Toshniwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Moshkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narenthiran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gitman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gitman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.10176</idno>
		<ptr target="http://arxiv.org/abs/2402.10176" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b623">
	<monogr>
		<title level="m" type="main">VidProM: A million-scale real prompt-gallery dataset for text-tovideo diffusion models</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.06098</idno>
		<ptr target="http://arxiv.org/abs/2403.06098" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b624">
	<monogr>
		<title level="m" type="main">SciBench: Evaluating college-level scientific problem-solving abilities of large language models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.10635</idno>
		<ptr target="http://arxiv.org/abs/2307.10635" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b625">
	<monogr>
		<title level="m" type="main">KIWI: A dataset of knowledge-intensive writing instructions for answering research questions</title>
		<author>
			<persName><forename type="first">F</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Soldaini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kuehl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wadden</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.03866</idno>
		<ptr target="http://arxiv.org/abs/2403.03866" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b626">
	<monogr>
		<title level="m" type="main">Magpie: Alignment data synthesis from scratch by prompting aligned LLMs with nothing</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Niu</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2406.08464</idno>
		<idno type="arXiv">arXiv:2406.08464</idno>
		<ptr target="http://arxiv.org/abs/2406.08464" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>cs visited on 10/02/2024</note>
</biblStruct>

<biblStruct xml:id="b627">
	<monogr>
		<title level="m" type="main">AlpaCare:instruction-tuned large language models for medical application</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Petzold</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.14558</idno>
		<ptr target="http://arxiv.org/abs/2310.14558" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

<biblStruct xml:id="b628">
	<monogr>
		<title level="m" type="main">LMSYS-chat-1m: A large-scale real-world LLM conversation dataset</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-L</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.11998</idno>
		<ptr target="http://arxiv.org/abs/2309.11998" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>visited on 05/01/2024</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
