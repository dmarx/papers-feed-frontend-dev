- Decision to adopt Maximal Update Parametrization (µP) for hyperparameter stability
- Choice to integrate Unit Scaling with µP to enhance training dynamics
- Selection of default hyperparameter values for u-µP
- Strategy for hyperparameter sweeping using proxy models
- Implementation of independent search for hyperparameter optimization
- Decision to support out-of-the-box FP8 training
- Choice of transferable hyperparameters for u-µP
- Approach to addressing limitations of standard µP in practice
- Decision to simplify scaling rules compared to µP
- Strategy for ensuring numerical stability during training
- Choice of tensor statistics for initialization in Unit Scaling
- Decision to focus on large language models (LLMs) as the primary application domain
- Approach to handling low-precision training challenges
- Decision to provide a guide and library for u-µP implementation
- Strategy for empirical validation of u-µP effectiveness across different architectures
- Decision to document drawbacks of standard µP and propose solutions through u-µP