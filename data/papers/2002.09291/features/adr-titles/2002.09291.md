- Decision to use Transformer architecture for modeling event sequences
- Choice of self-attention mechanism to capture dependencies
- Decision to generalize Transformer for continuous-time event sequences
- Selection of temporal encoding method for time stamps
- Choice of embedding matrix for event types
- Decision to incorporate relational information in multi-point processes
- Choice of datasets for numerical experiments
- Decision to compare THP with RNN-based models
- Selection of evaluation metrics (likelihood and event prediction accuracy)
- Decision to implement a graph regularization approach for relational graphs
- Choice of optimization techniques for training the model
- Decision to use specific activation functions in the model
- Choice of loss function for training the model
- Decision to implement parallel processing for efficiency
- Choice of hyperparameters for model training
- Decision to publish code for reproducibility and community use