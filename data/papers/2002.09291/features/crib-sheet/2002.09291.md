- **Problem Statement**: Traditional RNN-based point process models struggle with capturing complex short-term and long-term temporal dependencies in event sequence data.

- **Proposed Model**: Transformer Hawkes Process (THP) leverages self-attention to effectively model both short-term and long-term dependencies while maintaining computational efficiency.

- **Key Advantages of THP**:
  - Captures long-term dependencies better than RNNs due to the self-attention mechanism.
  - Allows for parallel processing of events, enhancing scalability.
  - Facilitates training of deeper models compared to RNNs, which are often shallow.

- **Hawkes Process Overview**:
  - Intensity function: 
    \[
    \lambda(t) = \mu + \sum_{j:t_j < t} \psi(t - t_j)
    \]
    where \(\mu\) is the base intensity and \(\psi(\cdot)\) is a decaying function.

- **Neural Hawkes Process**:
  - Generalizes Hawkes process using RNNs to parameterize the intensity function:
    \[
    \lambda(t) = \sum_{k=1}^{K} \lambda_k(t) = \sum_{k=1}^{K} f_k(w_k h(t))
    \]
    where \(f_k(\cdot)\) is a softplus function.

- **Self-Attention Mechanism**:
  - Assigns attention scores to model dependencies among events, allowing adaptive selection of relevant events regardless of temporal distance.

- **Temporal Encoding**:
  - Temporal encoding for event timestamps:
    \[
    [z(t_j)]_i = 
    \begin{cases} 
    \cos\left(\frac{t_j}{10000^{\frac{i-1}{M}}}\right) & \text{if } i \text{ is odd} \\ 
    \sin\left(\frac{t_j}{10000^{\frac{i}{M}}}\right) & \text{if } i \text{ is even} 
    \end{cases}
    \]
  - This encoding captures the temporal information of events.

- **Model Extensions**:
  - THP can incorporate relational graphs to model multiple point processes, enhancing prediction performance by leveraging structural knowledge.

- **Experimental Results**:
  - THP outperforms RNN-based models in likelihood and event prediction accuracy across multiple datasets.

- **Code Availability**: Implementation can be found at [GitHub Repository](https://github.com/SimiaoZuo/Transformer-Hawkes-Process).

- **Future Work**: Explore further applications of THP in diverse domains and refine the model to handle more complex event dynamics.