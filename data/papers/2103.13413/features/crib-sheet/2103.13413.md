- **Dense Vision Transformer (DPT)**: An architecture that replaces convolutional networks with vision transformers for dense prediction tasks, maintaining high-resolution representations throughout processing stages.

- **Key Advantages**:
  - **Global Receptive Field**: Every stage of the transformer has a global receptive field, allowing for fine-grained and coherent predictions.
  - **Constant Dimensionality**: Unlike convolutional networks, DPT maintains a constant dimensionality of representations, avoiding loss of feature granularity.

- **Architecture Overview**:
  - **Encoder-Decoder Structure**: DPT follows a traditional encoder-decoder design, utilizing a vision transformer as the encoder.
  - **Token Assembly**: Tokens from various transformer stages are reassembled into image-like representations at multiple resolutions.

- **Transformer Encoder**:
  - **Bag-of-Words Representation**: Processes image patches as tokens, maintaining spatial resolution throughout transformer layers.
  - **Multi-Headed Self-Attention (MHSA)**: Allows tokens to attend to each other, enhancing global context.

- **Reassemble Operation**:
  - **Formula**: 
    \[
    Reassemble_D^s(t) = (Resample_s \circ Concatenate \circ Read)(t)
    \]
  - **Read Variants**:
    - **Ignore**: Excludes the readout token.
    - **Add**: Adds readout token information to all other tokens.
    - **Project**: Concatenates readout token with others and projects to original feature dimension.

- **Convolutional Decoder**: 
  - Assembles tokens into image-like feature representations, progressively fusing them into final dense predictions.

- **Performance Metrics**:
  - **Monocular Depth Estimation**: Achieved a performance increase of over 28% compared to state-of-the-art fully-convolutional networks.
  - **Semantic Segmentation**: Set a new state of the art on ADE20K with 49.02% mIoU.

- **Fine-Tuning Capability**: DPT can be fine-tuned on smaller datasets (e.g., NYUv2, KITTI, Pascal Context) while achieving state-of-the-art results.

- **Experimental Results**: Demonstrated substantial improvements in dense prediction tasks, particularly with large training datasets.

- **Model Availability**: The models are accessible at [GitHub - Intel ISL DPT](https://github.com/intel-isl/DPT).