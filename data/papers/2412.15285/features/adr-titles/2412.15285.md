- Decision on the two-phase pretraining approach
- Choice of data sources for pretraining
- Criteria for data quality assessment
- Methodology for downsampling data
- Strategy for blending data in phase-1
- Strategy for blending data in phase-2
- Selection of evaluation benchmarks
- Decision on model architecture and size
- Hyperparameter tuning strategies
- Approach to scaling the token horizon
- Rationale for epoch distribution across phases
- Baseline comparisons for data blending strategies
- Assumptions regarding data diversity and quality
- Documentation of experimental setup and configurations
- Analysis of results and findings from experiments
- Guidelines for practitioners on data blend crafting
- Insights on generalizability of findings to larger models
- Considerations for future research directions in LLM pretraining