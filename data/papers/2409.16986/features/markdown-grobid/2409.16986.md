# HARNESSING DIVERSITY FOR IMPORTANT DATA SE-LECTION IN PRETRAINING LARGE LANGUAGE MOD-ELS

## Abstract

## 

Data selection is of great significance in pretraining large language models, given the variation in quality within the large-scale available training corpora. To achieve this, researchers are currently investigating the use of data influence to measure the importance of data instances, i.e., a high influence score indicates that incorporating this instance to the training set is likely to enhance the model performance. Consequently, they select the top-k instances with the highest scores. However, this approach has several limitations. (1) Calculating the accurate influence of all available data is time-consuming. (2) The selected data instances are not diverse enough, which may hinder the pretrained model's ability to generalize effectively to various downstream tasks. In this paper, we introduce Quad, a data selection approach that considers both quality and diversity by using data influence to achieve state-of-the-art pretraining results. To compute the influence (i.e., the quality) more accurately and efficiently, we incorporate the attention layers to capture more semantic details, which can be accelerated through the Kronecker product. For the diversity, Quad clusters the dataset into similar data instances within each cluster and diverse instances across different clusters. For each cluster, if we opt to select data from it, we take some samples to evaluate the influence to prevent processing all instances. Overall, we favor clusters with highly influential instances (ensuring high quality) or clusters that have been selected less frequently (ensuring diversity), thereby well balancing between quality and diversity. Experiments on Slimpajama demonstrate that Quad significantly outperforms other data selection methods with a low FLOPs consumption. Further analysis also validates the effectiveness of our influence calculation. Our code and data are available at ([https://anonymous.4open.science/r/Quad/](https://anonymous.4open.science/r/Quad/)).

## INTRODUCTION

Recently, large language models (LLMs) have significantly advanced the field of artificial intelligence [(Zhao et al., 2023;](#b50)[Hadi et al., 2023;](#b16)[Minaee et al., 2024)](#b24). Due to the unprecedented number of parameters (model size) and the pre-training on huge amount of training data, LLMs are generalizable a broad spectrum of downstream tasks. However, in practice, the computation resources limit both the model size and the volume of data used in pre-training. In this situation, judiciously selecting train datasets is critical for producing highly performance LLMs [(Brown, 2020;](#b3)[Du et al., 2022;](#b8)[Gururangan et al., 2020;](#b15)[Hoffmann et al., 2022;](#b17)[Raffel et al., 2020)](#b31). In particular, the quality of the training datasets vary dramatically, while the LLaMA-3.1 report [(Dubey et al., 2024)](#b9) shows that the use of high quality data in later training stages can greatly improve model performance.

Typical straightforward data selection approaches include rule-based data filtering [(Raffel et al., 2020;](#b31)[Rae et al., 2021)](#b30), querying high-performance models (e.g., GPT-4) [(Wettig et al., 2024;](#b44)[Sachdeva et al., 2024)](#b32), surrogate models [(Lin et al., 2024;](#b19)[Shao et al., 2024)](#b35), etc. Although these methods have achieved success on some datasets and models, they rely on simple heuristics to select training data. Without explicitly measuring the impact of the selected data on the model, these methods tend to produce sub-optimal pretraining results. To address this issue, some researchers [(Xia et al., 2024;](#b45)[Yu et al., 2024)](#b47) start evaluating each data instance by assigning it a score that reflects its impact on the model. Frequently used scoring methods include the influence function [(Xia et al., 2024)](#b45), early loss [(Albalak et al., 2023)](#b1), and perplexity [(Chen et al., 2024)](#b4). Among these methods, the influence function consistently delivers state-of-the-art results by effectively approximating the impact of adding each instance to the training set. A higher score signifies a higher priority for selecting a data instance, and hence the top-k (or gumble top-k) instances with the highest scores are chosen [(Xie et al., 2023;](#b46)[Wettig et al., 2024;](#b44)[Yu et al., 2024)](#b47). However, the above methodologies have the following limitations.

Prohibitive Computation Cost. First, accurately calculating the influence score of one data instance is expensive, because it involves the computation of the Hessian matrix. However, in the LLM pre-training, the number of the candidate data instances is extremely large. It is thus prohibitively expensive to compute the scores for all of the candidates.

Lack of Diversity. Second, assume that all influence scores have been calculated, as shown in Figure [1a](#fig_2). We can see that the top-k instances (e.g., some high-score instances in C 1 ) tend to be closely distributed in the feature space because the influence computation is closely related to the data features. That is, the training instances selected in this way are lack of diversity (e.g., other instances in C 3 with high influence are also worth selecting), while as confirmed by some studies [(Abbas et al., 2023;](#b0)[Tirumala et al., 2023)](#b38), diversifying training samples mitigates overfitting, thereby enhancing the generalizability of the model. Therefore, an effective data training selection method should take both the influence scores and the diversity into consideration.

We thus propose Quad, a scalabe and effective data selection approach, which successfully addressing above challenges, achieves state-of-the-art pretraining results. Initially, Quad organizes the given dataset into clusters where the data instances within each cluster are similar, and those in different clusters exhibit diversity. Hence, we can sample a data subset from a cluster to estimate the accurate average influence of the cluster, so as to represent the cluster quality w.r.t the model performance.

Next, leveraging the property of the attention-based Transformer architecture which is widely adopted by the LLMs, we design a novel method to accurately compute the influence of an instance on LLM pre-training. More specifically, rather than solely relying on the MLP layers to compute the influence [(Koh & Liang, 2017;](#b18)[Yu et al., 2024;](#b47)[Grosse et al., 2023;](#b13)[Engstrom et al., 2024)](#b10), we incorporate the attention layers such that the influence computation considers more semantic information. In addition, given that calculating the Hessian matrix is time-consuming, particularly for attention layers with complex interactions, we incorporate the Kronecker product to approximate the Hessian matrix, thereby greatly expediting the computation. This successfully addresses the computation cost challenge.

To improve diversity, we apply the Multi-Arm Bandit (MAB) technique, where each cluster is regarded as an arm of the MAB. Upon selecting an arm, we draw samples from the cluster to calculate influence scores. Subsequently, Quad iteratively samples from clusters, taking into account both the influence score and data diversity, e.g., whether the cluster has already been sampled. Moreover, because this sampling strategy effectively avoids calculating the influence of all instances, it further speeds up the data selection process.

We summarize our main contributions as follows:

• To balance the quality and diversity, we incorporate an iterative MAB solution to first cluster the data instances and select data instances from these clusters.

• We propose a novel method to compute the influence function in attention-based Transformer architecture, so as to precisely measure the data quality in LLM pre-training.

• Experiments on the widely-used dataset Slimpajama and 9 popular downstream tasks demonstrate that Quad significantly outperforms state-of-art data selection methods by 1.39% in zero-shot accuracy, also with low computation resources consumption.

## RELATED WORK

Rule-based Methods. Initially, researchers often relied on intuition to design hand-crafted heuristics [(Soldaini et al., 2024)](#b36) and [(Penedo et al., 2023)](#b27), aiming to improve data quality. Deduplication is another typical approach for selecting pretraining data, such as [(Penedo et al., 2023)](#b27) and SemDedup [(Abbas et al., 2023)](#b0) which use keyword-based and semantic deduplication, respectively. Additionally, certain approaches employ n-gram similarity [(Gao et al., 2020;](#b12)[Xie et al., 2023)](#b46) to assist in choosing corpora that is semantically aligned with the validation set data. Although these methods effectively filter out noise and redundant data from web sources, they rely on simple heuristics and cannot be well generalized.

LLM As a Selector. Although large models such as GPT-4 can effectively assess data quality due to their semantic comprehension capacity, the metrics utilized to rate data (e.g., writing style, educational value etc.) heavily rely on human intuition [(Wettig et al., 2024;](#b44)[Penedo et al., 2024;](#b28)[Zhang et al., 2024;](#b49)[Gunasekar et al., 2023)](#b14). This often leads to a mismatch between the selected data and the data desired by the model.

Surrogate Models. DeepSeekMath [(Shao et al., 2024)](#b35) proposes an active learning strategy to train a web data classifier. Similarly, in MATES [(Yu et al., 2024)](#b47), a surrogate model was developed to estimate the influence scores of the data instances. RHO-1 [(Lin et al., 2024](#b19)) used a surrogate model trained with high-quality data to perform token-level data filtering. However, these surrogate models are not trained over large-scale data, and thus their generalizatio ability is limited.

Perplexity serves as a metric for selecting high-probability data in a language model. In [(Chen et al., 2024;](#b4)[Marion et al., 2023;](#b21)[Muennighoff et al., 2024;](#b25)[Wenzek et al., 2019)](#b43), perplexity (PPL) is utilized to filter data. As also discussed in Qurating [(Wettig et al., 2024)](#b44), we observe that this method often incorporates a significant amount of simple and redundant data, because they are easy for the model to predict.

Influence Function [(Grosse et al., 2023;](#b13)[Choe et al., 2024)](#b5) demonstrates that influence function can reveal the impact of training data on the performance of large models. Consequently, LESS [(Xia et al., 2024)](#b45) and MATES [(Yu et al., 2024)](#b47) utilize influence functions for selecting data during the SFT and pretraining phases, respectively. For large models, computing influence functions is computationally expensive. [(Grosse et al., 2023)](#b13). Hence, given the large amount of data handled during pretraining, directly using LESS [(Xia et al., 2024)](#b45) for data selection at this stage poses considerable difficulties. To overcome this, MATES [(Yu et al., 2024](#b47)) employs a proxy model to approximate the influence score across the full dataset. However, the limited capacity of this small proxy model hinders its ability to provide accurate influence scores. Furthermore, relying on the influence to select data solely often leads to a lack of diversity in the chosen data.

## METHODS

First, we present our problem statement in §3.1. Next, in §3.2, we explain how our method achieves the balance between quality and diversity in selecting pretraining data. Finally, in §3.3, we introduce how we compute the influence with attention layers more accurately and efficiently. 

## BALANCE BETWEEN QUALITY AND DIVERSITY

As shown in Figure [1b](#fig_2), there are significant variations in the distribution of influence scores among different clusters. To achieve the quality-diversity balance, it is necessary to know the precise average influence score for instances in each cluster. However, Figure [1b](#fig_2) shows that the influence scores for each cluster also fluctuate around the average, indicating a certain level of uncertainty.

Estimating the average with a small sample size will not be accurate enough, while taking a large number of samples to compute the average influence is costly.

Hence, we propose to use the MAB [(Vermorel & Mohri, 2005)](#b41) technique that is capable of making decisions iteratively under uncertainty. At a high level, each cluster represents an arm of the MAB, and during each iteration, a cluster with a high average influence score tends to be selected and sampled. We will then compute the influence of data instances to update the average. Moreover, clusters that are not visited often present significant opportunities for sampling to balance the diversity.

The overall process of this approach is illustrated in Figure [2](#fig_1). Specifically, our method can be divided into the following four steps: First, we sample the top-k clusters with the highest cluster scores (denoted by CS) computed by MAB. Here, the cluster score is determined by both the influence score and the sample frequency. Then we calculate the influence scores for the samples in each cluster (Section 3.3). At this point, we select high scoring samples to be added for training and use their scores to update the cluster score for each cluster. Throughout the iterative process, the MAB algorithm focuses on frequently sampling high-quality clusters that have high influence scores, which also enhances the accuracy of their quality estimation (i.e., updating the average influence I i ). Simultaneously, it ensures diversity by also sampling less-visited clusters. Next, we discuss how to compute and update the cluster score in details.

Cluster Score (CS). The Upper Confidence Bound can effectively balance exploration (i.e., data diversity) and exploitation (i.e., data quality), so we use it as the cluster score to evaluate each cluster, as shown in Equation (1). Specifically, the cluster score is determined by the average influence score Īi and the exploration score

$2 ln j T (Cj ) T (Ci)$, where T (C i ) denotes the frequency of instances sampled from cluster C i , and j T (C j ) denotes the total times of samples taken from all clusters.

$CS i = Īi + α 2 ln j T (C j ) T (C i ) (1)$Update the cluster score. During each iteration, a subset of data B i is sampled from each cluster with a high cluster score (CS). The sum of their influence score I i can be used to denote the impact of the samples from the cluster C i on the model.

$R(C i )+ = z∈Bi I θ (D r , z), T (C i )+ = 1 (2)$where R(C j ) denotes the total reward accumulated by cluster C i over several iterations.Then the average influence score Īi for cluster C i can be represented as Īi = R(Ci) T (Ci) . As the sample size grows, Īi for each cluster C i steadily approaches the exact average influence of the cluster, which can be used to update the cluster scores for all clusters.

Data selection. During each iteration, we pick a small proportion(γ) of data instances from selected clusters. We also require that these instances have influence scores higher than the threshold τ , otherwise we will not select them, which are then added into the training dataset. 

## INFLUENCE CALCULATION WITH ATTENTION LAYERS

Instead of retraining the large model with each data sample z, the impact of z on the model M can be estimated by calculating the influence function for each instance. In this section, we extend the influence calculation to multi-head attention layers and provide acceleration techniques.

$I θ (D r , z) = -∇L(θ, D r )(H + λI) -1 ∇L(θ, z)(3)$In the above equation, I θ (D r , z) denote the influence function of data z on model θ. ∇L(θ, D r ) and ∇L(θ, z) denote the gradient of reference dataset D r and data z, respectively. Since the training of the large model does not often fully converge, resulting in a non-invertible Hessian matrix H, a regularization term λI is introduced [(Bae et al., 2022)](#b2). Equation ( [3](#formula_3)) is typically divided into the following two stages to speed up the computation:

1. Approximate the multiplication of the gradient of the validation set ∇L(θ, D r ) and the inverse Hessian matrix H -1 using the inverse Hessian vector product (iHVP).

2. Compute the dot product between the iHVP and the gradient of each training data point ∇L(θ, z).

While this framework can accelerate the computation of the influence function, scaling it up to large language models (LLMs) with massive parameters is still expensive. Hence, K-FAC [(Martens & Grosse, 2015;](#b22)[Ueno et al., 2020)](#b40) can be used to accelerate the iHVP computation by using the Kronecker product to decompose the Hessian matrix.

The K-FAC approximate the parameters of different MLP layer θ 1 , θ 2 and θ 3 as independent. That's because, during the gradient computation and update process, there are usually only minimal direct dependencies between the gradients of different MLP layers. This is particularly evident during back propagation, where the weight updates for each MLP layer are primarily influenced by the parameters of that specific layer. Therefore, the influence function I θ1,θ2,θ3 (D r , z) in K-FAC method can be expressed as:

$I θ1,θ2,θ3 (D r , z) = I θ1 (D r , z) + I θ2 (D r , z) + I θ3 (D r , z)(4)$In attention mechanisms, there exist complex connections between the Query, Key, and Value layers.

As the right-upper corner of Figure [3](#) shows, separately calculate the hessian matrix of Query, Key and Value layers, will miss massive information of Consequently, it is essential to consider the QKV layers as a unified layer θ qkv when computing the influence function. Therefore, the influence function I θatt (D r , z) can be expressed as:

$I θatt (D r , z) = I θ qkv (D r , z) + I θo (D r , z)(5)$Figure [3](#): Kronecker Product in calculating iHVP

Then, as the right-lower corner of Figure [3](#) shows, by decomposing the Hessian matrix into a kronecker product of smaller matrices and computing the inverse of each smaller matrix, we can avoid directly inverting the entire Hessian matrix, significantly reducing computational cost, and accelerate this process:

Forward propagation:

$Attention(Q, K, V ) = sof tmax( QK T √ d k )V (6)$Backward propagation: Dθ = vec(DW ) = δ ⊗ x (7) Here, ⊗ denotes the Kronecker product, and vec() represents the vectorization operation. Thus, the gradient of θ qkv can be written as:

$Dθ qkv = vec(DW Q ) vec(DW K ) vec(DW V ) = δ q δ k δ v ⊗ x (8) Let δ qkv = δ q δ k δ v$. Then, the Hessian matrix H qkv can be estimates by:

$H qkv = E(Dθ qkv Dθ qkv T ) = E(δ qkv δ T qkv ⊗ x qkv x T qkv ) ≈ E(δ qkv δ T qkv ) ⊗ E(x qkv x T qkv ) = ∆ qkv ⊗ X qkv (9) Also, H o = ∆ o ⊗ X o .$Thus, the iHVP of the attention layer can be estimated as follows:

$H -1 att v att = H -1 qkv v qkv H -1 o v o = (∆ qkv ⊗ X qkv ) -1 v qkv (∆ o ⊗ X o ) -1 v o = (∆ -1 qkv ⊗ X -1 qkv )v qkv (∆ -1 o ⊗ X -1 o )v o = vec(∆ -1 qkv V qkv X -1 qkv ) vec(∆ -1 o V o X -1 o )(10)$where v att , v qkv , v o represent the gradient of reference dataset D r on parameters θ att , θ qkv , θ o , respectively. Thus, the influence score of attention layers can be written as: I θatt = -∇L(θ att , z)H -1 att v att . To avoid the excessive memory usage of validation set gradients, we apply the Johnson-Lindenstrauss Lemma to reduce the dimensionality of both the iHVP computation results and the training data gradients ∇L(θ, z).

## EXPERIMENT

## EXPERIMENT SETUP

Dataset Preparation. We use the entire 627B-token SlimPajama dataset as the candidate pool D c . In the clustering process, the BAAI/bge-large-en-v1.5 model is employed to generate embeddings for the input data, and approximately 600 million data points from the candidate pool D c are clustered into 10,000 groups using the k-means algorithm. We use LAMBADA [(Paperno et al., 2016)](#b26) as our reference set D r , which is a widely used language modeling task and often serves as a validation benchmark for language model pretraining. [(Yu et al., 2024;](#b47)[Xie et al., 2023;](#b46)[Hoffmann et al., 2022)](#b17).

Experimental settings. We train a transformer-based decoder-only language model that contains 1.3B parameters, uses RoPE embeddings [(Su et al., 2023)](#b37), and has a maximum context window of 1024 tokens [(Touvron et al., 2023)](#b39). Following the setting of MATES [(Su et al., 2023)](#b37), 30B tokens out of the 627B are selected for training using Quad and compare with baselines. The learning rate is set to 5 × 10 -5 , the batch size is set to 4096, and the Adam optimizer is employed with hyperparameters β 1 = 0.9, β 2 = 0.95, ϵ = 10 -8 . As for Multi-Armed Badit, we set the α = 0.002 , sample proporation γ = 0.05 and the sample threshold τ as 0.0025.

Baselines. We compare our methods with several baselines. (1) Random samples data from the entire candidate dataset randomly. (2) Qurating uses the large language model to select data. (3) DSIR selects data instances that are similar to the LAMBADA dataset. ( [4](#formula_4)) PPL uses perplexitybased data selection, i.e., selecting data instances with the lowest perplexity scores. ( [5](#formula_5)) MATES trains a surrogate model to evaluate the influence of each data instance on the target model.

Evaluation datasets. To comprehensively evaluate the capabilities of pretrained models, we conduct experiments on various downstream tasks covering three significant categories:

General Knowledge: ARC-C, ARC-E [(Clark et al., 2018)](#b7), and SciQ [(Welbl et al., 2017)](#b42).

Commonsense Reasoning: HellaSwag [(Zellers et al., 2019)](#b48), SIQA [(Sap et al., 2019)](#b34), Wino-Grande [(Sakaguchi et al., 2021)](#b33), Logiqa [(Liu et al., 2020)](#b20).

Reading Comprehension: OpenbookQA [(Mihaylov et al., 2018)](#b23), and BoolQ [(Clark et al., 2019)](#b6).

Evaluations are conducted using the lm-evaluation-harness [(Gao et al., 2023)](#) framework and the average accuracy (i.e., Overall Score) is reported for comparison.

## RESULTS

Overall Performance. As demonstrated in Table [1](#tab_0), our method surpasses all the baseline methods in downstream tasks with zero-shot evaluation. To be specific, we can observe that on General Knowledge and Reading Comprehension tasks, Quad has the improvement of 1.75% and 1.98% respectively compared with Random. Quad outperforms DSIR and Semdedup because they use rule-based heuristics to select data without considering the model. Although PPL and MATES consider the model, they do not perform well because the former one always selects some simple and duplicated instances, and the surrogate model of the latter one is small and lacking of enough training data. Qurating generally performs the best among other baselines, but still worse than our approach, and it incorporates the highest FLOPS(1e19) because of the usage of LLMs for data selection. In terms of the FLOPs, we can observe that except the methods (i.e., DSIR, SemDeDup) that use simple heuristics, we consume minimal computation resources because our MAB solution samples from clusters without considering the entire candidate dataset like PPL, Qurating and MATES.

Effectiveness of MAB. This section evaluates the effectiveness of the MAB approach for data selection in contrast to the straightforward method of choosing the top-k clusters with the highest influence scores for model training. To be specific, we randomly select an equivalent number of data points from the top 150, 500, and 1000 clusters. Figure [4a](#) illustrates the trade-off between data quality and diversity: clusters with higher influence scores do not necessarily enhance model performance on downstream evaluation sets because of their lack of diversity. Hence, the multiarmed bandit method can more effectively capture the trade-off between quality and diversity across clusters, resulting in superior performance on downstream evaluation sets, as opposed to merely choosing the top-k clusters. Effectiveness of Influence Calculation. This experiment studies the effectiveness of our influence calculation method. In this section, we select the top 500 clusters with the highest scores using three methods: (1) no-Hessian (i.e., computing the gradient similarity between training data and reference data [(Pruthi et al., 2020)](#b29)) without considering the Hessian matrix; (2) MLP(i.e., calculating influence function on MLP layers) and ( [3](#formula_3)) Ours (i.e., calculating influence function on both MLP and attention layers). From each cluster, we uniformly sample data to train the large model. As shown in Figure [4b](#), our solution (MLP+Attention) performs better than MLP because the attention layer considers more semantics. no-Hessian performs the worst because it does not precisely capture the impact of training data instances on the model without the Hessian matrix.

Also, we conduct experiments to verify the relationship between the Query, Key, Value matrices, which is shown in Figure [4c](#). In this experiment, we compare the Pearson correlation coefficients between the following three methods and the baseline approach, which computes the influence score for the attention layer without any acceleration. (1) No-Hessian(i.e., computing the gradient similarity between training data and reference data) without considering the Hessian matrix; (2) Independent (i.e., calculating the Hessian matrices of the query, key, and value layers independently) and ( [3](#formula_3)) Ours (i.e., calculating the Hessian matrices of the query, key, and value layers as a whole).

## ABLATION STUDY

This group of experiments performs ablation studies on the hyperparameters of Quad. Figure [4d](#) and Figure [5](#fig_4) show the impact of sample threshold and α respectively.

Sampling Threshold of Influence (τ ). Setting the threshold too high or low will both degrade the model performance. This is because the selected data instances tend to exist in few clusters with high influence scores, resulting in poor diversity. In contrast, when the threshold is set too low, the sampled instances will be from many clusters with low influence scores, which also degrades the model performance.

α for Quality-Diversity Balance. Our approach employs α to balance the diversity and quality in the MAB framework. When α is small, we tend to focus on the several clusters with high influence scores without considering diversity much, so the MAB framework is likely to get stuck in a local optimum. For example, this results in the model enhancing its performance in specific areas (such as Common Sense Reasoning in Figure [5](#fig_4) when α = 1.5e -3), while the performance in other areas (i.e., General Knowledge and Reading Comprehension) is not good enough. Thus the overall score is not the optimal. However, when α is large, the MAB framework focuses too much on diversity without selecting enough high-quality data, which ultimately results in a limited improvement of model performance. 

## CONCLUSION

This paper presents Quad, a method designed to balance both the diversity and quality of data in pretraining data selection. Quad employs the influence function to identify data that benefits the model. First, we group the data into clusters and use a subset from each to represent the influence of the entire cluster. Given that influence scores within a cluster display some uncertainty, we view each cluster as an arm in an MAB framework. This method conducts samplings from high-quality clusters, allowing for more precise estimation of their influence scores and meanwhile maintaining the diversity. Moreover, we extend the influence function to attention layers and enhance the calculation efficiency to better measure the impact of data within each cluster on the model.    [1,345,423,360(1.3B)](#)

## A APPENDIX

![Figure 1: Distribution of influence scores of some sampled data instances.]()

![Figure 2: Overview of Quad]()

![Quad Algorithm Input: Candidate data pool D c , reference set D r , the model θ Output: Selected data D b 1 C = Cluster(D c ); 2 while do 3 C top k = top-k clusters with the highest Cluster Score(CS) ; 4 B top k = mini-batchs sampled from C top k 5 for C i in C top k do 6 R(C j ) += z∈Bi I θ (D r , z), T (C j ) += 1 ; Īi > threshold then D b + = γC i ; 11 end 12 CS i = Īi + α 2 ln j T (Cj ) T (Ci) ; 13 end 14 return D b ;]()

![Figure 4: (a) shows the effectiveness of the MAB method; (b) shows the accuracy of calculating the influence function on MLP and attention layers; (c) shows the correlation between Query, Key, Value layers impact a lot on the accuracy of influence calculation; (d) shows the model performance of varying sample threshold τ .]()

![Figure 5: α for Quality-Diversity Balance.]()

![]()

![Overall Performance]()

![Performance Comparison]()

![Ablation Study of Threshold τ]()

![Ablation Study of α]()

![Effectiveness of Influence Calculation]()

