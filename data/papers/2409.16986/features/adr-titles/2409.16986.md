- Decision to use data influence for measuring the importance of data instances
- Choice of top-k instances selection based on influence scores
- Adoption of clustering for enhancing data diversity
- Implementation of attention layers in influence computation
- Use of the Kronecker product for efficient Hessian matrix approximation
- Selection of Multi-Arm Bandit (MAB) technique for iterative sampling
- Balancing quality and diversity in data selection process
- Decision to evaluate influence scores through sampling rather than full computation
- Choice of Slimpajama dataset for experimental validation
- Strategy for updating cluster scores during the iterative process
- Decision to incorporate exploration and exploitation in cluster scoring
- Use of Upper Confidence Bound (UCB) for cluster score evaluation
- Decision to prioritize clusters with high influence and low sampling frequency
- Choice of metrics for evaluating model performance post-pretraining
- Decision to make code and data publicly available for reproducibility