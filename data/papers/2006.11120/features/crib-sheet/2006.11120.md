- **Continuous Convolution (CC) Layer**: Generalization of standard conv-layer allowing for learned continuous filters over sub-pixel coordinates.
  
- **Dynamic Resizing**: CC layers can resize feature maps to any scale (integer or non-integer) and shape at inference time, enhancing architectural flexibility.

- **Shift-Equivariance**: CC layers enable gradual downscaling, reducing aliasing and improving shift-equivariance compared to traditional strided and transposed convolutions.

- **Misalignment Resolution**: CC layers address inherent misalignments present in standard convolutional layers, improving output consistency.

- **Mathematical Formulation**: 
  - Continuous convolution output:
    \[
    CC{I}[n] = {I_{cont} * K_\theta}(g_n) = \int m \delta(g_n - \tau - m) I[m] K_\theta(\tau) d\tau
    \]
  - Projected grid mapping:
    \[
    g_n = n s + \frac{1}{2} \left( \text{in\_size} - 1 \right) - \frac{1}{2s} \left( \text{out\_size} - 1 \right)
    \]

- **CC Layer Construction**: Comprises four main blocks:
  1. **Projected Grid Calculation**: Maps output pixel coordinates to sub-pixel locations in the input.
  2. **Neighbors Extraction**: Identifies discrete neighbors within the continuous kernel support.
  3. **Weights Calculation**: Uses a learnable model \( K_\theta \) to compute weights based on distances to neighbors.
  4. **Weight Application**: Combines weights and neighbors to produce the output feature map.

- **Training**: CC layers are end-to-end trainable with gradients propagated through the weights tensor to the parameters \( \theta \) of \( K_\theta \).

- **Architectural Implications**: CC layers allow for dynamic layer shapes and gradual architectures, enhancing the design capabilities of CNNs.

- **Comparison with Traditional Methods**: 
  - Strided convolutions: Fixed integer strides, limited resizing capabilities.
  - Transposed convolutions: Prone to checkerboard artifacts.
  - Interpolation methods: Not learnable, limited to scaling without general feature transformations.

- **Applications**: Useful in various domains including image processing, generative models, and tasks requiring flexible feature map sizes.