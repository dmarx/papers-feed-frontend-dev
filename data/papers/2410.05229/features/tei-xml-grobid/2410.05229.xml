<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-10-07">7 Oct 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Iman</forename><surname>Mirzadeh</surname></persName>
							<email>imirzadeh@apple.com.1</email>
						</author>
						<author>
							<persName><forename type="first">Keivan</forename><surname>Alizadeh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hooman</forename><surname>Shahrokhi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Oncel</forename><surname>Tuzel</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Samy</forename><surname>Bengio</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mehrdad</forename><surname>Farajtabar</surname></persName>
							<email>farajtabar@apple.com.1</email>
						</author>
						<title level="a" type="main">GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-10-07">7 Oct 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">0116C4A8EA5E9C013334193B2AED1EF9</idno>
					<idno type="arXiv">arXiv:2410.05229v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-02-21T16:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent advancements in Large Language Models (LLMs) have sparked interest in their formal reasoning capabilities, particularly in mathematics. The GSM8K benchmark is widely used to assess the mathematical reasoning of models on grade-school-level questions. While the performance of LLMs on GSM8K has significantly improved in recent years, it remains unclear whether their mathematical reasoning capabilities have genuinely advanced, raising questions about the reliability of the reported metrics. To address these concerns, we conduct a largescale study on several state-of-the-art open and closed models. To overcome the limitations of existing evaluations, we introduce GSM-Symbolic, an improved benchmark created from symbolic templates that allow for the generation of a diverse set of questions. GSM-Symbolic enables more controllable evaluations, providing key insights and more reliable metrics for measuring the reasoning capabilities of models.Our findings reveal that LLMs exhibit noticeable variance when responding to different instantiations of the same question. Specifically, the performance of all models declines when only the numerical values in the question are altered in the GSM-Symbolic benchmark. Furthermore, we investigate the fragility of mathematical reasoning in these models and demonstrate that their performance significantly deteriorates as the number of clauses in a question increases. We hypothesize that this decline is due to the fact that current LLMs are not capable of genuine logical reasoning; instead, they attempt to replicate the reasoning steps observed in their training data. When we add a single clause that appears relevant to the question, we observe significant performance drops (up to 65%) across all state-of-the-art models, even though the added clause does not contribute to the reasoning chain needed to reach the final answer. Overall, our work provides a more nuanced understanding of LLMs' capabilities and limitations in mathematical reasoning.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Large Language Models (LLMs) have demonstrated remarkable capabilities across various domains, including natural language processing, question answering, and creative tasks <ref type="bibr">(Gunter et al., 2024;</ref><ref type="bibr">OpenAI, 2023;</ref><ref type="bibr">Dubey et al., 2024;</ref><ref type="bibr">Anil et al., 2023;</ref><ref type="bibr">Abdin et al., 2024;</ref><ref type="bibr">Rivière et al., 2024)</ref>. Their potential to perform complex reasoning tasks, particularly in coding and mathematics, has garnered significant attention from researchers and practitioners. However, the question of whether current LLMs are genuinely capable of true logical reasoning remains an important research focus. While some studies highlight impressive capabilities, a closer examination reveals substantial limitations. Literature suggests that the reasoning process in LLMs</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GSM8K</head><p>When Sophie watches her nephew, she gets out a variety of toys for him. The bag of building blocks has 31 blocks in it. The bin of stuffed animals has 8 stuffed animals inside. The tower of stacking rings has 9 multicolored rings on it.Sophie recently bought a tube of bouncy balls, bringing her total number of toys for her nephew up to 62. How many bouncy balls came in the tube?</p><p>Let T be the number of bouncy balls in the tube. After buying the tube of balls, So phie has 31+8+9+ T = 48 + T =62 toys for her nephew. Thus, T =62-48 = &lt;&lt;62-48=14&gt;&gt;14 bouncy balls came in the tube.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GSM Symbolic Template</head><p>When {name} watches her {family}, she gets out a variety of toys for him. The bag of building blocks has {x} blocks in it. The bin of stuffed animals has {y} stuffed animals inside.The tower of stacking rings has {z} multicolored rings on it.{name} recently bought a tube of bouncy balls, bringing her total number of toys she bought for her {family} up to {total}. How many bouncy balls came in the tube? #variables: -name = sample(names) -family = sample(["nephew", "cousin", "brother"]) -x = range(5, 100) -y = range(5, 100) -z = range(5, 100) -total = range(100, 500) -ans = range <ref type="bibr">(85,</ref><ref type="bibr">200)</ref> #conditions: -x + y + z + ans == total Let T be the number of bouncy balls in the tube. After buying the tube of balls, {name} has {x} + {y} + {z} + T = { x + y + z } + T = {total} toys for her {family}.</p><p>Thus, T = {total} -{ x + y + z } = &lt;&lt;{total}-{ x + y + z }={ans}&gt;&gt;{ans} bouncy balls came in the tube.</p><p>Figure <ref type="figure">1</ref>: Illustration of the GSM-Symbolic template creation process. This dataset serves as a tool to investigate the presumed reasoning capabilities of LLMs, enabling the design of controllable mathematical reasoning evaluations with more reliable metrics. Our results reveal that all state-ofthe-art LLMs exhibit significant performance variations, suggesting the fragility or lack of reasoning. is probabilistic pattern-matching rather than formal reasoning <ref type="bibr">(Jiang et al., 2024)</ref>. Although LLMs can match more abstract reasoning patterns, they fall short of true logical reasoning. Small changes in input tokens can drastically alter model outputs, indicating a strong token bias and suggesting that these models are highly sensitive and fragile <ref type="bibr">(Jiang et al., 2024;</ref><ref type="bibr" target="#b21">Shi et al., 2023)</ref>. Additionally, in tasks requiring the correct selection of multiple tokens, the probability of arriving at an accurate answer decreases exponentially with the number of tokens or steps involved, underscoring their inherent unreliability in complex reasoning scenarios <ref type="bibr" target="#b20">(Schaeffer et al., 2023)</ref>. Mathematical reasoning is a crucial cognitive skill that supports problem-solving in numerous scientific and practical applications. Consequently, the ability of large language models (LLMs) to effectively perform mathematical reasoning tasks is key to advancing artificial intelligence and its realworld applications. The GSM8K (Grade School Math 8K) dataset <ref type="bibr" target="#b3">(Cobbe et al., 2021)</ref> has emerged as a popular benchmark for evaluating the mathematical reasoning capabilities of LLMs. While it includes simple math questions with detailed solutions, making it suitable for techniques like Chain-of-Thought (CoT) prompting, it provides only a single metric on a fixed set of questions. This limitation restricts comprehensive insights into the models' mathematical reasoning. Moreover, the popularity and prevalence of GSM8K can increase the risk of inadvertent data contamination. Finally, the static nature of GSM8K does not allow for controllable experiments to understand model limitations, such as behavior under varied conditions or changes in question aspects and difficulty levels.</p><p>To address these limitations, a more versatile and adaptive evaluation framework is needed-one that can generate diverse question variants and adjust complexity levels to better explore the robustness and reasoning abilities of LLMs. This would facilitate a deeper understanding of the strengths and weaknesses of these models in mathematical reasoning tasks. We make the following contributions:</p><p>• We introduce GSM-Symbolic, an enhanced benchmark that generates diverse variants of GSM8K questions using symbolic templates (Sec. 3), as shown in Fig. <ref type="figure">1</ref>. This enables a more nuanced and reliable evaluation of LLMs' performance across various setups, moving beyond single-point accuracy metrics. Our large-scale study on 25 state-of-the-art open and closed models provides significant insights into LLMs' behavior in mathematical reasoning tasks.</p><p>• We question the reliability of currently reported results on GSM8K and demonstrate that the performance of LLMs can be viewed as a distribution with unwarranted variance across different instantiations of the same question. We show that the performance of all models drops on GSM-Symbolic (Sec. 4.1), hinting at potential data contamination.</p><p>• We show that LLMs exhibit more robustness to changes in superficial elements like proper names but are very sensitive to changes in numerical values (Sec. 4.2). We show that performance degradation and variance increase as the number of clauses increases, indicating that LLMs' reasoning capabilities struggle with increased complexity (Sec. 4.3).</p><p>• Finally, we further question the reasoning abilities of LLMs and introduce the GSM-NoOp dataset. By adding seemingly relevant but ultimately irrelevant information to problems, we demonstrate substantial performance drops (up to 65%) across all state-of-the-art models <ref type="bibr">(Sec. 4.4)</ref>. This reveals a critical flaw in the models' ability to discern relevant information for problem-solving, likely because their reasoning is not formal in the common sense term and is mostly based on pattern matching. We show that even when provided with multiple examples of the same question or examples containing similar irrelevant information, LLMs struggle to overcome the challenges posed by GSM-NoOp. This suggests deeper issues in their reasoning processes that cannot be alleviated by in-context shots and needs further investigation.</p><p>Overall, our work provides a comprehensive understanding of the limitations of LLMs in mathematical reasoning. Our results emphasize the need for more reliable evaluation methodologies and further research into the reasoning capabilities of large language models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work: Reasoning &amp; Language Models</head><p>Logical reasoning is a critical trait of intelligent systems. Recent advancements in Large Language Models (LLMs) have demonstrated significant potential across various domains, yet their reasoning abilities remain uncertain and inconsistent. Many works have investigated whether LLMs are truly capable of reasoning by examining how these models solve tasks requiring logical reasoning. One interesting direction focuses on modeling the computation performed by transformers. For example, parallels have been drawn between components such as attention and feed-forward modules and simple computational primitives <ref type="bibr" target="#b25">(Weiss et al., 2021;</ref><ref type="bibr" target="#b28">Zhou et al., 2024)</ref>. <ref type="bibr" target="#b4">Delétang et al. (2023)</ref> demonstrated that transformers fail to generalize on non-regular tasks and showed that structured memory (e.g., memory tape) is necessary for handling complex tasks. This is related to the effectiveness of Chain-of-Thought (CoT) prompting <ref type="bibr" target="#b24">(Wei et al., 2022)</ref> and using scratchpads for LLMs as additional memory for intermediate computations. Overall, current results suggest that while the transformer architecture has limitations and lacks the required expressiveness for solving problems across several complexity classes, these limitations can be alleviated with additional memory (e.g., scratchpads) <ref type="bibr" target="#b13">(Liu et al., 2024)</ref>. However, this still requires generating vast amounts of tokens to solve a problem <ref type="bibr">(Peng et al., 2024;</ref><ref type="bibr" target="#b16">OpenAI, 2024)</ref>. While these works provide insights into the theoretical computational complexity of transformers, in practice, it remains unclear whether these LLMs can perform formal logical reasoning to solve tasks.</p><p>There is a considerable body of work suggesting that the reasoning process in LLMs is not formal <ref type="bibr" target="#b10">(Kambhampati, 2024;</ref><ref type="bibr">Valmeekam et al., 2022</ref><ref type="bibr" target="#b23">Valmeekam et al., , 2024))</ref>, even though it appears that these models understand symbols and can work with them to some limited degree <ref type="bibr" target="#b2">(Boix-Adserà et al., 2024)</ref>. Instead, LLMs likely perform a form of probabilistic pattern-matching and searching to find closest seen data during training without proper understanding of concepts. While this process goes beyond naive memorization of words and the models are capable of searching and matching more abstract reasoning steps, it still falls short of true formal reasoning. For instance, <ref type="bibr">Jiang et al. (2024)</ref> show, with statistical guarantees, that most LLMs still struggle with logical reasoning due to strong token bias, where the reasoning output of the model changes when a single token of input changes. This aligns with our results, which indicate that the performance of models on different instances of the same mathematical question can vary greatly from one instance to another. <ref type="bibr">Li et al. (2024b)</ref> prove that a single transformer layer learns a one-nearest neighbor, which could explain why the reasoning of models is highly sensitive to input tokens. <ref type="bibr" target="#b20">Schaeffer et al. (2023)</ref> argue that when a task requires emitting multiple tokens correctly, the probability of answering correctly decreases exponentially with the number of tokens. <ref type="bibr" target="#b6">Dziri et al. (2023)</ref> represent reasoning tasks as computation graphs and find that full computation subgraphs appear much more frequently in training data for correct predictions than incorrect ones. <ref type="bibr" target="#b18">Razeghi et al. (2022)</ref> show a correlation between frequency in training and test performance, supporting the pattern matching hypothesis.</p><p>Our work builds upon these findings by introducing GSM-Symbolic, an improved benchmark using symbolic templates to generate diverse question variants. This allows us to study mathematical reasoning ability beyond a single performance metric. By evaluating performance on different instantiations and difficulty levels, we draw a comprehensive picture of LLMs' reasoning capabilities.</p><p>Our findings support the hypothesis that current LLMs are not capable of performing formal mathematical reasoning and pave the way for further research on this important topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">GSM-Symbolic</head><p>The GSM8K dataset <ref type="bibr" target="#b3">(Cobbe et al., 2021)</ref> includes over 8000 grade school math questions and answers, divided into 7473 training and 1319 test examples. As shown in Fig. <ref type="figure">1</ref>, the questions are relatively simple, requiring knowledge of only the four main arithmetic operations. However, since GSM8K is a single, popular test set, there is a risk of data contamination, and performance may change significantly with minor modifications to the questions. These limitations have led to efforts to generate new datasets and variants. iGSM <ref type="bibr" target="#b26">(Ye et al., 2024</ref>) is a math dataset created through a synthetic pipeline that captures parameter dependencies in a hierarchical and graph structure. GSM-IC <ref type="bibr" target="#b21">(Shi et al., 2023)</ref> shows that irrelevant context can impair LLM performance, focusing on prompting techniques. Our work, however, suggests a more fundamental issue: LLMs struggle even when given multiple shots of the same question, indicating deeper challenges in problem-solving that cannot be resolved with few-shot prompting or fine-tuning on unseen distractions or variations of the same or different difficulty levels. GSM-Plus <ref type="bibr">(Li et al., 2024a)</ref> introduces variants of GSM8K questions but lacks symbolic templates and has a fixed size and difficulty. GSM1K <ref type="bibr">(Zhang et al., 2024)</ref> mirrors the style and complexity of GSM8K to identify systematic overfitting in existing models, but has a fixed number of examples, and is not publicly available for researchers.</p><p>While the mentioned benchmarks offer a single performance metric on a fixed number of questions, we argue that viewing LLM performance as a distribution across various problem instances provides deeper insights. The design of GSM-Symbolic enables the generation of numerous instances and allows for finer control over question difficulty. We believe our paper contributes to this direction by offering a reliable evaluation framework that underscores the importance of generating multiple instances to assess LLMs' mathematical capabilities and their robustness to diverse problem difficulties and augmentations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">GSM-Symbolic: Template Generation</head><p>Given a specific example from the test set of GSM8K, we create parsable templates as shown in Fig. <ref type="figure">1</ref> (right). The annotation process involves identifying variables, their domains, and necessary conditions to ensure the correctness of both the question and the answer. For instance, since the questions are grade-school level, a common condition is divisibility to ensure the answer is a whole number.</p><p>We use common proper names (e.g., persons, foods, currencies) to streamline template creation.</p><p>After creating the templates, we apply several automated checks to ensure the annotation process is correct. For example, we verify that none of the original variable values appear in the template.</p><p>We also check that the original values satisfy all conditions and that the final answer matches the original question's answer. Once data are generated, 10 random samples per template are reviewed manually. As a final automated check, after evaluating all models, we verify that at least two models answer each question correctly; otherwise, the question is reviewed manually again.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experimental Setup</head><p>While we provide further details on our experimental setup and evaluation in the Appendix, we briefly review the important aspects here: Models. Throughout this work, we report on more than 20 open models of various sizes, ranging from 2B to 27B. Additionally, we include state-of-the-art closed models such as GPT-4o-mini, GPT-4o, o1-mini, and o1-preview. To conserve space, we present results for a few selected models in each experiment, but the full results for all models are available in Tab. 1 of the Appendix A.2. Evaluation Setup Overall, for this work, we conducted nearly 500 total evaluations on various setups. To this end, we maintained a manageable dataset size by using 100 templates and generating 50 samples per template, resulting in 5000 total examples for each benchmark. Therefore, we have 50 datasets of 100 examples each, where each example is a mutation of one of the original 100 examples from GSM8K. Unless stated otherwise, we follow a common evaluation setup on GSM8K and other math benchmarks that includes Chain-of-Thought (CoT) prompting with 8-shots with greedy decoding. However, we note that in our preliminary experiments, the number of shots did not significantly change the performance and conclusions. We provide our prompt template in Fig. <ref type="figure">9</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments &amp; Results</head><p>In this section, we present our main results and postpone complementary findings to the Appendix. We begin our experiments by addressing an important question regarding the reliability of current reported metrics on GSM8K. By studying the distribution of performance on GSM-Symbolic, we demonstrate notable performance variation. More importantly, we observe that the performance of models drops on GSM-Symbolic (Sec. Figure <ref type="figure">2</ref>: The distribution of 8-shot Chain-of-Thought (CoT) performance across 50 sets generated from GSM-Symbolic templates shows significant variability in accuracy among all state-of-the-art models. Furthermore, for most models, the average performance on GSM-Symbolic is lower than on GSM8K (indicated by the dashed line). Interestingly, the performance of GSM8K falls on the right side of the distribution, which, statistically speaking, should have a very low likelihood, given that GSM8K is basically a single draw from GSM-Symbolic.</p><p>that the original GSM8K performance of models is much closer to the performance distribution when only names are changed. However, performance drops more significantly when values are changed, with this trend continuing as both changes are applied simultaneously (Sec. 4.2). We then examine the impact of question difficulty, as indicated by the number of clauses added to or removed from the questions. Our results show that as the number of clauses increases, average performance drops, and the variance in performance increases consistently across all models (Sec. 4.3). Finally, in Sec. 4.4, we tackle a more fundamental question: whether the models truly understand the mathematical concepts. We show that, likely due to potential pattern matching and the fact that the training distribution of models included only necessary information for solving questions, adding seemingly relevant clauses to the question that do not impact the reasoning process required to solve it significantly drops the performance of all models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">How Reliable Are the Current GSM8K Results?</head><p>As our first experiment, we evaluate the performance of several state-of-the-art models on GSM-Symbolic.</p><p>The number of samples and difficulty can be adjusted by modifying variable domains, as we will see in subsequent sections. Fig. <ref type="figure">2</ref> shows the empirical distribution of the performance of models on GSM-Symbolic computed on these 50 datasets. As shown, all models exhibit a non-negligible variance across different sets. For instance, for the Gemma2-9B, the gap between the worst performance and the best performance is more than 12%, while for Phi-3.5-mini, this gap is around 15%. It is interesting that this variation even exists, as the only differences across different instances of each question are the changes in names and values, while the overall reasoning steps needed to solve a question remain the same. Gemma2-2b-it -6.2</p><p>Gemma2-9b -6.2</p><p>Gemma2-9b-it -6.2</p><p>Mistral-7b-it-v0.3 -6.1</p><p>Mathstral-7b-v0.1 -4.8</p><p>Phi-3-medium -4.8</p><p>Phi-3-small -3.9</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gemma2b</head><p>-3.9</p><p>Gemma2b-it -3.7</p><p>Gemma-7b-it -3.4</p><p>Mistral-7b-v0.1</p><formula xml:id="formula_0">-3.0 Phi-3-mini -2.8 Phi-3.5-mini-it -2.4 GPT-4o-mini -2.2 o1-preview -1.4 Gemma2-27b-it -1.3 Llama3-8b-it -0.7 Mistral-7b-v0.3 -0.6 o1-mini -0.3 GPT-4o</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models</head><p>Figure <ref type="figure">3</ref>: The performance of all state-of-the-art models on GSM-Symbolic drops compared to GSM8K.</p><p>Later, we investigate the factors that impact the performance drops in more depth.</p><p>Another noteworthy observation is that the performance (represented by the dashed line in Fig. <ref type="figure">2</ref>) on the original questions from the 100 examples of GSM8K used as templates is often more than one standard deviation away from the center of the GSM-Symbolic performance distribution, frequently on the right side of the distribution (this holds for 21 out of 25 models). One explanation for this could be data contamination, where some of the test examples from GSM8K inadvertently ended up in the training set of these models, leading to an optimistic bias in performance. Fig. <ref type="figure">3</ref> shows the performance drop from GSM8K to GSM-Symbolic for several models. We can see that for models such as Gemma2-9B, Phi-3, Phi-3.5, and Mathstral-7B, the dashed line in Fig. <ref type="figure">2</ref> lies on the right side, and the drop in performance is higher than for models such as Llama3-8b and GPT-4o, where the performance on GSM8K is close to the center of the GSM-Symbolic distribution and the drop in performance is negligible. In Appendix A.3, we present further results to support this claim for other models such as Phi-2 and Mistral-7B. These results lead us to investigate the fragility of the reasoning abilities of LLMs in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">How</head><p>Fragile is Mathematical Reasoning in Large Language Models?</p><p>In the previous sub-section, we observed high performance variation across different sets generated from the same templates, along with a performance degradation compared to the original GSM8K accuracy. This suggests that the perceived reasoning process of language models may not be formal and is hence susceptible to changes. One explanation is that these models attempt to perform a kind of in-distribution pattern-matching, aligning given questions and solution steps with similar ones seen in the training data. As no formal reasoning is involved in this process, it could lead to high variance across different instances of the same question. In this sub-section and the next one, we investigate these observations further and we show that several factors contribute to the performance variation of the models. First, we investigate the impact of the type of change to understand the difference between changing names (e.g., person names, places, foods, currencies, etc.) versus changing numbers (i.e., the values of variables). Figure <ref type="figure" target="#fig_2">4</ref> demonstrates that while performance variation persists, the variance is lower when changing names compared to numbers. Notably, the original GSM8K accuracy of models is now much closer to the center of the changed proper names distribution, in contrast to changed numbers or both. Furthermore, a gradual shift in the means of distributions from right to left, along with an increase in variance, is evident across almost all models. It is both striking and concerning that such performance variance exists when only changing proper names, as this level of variability would not be expected from a grade-school student with genuine mathematical understanding. From the results in this section, we observe that by increasing the difficulty of changes (from names to numbers), the performance drops and the variance increases, overall suggesting that the reasoning capabilities of state-of-the-art LLMs are fragile for the aforementioned reasons. Assuming that LLMs are not performing formal reasoning, how important is the question difficulty on the distribution of performance? In the next section, we study this question further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">How Does Question Difficulty Affect Performance Distribution?</head><p>The results in the previous subsection motivate us to study the impact of question difficulty on the mean and variance of the performance distribution. To this end, we generate several new templates from the GSM-Symb, as illustrated in Fig. <ref type="figure" target="#fig_3">5</ref>. First, by removing one clause, we obtain GSM-Symbolic-Minus-1 or GSM-M1 for short. Similarly, we can add one or two clauses to the questions to increase the difficulty, resulting in GSM-Symbolic-Plus-1 (GSM-P1) and GSM-Symbolic-Plus-2 (GSM-P2), respectively<ref type="foot" target="#foot_0">foot_0</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Different Levels of GSM-Symbolic Difficulty</head><p>GSM-Symbolic-M1: To make a call from a phone booth, you must pay $0.6 for each minute of your call. After 10 minutes, that price drops to $0.5 per minute.How much would a 60-minute call cost? GSM-Symbolic: To make a call from a phone booth, you must pay $0.6 for each minute of your call. After 10 minutes, that price drops to $0.5 per minute. How much would a 60-minute call cost? GSM-Symbolic-P1: To make a call from a hotel room phone, you must pay $0.6 for each minute of your call.After 10 minutes, that price drops to $0.5 per minute. After 25 minutes from the start of the call, the price drops even more to $0.3 per minute.How much would a 60-minute call cost? GSM-Symbolic-P2: To make a call from a hotel room phone, you must pay $0.6 for each minute of your call. After 10 minutes, the price drops to $0.5 per minute. After 25 minutes from the start of the call, the price drops even more to $0.3 per minute. If your total bill is more than $10, you get a 25% discount. How much would a 60-minute call cost?  As shown in Fig. <ref type="figure" target="#fig_4">6</ref>, the trend of the evolution of the performance distribution is very consistent across all models: as the difficulty increases, the performance decreases and the variance increases.</p><p>Note that overall, the rate of accuracy drop also increases as the difficulty increases. This is in line with the hypothesis that models are not performing formal reasoning, as the number of required reasoning steps increases linearly, but the rate of drop seems to be faster. Moreover, considering the pattern-matching hypothesis, the increase in variance suggests that searching and pattern-matching become significantly harder for models as the difficulty increases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GSM-NoOp</head><p>Oliver picks 44 kiwis on Friday. Then he picks 58 kiwis on Saturday. On Sunday, he picks double the number of kiwis he did on Friday, but five of them were a bit smaller than average. How many kiwis does Oliver have? o1-mini: Oliver picks kiwis over three days as follows:</p><p>-Friday: 44 kiwis -Saturday: 58 kiwis -Sunday: Double the number he picked on Friday, which is 2 × 44 = 88 kiwis However, on Sunday, 5 of these kiwis were smaller than average. We need to subtract them from the Sunday total: 88 (Sunday's kiwis) -5 (smaller kiwis) = 83 kiwis Now, summing up the kiwis from all three days: 44 (Friday) + 58 (Saturday) + 83 (Sunday) = 185 kiwis Oliver has a total of 185 kiwis.</p><p>Llama3-8B: Let's break it down step by step: Oliver picks 44 kiwis on Friday. He picks 58 kiwis on Saturday. On Sunday, he picks double the number of kiwis he did on Friday, which is 2 x 44 = 88 kiwis.</p><p>Five of the kiwis picked on Sunday are a bit smaller than average, so we subtract 5 from the total number of kiwis picked on Sunday: 88 -5 = 83 kiwis. Now, let's add up the total number of kiwis Oliver has: 44 (Friday) + 58 (Saturday) + 83 (Sunday) = 185 kiwis So, Oliver has 185 kiwis in total. We add seemingly relevant statements to the questions that are, in fact, irrelevant to the reasoning and conclusion. However, the majority of models fail to ignore these statements and blindly convert them into operations, leading to mistakes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Can LLMs Really Understand Mathematical Concepts?</head><p>In the previous sections, we studied the impact of type of change and difficulty on the performance distribution. In this section, we demonstrate that models are susceptible to catastrophic performance drops on instances not part of the training distribution, potentially due to their reliance on indistribution pattern-matching. We introduce GSM-NoOp, a dataset designed to challenge the reasoning capabilities of language models. To create the templates, we add seemingly relevant but ultimately inconsequential statements to GSM-Symbolic templates. Since these statements carry no operational significance, we refer to them as "No-Op". These additions do not affect the reasoning required to solve the problem. Fig. <ref type="figure" target="#fig_5">7</ref> illustrates an example from GSM-NoOp. An interesting observation is that models tend to blindly subtract the number of smaller fruits, potentially because their training datasets included similar examples that required conversion to subtraction operations. In the Appendix, we include additional failure cases from GSM-NoOp. Overall, we find that models tend to convert statements to operations without truly understanding their meaning. For instance, a common case we observe is that models interpret statements about "discount" as "multiplication", regardless of the context. This raises the question of whether these models have truly understood the mathematical concepts well enough. Consequently, as shown in Fig. <ref type="figure" target="#fig_8">8a</ref>, there is a catastrophic performance decline across all tested models, with the Phi-3-mini model experiencing over a 65% drop, and even stronger models such as o1-preview showing significant declines.</p><p>To better understand this performance drop, we conducted another experiment. While our previous evaluations on GSM-P2 used the original 8-shots of GSM8K, here we explore two new scenarios where we change the source of the 8-shots. We report the results in Figures <ref type="figure" target="#fig_8">8b</ref> and <ref type="figure" target="#fig_8">8c</ref>.   Gemma-7b-it -17.5 o1-preview 87.3 82.5 29.4 30.2 22.6 Questions Shot Source Phi-3-medium-128k-instruct GSM GSM Symb GSM NoOp GSM NoOp Symb NoOp NoOp 0 10 20 30 40 50 60 70 8-shot Accuracy(%) 76.0 74.6 18.6 19.6 19.2 Questions Shot Source Llama3-8b-instruct (b) GSM GSM Symb GSM NoOp GSM NoOp Symb NoOp NoOp 0 10 20 30 40 50 8-shot Accuracy(%) 12.1 8.2 4.7 48.3 3.1 Questions Shot Source Gemma2b GSM GSM Symb GSM NoOp GSM NoOp Symb NoOp NoOp 0 10 20 30 40 50 60 8-shot Accuracy(%) 44.5 41.1 16.2 62.5 14.5 Questions Shot Source Mistral-7b-v0.1 (c) As previously demonstrated, performance on GSM-Symbolic is very close to that on GSM8K. However, on GSM-NoOp, the significant drop in performance cannot be recovered, even when using the exact same question's variation as shots (NoOp-Symb) or when using different questions with different GSM-NoOpthat contain No-Op operations (NoOp-NoOp) as shots. (c) Notably, some models that perform significantly worse than those in (b) on GSM8K and GSM-Symbolic show much better performance on NoOp-Symb.</p><p>• NoOp-Symb (Using GSM-Symbolic shots of the same question): During evaluation, we include 8 different shots of the same question coming from GSM-Symbolic. Hence, each shot provides the required reasoning steps. The target question from GSM-NoOp then presents yet another variation of the same question that is different only in values and the added clause that is inconsequential. This setup should simplify the task by making it clear that the extra information in the target question is irrelevant. However, as shown in Fig. <ref type="figure" target="#fig_8">8b</ref>, the performance remains within the standard deviation, even with 8 shots of the same question providing the reasoning chain. Interestingly, Fig. <ref type="figure" target="#fig_8">8c</ref> shows that some models can perform significantly better, even though they don't perform nearly as well on GSM8K and GSM-Symbolic. We believe this is a very notable observation.</p><p>• NoOp-NoOp (Using GSM-NoOp shots of different questions): Here, we provide 8 shots chosen randomly from different questions of GSM-NoOp in the context. These questions share the common fact that the correct answer should ignore the No-Op statement. We observe that for the Llama-3-8B model, the performance remains the same compared to the original No-Op model, while for the Phi-3 model, performance slightly decreases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this work, we have investigated the reasoning capabilities of large language models (LLMs) and the limitations of current evaluations on GSM8K. We introduced GSM-Symbolic, a novel benchmark with multiple variants designed to provide deeper insights into the mathematical reasoning abilities of LLMs. Our extensive study reveals significant performance variability across different instantiations of the same question, challenging the reliability of current GSM8K results that rely on single-point accuracy metrics. We found that while LLMs exhibit some robustness to changes in proper names, they are more sensitive to variations in numerical values. We have also observed the performance of LLMs deteriorating as question complexity increases.</p><p>The introduction of GSM-NoOp exposes a critical flaw in LLMs' ability to genuinely understand mathematical concepts and discern relevant information for problem-solving. Adding seemingly relevant but ultimately inconsequential information to the logical reasoning of the problem led to substantial performance drops of up to 65% across all state-of-the-art models. Importantly, we demonstrate that LLMs struggle even when provided with multiple examples of the same question or examples containing similar irrelevant information. This suggests deeper issues in their reasoning processes that cannot be easily mitigated through few-shot learning or fine-tuning. Ultimately, our work underscores significant limitations in the ability of LLMs to perform genuine mathematical reasoning. The high variance in LLM performance on different versions of the same question, their substantial drop in performance with a minor increase in difficulty, and their sensitivity to inconsequential information indicate that their reasoning is fragile. It may resemble sophisticated pattern matching more than true logical reasoning. We remind the reader that both GSM8K and GSM-Symbolic include relatively simple grade-school math questions, requiring only basic arithmetic operations at each step. Hence, the current limitations of these models are likely to be more pronounced in more challenging mathematical benchmarks.</p><p>We believe further research is essential to develop AI models capable of formal reasoning, moving beyond pattern recognition to achieve more robust and generalizable problem-solving skills. This remains a critical challenge for the field as we strive to create systems with human-like cognitive abilities or general intelligence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Full Results</head><p>In Tab. 1, we present the comprehensive performance results of various models, including Gemma (Mesnard et al., 2024), Gemma2 <ref type="bibr">(Rivière et al., 2024</ref><ref type="bibr">), Phi (Abdin et al., 2024)</ref>, Mistral <ref type="bibr" target="#b6">(Jiang et al., 2023)</ref>, Llama3 <ref type="bibr">(Dubey et al., 2024)</ref>, <ref type="bibr">GPT-4o (OpenAI, 2023)</ref>, and the o1 (OpenAI, 2024) series, on GSM8K and its different variants, GSM-Symbolic.</p><p>We report two sets of results for GSM8K: the first column indicates the accuracy on the full test set of GSM8K (comprising 1,319 examples), while the second column shows the accuracy on a subset of 100 questions from the GSM8K test set, which we randomly selected to generate GSM-Symbolic templates.</p><p>It is noteworthy that the performance levels across both sets are very similar, with no significant differences observed. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GSM-NoOp</head><p>Liam wants to buy some school supplies. He buys 24 erasers that now cost $6.75 each, 10 notebooks that now cost $11.0 each, and a ream of bond paper that now costs $19. How much should Liam pay now, assuming that due to inflation, prices were 10% cheaper last year?</p><p>o1-preview: To solve the problem, we need to calculate how much Liam should pay, considering that last year's prices were 10% cheaper due to inflation. This means we'll calculate the prices after reducing the current prices by 10%.</p><p>Step 1: Calculate last year's prices by reducing the current prices by 10%.</p><p>-Eraser price last year: $6.75 × 0.90 = $6.075 -Notebook price last year: $11.00 × 0.90 = $9.90 -Bond paper price last year: $19.00 × 0.90 = $17.10</p><p>Step 2: Calculate the total cost using last year's prices.</p><p>-Total cost for erasers: 24 erasers × $6.075 = $145.80 -Total cost for notebooks: 10 notebooks × $9.90 = $99.00 -Total cost for bond paper: 1 ream × $17.10 = $17.10</p><p>Step 3: Sum up all the costs to get the total amount Liam should pay. $145.80 + $99.00 + $17.10 = $261.90</p><p>Answer:$261.90</p><p>Figure <ref type="figure">13</ref>: Sample response from o1-preview on an example from GSM-NoOp: the model blindly applies the inflation rate, even though the inflation amount is irrelevant as the question clearly indicates the given prices are for "now" and not last year.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GSM-NoOp</head><p>A loaf of sourdough at the cafe costs $9. Muffins cost $3 each. If we purchase 10 loaves of sourdough and 10 muffins, how much more do the sourdough loaves cost compared to the muffins, if we plan to do nate 3 loaves of sourdough and 2 muffins from this purchase? o1-preview:</p><p>To solve this problem, we need to compare the total cost of the sourdough loaves and muffins after considering the donated items.</p><p>Step 1: Calculate the number of items kept after donations.</p><p>-Sourdough loaves kept: 10 loaves -3 donated = 7 loaves -Muffins kept: 10 muffins -2 donated = 8 muffins</p><p>Step 2: Calculate the total cost of the items kept.</p><p>-Total cost of sourdough loaves: 7 loaves × $9 = $63 -Total cost of muffins: 8 muffins × $3 = $24</p><p>Step 3: Find the difference in total cost.</p><p>-Difference: $63 -$24 = $39</p><p>Answer:$39 o1-mini: Let's break down the costs step by step to determine how much more the sourdough loaves cost compared to the muffins after accounting for the donations.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><figDesc>4.1).Next, we investigate the fragility of reasoning in LLMs by comparing performance distributions when only proper names are changed versus when values and numbers are altered. Our findings indicate</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure4: How sensitive are LLMs when we change only names, only proper numbers, or both names and numbers? Overall, models have noticeable performance variation even if we only change names, but even more when we change numbers or combine these changes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Modifying the difficulty level of GSM-Symbolic by modifying the number of clauses.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure6: The impact of increasing the number of clauses on performance: As the difficulty increases from GSM-M1→ GSM-Symb→ GSM-P1→ GSM-P2, the distribution of performance shifts to the left (i.e., accuracy decreases), and the variance increases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: An example from the GSM-NoOp dataset:We add seemingly relevant statements to the questions that are, in fact, irrelevant to the reasoning and conclusion. However, the majority of models fail to ignore these statements and blindly convert them into operations, leading to mistakes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Figure8: (a) The performance of models drops significantly on GSM-NoOp, with more recent models experiencing a greater decline than older ones. (b) As previously demonstrated, performance on GSM-Symbolic is very close to that on GSM8K. However, on GSM-NoOp, the significant drop in performance cannot be recovered, even when using the exact same question's variation as shots (NoOp-Symb) or when using different questions with different GSM-NoOpthat contain No-Op operations (NoOp-NoOp) as shots. (c) Notably, some models that perform significantly worse than those in (b) on GSM8K and GSM-Symbolic show much better performance on NoOp-Symb.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><figDesc>Costs After DonationTo find the effective cost of what you're actually keeping (i.e., not donating): the donations, the sourdough loaves cost $39 more than the muffins.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 14 :</head><label>14</label><figDesc>Figure14: Sample response from o1-preview and o1-mini on an example from GSM-NoOp: while the donation amount is irrelevant to the price difference, the models subtract the amount we donate.22</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Full 8-shot results of all models on GSM8Kand different variants of GSM-Symbolic.</figDesc><table><row><cell>Model</cell><cell>GSM8K (Full)</cell><cell>GSM8K (100)</cell><cell>Symbolic-M1</cell><cell>Symbolic</cell><cell cols="3">Symbolic-P1 Symbolic-P2 Symbolic-NoOp</cell></row><row><cell>Gemma2b</cell><cell>12.1</cell><cell>11.0</cell><cell>24.5 (± 3.85)</cell><cell>8.2 (± 2.21)</cell><cell>3.6 (± 2.13)</cell><cell>1.5 (± 1.63)</cell><cell>4.7 (± 1.99)</cell></row><row><cell>Gemma2b-it</cell><cell>12.1</cell><cell>11.0</cell><cell>16.2 (± 3.28)</cell><cell>8.2 (± 2.21)</cell><cell>1.5 (± 1.49)</cell><cell>1.5 (± 1.63)</cell><cell>4.1 (± 2.48)</cell></row><row><cell>Gemma-7b</cell><cell>53.8</cell><cell>50.0</cell><cell>34.1 (± 4.41)</cell><cell cols="2">25.6 (± 3.25) 26.0 (± 5.30)</cell><cell>3.1 (± 1.92)</cell><cell>8.7 (± 2.71)</cell></row><row><cell>Gemma-7b-it</cell><cell>29.3</cell><cell>33.0</cell><cell>34.1 (± 4.41)</cell><cell>25.6 (± 3.25)</cell><cell>6.0 (± 3.38)</cell><cell>3.1 (± 1.92)</cell><cell>8.7 (± 2.71)</cell></row><row><cell>Gemma2-2b</cell><cell>47.5</cell><cell>46.0</cell><cell>57.2 (± 3.40)</cell><cell cols="2">40.1 (± 3.04) 19.5 (± 3.89)</cell><cell>1.3 (± 1.37)</cell><cell>8.8 (± 4.12)</cell></row><row><cell>Gemma2-2b-it</cell><cell>47.5</cell><cell>46.0</cell><cell>57.2 (± 3.40)</cell><cell cols="2">40.1 (± 3.04) 19.5 (± 3.89)</cell><cell>4.5 (± 1.94)</cell><cell>15.7 (± 3.97)</cell></row><row><cell>Gemma2-9b</cell><cell>85.3</cell><cell>87.0</cell><cell>71.2 (± 2.81)</cell><cell cols="2">79.1 (± 2.99) 44.0 (± 5.69)</cell><cell>41.8 (± 6.00)</cell><cell>22.3 (± 5.11)</cell></row><row><cell>Gemma2-9b-it</cell><cell>85.3</cell><cell>87.0</cell><cell>84.4 (± 2.36)</cell><cell cols="2">79.1 (± 2.99) 68.1 (± 4.77)</cell><cell>41.8 (± 6.00)</cell><cell>22.3 (± 5.11)</cell></row><row><cell>Gemma2-27b-it</cell><cell>89.7</cell><cell>92.0</cell><cell>90.2 (± 1.86)</cell><cell cols="2">88.3 (± 2.56) 80.7 (± 4.07)</cell><cell>63.4 (± 4.14)</cell><cell>30.0 (± 3.39)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>It is important to recognize that adding or removing a clause does not always result in an exact increase or decrease of one in the number of required reasoning steps. In general, the exact number of steps needed to solve a problem is not fixed, as there may be multiple valid solutions for each problem, each requiring a different number of steps. Regardless, our main focus in this section is to understand the evolution of the performance distribution rather than the precise performance metrics.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>The authors would like to thank <rs type="person">Max Horton</rs>, <rs type="person">Fartash Faghri</rs>, <rs type="person">Moin Nabi</rs>, and <rs type="person">Devi Krishna</rs> for the valuable feedback and support.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head><p>In this appendix, we provide additional details to the main text, including:</p><p>• A.1: Detailed experimental setups, including the prompt template.</p><p>• A.2: Full results on GSM8K, GSM-Symbolic, and their variants.</p><p>• A.3: Additional results for the distributional performance of several models, similar to the results from Sec. 4.1 in the main text.</p><p>• A.4: Additional results for Sec. 4.3, where we studied the impact of question difficulty. We show that fine-tuning on easier tasks does not necessarily improve performance on more difficult tasks.</p><p>• A.5: A more comprehensive discussion and analysis of performance for OpenAI o1-mini and o1-preview models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Detailed Experimental Setup</head><p>In this work, all reported evaluations results use 8-shots with chain-of-thought prompting. We use the following prompt format:  Except for the last experiment in Sec. 4.4, we use the original 8 shots from GSM8K. In addition, we allow the models to generate until either their context size limit is reached, they generate one of the end-of-response tokens such as '&lt;/s&gt;' or '&lt;|endoftext|&gt;', or they finish answering the current question and move on to generating the next question, indicated by another 'Q:' generation.</p><p>Finally, we note that in all experiments we use greedy decoding to generate responses from models, with one exception: currently, the available APIs for "o1-mini" and "o1-preview" models do not allow controlling the decoding strategy, and it seems that at the time of writing, these models do not perform greedy decoding, as responses to the same prompt change. Moreover, in Fig. <ref type="figure">11b</ref>, we demonstrate that fine-tuning Phi-3.5 on GSM-P1 slightly improves performance on GSM-P1 while decreasing performance on GSM-P2. We have used a set of 50 templates from GSM-P1, separate from the test templates, and generated 10000 examples for finetuning training set. Overall, while this direction warrants further research, current results suggest that scaling training data will not be helpful in improving the reasoning capabilities of language models. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Results on o1-preview and o1-mini</head><p>The recently released o1-preview and o1-mini models (OpenAI, 2024) have demonstrated strong performance on various reasoning and knowledge-based benchmarks. As observed in Tab. 1, the mean of their performance distribution is significantly higher than that of other open models. In Fig. <ref type="figure">12</ref> (top), we illustrate that both models exhibit non-negligible performance variation. When the difficulty level is altered, o1-mini follows a similar pattern to other open models: as the difficulty increases, performance decreases and variance increases.</p><p>The o1-preview model demonstrates robust performance across all levels of difficulty, as indicated by the closeness of all distributions. However, it is important to note that both o1-preview and o1-mini experience a significant performance drop on GSM-NoOp . In Fig. <ref type="figure">13</ref>, we illustrate that o1-preview struggles with understanding mathematical concepts, naively applying the 10% inflation discussed in </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Sam</forename><forename type="middle">Ade</forename><surname>Marah I Abdin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ammar</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jyoti</forename><surname>Ahmad Awan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Aneja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hany</forename><surname>Awadallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nguyen</forename><surname>Awadalla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amit</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arash</forename><surname>Bahree</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harkirat</forename><forename type="middle">S</forename><surname>Bakhtiari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alon</forename><surname>Behl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Misha</forename><surname>Benhaim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johan</forename><surname>Bilenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Bjorck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caio</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teodoro</forename><surname>César</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parul</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allie</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gustavo</forename><surname>Del Giorno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>De Rosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronen</forename><surname>Dixon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Eldan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amit</forename><surname>Iter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suriya</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emman</forename><surname>Gunasekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junheng</forename><surname>Haider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russell</forename><forename type="middle">J</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Hewett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mojan</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Javaheripi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piero</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikos</forename><surname>Kauffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongwoo</forename><surname>Karampatziakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahoud</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lev</forename><surname>Khademi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">R</forename><surname>Kurilenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhi</forename><surname>Tat Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weishung</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeqi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piyush</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arindam</forename><surname>Madan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hardik</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anh</forename><surname>Modi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barun</forename><surname>Norick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Patra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Perez-Becker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reid</forename><surname>Portet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heyang</forename><surname>Pryzant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marko</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Corby</forename><surname>Radmilac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sambudha</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olatunji</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olli</forename><surname>Ruwase</surname></persName>
		</author>
		<author>
			<persName><surname>Saarikivi ; Sonali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donghan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengruidong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cyril</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><forename type="middle">Lyna</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiren</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2404.14219</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2404.14219" />
		<editor>Amin Saied, Adil Salim, Michael Santacroce, Shital Shah, Ning Shang, Hiteshi Sharma, Xia Song, Masahiro Tanaka, Xin Wang, Rachel Ward, Guanhua Wang, Philipp Witte, Michael Wyatt, Can Xu, Jiahang Xu,</editor>
		<imprint/>
	</monogr>
	<note>Phi-3 technical report: A highly capable language model locally on your phone. CoRR, abs/2404.14219, 2024</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Gemini: A family of highly capable multimodal models</title>
		<author>
			<persName><forename type="first">Rohan</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Baptiste</forename><surname>Alayrac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiahui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johan</forename><surname>Schalkwyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anja</forename><surname>Hauth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katie</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amelia</forename><surname>Glaese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jilin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Pitler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Molloy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">Ronald</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Hennigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Malcolm</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Doherty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eli</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eliza</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erica</forename><surname>Moreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kareem</forename><surname>Ayoub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Megha</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enrique</forename><surname>Piqueras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxim</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iain</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolay</forename><surname>Savinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Becca</forename><surname>Roelofs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anaïs</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anders</forename><surname>Andreassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lakshman</forename><surname>Tamara Von Glehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehran</forename><surname>Yagati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Kazemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Misha</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakub</forename><surname>Khalman</surname></persName>
		</author>
		<author>
			<persName><surname>Sygnowski</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2312.11805</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2312.11805" />
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">When can transformers reason with abstract symbols?</title>
		<author>
			<persName><forename type="first">Enric</forename><surname>Boix-Adserà</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omid</forename><surname>Saremi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emmanuel</forename><surname>Abbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Etai</forename><surname>Littwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">M</forename><surname>Susskind</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=STUGfUz8ob" />
	</analytic>
	<monogr>
		<title level="m">The Twelfth International Conference on Learning Representations, ICLR 2024</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2024">May 7-11, 2024. 2024</date>
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Karl</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Plappert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reiichiro</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.14168</idno>
		<title level="m">Training verifiers to solve math word problems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural networks and the chomsky hierarchy</title>
		<author>
			<persName><forename type="first">Grégoire</forename><surname>Delétang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anian</forename><surname>Ruoss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordi</forename><surname>Grau-Moya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Genewein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elliot</forename><surname>Wenliang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Catt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcus</forename><surname>Cundy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shane</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Legg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><forename type="middle">A</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName><surname>Ortega</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=WbxHAzkeQcn" />
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations, ICLR 2023</title>
		<meeting><address><addrLine>Kigali, Rwanda</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">May 1-5, 2023. 2023</date>
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The llama 3 herd of models</title>
		<author>
			<persName><forename type="first">Abhimanyu</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Jauhri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Kadian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmad</forename><surname>Al-Dahle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aiesha</forename><surname>Letman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akhil</forename><surname>Mathur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Schelten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amy</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anirudh</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Hartshorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aobo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Archi</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Archie</forename><surname>Sravankumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artem</forename><surname>Korenev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Hinsvark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arun</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aston</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurélien</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Austen</forename><surname>Gregerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ava</forename><surname>Spataru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baptiste</forename><surname>Rozière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bethany</forename><surname>Biron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binh</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bobbie</forename><surname>Chern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charlotte</forename><surname>Caucheteux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaya</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chloe</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Marra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Mcconnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christophe</forename><surname>Touret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunyang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Corinne</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristian Canton</forename><surname>Ferrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cyrus</forename><surname>Nikolaidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Damien</forename><surname>Allonsius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danielle</forename><surname>Pintz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danny</forename><surname>Livshits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Esiobu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhruv</forename><surname>Choudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhruv</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>Garcia-Olano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>Perino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dieuwke</forename><surname>Hupkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Egor</forename><surname>Lakomkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ehab</forename><surname>Albadawy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elina</forename><surname>Lobanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hailey</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannah</forename><surname>Korevaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2407.21783</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2407.21783" />
		<editor>Eric Michael Smith, Filip Radenovic, Frank Zhang, Gabriel Synnaeve, Gabrielle Lee, Georgia Lewis Anderson, Graeme Nail, Grégoire Mialon, Guan Pang, Guillem Cucurell,</editor>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Nouha</forename><surname>Dziri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ximing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Sclar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lorraine</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Yuchen Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandra</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Ronan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jena</forename><forename type="middle">D</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumya</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Welleck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allyson</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zaid</forename><surname>Ettinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Harchaoui</surname></persName>
		</author>
		<author>
			<persName><surname>Choi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>Faith and fate: Limits of transformers on compositionality</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Apple intelligence foundation language models</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Gunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zirui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruoming</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aonan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chung-Cheng</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deepak</forename><surname>Gopinath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dian</forename><forename type="middle">Ang</forename><surname>Yap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feng</forename><surname>Nan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Floris</forename><surname>Weers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoli</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoshuo</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiarui</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Peebles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qibin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Keunebroek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Syd</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vivek</forename><surname>Rathod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianzhi</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanghao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongqiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zaid</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaoyang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyun</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Al</forename><surname>Rashid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albin Madappally</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Doane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alfredo</forename><surname>Bencomo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allison</forename><surname>Vanderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anupama</forename><surname>Mann Anupama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Areeba</forename><surname>Kamal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bugu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carolina</forename><surname>Brum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charlie</forename><surname>Maalouf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chinguun</forename><surname>Erdenebileg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dulhanty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduardo</forename><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evan</forename><surname>Ladd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fangping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fred</forename><surname>Hohman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hadas</forename><surname>Kotek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannah</forename><surname>Gillis Coleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jane</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><forename type="middle">P</forename><surname>Bigham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffery</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiulong</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karanjeet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karla</forename><surname>Vega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Heckman</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2407.21075</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2407.21075" />
		<editor>Lauren Gardiner, Margit Bowler, Maria Cordell, Meng Cao, Nicole Hay, Nilesh Shahdadpuri, Otto Godwin, Pranay Dighe, Pushyami Rachapudi, Ramsey Tantawi, Roman Frigg, Sam Davarnia, Sanskruti Shah, Saptarshi Guha, Sasha Sirovica, Shen Ma, Shuang Ma, Simon Wang, Sulgi Kim, Suma Jayaram, Vaishaal Shankar, Varsha Paidi, Vivek Kumar, Xin Wang, Xin Zheng, and Walker Cheng</editor>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Albert</forename><forename type="middle">Q</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Bamford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devendra</forename><surname>Singh Chaplot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>De Las</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gianna</forename><surname>Bressand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lengyel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucile</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><surname>Saulnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renard</forename><surname>Lélio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Anne</forename><surname>Lavaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Stock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibaut</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothée</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">El</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName><surname>Sayed</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2310.06825</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2310.06825" />
	</analytic>
	<monogr>
		<title level="j">Mistral</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">A peek into token bias: Large language models are not yet genuine reasoners</title>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangxinyu</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuoqun</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaomeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanwi</forename><surname>Mallick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weijie</forename><forename type="middle">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Camillo</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2406.11050</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2406.11050" />
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Can large language models reason and plan?</title>
		<author>
			<persName><forename type="first">Subbarao</forename><surname>Kambhampati</surname></persName>
		</author>
		<ptr target="https://api.semanticscholar.org/CorpusID" />
	</analytic>
	<monogr>
		<title level="j">Annals of the New York Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">1534</biblScope>
			<biblScope unit="page">268249961</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Gsm-plus: A comprehensive benchmark for evaluating the robustness of llms as mathematical problem solvers</title>
		<author>
			<persName><forename type="first">Qintong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leyang</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueliang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Bi</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2024.acl-long.163" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">Lun-Wei</forename><surname>Ku</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Andre</forename><surname>Martins</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Vivek</forename><surname>Srikumar</surname></persName>
		</editor>
		<meeting>the 62nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Bangkok, Thailand</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2024">August 11-16, 2024. 2024</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2961" to="2984" />
		</imprint>
	</monogr>
	<note>Long Papers), ACL 2024</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">One-layer transformer provably learns one-nearest neighbor in context</title>
		<author>
			<persName><forename type="first">Zihao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yihan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><forename type="middle">M</forename><surname>Klusowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianqing</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengdi</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="https://api.semanticscholar.org/CorpusID:272307690" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Chain of thought empowers transformers to solve inherently serial problems</title>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=3EWTEy9MTM" />
	</analytic>
	<monogr>
		<title level="m">The Twelfth International Conference on Learning Representations, ICLR 2024</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2024">May 7-11, 2024. 2024</date>
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Mesnard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cassidy</forename><surname>Hardin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Dadashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Surya</forename><surname>Bhupatiraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shreya</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgane</forename><surname>Rivière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihir</forename><surname>Sanjay Kale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juliette</forename><surname>Love</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pouya</forename><surname>Tafti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Léonard</forename><surname>Hussenot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Barua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Botev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Castro-Ros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ambrose</forename><surname>Slone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amélie</forename><surname>Héliou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Tacchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Bulanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonia</forename><surname>Paterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beth</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bobak</forename><surname>Shahriari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charline</forename><forename type="middle">Le</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">A</forename><surname>Choquette-Choo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clément</forename><surname>Crepy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Noland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George-Cristian</forename><surname>Muraru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grigory</forename><surname>Rozhdestvenskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henryk</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Tenney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Grishchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Keeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jane</forename><surname>Labanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Baptiste</forename><surname>Lespiau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Stanway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenny</forename><surname>Brennan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johan</forename><surname>Ferret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Chiu</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2403.08295</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2403.08295" />
		<title level="m">Open models based on gemini research and technology</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">GPT-4 technical report</title>
		<idno type="DOI">10.48550/arXiv.2303.08774</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2303.08774" />
		<imprint>
			<date type="published" when="2023">CoRR, abs/2303.08774, 2023</date>
		</imprint>
		<respStmt>
			<orgName>OpenAI</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Learning to reason with large language models</title>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<ptr target="https://openai.com/index/learning-to-reason-with-llms/" />
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="2024" to="2029" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">On limitations of the transformer architecture</title>
		<author>
			<persName><forename type="first">Binghui</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srini</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><forename type="middle">H</forename><surname>Papadimitriou</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2402.08164</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2402.08164" />
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Impact of pretraining term frequencies on few-shot reasoning</title>
		<author>
			<persName><forename type="first">Yasaman</forename><surname>Razeghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.08904</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Morgane</forename><surname>Rivière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shreya</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pier</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Giuseppe</forename><surname>Sessa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cassidy</forename><surname>Hardin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Surya</forename><surname>Bhupatiraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Léonard</forename><surname>Hussenot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Mesnard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bobak</forename><surname>Shahriari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Ramé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johan</forename><surname>Ferret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pouya</forename><surname>Tafti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abe</forename><surname>Friesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michelle</forename><surname>Casbon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabela</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravin</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charline</forename><forename type="middle">Le</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sammy</forename><surname>Jerome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anton</forename><surname>Tsitsulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nino</forename><surname>Vieillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Stanczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sertan</forename><surname>Girgin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikola</forename><surname>Momchev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shantanu</forename><surname>Thakoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Bastien</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Behnam</forename><surname>Neyshabur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Bachem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alanna</forename><surname>Walton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alicia</forename><surname>Parrish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aliya</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allen</forename><surname>Hutchison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alvin</forename><surname>Abdagic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Carl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amy</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Coenen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Laforge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonia</forename><surname>Paterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Bastian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bilal</forename><surname>Piot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Royal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charlie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chintu</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Perry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Welty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">A</forename><surname>Choquette-Choo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danila</forename><surname>Sinopalnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimple</forename><surname>Vijaykumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominika</forename><surname>Rogozinska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dustin</forename><surname>Herbison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elisa</forename><surname>Bandy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emma</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Noland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erica</forename><surname>Moreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evan</forename><surname>Senter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evgenii</forename><surname>Eltyshev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Visin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gary</forename><surname>Gabriel Rasskin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Glenn</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gus</forename><surname>Cameron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hadi</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanna</forename><surname>Hashemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harleen</forename><surname>Klimczak-Plucinska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harsh</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Dhand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacinda</forename><surname>Nardini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Mein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Svensson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jetha</forename><surname>Stanway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><forename type="middle">Peng</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joana</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joana</forename><surname>Carrasqueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jocelyn</forename><surname>Iljazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joost</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josh</forename><surname>Van Amersfoort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josh</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josh</forename><surname>Lipschultz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ju-Yeong</forename><surname>Newlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kareem</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kartikeya</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kat</forename><surname>Badola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katie</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keelin</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Mcdonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kiranbir</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kish</forename><surname>Sodhia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><forename type="middle">Lowe</forename><surname>Greene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lauren</forename><surname>Sjösund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Usui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lena</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leticia</forename><surname>Heuermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lilly</forename><surname>Lago</surname></persName>
		</author>
		<author>
			<persName><surname>Mcnealus</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2408.00118</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2408.00118" />
	</analytic>
	<monogr>
		<title level="j">Gemma</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>Improving open language models at a practical size. CoRR, abs/2408.00118, 2024</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Are emergent abilities of large language models a mirage?</title>
		<author>
			<persName><forename type="first">Rylan</forename><surname>Schaeffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brando</forename><surname>Miranda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanmi</forename><surname>Koyejo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Large language models can be easily distracted by irrelevant context</title>
		<author>
			<persName><forename type="first">Freda</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kanishka</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathanael</forename><surname>Schärli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<ptr target="https://proceedings.mlr.press/v202/shi23a.html" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning, ICML 2023</title>
		<editor>
			<persName><forename type="first">Andreas</forename><surname>Krause</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Emma</forename><surname>Brunskill</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Barbara</forename><surname>Engelhardt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Sivan</forename><surname>Sabato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jonathan</forename><surname>Scarlett</surname></persName>
		</editor>
		<meeting><address><addrLine>Honolulu, Hawaii, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023-07">July 2023. 2023</date>
			<biblScope unit="volume">202</biblScope>
			<biblScope unit="page" from="31210" to="31227" />
		</imprint>
	</monogr>
	<note>PMLR</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Large language models still can&apos;t plan (A benchmark for llms on planning and reasoning about change)</title>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Valmeekam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><forename type="middle">Olmo</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarath</forename><surname>Sreedharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subbarao</forename><surname>Kambhampati</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2206.10498</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2206.10498" />
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Llms still can&apos;t plan; can lrms? a preliminary evaluation of openai&apos;s o1 on planbench</title>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Valmeekam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaya</forename><surname>Stechly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subbarao</forename><surname>Kambhampati</surname></persName>
		</author>
		<ptr target="https://api.semanticscholar.org/CorpusID" />
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">272770270</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Chain-of-thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.11903</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Thinking like transformers</title>
		<author>
			<persName><forename type="first">Gail</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eran</forename><surname>Yahav</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v139/weiss21a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Machine Learning, ICML 2021</title>
		<editor>
			<persName><forename type="first">Marina</forename><surname>Meila</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</editor>
		<meeting>the 38th International Conference on Machine Learning, ICML 2021</meeting>
		<imprint>
			<date type="published" when="2021-07-24">18-24 July 2021. 2021</date>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="11080" to="11090" />
		</imprint>
	</monogr>
	<note>Virtual Event PMLR</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Physics of language models: Part 2.1, grade-school math and the hidden reasoning process</title>
		<author>
			<persName><forename type="first">Tian</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zicheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeyuan</forename><surname>Allen-Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2407.20311</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">A careful examination of large language model performance on grade school arithmetic</title>
		<author>
			<persName><forename type="first">Hugh</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dean</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vaughn</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Will</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiffany</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Raja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dylan</forename><surname>Slack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qin</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Hendryx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russell</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Lunati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Summer</forename><surname>Yue</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2405.00332</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2405.00332" />
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">What algorithms can transformers learn? A study in length generalization</title>
		<author>
			<persName><forename type="first">Hattie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arwen</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Etai</forename><surname>Littwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Razin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omid</forename><surname>Saremi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">M</forename><surname>Susskind</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preetum</forename><surname>Nakkiran</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=AssIuHnmHX" />
	</analytic>
	<monogr>
		<title level="m">The Twelfth International Conference on Learning Representations, ICLR 2024</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2024">May 7-11, 2024. 2024</date>
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Phi-3-mini-128k-instruct</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Phi-3-small-128k-instruct</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Phi-3-medium-128k-instruct</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Additional Results on GSM-Symbolic Performance Distributions In section 4.1, we have presented results for several models in Fig. 2. Here, we provide additional results showing the performance on GSM-Symbolic for other models also have high variance. Moreover, these models correspond to highest drop</title>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
		<imprint/>
	</monogr>
	<note>We also report the results for all models in table 1</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">that the performance on GSM-P2 is significantly lower than the performance on GSM-P1. We also argued that it is unlikely that additional fine-tuning or including shots from GSM-P1 would be beneficial. Here, in Fig. 11a, we show that including shots from GSM-P1 does not improve performance compared to the results where shots come solely from</title>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
		<imprint>
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
	<note>In Sec. 4.3, we observed Ablation: Does Fine-Tuning on Easier Tasks Help with More Difficult Tasks?</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
