- **Title**: Hallo3: Highly Dynamic and Realistic Portrait Image Animation with Diffusion Transformer Networks

- **Key Contributions**:
  - First application of a pretrained transformer-based video generative model for portrait animation.
  - Addresses challenges in nonfrontal perspectives, dynamic objects, and immersive backgrounds.

- **Identity Reference Network**:
  - Combines a causal 3D VAE with stacked transformer layers.
  - Ensures consistent facial identity across video sequences by embedding identity information into denoising latent codes.

- **Speech Audio Conditioning**:
  - High alignment between speech audio and facial expression dynamics.
  - Utilizes adaptive layer normalization and cross-attention strategies for integrating audio embeddings.

- **Video Extrapolation**:
  - Proposes a strategy for long-duration video generation using motion frames as conditional inputs.
  - Final frames of generated videos serve as inputs for subsequent clip generation.

- **Methodology Overview**:
  - Baseline model: CogVideoX with 3D VAE for video data compression.
  - Textual inputs encoded using T5 architecture; latent variables reshaped into sequential format \( z_t \).
  - Incorporates 3D Rotational Positional Encoding (3D RoPE) for capturing inter-frame relationships.

- **Conditioning Mechanisms**:
  - Four primary mechanisms: in-context conditioning, cross-attention, adaptive layer normalization (adaLN), and adaLN-zero.
  - Focus on cross-attention and adaLN for effective conditional information processing.

- **Audio-Driven Transformer Diffusion**:
  - Utilizes wav2vec for audio feature extraction, defined as \( c_{audio} \).
  - Audio embeddings concatenated from the final twelve layers of wav2vec for comprehensive semantic representation.

- **Mathematical Representation of Audio Transformation**:
  - Frame-specific audio representation transformation: 
  \[
  c(f)_{audio} = L_3(L_2(L_1(c_{audio})))
  \]
  where \( L_1, L_2, L_3 \) are linear transformation functions.

- **Experimental Validation**:
  - Validated on benchmark datasets (HTDF, Celeb-V) showing substantial improvements over prior methods.
  - Capable of generating dynamic foregrounds and backgrounds with complex poses.

- **Applications**:
  - Relevant for film production, game development, social media content creation, and online education.

- **Source Code and Visualizations**: Available at [Hallo3 Project Page](https://fudan-generative-vision.github.io/hallo3).