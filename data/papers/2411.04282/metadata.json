{
  "arxivId": "2411.04282",
  "title": "Language Models are Hidden Reasoners: Unlocking Latent Reasoning\n  Capabilities via Self-Rewarding",
  "authors": "Haolin Chen, Yihao Feng, Zuxin Liu, Weiran Yao, Akshara Prabhakar, Shelby Heinecke, Ricky Ho, Phil Mui, Silvio Savarese, Caiming Xiong, Huan Wang",
  "abstract": "Large language models (LLMs) have shown impressive capabilities, but still\nstruggle with complex reasoning tasks requiring multiple steps. While\nprompt-based methods like Chain-of-Thought (CoT) can improve LLM reasoning at\ninference time, optimizing reasoning capabilities during training remains\nchallenging. We introduce LaTent Reasoning Optimization (LaTRO), a principled\nframework that formulates reasoning as sampling from a latent distribution and\noptimizes it via variational approaches. LaTRO enables LLMs to concurrently\nimprove both their reasoning process and ability to evaluate reasoning quality,\nwithout requiring external feedback or reward models. We validate LaTRO through\nexperiments on GSM8K and ARC-Challenge datasets using multiple model\narchitectures. On GSM8K, LaTRO improves zero-shot accuracy by an average of\n12.5% over base models and 9.6% over supervised fine-tuning across\nPhi-3.5-mini, Mistral-7B, and Llama-3.1-8B. Our findings suggest that\npre-trained LLMs possess latent reasoning capabilities that can be unlocked and\nenhanced through our proposed optimization approach in a self-improvement\nmanner. The code of LaTRO is available at\n\\url{https://github.com/SalesforceAIResearch/LaTRO}.",
  "url": "https://arxiv.org/abs/2411.04282",
  "issue_number": 169,
  "issue_url": "https://github.com/dmarx/papers-feed/issues/169",
  "created_at": "2025-01-05T08:23:47.508546",
  "state": "open",
  "labels": [
    "paper",
    "rating:novote"
  ],
  "total_reading_time_seconds": 0,
  "last_read": null,
  "last_visited": "2024-12-22T21:35:41.978Z",
  "main_tex_file": null,
  "published_date": "2024-11-06T22:02:30Z",
  "arxiv_tags": [
    "cs.AI",
    "cs.CL",
    "cs.LG",
    "stat.ML",
    "I.2.7"
  ]
}