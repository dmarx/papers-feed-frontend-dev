- **Title**: TransPixar: Advancing Text-to-Video Generation with Transparency
- **Objective**: Develop a framework for RGBA video generation from text using DiT-based models, enabling realistic visual effects through transparency.
- **Key Contributions**:
  - Introduced a novel alpha channel adaptive attention mechanism.
  - Achieved simultaneous generation of RGB and alpha channels, enhancing RGBA video quality.
  - Utilized LoRA-based fine-tuning to maintain RGB generation quality while adapting to alpha tokens.
- **Method Overview**:
  - **Model Architecture**: Extends pretrained DiT models to generate RGB and alpha channels together.
  - **Token Structure**: Sequence includes text, RGB, and alpha tokens; employs a 3x3 grouped attention matrix.
  - **Attention Mechanisms**:
    - Text-attend-to-RGB: Original model's generation capabilities.
    - RGB-attend-to-Alpha: Necessary for refining RGB tokens based on alpha information.
    - Text-attend-to-Alpha: Removed to reduce performance degradation risk.
- **Attention Formula**: 
  \[
  Attention(Q, K, V) = softmax\left(\frac{QK^T}{\sqrt{d_k}}\right)V
  \]
- **Positional Encoding**:
  - Absolute positional encoding for RGB and alpha tokens:
  \[
  f_z(z \in \{q,k,v\})(x_{video}) := W_z(z \in \{q,k,v\})(x_m + p_m)
  \]
  - Shared positional encoding for RGB and alpha tokens to minimize spatial-temporal alignment challenges.
- **LoRA Fine-Tuning**:
  - Applied only to alpha tokens to control residual strength:
  \[
  W^*_z(z \in \{q,k,v\})(x_m + p_m-L + d) = W_z(z \in \{q,k,v\})(x_m + p_m-L + d) + \gamma \cdot LoRA(x_m + p_m-L + d)
  \]
- **Training Data Limitation**: Only ~484 RGBA videos available, necessitating innovative approaches to generate diverse content.
- **Applications**: Valuable for VFX, gaming, VR, and AR, where dynamic and interactive content is essential.
- **Validation**: Extensive experiments demonstrate effectiveness across various challenging scenarios.