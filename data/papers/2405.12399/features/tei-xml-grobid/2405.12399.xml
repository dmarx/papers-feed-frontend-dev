<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Diffusion for World Modeling: Visual Details Matter in Atari †</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-10-30">30 Oct 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Eloi</forename><surname>Alonso</surname></persName>
							<email>eloi.alonso@unige.ch</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Geneva</orgName>
								<orgName type="institution" key="instit2">University of Edinburgh</orgName>
								<orgName type="institution" key="instit3">University of Geneva</orgName>
								<orgName type="institution" key="instit4">Microsoft Research</orgName>
								<orgName type="institution" key="instit5">University of Edinburgh</orgName>
								<orgName type="institution" key="instit6">Microsoft Research</orgName>
								<orgName type="institution" key="instit7">University of Geneva</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Adam</forename><surname>Jelley</surname></persName>
							<email>adam.jelley@ed.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Geneva</orgName>
								<orgName type="institution" key="instit2">University of Edinburgh</orgName>
								<orgName type="institution" key="instit3">University of Geneva</orgName>
								<orgName type="institution" key="instit4">Microsoft Research</orgName>
								<orgName type="institution" key="instit5">University of Edinburgh</orgName>
								<orgName type="institution" key="instit6">Microsoft Research</orgName>
								<orgName type="institution" key="instit7">University of Geneva</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vincent</forename><surname>Micheli</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Geneva</orgName>
								<orgName type="institution" key="instit2">University of Edinburgh</orgName>
								<orgName type="institution" key="instit3">University of Geneva</orgName>
								<orgName type="institution" key="instit4">Microsoft Research</orgName>
								<orgName type="institution" key="instit5">University of Edinburgh</orgName>
								<orgName type="institution" key="instit6">Microsoft Research</orgName>
								<orgName type="institution" key="instit7">University of Geneva</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anssi</forename><surname>Kanervisto</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Geneva</orgName>
								<orgName type="institution" key="instit2">University of Edinburgh</orgName>
								<orgName type="institution" key="instit3">University of Geneva</orgName>
								<orgName type="institution" key="instit4">Microsoft Research</orgName>
								<orgName type="institution" key="instit5">University of Edinburgh</orgName>
								<orgName type="institution" key="instit6">Microsoft Research</orgName>
								<orgName type="institution" key="instit7">University of Geneva</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Amos</forename><surname>Storkey</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Geneva</orgName>
								<orgName type="institution" key="instit2">University of Edinburgh</orgName>
								<orgName type="institution" key="instit3">University of Geneva</orgName>
								<orgName type="institution" key="instit4">Microsoft Research</orgName>
								<orgName type="institution" key="instit5">University of Edinburgh</orgName>
								<orgName type="institution" key="instit6">Microsoft Research</orgName>
								<orgName type="institution" key="instit7">University of Geneva</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tim</forename><surname>Pearce</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Geneva</orgName>
								<orgName type="institution" key="instit2">University of Edinburgh</orgName>
								<orgName type="institution" key="instit3">University of Geneva</orgName>
								<orgName type="institution" key="instit4">Microsoft Research</orgName>
								<orgName type="institution" key="instit5">University of Edinburgh</orgName>
								<orgName type="institution" key="instit6">Microsoft Research</orgName>
								<orgName type="institution" key="instit7">University of Geneva</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">François</forename><surname>Fleuret</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Geneva</orgName>
								<orgName type="institution" key="instit2">University of Edinburgh</orgName>
								<orgName type="institution" key="instit3">University of Geneva</orgName>
								<orgName type="institution" key="instit4">Microsoft Research</orgName>
								<orgName type="institution" key="instit5">University of Edinburgh</orgName>
								<orgName type="institution" key="instit6">Microsoft Research</orgName>
								<orgName type="institution" key="instit7">University of Geneva</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Diffusion for World Modeling: Visual Details Matter in Atari †</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-10-30">30 Oct 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">280E3989E13203FD72560935D2E3BD0D</idno>
					<idno type="arXiv">arXiv:2405.12399v2[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-02-21T16:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>World models constitute a promising approach for training reinforcement learning agents in a safe and sample-efficient manner. Recent world models predominantly operate on sequences of discrete latent variables to model environment dynamics. However, this compression into a compact discrete representation may ignore visual details that are important for reinforcement learning. Concurrently, diffusion models have become a dominant approach for image generation, challenging well-established methods modeling discrete latents. Motivated by this paradigm shift, we introduce DIAMOND (DIffusion As a Model Of eNvironment Dreams), a reinforcement learning agent trained in a diffusion world model. We analyze the key design choices that are required to make diffusion suitable for world modeling, and demonstrate how improved visual details can lead to improved agent performance. DIAMOND achieves a mean human normalized score of 1.46 on the competitive Atari 100k benchmark; a new best for agents trained entirely within a world model. We further demonstrate that DIAMOND's diffusion world model can stand alone as an interactive neural game engine by training on static Counter-Strike: Global Offensive gameplay. To foster future research on diffusion for world modeling, we release our code, agents, videos and playable world models at <ref type="url" target="https://diamond-wm.github.io">https://diamond-wm.github.io</ref>.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Generative models of environments, or "world models" <ref type="bibr" target="#b20">(Ha and Schmidhuber, 2018)</ref>, are becoming increasingly important as a component for generalist agents to plan and reason about their environment <ref type="bibr" target="#b38">(LeCun, 2022)</ref>. Reinforcement Learning (RL) has demonstrated a wide variety of successes in recent years <ref type="bibr" target="#b64">(Silver et al., 2016;</ref><ref type="bibr" target="#b12">Degrave et al., 2022;</ref><ref type="bibr" target="#b48">Ouyang et al., 2022)</ref>, but is well-known to be sample inefficient, which limits real-world applications. World models have shown promise for training reinforcement learning agents across diverse environments <ref type="bibr" target="#b23">(Hafner et al., 2023;</ref><ref type="bibr" target="#b62">Schrittwieser et al., 2020)</ref>, with greatly improved sample-efficiency <ref type="bibr" target="#b86">(Ye et al., 2021)</ref>, which can enable learning from experience in the real world <ref type="bibr" target="#b81">(Wu et al., 2023)</ref>.</p><p>Recent world modeling methods <ref type="bibr" target="#b22">(Hafner et al., 2021;</ref><ref type="bibr" target="#b43">Micheli et al., 2023;</ref><ref type="bibr" target="#b56">Robine et al., 2023;</ref><ref type="bibr" target="#b23">Hafner et al., 2023;</ref><ref type="bibr" target="#b88">Zhang et al., 2023)</ref> often model environment dynamics as a sequence of discrete latent variables. Discretization of the latent space helps to avoid compounding error over multi-step time horizons. However, this encoding may lose information, resulting in a loss of generality and reconstruction quality. This may be problematic for more real-world scenarios where the information The environment time t flows along the horizontal axis, while the vertical axis represents the denoising time τ flowing backward from T to 0. Concretely, given (clean) past observations x 0 &lt;t , actions a &lt;t , and starting from an initial noisy sample x T t , we simulate a reverse noising process {x τ t } τ =0 τ =T by repeatedly calling D θ , and obtain the (clean) next observation x 0 t . The imagination procedure is autoregressive in that the predicted observation x 0 t and the action a t taken by the policy become part of the conditioning for the next time step. Animated visualizations of this procedure can be found at <ref type="url" target="https://diamond-wm.github.io">https://diamond-wm.github.io</ref>.</p><p>required for the task is less well-defined, such as training autonomous vehicles <ref type="bibr" target="#b29">(Hu et al., 2023)</ref>. In this case, small details in the visual input, such as a traffic light or a pedestrian in the distance, may change the policy of an agent. Increasing the number of discrete latents can mitigate this lossy compression, but comes with an increased computational cost <ref type="bibr" target="#b43">(Micheli et al., 2023)</ref>.</p><p>In the meantime, diffusion models <ref type="bibr" target="#b67">(Sohl-Dickstein et al., 2015;</ref><ref type="bibr" target="#b26">Ho et al., 2020;</ref><ref type="bibr" target="#b68">Song et al., 2020)</ref> have become a dominant paradigm for high-resolution image generation <ref type="bibr" target="#b57">(Rombach et al., 2022;</ref><ref type="bibr" target="#b52">Podell et al., 2023)</ref>. This class of methods, in which the model learns to reverse a noising process, challenges well-established approaches modeling discrete tokens <ref type="bibr" target="#b17">(Esser et al., 2021;</ref><ref type="bibr" target="#b55">Ramesh et al., 2021;</ref><ref type="bibr" target="#b9">Chang et al., 2023)</ref>, and thereby offers a promising alternative to alleviate the need for discretization in world modeling. Additionally, diffusion models are known to be easily conditionable and to flexibly model complex multi-modal distributions without mode collapse. These properties are instrumental to world modeling, since adherence to conditioning should allow a world model to reflect an agent's actions more closely, resulting in more reliable credit assignment, and modeling multi-modal distributions should provide greater diversity of training scenarios for an agent.</p><p>Motivated by these characteristics, we propose DIAMOND (DIffusion As a Model Of eNvironment Dreams), a reinforcement learning agent trained in a diffusion world model. Careful design choices are necessary to ensure our diffusion world model is efficient and stable over long-time horizons, and we provide a qualitative analysis to illustrate their importance. DIAMOND achieves a mean human normalized score of 1.46 on the well-established Atari 100k benchmark; a new state of the art for agents trained entirely within a world model. Additionally, operating in image space has the benefit of enabling our diffusion world model to be a drop-in substitute for the environment, which provides greater insight into world model and agent behaviors. In particular, we find the improved performance in some games follows from better modeling of critical visual details. To further demonstrate the effectiveness of our world model in isolation, we train DIAMOND's diffusion world model on 87 hours of static Counter-Strike: Global Offensive (CSGO) gameplay <ref type="bibr" target="#b50">(Pearce and Zhu, 2022)</ref> to produce an interactive neural game engine for the popular in-game map, Dust II. We release our code, agents and playable world models at <ref type="url" target="https://diamond-wm.github.io">https://diamond-wm.github.io</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Reinforcement learning and world models</head><p>We model the environment as a standard Partially Observable Markov Decision Process (POMDP) <ref type="bibr" target="#b70">(Sutton and Barto, 2018)</ref>, (S, A, O, T, R, O, γ), where S is a set of states, A is a set of discrete actions, and O is a set of image observations. The transition function T : S ×A×S → [0, 1] describes the environment dynamics p(s t+1 | s t , a t ), and the reward function R : S × A × S → R maps transitions to scalar rewards. Agents cannot directly access states s t and only see the environment through image observations x t ∈ O, emitted according to observation probabilities p(x t | s t ), described by the observation function O : S × O → [0, 1]. The goal is to obtain a policy π that maps observations to actions in order to maximize the expected discounted return E π [ t≥0 γ t r t ], where γ ∈ [0, 1] is a discount factor. World models <ref type="bibr" target="#b20">(Ha and Schmidhuber, 2018)</ref> are generative models of environments, i.e. models of p(s t+1 , r t | s t , a t ). These models can be used as simulated environments to train RL agents <ref type="bibr" target="#b69">(Sutton, 1991)</ref> in a sample-efficient manner <ref type="bibr" target="#b81">(Wu et al., 2023)</ref>. In this paradigm, the training procedure typically consists of cycling through the three following steps: collect data with the RL agent in the real environment; train the world model on all the collected data; train the RL agent in the world model environment (commonly referred to as "in imagination").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Score-based diffusion models</head><p>Diffusion models <ref type="bibr" target="#b67">(Sohl-Dickstein et al., 2015)</ref> are a class of generative models inspired by nonequilibrium thermodynamics that generate samples by reversing a noising process.</p><p>We consider a diffusion process {x τ } τ ∈[0,T ] indexed by a continuous time variable τ ∈ [0, T ], with corresponding marginals {p τ } τ ∈[0,T ] , and boundary conditions p 0 = p data and p T = p prior , where p prior is a tractable unstructured prior distribution, such as a Gaussian. Note that we use τ and superscript for the diffusion process time, in order to keep t and subscript for the environment time.</p><p>This diffusion process can be described as the solution to a standard stochastic differential equation (SDE) <ref type="bibr" target="#b68">(Song et al., 2020)</ref>,</p><formula xml:id="formula_0">dx = f (x, τ )dτ + g(τ )dw, (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where w is the Wiener process (Brownian motion), f a vector-valued function acting as a drift coefficient, and g a scalar-valued function known as the diffusion coefficient of the process.</p><p>To obtain a generative model, which maps from noise to data, we must reverse this process. Remarkably, <ref type="bibr" target="#b3">Anderson (1982)</ref> shows that the reverse process is also a diffusion process, running backwards in time, and described by the following SDE,</p><formula xml:id="formula_2">dx = [f (x, τ ) -g(τ ) 2 ∇ x log p τ (x)]dτ + g(τ )d w, (<label>2</label></formula><formula xml:id="formula_3">)</formula><p>where w is the reverse-time Wiener process, and ∇ x log p τ (x) is the (Stein) score function, the gradient of the log-marginals with respect to the support. Therefore, to reverse the forward noising process, we are left to define the functions f and g (in Section 3.1), and to estimate the unknown score functions ∇ x log p τ (x), associated with marginals {p τ } τ ∈[0,T ] along the process. In practice, it is possible to use a single time-dependent score model S θ (x, τ ) to estimate these score functions <ref type="bibr" target="#b68">(Song et al., 2020)</ref>.</p><p>At any point in time, estimating the score function is not trivial since we do not have access to the true score function. Fortunately, <ref type="bibr" target="#b30">Hyvärinen (2005)</ref> introduces the score matching objective, which surprisingly enables training a score model from data samples without the knowledge of the underlying score function. To access samples from the marginal p τ , we need to simulate the forward process from time 0 to time τ , as we only have clean data samples. This is costly in general, but if f is affine, we can analytically reach any time τ in the forward process in a single step, by applying a Gaussian perturbation kernel p 0τ to clean data samples <ref type="bibr" target="#b68">(Song et al., 2020)</ref>. Since the kernel is differentiable, score matching simplifies to a denoising score matching objective <ref type="bibr" target="#b76">(Vincent, 2011)</ref>,</p><formula xml:id="formula_4">L(θ) = E ∥S θ (x τ , τ ) -∇ x τ log p 0τ (x τ | x 0 )∥ 2 , (<label>3</label></formula><formula xml:id="formula_5">)</formula><p>where the expectation is over diffusion time τ , noised sample x τ ∼ p 0τ (x τ | x 0 ), obtained by applying the τ -level perturbation kernel to a clean sample x 0 ∼ p data (x 0 ). Importantly, as the kernel p 0τ is a known Gaussian distribution, this objective becomes a simple L 2 reconstruction loss,</p><formula xml:id="formula_6">L(θ) = E ∥D θ (x τ , τ ) -x 0 ∥ 2 ,<label>(4)</label></formula><p>with reparameterization D θ (x τ , τ ) = S θ (x τ , τ )σ 2 (τ ) + x τ , where σ(τ ) is the variance of the τ -level perturbation kernel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Diffusion for world modeling</head><p>The score-based diffusion model described in Section 2.2 provides an unconditional generative model of p data . To serve as a world model, we need a conditional generative model of the environment dynamics, p(x t+1 | x ≤t , a ≤t ), where we consider the general case of a POMDP, in which the Markovian state s t is unknown and can be approximated from past observations and actions. We can condition a diffusion model on this history, to estimate and generate the next observation directly, as shown in Figure <ref type="figure" target="#fig_0">1</ref>. This modifies Equation 4 as follows,</p><formula xml:id="formula_7">L(θ) = E ∥D θ (x τ t+1 , τ, x 0 ≤t , a ≤t ) -x 0 t+1 ∥ 2 . (<label>5</label></formula><formula xml:id="formula_8">)</formula><p>During training, we sample a trajectory segment x 0 ≤t , a ≤t , x 0 t+1 from the agent's replay dataset, and we obtain the noised next observation x τ t+1 ∼ p 0τ (x τ t+1 | x 0 t+1 ) by applying the τ -level perturbation kernel. In summary, this diffusion process for world modeling resembles the standard diffusion process described in Section 2.2, with a score model conditioned on past observations and actions.</p><p>To sample the next observation, we iteratively solve the reverse SDE in Equation 2, as illustrated in Figure <ref type="figure" target="#fig_0">1</ref>. While we can in principle resort to any ODE or SDE solver, there is an inherent trade-off between sampling quality and Number of Function Evaluations (NFE), that directly determines the inference cost of the diffusion world model (see Appendix A for more details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Practical choice of diffusion paradigm</head><p>Building on the background provided in Section 2, we now introduce DIAMOND as a practical realization of a diffusion-based world model. In particular, we now define the drift and diffusion coefficients f and g introduced in Section 2.2, corresponding to a particular choice of diffusion paradigm. While DDPM <ref type="bibr" target="#b26">(Ho et al., 2020)</ref> is an example of one such choice (as described in Appendix B) and would historically be the natural candidate, we instead build upon the EDM formulation proposed in <ref type="bibr" target="#b36">Karras et al. (2022)</ref>. The practical implications of this choice are discussed in Section 5.1. In what follows, we describe how we adapt EDM to build our diffusion-based world model.</p><p>We consider the perturbation kernel p 0τ (x τ t+1 | x 0 t+1 ) = N (x τ t+1 ; x 0 t+1 , σ 2 (τ )I), where σ(τ ) is a real-valued function of diffusion time called the noise schedule. This corresponds to setting the drift and diffusion coefficients to f (x, τ ) = 0 (affine) and g(τ ) = 2 σ(τ )σ(τ ).</p><p>We use the network preconditioning introduced by <ref type="bibr" target="#b36">Karras et al. (2022)</ref> and so parameterize D θ in Equation 5 as the weighted sum of the noised observation and the prediction of a neural network F θ ,</p><formula xml:id="formula_9">D θ (x τ t+1 , y τ t ) = c τ skip x τ t+1 + c τ out F θ c τ in x τ t+1 , y τ t ,<label>(6)</label></formula><p>where for brevity we define y τ t := (c τ noise , x 0 ≤t , a ≤t ) to include all conditioning variables. The preconditioners c τ in and c τ out are selected to keep the network's input and output at unit variance for any noise level σ(τ ), c τ noise is an empirical transformation of the noise level, and c τ skip is given in terms of σ(τ ) and the standard deviation of the data distribution σ data , as c τ skip = σ 2 data /(σ 2 data + σ 2 (τ )). These preconditioners are fully described in Appendix C.</p><p>Combining Equations 5 and 6 provides insight into the training objective of F θ ,</p><formula xml:id="formula_10">L(θ) = E ∥ F θ c τ in x τ t+1 , y τ t Network prediction - 1 c τ out x 0 t+1 -c τ skip x τ t+1 Network training target ∥ 2 . (<label>7</label></formula><formula xml:id="formula_11">)</formula><p>The network training target adaptively mixes signal and noise depending on the degradation level σ(τ ). When σ(τ ) ≫ σ data , we have c τ skip → 0, and the training target for F θ is dominated by the clean signal x 0 t+1 . Conversely, when the noise level is low, σ(τ ) → 0, we have c τ skip → 1, and the target becomes the difference between the clean and the perturbed signal, i.e. the added Gaussian noise. Intuitively, this prevents the training objective to become trivial in the low-noise regime. In practice, this objective is high variance at the extremes of the noise schedule, so <ref type="bibr" target="#b36">Karras et al. (2022)</ref> sample the noise level σ(τ ) from an empirically chosen log-normal distribution in order to concentrate the training around medium-noise regions, as described in Appendix C.</p><p>We use a standard U-Net 2D for the vector field F θ <ref type="bibr" target="#b58">(Ronneberger et al., 2015)</ref>, and we keep a buffer of L past observations and actions that we use to condition the model. We concatenate these past observations to the next noisy observation channel-wise, and we input actions through adaptive group normalization layers <ref type="bibr" target="#b89">(Zheng et al., 2020)</ref> in the residual blocks <ref type="bibr" target="#b24">(He et al., 2015)</ref> of the U-Net.</p><p>As discussed in Section 2.3 and Appendix A, there are many possible sampling methods to generate the next observation from the trained diffusion model. While our codebase supports a variety of sampling schemes, we found Euler's method to be effective without incurring the cost of additional NFE required by higher order samplers, or the unnecessary complexity of stochastic sampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Reinforcement learning in imagination</head><p>Given the diffusion model from Section 3.1, we now complete our world model with a reward and termination model, required for training an RL agent in imagination. Since estimating the reward and termination are scalar prediction problems, we use a separate model R ψ consisting of standard CNN <ref type="bibr" target="#b39">(LeCun et al., 1989;</ref><ref type="bibr" target="#b24">He et al., 2015)</ref> and LSTM <ref type="bibr" target="#b28">(Hochreiter and Schmidhuber, 1997;</ref><ref type="bibr" target="#b18">Gers et al., 2000)</ref> layers to handle partial observability. The RL agent involves an actor-critic network parameterized by a shared CNN-LSTM with policy and value heads. The policy π ϕ is trained with REINFORCE with a value baseline, and we use a Bellman error with λ-returns to train the value network V ϕ , similar to <ref type="bibr" target="#b43">Micheli et al. (2023)</ref>. We train the agent entirely in imagination as described in Section 2.1. The agent only interacts with the real environment for data collection. After each collection stage, the current world model is updated by training on all data collected so far. Then, the agent is trained with RL in the updated world model environment, and these steps are repeated. This procedure is detailed in Algorithm 1, and is similar to <ref type="bibr" target="#b33">Kaiser et al. (2019)</ref>; <ref type="bibr" target="#b21">Hafner et al. (2020)</ref>; <ref type="bibr" target="#b43">Micheli et al. (2023)</ref>. We provide architecture details, hyperparameters, and RL objectives in Appendices D, E, F, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Atari 100k benchmark</head><p>For comprehensive evaluation of DIAMOND we use the established Atari 100k benchmark <ref type="bibr" target="#b33">(Kaiser et al., 2019)</ref>, consisting of 26 games that test a wide range of agent capabilities. For each game, an agent is only allowed to take 100k actions in the environment, which is roughly equivalent to 2 hours of human gameplay, to learn to play the game before evaluation. As a reference, unconstrained Atari agents are usually trained for 50 million steps, a 500 fold increase in experience. We trained DIAMOND from scratch for 5 random seeds on each game. Each run utilized around 12GB of VRAM and took approximately 2.9 days on a single Nvidia RTX 4090 (1.03 GPU years in total). We compare with other recent methods training an agent entirely within a world model in Table <ref type="table" target="#tab_0">1</ref>, including STORM <ref type="bibr" target="#b88">(Zhang et al., 2023)</ref>, DreamerV3 <ref type="bibr" target="#b23">(Hafner et al., 2023)</ref>, IRIS <ref type="bibr" target="#b43">(Micheli et al., 2023)</ref>, TWM <ref type="bibr" target="#b56">(Robine et al., 2023)</ref>, and SimPle <ref type="bibr" target="#b33">(Kaiser et al., 2019)</ref>. A broader comparison to model-free and search-based methods, including BBF <ref type="bibr" target="#b63">(Schwarzer et al., 2023)</ref> and EfficientZero <ref type="bibr" target="#b86">(Ye et al., 2021)</ref>, the current best performing methods on this benchmark, is provided in Appendix J. BBF and EfficientZero use techniques that are orthogonal and not directly comparable to our approach, such as using periodic network resets in combination with hyperparameter scheduling for BBF, and computationally expensive lookahead Monte-Carlo tree search for EfficientZero. Combining these additional components with our world model would be an interesting direction for future work.  Table <ref type="table" target="#tab_0">1</ref> provides scores for all games, and the mean and interquartile mean (IQM) of humannormalized scores (HNS) <ref type="bibr" target="#b79">(Wang et al., 2016)</ref>. Following the recommendations of <ref type="bibr" target="#b0">Agarwal et al. (2021)</ref> on the limitations of point estimates, we provide stratified bootstrap confidence intervals for the mean and IQM in Figure <ref type="figure" target="#fig_2">2</ref>, as well as performance profiles and additional metrics in Appendix H. Our results demonstrate that DIAMOND performs strongly across the benchmark, outperforming human players on 11 games, and achieving a superhuman mean HNS of 1.46, a new best among agents trained entirely within a world model. DIAMOND also achieves an IQM on par with STORM, and greater than all other baselines. We find that DIAMOND performs particularly well on environments where capturing small details is important, such as Asterix, Breakout and Road Runner. We provide further qualitative analysis of the visual quality of the world model in Section 5.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Choice of diffusion framework</head><p>As explained in Section 2, we could in principle use any diffusion model variant in our world model. While DIAMOND utilizes EDM <ref type="bibr" target="#b36">(Karras et al., 2022)</ref> as described in Section 3, DDPM <ref type="bibr" target="#b26">(Ho et al., 2020)</ref> would also be a natural candidate, having been used in many image generation applications <ref type="bibr" target="#b57">(Rombach et al., 2022;</ref><ref type="bibr" target="#b46">Nichol and Dhariwal, 2021)</ref>. We justify this design decision in this section.</p><p>To provide a fair comparison of DDPM with our EDM implementation, we train both variants with the same network architecture, on a shared static dataset of 100k frames collected with an expert policy on the game Breakout. As discussed in Section 2.3, the number of denoising steps is directly related to the inference cost of the world model, and so fewer steps will reduce the cost of training an agent on imagined trajectories.</p><p>Ho et al. (2020) use a thousand denoising steps, and Rombach et al. (2022) employ hundreds steps for Stable Diffusion. However, for our world model to be computationally comparable with other world model baselines (such as IRIS which requires 16 NFE for each timestep), we need at most tens of denoising steps, and preferably fewer. Unfortunately, if the number of denoising steps is set too low, the visual quality will degrade, leading to compounding error.</p><p>To investigate the stability of the diffusion variants, we display imagined trajectories generated autoregressively up to t = 1000 timesteps in Figure <ref type="figure" target="#fig_4">3</ref>, for different numbers of denoising steps n ≤ 10. We see that using DDPM (Figure <ref type="figure" target="#fig_4">3a</ref>) in this regime leads to severe compounding error, causing the world model to quickly drift out of distribution. In contrast, the EDM-based diffusion world model (Figure <ref type="figure" target="#fig_4">3b</ref>) appears much more stable over long time horizons, even for a single denoising step. A quantitative analysis of this compounding error is provided in Appendix K.  The initial observation at t = 0 is common, and each row corresponds to a decreasing number of denoising steps n. We observe that DDPM-based generation suffers from compounding error, and that the smaller the number of denoising steps, the faster the error accumulates. In contrast, our EDM-based world model appears much more stable, even for n = 1.</p><p>This surprising result is a consequence of the improved training objective described in Equation <ref type="formula" target="#formula_10">7</ref>, compared to the simpler noise prediction objective employed by DDPM. While predicting the noise works well for intermediate noise levels, this objective causes the model to learn the identity function when the noise is dominant (</p><formula xml:id="formula_12">σ noise ≫ σ data =⇒ ξ θ (x τ t+1 , y τ t ) → x τ t+1 )</formula><p>, where ξ θ is the noise prediction network of DDPM. This gives a poor estimate of the score function at the beginning of the sampling procedure, which degrades the generation quality and leads to compounding error.</p><p>In contrast, the adaptive mixing of signal and noise employed by EDM, described in Section 3.1, means that the model is trained to predict the clean image when the noise is dominant (</p><formula xml:id="formula_13">σ noise ≫ σ data =⇒ F θ (x τ t+1 , y τ t ) → x 0 t+1</formula><p>). This gives a better estimate of the score function in the absence of signal, so the model is able to produce higher quality generations with fewer denoising steps, as illustrated in Figure <ref type="figure" target="#fig_4">3b</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Choice of the number of denoising steps</head><p>While we found that our EDM-based world model was very stable with just a single denoising step, as shown for Breakout in the last row of Figure <ref type="figure" target="#fig_4">3b</ref>, we discuss here how this choice would limit the visual quality of the model in some cases. We provide more a quantitative analysis in Appendix L.</p><p>As discussed in Section 2.2, our score model is equivalent to a denoising autoencoder <ref type="bibr" target="#b77">(Vincent et al., 2008)</ref> trained with an L 2 reconstruction loss. The optimal single-step prediction is thus the expectation over possible reconstructions for a given noisy input, which can be out of distribution if this posterior distribution is multimodal. While some games like Breakout have deterministic transitions that can be accurately modeled with a single denoising step (see Figure <ref type="figure" target="#fig_4">3b</ref>), in some other games partial observability gives rise to multimodal observation distributions. In this case, an iterative solver is necessary to drive the sampling procedure towards a particular mode, as illustrated in the game Boxing in Figure <ref type="figure">4</ref>. As a result, we therefore set n = 3 in all of our experiments.</p><p>Figure <ref type="figure">4</ref>: Single-step (top row) versus multi-step (bottom row) sampling in Boxing. Movements of the black player are unpredictable, so that single-step denoising interpolates between possible outcomes and results in blurry predictions. In contrast, multi-step sampling produces a crisp image by driving the generation towards a particular mode. Interestingly, the policy controls the white player, so his actions are known to the world model. This information removes any ambiguity, and so we observe that both single-step and multi-step sampling correctly predict the white player's position.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Qualitative visual comparison with IRIS</head><p>We now compare to IRIS <ref type="bibr" target="#b43">(Micheli et al., 2023)</ref>, a well-established world model that uses a discrete autoencoder <ref type="bibr" target="#b73">(Van Den Oord et al., 2017)</ref> to convert images to discrete tokens, and composes these tokens over time with an autoregressive transformer <ref type="bibr" target="#b53">(Radford et al., 2019)</ref>. For fair comparison, we train both world models on the same static datasets of 100k frames collected with expert policies. This comparison is displayed in Figure <ref type="figure" target="#fig_5">5</ref> below. In Asterix (top row), an enemy (orange) becomes a reward (red) in the second frame, before reverting to an enemy in the third, and again to a reward in the fourth. In Breakout (middle row), the bricks and score are inconsistent between frames. In Road Runner (bottom row), the rewards (small blue dots on the road) are inconsistently rendered between frames. None of these inconsistencies occur with DIAMOND. In Breakout, the score is even reliably updated by +7 when a red brick is broken<ref type="foot" target="#foot_0">foot_0</ref> .</p><p>We see in Figure <ref type="figure" target="#fig_5">5</ref> that the trajectories imagined by DIAMOND are generally of higher visual quality and more faithful to the true environment compared to the trajectories imagined by IRIS. In particular, the trajectories generated by IRIS contain visual inconsistencies between frames (highlighted by white boxes), such as enemies being displayed as rewards and vice-versa. These inconsistencies may only represent a few pixels in the generated images, but can have significant consequences for reinforcement learning. For example, since an agent should generally target rewards and avoid enemies, these small visual discrepancies can make it more challenging to learn an optimal policy.</p><p>These improvements in the consistency of visual details are generally reflected by greater agent performance on these games, as shown in Table <ref type="table" target="#tab_0">1</ref>. Since the agent component of these methods is similar, this improvement can likely be attributed to the world model.</p><p>Finally, we note that this improvement is not simply the result of increased computation. Both world models are rendering frames at the same resolution (64 × 64), and DIAMOND requires only 3 NFE per frame compared to 16 NFE per frame for IRIS. This is further reflected by the fact that DIAMOND has significantly fewer parameters and takes less time to train than IRIS, as provided in Appendix H.</p><p>6 Scaling the diffusion world model to Counter-Strike: Global Offensive<ref type="foot" target="#foot_1">foot_1</ref> </p><p>To investigate the ability of DIAMOND's diffusion world model to learn to model more complex 3D environments, we train the world model in isolation on static data from the popular video game Counter-Strike: Global Offensive (CS:GO). We use the Online dataset of 5.5M frames (95 hours) of online human gameplay captured at 16Hz from the map Dust II by <ref type="bibr" target="#b50">Pearce and Zhu (2022)</ref>. We randomly hold out 0.5M frames (corresponding to 500 episodes, or 8 hours) for testing, and use the remaining 5M frames (87 hours) for training. There is no reinforcement learning agent or online data collection involved in these experiments.</p><p>To reduce the computational cost, we reduce the resolution from (280 × 150) to (56 × 30) for world modeling. We then introduce a second, smaller diffusion model as an upsampler to improve the generated images at the original resolution <ref type="bibr" target="#b60">(Saharia et al., 2022b)</ref>. We scale the channels of the U-Net to increase the number of parameters from 4M for our Atari models to 381M for our CS:GO model (including 51M for the upsampler). The combined model was trained for 12 days on an RTX 4090.</p><p>Finally, we introduce stochastic sampling and increase the number of denoising steps for the upsampler to 10, which we found to improve the resulting visual quality of the generations, while keeping the dynamics model the same (in particular, still using only 3 denoising steps). This enables a reasonable tradeoff between visual quality and inference cost, with the model running at 10Hz on an RTX 3090.</p><p>Typical generations of the model are provided in Figure <ref type="figure" target="#fig_6">6</ref> below. We find the model is able to generate stable trajectories over hundreds of timesteps, although is more likely to drift out-of-distribution in less frequently visited areas of the map. Due to the limited memory of the model, approaching walls or losing visibility may cause the model to forget the current state and instead generate a new weapon or area of map. Interestingly, we find the model wrongly enables successive jumps by generalizing the effect of a jump on the geometry of the scene, since multiple jumps do not appear often enough in the training gameplay for the model to learn that mid-air jumps should be ignored. We expect scaling the model and data to address many of these limitations, with the exception of the memory of the model. Quantitative measurements of the capabilities of the CS:GO world model and attempts to address these limitations are left to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related work</head><p>World models. The idea of reinforcement learning (RL) in the imagination of a neural network world model was introduced by Ha and Schmidhuber (2018). SimPLe <ref type="bibr" target="#b33">(Kaiser et al., 2019)</ref> applied world models to Atari, and introduced the Atari 100k benchmark to focus on sample efficiency. Dreamer <ref type="bibr" target="#b21">(Hafner et al., 2020)</ref> introduced RL from the latent space of a recurrent state space model (RSSM). DreamerV2 <ref type="bibr" target="#b22">(Hafner et al., 2021)</ref> demonstrated that using discrete latents could help to reduce compounding error, and DreamerV3 <ref type="bibr" target="#b23">(Hafner et al., 2023)</ref> was able to achieve human-level performance on a wide range of domains with fixed hyperparameters. TWM <ref type="bibr" target="#b56">(Robine et al., 2023</ref>) adapts DreamerV2's RSSM to use a transformer architecture, while STORM <ref type="bibr" target="#b88">(Zhang et al., 2023)</ref> adapts DreamerV3 in a similar way but with a different tokenization approach. Alternatively, IRIS <ref type="bibr" target="#b43">(Micheli et al., 2023)</ref> builds a language of image tokens with a discrete autoencoder, and composes these tokens over time with an autoregressive transformer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generative vision models.</head><p>There are parallels between these world models and image generation models which suggests that developments in generative vision models could provide benefits to world modeling. Following the rise of transformers in natural language processing <ref type="bibr" target="#b74">(Vaswani et al., 2017;</ref><ref type="bibr" target="#b13">Devlin et al., 2018;</ref><ref type="bibr" target="#b53">Radford et al., 2019)</ref>, VQGAN <ref type="bibr" target="#b17">(Esser et al., 2021)</ref> and DALL•E <ref type="bibr" target="#b55">(Ramesh et al., 2021)</ref> convert images to discrete tokens with discrete autoencoders <ref type="bibr" target="#b73">(Van Den Oord et al., 2017)</ref>, and leverage the sequence modeling abilities of autoregressive transformers to build powerful text-to-image generative models. Concurrently, diffusion models <ref type="bibr" target="#b67">(Sohl-Dickstein et al., 2015;</ref><ref type="bibr" target="#b26">Ho et al., 2020;</ref><ref type="bibr" target="#b68">Song et al., 2020)</ref> gained traction <ref type="bibr" target="#b14">(Dhariwal and Nichol, 2021;</ref><ref type="bibr" target="#b57">Rombach et al., 2022)</ref>, and have become a dominant paradigm for high-resolution image generation <ref type="bibr" target="#b59">(Saharia et al., 2022a;</ref><ref type="bibr" target="#b54">Ramesh et al., 2022;</ref><ref type="bibr" target="#b52">Podell et al., 2023)</ref>.</p><p>The same trends have taken place in the recent developments of video generation methods. VideoGPT <ref type="bibr" target="#b85">(Yan et al., 2021)</ref> provides a minimal video generation architecture by combining a discrete autoencoder with an autoregressive transformer. Godiva <ref type="bibr" target="#b80">(Wu et al., 2021</ref>) enables text conditioning with promising generalization. Phenaki <ref type="bibr" target="#b75">(Villegas et al., 2023)</ref> allows arbitrary length video generation with sequential prompt conditioning. TECO <ref type="bibr" target="#b84">(Yan et al., 2023)</ref> improves upon autoregressive modeling by using MaskGit <ref type="bibr" target="#b10">(Chang et al., 2022)</ref>, and enables longer temporal dependencies by compressing input sequence embeddings. Diffusion models have also seen a resurgence in video generation using 3D U-Nets to provide high quality but short-duration video <ref type="bibr" target="#b65">(Singer et al., 2023;</ref><ref type="bibr" target="#b6">Bar-Tal et al., 2024)</ref>. Recently, transformer-based diffusion models such as DiT <ref type="bibr" target="#b51">(Peebles and Xie, 2023)</ref> and Sora <ref type="bibr" target="#b7">(Brooks et al., 2024)</ref> have shown improved scalability for both image and video generation, respectively.</p><p>Diffusion for reinforcement learning. There has also been much interest in combining diffusion models with reinforcement learning. This includes taking advantage of the flexibility of diffusion models as a policy <ref type="bibr" target="#b78">(Wang et al., 2022;</ref><ref type="bibr" target="#b1">Ajay et al., 2022;</ref><ref type="bibr" target="#b49">Pearce et al., 2023)</ref>, as planners <ref type="bibr" target="#b32">(Janner et al., 2022;</ref><ref type="bibr" target="#b40">Liang et al., 2023)</ref>, as reward models <ref type="bibr" target="#b47">(Nuti et al., 2023)</ref>, and trajectory modeling for data augmentation in offline RL <ref type="bibr" target="#b41">(Lu et al., 2023;</ref><ref type="bibr" target="#b15">Ding et al., 2024;</ref><ref type="bibr" target="#b31">Jackson et al., 2024)</ref>. DIAMOND represents the first use of diffusion models as world models for learning online in imagination.</p><p>Generative game engines. Playable games running entirely on neural networks have recently been growing in scope. GameGAN <ref type="bibr" target="#b37">(Kim et al., 2020)</ref> learns generative models of games using a GAN <ref type="bibr" target="#b19">(Goodfellow et al., 2014)</ref> while <ref type="bibr" target="#b5">Bamford and Lucas (2020)</ref> use a Neural GPU <ref type="bibr" target="#b34">(Kaiser and Sutskever, 2015)</ref>. Concurrent work includes Genie <ref type="bibr" target="#b8">(Bruce et al., 2024)</ref>, which generates playable platformer environments from image prompts, and GameNGen <ref type="bibr" target="#b72">(Valevski et al., 2024)</ref>, which similarly leverages a diffusion model to obtain a high resolution simulator of the game DOOM, but at a larger scale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Limitations</head><p>We identify three main limitations of our work for future research. First, our main evaluation is focused on discrete control environments, and applying DIAMOND to the continuous domain may provide additional insights. Second, the use of frame stacking for conditioning is a minimal mechanism to provide a memory of past observations. Integrating an autoregressive transformer over environment time, using an approach such as <ref type="bibr" target="#b51">Peebles and Xie (2023)</ref>, would enable longer-term memory and better scalability. We include an initial investigation into a potential cross-attention architecture in Appendix M, but found frame-stacking more effective in our early experiments. Third, we leave potential integration of the reward/termination prediction into the diffusion model for future work, since combining these objectives and extracting representations from a diffusion model is not trivial <ref type="bibr" target="#b42">(Luo et al., 2023;</ref><ref type="bibr" target="#b83">Xu et al., 2023)</ref> and would make our world model unnecessarily complex.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion and Broader Impact</head><p>We have introduced DIAMOND, a reinforcement learning agent trained in a diffusion world model. We explained the key design choices we made to adapt diffusion for world modeling and to make our world model stable over long time horizons with a low number of denoising steps. DIAMOND achieves a mean human normalized score of 1.46 on the well-established Atari 100k benchmark; a new best among agents trained entirely within a world model. We analyzed our improved performance in some games and found that it likely follows from better modeling of critical visual details. We further demonstrated DIAMOND's diffusion world model can successfully model 3D environments and serve as a real-time neural game engine by training on static Counter-Strike: Global Offensive gameplay.</p><p>World models constitute a promising direction to address sample efficiency and safety concerns associated with training agents in the real world. However, imperfections in the world model may lead to suboptimal or unexpected agent behaviors. We hope that the development of more faithful and interactive world models will contribute to broader efforts to further reduce these risks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Sampling observations in DIAMOND</head><p>We describe here how we sample an observation x 0 t from our diffusion world model. We initialize the procedure with a noisy observation x T t ∼ p prior , and iteratively solve the reverse SDE in Equation 2 from τ = T to τ = 0, using the learned score model S θ (x τ t , τ, x 0 &lt;t , a &lt;t ) conditioned on past observations x 0 &lt;t and actions a &lt;t . This procedure is illustrated in Figure <ref type="figure" target="#fig_0">1</ref>. In fact, there are many possible sampling methods for a given learned score model S θ <ref type="bibr" target="#b36">(Karras et al., 2022)</ref>. Notably, <ref type="bibr" target="#b68">Song al. (2020)</ref> introduce a corresponding "probability flow" ordinary differential equation (ODE), with marginals equivalent to the stochastic process described in Section 2.2. In that case, the solving procedure is deterministic, and the only randomness comes from sampling the initial condition. In practice, this means that for a given score model, we can resort to any ODE or SDE solver, from simple first order methods like Euler (deterministic) and Euler-Maruyama (stochastic) schemes, to higher-order methods like Heun's method <ref type="bibr" target="#b4">(Ascher and Petzold, 1998)</ref>.</p><p>Regardless of the choice of solver, each step introduces truncation errors, resulting from the local score approximation and the discretization of the continuous process. Higher order samplers may reduce this truncation error, but come at the cost of additional Number of Function Evaluations (NFE) -how many forward passes of the network are required to generate a sample. This local error generally scales superlinearly with respect to the step size (for instance Euler's method is O(h 2 ) for step size h), so increasing the number of denoising steps improves the visual quality of the generated next frame. Therefore, there is a trade-off between visual quality and NFE that directly determines the inference cost of the diffusion world model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Link between DDPM and continuous-time score-based diffusion models</head><p>Denoising Diffusion Probabilistic Models (DDPM, <ref type="bibr" target="#b26">Ho et al. (2020)</ref>) can be described as a discrete version of the diffusion process introduced in Section 2.2, as described in <ref type="bibr" target="#b68">Song et al. (2020)</ref>. The discrete forward process is a Markov chain characterized by a discrete noise schedule 0 &lt; β 1 , . . . , β i , . . . β N &lt; 1, and a variance-preserving Gaussian transition kernel,</p><formula xml:id="formula_14">p(x i |x i-1 ) = N (x i ; 1 -β i x i-1 , β i I).<label>(8)</label></formula><p>In the continuous time limit N → ∞, the Markov chain becomes a diffusion process, and the discrete noise schedule becomes a time-dependent function β(τ ). This diffusion process can be described by an SDE with drift coefficient f (x, τ ) = -1 2 β(τ )x and diffusion coefficient g(τ ) = β(τ ) <ref type="bibr" target="#b68">(Song et al., 2020)</ref>. <ref type="bibr" target="#b36">Karras et al. (2022)</ref> use the following preconditioners for normalization and rescaling purposes (as mentioned in Section 3.1) to improve network training:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C EDM network preconditioners and training</head><formula xml:id="formula_15">c τ in = 1 σ(τ ) 2 + σ 2 data (9) c τ out = σ(τ )σ data σ(τ ) 2 + σ 2 data (10) c τ noise = 1 4 log(σ(τ ))<label>(11)</label></formula><formula xml:id="formula_16">c τ skip = σ 2 data σ 2 data + σ 2 (τ ) ,<label>(12)</label></formula><p>where σ data = 0.5.</p><p>The noise parameter σ(τ ) is sampled to maximize the effectiveness of training as follows:</p><formula xml:id="formula_17">log(σ(τ )) ∼ N (P mean , P 2 std ),<label>(13)</label></formula><p>where P mean = -0.4, P std = 1.2. Refer to <ref type="bibr" target="#b36">Karras et al. (2022)</ref> for an in-depth analysis. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Training hyperparameters</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Reinforcement learning objectives</head><p>In what follows, we note x t , r t and d t the observations, rewards, and boolean episode terminations predicted by our world model. We note H the imagination horizon, V ϕ the value network, π ϕ the policy network, and a t the actions taken by the policy within the world model.</p><p>We use λ-returns to balance bias and variance as the regression target for the value network. Given an imagined trajectory of length H, we can define the λ-return recursively as follows,</p><formula xml:id="formula_18">Λ t = r t + γ(1 -d t ) (1 -λ)V ϕ (x t+1 ) + λΛ t+1 if t &lt; H V ϕ (x H ) if t = H.<label>(14)</label></formula><p>The value network V ϕ is trained to minimize L V (ϕ), the expected squared difference with λ-returns over imagined trajectories,</p><formula xml:id="formula_19">L V (ϕ) = E π ϕ H-1 t=0 V ϕ (x t ) -sg(Λ t ) 2 ,<label>(15)</label></formula><p>where sg(•) denotes the gradient stopping operation, meaning that the target is a constant in the gradient-based optimization, as classically established in the literature <ref type="bibr" target="#b45">(Mnih et al., 2015;</ref><ref type="bibr" target="#b22">Hafner et al., 2021;</ref><ref type="bibr" target="#b43">Micheli et al., 2023)</ref>.</p><p>As we can generate large amounts of on-policy trajectories in imagination, we use a simple RE-INFORCE objective to train the policy, with the value V ϕ (x t ) as a baseline to reduce the variance of the gradients <ref type="bibr" target="#b70">(Sutton and Barto, 2018)</ref>. The policy is trained to minimize the following objective, combining REINFORCE and a weighted entropy maximization objective to maintain sufficient exploration,</p><formula xml:id="formula_20">L π (ϕ) = -E π ϕ H-1 t=0 log (π ϕ (a t | x ≤t )) sg (Λ t -V ϕ (x t )) + η H (π ϕ (a t | x ≤t )) .<label>(16)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H Additional performance comparisons</head><p>We provide performance profiles <ref type="bibr" target="#b0">(Agarwal et al., 2021)</ref> for DIAMOND and baselines below. As additional angles of comparison, we also provide parameter counts and approximate training times for IRIS, DreamerV3 and DIAMOND in Table <ref type="table" target="#tab_3">4</ref> below. We see that DIAMOND has the highest mean HNS, with fewer parameters than both IRIS and DreamerV3. DIAMOND also trains faster than IRIS, although is slower than DreamerV3. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I Training time profile</head><p>Table 5 provides a full training time profile for DIAMOND. Table 6 provides scores for model-free and search-based methods, including the current best performing methods on the Atari 100k benchmark, EfficientZero <ref type="bibr" target="#b86">(Ye et al., 2021)</ref> and BBF <ref type="bibr" target="#b63">(Schwarzer et al., 2023)</ref>. Both of these methods use approaches that are out of scope of our approach, such as computationally expensive lookahead Monte-Carlo tree search for EfficientZero, and using periodic network resets in combination with hyperparameter scheduling for BBF. We see that while the use of lookahead search and more advanced reinforcement learning techniques (for EfficientZero <ref type="bibr" target="#b86">(Ye et al., 2021)</ref> and BBF <ref type="bibr" target="#b63">(Schwarzer et al., 2023)</ref> respectively) can still provide greater performance overall, DIAMOND promisingly still outperforms these methods on some games. We note that the purpose of our investigation is to train and evaluate DIAMOND's diffusion model on these static datasets, and that we do not perform reinforcement learning, since there is no standard reinforcement learning protocol for these environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M.2 Diffusion Model Architectures</head><p>We consider two potential diffusion model architectures, summarized in Figure <ref type="figure" target="#fig_9">9</ref>.  Frame-stacking. The simplest way to condition on previous observations is by concatenating the previous L frames together with the next noised frame, concat[x τ t , x 0 t-1 , . . . , x 0 t-L ], which is compatible with a standard U-Net 2D <ref type="bibr" target="#b58">(Ronneberger et al., 2015)</ref>. This architecture is particularly attractive due to its lightweight construction, requiring minimal additional parameters and compute compared to typical image diffusion. This is the architecture we used for the main body of the paper.</p><p>Cross-attention. The U-Net 3D <ref type="bibr">(Çiçek et al., 2016)</ref>, also displayed for comparison in Figure <ref type="figure" target="#fig_9">9</ref>, is a leading architecture in video diffusion <ref type="bibr" target="#b27">(Ho et al., 2022)</ref>. We adapted this design to have an autoregressive cross-attention architecture, formed of a core U-Net 2D, that only receives a single noised frame as direct input, but which cross-attends to the activations of a separate history encoder network. This encoder is a lightweight version of the U-Net 2D architecture. Parameters are shared for all L encoders, and each receives the relative environment timestep embedding as input. The final design differs from the U-Net 3D which diffuses all frames jointly, shares parameters across networks, and uses self-, rather than cross-, attention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M.3 Metrics, Baselines and Compute</head><p>Metrics. To evaluate the visual quality of generated trajectories, we use the standard Fréchet Video Distance (FVD) <ref type="bibr" target="#b71">(Unterthiner et al., 2018)</ref> as implemented by <ref type="bibr" target="#b66">Skorokhodov et al. (2022)</ref>. This is computed between 1024 real videos (taken from the test set), and 1024 generated videos, each 16 frames long (1-2 seconds). Models condition on L = 6 previous real frames, and the real action sequence. On this same data, we also report the Fréchet Inception Distance (FID) <ref type="bibr" target="#b25">(Heusel et al., 2017)</ref>, which measures the visual quality of individual observations, ignoring the temporal dimension. For these same sets of videos, we also compute the LPIPS loss <ref type="bibr" target="#b87">(Zhang et al., 2018)</ref> between each pair of real/generated observations <ref type="bibr" target="#b84">(Yan et al., 2023)</ref>. Sampling rate describes the number of observations that can be generated, in sequence, by a single Nvidia RTX A6000 GPU, per second.</p><p>Baselines. We compare against two well-established world model methods; DreamerV3 <ref type="bibr" target="#b23">(Hafner et al., 2023)</ref> and IRIS <ref type="bibr" target="#b43">(Micheli et al., 2023)</ref>, adapting the original implementations to train on a static dataset. We ensured baselines used a similar number of parameters to DIAMOND. Two variants of IRIS are reported; image observations are discretized into K = 16 tokens (as used in the original work), or into K = 64 tokens (achieved with one less down/up-sampling layer in the autoencoder, see Appendix E of <ref type="bibr" target="#b43">Micheli et al. (2023)</ref>), which provide the potential for modeling higher-fidelity visuals.</p><p>Compute. All models (baselines and DIAMOND) were trained for 120k updates with a batch size of 64, on up to 4×A6000 GPUs. Each training run took between 1-2 days.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M.4 Analysis</head><p>Table <ref type="table">8</ref>: Results for 3D environments. These metrics compare observations from real trajectories and generated trajectories. The generated trajectories are conditioned on an initial set of L = 6 observations and a real sequence of actions.</p><p>----CS:GO --------Driving ----</p><p>Sample rate Parameters Method FID ↓ FVD ↓ LPIPS ↓ FID ↓ FVD ↓ LPIPS ↓ (Hz) ↑ (#) DreamerV3 106.8 509.1 0.173 167.5 733.7 0.160 266.7 181M IRIS (K = 16) 24.5 110.1 0.129 51.4 368.7 0.188 4.2 123M IRIS (K = 64) 22.8 85.7 0.116 44.3 276.9 0.148 1.5 111M DIAMOND frame-stack (ours) 9.6 34.8 0.107 16.7 80.3 0.058 7.4 122M DIAMOND cross-attention (ours) 11.6 81.4 0.125 35.2 299.9 0.119 2.5 184M</p><p>Table <ref type="table">8</ref> reports metrics on the visual quality of generated trajectories, along with sampling rates and number of parameters, for the frame-stack and cross-attention DIAMOND architectures, compared to baseline methods. DIAMOND outperforms the baselines across all visual quality metrics. This validates the results seen in the wider video generation literature, where diffusion models currently lead, as discussed in Section 7. The simpler frame-stacking architecture performs better than cross-attention, something surprising given the prevalence of cross-attention in the video generation literature. We believe the inductive bias provided by directly feeding in the input, frame-wise, may be well suited to autoregressive generation. Overall, these results indicate DIAMOND frame-stack &gt; DIAMOND cross-attention ≈ IRIS 64 &gt; IRIS 16 &gt; DreamerV3, which we found corresponds to our intuition from visual inspection.</p><p>In terms of sampling rate, DIAMOND frame-stack (with 20 denoising steps) is faster than IRIS (K = 16). IRIS suffers from a further 2.8× slow down for the K = 64 version, verifying its sample time is bottlenecked by the number of tokens K. On the other hand, DreamerV3 is an order of magnitude faster -this derives from its independent, rather than joint, sampling procedure, and the flip-side of this is the low visual quality of its trajectories.  While the above experiments use real sequences of actions from the dataset, we also investigated how robust DIAMOND (frame stack) was to novel, user-input actions. Figure <ref type="figure" target="#fig_12">11</ref> shows the effect of the actions in motorway driving -conditioned on the same L = 6 real frames, we generate trajectories conditioned on five different action sequences. In general the effects are as intended, e.g. steer straight/left/right moves the camera as expected. Interestingly, when 'slow down' is input, the distance to the car in front decreases since the model predicts that the traffic ahead has come to a standstill. Figure <ref type="figure" target="#fig_13">12</ref> shows similar sequences for CS:GO. For the common actions (mouse movements and fire), the effects are as expected, though they are unstable beyond a few frames, since such a sequence of actions is unlikely to have been seen in the demonstration dataset. We note that these issues -the causal confusion and instabilities -are a symptom of training world models on offline data, rather than being an inherent weakness of DIAMOND.  For instance, it would have been very unlikely for the human demonstrator to look directly into ground in this game state, so the world model is unable to generate a plausible trajectory here, and instead snaps onto another area of the map when looking down does make sense.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Unrolling imagination of DIAMOND over time. The top row depicts a policy π ϕ taking a sequence of actions in the imagination of our learned diffusion world model D θ . The environment time t flows along the horizontal axis, while the vertical axis represents the denoising time τ flowing backward from T to 0. Concretely, given (clean) past observations x 0&lt;t , actions a &lt;t , and starting from an initial noisy sample x T t , we simulate a reverse noising process {x τ t } τ =0 τ =T by repeatedly calling D θ , and obtain the (clean) next observation x 0 t . The imagination procedure is autoregressive in that the predicted observation x 0 t and the action a t taken by the policy become part of the conditioning for the next time step. Animated visualizations of this procedure can be found at https://diamond-wm.github.io.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Mean and interquartile mean human normalized scores. DIAMOND, in blue, obtains a mean HNS of 1.46 and an IQM of 0.64.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><figDesc>(a) DDPM-based world model trajectories. (b) EDM-based world model trajectories.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Imagined trajectories with diffusion world models based on DDPM (left) and EDM (right).The initial observation at t = 0 is common, and each row corresponds to a decreasing number of denoising steps n. We observe that DDPM-based generation suffers from compounding error, and that the smaller the number of denoising steps, the faster the error accumulates. In contrast, our EDM-based world model appears much more stable, even for n = 1.</figDesc><graphic coords="7,108.00,72.00,194.05,111.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Consecutive frames imagined with IRIS (left) and DIAMOND (right). The white boxes highlight inconsistencies between frames, which we see only arise in trajectories generated with IRIS.In Asterix (top row), an enemy (orange) becomes a reward (red) in the second frame, before reverting to an enemy in the third, and again to a reward in the fourth. In Breakout (middle row), the bricks and score are inconsistent between frames. In Road Runner (bottom row), the rewards (small blue dots on the road) are inconsistently rendered between frames. None of these inconsistencies occur with DIAMOND. In Breakout, the score is even reliably updated by +7 when a red brick is broken 3 .</figDesc><graphic coords="8,108.00,158.41,194.05,145.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Images captured from people playing with keyboard and mouse inside DIAMOND's diffusion world model. This model was trained on 87 hours of static Counter-Strike: Global Offensive (CS:GO) gameplay (Pearce and Zhu, 2022) to produce an interactive neural game engine for the popular in-game map, Dust II. Best viewed as videos at https://diamond-wm.github.io.</figDesc><graphic coords="9,167.40,198.57,277.20,172.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Performance profiles, i.e. fraction of runs above a given human normalized score.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Figure9: We tested two architectures for DIAMOND's diffusion model which condition on previous image observations in different ways. To illustrate differences with typical video generation models, we also visualize a U-Net 3D(Çiçek et al., 2016)  which diffuses a block of frames simultaneously.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10</head><label>10</label><figDesc>Figure 10 below shows selected examples of the trajectories produced by DIAMOND in CS:GO and motorway driving. The trajectories are plausible, often even at time horizons of reasonable length.In CS:GO, the model accurately generates the correct geometry of the level as it passes through the doorway into a new area of the map. In motorway driving, a car is plausibly imagined overtaking on the left.</figDesc><graphic coords="27,147.60,137.65,316.81,158.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Example trajectories sampled every 25 timesteps from DIAMOND (frame stack) for the modern 3D first-person shooter CS:GO (top row), and real-world motorway driving (bottom row).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Effect of fixed actions on sampled trajectories in motorway driving. Conditioned on the same initial observations, we rollout the model applying differing actions. Interestingly, the model has learnt to associate 'Slow down' and 'Speed up' actions to the whole traffic slowing down and speeding up.</figDesc><graphic coords="28,109.98,92.28,392.04,195.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 12 :</head><label>12</label><figDesc>Figure12: Effect of fixed actions on sampled trajectories in CS:GO. Conditioned on the same initial observation, we rollout the model applying differing actions. Whilst in immediate frames these have the intended effect, for longer roll-outs the observations can degenerate. For instance, it would have been very unlikely for the human demonstrator to look directly into ground in this game state, so the world model is unable to generate a plausible trajectory here, and instead snaps onto another area of the map when looking down does make sense.</figDesc><graphic coords="28,127.80,391.49,356.39,230.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="24,108.00,130.10,396.00,198.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Returns on the 26 games of the Atari 100k benchmark after 2 hours of real-time experience, and human-normalized aggregate metrics. Bold numbers indicate the best performing methods. DIAMOND notably outperforms other world model baselines in terms of mean score over 5 seeds.</figDesc><table><row><cell>Game</cell><cell>Random</cell><cell cols="2">Human SimPLe</cell><cell>TWM</cell><cell cols="4">IRIS DreamerV3 STORM DIAMOND (ours)</cell></row><row><cell>Alien</cell><cell>227.8</cell><cell>7127.7</cell><cell>616.9</cell><cell>674.6</cell><cell>420.0</cell><cell>959.0</cell><cell>983.6</cell><cell>744.1</cell></row><row><cell>Amidar</cell><cell>5.8</cell><cell>1719.5</cell><cell>74.3</cell><cell>121.8</cell><cell>143.0</cell><cell>139.0</cell><cell>204.8</cell><cell>225.8</cell></row><row><cell>Assault</cell><cell>222.4</cell><cell>742.0</cell><cell>527.2</cell><cell>682.6</cell><cell>1524.4</cell><cell>706.0</cell><cell>801.0</cell><cell>1526.4</cell></row><row><cell>Asterix</cell><cell>210.0</cell><cell>8503.3</cell><cell>1128.3</cell><cell>1116.6</cell><cell>853.6</cell><cell>932.0</cell><cell>1028.0</cell><cell>3698.5</cell></row><row><cell>BankHeist</cell><cell>14.2</cell><cell>753.1</cell><cell>34.2</cell><cell>466.7</cell><cell>53.1</cell><cell>649.0</cell><cell>641.2</cell><cell>19.7</cell></row><row><cell>BattleZone</cell><cell cols="2">2360.0 37187.5</cell><cell>4031.2</cell><cell cols="2">5068.0 13074.0</cell><cell>12250.0</cell><cell>13540.0</cell><cell>4702.0</cell></row><row><cell>Boxing</cell><cell>0.1</cell><cell>12.1</cell><cell>7.8</cell><cell>77.5</cell><cell>70.1</cell><cell>78.0</cell><cell>79.7</cell><cell>86.9</cell></row><row><cell>Breakout</cell><cell>1.7</cell><cell>30.5</cell><cell>16.4</cell><cell>20.0</cell><cell>83.7</cell><cell>31.0</cell><cell>15.9</cell><cell>132.5</cell></row><row><cell>ChopperCommand</cell><cell>811.0</cell><cell>7387.8</cell><cell>979.4</cell><cell>1697.4</cell><cell>1565.0</cell><cell>420.0</cell><cell>1888.0</cell><cell>1369.8</cell></row><row><cell>CrazyClimber</cell><cell cols="5">10780.5 35829.4 62583.6 71820.4 59324.2</cell><cell>97190.0</cell><cell>66776.0</cell><cell>99167.8</cell></row><row><cell>DemonAttack</cell><cell>152.1</cell><cell>1971.0</cell><cell>208.1</cell><cell>350.2</cell><cell>2034.4</cell><cell>303.0</cell><cell>164.6</cell><cell>288.1</cell></row><row><cell>Freeway</cell><cell>0.0</cell><cell>29.6</cell><cell>16.7</cell><cell>24.3</cell><cell>31.1</cell><cell>0.0</cell><cell>33.5</cell><cell>33.3</cell></row><row><cell>Frostbite</cell><cell>65.2</cell><cell>4334.7</cell><cell>236.9</cell><cell>1475.6</cell><cell>259.1</cell><cell>909.0</cell><cell>1316.0</cell><cell>274.1</cell></row><row><cell>Gopher</cell><cell>257.6</cell><cell>2412.5</cell><cell>596.8</cell><cell>1674.8</cell><cell>2236.1</cell><cell>3730.0</cell><cell>8239.6</cell><cell>5897.9</cell></row><row><cell>Hero</cell><cell cols="2">1027.0 30826.4</cell><cell>2656.6</cell><cell>7254.0</cell><cell>7037.4</cell><cell>11161.0</cell><cell>11044.3</cell><cell>5621.8</cell></row><row><cell>Jamesbond</cell><cell>29.0</cell><cell>302.8</cell><cell>100.5</cell><cell>362.4</cell><cell>462.7</cell><cell>445.0</cell><cell>509.0</cell><cell>427.4</cell></row><row><cell>Kangaroo</cell><cell>52.0</cell><cell>3035.0</cell><cell>51.2</cell><cell>1240.0</cell><cell>838.2</cell><cell>4098.0</cell><cell>4208.0</cell><cell>5382.2</cell></row><row><cell>Krull</cell><cell>1598.0</cell><cell>2665.5</cell><cell>2204.8</cell><cell>6349.2</cell><cell>6616.4</cell><cell>7782.0</cell><cell>8412.6</cell><cell>8610.1</cell></row><row><cell>KungFuMaster</cell><cell cols="5">258.5 22736.3 14862.5 24554.6 21759.8</cell><cell>21420.0</cell><cell>26182.0</cell><cell>18713.6</cell></row><row><cell>MsPacman</cell><cell>307.3</cell><cell>6951.6</cell><cell>1480.0</cell><cell>1588.4</cell><cell>999.1</cell><cell>1327.0</cell><cell>2673.5</cell><cell>1958.2</cell></row><row><cell>Pong</cell><cell>-20.7</cell><cell>14.6</cell><cell>12.8</cell><cell>18.8</cell><cell>14.6</cell><cell>18.0</cell><cell>11.3</cell><cell>20.4</cell></row><row><cell>PrivateEye</cell><cell cols="2">24.9 69571.3</cell><cell>35.0</cell><cell>86.6</cell><cell>100.0</cell><cell>882.0</cell><cell>7781.0</cell><cell>114.3</cell></row><row><cell>Qbert</cell><cell cols="2">163.9 13455.0</cell><cell>1288.8</cell><cell>3330.8</cell><cell>745.7</cell><cell>3405.0</cell><cell>4522.5</cell><cell>4499.3</cell></row><row><cell>RoadRunner</cell><cell>11.5</cell><cell>7845.0</cell><cell>5640.6</cell><cell>9109.0</cell><cell>9614.6</cell><cell>15565.0</cell><cell>17564.0</cell><cell>20673.2</cell></row><row><cell>Seaquest</cell><cell cols="2">68.4 42054.7</cell><cell>683.3</cell><cell>774.4</cell><cell>661.3</cell><cell>618.0</cell><cell>525.2</cell><cell>551.2</cell></row><row><cell>UpNDown</cell><cell cols="2">533.4 11693.2</cell><cell cols="2">3350.3 15981.7</cell><cell>3546.2</cell><cell>9234.0</cell><cell>7985.0</cell><cell>3856.3</cell></row><row><cell>#Superhuman (↑)</cell><cell>0</cell><cell>N/A</cell><cell>1</cell><cell>8</cell><cell>10</cell><cell>9</cell><cell>10</cell><cell>11</cell></row><row><cell>Mean (↑)</cell><cell>0.000</cell><cell>1.000</cell><cell>0.332</cell><cell>0.956</cell><cell>1.046</cell><cell>1.097</cell><cell>1.266</cell><cell>1.459</cell></row><row><cell>IQM (↑)</cell><cell>0.000</cell><cell>1.000</cell><cell>0.130</cell><cell>0.459</cell><cell>0.501</cell><cell>0.497</cell><cell>0.636</cell><cell>0.641</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Hyperparameters for DIAMOND.Sequence construction during trainingFor D θ , number of conditioning observations and actions (L) 4 For R ψ , burn-in length (B R ), set to L in practice 4 For R ψ , training sequence length (B R + H) 19 For π ϕ and V ϕ , burn-in length (B π,V ), set to L in practice 4</figDesc><table><row><cell>Hyperparameter</cell><cell>Value</cell></row><row><cell>Training loop</cell><cell></cell></row><row><cell>Number of epochs</cell><cell>1000</cell></row><row><cell>Training steps per epoch</cell><cell>400</cell></row><row><cell>Batch size</cell><cell>32</cell></row><row><cell>Environment steps per epoch</cell><cell>100</cell></row><row><cell>Epsilon (greedy) for collection</cell><cell>0.01</cell></row><row><cell>RL hyperparameters</cell><cell></cell></row><row><cell>Imagination horizon (H)</cell><cell>15</cell></row><row><cell>Discount factor (γ)</cell><cell>0.985</cell></row><row><cell>Entropy weight (η)</cell><cell>0.001</cell></row><row><cell>λ-returns coefficient (λ)</cell><cell>0.95</cell></row><row><cell>Optimization</cell><cell></cell></row><row><cell>Optimizer</cell><cell>AdamW</cell></row><row><cell>Learning rate</cell><cell>1e-4</cell></row><row><cell>Epsilon</cell><cell>1e-8</cell></row><row><cell>Weight decay (D θ )</cell><cell>1e-2</cell></row><row><cell>Weight decay (R ψ )</cell><cell>1e-2</cell></row><row><cell>Weight decay (π ϕ and V ϕ )</cell><cell>0</cell></row><row><cell>Diffusion Sampling</cell><cell></cell></row><row><cell>Method</cell><cell>Euler</cell></row><row><cell>Number of steps</cell><cell>3</cell></row><row><cell>Environment</cell><cell></cell></row><row><cell>Image observation dimensions</cell><cell>64×64×3</cell></row><row><cell>Action space</cell><cell>Discrete (up to 18 actions)</cell></row><row><cell>Frameskip</cell><cell>4</cell></row><row><cell>Max noop</cell><cell>30</cell></row><row><cell>Termination on life loss</cell><cell>True</cell></row><row><cell>Reward clipping</cell><cell>{-1, 0, 1}</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Number of parameters, training time, and mean human-normalized score (HNS).</figDesc><table><row><cell></cell><cell>IRIS</cell><cell cols="2">DreamerV3 DIAMOND (ours)</cell></row><row><cell>#parameters (↓)</cell><cell>30M</cell><cell>18M</cell><cell>13M</cell></row><row><cell>Training days (↓)</cell><cell>4.1</cell><cell>&lt;1</cell><cell>2.9</cell></row><row><cell>Mean HNS (↑)</cell><cell>1.046</cell><cell>1.097</cell><cell>1.459</cell></row><row><cell cols="4">A full training time profile for DIAMOND is provided in Appendix I.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Detailed breakdown of training time. Profiling performed using a Nvidia RTX 4090 with the default hyperparameters specified in Appendices D and E These profiling measures are representative, since exact durations will depend on the machine, the environment, and the training stage.</figDesc><table><row><cell>Single update</cell><cell>Time (ms)</cell><cell>Detail (ms)</cell></row><row><cell>Total</cell><cell>543</cell><cell>88 + 115 + 340</cell></row><row><cell>Diffusion model update</cell><cell>88</cell><cell>-</cell></row><row><cell>Reward/Termination model update</cell><cell>115</cell><cell>-</cell></row><row><cell>Actor-Critic model update</cell><cell>340</cell><cell>15 × 20.4 + 34</cell></row><row><cell>Imagination step (x 15)</cell><cell>20.4</cell><cell>12.7 + 7.0 + 0.7</cell></row><row><cell>Next observation prediction</cell><cell>12.7</cell><cell>3 × 4.2</cell></row><row><cell>Denoising step (x 3)</cell><cell>4.2</cell><cell>-</cell></row><row><cell>Reward/Termination prediction</cell><cell>7.0</cell><cell>-</cell></row><row><cell>Action prediction</cell><cell>0.7</cell><cell>-</cell></row><row><cell>Loss computation and backward</cell><cell>34</cell><cell>-</cell></row><row><cell>Epoch</cell><cell>Time (s)</cell><cell>Detail (s)</cell></row><row><cell>Total</cell><cell>217</cell><cell>35 + 46 + 136</cell></row><row><cell>Diffusion model</cell><cell>35</cell><cell>400 × 88 × 10 -3</cell></row><row><cell>Reward/Termination model</cell><cell>46</cell><cell>400 × 115 × 10 -3</cell></row><row><cell>Actor-Critic model</cell><cell>136</cell><cell>400 × 340 × 10 -3</cell></row><row><cell>Run</cell><cell>Time (days)</cell><cell>Detail (days)</cell></row><row><cell>Total</cell><cell>2.9</cell><cell>2.5 + 0.4</cell></row><row><cell>Training time</cell><cell cols="2">2.5 1000 × 217/(24 × 3600)</cell></row><row><cell>Other (collection, evaluation, checkpointing)</cell><cell>0.4</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Raw scores and human-normalized metrics for search-based and model-free methods.In the main body of the paper, we evaluated the utility of DIAMOND for the purpose of training RL agents in a world model on the well-established Atari 100k benchmark<ref type="bibr" target="#b33">(Kaiser et al., 2019)</ref>, and demonstrated DIAMOND's diffusion world model could be applied to model a more complex 3D environment from the game Counter-Strike: Global Offensive. In this section, we provide early experiments investigating the effectiveness of DIAMOND's diffusion world model by directly evaluating the visual quality of the trajectories they generate. The two environments we consider are presented in Section M.1 below.We use the Counter-Strike: Global Offensive dataset introduced by Pearce and Zhu (2022).Here we use the Clean dataset containing 190k frames (3.3 hours) of high-skill human gameplay, captured on the Dust II map. This contains observations and actions (mouse and keyboard) captured at 16Hz. We use 150k frames (2.6 hours) for training and 40k frames (0.7 hours) for evaluation. We resize observations to 64×64 pixels, and use no augmentation.Motorway driving. We use the dataset from Santana and Hotz (2016) 5 , which contains camera and metadata captured from human drivers on US motorways. We select only trajectories captured in daylight, and exclude the first and last 5 minutes of each trajectory (typically traveling to/from a motorway), leaving 4.4 hours of data. We use five trajectories for training (3.6 hours) and two for testing (0.8 hours). We downsample the dataset to 10Hz, resize observations to 64×64, and for actions use the (normalized) steering angle and acceleration. During training, we apply data augmentation of shift &amp; scale, contrast, brightness, and saturation, and mirroring.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Search-based</cell><cell></cell><cell cols="2">Model-free</cell><cell></cell><cell></cell></row><row><cell>Game</cell><cell cols="4">Human MuZero EfficientZero CURL</cell><cell>SPR</cell><cell>SR-SPR</cell><cell cols="2">BBF DIAMOND (ours)</cell></row><row><cell>Alien</cell><cell>7127.7</cell><cell>530.0</cell><cell>808.5</cell><cell>711.0</cell><cell>841.9</cell><cell>1107.8</cell><cell>1173.2</cell><cell>744.1</cell></row><row><cell>Amidar</cell><cell>1719.5</cell><cell>38.8</cell><cell>148.6</cell><cell>113.7</cell><cell>179.7</cell><cell>203.4</cell><cell>244.6</cell><cell>225.8</cell></row><row><cell>Assault</cell><cell>742.0</cell><cell>500.1</cell><cell>1263.1</cell><cell>500.9</cell><cell>565.6</cell><cell>1088.9</cell><cell>2098.5</cell><cell>1526.4</cell></row><row><cell>Asterix</cell><cell>8503.3</cell><cell>1734.0</cell><cell>25557.8</cell><cell>567.2</cell><cell>962.5</cell><cell>903.1</cell><cell>3946.1</cell><cell>3698.5</cell></row><row><cell>BankHeist</cell><cell>753.1</cell><cell>192.5</cell><cell>351.0</cell><cell>65.3</cell><cell>345.4</cell><cell>531.7</cell><cell>732.9</cell><cell>19.7</cell></row><row><cell>BattleZone</cell><cell>37187.5</cell><cell>7687.5</cell><cell cols="3">13871.2 8997.8 14834.1</cell><cell cols="2">17671.0 24459.8</cell><cell>4702.0</cell></row><row><cell>Boxing</cell><cell>12.1</cell><cell>15.1</cell><cell>52.7</cell><cell>0.9</cell><cell>35.7</cell><cell>45.8</cell><cell>85.8</cell><cell>86.9</cell></row><row><cell>Breakout</cell><cell>30.5</cell><cell>48.0</cell><cell>414.1</cell><cell>2.6</cell><cell>19.6</cell><cell>25.5</cell><cell>370.6</cell><cell>132.5</cell></row><row><cell>ChopperCommand</cell><cell>7387.8</cell><cell>1350.0</cell><cell>1117.3</cell><cell>783.5</cell><cell>946.3</cell><cell>2362.1</cell><cell>7549.3</cell><cell>1369.8</cell></row><row><cell>CrazyClimber</cell><cell cols="2">35829.4 56937.0</cell><cell cols="3">83940.2 9154.4 36700.5</cell><cell cols="2">45544.1 58431.8</cell><cell>99167.8</cell></row><row><cell>DemonAttack</cell><cell>1971.0</cell><cell>3527.0</cell><cell>13003.9</cell><cell>646.5</cell><cell>517.6</cell><cell cols="2">2814.4 13341.4</cell><cell>288.1</cell></row><row><cell>Freeway</cell><cell>29.6</cell><cell>21.8</cell><cell>21.8</cell><cell>28.3</cell><cell>19.3</cell><cell>25.4</cell><cell>25.5</cell><cell>33.3</cell></row><row><cell>Frostbite</cell><cell>4334.7</cell><cell>255.0</cell><cell cols="2">296.3 1226.5</cell><cell>1170.7</cell><cell>2584.8</cell><cell>2384.8</cell><cell>274.1</cell></row><row><cell>Gopher</cell><cell>2412.5</cell><cell>1256.0</cell><cell>3260.3</cell><cell>400.9</cell><cell>660.6</cell><cell>712.4</cell><cell>1331.2</cell><cell>5897.9</cell></row><row><cell>Hero</cell><cell>30826.4</cell><cell>3095.0</cell><cell cols="2">9315.9 4987.7</cell><cell>5858.6</cell><cell>8524.0</cell><cell>7818.6</cell><cell>5621.8</cell></row><row><cell>Jamesbond</cell><cell>302.8</cell><cell>87.5</cell><cell>517.0</cell><cell>331.0</cell><cell>366.5</cell><cell>389.1</cell><cell>1129.6</cell><cell>427.4</cell></row><row><cell>Kangaroo</cell><cell>3035.0</cell><cell>62.5</cell><cell>724.1</cell><cell>740.2</cell><cell>3617.4</cell><cell>3631.7</cell><cell>6614.7</cell><cell>5382.2</cell></row><row><cell>Krull</cell><cell>2665.5</cell><cell>4890.8</cell><cell cols="2">5663.3 3049.2</cell><cell>3681.6</cell><cell>5911.8</cell><cell>8223.4</cell><cell>8610.1</cell></row><row><cell>KungFuMaster</cell><cell cols="2">22736.3 18813.0</cell><cell cols="3">30944.8 8155.6 14783.2</cell><cell cols="2">18649.4 18991.7</cell><cell>18713.6</cell></row><row><cell>MsPacman</cell><cell>6951.6</cell><cell>1265.6</cell><cell cols="2">1281.2 1064.0</cell><cell>1318.4</cell><cell>1574.1</cell><cell>2008.3</cell><cell>1958.2</cell></row><row><cell>Pong</cell><cell>14.6</cell><cell>-6.7</cell><cell>20.1</cell><cell>-18.5</cell><cell>-5.4</cell><cell>2.9</cell><cell>16.7</cell><cell>20.4</cell></row><row><cell>PrivateEye</cell><cell>69571.3</cell><cell>56.3</cell><cell>96.7</cell><cell>81.9</cell><cell>86.0</cell><cell>97.9</cell><cell>40.5</cell><cell>114.3</cell></row><row><cell>Qbert</cell><cell>13455.0</cell><cell>3952.0</cell><cell>13781.9</cell><cell>727.0</cell><cell>866.3</cell><cell>4044.1</cell><cell>4447.1</cell><cell>4499.3</cell></row><row><cell>RoadRunner</cell><cell>7845.0</cell><cell>2500.0</cell><cell cols="3">17751.3 5006.1 12213.1</cell><cell cols="2">13463.4 33426.8</cell><cell>20673.2</cell></row><row><cell>Seaquest</cell><cell>42054.7</cell><cell>208.0</cell><cell>1100.2</cell><cell>315.2</cell><cell>558.1</cell><cell>819.0</cell><cell>1232.5</cell><cell>551.2</cell></row><row><cell>UpNDown</cell><cell>11693.2</cell><cell>2896.9</cell><cell cols="5">17264.2 2646.4 10859.2 112450.3 12101.7</cell><cell>3856.3</cell></row><row><cell>#Superhuman (↑)</cell><cell>N/A</cell><cell>5</cell><cell>14</cell><cell>2</cell><cell>6</cell><cell>9</cell><cell>12</cell><cell>11</cell></row><row><cell>Mean (↑)</cell><cell>1.000</cell><cell>0.562</cell><cell>1.943</cell><cell>0.261</cell><cell>0.616</cell><cell>1.271</cell><cell>2.247</cell><cell>1.459</cell></row><row><cell>IQM (↑)</cell><cell>1.000</cell><cell>0.288</cell><cell>1.047</cell><cell>0.113</cell><cell>0.337</cell><cell>0.700</cell><cell>1.139</cell><cell>0.641</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>https://en.wikipedia.org/wiki/Breakout_(video_game)#Gameplay</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>This section was added after NeurIPS acceptance, following community interest in later CS:GO experiments.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2"><p>https://github.com/commaai/research</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments and Disclosure of Funding</head><p>We would like to thank <rs type="person">Andrew Foong</rs>, <rs type="person">Bálint Máté</rs>, <rs type="person">Clément Vignac</rs>, <rs type="person">Maxim Peter</rs>, <rs type="person">Pedro Sanchez</rs>, <rs type="person">Rich Turner</rs>, <rs type="person">Stéphane Nguyen</rs>, <rs type="person">Tom Lee</rs>, <rs type="person">Trevor McInroe</rs> and <rs type="person">Weipu Zhang</rs> for insightful discussions and comments. Adam and Eloi met during an internship at <rs type="institution">Microsoft Research Cambridge</rs>, and would like to thank the <rs type="institution">Game Intelligence team</rs>, including <rs type="person">Anssi Kanervisto</rs>, <rs type="person">Dave Bignell</rs>, <rs type="person">Gunshi Gupta</rs>, <rs type="person">Katja Hofmann</rs>, <rs type="person">Lukas Schäfer</rs>, <rs type="person">Raluca Georgescu</rs>, <rs type="person">Sam Devlin</rs>, <rs type="person">Sergio Valcarcel Macua</rs>, <rs type="person">Shanzheng Tan</rs>, <rs type="person">Tabish Rashid</rs>, <rs type="person">Tarun Gupta</rs>, <rs type="person">Tim Pearce</rs>, and <rs type="person">Yuhan Cao</rs>, for their support in the early stages of this project, and a great summer.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Model architectures</head><p>The diffusion model D θ is a standard U-Net 2D <ref type="bibr" target="#b58">(Ronneberger et al., 2015)</ref>, conditioned on the last 4 frames and actions, as well as the diffusion time τ . We use frame stacking for observation conditioning, and adaptive group normalization <ref type="bibr" target="#b89">(Zheng et al., 2020)</ref> for action and diffusion time conditioning.</p><p>The reward/termination model R ψ layers are shared except for the final prediction heads. The model takes as input a sequence of frames and actions, and forwards it through convolutional residual blocks <ref type="bibr" target="#b24">(He et al., 2015)</ref> followed by an LSTM cell <ref type="bibr" target="#b44">(Mnih et al., 2016;</ref><ref type="bibr" target="#b28">Hochreiter and Schmidhuber, 1997;</ref><ref type="bibr" target="#b18">Gers et al., 2000)</ref>. Before starting the imagination procedure, we burn-in <ref type="bibr" target="#b35">(Kapturowski et al., 2018)</ref> the conditioning frames and actions to initialize the hidden and cell states of the LSTM.</p><p>The weights of the policy π ϕ and value network V ϕ are shared except for the last layer. In the following, we refer to (π, V ) ϕ as the "actor-critic" network, even though V is technically a statevalue network, not a critic. This network takes as input a frame, and forwards it through convolutional trunk followed by an LSTM cell. The convolutional trunk consists of four residual blocks and 2x2 max-pooling with stride 2. The main path of the residual blocks consists of a group normalization <ref type="bibr" target="#b82">(Wu and He, 2018)</ref> layer, a SiLU activation <ref type="bibr" target="#b16">(Elfwing et al., 2018)</ref>, and a 3x3 convolution with stride 1 and padding 1. Before starting the imagination procedure, we burn-in the conditioning frames to initialize the hidden and cell states of the LSTM.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Please refer to</head><p>Sample initial buffer (x 0 t-L+1 , a t-L+1 , . . . , x 0 t ) ∼ D Burn-in buffer with R ψ , π ϕ and V ϕ to initialize LSTM states</p><p>i+1 by simulating reverse diffusion process with D θ Compute V ϕ (x i ) for i = t, . . . , t + H Compute RL losses L V (ϕ) and L π (ϕ) Update π ϕ and V ϕ K Quantitative analysis of autoregressive model drift Figure <ref type="figure">8</ref>: Average pixel drift between an imagined trajectory and the corresponding reference trajectory collected with an expert in Breakout. The trajectories are each 1000 timesteps, starting from the same frame and following the same sequence of actions. Each line displays the average and shaded standard deviation of 400 reference trajectories held out from training data. DDPM becomes more stable with increasing number of denoising steps, but is less stable than 1-step EDM, even with 10 denoising steps. The drift we observe for EDM corresponds to differences in the imagined trajectory rather than a pathological color shift as we see in Figure <ref type="figure">3a</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L Quantitative ablation on reducing the number of denoising steps</head><p>Table <ref type="table">7</ref> provides a quantitative ablation of the effect of reducing the number of denoising steps used for our EDM diffusion world model from 3 (used for Table <ref type="table">1</ref>) to 1, for DIAMOND's 10 highest performing games. Note that the 1-step results correspond to a single seed only so will have higher variance. Nonetheless, these results provide some signal that agents trained with 1 denoising step perform worse than our default choice of 3, particularly for the game Boxing, despite the apparent similarity in Figure <ref type="figure">8</ref>. This additional evidence supports our qualitative analysis in Section 5.2. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning at the edge of the statistical precipice</title>
		<author>
			<persName><forename type="first">R</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schwarzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bellemare</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="29304" to="29320" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Ajay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Agrawal</surname></persName>
		</author>
		<title level="m">Is conditional generative modeling all you need for decision-making? International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jelley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kanervisto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pearce</surname></persName>
		</author>
		<title level="m">Diffusion world models</title>
		<imprint>
			<publisher>OpenReview</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Reverse-time diffusion equation models</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Stochastic Processes and their Applications</title>
		<imprint>
			<date type="published" when="1982">1982</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="313" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Computer methods for ordinary differential equations and differential-algebraic equations</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">M</forename><surname>Ascher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Petzold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Society for Industrial and Applied Mathematics</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural game engine: Accurate learning of generalizable forward models from pixels</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bamford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Lucas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE Conference on Games (CoG)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="81" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">O</forename><surname>Bar-Tal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chefer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Tov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Herrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Paiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ephrat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Michaeli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.12945</idno>
		<title level="m">Lumiere: A space-time diffusion model for video generation</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">T</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Peebles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Depue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schnurr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Luhman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Luhman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>Video generation models as world simulators</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Genie: Generative interactive environments</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Dennis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Parker-Holder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mavalankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Steigerwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Apps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Forty-first International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Muse: Text-to-image generation via masked generative transformers</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Barber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Maschinot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lezama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="4055" to="4075" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Maskgit: Masked generative image transformer</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="11315" to="11325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">3d u-net: learning dense volumetric segmentation from sparse annotation</title>
		<author>
			<persName><forename type="first">Ö</forename><surname>Çiçek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abdulkadir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Lienkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer-Assisted Intervention-MICCAI 2016: 19th International Conference</title>
		<meeting><address><addrLine>Athens, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016-10-17">2016. October 17-21, 2016</date>
			<biblScope unit="page" from="424" to="432" />
		</imprint>
	</monogr>
	<note>Proceedings, Part II 19</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Magnetic control of tokamak plasmas through deep reinforcement learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Degrave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Felici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Buchli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Neunert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tracey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Carpanese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ewalds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hafner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abdolmaleki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>De Las Casas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">602</biblScope>
			<biblScope unit="page" from="414" to="419" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Diffusion models beat gans on image synthesis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nichol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="8780" to="8794" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.03570</idno>
		<title level="m">Diffusion world model</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sigmoid-weighted linear units for neural network function approximation in reinforcement learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Elfwing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Uchibe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Doya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="3" to="11" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Taming transformers for high-resolution image synthesis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rombach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="12873" to="12883" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning to forget: Continual prediction with LSTM</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Gers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cummins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2451" to="2471" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Recurrent world models facilitate policy evolution</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="2451" to="2463" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Dream to control: Learning behaviors by latent imagination</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hafner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Mastering atari with discrete world models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hafner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Hafner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pasukonis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.04104</idno>
		<title level="m">Mastering diverse domains through world models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03385</idno>
		<title level="m">Deep residual learning for image recognition</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Gans trained by a two time-scale update rule converge to a local nash equilibrium</title>
		<author>
			<persName><forename type="first">M</forename><surname>Heusel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ramsauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6840" to="6851" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gritsenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2204.03458" />
		<title level="m">Video diffusion models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yeo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Murez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fedoseev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.17080</idno>
		<title level="m">Gaia-1: A generative world model for autonomous driving</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Estimation of non-normalized statistical models by score matching</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="695" to="709" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Whiteson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Foerster</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2404.06356</idno>
		<title level="m">Policy-guided diffusion</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Planning with diffusion for flexible behavior synthesis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Janner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="9902" to="9915" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Model-based reinforcement learning for atari</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Babaeizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Milos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Osinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Czechowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kozakowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.00374</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.08228</idno>
		<title level="m">Neural gpus learn algorithms</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Recurrent experience replay in distributed reinforcement learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kapturowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ostrovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dabney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Elucidating the design space of diffusion-based generative models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aittala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="26565" to="26577" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning to simulate dynamic environments with gamegan</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Philion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1231" to="1240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<title level="m">A path towards autonomous machine intelligence version 0.9</title>
		<imprint>
			<publisher>OpenReview</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2022" to="2026" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Backpropagation applied to handwritten zip code recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hubbard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Jackel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="541" to="551" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Adaptdiffuser: Diffusion models as adaptive self-evolving planners</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tomizuka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Parker-Holder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.06614</idno>
		<title level="m">Synthetic experience replay</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Diffusion hyperfeatures: Searching through time and space for semantic correspondence</title>
		<author>
			<persName><forename type="first">G</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dunlap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Holynski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Micheli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fleuret</surname></persName>
		</author>
		<title level="m">Transformers are sample-efficient world models. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Asynchronous methods for deep reinforcement learning</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 33rd International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Balcan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<meeting>The 33rd International Conference on Machine Learning<address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="1928" to="1937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Human-level control through deep reinforcement learning</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Fidjeland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ostrovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">518</biblScope>
			<biblScope unit="issue">7540</biblScope>
			<biblScope unit="page" from="529" to="533" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Improved denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Q</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Nuti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Franzmeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.01804</idno>
		<title level="m">Extracting reward functions from diffusion models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Training language models to follow instructions with human feedback</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="27730" to="27744" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Imitating human behaviour with diffusion models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rashid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kanervisto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bignell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Macua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Momennejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Devlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Counter-strike deathmatch with large-scale behavioural cloning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 IEEE Conference on Games (CoG)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="104" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Scalable diffusion models with transformers</title>
		<author>
			<persName><forename type="first">W</forename><surname>Peebles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="4195" to="4205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Podell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>English</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lacey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blattmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dockhorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Penna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rombach</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.01952</idno>
		<title level="m">Sdxl: Improving latent diffusion models for high-resolution image synthesis</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Hierarchical text-conditional image generation with clip latents</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.06125</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Zero-shot text-to-image generation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pavlov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Transformer-based world models are happy with 100k interactions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Robine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Höftmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Uelwer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">High-resolution image synthesis with latent diffusion models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rombach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blattmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lorenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="10684" to="10695" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer-Assisted Intervention-MICCAI 2015: 18th International Conference</title>
		<meeting><address><addrLine>Munich, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015-09">2015. October 5-9, 2015</date>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
	<note>Proceedings, Part III 18</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Photorealistic text-to-image diffusion models with deep language understanding</title>
		<author>
			<persName><forename type="first">C</forename><surname>Saharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Whang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ghasemipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gontijo Lopes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Karagol Ayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="36479" to="36494" />
			<date type="published" when="2022">2022a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Image superresolution via iterative refinement</title>
		<author>
			<persName><forename type="first">C</forename><surname>Saharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Santana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hotz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.01230</idno>
		<title level="m">Learning a driving simulator</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Mastering atari, go, chess and shogi by planning with a learned model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schmitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lockhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Graepel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">588</biblScope>
			<biblScope unit="issue">7839</biblScope>
			<biblScope unit="page" from="604" to="609" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Schwarzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S O</forename><surname>Ceron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Castro</surname></persName>
		</author>
		<title level="m">Bigger, better, faster: Human-level atari with human-level efficiency. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Mastering the game of go with deep neural networks and tree search</title>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Panneershelvam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lanctot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">529</biblScope>
			<biblScope unit="page" from="484" to="489" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Make-a-video: Text-to-video generation without text-video data</title>
		<author>
			<persName><forename type="first">U</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Polyak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ashual</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Gafni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Stylegan-v: A continuous video generator with the price, image quality and perks of stylegan2</title>
		<author>
			<persName><forename type="first">I</forename><surname>Skorokhodov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tulyakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elhoseiny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="3626" to="3636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Maheswaranathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
		<title level="m">Deep unsupervised learning using nonequilibrium thermodynamics. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<title level="m">Scorebased generative modeling through stochastic differential equations. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Dyna, an integrated architecture for learning, planning, and reacting</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Sigart Bulletin</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="160" to="163" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Reinforcement learning: An introduction</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Van Steenkiste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kurach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Marinier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Michalski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.01717</idno>
		<title level="m">Towards accurate generative models of video: A new metric &amp; challenges</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Diffusion models are real-time game engines</title>
		<author>
			<persName><forename type="first">D</forename><surname>Valevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Leviathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Arar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fruchter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Neural discrete representation learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Phenaki: Variable length video generation from open domain textual descriptions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Babaeizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-J</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Moraldo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Saffar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kunze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">A connection between score matching and denoising autoencoders</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1661" to="1674" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Extracting and composing robust features with denoising autoencoders</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine learning</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Diffusion policies as an expressive policy class for offline reinforcement learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Dueling network architectures for deep reinforcement learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hessel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hasselt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lanctot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Duan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.14806</idno>
		<title level="m">Godiva: Generating open-domain videos from natural descriptions</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Daydreamer: World models for physical robot learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Escontrela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hafner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Goldberg</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Robot Learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="2226" to="2240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Group normalization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Open-vocabulary panoptic segmentation with text-to-image diffusion models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Byeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>De Mello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="2955" to="2966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Temporally consistent transformers for video generation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hafner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">Videogpt: Video generation using vq-vae and transformers</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Srinivas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.10157</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Mastering atari games with limited data</title>
		<author>
			<persName><forename type="first">W</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kurutach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="page">34</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">The unreasonable effectiveness of deep features as a perceptual metric</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="586" to="595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Storm: Efficient stochastic transformer based world models for reinforcement learning</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-seventh Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Learning semantic-aware normalization for generative adversarial networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-J</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
