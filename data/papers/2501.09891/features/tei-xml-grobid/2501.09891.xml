<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Evolving Deeper LLM Thinking</title>
				<funder>
					<orgName type="full">Google DeepMind FunSearch</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-01-17">17 Jan 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kuang-Huei</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ian</forename><surname>Fischer</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yueh-Hua</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dave</forename><surname>Marwood</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shumeet</forename><surname>Baluja</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xinyun</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Google</forename><surname>Deepmind</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Uc</forename><forename type="middle">San</forename><surname>Diego</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Evolving Deeper LLM Thinking</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-01-17">17 Jan 2025</date>
						</imprint>
					</monogr>
					<idno type="MD5">2B6104046A9FFCD296B68C9D84E81574</idno>
					<idno type="arXiv">arXiv:2501.09891v1[cs.AI]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-02-21T16:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We explore an evolutionary search strategy for scaling inference time compute in Large Language Models. The proposed approach, Mind Evolution, uses a language model to generate, recombine and refine candidate responses. The proposed approach avoids the need to formalize the underlying inference problem whenever a solution evaluator is available. Controlling for inference cost, we find that Mind Evolution significantly outperforms other inference strategies such as Best-of-N and Sequential Revision in natural language planning tasks. In the TravelPlanner and Natural Plan benchmarks, Mind Evolution solves more than 98% of the problem instances using Gemini 1.5 Pro without the use of a formal solver.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>How can a large language model (LLM) be guided to think deeper about a complex problem and leverage inference time compute to improve its problem solving ability? Prior research has investigated various strategies for leveraging inference time compute, such as chain-of-thought <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b20">21]</ref>, self-consistency <ref type="bibr" target="#b38">[39]</ref>, sequential revision based on feedback <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b0">1]</ref>, and search guided by auxiliary verifiers or evaluators <ref type="bibr" target="#b42">[43]</ref>. When a solution evaluator is available, search strategies have an advantage of being able to reliably improve problem solving ability with increased compute. For example, methods such as Bestof-N <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25]</ref> and tree search <ref type="bibr" target="#b36">[37]</ref> naturally exploit additional compute to explore a larger set of solution candidates, thereby increasing the probability of finding a successful solution.</p><p>To better exploit inference time compute, we propose an evolutionary search strategy for LLMs that combines free-flowing stochastic exploration with large-scale iterative refinement. We refer to this approach as Mind Evolution. As illustrated in Figure <ref type="figure" target="#fig_5">1</ref>, Mind Evolution is a genetic search strategy that evolves a diverse population of candidate solutions, leveraging an LLM to generate, recombine and refine solution candidates based on feedback from an evaluator. The overall process is analogous to combining divergent thinking (free-flowing parallel idea exploration) with convergent thinking (idea evaluation and selection), considered as hallmarks of intelligent problem solving behavior <ref type="bibr" target="#b13">[14]</ref>.</p><p>Unlike Best-of-N, which searches broadly by generating independent candidates for evaluation, Mind Evolution searches both broadly and deeply, exploring a diverse set of candidates and refining the most promising alternatives. Unlike sequential reasoning approaches, such as self-refinement or tree search <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b24">25]</ref>, which require evaluation of individual reasoning steps, Mind Evolution performs global refinement of complete solutions, and therefore only requires a global solution evaluator rather than a stepwise process reward. Also, typical of evolutionary methods, Mind Evolution can be easily parallelized.</p><p>There has been prior work on combining evolutionary search with LLMs, primarily in the literature on evolutionary program generation <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b5">6]</ref>. However, this prior work focuses on searching through formal program spaces, using guidance from execution feedback or code explanation. By contrast, Mind Evolution is not restricted to searching in a formal space. This allows Mind Evolution to be applied to problems that are not formalized, or remain difficult to formalize, as long as a programmatic solution evaluator is available. In particular, we focus on natural language planning tasks where candidate solutions can still be automatically parsed, evaluated and critiqued using an implementable oracle evaluator. This approach exploits the observation that it is often easier to evaluate the quality of a candidate solution than it is to generate good solutions for a given problem <ref type="bibr" target="#b10">[11]</ref>.</p><p>In the domain of natural language planning, we consider the TravelPlanner <ref type="bibr" target="#b41">[42]</ref> and Natural Plan <ref type="bibr" target="#b46">[47]</ref> benchmarks, where constraint satisfaction problems are expressed in natural language without any explicit formalization of the underlying objectives, constraints or variables. These problems require a set of interconnected decisions that satisfy a set of global and local constraints. For example, in TravelPlanner, a travel plan should be produced that respects various accommodation and dinning constraints, while also considering budget limitations and other preferences, all expressed solely in natural language. To date, LLMs have yet to achieve good performance on these tasks Feedbacks from Evaluator: „ÄÇThe cost exceeds budget limit „ÄÇDining preference is not met ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Terminate at</head><p>(a) A valid solution (b) Gen N (max compute budget)</p><p>Figure <ref type="figure" target="#fig_5">1</ref> | Mind Evolution is a genetic-based evolutionary search strategy that operates in natural language space. The figure illustrates how Mind Evolution evolves a population of solution candidates toward higher quality candidates for a travel planning task. The candidate population is improved through an iterative process, where an LLM is used to recombine and refine candidates in each iteration.</p><p>without the aid of formal solvers <ref type="bibr" target="#b15">[16]</ref>. For example, Gemini 1.5 Flash and o1-preview only achieve a success rate of 5.6% and 11.7% on TravelPlanner respectively, while for the Meeting Planning domain in Natural Plan, they respectively only achieve 20.8% and 44.2%. Even exploiting Best-of-N over 800 independently generated responses, Gemini 1.5 Flash still only achieves 55.6% success on TravelPlanner and 69.4% on Meeting Planning. In this paper, we show that exploration and refinement with evolutionary search can notably improve problem solving ability. In particular, when controlling for inference time compute, Mind Evolution allows Gemini 1.5 Flash to achieve a 95.6% success rate on TravelPlanner and 85.0% on Meeting Planning. We further experiment with a two-stage approach, where any unsolved problem instances are subsequently tackled by Mind Evolution with Gemini 1.5 Pro, which leads to 100% success on TravelPlanner and 98.4% on Meeting Planning. All of the experiments in this paper only use off-the-shelf LLMs without any finetuning.</p><p>To our knowledge, the only prior work that achieves comparable performance on the TravelPlanner benchmark is <ref type="bibr" target="#b15">[16]</ref>, which leverages an auxiliary formal solver and requires the LLM to first translate a given problem instance into an equivalent formalization. In general, it takes significant effort and expertise to correctly formalize a problem expressed in natural language; prompting an LLM to correctly perform such a translation requires at least as much domain expertise. Mind Evolution removes this constraint by directly optimizing solutions in the space of natural language.</p><p>Finally, we introduce a new benchmark problem, StegPoet, that involves encoding a hidden message in a generated essay, story or poem. This form of stenography <ref type="bibr" target="#b32">[33]</ref> is difficult to formalize and solve, yet a hidden message detector can still be implemented to programmatically guide the search. Our motivation is to demonstrate the applicability of search beyond natural language domains that can be easily formalized. We find that Mind Evolution allows Gemini 1.5 Pro to achieve a success rate of 87% in this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Pairing LLMs with Evolutionary Search In addition to the program generation studies discussed in Section 1, several recent works have explored combining LLMs and evolution for numerical optimization <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b2">3]</ref> and combinatorial optimization <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b43">44]</ref>. The problem spaces we tackle in this work, such as natural language planning, can also be viewed as combinatorial optimization problems -optimizing plans subject to constraints specified in natural language. In contrast to these previous studies, we focus on evolving solutions in natural language spaces instead of formal spaces. This removes the requirement of task formalization, which requires significant effort and expert knowledge for each task instance.</p><p>Other works have also applied evolutionary search to prompt optimization, with the goal of improving performance on target tasks <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b14">15]</ref>. Among these, EvoAgent <ref type="bibr" target="#b44">[45]</ref> also evaluated their approach on the TravelPlanner benchmark. In contrast to our work, which performs evolutionary search directly on plans, EvoAgent evolves new LLM agents to form a multi-agent system for problem solving. Their best success rate on the TravelPlanner validation set was 7.2% with GPT-4, while our approach achieved over 95% with Gemini 1.5 Flash.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pairing LLMs with Evaluators</head><p>In this work, we evaluate solutions with program-based evaluators during the evolutionary search. The idea of integrating execution-based evaluators in the inference loop has been widely adopted in the literature of code generation, where the execution environment provides feedback for the LLM to fix bugs in the generated code <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b35">36]</ref>.</p><p>Other prior work has also considered using learned verifiers, reward models, or self-evaluation for response refinement <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b29">30]</ref>, search <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b34">35]</ref>, and improving model learning <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b0">1]</ref>. These approaches can often be applied to wider domains and free-form solutions, but learned feedback models or self-evaluators can be noisy and are not perfectly reliable. We leave consideration of such approximate feedback mechanisms for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>Mind Evolution employs a genetic search strategy, combined with an LLM and a tailored set of prompts, to orchestrate an efficient search for solutions to natural language planning tasks. Before describing Mind Evolution in detail, we first provide a brief overview of language-based genetic algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Language-based Genetic Algorithm Overview</head><p>Genetic algorithms <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b30">31]</ref> are a meta-heuristic inspired by natural selection. In a genetic algorithm, a population of candidate solutions is evolved toward populations that contain a greater proportion of higher quality individuals with respect to a target optimization objective. Such an objective is also often referred to as the "fitness" function. Each individual candidate has a genetic representation that can be mutated and recombined with others.</p><p>Evolutionary search usually begins with a population of independently generated candidate solutions. In each generation, the fitness of every individual is evaluated with respect to the target objective. Candidates are then stochastically selected for reproduction based on their fitness ("selection"). In reproduction, the genetic representations of selected parents are combined ("crossover") and potentially altered ("mutation") to produce new child solutions. Such a process creates the next generation of children, which then enter the population. Population fitness generally increases over successive generations, as parents with greater fitness are more likely to be selected for recombination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Island Model</head><p>To sustain diversity in an evolving population it is also helpful to introduce an island model <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b4">5]</ref>, where distinct sub-populations ("islands") are created and evolved independently between "migration" and "island reset" events that occur at specified frequencies. For a migration operation, the solutions on one island are stochastically chosen based on fitness to migrate to an adjacent island. For an Island Reset operation, the populations on islands with low overall fitness are replaced by strong solutions from the global population, which also has a selection effect. The island model has been adopted in recent successful efforts, such as FunSearch <ref type="bibr" target="#b33">[34]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language-based Genetic Representation</head><p>The individual candidates in a language-based genetic algorithm are represented by natural language. This allows the strong language understanding and generation capabilities of an LLM to be leveraged to implement powerful recombination (crossover and mutation) and island reset operations through prompting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Mind Evolution</head><p>Figure <ref type="figure" target="#fig_5">1</ref> illustrates the design of Mind Evolution, with its hyperparameters listed in Table <ref type="table" target="#tab_0">1</ref>. The core components of Mind Evolution are:</p><p>1. the specific choices for the selection and migration operations; 2. the set of prompts that implement the initialization, recombination (crossover and mutation), and island reset operations with an LLM; 3. the fitness function that evaluates the quality of a given solution and optionally provides feedback on issues detected.</p><p>The overall evolution process is repeated until a valid solution is found, or until ùëÅ gens generations have been completed, after which the best scoring candidate is returned. Note that for many classical search problems (e.g., NP-complete problems), verifying solutions can be much easier than solving the problem <ref type="bibr" target="#b10">[11]</ref>. Similarly, we observe that it is possible to write an evaluation function for the natural language planning tasks we consider. The ability to check the correctness of a candidate solution does not obviously lead to the ability to generate a valid solution in the tasks we consider. That is, implementing an evaluation function is not equivalent to solving the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fitness Evaluation</head><p>Population Initialization Given a target problem, we independently sample ùëÅ convs initial solutions by prompting an LLM with a description of the problem, any information needed for solving the problem, and relevant instructions. If ùëÅ seq &gt; 1, each of these initial solutions is then evaluated and refined sequentially through ùëÅ seq -1 additional turns of the "Refinement through Critical Conversation" process explained below. In total, this initialization procedure generates ùëÅ convs √ó ùëÅ seq candidate solutions, which forms the initial population on the first island for the first generation.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Refinement through Critical Conversation (RCC)</head><p>Given a candidate solution (or a set of candidate solutions for the process of recombination) we leverage an LLM to generate an improved solution by organizing a critical conversation between a "critic" character and an "author" character, as illustrated in Figure <ref type="figure" target="#fig_2">2</ref>. Separating these two roles is intended to improve the critical thinking ability of an LLM. Each conversational turn is structured as a prompt-driven process, where solutions are refined based on critical feedback, similar to Reflexion <ref type="bibr" target="#b35">[36]</ref>. In particular, the critic first analyzes the candidate solution(s) provided as input, interprets the textual evaluation feedback, and suggest ways to correct any issues presented in the feedback. The author then proposes a single refined solution based on the input candidate(s), the subsequent evaluation(s), and the critic's analyses. The specific prompts used to drive these conversations are given in Appendix A.1. An ablation study in Section 4.4 shows that the critic's analysis step provides substantial performance improvements.</p><p>Selection To produce the next generation of an island, we follow Boltzmann tournament selection <ref type="bibr" target="#b12">[13]</ref> where 0 to ùëÅ parent parents are stochastically sampled from the population according a probability distribution that is derived from a softmax transformation of their fitness scores. In this way, higher-performing solutions are more likely to be selected for reproduction, while other candidates can still be occasionally selected for diversity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Crossover and Mutation</head><p>We implement the crossover and mutation operations as a single recombination step, where an LLM is instructed to improve a given set of parents using the RCC process described above (Figure <ref type="figure" target="#fig_2">2</ref>). In particular, for recombination we sample 1 to ùëÅ parent parents and alter Step (b) in Figure <ref type="figure" target="#fig_2">2</ref> to first incorporate the evaluation results of the parents, then apply the critic to all parents and propose the revised solution as an "initial solution" for the next generation. Then, if ùëÅ seq &gt; 1, we continue to follow Steps (c)(d)(e) to sequentially generate ùëÅ seq -1 child solutions by refining each previous child using the RCC process.</p><p>For each generation on each island, ùëÅ convs √ó ùëÅ seq child solutions are added to the island population, with duplicate solutions removed. For selection, we follow a Boltzmann tournament instead of explicitly retiring candidate solutions, except when performing an Island Reset below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Migration between Islands</head><p>Between migration events, each island population is evolved independently. During a migration, the top ùëÅ emigrate solutions are cloned from the current Island ùëñ to the next Island ùëñ + 1 after completing the generation on the current island (we update the populations on the islands sequentially from 1 to ùëÅ island ). Migration is performed cyclically between the islands, so emigrants from Island ùëÅ island arrive at Island 1. We have found that this form of cyclic migration accelerates the overall evolution process.</p><p>Island Reset Island reset happens every ùëÅ reset interval generations. During an Island Reset event, the top performers are first selected from the global population, the populations on ùëÅ reset islands with the lowest average scores are retired, and the selected top performers are cloned onto the reset islands. To select top performers, we explore two approaches: (1) directly select the top ùëÅ top candidates according to fitness; and (2) first select the top ùëÅ candidate candidates according to fitness, then prompt the LLM to select ùëÅ top good candidates from this pool that are substantially different from each other. The ablation study in <ref type="bibr">Section 4.4</ref> show that the latter strategy, using an LLM for Island Reset, achieves better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>Tasks We evaluate Mind Evolution on three benchmark natural language planning domains: two tasks from Natural Plan <ref type="bibr" target="#b46">[47]</ref>, including Trip Planning (Section 4.2) and Meeting Planning (Section 4.3), and the TravelPlanner <ref type="bibr" target="#b41">[42]</ref> benchmark (Section 4.1). (We omit the Calendar Scheduling task from Natural Plan, since these problems can be solved by enumeration.) Implementation details for each task is provided in Appendix A, including the prompts (Appendix A.1) and evaluation functions used (Appendix A.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models</head><p>We use Gemini 1.5 Flash (gemini-1.5-flash-001) as the default LLM in our experiments below. The hyperparameters used when applying Mind Evolution to Flash are specified in Table <ref type="table" target="#tab_0">1</ref>. In addition to evaluating Mind Evolution with the Flash model, we also investigate a two-stage approach, where Gemini 1.5 Pro model (gemini-1.5-pro-exp-0827) is used to tackle problems that are not solved within the ùëÅ gens generation limit. Such a two-stage approach provides better cost-efficiency than using the Pro model on every problem instance. When applying Mind Evolution to the Pro model we alter the hyperparameters from those specified in Table <ref type="table" target="#tab_0">1</ref> to: ùëÅ convs = 8, ùëÅ seq = 3, ùëÅ parent = 10, ùëÉùëü no parents = 1/5.</p><p>Baselines For each task, we compare Mind Evolution to three baseline search strategies that use the same solution evaluator and task-specific prompts:</p><p>1. 1-Pass, where a solution is proposed using a single forward pass of the LLM. 2. Best-of-N <ref type="bibr" target="#b3">[4]</ref>, where up to 800 candidate solutions are independently generated until a successful solution is found (the same upper bound as Mind Evolution). 3. Sequential-Revision+, where 10 candidate solutions are proposed independently, then revised separately for 80 turns using the RCC process (Figure <ref type="figure" target="#fig_2">2</ref>). Note that 10 independent threads of 80-turn refinements are used instead of a single 800-turn refinement, because we rarely observe improvements after 80 turns. This baseline is similar to running 10 trials of multi-turn Reflexion <ref type="bibr" target="#b35">[36]</ref>.</p><p>Additionally, for reference, we also include an additional 1-Pass baseline that uses OpenAI o1-preview.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Metrics</head><p>We measure Success Rate as the percentage of problem instances that are solved completely within a benchmark domain, separating the validation and test sets. (Note that the Success rate is referred to as Solve Rate in Natural Plan <ref type="bibr" target="#b46">[47]</ref> and Final Pass Rate in TravelPlanner <ref type="bibr" target="#b41">[42]</ref>.)</p><p>To assess the cost of inference compute we report the number of LLM calls, the number of input and output tokens, and the total API cost of calling the LLM. (These costs are given in US Dollars, using prices from October 2024 when the experiments were conducted. The base rates are listed in Appendix D.) Note that assessing computational cost is particularly important when evaluating search strategies like Mind Evolution, since search is more expensive than generating a single solution. These statistics can help researchers and developers understand the cost-benefit trade-offs when using search to enhance LLM problem solving ability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">TravelPlanner</head><p>TravelPlanner <ref type="bibr" target="#b41">[42]</ref> is a natural language planning benchmark that simulates the problem of organizing a trip plan for a user who expresses preferences and constraints. We focus on the sole-planning mode (see <ref type="bibr" target="#b41">[42]</ref> for details), where each problem instance consists of a list of options regarding accommodation, restaurants, attractions and transportation, plus additional constraints that specify user preferences for budget, cuisine, etc. A plan is evaluated based on whether it satisfies the user preferences and commonsense constraints.</p><p>Table <ref type="table" target="#tab_2">2</ref> gives detailed results that compare the overall Success Rate and computational cost of Mind Evolution versus the baseline strategies. In terms of Success Rate, Mind Evolution clearly outperforms the baseline strategies, achieving over 95%. By comparison, Sequential-Revision+ provides a reasonable baseline, achieving almost 83%, while Best-of-N struggles, achieving only 55.6%. Overall, these results demonstrate a clear advantage of an evolutionary strategy that combines a broad search, through stochastic exploration, with a deep search that leverages an LLM for solution refinement.</p><p>Considering the two-stage approach, where Mind Evolution uses Gemini 1.5 Pro for any unsolved problems, we find that nearly the entire dataset can be solved, achieving a 100% success rate on validation and 99.9% on test problems respectively. The only work we are aware of that comes close to this success rate is <ref type="bibr" target="#b15">[16]</ref>, which uses GPT-4 for auto-formalization then leverages a formal solver to achieve 98.9% and 97.0% on validation and test respectively. Mind Evo- lution achieves comparable results without requiring a formal solver.</p><p>Finally, we note that the TravelPlanner dataset is organized into three levels of difficulty (Easy, Medium, Hard) and three trip durations (3 days, 5 days, 7 days), rendering 9 different problem classes. Figure <ref type="figure" target="#fig_3">3</ref> presents a breakdown of the success rates achieved across these different categories, showing that the success rates of 1-Pass and Best-of-N decline when planning for more travel days, but the trend is less clear for Mind Evolution and Sequential-Revision+, both of which iteratively refine proposed solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Natural Plan -Trip Planning</head><p>The Trip Planning task <ref type="bibr" target="#b46">[47]</ref> involves finding an itinerary that consists of a sequence of cities to visit and number of days in each that satisfies flight connectivity and scheduling constraints -see Table <ref type="table" target="#tab_3">3</ref> for a problem instance. We split the benchmark into 320 validation and 1,280 test instances (described in more detail in Appendix B).</p><p>The results in Table <ref type="table" target="#tab_2">2</ref> again show that Mind Evolution strongly outperforms the baselines on this task, achieving 96.2% on the validation and 94.1% on the test instances. Table 2 also shows a qualitative comparison between the results produced by Mind Evolution and the baseline strategies. Note that Best-of-N performs better in this scenario (77.2%), even beating Sequential-Revision+ (74.4%). We find that for the two-stage approach, Mind Evolution achieves 100% on the validation set and 99.6% on the test set. These findings again highlight the benefit of evolutionary search versus simple sampling and sequential refinement.</p><p>Finally, we note that the difficulty of this task varies with the number of cities to visit, ranging from 3 to 10. Figure <ref type="figure" target="#fig_4">4</ref> shows a breakdown of the Success Rate in terms of number of cities, where the relative advantage of Mind Evolution appears to increase as the number of cities grows.</p><p>Set Success Rate LLM Calls Input Tokens Output Tokens API Cost (Oct 2024) TravelPlanner [42] 1-Pass val 10/180 = 5.6% 1 0.009M 0.001M US$0.001 (o1-preview 1-Pass) val 21/180 = 11.7% 1 0.008M 0.008M US$0.601 Best-of-N val 100/180 = 55.6% 472 4.44M 0.47M US$0.47 Sequential-Revision+ val 149/180 = 82.8% 280 35.53M 0.29M US$2.75 Mind Evolution val 172/180 = 95.6% 174 3.10M 0.18M US$0.29 (+pro) val 180/180 = 100% (257) (3.25M) (0.19M) (US$0.54) Mind Evolution test 952/1000 = 95.2% 167 3.02M 0.18M US$0.28 (+pro) test 999/1000 = 99.9% (67) (3.05M) (0.18M) (US$0.33) Natural Plan [47] Trip Planning 1-Pass val 66/320 = 20.6% 1 0.002M 0.001M &lt;US$0.001 (o1-preview 1-Pass) val 116/320 = 36.2% 1 0.002M 0.008M US$0.53 Best-of-N val 247/320 = 77.2% 274 0.61M 0.18M US$0.10 Sequential-Revision+ val 238/320 = 74.4% 391 41.57M 0.38M US$3.23 Mind Evolution val 308/320 = 96.2% 168 1.48M 0.19M US$0.17 (+pro) val 320/320 = 100% (111) (1.51M) (0.19M) (US$0.22) Mind Evolution test 1204/1280 = 94.1% 196 1.78M 0.22M US$0.20 (+pro) test 1275/1280 = 99.6% (211) (1.86M) (0.24M) (US$0.37) Natural Plan [47] Meeting Planning 1-Pass val 104/500 = 20.8% 1 0.007M 0.001M US$0.001 (o1-preview 1-Pass) val 221/500 = 44.2% 1 0.006M 0.006M US$0.47 Best-of-N val 347/500 = 69.4% 444 3.99M 0.31M US$0.39 Sequential-Revision+ val 310/500 = 62.0% 484 32.16M 0.40M US$2.53 Mind Evolution val 425/500 = 85.0% 406 5.35M 0.41M US$0.52 (+pro) val 492/500 = 98.4% (890) (13.36M) (0.91M) (US$2.55) Mind Evolution test 419/500 = 83.8% 394 5.24M 0.40M US$0.51 (+pro) test 491/500 = 98.2% (828) (12.25M) (0.83M) (US$2.34)  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Natural Plan -Meeting Planning</head><p>For the Meeting Planning task a sequence of meetings should be scheduled to maximize the number of meetings between individuals subject to availability, location and travel time constraints <ref type="bibr" target="#b46">[47]</ref>. This task differs from TravelPlanner and Trip Planning in that not every meeting can be scheduled for every problem instance, implying that it is not possible to know whether an optimal solution has been reached. There-fore, to obtain the results shown in Table <ref type="table" target="#tab_2">2</ref>, we allow the searches to proceed until the upper bounds on iteration counts have been reached. For this task, we split the set of instances into 500 validation and 500 test instances (see Appendix B for details).</p><p>The results shown in Table <ref type="table" target="#tab_2">2</ref> continue to demonstrate a significant performance for Mind Evolution over baseline strategies, achieving an 85.0% Success Rate on the validation set and 83.8% on the test set. Notably, the two-stage approach using Gemini 1.5 Pro achieves success rates to 98.4% and 98.2% on validation and test respectively. Finally, Figure <ref type="figure">5</ref> shows the breakdown of success rates by the number of people to schedule meetings with. In this case, we find that Mind Evolution sustains a significant advantage in success rate as the number of people increases.</p><p>Q: You plan to visit 5 European cities for 16 days in total. You only take direct flights to commute between cities. You want to spend 5 days in Madrid. From day 3 to day 7, there is a annual show you want to attend in Madrid. You plan to stay in Zurich for 3 days. You would like to visit Frankfurt for 3 days. You would like to visit Santorini for 6 days. You are going to attend a wedding in Santorini between day 7 and day 12. You want to spend 3 days in Riga.</p><p>Here are the cities that have direct flights: Zurich and Riga, Frankfurt and Riga, Santorini and Zurich, Madrid and Zurich, Frankfurt and Zurich, Madrid and Santorini, Frankfurt and Madrid.</p><p>Find a trip plan of visiting the cities for 16 days by taking direct flights to commute between them.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Analysis and Ablation Studies</head><p>To understand how Mind Evolution's performance scales, and how the different components affect its behavior, we provide additional measurements and ablations to gain additional insight.</p><p>Scaling Regarding scaling, Figure <ref type="figure">6</ref> reports the Success Rate achieved by Mind Evolution across the planning tasks as a function of the number of generations. These results clearly show steady improvement for Mind Evolution as the number of generations is increased.</p><p>To compare the scaling of Mind Evolution to that of the baseline search methods, we also plot the Success Rate and average task evaluation scores as a function of the number of candidate solutions generated by the each strategy (Figures <ref type="figure">7</ref><ref type="figure">8</ref><ref type="figure">9</ref>). The task evaluation scores are calculated by penalizing unsatisfied constraints and suboptimality of the objective value, hence the maximum score that can be achieved in any problem instance is zero (see Appendix A.2 for details). In Appendix D, we provide another perspective on the cost-benefit trade-offs in terms of the specific API costs incurred.</p><p>Figures <ref type="figure">7</ref><ref type="figure">8</ref><ref type="figure">9</ref>show the results for the TravelPlanner, Trip Planning and Meeting Planning tasks respectively. In each case, we see that the overall success rates and average task evaluation scores improve monotonically with an increasing number of proposed solutions across all search methods. These plots also show that Mind Evolution is consistently more effective than the baseline strategies with respect to the number of candidate solutions needed to achieve a specified level of success rate (or average task performance).</p><p>We note that Best-of-N appears to be significantly underperforming on TravelPlanner. We hypothesize that this occurs because this task involves implicit commonsense constraints (e.g., a trip plan should return to the origin city, a restaurant cannot be visited twice, etc.), which are not given in the problem instance but instead learned from evaluation feedback, which Best-of-N does not leverage. Ablations We also conducted a set of ablations to study the contribution of the different components of Mind Evolution. Table <ref type="table">4</ref> shows that using the critic step in the RCC process (Figure <ref type="figure" target="#fig_2">2</ref> in Section 3.2) and textual feedback from the evaluation functions are the most critical to performance, although the other components also make meaningful contributions to performance.</p><p>To assess hyperparameter sensitivity, we investigated the Trip Planning task in greater detail, choosing the harder setting with 10 cities to better reveal differences in performance. (Similar results are also</p><p>0 200 400 600 800 # Candidate Solutions 8 7 6 5 4 3 2 1 Averaged Evaluation Scores 0 200 400 600 800 # Candidate Solutions 0.2 0.3 0.4 0.5 0.6 0.7 0.8 Success Rate Mind Evolution Seq. Revisions+ Best-of-N Figure 9 | Meeting Planning success rates and evaluation scores as the number of candidate solutions is increased. Critic ‚úì ‚úì ‚úì ‚úì S/Q Prompts ‚úì ‚úì ‚úì Textual Feedback ‚úì ‚úì Reset with LLM ‚úì Success Rate 46.1% 71.1% 76.1% 91.1% 95.6%</p><p>Table 4 | An ablation study of Mind Evolution components on the TravelPlanner validation set. Each column in the table shows an experiment where ‚úì indicates whether a component is used. If "Critic" is disabled, we skip the critic step in Figure <ref type="figure" target="#fig_2">2</ref> and go straight to the author step. "S/Q Prompts" stands for Strategy/Question prompts, which are additional taskspecific instructions in the critical thinking prompts (see Appendix A.1 for details). If "Textual Feedback" is disabled, we do not include evaluation feedback in the prompts. If "Reset with LLM" is disabled, we directly select global elites by their evaluation scores in island reset events, rather than use an LLM to choose, as described in Section 3.</p><p>2. Succ. Rate w/ island model (ùëÅ island = 4, ùëÅ convs = 5) 87.5% w/o island model (ùëÅ island = 1, ùëÅ convs = 20) 77.4% ùëÅ convs = 10, ùëÅ gens = 5 82.5% ùëÅ convs = 5, ùëÅ gens = 10 (default) 87.5% ùëÅ convs = 4, ùëÅ gens = 13 85.0%  improves the performance of Mind Evolution. The bottom three rows compare the effect of increasing the number of candidate solutions per generation versus having more generations while controlling for a similar number of candidates considered overall. In this case, it appears that deeper evolutionary search indeed has benefits, although it is also important to continue exploring broadly in each generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">A Challenging New Task: StegPoet</head><p>We introduce a challenging new task, StegPoet, where a hidden message should be stenographically encoded <ref type="bibr" target="#b32">[33]</ref> into a piece of creative writing. Even though the problem is difficult to formalize, it remains amenable to programmatic verification, which makes it addressable by the methods considered in this paper. In this task, a hidden message (ùëÄ) expressed by a sequence of numbers should be encoded in a piece of creative text about a particular topic, expressed in the form of an essay, story or poem. The goal is to both provide a number-to-word substitution cipher and a generated text that uses the cipher to encode the message. Figure <ref type="figure" target="#fig_5">10</ref> gives an example. We impose an additional constraint that there must be, on average, ùêµ words between successive cipher words in the generated text, which ensures that simply listing the cipher words as the text portion does not qualify as solution when ùêµ &gt; 0.</p><p>The difficulty of this problem varies along four axes:</p><p>1. Difficulty increases with the length of the hidden message, ùëÄ. We set 10 ‚â§ |ùëÄ| ‚â§ 30. 2. The repetition of the numbers in ùëÄ. The more repetition, the more stringent the constraints. 3. The "closeness" of the repeated numbers to each other. Each form of writing dictates how much repetition of the same word and proximity of occurrence is acceptable. The LLM must balance adherence to the form with the need to correctly encode the message. 4. Empirically, as ùêµ (the mean distance between cipher words) grows, the problem becomes more difficult.</p><p>In our tests, 3 ‚â§ ùêµ ‚â§ 7.</p><p>We divide the problem instances into a validation split of 101 instances and a test split of 245 instances. See Appendix F for additional details about the StegPoet evaluation.</p><p>Detailed performance results for Mind Evolution and the baseline strategies are given in Table <ref type="table" target="#tab_8">6</ref>, while Figure <ref type="figure" target="#fig_5">11</ref> shows performance per difficulty level. Here the two-stage Mind Evolution (+pro) achieves 87.1% on validation and 79.2% on test. Best-of-N only manages to solve 1% of the validation tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We have presented Mind Evolution, an evolutionary search approach for solving challenging natural language planning problems, by scaling inference-time compute for stochastic exploration and iterative refinement. An evaluation on the TravelPlanner and Natural Plan natural language planning benchmarks, as well as a new benchmark StegPoet introduced in this paper, demonstrates that Mind Evolution significantly outperforms Best-of-N and sequential revision. To our knowledge, this is the first approach that is able to achieve such a level of success on these tasks without explicitly leveraging a formal solver.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>The main limitation of the current work is the focus on natural language planning problems where proposed solutions can be programmatically evaluated and critiqued. In future work, we aim to extend beyond this limitation by developing LLM-based evaluators that would enable broader applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Implementation Details</head><p>Here we describe the implementation details of Mind Evolution. The code will be made available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. Prompt Design</head><p>We first use Meeting Planning as an example to illustrate the structure of the prompts used. The prompts, as well as the model responses when parent solutions are given, are shown in Figures <ref type="figure" target="#fig_5">12</ref><ref type="figure" target="#fig_5">13</ref><ref type="figure" target="#fig_5">14</ref><ref type="figure" target="#fig_5">15</ref><ref type="figure" target="#fig_5">16</ref>. The prompts begin with general instructions and a general problem definition, few-shot examples, then a task description. The few-shot examples help the LLM understand the problem and generate solutions closer to the desired formats. For TravelPlanner, we take two 3-day example plans from the training set and use them across all tasks (3-7 days). For Trip Planning, we take two example plans from the few-shot examples provided by the benchmark and use them across all tasks. For Meeting Planning, we use the 5-shot examples provided by the benchmark for each task.</p><p>After the task description, we include parent solutions with corresponding evaluation feedback, followed by critical thinking instructions (in Figures <ref type="figure" target="#fig_5">14</ref><ref type="figure" target="#fig_5">15</ref>). These instructions lead the LLM to improve the parent solutions, following the Refinement through Critical Conversation (RCC) process described in Section 3.2. The critical thinking instructions include problem-specific Strategy/Question prompts based on findings in each validation set (ablated in Section 4.4). In the model responses, one can see that the LLM follows the critical thinking instructions in playing the critic role to analyze the parent solutions, and playing the author role to propose a new solution. We also give an example of the prompt and a model response for TravelPlanner, which has the same structure, in Figures <ref type="figure" target="#fig_5">17</ref><ref type="figure" target="#fig_5">18</ref><ref type="figure" target="#fig_5">19</ref><ref type="figure" target="#fig_2">20</ref><ref type="figure" target="#fig_5">21</ref><ref type="figure" target="#fig_2">22</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Evaluation Functions</head><p>In this work, solutions are evaluated programmatically with a function. As described in Section 3.2, an evaluation function has three main roles: (1) scoring solutions by measuring the optimization objective, if any; (2) verifying whether the solution satisfies given constraints; and (3) providing corresponding textual feedback. Specifically, we score natural language plans by penalizing the constraints that are not satisfied, the objectives that are not maximized, and for not following the required solution format. Thus the maximum score for all tasks is zero. We also provide textual feedback that describes how the constraints are not satisfied and how the objectives are not maximized.</p><p>TravelPlanner Our evaluation function for Trav-elPlanner is modified from the TravelPlanner evaluation code <ref type="bibr" target="#b41">[42]</ref>. The evaluation code expects travel plans in JSON format. We modify the original evaluation code to make it output a cumulative score that reflects all the constraints that are not satisfied, instead of simply answering whether or not a plan satisfies all the constraints. We also make it provide textual feedback for the violated constraints.</p><p>In the TravelPlanner validation set, the constraints are provided in both user query text and a structured JSON format. However, in the test set, the constraints are only described in user query text. To make it easier for the evaluation function to consider the constraints, we extract them from user query into JSON using Gemini 1.5 Flash. For example, to extract the requested cuisines, we prompt Gemini with "Look at the following text and tell me if there are any cuisine requirements on the upcoming trip..." multiple times, and formulate the final answer via majority voting. To verify the reliability of this approach, we tested on the validation set and found complete agreement between the JSON extracted from user query and the provided JSON. In addition, we upload our test solutions to the TravelPlanner evaluation server, and found that the results agree with the official evaluation.</p><p>Trip Planning Similar to TravelPlanner, the Trip Planning evaluation function expects plans in JSON format. Since Trip Planning user queries are programmatically generated, we can parse the constraints specified in user queries. These constraints include number of days to stay in a city, specific days to be in a city (e.g., for events), and whether there are flights between cities. Our evaluation function scores a plan by the constraints that are not satisfied and whether it conforms with the desired JSON format, while also providing corresponding textual feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Meeting Planning</head><p>The Meeting Planning evaluation function also expects plans in JSON. Constraints are also provided in structured JSON format. Unlike Trav-elPlanner and Trip Planning, Meeting Planning has an optimization objective -the number of friends to meet with. We modify the original evaluation evaluation function to score a proposed plan by how many people that are not going to be met with; whether it conflicts with the schedules of other people; whether it includes meetings with the same person more than once; whether any part of the plan conflict with other parts; whether it follows the desired format as instructed. In Figures <ref type="figure" target="#fig_3">23</ref><ref type="figure" target="#fig_4">24</ref>we present the evaluation function that implements the simple logic described above as an example. import d a t e t i m e from t y p i n g import Any , Sequence d e f m e e t i n g _ p l a n _ e v a l ( plan : l i s t [ s t r ] , s t a r t _ l o c a t i o n : s t r , i n i t i a l _ t i m e : s t r , f r i e n d _ s c h e d u l e s : d i c t [ s t r , Any ] , d i s t a n c e _ m a t r i x : d i c t [ s t r , Any ] ) : " " " E v a l u a t e meeting plan . Args : plan : a l i s t o f planned s t e p s , such as [ ' You s t a r t a t R u s s i a n H i l l a t 9:00AM. ' , ' You t r a v e l t o Marina D i s t r i c t i n 7 minutes and a r r i v e a t 9:07AM. ' , ' You w a i t u n t i l 3:45 PM. ' , ' You meet James f o r 75 minutes from 3:45PM t o 5:00PM . ' ] s t a r t _ l o c a t i o n : Your i n i t i a l l o c a t i o n i n i t i a l _ t i m e : t h e i n i t i a l time , such as 10:30AM f r i e n d _ s c h e d u l e s : f r i e n d ' s l o c a t i o n , a v a i l a b l e time , t h e amount o f time f o r t h e meeting , such as { ' Stephanie ' : { ' l o c a t i o n ' : ' M i s s i o n D i s t r i c t ' , ' s t a r t _ t i m e ' : ' 1 0 : 3 0AM' , ' end_time ' : ' 1 : 3 0PM' , ' meeting_time ' : 120}} d i s t a n c e _ m a t r i x : D i s t a n c e s between l o c a t i o n s , such as { ' Marina D i s t r i c t ' : { ' M i s s i o n D i s t r i c t ' : 20} , ' M i s s i o n D i s t r i c t ' : { ' Marina D i s t r i c t ' : 19}} " " " met_with = {} s c o r e = 0 . 0 f e e d b a c k = [ ] c u r _ l o c a t i o n = s t a r t _ l o c a t i o n c u r _ t i m e = d a t e t i m e . d a t e t i m e . s t r p t i m e ( i n i t i a l _ t i m e , "% a s s e r t i s i n s t a n c e ( plan , l i s t ) f o r s t e p i n plan : t r y : i f s t e p . s t a r t s w i t h ( " You s t a r t " ) : c o n t i n u e e l i f s t e p . s t a r t s w i t h ( " You t r a v e l " ) : d e s t i n a t i o n = s t e p . s p l i t ( " t r a v e l t o " ) [ 1 ] . s p l i t ( " i n " ) [ 0 ] . s t r i p ( ) c u r _ t i m e = c u r _ t i m e + d a t e t i m e . t i m e d e l t a ( minutes=d i s t a n c e _ m a t r i x [ c u r _ l o c a t i o n ] [ d e s t i n a t i o n ] ) c u r _ l o c a t i o n = d e s t i n a t i o n e l i f s t e p . s t a r t s w i t h ( " You w a i t " ) : raw_end_time = s t e p . s p l i t ( " w a i t u n t i l " ) [ 1 ] . s p l i t ( " . " ) [ 0 ] . s t r i p ( ) end_time = None t r y : end_time = d a t e t i m e . d a t e t i m e . s t r p t i m e ( raw_end_time , "% e x c e p t V a l u e E r r o r : s c o r e -= 2 f e e d b a c k . append ( f " \ " { s t e p } \ " i s i n v a l i d because t h e time format doesn ' t f o l l o w t h e examples . " ) i f end_time &lt;= c u r _ t i m e : e n d _ t i m e _ s t r = end_time . s t r f t i m e ("% s c o r e -= 2 f e e d b a c k . append ( f " \ " { s t e p } \ " i s i n v a l i d because but t h e p r e v i o u s s t e p a l r e a d y ends a t { e n d _ t i m e _ s t r } and you cannot go backwards i n time . " ) c u r _ t i m e = end_time e l i f s t e p . s t a r t s w i t h ( " You meet " ) : </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Data Splits</head><p>TravelPlanner TravelPlanner has 45 training tasks, 180 validation tasks, and 1,000 test tasks in the original benchmark. Natural Plan -Trip Planning The Trip Planning benchmakr has 1,600 example tasks. There are eight different difficulty levels, ranging from 3 to 10 cities. Each difficulty level has 200 examples. We split the dataset into validation and test sets by putting the first 40 examples from each difficulty level into validation, and the last 160 examples into test, giving 320 examples in validation (which we used for prompt development) and 1,280 for test. In Figure 4, we show the performance at each difficulty level. Natural Plan -Meeting Planning The Meeting Planning benchmark has 1,000 example tasks. There are ten different difficulty levels, ranging from meeting one to ten different friends. Each difficulty level has 100 examples. We split the dataset into validation and test sets by putting the first 50 examples from each difficulty level into validation, and the last 50 examples into test, giving 500 examples in validation (which we used for prompt development) and 500 for test. In Figure 5, we show the performance at difficulty level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. GPT Results</head><p>Table <ref type="table">7</ref> presents the results of Mind Evolution using GPT-4o-mini with the same sets of prompts. Specifically, with 1-pass inference, GPT-4o-mini also struggles at planning tasks, achieving 0%</p><p>on TravelPlanner, 9.1% success rate on Trip Planning, and 20.2% success rate on Meeting Planning. Again, Mind Evolution significantly improves the performance by over 100% relatively across different benchmarks. Success Rate TravelPlanner [42] 79.4% Natural Plan [47] Trip Planning 48.1% Natural Plan [47] Meeting Planning 86.4%</p><p>Table 7 | Mind Evolution with GPT-4o-Mini results on validation sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Model Pricing and API Cost Curves</head><p>Table <ref type="table">8</ref> shows the API pricing of different models used in our evaluation (Tables 2), at the time of writing (October 2024).</p><p>Figure <ref type="figure" target="#fig_2">25</ref> gives insight into the scaling properties of the various strategies in terms of their API cost, which Model Input Token Output Token Gemini 1.5 Flash $0.075/M $0.30/M Gemini 1.5 Pro $1.25/M $5.00/M GPT-4o-Mini $0.15 $0.60 OpenAI o1-preview $15.00/M $60.00/M Table <ref type="table">8</ref> | Pricing at the time of writing (October 2024). These differences serve as a proxy for real computational cost differences among models.</p><p>is also a linear combination of the input token counts and the output token counts, weighted by base rate (Table <ref type="table">8</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Additional Examples</head><p>In addition to</p><p>Table 3, we present qualitative examples of TravelPlanner and Meeting Planning in Table 9 and Table 10, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Additional Details for StegPoet</head><p>The prompt design used for StegPoet is given in Figure <ref type="figure" target="#fig_2">26</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>StegPoet Evaluation</head><p>Each proposed solution should contain a cipher and text component. The first step is to calculate what is encoded in the text by finding all the cipher strings; this is done via simple capitalization-agnostic character-matches. We refer to the actual encoded string as ùëÄ . If ùëÄ = ùëÄ ‚Ä≤ the problem is solved correctly. The numeric evaluation of a proposed solution is computed as follows: 1. Invalid if the text or cipher component cannot be parsed or violates constraints. 2. What is the first position, ùëñ, in which ùëÄ ùëñ ‚â† ùëÄ ‚Ä≤ ùëñ ? This is the integer part of the score. 3. Compute the Levenshtein distance between ùëÄ and ùëÄ ‚Ä≤ . Levenshtein distance is often used in information theory and linguistics to measure the difference between two sequences <ref type="bibr" target="#b1">[2]</ref>. This is scaled between (0,1) and added to the integer component above.</p><p>Additionally, textual feedback, without numeric penalties, is also provided in the revision request made to the LLM.</p><p>1. A clearly marked list of what ùëÄ ‚Ä≤ was found. 2. A list of number mappings missing from the cipher, or unnecessary numbers specified in the cipher.</p><p>3. If a word appears an incorrect number of times (too few or too many) in the text, it is indicated, along with the error. 4. An annotated copy of the text is returned. The annotations indicate where the cipher-keywords were found (they are shown asterisked), and the first error is indicated. 5. If the text encodes the cipher correctly, but also encodes extra words, that is indicated. 6. If everything in ùëÄ ‚Ä≤ is correct, but |ùëÄ ‚Ä≤ | &lt; |ùëÄ|, it is indicated as such.</p><p>For this task, we experimented with many different genre forms (poetry, short-story fiction, essay, monologue, etc.), as well as inspirations from contemporary to classic writers.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><figDesc>plan a 5-day trip from Seattle to LA and SD with a budget of $800. We want to have Japanese for at least one dinner and prefer private hotel rooms. Seattle to LA „ÄÇAttractions: -„ÄÇTransport: Flight 9587 „ÄÇHotel: Grand Hotel, private rm „ÄÇDinner: Din Tai Fung Day 2: „ÄÇPlaces: LA „ÄÇAttraction: Dodgers Stadium „ÄÇTransport: -„ÄÇHotel: Grand Hotel, private rm „ÄÇDinner: STK ‚Ä¶ Evaluate Refine (Selection, Crossover, Mutation) [Gen 1] A valid or the best solution : "Improve previous solutions" LLM [Gen 2, 3, ‚Ä¶]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><figDesc>refines Q: You are planning to visit 7 Asian cities. You want to spend 5 days in Tokyo. You want to attend a wedding on day 11 ... Plan: [{'city': 'Tokyo', 'days': '3'}, {'city': 'Taipei', days': '2'}, ‚Ä¶] Feedback: ['You planned 3 days for Tokyo, but you are required to stay 5 days in Tokyo ', ‚Ä¶] The number of days to stay in Tokyo should be 5 instead of 3 ... Plan: [{'city': 'Tokyo', 'days': '5'}, {'city': 'Taipei', days': '2'}, ‚Ä¶]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 |</head><label>2</label><figDesc>Figure2| Illustrating the Refinement through Critical Conversation (RCC) process, where an initial solution is first proposed, then evaluated and subjected to feedback from a critic, after which an author proposed a refined solution and the process iterates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 |</head><label>3</label><figDesc>Figure 3 | Success rate on the validation set of the TravelPlanner benchmark, organized by problem instance difficulty and the number of travel days.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 |</head><label>4</label><figDesc>Figure 4 | Success rate on the validation set of the Trip Planning benchmark per number of cities to visit.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Answer 1 -</head><label>1</label><figDesc>Pass Madrid (Day 1-7) ‚à† Santorini (Day 7-12) ‚à† Zurich (Day 12-14) ‚à† Frankfurt (Day 14-16) ‚à† Riga (Day 16-19) 7 days for Madrid instead of 5; 4 days for Riga instead of 3; 19 days in total instead of 16. Best-of-N Madrid (Day 1-7) ‚à† Santorini (Day 7-12) ‚à† Zurich (Day 12-14) ‚à† Frankfurt (Day 14-16) ‚à† Riga (Day 16-16) 7 days for Madrid instead of 5; 1 day for Riga instead of 3. Sequential Revisions+ Zurich (Day 1-3) ‚à† Frankfurt (Day 3-5) ‚à† Riga (Day 5-7) ‚à† Santorini (Day 7-12) ‚à† Madrid (Day 12-16) omitted the show in Madrid (Day 3-7); no direct flight from Riga to Santorini. Mind Evolution (ours) Frankfurt (Day 1-3) ‚à† Madrid (Day 3-7) ‚à† Santorini (Day 7-12) ‚à† Zurich (Day 12-14) ‚à† Riga (Day 14-16)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 |Figure 7 |Figure 8 |</head><label>678</label><figDesc>Figure6| Success rate on the validation set for each natural language planning benchmark at each generation of Mind Evolution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 12 |Figure 14 |Figure 16 |Figure 17 |Figure 18 |Figure 20 |Figure 21 |Figure 22 |</head><label>1214161718202122</label><figDesc>Figure 12 | Example Meeting Planning prompt and model response with parent solutions given (Part 1)</figDesc><graphic coords="15,74.13,94.03,447.01,631.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 23 |Figure 24 |</head><label>2324</label><figDesc>Figure 23 | The Meeting Planning evaluation function (part 1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>( a )</head><label>a</label><figDesc>Words in the cipher cannot be subsets of each other (e.g., origin and original). (b) Words in the cipher cannot be repeated. (c) Words in the cipher should be at least 4 characters long. (d) Words in the cipher should contain only alphabetic characters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 |</head><label>1</label><figDesc>Definition of hyperparameters in Mind Evolution. Unless otherwise specified, the experiments in work use the default values. The product of the first four hyperparameters gives the maximum number of candidate solutions generated (800 in the default setting).</figDesc><table><row><cell>As discussed in Section 1, we</cell></row><row><cell>implement a fitness function for each problem domain,</cell></row><row><cell>where candidate solutions are parsed and evaluated</cell></row><row><cell>programmatically. In principle, any function that can</cell></row><row><cell>evaluate solution quality can be used, including LLM</cell></row><row><cell>evaluation. The evaluation function plays three key</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 |</head><label>2</label><figDesc>Experimental results on benchmark natural language planning tasks. "(+pro)" denotes the two-stage results, where we use Gemini 1.5 Pro to solve the problems that were not solved in experiments using Gemini 1.5 Flash. Number of LLM calls, token counts, and API cost are averaged across the validation or test problem set, and they are calculated only on the remaining problems for the "(+pro)" experiments. Here, we also show OpenAI o1-preview results as a reference.</figDesc><table><row><cell></cell><cell cols="3">Mind Evolution (Ours)</cell><cell cols="2">Seq. Revisions+</cell><cell></cell><cell>Best-of-N</cell><cell>1-Pass</cell></row><row><cell></cell><cell>100%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Success Rate</cell><cell>25% 50% 75%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="4">Number of Cities (to visit)</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 |</head><label>3</label><figDesc>An example problem instance from the Trip Planning task in Natural Plan, with the predicted plans from Mind Evolution and the baselines. 1-Pass and Best-of-N both make mistakes on number of days to stay, but satisfy the requirements of being in Madrid and Santorini on specific days. The Sequential-Revision+ plan omits the annual show in Madrid and plans a non-existent flight, but is correct in the number of days. In contrast, the Mind Evolution plan satisfies all specified requirements.</figDesc><table><row><cell></cell><cell cols="3">Mind Evolution (Ours)</cell><cell></cell><cell cols="2">Seq. Revisions+</cell><cell cols="2">Best-of-N</cell><cell></cell><cell>1-Pass</cell></row><row><cell></cell><cell>100%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Success Rate</cell><cell>25% 50% 75%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">Number of People (to meet)</cell><cell></cell><cell></cell></row><row><cell cols="11">Figure 5 | Success rate on the validation set of the</cell></row><row><cell cols="11">Meeting Planning benchmark per number of people</cell></row><row><cell cols="2">to meet with.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 |</head><label>5</label><figDesc>Hyperparameter studies on the Trip Planning problem instances with 10 cities. The first two rows show the difference between enabling and disabling the island model. The bottom three rows illustrate a trade-off between the number of candidates per generation versus the number of generations. (Note that the bottom row (ùëÅ convs = 4, ùëÅ gens = 13) produces slightly more than 800 solutions (832).Example of the encoding of a StegPoet problem instance (left) and a correct solution (right) that includes the number-to-word cipher and a poem in the style of a children's poetry author. Note that |ùëÄ| = 12 in this instance. We added capitalization to the code words to highlight them.</figDesc><table><row><cell>observed on the harder problem instances from the</cell></row><row><cell>other benchmark tasks.) In Table 5, the top two rows</cell></row><row><cell>compare the effect of including or excluding the is-</cell></row><row><cell>land model from the evolutionary search, controlling</cell></row><row><cell>for the same number (800) of candidate solutions.</cell></row><row><cell>These results show that the island model significantly</cell></row></table><note><p>Figure 10 | StegPoet example.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 |</head><label>6</label><figDesc>Experimental results on StegPoet. Price and token counts are averages per problem. All results use Gemini 1.5 Flash, except (+pro), which solves the problems that were not solved in the Flash runs, using Gemini 1.5 Pro.</figDesc><table><row><cell></cell><cell cols="2">Mind Evolution (Ours)</cell><cell></cell><cell>Seq. Revisions+</cell><cell cols="2">Best-of-N</cell><cell>1-Pass</cell></row><row><cell></cell><cell>100%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Success Rate</cell><cell>25% 50% 75%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell></row><row><cell></cell><cell></cell><cell cols="4">Min Required Word Spacing</cell><cell></cell></row></table><note><p>Figure 11 | Histogram of Success Rate for each difficulty level. 1-Pass returns valid responses, but fails to solve any of the problems, so it is not visible in the histogram.</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>The authors thank <rs type="person">Sergio Guadarrama</rs> and <rs type="person">Doina Precup</rs> for supporting this work. We also thank <rs type="person">Sirui Xie</rs>, <rs type="person">John Canny</rs>, and the <rs type="funder">Google DeepMind FunSearch</rs> team for valuable discussion.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="bibr">Figure 25</ref> <p>| API cost per task (Oct 2024) vs. Success Rate on the validation sets with Gemini 1.5 Flash. API cost is also a linear combination of input token counts and output token counts. Note that Sequential-Revision+ curves are cut short. As the conversations can run up to 80 turns, it usually consumes a lot more tokens than the other methods.</p><p>Q: Could you construct a 3-day journey for two people from Chicago to Albany that takes place from March 22nd to March 24th, 2022? Our budget is $2,300. We require accommodations that allow smoking and should ideally be entire rooms. We will not be self-driving during this trip. On the subject of cuisine, we're open to any suggestions you might have.</p><p>[Transportation Options] Taxi: Self-Driving: N/A, Flights: F3732604    &lt;ENCODING-CIPHER START&gt; "22" : "computers"; "33" : "become"; "44" : "vital"; "55" : "them"; "66" : "need"; "77" : "everyday"; "40" : "more"; "50" : "need"; "70" : "certain"; "3" : "grow"; "5" : "exist"; "8" : "future"; &lt;ENCODING-CIPHER END&gt; &lt;POEM START&gt; Everyday, computers become more vital to our lives. Everyday, we need them to exist more and more. That will grow, for certain, in the future. &lt;POEM END&gt; </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kernion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goldie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mirhoseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mckinnon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.08073</idno>
		<title level="m">Constitutional AI: Harmlessness from AI feedback</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Levenshtein distance, sequence comparison and biological database search</title>
		<author>
			<persName><forename type="first">B</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Waterman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TIT.2020.2996543</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on In-formation Theory</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3287" to="3294" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Brahmachary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Panda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Koneripalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Sagotra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Jagtap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kalyanaraman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.02054</idno>
		<title level="m">Large language model-based evolutionary optimizer: Reasoning with elitism</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Juravsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ehrlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>R√©</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mirhoseini</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2407.21787</idno>
		<title level="m">Large language monkeys: Scaling inference compute with repeated sampling</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A survey of parallel genetic algorithms</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cant√∫-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Calculateurs paralleles, reseaux et systems repartis</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="141" to="171" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">EvoPrompting: Language models for code-level neural architecture search</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>So</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Neural Information Processing Systems</title>
		<meeting>the 37th International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="7787" to="7817" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">CodeT: Code generation with generated tests</title>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-G</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=ktrw68Cmu9c" />
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Teaching large language models to selfdebug</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sch√§rli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=KuPixIqPiq" />
	</analytic>
	<monogr>
		<title level="m">The Twelfth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Training verifiers to solve math word problems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Plappert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nakano</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.14168</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Promptbreeder: Self-referential self-improvement via prompt evolution</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Banarse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rockt√§schel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.16797</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Computers and Intractability: A Guide to the Theory of NP Completeness</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Garey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
			<publisher>W. H. Freeman &amp; Co</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Genetic Algorithms in Search, Optimization, and Machine Learning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Golberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Addison Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A note on Boltzmann tournament selection for genetic algorithms and population-oriented simulated annealing</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex Systems</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="445" to="460" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">The Nature of Human Intelligence</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Guilford</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1967">1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">Q</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.08532</idno>
		<title level="m">Connecting large language models with evolutionary algorithms yields powerful prompt optimizers</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Large language models can plan your travels rigorously with formal verification tools</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2404.11891</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">E</forename><surname>Hemberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moskal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U.-M</forename><surname>O'reilly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolving code with a large language model. Genetic Programming and Evolvable Machines</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">21</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Adaptation in Natural and Artificial Systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Holland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975. 1992</date>
			<publisher>University of Michigan Press</publisher>
			<pubPlace>Ann Arbor, MI</pubPlace>
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Language models can solve computer tasks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mcaleer</surname></persName>
		</author>
		<idno>arxiv:2303.17491</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Kirchner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mcaleese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Burda</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2407.13692</idno>
		<title level="m">Prover-verifier games improve legibility of LLM outputs</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Large language models are zeroshot reasoners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Iwasawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="22199" to="22213" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">CodeRL: Mastering code generation through pretrained models and deep reinforcement learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Gotmare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="21314" to="21328" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Evolution through large models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ndousse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">O</forename><surname>Stanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Evolutionary Machine Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="331" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Improving LLM reasoning through scaling inference computation with collaborative verification</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yavuz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2410.05318</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Lightman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cobbe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.20050</idno>
		<title level="m">Let&apos;s verify step by step</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Large language model for multi-objective evolutionary optimization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.12541</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">RLTF: Reinforcement learning from unit test feedback</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ye</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=hjYmsV6nXZ" />
	</analytic>
	<monogr>
		<title level="j">Transactions on Machine Learning Research</title>
		<idno type="ISSN">2835- 8856</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Large language models as evolutionary optimizers</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Ong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2024 IEEE Congress on Evolutionary Computation (CEC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Fully autonomous programming with large language models</title>
		<author>
			<persName><forename type="first">V</forename><surname>Liventsev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Grishina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>H√§rm√§</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Moonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Genetic and Evolutionary Computation Conference</title>
		<meeting>the Genetic and Evolutionary Computation Conference</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1146" to="1155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Self-refine: Iterative refinement with self-feedback</title>
		<author>
			<persName><forename type="first">A</forename><surname>Madaan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hallinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wiegreffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dziri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Prabhumoye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">36</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">An Introduction to Genetic Algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Generative agents: Interactive simulacra of human behavior</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>O'brien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology</title>
		<meeting>the 36th Annual ACM Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Hide and seek: An introduction to steganography</title>
		<author>
			<persName><forename type="first">N</forename><surname>Provos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Honeyman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE security &amp; privacy</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="32" to="44" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Mathematical discoveries from program search with large language models</title>
		<author>
			<persName><forename type="first">B</forename><surname>Romera-Paredes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Barekatain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Novikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dupont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Ellenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Fawzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">625</biblScope>
			<biblScope unit="issue">7995</biblScope>
			<biblScope unit="page" from="468" to="475" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Rewarding progress: Scaling automated process verifiers for LLM reasoning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Setlur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Nagpal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2410.08146</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Reflexion: Language agents with verbal reinforcement learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Shinn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cassano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gopinath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Scaling LLM test-time compute optimally can be more effective than scaling model parameters</title>
		<author>
			<persName><forename type="first">C</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2408.03314</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Distributed genetic algorithms for function optimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tanese</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
		<respStmt>
			<orgName>University of Michigan</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Self-consistency improves chain of thought reasoning in language models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=1PL1NIMMrw" />
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Multi-step problem solving through a verifier: An empirical analysis on modelinduced process supervision</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.02658</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Chainof-thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="24824" to="24837" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.01622</idno>
		<title level="m">Travelplanner: A benchmark for real-world planning with language agents</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Tree of thoughts: Deliberate problem solving with large language models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Shafran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Neural Information Processing Systems</title>
		<meeting>the 37th International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="11809" to="11822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Berto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.01145</idno>
		<title level="m">ReEvo: Large language models as hyper-heuristics with reflective evolution</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><surname>Evoagent</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.14228</idno>
		<title level="m">Towards automatic multiagent generation via evolutionary algorithms</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">ALGO: Synthesizing algorithmic programs with LLM-generated oracle verifiers</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Neural Information Processing Systems</title>
		<meeting>the 37th International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="54769" to="54784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-T</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.04520</idno>
		<title level="m">NATURAL PLAN: Benchmarking LLMs on natural language planning</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
