- Decision to use continuous-time Markov chains (CTMCs) for sampling from discrete distributions
- Choice of locally equivariant functions for rate matrix representation
- Adoption of a physics-informed neural network (PINN) loss function for optimization
- Implementation of a scalable training algorithm for the rate matrix
- Use of Radon-Nikodym derivatives for deriving importance weights
- Selection of multilayer perceptrons, attention layers, and convolutional networks as base architectures
- Decision to focus on minimizing variance of importance weights
- Choice of annealed importance sampling and sequential Monte Carlo methods as foundational techniques
- Assumption of continuous differentiability of potential functions U_t
- Strategy for initializing the CTMC with a uniform distribution
- Definition of proactive importance sampling for weight computation
- Approach to ensure unbiased estimators through importance sampling
- Decision to experimentally validate the LEAPS algorithm using the Ising model
- Choice of discrete state space for the application of the proposed method
- Assumption regarding the intractability of standard neural network parameterizations for rate matrices
- Decision to derive a time-dependent probability mass function (pmf) for the sampling process
- Use of the Kolmogorov forward equation (KFE) as a guiding principle for CTMC design
- Decision to utilize Monte Carlo estimators for approximating expectations under the target distribution
- Choice of a heuristic approach for deriving the proactive importance sampling scheme
- Decision to characterize the Radon-Nikodym derivative in path space for the CTMC trajectories