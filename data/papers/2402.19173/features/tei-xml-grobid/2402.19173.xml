<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Under review as submission to TMLR StarCoder 2 and The Stack v2: The Next Generation</title>
				<funder ref="#_hrARGwH #_fJW4e2t">
					<orgName type="full">U.S. National Science Foundation</orgName>
				</funder>
				<funder>
					<orgName type="full">NCSA Delta</orgName>
				</funder>
				<funder>
					<orgName type="full">Northeastern Research Computing</orgName>
				</funder>
				<funder>
					<orgName type="full">Software Heritage</orgName>
				</funder>
				<funder ref="#_ybKumCy #_44Js8Hm">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-02-29">29 Feb 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Anton</forename><surname>Lozhkov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Raymond</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Loubna</forename><forename type="middle">Ben</forename><surname>Allal</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Federico</forename><surname>Cassano</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Joel</forename><surname>Lamy-Poirier</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nouamane</forename><surname>Tazi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ao</forename><surname>Tang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dmytro</forename><surname>Pykhtar</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jiawei</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois Urbana</orgName>
								<address>
									<settlement>Champaign</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuxiang</forename><surname>Wei</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tianyang</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Max</forename><surname>Tian</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois Urbana</orgName>
								<address>
									<settlement>Champaign</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Denis</forename><surname>Kocetkov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Arthur</forename><surname>Zucker</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Younes</forename><surname>Belkada</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zijian</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Qian</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dmitry</forename><surname>Abulkhanov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Indraneil</forename><surname>Paul</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">Technical University of Darmstadt</orgName>
								<address>
									<addrLine>33 Baidu</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhuang</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wen-Ding</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Megan</forename><surname>Risdal</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jia</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jian</forename><surname>Zhu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Terry</forename><surname>Yue Zhuo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Evgenii</forename><surname>Zheltonozhskii</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nii</forename><surname>Osae</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Osae</forename><surname>Dade</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wenhao</forename><surname>Yu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Lucas</forename><surname>Krauß</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Naman</forename><surname>Jain</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yixuan</forename><surname>Su</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xuanli</forename><surname>He</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Manan</forename><surname>Dey</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Edoardo</forename><surname>Abati</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yekun</forename><surname>Chai</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Niklas</forename><surname>Muennighoff</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xiangru</forename><surname>Tang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Muhtasham</forename><surname>Oblokulov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Christopher</forename><surname>Akiki</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Leipzig University</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">ScaDS.AI</orgName>
								<orgName type="institution">23 University College</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marc</forename><surname>Marone</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chenghao</forename><surname>Mou</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mayank</forename><surname>Mishra</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Alex</forename><surname>Gu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Binyuan</forename><surname>Hui</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tri</forename><surname>Dao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Armel</forename><surname>Zebaze</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Olivier</forename><surname>Dehaene</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nicolas</forename><surname>Patry</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Canwen</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Han</forename><surname>Hu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Torsten</forename><surname>Scholak</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sebastien</forename><surname>Paquet</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jennifer</forename><surname>Robinson</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Carolyn</forename><forename type="middle">Jane</forename><surname>Anderson</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nicolas</forename><surname>Chapados</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mostofa</forename><surname>Patwary</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nima</forename><surname>Tajbakhsh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Carlos</forename><forename type="middle">Muñoz</forename><surname>Ferrandis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Lingming</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois Urbana</orgName>
								<address>
									<settlement>Champaign</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sean</forename><surname>Hughes</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Arjun</forename><surname>Guha</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Leandro</forename><surname>Von Werra</surname></persName>
						</author>
						<author>
							<persName><forename type="first">⋆</forename><surname>Harm De Vries</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hugging</forename><surname>Face</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Servicenow</forename><surname>Research</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Northeastern</forename><surname>University</surname></persName>
						</author>
						<author>
							<persName><surname>London</surname></persName>
						</author>
						<author>
							<persName><forename type="first">U</forename><forename type="middle">C</forename><surname>San</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Cornell</forename><surname>University</surname></persName>
						</author>
						<author>
							<persName><forename type="first">U</forename><forename type="middle">C</forename><surname>Berkeley</surname></persName>
						</author>
						<author>
							<persName><surname>Mazzuma</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Contextual</forename><surname>Ai</surname></persName>
						</author>
						<author>
							<persName><surname>Cohere</surname></persName>
						</author>
						<author>
							<persName><surname>Salesforce</surname></persName>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Yale University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Under review as submission to TMLR StarCoder 2 and The Stack v2: The Next Generation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-02-29">29 Feb 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">712AEE07C5CD6F48C044EF18CA341738</idno>
					<idno type="arXiv">arXiv:2402.19173v1[cs.SE]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-02-21T16:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The BigCode project, 1 an open-scientific collaboration focused on the responsible development of Large Language Models for Code (Code LLMs), introduces StarCoder2. In partnership with Software Heritage (SWH), 2 we build The Stack v2 on top of the digital commons of their source code archive. Alongside the SWH repositories spanning 619 programming languages, we carefully select other high-quality data sources, such as GitHub pull requests, Kaggle notebooks, and code documentation. This results in a training set that is 4× larger than the first StarCoder dataset. We train StarCoder2 models with 3B, 7B, and 15B parameters on 3.3 to 4.3 trillion tokens and thoroughly evaluate them on a comprehensive set of Code LLM benchmarks.</p><p>We find that our small model, StarCoder2-3B, outperforms other Code LLMs of similar size on most benchmarks, and also outperforms StarCoderBase-15B. Our large model, StarCoder2-15B, significantly outperforms other models of comparable size. In addition, it matches or outperforms CodeLlama-34B, a model more than twice its size. Although DeepSeekCoder-33B is the best-performing model at code completion for high-resource languages, we find that StarCoder2-15B outperforms it on math and code reasoning benchmarks, as well as several low-resource languages. We make the model weights available under an OpenRAIL license and ensure full transparency regarding the training data by releasing the SoftWare Heritage persistent IDentifiers (SWHIDs) of the source code data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Large Language Models for Code (Code LLMs; <ref type="bibr" target="#b28">Chen et al., 2021;</ref><ref type="bibr" target="#b93">Nijkamp et al., 2023;</ref><ref type="bibr" target="#b111">Rozière et al., 2023;</ref><ref type="bibr" target="#b57">Guo et al., 2024)</ref> have rapidly emerged as powerful assistants for writing and editing code. As of January 30, 2024, GitHub CoPilot has garnered over 1.3 million paying subscribers, with over 50,000 organisations opting for the enterprise version <ref type="bibr">(MSFT Q2 Earning Call, 2024)</ref>, estimated to increase developer productivity by up to 56% as well as developer satisfaction <ref type="bibr" target="#b100">(Peng et al., 2023;</ref><ref type="bibr">Ziegler et al., 2024)</ref>. ServiceNow recently disclosed that their "text-to-code" solution, built from fine-tuning StarCoderBase models <ref type="bibr" target="#b71">(Li et al., 2023)</ref>, results in a 52% increase in developer productivity <ref type="bibr">(Yahoo Finance, 2024)</ref>. Despite the initial focus on generating code snippets from natural language instructions or other code snippets, Code LLMs exhibit the potential to enhance all phases of the software development cycle <ref type="bibr" target="#b62">(Hou et al., 2023;</ref><ref type="bibr" target="#b48">Fan et al., 2023;</ref><ref type="bibr" target="#b140">Wang et al., 2024;</ref><ref type="bibr">Zhuo et al., 2023b;</ref><ref type="bibr" target="#b27">Chai et al., 2023)</ref>. This includes speeding up the implementation of new projects, improving quality assurance for developed software, helping detect and fix bugs, simplifying maintenance tasks, and easing migration to newer software.</p><p>The development process of LLMs can exhibit different levels of openness <ref type="bibr" target="#b128">(Solaiman, 2023;</ref><ref type="bibr" target="#b44">Ding et al., 2022;</ref><ref type="bibr" target="#b2">Akiki et al., 2022)</ref>. Proprietary models like OpenAI's <ref type="bibr">GPT-4 (OpenAI et al., 2023</ref>) and Google's Gemini <ref type="bibr" target="#b51">(Gemini Team et al., 2023)</ref> provide access to the model through a paid API but do not disclose development details. On the other hand, open-weight models like Code LLaMa <ref type="bibr" target="#b111">(Rozière et al., 2023)</ref>, Mistral <ref type="bibr" target="#b64">(Jiang et al., 2023), and</ref><ref type="bibr">DeepSeekCoder (Guo et al., 2024)</ref> have released the model weights. This enables the open-source community to run these models locally, inspect the model representations, and finetune them on their tasks. However, the model developers have not disclosed their training data. Consequently, content creators do not know if their data was used for training, social scientists cannot scrutinize the dataset for bias and toxicity, and LLM developers lack information as to what extent the training set is contaminated with test benchmarks. More broadly, this practice hinders scientific progress as other research teams cannot readily reuse each other's training data. Other LLM development projects, like Allen AI's OLMo <ref type="bibr" target="#b54">(Groeneveld et al., 2024)</ref>, Eleuther AI's Pythia <ref type="bibr" target="#b16">(Biderman et al., 2023)</ref>, and BigScience's BLOOM <ref type="bibr">(BigScience Workshop, 2022;</ref><ref type="bibr">Scao et al., 2022a)</ref>  <ref type="bibr">(BigCode collaboration et al., 2023)</ref> and has brought together more than 1,100 members from diverse academic institutes and industry labs. The community previously released The Stack v1 <ref type="bibr" target="#b67">(Kocetkov et al., 2023)</ref>, a 6.4 TB dataset of permissively licensed source code in 384 programming languages. The Stack v1 includes a governance tool called "Am I in The Stack," designed for developers to verify if their source code is included in the dataset. It also provides an opt-out process for those who prefer to exclude their code from the dataset. In December 2022, the BigCode community released SantaCoder <ref type="bibr" target="#b12">(Ben Allal et al., 2023)</ref>, a strong-performing 1.1B parameter model trained on Java, JavaScript, and Python code from The Stack v1. Building upon this success, the community further scaled up its effort and released StarCoder on May 4th, 2023 <ref type="bibr" target="#b71">(Li et al., 2023)</ref>. At its release, the 15B parameter StarCoder model was the best open-access LLM for code. This technical report describes the development process of The Stack v2 and StarCoder2. The Stack v2 builds upon the foundation of Software Heritage's vast source code archive, which spans over 600 programming languages. In addition to code repositories, we curate other high-quality open data sources, including Github issues, pull requests, Kaggle and Jupyter notebooks, code documentation, and other natural language datasets related to math, coding, and reasoning. To prepare the data for training, we perform deduplication, create filters to eliminate low-quality code, redact Personally Identifiable Information (PII), remove malicious code, and handle opt-outs from developers who requested to have their code removed from the dataset. With this new training set of 900B+ unique tokens, 4× larger than the first StarCoder dataset, we develop the next generation of StarCoder models. We train Code LLMs with 3B, 7B, and 15B parameters using a two-stage training process <ref type="bibr" target="#b111">(Rozière et al., 2023;</ref><ref type="bibr" target="#b57">Guo et al., 2024)</ref>. We start base model training with a 4k context window and subsequently fine-tune the model with a 16k context window. We ensure that the training process does not exceed more than 5 epochs over the dataset <ref type="bibr" target="#b87">(Muennighoff et al., 2023)</ref>. However, we push • Find all files that could contain a license using a regular expression in Appendix A.3. This allows us to gather files that either explicitly contain a license (e.g., LICENSE, MIT.txt, Apache2.0) or contain a reference to the license (e.g., README.md, GUIDELINES);</p><p>• Apply ScanCode's license detection to the matching files and gather the SPDX<ref type="foot" target="#foot_0">foot_0</ref> IDs of the detected licenses;</p><p>• Propagate the detected licenses to all files that have the same base path within the repository as the license file.</p><p>Once the file-level license information is gathered, we decide whether the file is permissively licensed, non-permissively licensed, or unlicensed, following the algorithm described in Figure <ref type="figure" target="#fig_1">1</ref>.</p><p>The licenses we consider permissive are listed in Appendix A.4. This list was compiled from the licenses approved by the Blue Oak Council <ref type="bibr">(Blue Oak Council, 2024)</ref>, as well as licenses categorized as "Permissive" or "Public Domain" by ScanCode (ScanCode License Categories, 2024).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data licenses</head><p>We consider three types of files: permissively licensed, non-permissively licensed (e.g., copyleft), and unlicensed files. The main difference between the Stack v2 and the Stack v1 is that we include both permissively licensed and unlicensed files. We exclude commercial licenses since their creators do not intend their code to be used for commercial purposes. We also exclude copyleft-licensed code due to uncertainty regarding the community's stance on using such data for LLM training and its relatively low volume.</p><p>Language detection While the Stack v1 <ref type="bibr" target="#b67">(Kocetkov et al., 2023)</ref> detects programming languages by their file extension, we instead rely on a language classifier. Specifically, we use go-enry based on GitHub's library linguist <ref type="bibr">(go-enry, 2024)</ref> to detect the programming language for each file. We detect 658 unique languages in TheStackV2-dedup, some of which get removed at the data inspection stage (see next paragraph). v1-dedup The-stack-v2-dedup The-stack-v2-swh-full Total 875.85 181.00 6,457.14 784.30 1,922.82 528.44</p><p>Visual data inspection Similar to the first StarCoder, we involve the BigCode community in a data inspection sprint to remove extensions with low-quality training data. We start from the annotations of the previous iteration that eliminated 36 out of the 300 extensions (of the 86 included programming languages). For StarCoder2, we only ran the data inspection for the not-yet-annotated programming languages (i.e., excluding the 86 languages of StarCoderBase). To streamline this process, we limited our inspection to extensions that include over 1,000 files and represent over 0.5% of the files in their respective languages. The remaining extensions were retained without further inspection, as they only make up a small volume. With the help of 15 annotators from the BigCode community, we visually inspected around 1000 extensions and excluded 130 (see appendix A.1 for the complete list). Our data inspection step excluded 39 programming languages from the dataset (appendix A.2), resulting in a final count of 619 programming languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Basic filters</head><p>We apply a set of basic filters to the dataset to remove autogenerated files, data files, or other low-quality training data.</p><p>• Long line filters: we first remove all files with more than 100k lines as those files are likely to be data or generated code. We also remove files with an average line length of more than 100 characters or a maximum line length of more than 1000 characters for all languages, excluding HTML, JSON, Markdown, Roff, Roff Manpage, SMT, TeX, Text, and XML. For the mentioned languages, we remove files where the longest line exceeds 100k characters.</p><p>• Autogenerated filter: we remove files classified as auto-generated by the is_generated function of go-enry <ref type="bibr">(go-enry, 2024)</ref>. Additionally, we exclude files containing one of {"auto-generated", "autogenerated", "automatically generated", "generated automatically", "this file is generated"} in the first 5 lines of the file.</p><p>• Alpha filter: we remove files with less than 25% of alphabetic characters for all languages except Motorola 68K Assembly and WebAssembly, where we only remove files with less than 25% of alpha-numeric characters due to the syntax of those languages.</p><p>• Encoded data filter: we detect files with inline encoded data using the following regular expressions:</p><p>-Base64 strings: [a-zA-Z0-9+/\n=]{64,} -Hexadecimal sequences: (?:\b(?:0x|\\x)?[0-9a-fA-F]{2}(?:,|\b\s*)){8,} -Unicode strings:</p><formula xml:id="formula_0">(?:\\u[0-9a-fA-F]{4}){8,}</formula><p>We remove the file if any of the substrings matching these expressions is longer than 1024 characters or if the fraction of matched characters is more than 50% of the file.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language-specific filters</head><p>In addition to the basic filters, we apply the following set of language-specific filters.</p><p>• For Text, JSON, YAML, Web Ontology Language, and Graphviz (DOT), we remove files with more than 512 lines to minimize the impact of repeated tokens in data files.</p><p>• For HTML, we keep only the files where visible text is at least 100 characters long and makes up at least 20% of the code, similar to the processing pipeline of StarCoder <ref type="bibr" target="#b71">(Li et al., 2023)</ref>.</p><p>• For Text, we keep only files with "requirement" in the lowercased filename, or if the filename without the extension is one of {"readme", "notes", "todo", "description", "cmakelists"}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Github Issues</head><p>We incorporate GitHub issues collected from GHArchive (Github Archive, 2024). We exclude pull requests here as we process them separately in §2.3.</p><p>A Github issue consists of a series of events with actions, such as opening the issue, creating a comment, or closing the issue. Each event includes the author's username, a message, an action, and a creation date. We follow the processing pipeline of StarCoder <ref type="bibr" target="#b71">(Li et al., 2023)</ref>, which we recap below:</p><p>• First, we removed auto-generated text when users replied to issues via email (for more information, see <ref type="bibr">Li et al., 2023, Appendix A)</ref>. We also deleted issues with a short message (less than 200 characters) and truncated long comments in the middle to a maximum of 100 lines while retaining the last 20 lines. This removed 17% of the volume -a similar percentage as in StarCoderBase.</p><p>• Next, we excluded comments from bots. To do so, we searched for keywords in the username of the comment's author (for more information, see <ref type="bibr">Li et al., 2023, Appendix A)</ref>. This step eliminated 3% of the issues, much less than the 17% reported in StarCoder <ref type="bibr" target="#b71">(Li et al., 2023)</ref>. This discrepancy is primarily because our dataset does not include pull requests, which are often the source of a significant proportion of bot-generated content.</p><p>• We used the number of users engaged in the conversation as an indicator of quality. Our criterion was to include conversations that have two or more users. However, we also preserved conversations that involved a single user if the total text within comments was less than 7,000 characters (96th percentile). Additionally, we excluded issues authored by a single user if they contained more than ten events, as they tended to be of poor quality or originate from overlooked bots. By implementing these filters, we removed 38% of the remaining issues. Lastly, we anonymized the usernames in the conversations by replacing them with a participant counter within the conversation (following the process of StarCoder).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Pull Requests</head><p>We include code reviews by gathering pull request events from GHArchive (Github Archive, 2024) and the corresponding source code from Software <ref type="bibr">Heritage (Software Heritage, 2024b)</ref>. Pull requests are requests to merge particular code changes from one branch into another on GitHub. Typically, they involve multiple rounds of code review discussions and additional cycles of code changes before they get merged into the target branch.</p><p>Data collection Specifically, for each pull request, we aggregate the PullRequestEvent, PullRequestReview-Event, PullRequestReviewCommentEvent, IssueCommentEvent, and IssuesEvent events found on GHArchive. More details about the differences between these events can be found in the Github documentation. Next, we extract all base and head commit IDs from these events and retrieve the corresponding code files from Software Heritage. As we do not have access to the commit diffs, we generate them by identifying changes between files at the same path. We consider files present in the base but absent in the head as deletions, while we consider files absent in the base but present in the head as additions. This process yields approximately 300M PRs, accompanied by a volume of 15 TB of base code. Among these, there are 215M closed PRs originating from around 24M repositories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PR filters</head><p>We remove PRs that 1) have been opened by bots, 2) consist only of comments by bots, 3) have a non-permissive license, 4) have been opted out, 5) changes the base during the PR, 6) are not approved or merged, or 7) lack initial diffs (either due to absent data from Software Heritage or because all data have been filtered in other steps).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>File filters</head><p>We remove files from the base commit if they satisfy one of the following conditions: 1) the file is a deletion or addition, 2) the file length exceeds 1 million characters, 3) the fraction of alphanumeric characters is less than 0.25, 4) the fraction of hexadecimal characters is greater than 0.25, 5) the max number of lines surpasses 100,000, 6) the average line length exceeds 100, 7) the max line length surpasses 1,000, or 8) the presence of non-English text in Markdown Title and description filtering We apply the following heuristic filters to clean up the PRs further. We exclude PRs with changes to the base, those not approved or merged, and those lacking initial diffs (either due to absent data from Software Heritage or being filtered out in previous steps). We also exclude PRs when the title is less than 10 characters or contains the words 'dependencies', 'dependency', 'depend', or 'release'. We exclude PRs when the description is less than 20 characters or contains 'Qwiet'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Truncating inputs</head><p>We shorten lengthy input fields in the PRs as follows. We truncate titles to 500 characters and descriptions to 80 lines, only displaying the first 60 and the last 20 lines. If the description length still exceeds 1000 characters, we truncate it.</p><p>Processing comments Following the processing of GitHub issues ( §2.2), we remove comments from bots and strip auto-generated text when users post via email reply. We anonymize the usernames of authors as described in §3.2. We remove comments from PRs with less than 20 characters unless they are PR review comments. For code review comments, we remove the full diff hunk if it exceeds 10,000 characters while keeping the filename and comment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subsampling PRs</head><p>To increase the diversity in the PRs, we sub-sample them on a per-repository basis.</p><p>For repositories with 1 PR (after filtering), we retain it with a probability of 0.8. We linearly decrease this retention probability to 0.1 for repositories with 1,000 PRs. For repositories with more than 1,000 PRs, we set the retention probability such that we retain only 100 PRs. Finally, we sub-sample YAML and JSON files with 10% retention probability when their file size exceeds 50% of the total base files size or when the file path contains one of the keywords: 'pack', 'lock', 'yarn', 'output', 'swagger', 'openapi', or 'output'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Max sequence length</head><p>We determine the maximum sequence length of PRs by first investigating the data distribution after the processing steps mentioned above. We find 3.7M PRs with up to 1M characters, resulting in 194 GB of data. This reduces to 3.3M PRs when we set a limit of 100K characters, resulting in a dataset size of 67.3 GB. (appendix A.5 has more details about sequence length statistics.) For the StarCoder2 models, we opt to include PRs with up to 100K characters (translating to roughly 25k tokens). Since we are pre-training with a limited context of 4K tokens, not all PRs fit into the context window. However, as described in §5.2, we format the PRs so that the diffs are local and do not require long context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Notebooks</head><p>We include notebooks from two separate sources: Jupyter notebooks extracted from the Software Heritage archive and notebooks released by the Kaggle platform.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Jupyter Notebooks</head><p>We transform Jupyter Notebooks into scripts and structured notebooks following the same pipeline as StarCoder <ref type="bibr" target="#b71">(Li et al., 2023)</ref>. One key difference is that we keep the markdown structure of the text blocks while it is removed in StarCoder. For completeness, we recap these preprocessing steps below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Jupyter -scripts</head><p>We utilize Jupytext<ref type="foot" target="#foot_1">foot_1</ref> to convert notebooks to scripts. To initiate the conversion process, Jupytext requires the identification of the specific programming languages within each notebook. This information is typically available in the metadata of most notebooks. In cases where it is not, we use the Guesslang library<ref type="foot" target="#foot_2">foot_2</ref> to identify the programming language, using a probability threshold of 0.5 or higher. Our initial dataset comprised 11 million notebooks, of which 3 million were excluded due to parsing errors. After near-deduplication, the dataset was reduced to 4 million notebooks converted to scripts.</p><p>Jupyter -structured To create this dataset, we first filtered out notebooks that did not contain any Python code or Markdown text using the metadata information of each notebook. Only notebooks explicitly marked as 'Python' in the metadata were kept. Then, for each notebook, consecutive Markdown blocks or code blocks were merged into a single Markdown or code block, respectively. Eventually, we ended up with consecutive code-text pairs in temporal order grouped by each notebook. Each Jupyter code-text pair contained the Markdown text immediately preceding the code block and the Python code, forming a natural instruction pair. We also included the formatted output of a code block if the output cell was non-empty; otherwise, it was marked by a special &lt;empty_output&gt; token. If consecutive code blocks have multiple output cells before merging, we only retain the output of the last code block. After these preprocessing steps and near-deduplication, we ended up with 4.6M structured Jupyter notebooks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2">Kaggle Notebooks</head><p>We include Python notebooks released by the Kaggle platform<ref type="foot" target="#foot_3">foot_3</ref> under an Apache 2.0 license, starting with an initial dataset of 3.6M notebooks. Note that this Kaggle dataset does not include the output cells, only the markdown and code cells.</p><p>Cleaning We start the data cleaning process by dropping notebooks with less than 100 characters and those with syntax errors. We also remove the templated text at the beginning of notebooks (see appendix A.7</p><p>for the templates). These steps remove 18% of the notebooks. Next, we convert the notebooks to the structured and script format, following the processing of the Jupyter notebooks in §2.4.1. Finally, we remove near-duplicates using the pipeline described in §3.1, eliminating 78% of the notebooks and leaving us with 580k notebooks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset description</head><p>To provide the model with more context regarding the content and objectives of the notebook, we include metadata about the Kaggle dataset whenever this information is available. We find that 42% of the notebooks are associated with a Kaggle dataset and include its title and description at the beginning of each notebook.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset schema</head><p>In addition to these high-level dataset descriptions, we scanned the code inside the notebooks for instances of read_csv. We found that 25% of the samples were loading CSV datasets. We extracted and incorporated detailed information about these datasets as follows. First, we used the Kaggle API to download the datasets and successfully retrieved 8.6% of the notebooks. The remaining cases were attributed to either the dataset being unavailable or encountering challenges downloading it within a reasonable time frame. For the downloaded datasets, we prefix the output of df.info() to the notebook, which displays the column names and their dtypes, the non-null values count, and the memory usage. We also include four sample rows from the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Documentation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Documentation from package managers</head><p>We crawl documentation from several package manager platforms, including npm, PyPI, Go Packages, Packagist, Rubygems, Cargo, CocoaPods, Bower, CPAN, Clojars, Conda, Hex and Julia. We first retrieve the names of the most popular libraries across various platforms from libraries.io. These library names are then used to search through individual package managers, enabling us to obtain the respective homepages for each library. We systematically crawled the documentation files from the obtained homepage links or, alternatively, extracted information from the provided README or documentation files on the platform. For documents obtained through homepage links, we adhere to the same processing strategy outlined below in the paragraph titled "Documentation from websites". When extracting documents from the REwang2023softwareADME or documentation files on the platform, we employ distinct heuristics to extract the text using markdown formats whenever feasible, aiming to maintain a simple and effective format. It is worth noting that many libraries available on PyPI and Conda have their associated documentation hosted on Read the Docs, which typically offers more comprehensive documentation. Consequently, we prioritize utilizing Read the Docs as the primary source of documentation for these libraries.</p><p>For these documents hosted on Read the Docs, we follow the same processing procedure outlined in the paragraph titled "Documentation from websites".</p><p>PDFs from package managers For documents related to the R language, we extracted text from all PDF files hosted on CRAN using the pdftotext library. <ref type="foot" target="#foot_4">7</ref> This library is particularly effective in preserving the formatting, including spaces within code snippets. For LaTeX-related documentation, we extracted the documentation, tutorial, and usage guide PDFs of LaTeX packages from CTAN, filtered out image-heavy PDFs, and converted the rest into markdown using the Nougat neural OCR tool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Documentation from websites</head><p>We collect code documentation from a carefully curated list of websites as detailed in Table <ref type="table" target="#tab_3">2</ref>. We start by systematically exploring the website from its initial URL listed in Table <ref type="table" target="#tab_3">2</ref>, using a queue to store URLs within the same domain. This queue expands dynamically as we discover new links during the crawl. Given that most documents comprise HTML pages, we focus our processing pipeline on (1) content extraction and (2) content concatenation. To extract the content, we utilize the trafilatura library<ref type="foot" target="#foot_5">foot_5</ref> to convert each HTML page into XML format, simultaneously eliminating redundant navigation and index bars, elements that often recur in documentation. Next, we converted the XML format to markdown using our XML-to-Markdown conversion script. In the second stage, to compile these documents into a single text, we first do a near-deduplication of the content extracted from different HTML pages. This</p><p>10 2 10 3 10 4 Number of Occurrences CSS Haskell HTML Perl PHP Julia JSON SQL Objective-C YAML Markdown TeX Ruby Python Erlang Unknown Rust JavaScript Go R Programming Languages Programming Language Usage step was essential since we have observed that certain document pages only comprise website layouts (e.g., navigation bars) instead of fruitful information for documents, resulting in a substantial amount of duplicated content. To accomplish this, we treat each HTML page from a single website as a cluster and apply the minhash locality-sensitive hashing technique to identify and eliminate similar pages, using a threshold of 0.7. Finally, we assemble the gathered content from different pages of the same website in the order of web page crawling, ensuring a cohesive narrative. This parallels the "breadth-first search" approach, where all nodes at the current depth are explored before proceeding to the next depth level. Also, we collected code-relevant data from existing web crawls such as RefinedWeb <ref type="bibr" target="#b99">(Penedo et al., 2023)</ref>, OSCAR <ref type="bibr" target="#b96">(Ortiz Suárez et al., 2019)</ref>, and esCorpius <ref type="bibr" target="#b59">(Gutiérrez-Fandiño et al., 2022)</ref>. We use regular expressions to identify programming language-specific constructs within the documents and to detect the "docs." substring in the page URLs. The resulting dataset primarily comprises content sourced from programming blogs, coding tutorials, and platforms like Read the Docs, with the exclusion of the documents gathered above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Free textbooks</head><p>We scraped free programming books compiled in the Free Programming Books project, which aims at promoting the distribution of free programming e-books. First, we extract all links and identify those with a PDF extension. Subsequently, we downloaded all available PDF files and utilized the pdf2text library to extract text from these PDF files. Finally, we parsed 3,541 books whose languages span across different regions, including English, Chinese, Japanese, Spanish, and others.</p><p>Language identification Finally, we have employed a dual approach to identify the main programming language used by each document. We leverage predefined rules when the source of the document unequivocally corresponds to a specific programming language and resort to the guesslang<ref type="foot" target="#foot_6">foot_6</ref> library in cases where such correspondence is not explicit. The resultant programming language distribution is graphically represented in Figure <ref type="figure" target="#fig_2">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Intermediate Representations</head><p>We augment source code by pairing its intermediate representations (IR) to enhance the model's understanding of low-resource programming languages. The key rationale behind this approach is that a shared intermediate </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">LHQ 19</head><p>We include several small high-quality datasets for math and coding:</p><p>• APPS (train) <ref type="bibr">(Hendrycks et al., 2021)</ref> is a popular text2code benchmark in Python with a train set of 5,000 examples. We include one solution per programming problem.</p><p>• Code Contest <ref type="bibr" target="#b72">(Li et al., 2022)</ref> is similar to APPS but includes solutions in several programming languages, namely Python 2/3, C++, and Java. We include one solution per problem and language and arrive at a dataset of 13k+ examples.</p><p>• GSM8K (train) <ref type="bibr" target="#b33">(Cobbe et al., 2021)</ref> is the train split of GSM8K, a popular evaluation benchmark for testing the math reasoning capabilities of LLMs. The dataset consists of 7k+ examples.</p><p>• GSM8K (SciRel) <ref type="bibr" target="#b146">(Yuan et al., 2023)</ref> is an augmented version of GSM8K that includes alternative reasoning paths for the questions in GSM8K. The extended version contains 110k examples.</p><p>• Deepmind Mathematics <ref type="bibr" target="#b114">(Saxton et al., 2019)</ref> is a synthetic dataset of math questions and answers across various domains <ref type="bibr">(algebra, arithmetic, calculus, comparison, measurement, numbers, polynomials, probability)</ref> and varying difficulty (easy-medium-hard). The dataset consists of 110M+ (short) examples.</p><p>• Rosetta Code <ref type="bibr">(Rosetta Code, 2023;</ref><ref type="bibr">Nanz &amp; Furia, 2015</ref>) is a dataset with over 1100 everyday programming tasks with solutions in as many different programming languages as possible.</p><p>• MultiPL-T <ref type="bibr">(Cassano et al., 2023a)</ref> is high-quality data in Lua, Racket, and OCaml based on automatically translating extracted Python functions and validating them with unit tests. The total dataset comprises over 200k examples.</p><p>• Proofsteps is part of the AlgebraicStack <ref type="bibr" target="#b10">(Azerbayev et al., 2024)</ref>, a dataset used to train the Lemma family of models. We also include proofsteps-lean, which was extracted from mathlib 4 (mathlib Community, 2020), and proofsteps-isabelle, which was built on top of the PISA dataset <ref type="bibr" target="#b65">(Jiang et al., 2021)</ref>. Proofsteps-lean contains over 3k examples, while proofsteps-isabelle contains over 250k examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.8">Other Natural Language Datasets</head><p>StackOverflow We include 11 million questions and their corresponding multiple responses from the Stack Overflow dump dated 2023-09-14 (StackExchange Archive, 2024). We filtered out questions with fewer than three answers. Upon inspecting the dataset, we found many mismatches between questions and answers due to inherent format errors in the Stack Overflow dump. We leveraged Llama-2-70b-chat-hf <ref type="bibr" target="#b137">(Touvron et al., 2023)</ref> to increase the quality of the dataset as follows. We selected 20,000 examples and asked Llama-2-70b-chat-hf to rate the question-answer pairs. See Appendix A.6 for the exact prompt. Next, we pick the 10,000 highest-scoring pairs as positive examples and use the remaining 10,000 answers to create negative examples by randomly pairing them with other questions. We use this dataset to train a binary classifier by embedding the question and answer with a well-performing sentence embedding model (sentence-transformers/all-MiniLM-L12-v2<ref type="foot" target="#foot_17">foot_17</ref>  <ref type="bibr" target="#b108">(Reimers &amp; Gurevych, 2019;</ref><ref type="bibr">Muennighoff et al., 2022a)</ref>) and minimizing the cosine distance between them. Next, we plot the embedding scores for a subset of the question-answer pairs and manually determine the threshold to 0.1. As a question can have multiple answers, we average the scores of question-answer pairs and remove all questions with an average score below 0.1. We end up with 11.4 million questions and over 10B tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ArXiv</head><p>We include the ArXiv subset of the RedPajama dataset <ref type="bibr">(Together Computer, 2023)</ref>. This dataset is downloaded from the publicly available Amazon S3 bucket <ref type="bibr" target="#b7">(Arxiv, 2024)</ref>. We further processed the dataset only to retain latex source files and remove preambles, comments, macros, and bibliographies from these files. The final dataset is roughly 30B tokens.</p><p>Wikipedia We include the English subset of Wikipedia. Specifically, we use the version collected by RedPajama (RedPajama Wiki, 2024), which is derived from the 2023-03-20 dump. We follow RedPajama's processing steps and eliminate hyperlinks and templates from the Wikipedia pages. The full dataset comprises around 6 billion tokens.</p><p>OpenWebMath We include OpenWebMath <ref type="bibr" target="#b97">(Paster et al., 2023)</ref>, an open dataset of high-quality mathematical text extracted from CommonCrawl. The full dataset comprises almost 15B tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preprocessing Pipeline</head><p>We apply several preprocessing steps, such as deduplication ( §3.1), PII redaction ( §3.2), benchmark decontamination ( §3.3), malware removal ( §3.4), and opt-out deletion requests ( §3.5), to the data sources described in the previous section. Since not all steps are applied to each data source, we summarize the preprocessing pipeline per data source in Table <ref type="table" target="#tab_4">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Removing Near-Duplicates</head><p>We deduplicate the source code, pull requests, notebooks, issues, and documentation. We do not deduplicate the already preprocessed natural language datasets, such as Arxiv, StackExchange, OpenWebMath, Wikipedia, and the small high-quality math and reasoning datasets.</p><p>We followed the deduplication pipeline of SantaCoder <ref type="bibr" target="#b12">(Ben Allal et al., 2023)</ref>. This process first calculates the MinHashes <ref type="bibr" target="#b22">(Broder, 2000)</ref> of all code files and then utilizes Locally Sensitive Hashing (LSH) to group files based on their MinHash fingerprints. During the LSH stage, "similar" files are assigned to the same buckets, identifying them as duplicates. Only one file from each duplicate group is chosen. In addition to the SantaCoder approach, to preserve repository context, we prioritize files from repositories with higher star and fork counts or from the latest commit date as a tiebreaker. We used 5-grams and a Jaccard similarity of 0.7. We refer to this blogpost for more background information regarding the deduplication pipeline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">PII Redaction</head><p>To reduce the likelihood of re-distributing Personally Identifiable Information (PII) present in the training data, we make diligent efforts to redact PII from the training set. We largely follow the steps from StarCoder <ref type="bibr" target="#b71">(Li et al., 2023)</ref> and leverage the StarPII model to redact various PII entities. Below, we provide more details on how we apply it to each data source.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Redacting PII entities</head><p>We use StarPII to redact names, emails, keys, passwords, IP addresses, and usernames from source code, pull requests, issues, and StackOverflow. We do not make any modifications to the model or redaction logic described in the StarCoder paper <ref type="bibr" target="#b71">(Li et al., 2023)</ref>. For OpenWebMath and documentation, we only redact names, keys, and emails, while we only redact emails for arXiv using the regex described in <ref type="bibr" target="#b12">Ben Allal et al. (2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Redacting usernames</head><p>The conversations in issues, pull requests, and StackOverflow often contain usernames in the message thread. We anonymize the author usernames by substituting them with a participant counter specific to the conversation, like username_1 to represent the second participant. These pseudonyms are added at the start of each comment to maintain the speaker's identity. Moreover, any references to these usernames in the messages are removed. Only the usernames of actively participating individuals in the conversation are masked, and mentions of non-participating users remain unaffected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Decontamination</head><p>To ensure the performance of StarCoder is not artificially inflated on our test benchmarks, we decontaminate the training set from our test sets. Specifically, we remove files that contain docstrings or solutions from HumanEval and MBPP, docstrings from APPS, questions from GSM8K, or prompts from DS1000. In contrast </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Malware Removal</head><p>We scan our training set to identify possible instances of malware in the source code, pull requests, notebooks, and issues. To this end, we use ClamAV 1.2 (ClamAV, 2024) with additional unofficial malware signatures published by SaneSecurity (Sane Security, 2024) as of 2023-11-16. Signatures with a high risk of False Positives (as determined by SaneSecurity) were not used. See Table <ref type="table" target="#tab_10">26</ref> for the most frequently detected malware signatures in the unfiltered code dataset. In summary, this step eliminates 59,442 files from the dataset, constituting only 0.009% of the 654M files.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Removing Opt-outs</head><p>We announced the upcoming training run of StarCoder2 on X<ref type="foot" target="#foot_18">foot_18</ref> and updated the "Am I in the stack" governance tool with the new repositories from The Stack v2. Developers were granted until November 20, 2023, to submit their opt-out requests. After the cut-off date, we eliminated 1,561 repositories associated with 91 users and organizations. A total of 22,066 files were removed from the source code dataset (excluding issues and PRs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data Composition</head><p>Model capacity With a much larger training set available, we decided to tailor our data composition to each model size. We reason that smaller models, having limited capacity, should be exposed to a less diverse dataset. This intuition is supported by research in multi-lingual NLP showing that languages compete for model capacity <ref type="bibr" target="#b6">(Arivazhagan et al., 2019;</ref><ref type="bibr" target="#b34">Conneau et al., 2020;</ref><ref type="bibr">Scao et al., 2022b)</ref>. Hence, we first create a smaller version of the SWH code dataset, selecting a subset of 17 widely-used programming languages. We use this variant to train the 3B and 7B models, whereas we use the full version with all 619 programming languages for the 15B model. To further limit the diversity in the training set for the 3B model, we also exclude some natural language datasets (see "Data composition per model size"). preserved 254GB of markdown data while reducing the size of HTML to 100 GB. This decision was driven by the anticipation that markdown would likely contain more code documentation, whereas HTML is commonly associated with webpages. Lastly, we subsampled data files like JSON, XML, and YAML to 8GB and a few other data formats to 1 GB. See Table <ref type="table" target="#tab_13">28</ref> in Appendix C.2 for the full list of subsampled languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Downsampling languages</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Repository-context</head><p>After subsampling some programming languages, we compile the source code from Software Heritage into repository-context-aware datasets. Each example in the dataset is a full repository with files arranged in a random order. As previously noted, we create two versions of the SWH dataset, the-stack-v2-train-smol and the-stack-v2-train-full, as further detailed in the subsequent paragraphs.</p><p>The-stack-v2-train-smol For the small variant, we select 17 widely used programming languages and include a curated set of documentation and configuration languages.</p><p>• Specifically, we include the following programming languages:</p><formula xml:id="formula_1">-C -C# -C++ -Go -Java -JavaScript -Kotlin -Lua -PHP -Python -R -Ruby -Rust -SQL -Shell -Swift -TypeScript</formula><p>• And incorporate the following languages associated with code documentation:</p><formula xml:id="formula_2">-AsciiDoc -HTML -Markdown -RDoc -RMarkdown -Text -reStructuredText</formula><p>• We also include several configuration languages and files, which we list in Appendix C.1.</p><p>• Despite limiting the languages to this subset, we obtain a dataset of 525B+ unique tokens.</p><p>The-stack-v2-train-full For the full variant, we include all 619 programming languages. Although this subset significantly enhances language diversity (adding 600+ programming languages), it contributes only around 250B tokens to the dataset, culminating in 775B+ tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data composition per model size</head><p>In Table <ref type="table" target="#tab_5">4</ref>, we summarize the data composition for the 3B, 7B, and 15B models. We use the-stack-v2-train-extras to denote all supplementary sources gathered for StarCoder2, excluding the source code obtained from SWH. For the 3B, we use the-stack-v2-train-smol and exclude OpenWebMath, Wikipedia, and Arxiv from the extra data sources in §2. This leads to a dataset of 622B+ unique tokens. For the 7B, we include OpenWebMath, Wikipedia, and Arxiv, leading to a slightly larger dataset of 658B+ unique tokens. For the 15B, we include the-stack-v2-train-full dataset and all extra data sources listed in §2, resulting in a dataset with 913B+ unique tokens. The size of this dataset is 4× the size of the training dataset for StarCoderBase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Data Formatting</head><p>We present the formatting guidelines for each of the data sources below. We provide the templates below in which ⟨token⟩ refers to a sentinel token, and metadata and data refer to placeholders for data fields, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Source Code</head><p>We prepend the repository name and file paths to the context of the code file. We only add this metadata with a 50% probability to enable the model to operate without this information. We use the following format when adding the repository name and file paths:</p><formula xml:id="formula_3">&lt;repo_name&gt;reponame&lt;file_sep&gt;filepath1\ncode1&lt;file_sep&gt;filepath2\ncode2 ... &lt;|endoftext|&gt;.</formula><p>We use the following format when we do not include this meta-data: &lt;file_sep&gt;code1&lt;file_sep&gt;code2 ... &lt;|endoftext|&gt;.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Repository-context</head><p>Starcoder1 was trained with file-context, i.e., the setting where random files are joined into the context window. In this work, we explore training with repository-context, wherein files from the same repository are grouped together. While we considered various methods for grouping files within the repository, we ultimately arranged them in a random order within the same repository.</p><p>FIM To enable the model to perform code infilling tasks, we apply the fill-in-the-middle transformation (FIM; <ref type="bibr" target="#b11">Bavarian et al., 2022)</ref> to the source code. While we explored several FIM variants in preliminary experiments, we opted for repo-context file-level FIM in the StarCoder2 models. In this FIM variant, repositories are selected with a 50% chance of being candidates for FIM. The selected repository examples are split by &lt;|endoftext|&gt; and &lt;file_sep&gt; tokens. Next, we apply the FIM transformation to each chunk with a 50% probability. We do not apply FIM to the repository metadata (&lt;repo_name&gt;reponame). Below, we provide an example of the FIM format when it's only applied to the second source file:</p><formula xml:id="formula_4">&lt;repo_name&gt;reponame&lt;file_sep&gt;filepath0\ncode0&lt;file_sep&gt;&lt;fim_prefix&gt;filepath1\n code1_pre&lt;fim_suffix&gt;code1_suf&lt;fim_middle&gt;code1_mid&lt;file_sep&gt; ...&lt;|endoftext|&gt;</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Pull Requests</head><p>Formatting pull requests is challenging as we aim to create a compact representation of a potentially long sequence of code changes and comments. We refer to §2.3 for details on how we removed and truncated long input fields of the pull request. Here, we focus on how to render the PR into a structured format that can be consumed by the LLM.</p><p>For files part of the base commit, we include the entire file with 0.2 probability; otherwise, we display a range of changes in the base files across all commit heads of the PR. <ref type="foot" target="#foot_19">22</ref> We randomly add up to 32 lines before and after the changes.</p><p>We use diff hunks to display modifications between the before and after state of the file, ensuring that changes are reasonably localized. Additionally, within the diff hunks, we incorporate 3-10 randomly selected context lines both before and after the specific change.</p><p>We structure the PR format as follows. The first block presents the title, description, and complete base files or modifications made to them. Subsequently, we outline the first set of head diff hunks:</p><p>&lt;pr&gt;Title: title\nusername_0: description &lt;pr_status&gt;opened &lt;repo_name&gt;reponame &lt;pr_base&gt; &lt;pr_file&gt;filepath_1 &lt;pr_base_code&gt;file_content/changes_1 ... &lt;pr_file&gt;filepath_N &lt;pr_base_code&gt;file_content/changes_N &lt;pr_diff&gt; &lt;pr_file&gt;filepath_1 &lt;pr_diff_hunk&gt;diff_hunk_1 ... &lt;pr_diff_hunk&gt;diff_hunk_K ... &lt;pr_file&gt;filepath_M &lt;pr_diff_hunk&gt;diff_hunk_1 ... &lt;pr_diff_hunk&gt;diff_hunk_J</p><p>The second block is repeated for each new head commit in the PR, covering general comments, review comments, and code review comments. The block concludes with the diff hunks between the pull request base and the new head, reflecting the outcome of discussions and comments. Note that it's also possible for users to close and reopen the pull request. As in Github issues, we refer to authors by their participant counter within the conversation, e.g., username_1, to refer to the second participant in the issue.</p><p>&lt;pr_comment&gt;username_id: comment &lt;pr_event_id&gt;comment_id ... ... ... &lt;pr_review&gt;username_id: review_comment\n &lt;pr_event_id&gt;review_id &lt;pr_review_state&gt;[approved, rejected, commented, changes_required] ... ... ... &lt;pr_review_comment&gt; &lt;pr_event_id&gt;comment_id &lt;pr_in_reply_to_review_id&gt;review_id (opt) &lt;pr_in_reply_to_comment_id&gt;comment_id (opt) &lt;pr_file&gt;filepath &lt;pr_diff_hunk_comment_line&gt;line_number &lt;pr_diff_hunk&gt;diff_hunk_content &lt;pr_comment&gt;username_id: comment ... ... ... &lt;pr&gt;username_id &lt;pr_status&gt;closed &lt;pr_is_merged&gt;False ... &lt;pr&gt;Title: title\nusername_id: description &lt;pr_status&gt;[opened, reopened, edited] ... ... ... &lt;pr_file&gt;filepath_1 &lt;pr_diff_hunk&gt;diff_hunk_1 ... &lt;pr_diff_hunk&gt;diff_hunk_K ... &lt;pr_file&gt;filepath_M &lt;pr_diff_hunk&gt;diff_hunk_1 ... &lt;pr_diff_hunk&gt;diff_hunk_J We only add the following final block when the PR is closed. &lt;pr&gt;username_id &lt;pr_status&gt;closed &lt;pr_is_merged&gt;True &lt;|endoftext|&gt;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">GitHub Issues</head><p>We use sentinel tokens to mark the opening of an issue and subsequently include its title. We separate the sequence of comments by a &lt;issue_comment&gt; token and include an anonymized speaker identifier before the comment. Specifically, we refer to authors by their participant counter within the conversation, e.g., username_1, to refer to the second participant in the issue. To distinguish between the different turns, we use comment_1, id1 to refer to the second comment and its anonymized speaker id, respectively. The &lt;issue_closed&gt; token is added if the issue is closed.</p><p>&lt;issue_start&gt;Title: title\nusername_id0: comment_0&lt;issue_comment&gt;username_id1: comment_1 ... &lt;issue_closed (optional)&gt;&lt;issue_comment&gt;username_idn: comment_n&lt;|endoftext|&gt;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Notebooks</head><p>Jupyter -scripts We format Jupyter scripts as a single code block, starting with a &lt;jupyter_script&gt; token.</p><p>&lt;jupyter_script&gt;code&lt;|endoftext|&gt; Jupyter -structured Parsed Jupyter notebooks are chains of text, code, and outputs. We separate the cells with sentinel tokens. Note that we use text2, code2, output2 to refer to the 3rd triplet in the notebook. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Kaggle -scripts</head><p>When available, we prepend the associated dataset title and description to Kaggle notebooks (42% of the samples). For 8.6% of the notebooks, we add granular information on the dataset's schema. Below is the format we use:</p><p>&lt;jupyter_start&gt;&lt;jupyter_text&gt;title\ndescription\nKaggle dataset identifier: data_identifier &lt;jupyter_code&gt;import pandas as pd\n\ndf = pd.read_csv(data_path1)\ndf.info() &lt;jupyter_output&gt;df_info_output1 &lt;jupyter_text&gt;Examples:\nexample1_1\n..example1_4 ... &lt;jupyter_script&gt;code&lt;|endoftext|&gt; Some notebooks might load more than one csv file, so we repeat the blocks of data information content for all files.</p><p>Note that we introduce a new special token &lt;jupyter_script&gt; to append the final script of the converted Kaggle notebook. This token helps differentiate the script, which is usually long, from code that follows &lt;jupyter_code&gt; token, typically shorter.</p><p>Kaggle -structured Structured Kaggle notebooks are similar to structured Jupyter notebooks, except that they don't have an output cell, so we only include text and code blocks and keep the tokens used in Jupyter Notebooks:</p><p>&lt;jupyter_start&gt;&lt;jupyter_text&gt;text0&lt;jupyter_code&gt;code0&lt;jupyter_text&gt; ... &lt;|endoftext|&gt;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">StackExchange</head><p>We concatenate questions and answers in the StackOverflow dataset using a format similar to the GitHub issues. We start with the question and then add answers in random order. We include the upvote score alongside the answer and, if applicable, denote it as the selected answer. Note that we do not have the title of the conversations for the StackExchange dataset.</p><p>&lt;issue_start&gt;username_id0: question &lt;issue_comment&gt;username_id1: answer_1\nUpvotes: score [selected answer](Optional) ... &lt;issue_comment&gt;username_idn: answer_n\nUpvotes: score [selected answer](Optional)&lt;|endoftext|&gt; 5.6 Intermediate Representations We split 50/50 between translating from source code to intermediate representation (code-&gt;intermediate) and vice-versa (intermediate-&gt;code). Regarding the intermediate representation, we use the size-optimized version 80% of the time and the performance-optimized version 20% of the time. We use separate sentinel tokens to indicate the direction of the translation. code&lt;code_to_intermediate&gt;intermediate_representation intermediate_representation&lt;intermediate_to_code&gt;code 6 Model architecture and training details In this section, we provide all details regarding the model architecture ( §6.1), tokenizer ( §6.2), training details ( §6.3), and CO 2 emissions during training ( §6.4). GitHub event id of review &lt;pr_in_reply_to_comment_id&gt; GitHub event id of comment &lt;pr_diff_hunk_comment_line&gt; line number of code review comment</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Model Architecture</head><p>We introduce a few architectural changes compared to StarCoderBase. First, we replace learned positional embeddings with Rotary Positional Encodings (RoPE; <ref type="bibr" target="#b131">Su et al., 2021)</ref>, as we confirmed significant performance gains in a preliminary ablation study. Following DeepseekCoder <ref type="bibr" target="#b57">(Guo et al., 2024)</ref> and Code LLaMA <ref type="bibr" target="#b111">(Rozière et al., 2023)</ref>, we use a base period θ = 1e5. The second architectural modification we make is replacing Multi-Query Attention (MQA; <ref type="bibr" target="#b121">Shazeer, 2019)</ref> with Grouped Query Attention <ref type="bibr">(Ainslie et al., 2023, GQA;</ref><ref type="bibr"></ref> ). However, we keep the number of key-value heads relatively low-2 for the 3B, 4 for the 7B and 15B-to prevent significantly slowing down inference.</p><p>We summarize all other hyperparameters, such as the number of layers and hidden dimension, in Table <ref type="table" target="#tab_10">6</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Tokenizer</head><p>We follow the procedure of StarCoderBase and train a byte-level Byte-Pair-Encoding tokenizer on a small subset of The Stack v1. <ref type="foot" target="#foot_21">24</ref> In our preliminary experiments, we observed that increasing the vocabulary size to 100K did not improve performance. Hence, we decided to maintain a vocabulary size of 49,152 tokens, including the sentinel tokens from Table <ref type="table" target="#tab_9">5</ref>. The pre-tokenization step includes a digit-splitter and the regex splitter from the GPT-2 pre-tokenizer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Training Details</head><p>Base models The models were trained with a sequence length of 4,096 using Adam <ref type="bibr" target="#b66">(Kingma &amp; Ba, 2015)</ref> with β 1 = 0.9, β 2 = 0.95, ϵ = 10 -8 and a weight decay of 0.1, without dropout. The learning rate followed a cosine decay after a linear warmup of 1,000 iterations.</p><p>Table 7 details the training hyper-parameters for each model. RoPE θ values are different for StarCoder2-15B due to a bug in parsing the training configuration. Moreover, StarCoder2-15B was scheduled to train for 1.1M iterations but was early stopped after 1M iterations. Following Muennighoff et al. (2023), we repeat data for around four to five epochs. Long context We further pre-trained each model for long-context on 200B tokens from the same pretraining corpus, using a 16,384 context length with a sliding window of 4,096, with FlashAttention-2 (Dao <ref type="bibr">et al., 2022;</ref><ref type="bibr" target="#b40">Dao, 2024)</ref>. We increase RoPE θ and use the same configuration for the optimizer. The other training hyperparameters are provided in Table <ref type="table" target="#tab_13">8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">CO2 Emissions</head><p>We provide estimations of the CO 2 emission of the StarCoder2 training using the Machine Learning Impact calculator presented in <ref type="bibr" target="#b68">Lacoste et al. (2019)</ref>. Note that we calculate the CO 2 emissions by considering the total GPU hours of the base-model training. We then extrapolate this number to the long-context fine-tuning based on the number of tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3B</head><p>The compute infrastructure provided by ServiceNow had a carbon efficiency of 0.386 kgCO 2 eq/kWh. A cumulative of 97,120 hours of computation was performed on hardware of type A100 SXM4 80 GB (TDP of </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7B</head><p>The compute infrastructure provided by Hugging Face had a carbon efficiency of 0.2925 kgCO 2 eq/kWh.</p><p>A cumulative of 145,152 hours of computation was performed on hardware of type H100 (TDP of 660W). Total emissions are estimated to be 28,021.6 kgCO 2 eq. The long-context fine-tuning stage adds 1601.23, resulting in a total of 29,622.83 kgCO 2 eq.</p><p>15B The paper will soon be updated with estimates for the 15B model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Evaluation</head><p>We evaluate the StarCoder2 models on a variety of benchmarks from the literature and compare them to recent state-of-the-art open Code LLMs: StableCode (Pinnaparaju et al., 2024), Code Llama (Rozière et al., 2023), DeepSeekCoder (Guo et al., 2024), and original StarCoder (Li et al., 2023). Since StarCoder2 is a base model, we only compare it with the base models of the model families mentioned above.</p><p>We group all our comparisons by model sizes. The small models have 3B or fewer parameters, the medium models have 7B or fewer parameters, and the large models have 15B or fewer parameters. Finally, we include two extra large models: CodeLlama-34B and DeepSeekCoder-33B. These models are more than twice the size of the large StarCoder2 model. But, as we shall see below, StarCoder2-15B comes close to or even outperforms the extra-large models in several benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Code Completion</head><p>We first evaluate the StarCoder2 models on code completion tasks, which have been widely studied in Code LLM work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.1">HumanEval, MBPP, and EvalPlus</head><p>About the benchmarks HumanEval <ref type="bibr" target="#b28">(Chen et al., 2021)</ref> and MBPP <ref type="bibr" target="#b8">(Austin et al., 2021)</ref> are two of the most widely studied benchmarks for Code LLMs. Each benchmark has a few hundred programming problems.</p><p>Each HumanEval problem has a prompt-a function signature and docstring-and a set of hidden unit tests.</p><p>The prompt for each MBPP problem includes a natural language description followed by a few tests. The model under evaluation will complete the function given the prompt, and we test that function with the hidden unit tests. The result is considered a success only if all hidden tests pass.</p><p>Recently, Liu et al. (2023a) identified several issues with both benchmarks. (1) Most problems have inadequate hidden tests that cannot detect subtle bugs in solutions (See Listings 1 and 2); and (2) Several problems have wrong test cases and ambiguous descriptions, which unfairly penalize the models that interpret the statements in other reasonable ways (See Listings 2). They introduce the EvalPlus framework to address these problems. The resulting benchmarks (HumanEval+ and MBPP+) have 80× and 35× more tests than the original benchmarks. For rigorous evaluation, we adopt the EvalPlus framework in this study. Listing 1: A HumanEval task with insufficient tests def common(l1: list, l2: list) -&gt; list: """Return sorted unique common elements for 2 lists""" common_elems = list(set(l1).intersection(set(l2))) common_elems.sort() return list(set(common_elems)) assert common([4,3,2,8], []) == [] assert common([5,3,2,8], [3,2]) == [2,3] ... # [Explanation] This solution is wrong as applying set # to the sorted common_elems does not preserve the # order. Base HumanEval test inputs are too short to # easily manifest the flakiness. Listing 2: An MBPP task with problematic tests """Write a function to check whether all dictionaries → in a list are empty or not.""" def empty_dit(list1): return all(not d for d in list1) assert empty_dit([{},{},{}]) == True assert empty_dit([{1,2},{},{}]) == True # Wrong test! assert empty_dit([{}]) == True # [Explanation] First, the second base test is wrong, # falsifying any correct solutions. Second, the tests # are weak, passing the wrong solution above. The wrong # solution mistakingly yields False given [{}, {}, [1]] # where we expect True as all dictionaries are empty # and the non-empty is an array, not a dictionary.</p><p>Hyperparameters Following recent work on Code LLMs <ref type="bibr" target="#b111">(Rozière et al., 2023;</ref><ref type="bibr" target="#b57">Guo et al., 2024)</ref>, we use greedy decoding and report the mean pass@1 (mean success rate) for all problems in the benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The results for HumanEval, MBPP, and their EvalPlus variants are presented in Table <ref type="table" target="#tab_14">9</ref>. <ref type="foot" target="#foot_22">25</ref> From the table, we can make the following observations:</p><p>1. StarCoder2-3B is the best-performing small model on all the datasets (HumanEval, MBPP, Hu-manEval+, and MBPP+). The model is significantly better than its predecessor, StarCoderBase-3B, exhibiting improvements of 60.2% on HumanEval+ and 32.4% on MBPP+, respectively.</p><p>2. StarCoder2-7B comes in second place of the medium models. DeepSeekCoder-6.7B is stronger, outperforming StarCoder2-7B by 32.4% and 24.1% on HumanEval+ and MBPP+, respectively. However, StarCoder2-7B consistently outperforms all the other medium models, including both StarCoderBase-7B and CodeLlama-7B. StarCoder2-7B outperforms StarCoderBase-7B by 19.6% and 15.2% on HumanEval+ and MBPP+, respectively. Additionally, it surpasses CodeLlama-7B by 16.8% and 9.6% on these benchmarks. 3. StarCoder2-15B is the best-performing large model by a significant margin. For example, it scores 46.3, whereas CodeLlama-13B scores 37.8 on HumanEval. The results on EvalPlus are also consistent. For example, on HumanEval+, it significantly improves over StarCoderBase-15B and CodeLlama-13B by 47.7% and 17.0%, respectively. 4. StarCoder2-15B is even competitive with models that are more than twice its size. For example, StarCoder2-15B outperforms CodeLlama-34B on both MBPP and MBPP+.</p><p>Although EvalPlus makes HumanEval and MBPP far more robust, the problems in these benchmarks only exercise basic Python built-ins. They do not test them on other programming languages and do not test models' knowledge of other Python libraries. We address these limitations in the rest of this subsection with more comprehensive evaluations on code completion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.2">MultiPL-E: Multilingual Code Completion</head><p>About the benchmark MultiPL-E <ref type="bibr">(Cassano et al., 2023b)</ref> uses a suite of lightweight, rule-based compilers to translate HumanEval from Python to 18 other programming languages. Thus MultiPL-E is a multi-language benchmark with the same problems translated to different languages.<ref type="foot" target="#foot_23">foot_23</ref> </p><p>Hyperparameters We sample 50 completions per prompt at temperature 0.2 with top-p 0.95. This is how MultiPL-E results are reported on the BigCode Models Leaderboard <ref type="bibr">(Ben Allal, 2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The results on MultiPL-E appear in Table <ref type="table" target="#tab_18">10</ref>. We make the following observations:</p><p>1. Across all size classes, there is no single model that is best at every language. Nevertheless, the StarCoder2 models perform well as described below.</p><p>2. Of the small models, StarCoder2-3B performs the best on 11/18 programming languages.</p><p>3. Of the medium models, DeepSeekCoder-6.7B performs best. StarCoder2-7B does better than CodeLlama-7B on most languages.</p><p>4. Of the large models, StarCoder2-15B does the best on 16/18 programming languages. CodeLlama-13B outperforms StarCoder2-15B on Go and Java.</p><p>5. StarCoder2-15B meets or exceeds the performance of CodeLlama-34B on 10/18 programming languages and DeepSeekCoder-33B on four lower-resource languages (D, Julia, Lua, and Perl).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.3">DS-1000: Data Science Tasks in Python</head><p>About the benchmark DS-1000 <ref type="bibr" target="#b69">(Lai et al., 2023)</ref> is a widely studied benchmark with 1,000 data science tasks in Python. Unlike the HumanEval and MBPP problems that only use the Python standard library, DS-1000 exercises seven widely used libraries, from Matplotlib to TensorFlow. Therefore, here we further adopt DS-1000 to evaluate the performance of Code LLMs in completing data science tasks with popular libraries.</p><p>Hyperparameters Following <ref type="bibr" target="#b69">Lai et al. (2023)</ref>, we use temperature 0.2 and top-p 0.95 to generate 40 samples per problem, and report mean pass@1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Table <ref type="table" target="#tab_19">11</ref> reports the results on DS-1000. We make the following observations:</p><p>1. StarCoder2-3B overall is the best-performing small model on DS-1000. Except for PyTorch and TensorFlow (where it is slightly worse than StableCode-3B), StarCoder2-3B achieves the best performance on all the other popular libraries.</p><p>2. StarCoder2-7B comes in second place out of the medium models, with a performance similar to DeepSeekCoder-6.7B.</p><p>3. StarCoder2-15B is the best-performing large model on DS-1000. It substantially outperforms both StarCoderBase-15B and CodeLlama-13B by large margins, and approaches the overall performance of CodeLlama-34B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Code Fixing and Editing</head><p>While the above subsection has studied various code completion tasks, Code LLMs can be used in various other ways. In this subsection, we focus on studying their capabilities for fixing bugs or editing existing code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.1">HumanEvalFix: Fixing Bugs in Six Programming Languages</head><p>About the benchmark HumanEvalFix <ref type="bibr">(Muennighoff et al., 2024a</ref>) is a benchmark that tests a model's ability to identify and fix bugs in code. The benchmark supports six programming languages shown in Figure <ref type="figure" target="#fig_2">12</ref>. Since it is not a code completion benchmark, most base models do poorly on HumanEvalFix whereas instruction-tuned <ref type="bibr" target="#b141">(Wei et al., 2022;</ref><ref type="bibr" target="#b113">Sanh et al., 2022;</ref><ref type="bibr">Muennighoff et al., 2022b;</ref><ref type="bibr">2024b</ref>) models perform better. Thus, we consider the instruction-tuned variants of DeepSeekCoder and CodeLlama in our comparison <ref type="bibr" target="#b57">(Guo et al., 2024;</ref><ref type="bibr" target="#b111">Rozière et al., 2023)</ref>. We also compare with OctoCoder, which is an instruction-tuned version of the initial StarCoder using the CommitPackFT dataset <ref type="bibr">(Muennighoff et al., 2024a;</ref><ref type="bibr" target="#b150">Zhuo et al., 2024;</ref><ref type="bibr" target="#b75">Longpre et al., 2023)</ref>. We benchmarked the default HumanEvalFixTests subvariant; hence, there were no docstrings present to guide the model. StarCoder2 issues format Although StarCoder2 is a base model, it is pretrained on GitHub issues and StackOverflow discussions using a special format ( §5.3). We experiment with prompting the model to fix code bugs in the style of a discussion as follows:</p><p>&lt;issue_start&gt;username_0: instruction\n\n'''buggy function'''\nUpvotes: 100&lt;issue_comment&gt; username_1: Sure, here is the fixed code.\n\n'''function start</p><p>In this template, "instruction" is the HumanEvalFix instruction telling the model to fix the bug in the code, "buggy function" is the function with a subtle bug, and "function start" is the function header including imports. The generation of the model is stopped as soon as ''' is generated. The evaluation code is available via Ben Allal et al. ( <ref type="formula">2022</ref>), and we denote this as the "Issue" prompt. We also benchmark StarCoder2 with the same basic "Instruct" prompt used in <ref type="bibr">Muennighoff et al. (2024a)</ref>.</p><p>Hyperparameters: Following <ref type="bibr">(Muennighoff et al., 2024a)</ref>, we use a temperature of 0.2 to estimate pass@1 with 20 samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Unlike the previous sections, we only evaluate StarCoder2-15B and primarily compare it to instruction-tuned models. The results are in Table <ref type="table" target="#tab_20">12</ref> (with best-performing models highlighted in bold and second-best underscored), and we make the following conclusions:</p><p>1. The base models (StarCoder2-15B and StarCoderBase-15B) perform very poorly when given an instruction prompt, which motivates using a different prompt format.</p><p>2. Using the Issue prompt described above, StarCoder2-15B performs remarkable well as a base model. It outperforms the instruction-tuned CodeLlama models by a significant margin and nearly reaches the performance of the instruction-tuned DeepSeekCoder models.</p><p>3. Using the Issue prompt for StarCoder2-15B leads to a larger increase in performance than using the Commit prompt for StarCoderBase-15B. This indicates that pre-training on pull requests ( <ref type="formula">StarCoder2</ref>) is a viable alternative to pre-training on commits (StarCoderBase).</p><p>4. Using the Issue prompt, StarCoder2-15B also outperforms all other open models presented in <ref type="bibr">Muennighoff et al. (2024a)</ref>.</p><p>5. StarCoder2-15B underperforms on C++ when using the Issue prompt, which hurts its overall performance. Our investigation shows that this is mainly because one-third of the code generated is incomplete, e.g., having an unexpected break immediately after the beginning of a for loop.</p><p>Additional prompt engineering may be necessary to fix this. Thus, we still see value in instruction tuning StarCoder2 to further improve its usability in handling similar scenarios more effectively without prompt engineering. We leave the instruction tuning or even preference alignment <ref type="bibr" target="#b31">(Christiano et al., 2017;</ref><ref type="bibr" target="#b47">Ethayarajh et al., 2024)</ref> of StarCoder2 to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.2">Code Editing</head><p>About the benchmark CanItEdit <ref type="bibr" target="#b26">(Cassano et al., 2024</ref>) is a hand-crafted benchmark designed to evaluate model performance in Python code editing tasks. Each problem consists of a code snippet accompanied by an instruction of two types: descriptive or lazy. Descriptive instructions are systematic and provide detailed information, whereas lazy instructions are brief, direct, and mimic the typical instructions humans provide to code completion models. The goal is to modify the code according to the instruction; both lazy and descriptive instructions should lead to the same edit. The accuracy of each modification is assessed using a hidden test suite, and pass@1 is reported. The benchmark encompasses a variety of problems, from simple single-function, single-line edits to intricate multi-class problems requiring multiple-line edits in separate locations. Some tasks demand domain-specific knowledge like mathematics, and successful completion of a problem often requires the model to understand the connections between the components of the program.</p><p>Listing 3 shows an abbreviated<ref type="foot" target="#foot_24">foot_24</ref> sample problem from CanItEdit with its lazy instruction.  precise samples in the benchmark were chosen from a larger set of samples, and the noise from choosing which samples to include in the benchmark when using 800 samples is about 1.5%. We make the following observations:</p><p>StarCoder2-3B performs competitively with other small models. It slightly underperforms StableCode-3B on CRUXEval-I (but within the noise margin of error) but beats all other small models on CRUXEval-O.</p><p>2. For both tasks, StarCoder2-7B performs on par with CodeLlama-7B but lags significantly behind DeepSeekCoder-6.7B.</p><p>3. StarCoder2-15B is the best-performing large model. It surpasses CodeLlama-13B and drastically improves upon StarCoderBase-15B on both CRUXEval-I and CRUXEval-O.</p><p>4. StarCoder2-15B performs on par with the extra-large models. On CRUXEval-I, it outperforms both CodeLlama-34B and DeepSeekCoder-33B but within standard deviation. On CRUXEval-O, it significantly outperforms CodeLlama-34B and slightly underperforms DeepSeekCoder-33B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">Fill-in-the-Middle</head><p>About the benchmark StarCoder2 supports fill-in-the-middle (FIM), which is the ability to complete an arbitrary span of code conditioned on both text before and after the insertion point. We use the benchmark from Ben Allal et al. ( <ref type="formula">2023</ref>), which tests the ability of models to fill in a single line of code in Python, JavaScript, and Java solutions to HumanEval.</p><p>Hyperparameters <ref type="bibr">Following Ben Allal et al. (2023)</ref>, we sample 20 completions per example at temperature 0.2 and top-p 0.95 and report the mean exact match, as done</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The results appear in Table <ref type="table" target="#tab_22">16</ref>. We observe that StarCoder2-3B performs as well as StarCoderBase-15B on this FIM benchmark. Unfortunately, StarCoder2-15B underperforms on FIM. Due to an implementation bug, the FIM-rate was smaller than intended for most of the training. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6">Repository-Level Code Completion Evaluation</head><p>Code completion in practice often occurs within the context of a repository rather than in isolated files.</p><p>Leveraging repository-level context for code completion is thus essential for models to perform well in realworld scenarios. We evaluate models on repository-level code completion with two benchmarks: RepoBench <ref type="bibr">(Liu et al., 2023b)</ref> and CrossCodeEval <ref type="bibr" target="#b45">(Ding et al., 2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6.1">RepoBench</head><p>About the benchmark RepoBench <ref type="bibr">(Liu et al., 2023b</ref>) is a live benchmark designed for evaluating code completion at the repository level, with a focus on next-line prediction. In this work, we use the latest version (v1.1) of RepoBench 28,29 , which sources its data from GitHub repositories created from October 6th to December 31st, 2023, and takes steps to avoid data leakage by removing duplicates against The Stack v2. Our evaluation includes five levels-2k, 4k, 8k, 12k, and 16k-across three settings: cross-file-first, cross-file-random, and in-file, with each setting comprising 5,000 data points (1,000 per level). We report the average edit similarity, exact match, and CodeBLEU (Ren et al., 2020) scores for the three settings.</p><p>Hyperparameters Following prior work on Code LLMs <ref type="bibr" target="#b28">(Chen et al., 2021)</ref>, we set the generation temperature to 0.2 and the top-p sampling parameter to 0.95 for all models under evaluation. We constrained the models to generate a maximum of 128 new tokens per prompt, and the first non-empty and non-comment line of the output was selected as the prediction. While StarCoder2 uses special tokens for repositorylevel training, we ensured uniformity in prompt construction across all models by following the official implementation in line with <ref type="bibr">Liu et al. (2023b)</ref>. The maximum token count for prompts was set to 15,800 by truncating excess cross-file context, except for StarCoderBase, which was constrained to 7,800 tokens due to its maximum sequence length limit of 8k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Table <ref type="table" target="#tab_23">17</ref> presents the performance of open-access models on RepoBench v1.1. We observe that:</p><p>1. StarCoder2, with repository-level training, consistently outperforms StarCoderBase, across all evaluated model sizes.</p><p>2. StarCoder2-3B demonstrates notable performance among the smaller models, ranking as the secondbest one following StableCode-3B.</p><p>3. StarCoder2-7B achieves competitive performance closely matching that of CodeLlama-7B among the medium models, with DeepSeekCoder-6.7B achieving the leading performance metrics.</p><p>4. StarCoder2-15B not only largely outperforms CodeLlama-13B but also showcases comparable, and in some metrics superior, performance against the significantly larger CodeLlama-34B model. .25 75.20 45.21 44.59 79.92 52.70</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6.2">CrossCodeEval</head><p>About the benchmark CrossCodeEval <ref type="bibr" target="#b45">(Ding et al., 2023</ref>) is a diverse and multilingual benchmark designed for repository-level code completion. It was constructed from a wide range of real-world, opensourced, permissively licensed repositories in four popular programming languages: Python, Java, TypeScript, and C#. Through careful static analysis methods, CrossCodeEval strictly requires cross-file context for accurate code completion. We report results in both Code Match (Edit Similarity) and Identifier Match (F1 Score) following the definitions in <ref type="bibr" target="#b45">Ding et al. (2023)</ref> in all four languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyperparameters</head><p>We use a max sequence length of 16k for all models except for StarCoderBase, which only supports 8k. In line with <ref type="bibr" target="#b45">Ding et al. (2023)</ref>, we use the retrieve-and-generate (RG) method with OpenAI's ada embedding, which was found to perform well in their study. To optimize the usage of the extended 16k context, we retrieve a maximum of 100 code segments, each comprising its file path and 10 lines of code. The maximum cross-file context was set to 12,800 tokens and the max generation token is 50 tokens following. Consistent with <ref type="bibr" target="#b45">Ding et al. (2023)</ref>, we use the uniform prompt formatting in the original implementation, with a temperature of 0.2 and top-p of 0.95 for all model generations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Table <ref type="table" target="#tab_25">18</ref> presents the evaluation results. We found that:</p><p>1. Across almost all dimensions, including model sizes, programming languages, and metrics, StarCoder2 consistently outperforms StarCoderBase. This enhancement could likely be attributed to better pre-training with increased context length and repository-level objectives (Section 5.1).</p><p>2. StarCoder2-15B achieves the state-of-the-art performance compared to models of similar sizes. For certain languages like Java and C#, the performance is better even than models with 2x capacity.</p><p>3. The analysis also reveals significant performance variances in different languages for the same model, similar to the findings in MultiPL-E ( §7.1.2). While a model can be strong overall, achieving uniformly high performance across all programming languages remains challenging, e.g., StarCoder2-15B is behind on TypeScript while StableCode-3B in C# and DeepSeekCoder-34B in Java. The disparity calls for future research on building models that can achieve high performance across diverse range of languages in different settings. Hyperparameters <ref type="bibr">Following Li et al. (2023)</ref>, we set the temperature to 0.2 and top-p to 0.95. Each model generates 25 samples per scenario, resulting in a total of 1,000 completions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We report results of selected models in</p><p>Table 19. Column Valid gives the percentage of solutions that were syntactically valid, and Column Insecure shows the percentage of valid solutions that include the vulnerability the scenario tests for. From the table, we draw the following conclusions: 1. StarCoder2 generates comparable numbers of valid programs to StarCoderBase, CodeLlama, and DeepSeekCoder. Both StarCoderBase and StarCoder2 models achieve around 90% valid program rate. However, after some manual inspection, we notice that StarCoder2 tends to generate more functionally correct code than StarCoderBase. The observation is aligned with the evaluation in previous sections. 2. Except for StarCoder2-3B, StarCoder2-7B and StarCoder2-15B have the highest insecure program rate among the models having similar parameters.</p><p>The high insecure rate might be a side-effect of its higher rate of valid and functionally correct completions. These generated programs are more likely to be exposed to potential vulnerabilities, as suggested by <ref type="bibr" target="#b15">Bhatt et al. (2023)</ref>. Notably, <ref type="bibr" target="#b71">Li et al. (2023)</ref> find that code-cushman-001, the initial model used in commercialized Copilot, has an insecure rate beyond 40%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.8">Measuring Harmful Generations</head><p>About the benchmarks Bias in Open-ended Language Generation Dataset (BOLD) <ref type="bibr" target="#b43">(Dhamala et al., 2021)</ref> is a dataset of 23,679 prompts that measure fairness across Religious Ideology, Procession, Race, Gender, and Political Ideology. We use the Regard classifier by <ref type="bibr" target="#b122">Sheng et al. (2019)</ref> and average the classifier scores across each category.</p><p>WinoBias <ref type="bibr" target="#b147">(Zhao et al., 2018)</ref> measures bias towards gender stereotypes across professions. When given a sentence regarding a profession, the gender is masked, and a language model is used to generate the replaced masked token and the perplexity is used to calculate the bias towards male and female pronouns.</p><p>Hurtful Sentence Completion in English Language Models (HONEST) <ref type="bibr" target="#b94">(Nozza et al., 2021</ref>) is a template-based corpus to assess the hurtfulness of sentence completions generated by the language models. To calculate the HONEST score, we check whether each generated completion has any terms contained in each of the categories within Hurtlex<ref type="foot" target="#foot_27">foot_27</ref> .</p><p>RealToxicityPrompts <ref type="bibr" target="#b50">(Gehman et al., 2020)</ref> consists of 100,000 naturally occurring, sentence-level prompts, which are extracted from the large web corpus of English text. They can be used to evaluate the risk of neural toxic degeneration in the language models. We use a 10,000 subset to perform the evaluation. We use the classifier by <ref type="bibr" target="#b139">Vidgen et al. (2021)</ref> to detect toxicity and report the average probability of the detected toxic output as our toxicity score.</p><p>Hyperparameters For each prompt in BOLD and RealToxicityPrompts, we generate one completion with up to 50 additional tokens. On HONEST, we generate 5 completions for each sample with up to 50 additional tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The results for BOLD, WinoBias, HONEST, and RealToxicityPrompts are presented in Tables <ref type="table" target="#tab_28">20,</ref> <ref type="table" target="#tab_29">21</ref>, 22, and 23, respectively. The tables suggest that our models LLMs that we consider produce roughly the same amount of harmful content, and based on <ref type="bibr" target="#b71">Li et al. (2023)</ref>, LLMs trained primarily on code produce less harmful content than LLMs trained on general web text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Search Index and Attribution Tools</head><p>Following the standard set by <ref type="bibr" target="#b71">Li et al. (2023)</ref> we build another suite of data inspection, attribution, and search tools. The NLP community has recognized the need for data inspection and has begun producing computational documentation artifacts to complement static data descriptions <ref type="bibr">(Piktus et al., 2023b;</ref><ref type="bibr" target="#b78">Marone &amp; Van Durme, 2023;</ref><ref type="bibr">Piktus et al., 2023a;</ref><ref type="bibr">Akiki et al., 2023, among others)</ref>. Open science and open data go beyond releasing dumps of datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Membership checking tools</head><p>This work collects and constructs a dataset 4 times larger than that used in StarCoderBase. Compared to the initial version of The Stack, the version here contains many additional non-code sources (see Table <ref type="table" target="#tab_5">4</ref>). As data sizes increase, it becomes even more important to construct tools that allow for accessible and efficient data inspection. We update the "Am I in the Stack" tool with repositories in  describe algorithms or solutions not present elsewhere. Content creators can use our system as a simple "no code" inspection tool to check if their material occurs verbatim in our data. It also enables a rapid first-pass attribution check for coding tools built on our models. <ref type="foot" target="#foot_30">33</ref> This system takes about 70GB, substantially smaller than the data, but provides only exact matches for long strings. If necessary, users can use the full search index for additional analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Search index</head><p>The preceding tools provide lightweight data inspection. However, it may be necessary to perform full-text searches that support fuzzy matching and retrieval. Following StarCoder1 <ref type="bibr" target="#b71">(Li et al., 2023)</ref>, we build an Elasticsearch index on the source code subset of The Stack v2 and make it available at <ref type="url" target="https://huggingface.co/spaces/bigcode/search-v2">https://huggingface.co/spaces/bigcode/search-v2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Social Impact and Limitations</head><p>Social impact and limitations have already been documented in the BigCode project <ref type="bibr" target="#b67">(Kocetkov et al., 2023;</ref><ref type="bibr" target="#b12">Ben Allal et al., 2023;</ref><ref type="bibr" target="#b71">Li et al., 2023;</ref><ref type="bibr">BigCode collaboration et al., 2023)</ref>. In the following sections, we cover our project approach towards the responsible development of large language models for code and highlight some more recent advances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1">Project Approach</head><p>Open-science StarCoder2 is the output of a community research project. The project is conducted in the spirit of Open Science <ref type="bibr" target="#b142">(Woelfle et al., 2011;</ref><ref type="bibr" target="#b80">Mendez et al., 2020)</ref>, focused on the responsible development and use of Code LLMs. Through open-governance practices, priority in decision-making has always yielded to the more responsible option, even if this meant introducing limitations that might impact adoption or future research (BigCode collaboration et al., 2023). Ethical data sourcing Significant efforts from the BigCode community went into the careful curation, validation, decontamination, malware removal, license filtering, opt-out process, PII removal, structuring, packaging, hosting, licensing, and the publishing of a Dataset Card (Project, 2024) for the data used to train StarCoder2. Full transparency has been provided about the data used for training StarCoder2. A significant portion of the training dataset was sourced under license from Software Heritage (Software Heritage, 2024a). Accelerating research BigCode's open approach to scientific collaboration (BigCode collaboration et al., 2023), open access model distribution and licensing (BigCode Project, 2023a; Malfa et al., 2023), and openness and disclosures of training data, architectures, and development are essential for the research community to have access to powerful, truly open LLMs, helping to accelerate future research <ref type="bibr" target="#b54">(Groeneveld et al., 2024;</ref><ref type="bibr" target="#b143">Xu et al., 2024;</ref><ref type="bibr" target="#b129">Soldaini et al., 2024;</ref><ref type="bibr" target="#b124">Singh et al., 2024;</ref><ref type="bibr" target="#b138">Üstün et al., 2024;</ref><ref type="bibr" target="#b76">Luukkonen et al., 2023;</ref><ref type="bibr" target="#b142">Woelfle et al., 2011)</ref>.</p><p>Open, but responsible The BigCode Open RAIL-M license (BigCode Project, 2023a) contains important use restrictions and is accompanied by an FAQ to help guide the responsible deployment and use of the model by downstream users (BigCode Project, 2023b).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Community of practice</head><p>BigCode is very much a community of practice, with over 1,200 multi-disciplinary members from more than 60 countries working towards the responsible development of large language models for code <ref type="bibr" target="#b123">(Sholler et al., 2019;</ref><ref type="bibr" target="#b67">Kocetkov et al., 2023;</ref><ref type="bibr" target="#b12">Ben Allal et al., 2023;</ref><ref type="bibr" target="#b71">Li et al., 2023;</ref><ref type="bibr">Muennighoff et al., 2024a;</ref><ref type="bibr" target="#b150">Zhuo et al., 2024)</ref>. Of these members, 417 were active in the BigCode community collaboration tools within the period 27 October 2023 through 24 February 2024, the period aligning with StarCoder2 development. There has also been considerable downstream adoption of BigCode outputs, with millions of downloads collectively reported via the Hugging Face API <ref type="bibr">(BigCode, 2024)</ref>.</p><p>Auditable The StarCoder2 model, pre-training dataset, and supporting artifacts are easily accessible and available to anyone who wishes to conduct an independent audit <ref type="bibr" target="#b128">(Solaiman, 2023;</ref><ref type="bibr" target="#b90">Mökander et al., 2023;</ref><ref type="bibr">BigCode collaboration et al., 2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2">Advancements in Code LLMs</head><p>Governance Card The BigCode Governance Card (BigCode collaboration et al., 2023) serves as an overview of the different mechanisms and areas of governance in the BigCode project. It aims to support transparency by providing relevant information about choices that were made during the project to the broader public and to serve as an example of intentional governance <ref type="bibr" target="#b123">(Sholler et al., 2019)</ref> of an open research project that future endeavors can leverage to shape their own approach. The first section, Project Structure, covers the project organization, its stated goals and values, its internal decision processes, and its funding and resources. The second section, Data and Model Governance, covers decisions relating to the questions of data subject consent, privacy, and model release.</p><p>Archival of software metadata: Software metadata is vital for the classification, curation, and sharing of free and open-source software (FOSS). The source code landscape is very diverse. By generating linked data and referencing source code contributions within the Software Heritage archive from the global community of developers and scientists <ref type="bibr">(Heritage, 2024)</ref>, there is potential to enable a more ethical data supply chain for training LLMs <ref type="bibr" target="#b35">(Cosmo &amp; Zacchiroli, 2017;</ref><ref type="bibr" target="#b0">Abramatic et al., 2018)</ref>.</p><p>Acceptable ML use: On October 19, 2023, Software Heritage published a statement that defines the acceptable machine learning use of the Software Heritage archive. This is a significant milestone that opens the door for more responsible data sourcing and licensing of AI training data (Software <ref type="bibr" target="#b125">Heritage, 2023)</ref>.</p><p>SoftWare Hash IDentifiers (SWHID): Software Heritage provides the SWHID unique identifiers, intrinsically bound to the software components, and that need no central registry, to ensure that a resilient web of knowledge can be built on top of the Software Heritage archive (The SWHID Specification <ref type="bibr" target="#b105">Project, 2024)</ref>. This can also be used by downstream developers to support efforts for those companies that prioritize a "software bill of materials" (SBOM) as a key building block in software security and software supply chain transparency and risk management (Cybersecurity &amp; Infrastructure Security Agency, 2024; <ref type="bibr" target="#b82">Mirakhorli et al., 2024)</ref>, for example by including the SWHIDs in the SBOM, alongside other relevant information such as component names, versions, licenses, and source locations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.3">Challenges and Risks</head><p>Openness and safety risks <ref type="bibr" target="#b128">Solaiman (2023)</ref> explains how the degree of openness in the LLM development process is connected to the potential risks associated with a model release. When systems are developed in a fully closed manner, it is more likely for power to become concentrated among high-resourced organizations, and the small development team may not fully comprehend the impact and long-term consequences of the model being deployed. In addition, closed-development systems are often less auditable by external experts and can impede scientific progress since researchers cannot build upon each other's work. On the other hand, fully open development allows for community research, democratizes access to the models, and enables audits throughout the whole development process. However, without appropriate guardrails, open LLM development poses a higher risk of misuse, as increased model access also increases the likelihood of harm caused by the model. Even though a released API can be shut down, once the model weights are released, it is nearly impossible to retract them. Discussing and implementing responsible AI practices has, therefore, been front and center during the development of our project's LLMs.</p><p>Privacy compliant generated code It is difficult to correctly identify and classify the different types of PII so that personal data processing, transformations, and flows through code can be evaluated <ref type="bibr" target="#b133">(Tang et al., 2023)</ref>. Where privacy-relevant methods are invoked in generated code, checking for PII leaks to the internet, use of encrypted data and anonymous IDs, will be necessary <ref type="bibr" target="#b134">(Tang &amp; Østvold, 2024)</ref>. Downstream users are advised to implement additional PII scanning, filtering, cleansing, and mitigation to ensure compliance with their intended use cases <ref type="bibr" target="#b145">(Yang et al., 2023;</ref><ref type="bibr" target="#b4">Albalak et al., 2024)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Security</head><p>As with any open scientific research that provides open access to model weights, hyper-parameters, data processing code, training code, training data, and documentation, any actor can run or fine-tune the optimized model with very low computing costs <ref type="bibr" target="#b53">(Governance AI, 2024)</ref>. Even with the use restrictions set forth within the BigCode Open RAIL-M license, this will not prevent bad actors with malicious intent from attempting to cause harm <ref type="bibr" target="#b84">(Mozes et al., 2023)</ref>. For example, code LLMs with API access could be used to create sophisticated polymorphic malware (CrowdStrike, 2024) that would be highly evasive to security products that rely on signature-based detection and will be able to bypass measures such as Anti-Malware Scanning Interface (AMSI) as it eventually executes and runs code <ref type="bibr" target="#b38">(CyberArk, 2024;</ref><ref type="bibr" target="#b58">Gupta et al., 2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Societal bias</head><p>As has been previously established in evaluations of coding models, code LLMs can generate code with a structure that reflects stereotypes about gender, race, emotion, class, the structure of names, and other characteristics <ref type="bibr" target="#b28">(Chen et al., 2021;</ref><ref type="bibr">Zhuo et al., 2023a)</ref>. Further evaluation and guardrail mitigations are required in the context of downstream use cases <ref type="bibr" target="#b63">(Huang et al., 2023;</ref><ref type="bibr" target="#b46">Dong et al., 2024)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Representation bias</head><p>As discussed in previous sections, there is a lot more data in the training dataset for popular programming languages like Python and Java than for niche languages like Haskell and Fortran.</p><p>As such, the model performs better on such high-resource languages, which may reinforce the preference of developers towards using such languages. Fortunately, there's much ongoing research on how to improve the performance of Code LLMs on low-resource languages <ref type="bibr">(Cassano et al., 2023a;</ref><ref type="bibr">Zhuo et al., 2023b)</ref>. Furthermore, the predominant natural language in source code and other datasets used is English although other languages are also present. As such, the model can generate code snippets provided some non-English context, but the generated code is not guaranteed to work as intended or equally as well for all languages. This could limit the model's fairness and effectiveness across different coding tasks and environments <ref type="bibr" target="#b5">(Alyafeai et al., 2024)</ref>.</p><p>Traceability Using the SWHID to trace software components is not an easy task and will challenge most if not all, downstream developers. Future development and advancement of tools that make it easier to trace software components will be necessary to enable more transparent and responsible data supply chains <ref type="bibr" target="#b36">(Cosmo et al., 2020)</ref>.</p><p>Job augmentation vs. automation Code LLMs serve as powerful foundation models that can be finetuned to generate high-quality code, documentation, unit tests, text summaries, automation workflows, and more. <ref type="bibr" target="#b29">Chen et al. (2023)</ref> find a positive correlation between occupation exposure and wage levels/experience premiums, suggesting higher-paying and experience-intensive jobs may face greater displacement risks from LLM-powered software. Goldman Sachs <ref type="bibr">(2024)</ref> suggest that AI has the potential to automate 25% of labor tasks in advanced economies and 10 -20% in emerging economies, however, they also state that "those fears should be counterbalanced, since AI has the potential to create new job tasks or categories requiring specialized human expertise". <ref type="bibr" target="#b9">Autor et al. (2022)</ref> reports that "Roughly 60% of employment in 2018 is found in job titles that did not exist in 1940." and that "augmentation innovations boost occupational labor demand, while automation innovations erode it". Results from the task-based analysis in (World Economic Forum, 2024) reveal that jobs with the highest potential for automation of tasks by LLMs emphasize routine and repetitive procedures and do not require a high degree of interpersonal communication. Jobs with the highest potential for augmentation by LLMs emphasize critical thinking and complex problem-solving skills, especially those in science, technology, engineering, and mathematics (STEM) fields. Ziegler et al. ( <ref type="formula">2024</ref>) reports the benefits of receiving AI suggestions while coding span the full range of typically investigated aspects of productivity, such as task time, product quality, cognitive load, enjoyment, and learning. In <ref type="bibr" target="#b100">(Peng et al., 2023)</ref>, a two-year collaboration between Google Core and Google Research (Brain Team), they find that of the 10k+ Google-internal developers using the code completion setup in their IDE, they measured user's code acceptance rate of 25-34%. Yahoo Finance (2024) announced ServiceNow, Inc. (NYSE: NOW) 2024 Q4 Earnings with coverage that the ServiceNow platform Now Assist skills using text-to-code (ServiceNow, 2024b) and text-to-workflow (ServiceNow, 2024a) LLMs (based on StarCoder), augment and increased developer productivity and speed of innovation by 52%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Conclusion</head><p>We introduced StarCoder2, a family of LLMs designed for code generation, along with The Stack v2, the largest pre-training corpus for Code LLMs built on the foundations of the Software Heritage archive. The Stack v2 is ten times larger than its predecessor, yielding a raw dataset of 67.5 TB. Through extensive cleaning, filtering, and subsampling of the source code, along with the incorporation of other high-quality code-related datasets, we created a training set of approximately 3TB (900B+ tokens). Leveraging this new dataset, we trained StarCoder2 models with 3B, 7B, and 15B parameters. Our extensive Code LLM evaluations, assessing code completion, editing, and reasoning capabilities, revealed that StarCoder2-3B and StarCoder2-15B are state-of-the-art models within their respective size classes. By not only releasing the model weights but also ensuring complete transparency regarding the training data, we hope to increase trust in the developed models and empower other engineering teams and scientists to build upon our efforts.</p><p>and Lingming Zhang were partially sponsored by the U.S. National Science Foundation award CCF-2131943. Federico Cassano was partly sponsored by Roblox. Albert Ziegler, Eirini Kalliamvakou, X. Alice Li, Andrew Rice, Devon Rifkin, Shawn Simister, Ganesh Sittampalam, and Edward Aftandilian. Measuring GitHub Copilot's impact on productivity. Commun. ACM, 67(3):54-63, feb 2024. ISSN 0001-0782. doi: 10.1145/3633453. URL <ref type="url" target="https://doi.org/10.1145/3633453">https://doi.org/10.1145/3633453</ref>. (cited on pp. 2 and 39) x11 <ref type="bibr">-dsc, x11-hanson, x11-lucent-variant, x11-oar, x11-opengl, x11-quarterdeck, x11-realmode, x11-sg, x11stanford, x11-tektronix, x11-x11r5, x11-xconsortium-veillard, xfree86-1.0, xmldb-1.0, xxd, yale-cas, yensdesign, zeusbench, zpl-1.0, zsh, zuora-software, zveno-research}</ref> Non-licenses The following contributor license agreements, warranty disclaimers, and other license amendments were not considered during license labeling: LicenseRef-scancode-{dco-1.1, generic-cla, google-cla, jetty-ccla-1.1, newton-king-cla, generic-exception, generic-export-compliance, generic-tos, generic-trademark, warranty-disclaimer}</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Pull Requests</head><p>Table <ref type="table" target="#tab_5">24</ref> shows the volume of PR renderings for various sequence lengths (measured in characters). We list the volume of the base files for the top 20 languages in Table <ref type="table" target="#tab_9">25</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.6 StackOverflow</head><p>We used the following prompt to</p><p>Below is an instruction from a user and a candidate's answer. Evaluate whether or not the answer is a good example of how AI Assistant should respond to the user's instruction. Please assign a score using the following 10-point scale:</p><p>1: The response is entirely off-topic, contains significant inaccuracies, or is incomprehensible. It fails to address the user's query in any meaningful way.</p><p>2: The answer is largely irrelevant, vague, or controversial. It contains some elements that relate to the topic but misses the core of the user's question or includes substantial misinformation.</p><p>3: The response is somewhat relevant but remains incomplete or contains elements that are off-topic or controversial. Key aspects of the user's query are left unaddressed.</p><p>4: The answer addresses the user's question to some extent but lacks depth or clarity. It may be somewhat helpful but is not comprehensive or detailed.</p><p>5: The response is relevant and offers a basic answer to the user's question but lacks detail or specificity. It's helpful but not fully developed or insightful.</p><p>6: The answer is moderately helpful and addresses most aspects of the user's question. It might lack some depth or contain minor inaccuracies or irrelevant information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7:</head><p>The response is quite helpful and addresses the user's query well, but it might not be from an AI Assistant's perspective. It could resemble content from other sources like blog posts or web pages.</p><p>8: The answer is comprehensive and relevant, written from an AI assistant's perspective. It addresses the user's query effectively but may have minor areas for improvement in focus, conciseness, or organization. 9: The response is almost perfect, providing a clear, comprehensive, and well-organized answer from an AI assistant's perspective. It might have very minor areas for improvement in terms of engagement or insight.</p><p>10: The answer is exemplary, perfectly addressing the user's query from an AI Assistant's perspective. It is highly informative, expertly written, engaging, and insightful, with no discernible areas for improvement.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><figDesc>, have adopted a fully open development approach by releasing training data, training frameworks, and evaluation suites. The BigCode project was established in September 2022 as an open scientific collaboration focused on the open and responsible development of Code LLMs. BigCode is stewarded by ServiceNow and Hugging Face in the spirit of open governance</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: File-level license assignment logic.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The distribution of the top 20 programming languages in our crawled documentation collection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Listing 3 :</head><label>3</label><figDesc>Abbreviated sample problem from CanItEditall the elements of this group""" -return torch.tensor([0., np.pi/2, np.pi, 3*np.pi/2]) + d = np.pi / 4 + return torch.tensor([0., d, d*2, d*3, d*4, d*5, d*6, d*7])Code Editing Instruction: Edit the C4 class and its methods to represent the C8 group.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>A comparison of The Stack v1 and v2 on 32 popular programming languages. We show the size and number of files for different data splits: The Stack v1 deduped, The Stack v2 deduped, and the training data used for StarCoder2-15B.</figDesc><table><row><cell>The-stack-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>The websites scraped for the code documentation dataset.</figDesc><table><row><cell>Website Name</cell><cell>URL</cell></row><row><cell>DevDocs API Documentation</cell><cell>https://devdocs.io</cell></row><row><cell>MDN Web Docs</cell><cell>https://developer.mozilla.org</cell></row><row><cell>TensorFlow Docs</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Overview of the data processing steps applied to each data source.</figDesc><table><row><cell>Dataset</cell><cell cols="5">Dedup Malicious Code Decontaminate Opt-out PII</cell></row><row><cell>Source Code</cell><cell>Yes</cell><cell>Yes</cell><cell>Yes</cell><cell>Yes</cell><cell>StarPII</cell></row><row><cell>Pull Requests</cell><cell>Yes</cell><cell>Yes</cell><cell>Yes</cell><cell>Yes</cell><cell>StarPII + Usernames</cell></row><row><cell cols="2">Jupyter/Kaggle Notebooks Yes</cell><cell>Yes</cell><cell>Yes</cell><cell>Yes/No</cell><cell>StarPII</cell></row><row><cell>Issues</cell><cell>Yes</cell><cell>Yes</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Similar to StarCoderBase, we adhere to the natural distribution of the data as much as possible. Before constructing the source code datasets, we examined the data distribution among Overview of the data composition of StarCoder2 models. We refer to the training set of the 3B model as the-stack-v2-train-3B.</figDesc><table><row><cell></cell><cell>Dataset</cell><cell>Tokens (B)</cell><cell>3B</cell><cell>7B</cell><cell>15B</cell></row><row><cell></cell><cell cols="2">the-stack-v2-train-smol 525.5</cell><cell>✓</cell><cell>✓</cell><cell>✗</cell></row><row><cell></cell><cell cols="2">the-stack-v2-train-full 775.48</cell><cell>✗</cell><cell>✗</cell><cell>✓</cell></row><row><cell></cell><cell>Pull requests</cell><cell>19.54</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell></row><row><cell>the-stack-v2-train-extras</cell><cell>Issues Jupyter structured Jupyter scripts Kaggle scripts Documentation OpenWebMath Wikipedia StackOverflow Arxiv LHQ Intermediate Repr.</cell><cell>11.06 14.74 16.29 1.68 1.6 14.42 6.12 10.26 30.26 5.78 6</cell><cell>✓ ✓ ✓ ✓ ✓ ✗ ✗ ✓ ✗ ✓ ✓</cell><cell>✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓</cell><cell>✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓</cell></row><row><cell></cell><cell>Unique tokens (B)</cell><cell></cell><cell>622.09</cell><cell>658.58</cell><cell>913.23</cell></row></table><note><p>the programming languages. Compared to StarCoderBase, we found slightly larger variations among the high-resource languages. The observed data volume (in GB) is as follows: Java (479.68), JavaScript (277.25),C++ (204.49), Python (190.99)</p><p>,PHP (171.57), C# (166.22), and C (114.49)</p><p>. We decided to downsample both Java and Javascript to 200GB to put these high-resource languages on a more equal footing. Furthermore, we</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Overview of the sentinel tokens.</figDesc><table><row><cell>Token</cell><cell>Description</cell></row><row><cell>&lt;|endoftext|&gt;</cell><cell>end of text/sequence</cell></row><row><cell>&lt;fim_prefix&gt;</cell><cell>FIM prefix</cell></row><row><cell>&lt;fim_middle&gt;</cell><cell>FIM middle</cell></row><row><cell>&lt;fim_suffix&gt;</cell><cell>FIM suffix</cell></row><row><cell>&lt;fim_pad&gt;</cell><cell>FIM pad</cell></row><row><cell>&lt;repo_name&gt;</cell><cell>repository name</cell></row><row><cell>&lt;file_sep&gt;</cell><cell>file separator</cell></row><row><cell>&lt;issue_start&gt;</cell><cell>start of GitHub issue</cell></row><row><cell>&lt;issue_comment&gt;</cell><cell>start of GitHub issue comment</cell></row><row><cell>&lt;issue_closed&gt;</cell><cell>GitHub issue closed event</cell></row><row><cell>&lt;jupyter_start&gt;</cell><cell>start of Jupyter notebook</cell></row><row><cell>&lt;jupyter_text&gt;</cell><cell>start of Jupyter text cell</cell></row></table><note><p>&lt;jupyter_code&gt; start of Jupyter code cell &lt;jupyter_output&gt; start of Jupyter output cell &lt;jupyter_script&gt; start of Jupyter script (converted kaggle notebook) &lt;empty_output&gt; output cell without content &lt;code_to_intermediate&gt; translate source code to intermediate representation &lt;intermediate_to_code&gt; translate intermediate representation to source code &lt;pr&gt; start of pull request &lt;pr_status&gt; status of pull request &lt;pr_is_merged&gt; whether pr is merged &lt;pr_base&gt; start of list of base files &lt;pr_file&gt; path of pull request file &lt;pr_base_code&gt; code that is part of the base commit in the PR &lt;pr_diff&gt; start of a diff &lt;pr_diff_hunk&gt; diff hunk &lt;pr_comment&gt; general comment &lt;pr_event_id&gt; GitHub id of review comment or code review comment &lt;pr_review&gt; start of review &lt;pr_review_state&gt; review state (e.g. approved, rejected) &lt;pr_review_comment&gt; code review comment &lt;pr_in_reply_to_review_id&gt;</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc>Model architecture details of the StarCoder2 models.</figDesc><table><row><cell>Parameter</cell><cell cols="3">StarCoder2-3B StarCoder2-7B StarCoder2-15B</cell></row><row><cell>hidden_dim</cell><cell>3072</cell><cell>4608</cell><cell>6144</cell></row><row><cell>n_heads</cell><cell>24</cell><cell>36</cell><cell>48</cell></row><row><cell>n_kv_heads</cell><cell>2</cell><cell>4</cell><cell>4</cell></row><row><cell>n_layers</cell><cell>30</cell><cell>32</cell><cell>40</cell></row><row><cell>vocab size</cell><cell>49152</cell><cell>49152</cell><cell>49152</cell></row><row><cell>seq_len</cell><cell cols="3">base-4k/long-16k base-4k/long-16k base-4k/long-16k</cell></row><row><cell cols="2">positional encodings RoPE</cell><cell>RoPE</cell><cell>RoPE</cell></row><row><cell>FLOPs 23</cell><cell>5.94e+22</cell><cell>1.55e+23</cell><cell>3.87e+23</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc>Training details of StarCoder2 base models.</figDesc><table><row><cell>Model</cell><cell cols="6">learning rate RoPE θ batch size n iterations n tokens n epochs</cell></row><row><cell>StarCoder2-3B</cell><cell>3 × 10 -4</cell><cell>1e5</cell><cell>2.6M</cell><cell>1.2M</cell><cell>3.1T</cell><cell>4.98</cell></row><row><cell>StarCoder2-7B</cell><cell>3 × 10 -4</cell><cell>1e5</cell><cell>3.5M</cell><cell>1M</cell><cell>3.5T</cell><cell>5.31</cell></row><row><cell>StarCoder2-15B</cell><cell>3 × 10 -4</cell><cell>1e4</cell><cell>4.1M</cell><cell>1M</cell><cell>4.1T</cell><cell>4.49</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 8 :</head><label>8</label><figDesc>Training details for the long context training of StarCoder2 models.</figDesc><table><row><cell>Model</cell><cell cols="5">learning rate RoPE θ batch size n iterations n tokens</cell></row><row><cell>StarCoder2-3B</cell><cell>3 × 10 -5</cell><cell>1e6</cell><cell>2.6M</cell><cell>80k</cell><cell>200B</cell></row><row><cell>StarCoder2-7B</cell><cell>2 × 10 -5</cell><cell>1e6</cell><cell>3.5M</cell><cell>56k</cell><cell>200B</cell></row><row><cell>StarCoder2-15B</cell><cell>3 × 10 -5</cell><cell>1e5</cell><cell>4.1M</cell><cell>50k</cell><cell>200B</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 9 :</head><label>9</label><figDesc>Pass@1 on HumanEval(+) and MBPP(+). These results were generated using greedy decoding.</figDesc><table><row><cell>Model</cell><cell cols="4">HumanEval HumanEval+ MBPP MBPP+</cell></row><row><cell>StarCoderBase-3B</cell><cell>21.3</cell><cell>17.1</cell><cell>42.6</cell><cell>35.8</cell></row><row><cell>DeepSeekCoder-1.3B</cell><cell>28.7</cell><cell>23.8</cell><cell>55.4</cell><cell>46.9</cell></row><row><cell>StableCode-3B</cell><cell>28.7</cell><cell>24.4</cell><cell>53.1</cell><cell>43.1</cell></row><row><cell>StarCoder2-3B</cell><cell>31.7</cell><cell>27.4</cell><cell>57.4</cell><cell>47.4</cell></row><row><cell>StarCoderBase-7B</cell><cell>30.5</cell><cell>25.0</cell><cell>47.4</cell><cell>39.6</cell></row><row><cell>CodeLlama-7B</cell><cell>33.5</cell><cell>25.6</cell><cell>52.1</cell><cell>41.6</cell></row><row><cell>DeepSeekCoder-6.7B</cell><cell>47.6</cell><cell>39.6</cell><cell>70.2</cell><cell>56.6</cell></row><row><cell>StarCoder2-7B</cell><cell>35.4</cell><cell>29.9</cell><cell>54.4</cell><cell>45.6</cell></row><row><cell>StarCoderBase-15B</cell><cell>29.3</cell><cell>25.6</cell><cell>50.6</cell><cell>43.6</cell></row><row><cell>CodeLlama-13B</cell><cell>37.8</cell><cell>32.3</cell><cell>62.4</cell><cell>52.4</cell></row><row><cell>StarCoder2-15B</cell><cell>46.3</cell><cell>37.8</cell><cell>66.2</cell><cell>53.1</cell></row><row><cell>CodeLlama-34B</cell><cell>48.2</cell><cell>44.3</cell><cell>65.4</cell><cell>52.4</cell></row><row><cell>DeepSeekCoder-33B</cell><cell>54.3</cell><cell>46.3</cell><cell>73.2</cell><cell>59.1</cell></row></table><note><p>400W</p><p>). Total emissions are estimated to be 14,995.33 kgCO 2 eq. The long-context fine-tuning stage adds 1,111.68 kgCO 2 eq, resulting in a total of 16,107.01 kgCO 2 eq.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 10 :</head><label>10</label><figDesc>Pass@1 results on MultiPL-E averaged over 50 samples for each problem. All models are evaluated at temperature 0.2 and top-p 0.95.</figDesc><table><row><cell>Model</cell><cell cols="2">C++ C#</cell><cell>D</cell><cell>Go</cell><cell>Java</cell><cell cols="2">Julia JavaScript</cell><cell>Lua</cell><cell>PHP</cell></row><row><cell>StableCode-3B</cell><cell>28.4</cell><cell>14.4</cell><cell>13.4</cell><cell>19.3</cell><cell>27.8</cell><cell>20.6</cell><cell>32.0</cell><cell>17.1</cell><cell>23.7</cell></row><row><cell cols="2">DeepSeekCoder-1.3B 28.3</cell><cell>21.3</cell><cell>10.4</cell><cell>19.1</cell><cell>29.2</cell><cell>15.0</cell><cell>28.3</cell><cell>19.2</cell><cell>23.2</cell></row><row><cell cols="2">StarCoderBase-3B 19.4</cell><cell>13.3</cell><cell>5.0</cell><cell>13.3</cell><cell>19.2</cell><cell>16.1</cell><cell>21.3</cell><cell>18.0</cell><cell>18.6</cell></row><row><cell>StarCoder2-3B</cell><cell>27.2</cell><cell>20.5</cell><cell>12.6</cell><cell>23.6</cell><cell>27.4</cell><cell>19.9</cell><cell>35.4</cell><cell>28.0</cell><cell>27.6</cell></row><row><cell>CodeLlama-7B</cell><cell>26.4</cell><cell>21.0</cell><cell>11.6</cell><cell>20.9</cell><cell>28.2</cell><cell>25.9</cell><cell>31.6</cell><cell>30.4</cell><cell>25.1</cell></row><row><cell cols="2">DeepSeekCoder-6.7B 46.7</cell><cell>32.9</cell><cell>18.4</cell><cell>31.0</cell><cell>39.7</cell><cell>31.4</cell><cell>46.6</cell><cell>34.2</cell><cell>32.6</cell></row><row><cell cols="2">StarCoderBase-7B 23.3</cell><cell>19.3</cell><cell>8.1</cell><cell>19.6</cell><cell>24.4</cell><cell>21.8</cell><cell>27.4</cell><cell>23.4</cell><cell>22.1</cell></row><row><cell>StarCoder2-7B</cell><cell>33.6</cell><cell>20.7</cell><cell>15.1</cell><cell>20.2</cell><cell>29.4</cell><cell>20.4</cell><cell>35.4</cell><cell>30.7</cell><cell>30.6</cell></row><row><cell>CodeLlama-13B</cell><cell>37.4</cell><cell>24.8</cell><cell>15.5</cell><cell>26.6</cell><cell>37.5</cell><cell>27.9</cell><cell>39.3</cell><cell>31.6</cell><cell>33.9</cell></row><row><cell cols="2">StarCoderBase-15B 30.6</cell><cell>20.6</cell><cell>10.0</cell><cell>21.5</cell><cell>28.5</cell><cell>21.1</cell><cell>31.7</cell><cell>26.6</cell><cell>26.8</cell></row><row><cell>StarCoder2-15B</cell><cell>41.4</cell><cell>29.2</cell><cell>23.6</cell><cell>26.2</cell><cell>33.9</cell><cell>33.2</cell><cell>44.2</cell><cell>43.8</cell><cell>39.5</cell></row><row><cell>CodeLlama-34B</cell><cell>41.4</cell><cell>30.7</cell><cell>15.3</cell><cell>28.7</cell><cell>40.2</cell><cell>31.4</cell><cell>41.7</cell><cell>37.5</cell><cell>40.4</cell></row><row><cell cols="2">DeepSeekCoder-33B 51.2</cell><cell>35.3</cell><cell>17.4</cell><cell>34.2</cell><cell>43.8</cell><cell>32.8</cell><cell>51.3</cell><cell>36.5</cell><cell>41.8</cell></row><row><cell>Model</cell><cell>Perl</cell><cell>R</cell><cell cols="4">Ruby Racket Rust Scala</cell><cell>Bash</cell><cell cols="2">Swift TypeScript</cell></row><row><cell>StableCode-3B</cell><cell>9.4</cell><cell>11.5</cell><cell>0.8</cell><cell>7.0</cell><cell>22.9</cell><cell>5.9</cell><cell>8.6</cell><cell>13.2</cell><cell>29.6</cell></row><row><cell cols="2">DeepSeekCoder-1.3B 12.5</cell><cell>9.8</cell><cell>24.6</cell><cell>9.1</cell><cell>18.6</cell><cell>19.6</cell><cell>9.7</cell><cell>11.0</cell><cell>27.4</cell></row><row><cell cols="2">StarCoderBase-3B 11.3</cell><cell>10.1</cell><cell>4.2</cell><cell>7.9</cell><cell>16.3</cell><cell>16.8</cell><cell>3.8</cell><cell>10.0</cell><cell>22.8</cell></row><row><cell>StarCoder2-3B</cell><cell>13.6</cell><cell>14.2</cell><cell>31.3</cell><cell>7.8</cell><cell>24.5</cell><cell>18.9</cell><cell>12.3</cell><cell>25.1</cell><cell>34.4</cell></row><row><cell>CodeLlama-7B</cell><cell>16.9</cell><cell>14.9</cell><cell>29.5</cell><cell>11.4</cell><cell>25.5</cell><cell>22.8</cell><cell>9.6</cell><cell>24.9</cell><cell>33.4</cell></row><row><cell cols="2">DeepSeekCoder-6.7B 30.4</cell><cell>20.5</cell><cell>46.2</cell><cell>17.4</cell><cell>37.7</cell><cell>35.2</cell><cell>22.2</cell><cell>30.3</cell><cell>39.5</cell></row><row><cell cols="2">StarCoderBase-7B 15.2</cell><cell>14.5</cell><cell>19.6</cell><cell>11.1</cell><cell>22.6</cell><cell>20.9</cell><cell>7.3</cell><cell>15.1</cell><cell>27.5</cell></row><row><cell>StarCoder2-7B</cell><cell>16.6</cell><cell>16.7</cell><cell>28.3</cell><cell>11.6</cell><cell>29.6</cell><cell>19.5</cell><cell>12.2</cell><cell>26.1</cell><cell>36.3</cell></row><row><cell>CodeLlama-13B</cell><cell>23.4</cell><cell>14.1</cell><cell>31.9</cell><cell>13.0</cell><cell>31.0</cell><cell>29.7</cell><cell>13.3</cell><cell>30.1</cell><cell>40.1</cell></row><row><cell cols="2">StarCoderBase-15B 16.3</cell><cell>10.2</cell><cell>17.2</cell><cell>11.8</cell><cell>24.5</cell><cell>28.8</cell><cell>11.0</cell><cell>16.7</cell><cell>32.1</cell></row><row><cell>StarCoder2-15B</cell><cell>37.2</cell><cell>19.8</cell><cell>41.5</cell><cell>22.4</cell><cell>38.0</cell><cell>37.4</cell><cell>18.9</cell><cell>34.2</cell><cell>43.8</cell></row><row><cell>CodeLlama-34B</cell><cell>28.5</cell><cell>22.7</cell><cell>37.8</cell><cell>16.9</cell><cell>38.7</cell><cell>36.7</cell><cell>16.4</cell><cell>35.3</cell><cell>42.1</cell></row><row><cell cols="2">DeepSeekCoder-33B 31.0</cell><cell>20.5</cell><cell>44.0</cell><cell>23.4</cell><cell>43.8</cell><cell>43.9</cell><cell>28.7</cell><cell>35.8</cell><cell>48.4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 11 :</head><label>11</label><figDesc>Performance of open-access models on DS-1000. Benchmarks are as follows. All models were evaluated at temperature 0.2 and top-p 0.95. Scores reflect mean pass@1 accuracy averaged over 40 samples.</figDesc><table><row><cell>Format</cell><cell>Model</cell><cell>M a t p l o t l i b</cell><cell>N</cell><cell>u m P y</cell><cell>P a n d a s</cell><cell>P y T o r c h</cell><cell>S c i P y</cell><cell>S c i k i t -L e a r n</cell><cell cols="2">T e n s o r F l o w Overall</cell></row><row><cell></cell><cell># problems:</cell><cell>155</cell><cell cols="2">220</cell><cell>291</cell><cell>68</cell><cell>106</cell><cell>115</cell><cell>45</cell><cell>1,000</cell></row><row><cell cols="2">Completion StarCoderBase-3B</cell><cell>32.1</cell><cell cols="2">16.8</cell><cell>5.3</cell><cell>9.2</cell><cell>13.2</cell><cell>10.5</cell><cell>17.2</cell><cell>14.2</cell></row><row><cell cols="2">Completion StableCode-3B</cell><cell>42.5</cell><cell cols="2">24.5</cell><cell>16.2</cell><cell>15.4</cell><cell>13.5</cell><cell>20.2</cell><cell>27.7</cell><cell>22.7</cell></row><row><cell cols="2">Completion DeepSeekCoder-1.3B</cell><cell>36.2</cell><cell cols="2">18.8</cell><cell>9.1</cell><cell>10.7</cell><cell>7.9</cell><cell>13.9</cell><cell>13.3</cell><cell>16.2</cell></row><row><cell cols="2">Completion StarCoder2-3B</cell><cell>45.5</cell><cell cols="2">27.7</cell><cell>16.2</cell><cell>12.9</cell><cell>15.8</cell><cell>30.8</cell><cell>22.8</cell><cell>25.0</cell></row><row><cell cols="2">Completion StarCoderBase-7B</cell><cell>38.0</cell><cell cols="2">23.0</cell><cell>8.2</cell><cell>13.1</cell><cell>13.7</cell><cell>24.5</cell><cell>14.6</cell><cell>19.1</cell></row><row><cell cols="2">Completion DeepSeekCoder-6.7B</cell><cell>52.4</cell><cell cols="2">33.0</cell><cell>20.0</cell><cell>13.9</cell><cell>19.8</cell><cell>29.7</cell><cell>27.4</cell><cell>28.9</cell></row><row><cell cols="2">Completion CodeLlama-7B</cell><cell>46.3</cell><cell cols="2">21.6</cell><cell>13.9</cell><cell>12.2</cell><cell>17.5</cell><cell>16.7</cell><cell>20.6</cell><cell>21.5</cell></row><row><cell cols="2">Completion StarCoder2-7B</cell><cell>53.6</cell><cell cols="2">33.3</cell><cell>16.9</cell><cell>16.2</cell><cell>20.6</cell><cell>22.2</cell><cell>31.9</cell><cell>27.8</cell></row><row><cell cols="2">Completion StarCoderBase-15B</cell><cell>47.0</cell><cell cols="2">27.1</cell><cell>10.1</cell><cell>19.5</cell><cell>21.7</cell><cell>27.0</cell><cell>20.5</cell><cell>23.8</cell></row><row><cell cols="2">Completion CodeLlama-13B</cell><cell>49.0</cell><cell cols="2">27.2</cell><cell>17.4</cell><cell>12.9</cell><cell>15.6</cell><cell>24.0</cell><cell>24.8</cell><cell>25.1</cell></row><row><cell cols="2">Completion StarCoder2-15B</cell><cell>60.3</cell><cell cols="2">43.3</cell><cell>23.2</cell><cell>11.0</cell><cell>26.4</cell><cell>26.0</cell><cell>36.0</cell><cell>33.8</cell></row><row><cell cols="2">Completion DeepSeekCoder-33B</cell><cell>56.1</cell><cell cols="2">49.6</cell><cell>25.8</cell><cell>36.8</cell><cell>36.8</cell><cell>40.0</cell><cell>46.7</cell><cell>40.2</cell></row><row><cell cols="2">Completion CodeLlama-34B</cell><cell>50.3</cell><cell cols="2">42.7</cell><cell>23.0</cell><cell>25.0</cell><cell>28.3</cell><cell>33.9</cell><cell>40.0</cell><cell>34.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 12 :</head><label>12</label><figDesc>Pass@1 performance on HumanEvalFix. StarCoder2 and StarCoderBase are not instruction-tuned thus they are at a disadvantage compared to the other models which are all instruction-tuned.</figDesc><table><row><cell>Model</cell><cell cols="4">Prompt Python JavaScript Java</cell><cell>Go</cell><cell cols="3">C++ Rust Avg.</cell></row><row><cell>StarCoderBase-15B</cell><cell>Instruct</cell><cell>12.6</cell><cell>16.8</cell><cell>18.9</cell><cell>12.5</cell><cell>11.2</cell><cell>0.6</cell><cell>12.1</cell></row><row><cell>StarCoderBase-15B</cell><cell>Commit</cell><cell>25.6</cell><cell>29.4</cell><cell>28.8</cell><cell>28.7</cell><cell>28.2</cell><cell>19.7</cell><cell>26.7</cell></row><row><cell>CodeLlama-13B-Instruct</cell><cell>Instruct</cell><cell>19.4</cell><cell>18.9</cell><cell>24.1</cell><cell>21.6</cell><cell>10.1</cell><cell>0.4</cell><cell>15.8</cell></row><row><cell>CodeLlama-34B-Instruct</cell><cell>Instruct</cell><cell>36.5</cell><cell>28.1</cell><cell>36.4</cell><cell>25.7</cell><cell>25.2</cell><cell>18.5</cell><cell>28.4</cell></row><row><cell>DeepSeekCoder-6.7B-Instruct</cell><cell>Instruct</cell><cell>44.9</cell><cell>55.3</cell><cell>52.2</cell><cell>42.9</cell><cell>37.9</cell><cell>19.5</cell><cell>42.1</cell></row><row><cell>DeepSeekCoder-33B-Instruct</cell><cell>Instruct</cell><cell>47.5</cell><cell>47.6</cell><cell>46.5</cell><cell>52.0</cell><cell>48.0</cell><cell>10.2</cell><cell>42.1</cell></row><row><cell>OctoCoder-15B</cell><cell>Instruct</cell><cell>30.4</cell><cell>28.4</cell><cell>30.6</cell><cell>30.2</cell><cell>26.1</cell><cell>16.5</cell><cell>27.0</cell></row><row><cell>StarCoder2-15B</cell><cell>Instruct</cell><cell>9.7</cell><cell>20.7</cell><cell>24.1</cell><cell>36.3</cell><cell>25.6</cell><cell>15.4</cell><cell>22.0</cell></row><row><cell>StarCoder2-15B</cell><cell>Issue</cell><cell>48.6</cell><cell>41.6</cell><cell>48.4</cell><cell>48.5</cell><cell>20.7</cell><cell>24.2</cell><cell>38.7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 15 :</head><label>15</label><figDesc>Accuracy on the CRUXEval benchmark.</figDesc><table><row><cell>Model</cell><cell cols="2">CRUXEval-I</cell><cell cols="2">CRUXEval-O</cell></row><row><cell></cell><cell cols="4">Pass@1 Pass@5 Pass@1 Pass@5</cell></row><row><cell>StarCoderBase-3B</cell><cell>27.1</cell><cell>43.7</cell><cell>27.4</cell><cell>40.9</cell></row><row><cell>DeepSeekCoder-1.3B</cell><cell>27.8</cell><cell>44.7</cell><cell>31.0</cell><cell>43.4</cell></row><row><cell>StableCode-3B</cell><cell>33.5</cell><cell>53.3</cell><cell>26.7</cell><cell>43.5</cell></row><row><cell>StarCoder2-3B</cell><cell>32.7</cell><cell>50.1</cell><cell>34.2</cell><cell>48.4</cell></row><row><cell>StarCoderBase-7B</cell><cell>29.7</cell><cell>47.3</cell><cell>32.2</cell><cell>44.9</cell></row><row><cell>CodeLlama-7B</cell><cell>35.9</cell><cell>52.9</cell><cell>34.2</cell><cell>48.4</cell></row><row><cell>DeepSeekCoder-6.7B</cell><cell>41.9</cell><cell>62.7</cell><cell>43.5</cell><cell>54.8</cell></row><row><cell>StarCoder2-7B</cell><cell>34.6</cell><cell>53.5</cell><cell>36.0</cell><cell>52.0</cell></row><row><cell>StarCoderBase-15B</cell><cell>31.3</cell><cell>49.2</cell><cell>34.2</cell><cell>47.1</cell></row><row><cell>CodeLlama-13B</cell><cell>42.5</cell><cell>62.0</cell><cell>39.7</cell><cell>53.9</cell></row><row><cell>StarCoder2-15B</cell><cell>48.1</cell><cell>66.9</cell><cell>47.1</cell><cell>59.5</cell></row><row><cell>CodeLlama-34B</cell><cell>47.2</cell><cell>66.6</cell><cell>42.4</cell><cell>55.9</cell></row><row><cell>DeepSeekCoder-33B</cell><cell>46.5</cell><cell>64.9</cell><cell>48.6</cell><cell>61.6</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 16 :</head><label>16</label><figDesc>Exact-match on FIM-task<ref type="bibr" target="#b12">(Ben Allal et al., 2023)</ref>. Due to an implementation bug, FIM was incorrect for most of the training of StarCoder2-15B. CodeLlama results are from<ref type="bibr" target="#b111">Rozière et al. (2023)</ref>.</figDesc><table><row><cell>Model</cell><cell cols="3">Java JavaScript Python</cell></row><row><cell>StableCode-3B</cell><cell>63.7</cell><cell>73.3</cell><cell>59.1</cell></row><row><cell>StarCoder2-3B</cell><cell>75.0</cell><cell>73.0</cell><cell>59.1</cell></row><row><cell>StarCoder2-7B</cell><cell>81.1</cell><cell>77.5</cell><cell>61.1</cell></row><row><cell>CodeLlama-13B</cell><cell>80.0</cell><cell>85.0</cell><cell>74.5</cell></row><row><cell>StarCoderBase-15B</cell><cell>73</cell><cell>74</cell><cell>62</cell></row><row><cell>StarCoder2-15B</cell><cell>60.5</cell><cell>54.7</cell><cell>48.4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>Table 17 :</head><label>17</label><figDesc>Average exact match (EM), edit similarity (ES), and CodeBLEU (CB) scores for open-access base models on RepoBench v1.1(Liu et al., 2023b).</figDesc><table><row><cell>Model</cell><cell></cell><cell>Python</cell><cell></cell><cell></cell><cell>Java</cell><cell></cell></row><row><cell></cell><cell>EM</cell><cell>ES</cell><cell>CB</cell><cell>EM</cell><cell>ES</cell><cell>CB</cell></row><row><cell>StarCoderBase-3B</cell><cell>29.99</cell><cell>69.37</cell><cell>36.77</cell><cell>36.01</cell><cell>74.18</cell><cell>45.30</cell></row><row><cell cols="2">DeepSeekCoder-1.3B 31.02</cell><cell>70.07</cell><cell>37.88</cell><cell>37.75</cell><cell>75.66</cell><cell>46.69</cell></row><row><cell>StableCode-3B</cell><cell cols="6">34.48 71.79 40.43 40.13 76.56 49.00</cell></row><row><cell>StarCoder2-3B</cell><cell>32.47</cell><cell>71.19</cell><cell>39.25</cell><cell>38.46</cell><cell>76.53</cell><cell>47.96</cell></row><row><cell>StarCoderBase-7B</cell><cell>32.70</cell><cell>71.08</cell><cell>39.48</cell><cell>37.97</cell><cell>75.66</cell><cell>47.47</cell></row><row><cell>CodeLlama-7B</cell><cell>33.85</cell><cell>71.79</cell><cell>40.47</cell><cell>39.61</cell><cell>76.71</cell><cell>48.92</cell></row><row><cell cols="7">DeepSeekCoder-6.7B 36.79 73.85 42.65 42.87 78.93 51.69</cell></row><row><cell>StarCoder2-7B</cell><cell>33.72</cell><cell>72.07</cell><cell>40.34</cell><cell>39.84</cell><cell>77.23</cell><cell>48.96</cell></row><row><cell>StarCoderBase-15B</cell><cell>33.51</cell><cell>71.64</cell><cell>40.39</cell><cell>39.34</cell><cell>76.24</cell><cell>48.36</cell></row><row><cell>CodeLlama-13B</cell><cell>35.50</cell><cell>72.98</cell><cell>42.02</cell><cell>41.27</cell><cell>77.57</cell><cell>50.26</cell></row><row><cell>StarCoder2-15B</cell><cell cols="6">36.99 74.08 43.25 42.57 79.05 51.45</cell></row><row><cell>CodeLlama-34B</cell><cell>37.22</cell><cell>73.77</cell><cell>43.38</cell><cell>42.35</cell><cell>78.22</cell><cell>50.99</cell></row><row><cell cols="2">DeepSeekCoder-33B 39</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_25"><head>Table 18 :</head><label>18</label><figDesc>CrossCodeEval<ref type="bibr" target="#b45">(Ding et al., 2023)</ref> evaluation results. We report Code Match (Edit Similarity) and Identifier Match (F1) results for four languages.</figDesc><table><row><cell></cell><cell cols="2">Python</cell><cell>Java</cell><cell></cell><cell cols="2">TypeScript</cell><cell>C#</cell><cell></cell></row><row><cell>Model</cell><cell cols="8">Code ES ID F1 Code ES ID F1 Code ES ID F1 Code ES ID F1</cell></row><row><cell>StarCoderBase-3B</cell><cell>69.47</cell><cell>62.56</cell><cell>66.43</cell><cell>59.77</cell><cell>41.42</cell><cell>35.26</cell><cell>70.11</cell><cell>53.15</cell></row><row><cell>DeepSeekCoder-1.3B</cell><cell>72.41</cell><cell>66.76</cell><cell>65.92</cell><cell>59.93</cell><cell>63.59</cell><cell>56.41</cell><cell>70.98</cell><cell>54.84</cell></row><row><cell>StableCode-3B</cell><cell>76.00</cell><cell>70.75</cell><cell>73.19</cell><cell>67.93</cell><cell>65.61</cell><cell>59.61</cell><cell>61.70</cell><cell>48.98</cell></row><row><cell>StarCoder2-3B</cell><cell>73.01</cell><cell>67.85</cell><cell>66.31</cell><cell>61.06</cell><cell>38.79</cell><cell>35.17</cell><cell>70.86</cell><cell>55.42</cell></row><row><cell>StarCoderBase-7B</cell><cell>72.24</cell><cell>65.40</cell><cell>69.91</cell><cell>64.12</cell><cell>44.21</cell><cell>39.77</cell><cell>71.93</cell><cell>55.98</cell></row><row><cell>DeepSeekCoder-6.7B</cell><cell>77.43</cell><cell>73.16</cell><cell>70.60</cell><cell>66.28</cell><cell>69.08</cell><cell>63.61</cell><cell>74.84</cell><cell>62.29</cell></row><row><cell>CodeLlama-7B</cell><cell>74.52</cell><cell>69.11</cell><cell>71.49</cell><cell>65.99</cell><cell>65.96</cell><cell>59.46</cell><cell>71.41</cell><cell>56.66</cell></row><row><cell>StarCoder2-7B</cell><cell>74.52</cell><cell>68.81</cell><cell>70.75</cell><cell>65.27</cell><cell>43.19</cell><cell>38.84</cell><cell>72.73</cell><cell>57.69</cell></row><row><cell>StarCoderBase-15B</cell><cell>73.43</cell><cell>66.74</cell><cell>70.58</cell><cell>64.66</cell><cell>45.24</cell><cell>40.47</cell><cell>71.77</cell><cell>55.71</cell></row><row><cell>CodeLlama-13B</cell><cell>75.88</cell><cell>70.97</cell><cell>73.08</cell><cell>68.29</cell><cell>67.88</cell><cell>61.46</cell><cell>72.73</cell><cell>59.62</cell></row><row><cell>StarCoder2-15B</cell><cell>78.72</cell><cell>74.27</cell><cell>74.92</cell><cell>70.45</cell><cell>48.63</cell><cell>43.78</cell><cell>75.38</cell><cell>62.14</cell></row><row><cell>CodeLlama-34B</cell><cell>76.34</cell><cell>71.36</cell><cell>74.30</cell><cell>69.45</cell><cell>68.98</cell><cell>63.19</cell><cell>73.96</cell><cell>60.07</cell></row><row><cell>DeepSeekCoder-33B</cell><cell>78.78</cell><cell>74.51</cell><cell>73.41</cell><cell>69.02</cell><cell>70.31</cell><cell>65.14</cell><cell>75.04</cell><cell>63.03</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_26"><head>Table 19 :</head><label>19</label><figDesc>Performance on the "Asleep at the Keyboard" benchmark.Asleep at the Keyboard" is a benchmark designed for assessing security vulnerabilities in code generation<ref type="bibr" target="#b98">(Pearce et al., 2022)</ref>. Similar to<ref type="bibr" target="#b71">Li et al. (2023)</ref>, we focus on the subset of tasks amenable to automated evaluation, which is the Diversity of Weakness problems. These cover 18 diverse vulnerability classes from the MITRE Common Weakness Enumeration (CWE) taxonomy, with scenarios drawn from the 2021 CWE Top 25 Most Dangerous Software Weaknesses list published by MITRE. The problems have 23 scenarios in C and 17 scenarios in Python.</figDesc><table><row><cell>Model</cell><cell>Valid (↑)</cell><cell>Insecure (↓)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_28"><head>Table 20 :</head><label>20</label><figDesc>BOLD evaluations of open source code models.This tool allows for data inspection at the username and repository level.<ref type="bibr" target="#b78">Marone &amp; Van Durme (2023)</ref> recommend releasing a documentation artifact called a Data Portrait to support lightweight membership inspection. We implement one using Bloom filters to enable matching on file contents, crucially including the non-code sources like documentation, textbooks, and papers. 32 These prose data sources may</figDesc><table><row><cell>Model</cell><cell>Category</cell><cell cols="4">Negative Score Neutral Score Other Score Positive Score</cell></row><row><cell></cell><cell>Religious Ideology</cell><cell>0.16</cell><cell>0.33</cell><cell>0.13</cell><cell>0.38</cell></row><row><cell></cell><cell>Profession</cell><cell>0.07</cell><cell>0.6</cell><cell>0.06</cell><cell>0.27</cell></row><row><cell>StarCoder2-3B</cell><cell>Race</cell><cell>0.05</cell><cell>0.5</cell><cell>0.05</cell><cell>0.5</cell></row><row><cell></cell><cell>Gender</cell><cell>0.05</cell><cell>0.48</cell><cell>0.05</cell><cell>0.43</cell></row><row><cell></cell><cell>Political Ideology</cell><cell>0.3</cell><cell>0.29</cell><cell>0.18</cell><cell>0.23</cell></row><row><cell></cell><cell>Religious Ideology</cell><cell>0.12</cell><cell>0.32</cell><cell>0.12</cell><cell>0.45</cell></row><row><cell></cell><cell>Profession</cell><cell>0.07</cell><cell>0.58</cell><cell>0.06</cell><cell>0.3</cell></row><row><cell>StarCoderBase-3B</cell><cell>Race</cell><cell>0.04</cell><cell>0.44</cell><cell>0.05</cell><cell>0.47</cell></row><row><cell></cell><cell>Gender</cell><cell>0.04</cell><cell>0.35</cell><cell>0.05</cell><cell>0.55</cell></row><row><cell></cell><cell>Political Ideology</cell><cell>0.3</cell><cell>0.27</cell><cell>0.18</cell><cell>0.25</cell></row><row><cell></cell><cell>Religious Ideology</cell><cell>0.18</cell><cell>0.25</cell><cell>0.16</cell><cell>0.41</cell></row><row><cell></cell><cell>Profession</cell><cell>0.08</cell><cell>0.57</cell><cell>0.06</cell><cell>0.28</cell></row><row><cell>StableCode-3B</cell><cell>Race</cell><cell>0.07</cell><cell>0.4</cell><cell>0.06</cell><cell>0.46</cell></row><row><cell></cell><cell>Gender</cell><cell>0.05</cell><cell>0.36</cell><cell>0.06</cell><cell>0.53</cell></row><row><cell></cell><cell>Political Ideology</cell><cell>0.32</cell><cell>0.27</cell><cell>0.18</cell><cell>0.25</cell></row><row><cell></cell><cell>Religious Ideology</cell><cell>0.19</cell><cell>0.81</cell><cell>0.03</cell><cell>0.13</cell></row><row><cell></cell><cell>Profession</cell><cell>0.08</cell><cell>0.52</cell><cell>0.07</cell><cell>0.33</cell></row><row><cell>StarCoder2-7B</cell><cell>Race</cell><cell>0.06</cell><cell>0.4</cell><cell>0.07</cell><cell>0.47</cell></row><row><cell></cell><cell>Gender</cell><cell>0.06</cell><cell>0.37</cell><cell>0.07</cell><cell>0.5</cell></row><row><cell></cell><cell>Political Ideology</cell><cell>0.33</cell><cell>0.22</cell><cell>0.21</cell><cell>0.24</cell></row><row><cell></cell><cell>Religious Ideology</cell><cell>0.16</cell><cell>0.28</cell><cell>0.13</cell><cell>0.43</cell></row><row><cell></cell><cell>Profession</cell><cell>0.07</cell><cell>0.56</cell><cell>0.06</cell><cell>0.31</cell></row><row><cell>StarCoderBase-7B</cell><cell>Race</cell><cell>0.05</cell><cell>0.41</cell><cell>0.06</cell><cell>0.48</cell></row><row><cell></cell><cell>Gender</cell><cell>0.04</cell><cell>0.33</cell><cell>0.06</cell><cell>0.57</cell></row><row><cell></cell><cell>Political Ideology</cell><cell>0.33</cell><cell>0.23</cell><cell>0.19</cell><cell>0.25</cell></row><row><cell></cell><cell>Religious Ideology</cell><cell>0.16</cell><cell>0.27</cell><cell>0.14</cell><cell>0.43</cell></row><row><cell></cell><cell>Profession</cell><cell>0.07</cell><cell>0.58</cell><cell>0.06</cell><cell>0.3</cell></row><row><cell>CodeLlama-7B</cell><cell>Race</cell><cell>0.06</cell><cell>0.42</cell><cell>0.06</cell><cell>0.46</cell></row><row><cell></cell><cell>Gender</cell><cell>0.05</cell><cell>0.38</cell><cell>0.06</cell><cell>0.5</cell></row><row><cell></cell><cell>Political Ideology</cell><cell>0.3</cell><cell>0.28</cell><cell>0.19</cell><cell>0.24</cell></row><row><cell></cell><cell>Religious Ideology</cell><cell>0.15</cell><cell>0.33</cell><cell>0.13</cell><cell>0.39</cell></row><row><cell></cell><cell>Profession</cell><cell>0.07</cell><cell>0.61</cell><cell>0.06</cell><cell>0.27</cell></row><row><cell>DeepSeekCoder-6.7B</cell><cell>Race</cell><cell>0.05</cell><cell>0.46</cell><cell>0.05</cell><cell>0.44</cell></row><row><cell></cell><cell>Gender</cell><cell>0.04</cell><cell>0.34</cell><cell>0.06</cell><cell>0.56</cell></row><row><cell></cell><cell>Political Ideology</cell><cell>0.3</cell><cell>0.28</cell><cell>0.19</cell><cell>0.23</cell></row><row><cell></cell><cell>Religious Ideology</cell><cell>0.21</cell><cell>0.22</cell><cell>0.16</cell><cell>0.42</cell></row><row><cell></cell><cell>Profession</cell><cell>0.09</cell><cell>0.51</cell><cell>0.07</cell><cell>0.33</cell></row><row><cell>StarCoder2-15B</cell><cell>Race</cell><cell>0.07</cell><cell>0.39</cell><cell>0.07</cell><cell>0.47</cell></row><row><cell></cell><cell>Gender</cell><cell>0.05</cell><cell>0.36</cell><cell>0.07</cell><cell>0.53</cell></row><row><cell></cell><cell>Political Ideology</cell><cell>0.25</cell><cell>0.02</cell><cell>0.1</cell><cell>0.09</cell></row><row><cell></cell><cell>Religious Ideology</cell><cell>0.16</cell><cell>0.31</cell><cell>0.13</cell><cell>0.41</cell></row><row><cell></cell><cell>Profession</cell><cell>0.07</cell><cell>0.61</cell><cell>0.06</cell><cell>0.26</cell></row><row><cell>StarCoderBase-15B</cell><cell>Race</cell><cell>0.06</cell><cell>0.46</cell><cell>0.06</cell><cell>0.43</cell></row><row><cell></cell><cell>Gender</cell><cell>0.04</cell><cell>0.38</cell><cell>0.06</cell><cell>0.53</cell></row><row><cell></cell><cell>Political Ideology</cell><cell>0.32</cell><cell>0.28</cell><cell>0.19</cell><cell>0.22</cell></row><row><cell></cell><cell>Religious Ideology</cell><cell>0.17</cell><cell>0.24</cell><cell>0.14</cell><cell>0.45</cell></row><row><cell></cell><cell>Profession</cell><cell>0.07</cell><cell>0.54</cell><cell>0.06</cell><cell>0.33</cell></row><row><cell>CodeLlama-13B</cell><cell>Race</cell><cell>0.07</cell><cell>0.36</cell><cell>0.07</cell><cell>0.5</cell></row><row><cell></cell><cell>Gender</cell><cell>0.05</cell><cell>0.35</cell><cell>0.06</cell><cell>0.53</cell></row><row><cell></cell><cell>Political Ideology</cell><cell>0.3</cell><cell>0.23</cell><cell>0.19</cell><cell>0.28</cell></row><row><cell>new dataset. 31</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_29"><head>Table 21 :</head><label>21</label><figDesc>WinoBias evaluations of open source code models.</figDesc><table><row><cell>Model</cell><cell cols="3">Male Female Average</cell></row><row><cell>StarCoder2-3B</cell><cell>0.33</cell><cell>-0.33</cell><cell>0.27</cell></row><row><cell>StarCoderBase-3B</cell><cell>0.42</cell><cell>-0.42</cell><cell>0.28</cell></row><row><cell>StableCode-3B</cell><cell>0.44</cell><cell>-0.44</cell><cell>0.39</cell></row><row><cell>StarCoder2-7B</cell><cell>0.45</cell><cell>-0.45</cell><cell>0.34</cell></row><row><cell>StarCoderBase-7B</cell><cell>0.51</cell><cell>-0.51</cell><cell>0.31</cell></row><row><cell>CodeLlama-7B</cell><cell>0.37</cell><cell>-0.37</cell><cell>0.38</cell></row><row><cell>DeepSeekCoder-6.7B</cell><cell>0.41</cell><cell>-0.41</cell><cell>0.34</cell></row><row><cell>StarCoder2-15B</cell><cell>0.36</cell><cell>-0.36</cell><cell>0.38</cell></row><row><cell>StarCoderBase-15B</cell><cell>0.55</cell><cell>-0.55</cell><cell>0.35</cell></row><row><cell>CodeLlama-13B</cell><cell>0.36</cell><cell>-0.36</cell><cell>0.37</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_30"><head>Table 22 :</head><label>22</label><figDesc>HONEST evaluations.</figDesc><table><row><cell>Model</cell><cell>Score</cell></row><row><cell>StarCoder2-3B</cell><cell>0.11</cell></row><row><cell>StarCoderBase-3B</cell><cell>0.11</cell></row><row><cell>StableCode-3B</cell><cell>0.09</cell></row><row><cell>StarCoder2-7B</cell><cell>0.1</cell></row><row><cell>StarCoderBase-7B</cell><cell>0.11</cell></row><row><cell>CodeLlama-7B</cell><cell>0.11</cell></row><row><cell>DeepSeekCoder-6.7B</cell><cell>0.1</cell></row><row><cell>StarCoder2-15B</cell><cell>0.11</cell></row><row><cell>StarCoderBase-15B</cell><cell>0.1</cell></row><row><cell>CodeLlama-13B</cell><cell>0.1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_31"><head>Table 23 :</head><label>23</label><figDesc>Toxicity score evaluation of open source code models.</figDesc><table><row><cell>Model</cell><cell>Toxicity Score</cell></row><row><cell>StarCoder2-3B</cell><cell>0.05</cell></row><row><cell>StarCoderBase-3B</cell><cell>0.04</cell></row><row><cell>StableCode-3B</cell><cell>0.05</cell></row><row><cell>StarCoder2-7B</cell><cell>0.08</cell></row><row><cell>StarCoderBase-7B</cell><cell>0.04</cell></row><row><cell>CodeLlama-7B</cell><cell>0.04</cell></row><row><cell>DeepSeekCoder-6.7B</cell><cell>0.05</cell></row><row><cell>StarCoder2-15B</cell><cell>0.05</cell></row><row><cell>StarCoderBase-15B</cell><cell>0.04</cell></row><row><cell>CodeLlama-13B</cell><cell>0.04</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>System Package Data Exchange, https://spdx.dev.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>https://jupytext.readthedocs.io/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2"><p>https://guesslang.readthedocs.io/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3"><p>https://www.kaggle.com/datasets/kaggle/meta-kaggle-code</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4"><p>https://github.com/jalan/pdftotext</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_5"><p>https://github.com/adbar/trafilatura</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_6"><p>https://github.com/yoeo/guesslang</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_7"><p>https://llvm.org/ProjectsWithLLVM/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_8"><p>https://clang.llvm.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_9"><p>https://docs.exaloop.io/codon</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_10"><p>https://www.rust-lang.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_11"><p>https://go.googlesource.com/gollvm/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_12"><p>https://www.haskell.org/ghc/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16" xml:id="foot_13"><p>https://wiki.dlang.org/LDC</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="17" xml:id="foot_14"><p>https://flang.llvm.org/docs/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="18" xml:id="foot_15"><p>https://github.com/arnetheduck/nlvm</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="19" xml:id="foot_16"><p>Leandro's High-Quality dataset</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="20" xml:id="foot_17"><p>https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="21" xml:id="foot_18"><p>https://x.com/BigCodeProject/status/1721583097580249254?s=20</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="22" xml:id="foot_19"><p>We take the union of file line changes in all commits</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="23" xml:id="foot_20"><p>Estimated with 6ND, where N is the number of parameters and D is the number of training tokens. Includes base and long-context training.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="24" xml:id="foot_21"><p>https://huggingface.co/datasets/bigcode/the-stack-march-sample-special-tokens-stripped</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="25" xml:id="foot_22"><p>Note that EvalPlus omits a few ill-formed and noisy problems from the MBPP dataset. It uses 399 out of the 427 problems from the MBPP subset that was sanitized by the original authors<ref type="bibr" target="#b8">(Austin et al., 2021)</ref>. For HumanEval, we kept all 164 problems from the original dataset.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="26" xml:id="foot_23"><p>MultiPL-E makes some small changes to the HumanEval prompts, and a few prompts fail to translate to certain languages. We refer the reader toCassano et al. (2023b)  for more information.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="27" xml:id="foot_24"><p>The original problem includes additional methods to edit in the C4 class and a descriptive instruction.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="28" xml:id="foot_25"><p>https://huggingface.co/datasets/tianyang/repobench_python_v1.1</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="29" xml:id="foot_26"><p>https://huggingface.co/datasets/tianyang/repobench_java_v1.1</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="30" xml:id="foot_27"><p>https://github.com/valeriobasile/hurtlex</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="31" xml:id="foot_28"><p>https://huggingface.co/spaces/bigcode/in-the-stack</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="32" xml:id="foot_29"><p>https://stack-v2.dataportraits.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="33" xml:id="foot_30"><p>https://github.com/huggingface/llm-vscode</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="11">Acknowledgements</head><p>This work was made possible by <rs type="funder">Software Heritage</rs>, the great library of source code: <ref type="url" target="https://www.softwareheritage.org">https:// www.softwareheritage.org</ref>, and all the developers and scientists that contribute to the open source archives.</p><p>We thank <rs type="person">Joydeep Biswas</rs> (<rs type="affiliation">UT Austin</rs>), <rs type="funder">Northeastern Research Computing</rs>, and <rs type="funder">NCSA Delta</rs> for providing computing resources used for evaluation. <rs type="person">Carolyn Jane Anderson</rs> and <rs type="person">Arjun Guha</rs> were partially sponsored by the <rs type="funder">U.S. National Science Foundation</rs> awards <rs type="grantNumber">SES-2326173</rs> and <rs type="grantNumber">SES-2326174</rs>. <rs type="person">Jiawei Liu</rs>, <rs type="person">Yuxiang Wei</rs>, We thank <rs type="person">Jenny Hui, ServiceNow</rs>, for her leadership in executing the <rs type="institution">StarCoder2 Research Collaboration Agreement between ServiceNow</rs>, <rs type="person">Hugging Face</rs>, and <rs type="institution">NVIDIA</rs> to enable the training of all 3 models. We thank the extended members of the <rs type="institution">BigCode community</rs> for the ongoing support and for their downstream contributions back to the community.</p><p>We also thank <rs type="person">Hessie Jones</rs> and the <rs type="institution">Privacy Protection Collab</rs> that shared insights and lessons learned from their work in Defining Personal Information and the Remediation Framework during early exploration and consideration of PII redaction.</p><p><rs type="person">Evgenii Zheltonozhskii</rs> is supported by the <rs type="programName">Adams Fellowships Program</rs> of the <rs type="institution">Israel Academy of Sciences and Humanities</rs>.</p></div>
			</div>
			<div type="funding">
<div><p><rs type="projectName">Yes Yes StarPII + Usernames Docs Yes No No No StarPII: Names, Keys, Emails LHQ No No No No No Arxiv No No No No Email OpenWebMath No No Yes No StarPII: Names, Keys, Emails Wikipedia No No No No No StackExchange No No Yes No StarPII + Usernames</rs></p><p>to the first iteration of StarCoder <ref type="bibr" target="#b71">(Li et al., 2023)</ref>, we further enhance the recall of the decontamination process by removing whitespace during string matching. Note that we exclude docs, LHQ, arXiv, and <rs type="person">Wikipedia</rs> from this decontamination step.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_hrARGwH">
					<idno type="grant-number">SES-2326173</idno>
				</org>
				<org type="funding" xml:id="_fJW4e2t">
					<idno type="grant-number">SES-2326174</idno>
				</org>
				<org type="funding" xml:id="_ybKumCy">
					<orgName type="program" subtype="full">Adams Fellowships Program</orgName>
				</org>
				<org type="funded-project" xml:id="_44Js8Hm">
					<orgName type="project" subtype="full">Yes Yes StarPII + Usernames Docs Yes No No No StarPII: Names, Keys, Emails LHQ No No No No No Arxiv No No No No Email OpenWebMath No No Yes No StarPII: Names, Keys, Emails Wikipedia No No No No No StackExchange No No Yes No StarPII + Usernames</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Table <ref type="table">13</ref>: Performance of instructional code editing on the CanItEdit benchmark <ref type="bibr" target="#b26">(Cassano et al., 2024)</ref>. The results for non-StarCoder2 models are from the benchmark paper. Hyperparameters We evaluate all sizes of StarCoder2 on the CanItEdit benchmark using the Issue prompt format (introduced in §7.2.1) and compare its performance with other models previously assessed on this benchmark. Following <ref type="bibr" target="#b26">Cassano et al. (2024)</ref>, we employ random sampling with a temperature of 0.2 and a top-p of 0.95, with 100 completions per problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The results appear in Table <ref type="table">13</ref>. As described in §7.2.1, we use an "Issue" prompt and "Commit" prompt for the StarCoder2 and StarCoderBase models since they are not instruction-tuned. For all the other models, we use instruction-tuned versions. From the table, we make the following observations:</p><p>1. Of the small models, StarCoder2-3B comes in second place behind DeepSeekCoder-Instruct-1.3B.</p><p>2. Of the medium models, StarCoder2-7B and DeepSeekCoder-Instruct-6.7B each performs best at descriptive and lazy instructions respectively.</p><p>3. StarCoder2-15B is the best-performing large model by a significant margin.</p><p>4. StarCoder2-15B outperforms CodeLlama-Instruct-34B as well.</p><p>These results give further evidence that the StarCoder2 "Issue" format is a viable alternative to the StarCoderBase "Commit" format.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Math Reasoning</head><p>About the benchmark We use the widely studied GSM8K benchmark <ref type="bibr" target="#b33">(Cobbe et al., 2021)</ref>, a set of middle-school math problems, to evaluate the mathematical reasoning capabilities of the models. We use the PAL approach proposed by <ref type="bibr" target="#b49">Gao et al. (2023)</ref>: the model is prompted to generate a Python program, which is executed to produce the answer to the problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyperparameters</head><p>We evaluate models with greedy decoding in an 8-shot setting following <ref type="bibr" target="#b30">Chowdhery et al. (2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The results on GSM8K with PAL appear in Table <ref type="table">14</ref> and we make the following observations:</p><p>1. StableCode-3B is the best-performing small model. StarCoder2-3B is in second place. 4. In fact, StarCoder2-15B even outperforms CodeLlama-34B and DeepSeekCoder-33B which are more than twice its size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">CRUXEval: Code Reasoning, Understanding, and Execution</head><p>About the benchmark CRUXEval <ref type="bibr" target="#b56">(Gu et al., 2024</ref>) is a two-part benchmark consisting of 800 samples designed to evaluate code reasoning, understanding, and execution. In the first task, CRUXEval-I, the model is asked to predict any input such that executing a given Python function on that input produces a given output. In the second task, CRUXEval-O, the model is asked to simulate the execution of a given function on an input and predict an output. Two samples are shown below in Listings 4 and 5. The functions and inputs of the benchmark were generated by CodeLlama-34B and then filtered to remove complicated functions such as those requiring complex arithmetic or a large number of execution steps. # input prediction, CRUXEval-I assert f(??) == <ref type="bibr">[2,</ref><ref type="bibr">6,</ref><ref type="bibr" target="#b61">1,</ref><ref type="bibr">3,</ref><ref type="bibr" target="#b61">1,</ref><ref type="bibr">6,</ref><ref type="bibr">3,</ref><ref type="bibr">6,</ref><ref type="bibr">6]</ref> Hyperparameters Following <ref type="bibr" target="#b56">(Gu et al., 2024)</ref>, we use temperature 0.2 to report pass@1 and temperature 0.8 to report pass@5, both using 10 samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We show the pass@1 and pass@5 scores for both tasks in our benchmark in Table <ref type="table">15</ref>. In terms of error and standard deviation, the original paper reports two sources of noise. First, the noise due to sampling from the language model for the given set of 800 candidates is around 0.2% for 10 samples. Second, the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Data Curation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Excluded Extensions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>0.9</head><p>Please write "Score: &lt;rating&gt;" in the last line, and then provide a brief reasoning you used to derive the rating score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.7 Kaggle Notebooks templates</head><p>We remove the following templates if they appear at the beginning of a Kaggle notebook: TEMPLATE_1 = '# It is defined by the kaggle/python Docker image: <ref type="url" target="https://github.com/kaggle/docker-">https://github.com/kaggle/docker-</ref>python import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) # Input data files are available in the read-only "../input/" directory # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory import os for dirname, _, filenames in os.walk("/kaggle/input"):</p><p>for filename in filenames: print(os.path.join(dirname, filename)) # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save &amp; Run All" # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session' TEMPLATE_2 = '# It is defined by the kaggle/python Docker image: <ref type="url" target="https://github.com/kaggle/docker-">https://github.com/kaggle/docker-</ref>python\n' </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 TheStackV2-train-full</head><p>In Table <ref type="table">28</ref>, we summarize the data volume for the subsamples languages. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Asleep at the Keyboard&quot; Security Benchmark References</title>
		<author>
			<persName><forename type="first">Jean-François</forename><surname>Abramatic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cosmo</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Zacchiroli</surname></persName>
		</author>
		<idno type="DOI">10.1145/3183558</idno>
		<ptr target="https://cacm.acm.org/magazines/2018/10/231366-building-the-universal-archive-of-source-code/fulltext" />
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3" to="37" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Building the universal archive of source code</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">GQA: Training generalized multi-query transformer models from multi-head checkpoints</title>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Ainslie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Lee-Thorp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michiel</forename><surname>De Jong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yury</forename><surname>Zemlyanskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Federico</forename><surname>Lebron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Sanghai</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.emnlp-main.298</idno>
		<ptr target="https://aclanthology.org/2023.emnlp-main.298" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">Houda</forename><surname>Bouamor</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Juan</forename><surname>Pino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kalika</forename><surname>Bali</surname></persName>
		</editor>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023-12">December 2023</date>
			<biblScope unit="page">20</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">BigScience: a case study in the social construction of a multilingual large language model</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giada</forename><surname>Pistilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margot</forename><surname>Mieskes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Gallé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suzana</forename><surname>Ilic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum" />
	</analytic>
	<monogr>
		<title level="m">Workshop on Broadening Research Collaborations 2022</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>id= 2e346l2PPOm</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Spacerini: Plug-and-play search engines with pyserini and Hugging Face</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Odunayo</forename><surname>Ogundepo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akintunde</forename><surname>Oladipo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.emnlp-demo.12</idno>
		<ptr target="https://aclanthology.org/2023.emnlp-demo.12" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<editor>
			<persName><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Els</forename><surname>Lefever</surname></persName>
		</editor>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023-12">December 2023</date>
			<biblScope unit="page">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A survey on data selection for language models</title>
		<author>
			<persName><forename type="first">Alon</forename><surname>Albalak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanai</forename><surname>Elazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sang</forename><surname>Michael Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shayne</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bairu</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liangming</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haewon</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsunori</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2402.16827" />
		<imprint>
			<date type="published" when="2024-02">February 2024</date>
			<biblScope unit="page">38</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">CIDAR: culturally relevant instruction dataset for Arabic</title>
		<author>
			<persName><forename type="first">Zaid</forename><surname>Alyafeai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khalid</forename><surname>Almubarak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Ashraf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deema</forename><surname>Alnuhait</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saied</forename><surname>Alshahrani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Q</forename><surname>Gubran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gamil</forename><surname>Abdulrahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qais</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zead</forename><surname>Gawah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mustafa</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yousef</forename><surname>Ghaleb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maged</forename><forename type="middle">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><surname>Al-Shaibani</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2402.03177" />
		<imprint>
			<date type="published" when="2024-02">February 2024</date>
			<biblScope unit="page">39</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Naveen</forename><surname>Arivazhagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur</forename><surname>Bapna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Lepikhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxim</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mia</forename><surname>Xu Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wolfgang</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1907.05019" />
		<title level="m">Massively multilingual neural machine translation in the wild: Findings and challenges</title>
		<imprint>
			<date type="published" when="2019-07">July 2019</date>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName><surname>Arxiv</surname></persName>
		</author>
		<ptr target="https://info.arxiv.org/help/bulk_data_s3.html" />
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Program synthesis with large language models</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henryk</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carrie</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Terry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2108.07732" />
		<imprint>
			<date type="published" when="2021-08">August 2021</date>
			<biblScope unit="page" from="3" to="23" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">New frontiers: The origins and content of new work</title>
		<author>
			<persName><forename type="first">David</forename><surname>Autor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caroline</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><forename type="middle">M</forename><surname>Salomons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Seegmiller</surname></persName>
		</author>
		<idno>30389</idno>
		<ptr target="http://www.nber.org/papers/w30389" />
	</analytic>
	<monogr>
		<title level="j">National Bureau of Economic Research</title>
		<imprint>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="2022-08">August 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Llemma: An open language model for mathematics</title>
		<author>
			<persName><forename type="first">Zhangir</forename><surname>Azerbayev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hailey</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keiran</forename><surname>Paster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><forename type="middle">Dos</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">Marcus</forename><surname>Mcaleer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><forename type="middle">Q</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Welleck</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=4WnqRR915j" />
	</analytic>
	<monogr>
		<title level="m">The Twelfth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Efficient training of language models to fill in the middle</title>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolas</forename><surname>Tezak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christine</forename><surname>Mcleavey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2207.14255" />
		<imprint>
			<date type="published" when="2022-07">July 2022</date>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Big code models leaderboard</title>
		<author>
			<persName><forename type="first">Loubna</forename><surname>Ben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allal</forename></persName>
		</author>
		<ptr target="https://huggingface.co/spaces/bigcode/bigcode-models-leaderboard" />
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A framework for the evaluation of code generation models</title>
		<author>
			<persName><forename type="first">Loubna</forename><surname>Ben Allal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Logesh</forename><surname>Kumar Umapathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Lipkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leandro</forename><surname>Von</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Werra</forename></persName>
		</author>
		<ptr target="https://github.com/bigcode-project/bigcode-evaluation-harness" />
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Arjun Guha, Harm de Vries, and Leandro von Werra. SantaCoder: don&apos;t reach for the stars! arXiv preprint</title>
		<author>
			<persName><forename type="first">Loubna</forename><surname>Ben Allal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raymond</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denis</forename><surname>Kocetkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenghao</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Munoz Ferrandis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mayank</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manan</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Logesh</forename><surname>Kumar Umapathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carolyn</forename><forename type="middle">Jane</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangtian</forename><surname>Zi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><forename type="middle">Lamy</forename><surname>Poirier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hailey</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Troshin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Abulkhanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Lappert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><forename type="middle">De</forename><surname>Toni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernardo</forename><surname>García Del Río</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shamik</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Urvashi</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Terry</forename><surname>Yue Zhuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paulo</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Zocca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sourab</forename><surname>Mangrulkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lansky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huu</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danish</forename><surname>Contractor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Villa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Fried</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2301.03988" />
		<imprint>
			<date type="published" when="2023-08">August 2023</date>
		</imprint>
	</monogr>
	<note>cited on pp. 2, 13, 30, 31, 36, and 37</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Purple llama CyberSecEval: A secure coding benchmark for language models</title>
		<author>
			<persName><forename type="first">Manish</forename><surname>Bhatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sahana</forename><surname>Chennabasappa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cyrus</forename><surname>Nikolaidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengye</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Evtimov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Gabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faizan</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cornelius</forename><surname>Aschermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lorenzo</forename><surname>Fontana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasha</forename><surname>Frolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravi</forename><surname>Prakash Giri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhaval</forename><surname>Kapil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiannis</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Leblanc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Milazzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandar</forename><surname>Straumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varun</forename><surname>Vontimitta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Spencer</forename><surname>Whitman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Saxe</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2312.04724" />
		<imprint>
			<date type="published" when="2023-12">December 2023</date>
			<biblScope unit="page">34</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Lintang Sutawika, and Oskar Van Der Wal. Pythia: A suite for analyzing large language models across training and scaling</title>
		<author>
			<persName><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hailey</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><forename type="middle">Gregory</forename><surname>Anthony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Herbie</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O'</forename><surname>Kyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Brien</surname></persName>
		</author>
		<author>
			<persName><surname>Hallahan</surname></persName>
		</author>
		<idno>PMLR</idno>
		<ptr target="https://proceedings.mlr.press/v202/biderman23a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">Andreas</forename><surname>Krause</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Emma</forename><surname>Brunskill</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Barbara</forename><surname>Engelhardt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Sivan</forename><surname>Sabato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jonathan</forename><surname>Scarlett</surname></persName>
		</editor>
		<meeting>the 40th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2023-07">Jul 2023</date>
			<biblScope unit="volume">202</biblScope>
			<biblScope unit="page" from="23" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Models by BigCode on Hugging Face</title>
		<author>
			<persName><surname>Bigcode</surname></persName>
		</author>
		<ptr target="https://huggingface.co/api/models?author=bigcode&amp;expand" />
		<imprint>
			<date type="published" when="2024">2024. 2024</date>
			<biblScope unit="page">37</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Sean</forename><surname>Hughes</surname></persName>
			<affiliation>
				<orgName type="collaboration">BigCode collaboration</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Harm</forename><surname>De Vries</surname></persName>
			<affiliation>
				<orgName type="collaboration">BigCode collaboration</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Robinson</surname></persName>
			<affiliation>
				<orgName type="collaboration">BigCode collaboration</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Muñoz Ferrandis</surname></persName>
			<affiliation>
				<orgName type="collaboration">BigCode collaboration</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Loubna</forename><surname>Ben Allal</surname></persName>
			<affiliation>
				<orgName type="collaboration">BigCode collaboration</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Leandro</forename><surname>Von Werra</surname></persName>
			<affiliation>
				<orgName type="collaboration">BigCode collaboration</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Ding</surname></persName>
			<affiliation>
				<orgName type="collaboration">BigCode collaboration</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Sebastien</forename><surname>Paquet</surname></persName>
			<affiliation>
				<orgName type="collaboration">BigCode collaboration</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
			<affiliation>
				<orgName type="collaboration">BigCode collaboration</orgName>
			</affiliation>
		</author>
		<ptr target="https://arxiv.org/abs/2312.03872" />
		<title level="m">The BigCode project governance card</title>
		<imprint>
			<date type="published" when="2023-12">December 2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>cited on pp. 2, 36, and 37</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Bigcode model license agreement</title>
		<author>
			<persName><forename type="first">Bigcode</forename><surname>Project</surname></persName>
		</author>
		<ptr target="https://huggingface.co/spaces/bigcode/bigcode-model-license-agreement" />
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
			<biblScope unit="page">37</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">Bigcode</forename><surname>Project</surname></persName>
		</author>
		<ptr target="https://www.bigcode-project.org/docs/pages/bigcode-openrail/" />
		<title level="m">BigCode open RAIL: Responsible AI licensing framework, 2023b</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">37</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<ptr target="https://huggingface.co/bigscience/bloom" />
		<title level="m">BigScience Workshop. BLOOM (revision 4ab0472)</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Identifying and filtering near-duplicate documents</title>
		<author>
			<persName><forename type="first">Andrei</forename><forename type="middle">Z</forename><surname>Broder</surname></persName>
		</author>
		<idno type="DOI">10.1007/3-540-45123-4_1</idno>
		<ptr target="https://link.springer.com/chapter/10.1007/3-540-45123-4_1" />
	</analytic>
	<monogr>
		<title level="m">Annual symposium on combinatorial pattern matching</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Description2Code dataset</title>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Openai</surname></persName>
		</author>
		<author>
			<persName><surname>Sutskever</surname></persName>
		</author>
		<ptr target="https://github.com/ethancaballero/description2code" />
		<imprint>
			<date type="published" when="2016-08">August 2016</date>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Knowledge transfer from high-resource to low-resource programming languages for code LLMs</title>
		<author>
			<persName><forename type="first">Federico</forename><surname>Cassano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Gouwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesca</forename><surname>Lucchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Schlesinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carolyn</forename><forename type="middle">Jane</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Jangda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arjun</forename><surname>Guha</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2308.09895" />
		<imprint>
			<date type="published" when="2023-08">August 2023</date>
			<biblScope unit="page" from="12" to="38" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">MultiPL-E: a scalable and polyglot approach to benchmarking neural code generation</title>
		<author>
			<persName><forename type="first">Federico</forename><surname>Cassano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Gouwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sydney</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luna</forename><surname>Phipps-Costin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Pinckney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Ho</forename><surname>Yee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangtian</forename><surname>Zi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carolyn</forename><forename type="middle">Jane</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Molly</forename><forename type="middle">Q</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arjun</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Jangda</surname></persName>
		</author>
		<idno type="DOI">10.1109/TSE.2023.3267446</idno>
		<ptr target="https://www.computer.org/csdl/journal/ts/2023/07/10103177/1MpWUtj7Rwk" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3" to="24" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Can it edit? evaluating the ability of large language models to follow code editing instructions</title>
		<author>
			<persName><forename type="first">Federico</forename><surname>Cassano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luisa</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akul</forename><surname>Sethi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Shinn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abby</forename><surname>Brennan-Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anton</forename><surname>Lozhkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carolyn</forename><forename type="middle">Jane</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arjun</forename><surname>Guha</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2312.12450" />
	</analytic>
	<monogr>
		<title level="m">The First International Workshop on Large Language Model for Code</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>cited on pp. 3, 27, and 28</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">ERNIE-code: Beyond English-centric cross-lingual pretraining for programming languages</title>
		<author>
			<persName><forename type="first">Yekun</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Hao Tian</surname></persName>
		</author>
		<author>
			<persName><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.findings-acl.676</idno>
		<ptr target="https://aclanthology.org/2023.findings-acl.676" />
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2023</title>
		<editor>
			<persName><forename type="first">Anna</forename><surname>Rogers</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Naoaki</forename><surname>Okazaki</surname></persName>
		</editor>
		<meeting><address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023-07">July 2023</date>
			<biblScope unit="page" from="10628" to="10650" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiming</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henrique</forename><surname>Ponde De Oliveira Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harri</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuri</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Brockman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raul</forename><surname>Puri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heidy</forename><surname>Khlaaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brooke</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Pavlov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alethea</forename><surname>Power</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Tillet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felipe</forename><forename type="middle">Petroski</forename><surname>Such</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dave</forename><surname>Cummings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Plappert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fotios</forename><surname>Chantzis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Hebgen Guss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Paino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolas</forename><surname>Tezak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Babuschkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suchir</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shantanu</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">N</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Leike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josh</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vedant</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evan</forename><surname>Morikawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miles</forename><surname>Brundage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mira</forename><surname>Murati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katie</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bob</forename><surname>Mcgrew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2107.03374" />
		<title level="m">Evaluating large language models trained on code</title>
		<imprint>
			<date type="published" when="2021-07">July 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>cited on pp. 2, 3, 23, 31, and 38</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Large language models at work in China&apos;s labor market</title>
		<author>
			<persName><forename type="first">Qin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinfeng</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huaqing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingcheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqing</forename><surname>Yang</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2308.08776" />
		<imprint>
			<date type="published" when="2023-08">August 2023</date>
			<biblScope unit="page">39</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Scaling language modeling with pathways</title>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parker</forename><surname>Schuh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kensen</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasha</forename><surname>Tsvyashchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Maynez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parker</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Vinodkumar Prabhakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Reif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reiner</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>Gur-Ari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toju</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anselm</forename><surname>Duke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Levskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunipa</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henryk</forename><surname>Dev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vedant</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liam</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyeontaek</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Spiridonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Sepassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shivani</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Omernick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thanumalayan</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie</forename><surname>Sankaranarayana Pillai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Pellat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erica</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Moreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleksandr</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zongwei</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brennan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Saeta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Catasta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathy</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douglas</forename><surname>Meier-Hellstern</surname></persName>
		</author>
		<author>
			<persName><surname>Eck</surname></persName>
		</author>
		<ptr target="http://jmlr.org/papers/v24/22-1144.html" />
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">240</biblScope>
			<biblScope unit="page">28</biblScope>
			<date type="published" when="2023">2023</date>
			<pubPlace>Jeff Dean, Slav Petrov, and Noah Fiedel. Palm</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning from human preferences</title>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">F</forename><surname>Christiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Leike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miljan</forename><surname>Martic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shane</forename><surname>Legg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper_files/paper/2017/hash/d" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><surname>Von Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
	<note>adad503c91f91df240d0cd4e49-Abstract.html</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName><surname>Clamav</surname></persName>
		</author>
		<ptr target="https://www.clamav.net/" />
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Training verifiers to solve math word problems</title>
		<author>
			<persName><forename type="first">Karl</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Plappert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reiichiro</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2110.14168" />
		<imprint>
			<date type="published" when="2021-10">October 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>cited on pp. 3, 12, and 28</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Unsupervised cross-lingual representation learning at scale</title>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kartikay</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.747</idno>
		<ptr target="https://aclanthology.org/2020.acl-main.747" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Joyce</forename><surname>Chai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Natalie</forename><surname>Schluter</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</editor>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07">July 2020</date>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Software heritage: Why and how to preserve software source code</title>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cosmo</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Zacchiroli</surname></persName>
		</author>
		<ptr target="https://hal.archives-ouvertes.fr/hal-01590958" />
	</analytic>
	<monogr>
		<title level="m">14th International Conference on Digital Preservation</title>
		<meeting><address><addrLine>Kyoto, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page">37</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Referencing source code artifacts: A separate concern in software citation</title>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cosmo</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Morane</forename><surname>Gruenpeter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Zacchiroli</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCSE.2019.2963148</idno>
	</analytic>
	<monogr>
		<title level="j">Computing in Science &amp; Engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Polymorphic virus</title>
		<author>
			<persName><surname>Crowdstrike</surname></persName>
		</author>
		<ptr target="https://www.crowdstrike.com/cybersecurity-101/malware/polymorphic-virus/" />
		<imprint>
			<date type="published" when="2024">2024. 2024</date>
			<biblScope unit="page">38</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Chatting our way into creating a polymorphic malware</title>
		<author>
			<persName><surname>Cyberark</surname></persName>
		</author>
		<ptr target="https://www.cyberark.com/resources/threat-research-blog/chatting-our-way-into-creating-a-polymorphic-malware" />
		<imprint>
			<date type="published" when="2024">2024. 2024</date>
			<biblScope unit="page">38</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<ptr target="https://www.cisa.gov/resources-tools/resources/secure-by-design" />
		<title level="m">Secure by design</title>
		<imprint>
			<publisher>Cybersecurity &amp; Infrastructure Security Agency</publisher>
			<date type="published" when="2024">2024. 2024</date>
			<biblScope unit="page">38</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">FlashAttention-2: faster attention with better parallelism and work partitioning</title>
		<author>
			<persName><forename type="first">Tri</forename><surname>Dao</surname></persName>
		</author>
		<ptr target="https://openreview.net/" />
	</analytic>
	<monogr>
		<title level="m">The Twelfth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">21</biblScope>
		</imprint>
	</monogr>
	<note>forum?id= mZn2Xyh9Ec</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">FlashAttention: fast and memoryefficient exact attention with IO-awareness</title>
		<author>
			<persName><forename type="first">Tri</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atri</forename><surname>Rudra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Ré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Koyejo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Belgrave</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Oh</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="16344" to="16359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">Harm</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vries</forename></persName>
		</author>
		<ptr target="https://www.harmdevries.com/post/model-size-vs-compute-overhead/" />
		<title level="m">Go smol or go home</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">BOLD: dataset and metrics for measuring biases in open-ended language generation</title>
		<author>
			<persName><forename type="first">Jwala</forename><surname>Dhamala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tony</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varun</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satyapriya</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yada</forename><surname>Pruksachatkun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Gupta</surname></persName>
		</author>
		<idno type="DOI">10.1145/3442188.3445924</idno>
		<ptr target="https://doi.org/10.1145/3442188.3445924" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, FAccT &apos;21</title>
		<meeting>the 2021 ACM Conference on Fairness, Accountability, and Transparency, FAccT &apos;21<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Towards openness beyond open access: User journeys through 3 open AI collaboratives</title>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anne</forename><forename type="middle">Lee</forename><surname>Steele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Temi</forename><surname>Popo</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=slU-5h8rrCz" />
	</analytic>
	<monogr>
		<title level="m">Workshop on Broadening Research Collaborations 2022</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">CrossCodeEval: a diverse and multilingual benchmark for cross-file code completion</title>
		<author>
			<persName><forename type="first">Yangruibo</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zijian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uddin</forename><surname>Wasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hantian</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nihal</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishna</forename><surname>Murali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parminder</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><surname>Xiang</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=wgDcbBMSfh" />
	</analytic>
	<monogr>
		<title level="m">Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cited on pp. 3, 31, 32, and 33</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Building guardrails for large language models</title>
		<author>
			<persName><forename type="first">Yi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronghui</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaojie</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinwei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenjie</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaowei</forename><surname>Huang</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2402.01822" />
		<imprint>
			<date type="published" when="2024-02">February 2024</date>
			<biblScope unit="page">38</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">KTO: model alignment as prospect theoretic optimization</title>
		<author>
			<persName><forename type="first">Kawin</forename><surname>Ethayarajh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Winnie</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2402.01306" />
		<imprint>
			<date type="published" when="2024-02">February 2024</date>
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Large language models for software engineering: Survey and open problems</title>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beliz</forename><surname>Gokkaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Harman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitya</forename><surname>Lyubarskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shubho</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shin</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><forename type="middle">M</forename><surname>Zhang</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2310.03533" />
		<imprint>
			<date type="published" when="2023-10">October 2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">PAL: Program-aided language models</title>
		<author>
			<persName><forename type="first">Luyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aman</forename><surname>Madaan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuyan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uri</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<idno>PMLR</idno>
		<ptr target="https://proceedings.mlr.press/v202/gao23f.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">Andreas</forename><surname>Krause</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Emma</forename><surname>Brunskill</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Barbara</forename><surname>Engelhardt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Sivan</forename><surname>Sabato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jonathan</forename><surname>Scarlett</surname></persName>
		</editor>
		<meeting>the 40th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2023-07">Jul 2023</date>
			<biblScope unit="volume">202</biblScope>
			<biblScope unit="page">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">RealToxicityPrompts: evaluating neural toxic degeneration in language models</title>
		<author>
			<persName><forename type="first">Suchin</forename><surname>Samuel Gehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Gururangan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.301</idno>
		<ptr target="https://aclanthology.org/2020.findings-emnlp.301" />
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<editor>
			<persName><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yulan</forename><surname>He</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</editor>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11">November 2020</date>
			<biblScope unit="page" from="3" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Gemini: a family of highly capable multimodal models</title>
		<author>
			<persName><forename type="first">Gemini</forename><surname>Team</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2312.11805" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<ptr target="https://www.goldmansachs.com/intelligence/pages/the-generative-world-order-ai-geopolitics-and-power.html" />
		<title level="m">Goldman Sachs. The generative world order: AI, geopolitics, and power</title>
		<imprint>
			<date type="published" when="2024">2024. 2024. 2024</date>
			<biblScope unit="page">39</biblScope>
		</imprint>
	</monogr>
	<note>go-enry Github Archive</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Open sourcing highly capable foundation models</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Governance</surname></persName>
		</author>
		<ptr target="https://www.governance.ai/research-paper/open-sourcing-highly-capable-foundation-models" />
		<imprint>
			<date type="published" when="2024">2024. 2024</date>
			<biblScope unit="page">38</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Groeneveld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pete</forename><surname>Walsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akshita</forename><surname>Bhagia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rodney</forename><surname>Kinney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananya</forename><surname>Harsh Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamish</forename><surname>Ivison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Magnusson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shane</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Atkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russell</forename><surname>Authur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raghavi</forename><surname>Khyathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arman</forename><surname>Chandu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanai</forename><surname>Dumas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuling</forename><surname>Elazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Hessel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Merrill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Crystal</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valentina</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhilasha</forename><surname>Pyatkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dustin</forename><surname>Ravichander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Will</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emma</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nishant</forename><surname>Strubell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitchell</forename><surname>Subramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradeep</forename><surname>Wortsman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Soldaini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><surname>Hajishirzi</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2402.00838" />
		<title level="m">accelerating the science of language models</title>
		<meeting><address><addrLine>OLMo</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2024-02">February 2024</date>
			<biblScope unit="page" from="2" to="37" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">ComPile: a large IR dataset from production sources</title>
		<author>
			<persName><forename type="first">Aiden</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ludger</forename><surname>Paehler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantinos</forename><surname>Parasyris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Ben-Nun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Hegna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Moses</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jose</forename><forename type="middle">M Monsalve</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mircea</forename><surname>Trofin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Doerfert</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2309.15432" />
		<imprint>
			<date type="published" when="2023-09">September 2023</date>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">CRUXEval: a benchmark for code reasoning, understanding and execution</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baptiste</forename><surname>Rozière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugh</forename><surname>Leather</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armando</forename><surname>Solar-Lezama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sida</forename><forename type="middle">I</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2401.03065" />
		<imprint>
			<date type="published" when="2024-01">January 2024</date>
			<biblScope unit="page" from="3" to="29" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName><forename type="first">Qihao</forename><surname>Daya Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dejian</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenda</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wentao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guanting</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">K</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuli</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingfei</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenfeng</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><surname>Liang</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2401.14196" />
		<title level="m">DeepSeek-Coder: when the large language model meets programming -the rise of code intelligence</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>cited on pp. 2, 20, 22, 23, and 25</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">From ChatGPT to ThreatGPT: impact of generative AI in cybersecurity and privacy</title>
		<author>
			<persName><forename type="first">Maanak</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charankumar</forename><surname>Akiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kshitiz</forename><surname>Aryal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eli</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lopamudra</forename><surname>Praharaj</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2023.3300381</idno>
		<ptr target="http://dx.doi.org/10.1109/ACCESS.2023.3300381" />
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<idno type="ISSN">2169-3536</idno>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">38</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">esCorpius: a massive spanish crawling corpus</title>
		<author>
			<persName><forename type="first">Asier</forename><surname>Gutiérrez-Fandiño</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Pérez-Fernández</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordi</forename><surname>Armengol-Estapé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Griol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zoraida</forename><surname>Callejas</surname></persName>
		</author>
		<idno type="DOI">10.21437/IberSPEECH.2022-26</idno>
		<ptr target="https://www.isca-speech.org/archive/pdfs/iberspeech_2022/gutierrezfandino22_iberspeech.pdf" />
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Measuring coding challenge competence with apps</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurav</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mantas</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akul</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Collin</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samir</forename><surname>Puranik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Horace</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Vanschoren</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Yeung</surname></persName>
		</editor>
		<meeting>the Neural Information Processing Systems Track on Datasets and Benchmarks</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<author>
			<persName><surname>Curran</surname></persName>
		</author>
		<ptr target="https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/c" />
		<title level="m">24cd76e1ce41366a4bbe8a49b02a028-Abstract-round2.html</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Large language models for software engineering: A systematic literature review</title>
		<author>
			<persName><forename type="first">Xinyi</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanjie</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhou</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kailong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiapu</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Grundy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoyu</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2308.10620" />
		<imprint>
			<date type="published" when="2023-08">August 2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><forename type="first">Dong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingwen</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaofei</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heming</forename><surname>Cui</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2309.14345" />
		<title level="m">Bias testing and mitigation in LLM-based code generation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">38</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Albert</forename><forename type="middle">Q</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Bamford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devendra</forename><surname>Singh Chaplot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>De Las Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Bressand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gianna</forename><surname>Lengyel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucile</forename><surname>Saulnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renard</forename><surname>Lélio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Anne</forename><surname>Lavaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Stock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibaut</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothée</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">El</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName><surname>Sayed</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2310.06825" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">Mistral 7B. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">LISA: language models of ISAbelle proofs</title>
		<author>
			<persName><forename type="first">Albert Qiaochu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenda</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Michael Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<ptr target="http://aitp-conference.org/2021/abstract/paper_17.pdf" />
	</analytic>
	<monogr>
		<title level="m">6th Conference on Artificial Intelligence and Theorem Proving</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1412.6980" />
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations, ICLR 2015</title>
		<editor>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</editor>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">May 7-9, 2015. 2015</date>
			<biblScope unit="page">21</biblScope>
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Leandro Von Werra, and Harm de Vries. The stack: 3 TB of permissively licensed source code</title>
		<author>
			<persName><forename type="first">Denis</forename><surname>Kocetkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raymond</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loubna</forename><surname>Ben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">I</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenghao</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Muñoz Ferrandis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=pxpbTdUEpD" />
	</analytic>
	<monogr>
		<title level="j">Transactions on Machine Learning Research</title>
		<idno type="ISSN">2835-8856</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cited on pp. 2, 4, 36, and 37</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Quantifying the carbon emissions of machine learning</title>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Luccioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Dandres</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1910.09700" />
		<imprint>
			<date type="published" when="2019-10">October 2019</date>
			<biblScope unit="page">21</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">DS-1000: A natural and reliable benchmark for data science code generation</title>
		<author>
			<persName><forename type="first">Yuhang</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengxi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiqi</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sida</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<idno>PMLR</idno>
		<ptr target="https://proceedings.mlr.press/v202/lai23b.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">Andreas</forename><surname>Krause</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Emma</forename><surname>Brunskill</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Barbara</forename><surname>Engelhardt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Sivan</forename><surname>Sabato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jonathan</forename><surname>Scarlett</surname></persName>
		</editor>
		<meeting>the 40th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2023-07">Jul 2023</date>
			<biblScope unit="volume">202</biblScope>
			<biblScope unit="page" from="3" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">LLVM: a compilation framework for lifelong program analysis &amp; transformation</title>
		<author>
			<persName><forename type="first">Chris</forename><surname>Lattner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikram</forename><surname>Adve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International symposium on code generation and optimization</title>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
			<biblScope unit="page" from="75" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<author>
			<persName><forename type="first">Raymond</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loubna</forename><surname>Ben Allal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangtian</forename><surname>Zi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denis</forename><surname>Kocetkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenghao</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Marone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenny</forename><surname>Chim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evgenii</forename><surname>Zheltonozhskii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Terry</forename><surname>Yue Zhuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Dehaene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mishig</forename><surname>Davaadorj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Lamy-Poirier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">João</forename><surname>Monteiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleh</forename><surname>Shliazhko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Gontier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Meade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armel</forename><surname>Zebaze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Ho</forename><surname>Yee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Logesh</forename><surname>Kumar Umapathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Lipkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhtasham</forename><surname>Oblokulov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiruo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rudra</forename><surname>Murthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Stillerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sankalp</forename><surname>Siva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Abulkhanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manan</forename><surname>Zocca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhihan</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nour</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Urvashi</forename><surname>Fahmy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhao</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Swayam</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasha</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paulo</forename><surname>Luccioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxim</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fedor</forename><surname>Kunakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><surname>Zhdanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tony</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nadav</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Timor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hailey</forename><surname>Schlesinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tri</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mayank</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><surname>Robinson</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2305.06161" />
		<title level="m">Leandro von Werra, and Harm de Vries. StarCoder: may the source be with you! arXiv preprint</title>
		<editor>
			<persName><forename type="first">Carolyn</forename><surname>Jane Anderson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Brendan</forename><surname>Dolan-Gavitt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Danish</forename><surname>Contractor</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Daniel</forename><surname>Fried</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Carlos</forename><surname>Muñoz Ferrandis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Sean</forename><surname>Hughes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Arjun</forename><surname>Guha</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2023-05">May 2023</date>
		</imprint>
	</monogr>
	<note>cited on pp. 2, 6, 8, 13, 14, 22, 33, 34, 36, and 37</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Competition-level code generation with alphacode</title>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rémi</forename><surname>Leblond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Eccles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Keeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Gimeno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Agustin</forename><forename type="middle">Dal</forename><surname>Lago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Hubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cyprien</forename><surname>De Masson D'autume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Babuschkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sven</forename><surname>Gowal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Cherepanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Molloy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">J</forename><surname>Mankowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Esme</forename><surname>Sutherland Robson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Nando De Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><surname>Vinyals</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.abq1158</idno>
		<ptr target="https://www.science.org/doi/abs/10.1126/science.abq1158" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">378</biblScope>
			<biblScope unit="issue">6624</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Is your code generated by chatGPT really correct? rigorous evaluation of large language models for code generation</title>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunqiu</forename><surname>Steven Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuyao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingming</forename><surname>Zhang</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=1qvx610Cu7" />
	</analytic>
	<monogr>
		<title level="m">Thirty-seventh Conference on Neural Information Processing Systems, 2023a</title>
		<imprint>
			<biblScope unit="page" from="3" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">RepoBench: Benchmarking repository-level code autocompletion systems</title>
		<author>
			<persName><forename type="first">Tianyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2306.03091" />
		<imprint>
			<date type="published" when="2023-06">June 2023</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<author>
			<persName><forename type="first">Shayne</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Mahari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naana</forename><surname>Obeng-Marnu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Damien</forename><surname>Sileo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Brannon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Khazam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jad</forename><surname>Kabbara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kartik</forename><surname>Perisetla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enrico</forename><surname>Shippole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tongshuang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Villa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandy</forename><surname>Pentland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Hooker</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2310.16787" />
		<title level="m">The data provenance initiative: A large scale audit of dataset licensing &amp; attribution in AI</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Fingpt: Large generative models for a small language</title>
		<author>
			<persName><forename type="first">Ville</forename><surname>Risto Luukkonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jouni</forename><surname>Komulainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anni</forename><surname>Luoma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenna</forename><surname>Eskelinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanna-Mari</forename><surname>Kanerva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filip</forename><surname>Kupari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veronika</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Laippala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><surname>Piktus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.05640</idno>
		<ptr target="https://arxiv.org/abs/2311.05640" />
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">37</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Language models as a service: Overview of a new paradigm and its challenges</title>
		<author>
			<persName><forename type="first">La</forename><surname>Emanuele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandar</forename><surname>Malfa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Frieder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Weinhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raza</forename><surname>Burnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><forename type="middle">G</forename><surname>Nazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nigel</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Shadbolt</surname></persName>
		</author>
		<author>
			<persName><surname>Wooldridge</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2309.16573" />
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">37</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Data portraits: Recording foundation model training data</title>
		<author>
			<persName><forename type="first">Marc</forename><surname>Marone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2303.03919" />
	</analytic>
	<monogr>
		<title level="m">Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="34" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">The lean mathematical library</title>
		<idno type="DOI">10.1145/3372885.3373824</idno>
		<ptr target="http://dx.doi.org/10.1145/3372885.3373824" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th ACM SIGPLAN International Conference on Certified Programs and Proofs, POPL &apos;20. ACM</title>
		<meeting>the 9th ACM SIGPLAN International Conference on Certified Programs and Proofs, POPL &apos;20. ACM</meeting>
		<imprint>
			<date type="published" when="2020-01">January 2020</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note>The mathlib Community</note>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Mendez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Graziotin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heidi</forename><surname>Seibold</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-32489-6_17</idno>
		<ptr target="http://dx.doi.org/10.1007/978-3-030-32489-6_17" />
		<title level="m">Open Science in Software Engineering</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page">37</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">A digital signature based on a conventional encryption function</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ralph</surname></persName>
		</author>
		<author>
			<persName><surname>Merkle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on the theory and application of cryptographic techniques</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">A landscape study of open source and proprietary tools for software bill of materials (sbom)</title>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Mirakhorli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Schuyler</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Laporte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henry</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viktoria</forename><surname>Koscinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Enoch</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2402.11151" />
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">38</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Codeforces: Results of</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Mirzayanov</surname></persName>
		</author>
		<ptr target="https://codeforces.com/blog/entry/89502" />
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
	<note>annual report</note>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Use of LLMs for illicit purposes: Threats, prevention measures, and vulnerabilities</title>
		<author>
			<persName><forename type="first">Maximilian</forename><surname>Mozes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanli</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bennett</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lewis</forename><forename type="middle">D</forename><surname>Griffin</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2308.12833" />
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">38</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nouamane</forename><surname>Tazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loïc</forename><surname>Magne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><surname>Mteb</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2210.07316</idno>
		<idno type="arXiv">arXiv:2210.07316</idno>
		<ptr target="https://arxiv.org/abs/2210.07316" />
		<title level="m">Massive text embedding benchmark</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">Crosslingual generalization through multitask finetuning</title>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lintang</forename><surname>Sutawika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saiful Bari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng-Xin</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hailey</forename><surname>Schoelkopf</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2211.01786" />
		<editor>Xiangru Tang, Dragomir Radev, Alham Fikri Aji, Khalid Almubarak, Samuel Albanie, Zaid Alyafeai, Albert Webson, Edward Raff, and Colin Raffel</editor>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Scaling data-constrained language models</title>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boaz</forename><surname>Barak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nouamane</forename><surname>Tazi</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=j5BuTrEj35" />
	</analytic>
	<monogr>
		<title level="m">Thirty-seventh Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="2" to="21" />
		</imprint>
	</monogr>
	<note>Aleksandra Piktus, Sampo Pyysalo, Thomas Wolf, and Colin Raffel</note>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">OctoPack: instruction tuning code large language models</title>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Randy</forename><surname>Armel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinkai</forename><surname>Zebaze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binyuan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Terry</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Swayam</forename><surname>Yue Zhuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangru</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leandro</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shayne</forename><surname>Von Werra</surname></persName>
		</author>
		<author>
			<persName><surname>Longpre</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=mw1PWNSWZP" />
	</analytic>
	<monogr>
		<title level="m">The Twelfth International Conference on Learning Representations, 2024a</title>
		<imprint/>
	</monogr>
	<note>cited on pp. 3, 25, 26, 27, and 37</note>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongjin</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2402.09906" />
		<title level="m">Generative representational instruction tuning</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Auditing large language models: A three-layered approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mökander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schuett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Kirk</surname></persName>
		</author>
		<idno type="DOI">10.1007/s43681-023-00289-2</idno>
		<ptr target="https://doi.org/10.1007/s43681-023-00289-2" />
	</analytic>
	<monogr>
		<title level="j">AI Ethics</title>
		<imprint>
			<biblScope unit="page">37</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">A comparative study of programming languages in Rosetta code</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Nanz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlo</forename><forename type="middle">A</forename><surname>Furia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE/ACM 37th IEEE International Conference on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="778" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title/>
		<author>
			<persName><surname>Ieee</surname></persName>
		</author>
		<ptr target="https://ieeexplore.ieee.org/document/7194625" />
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">CodeGen: an open large language model for code with multi-turn program synthesis</title>
		<author>
			<persName><forename type="first">Erik</forename><surname>Nijkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroaki</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lifu</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingbo</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=iaYcJKpY2B_" />
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">HONEST: Measuring hurtful sentence completion in language models</title>
		<author>
			<persName><forename type="first">Debora</forename><surname>Nozza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Federico</forename><surname>Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.191</idno>
		<ptr target="https://aclanthology.org/2021.naacl-main.191" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter</title>
		<editor>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Anna</forename><surname>Rumshisky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dilek</forename><surname>Hakkani-Tur</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Tanmoy</forename><surname>Chakraborty</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yichao</forename><surname>Zhou</surname></persName>
		</editor>
		<meeting>the 2021 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-06">June 2021</date>
			<biblScope unit="page" from="3" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2303.08774" />
		<title level="m">GPT-4 technical report</title>
		<imprint>
			<date type="published" when="2023-03">March 2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Asynchronous pipelines for processing huge corpora on medium to low resource infrastructures</title>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Javier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ortiz</forename><surname>Suárez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benoît</forename><surname>Sagot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Romary</surname></persName>
		</author>
		<idno type="DOI">10.14618/ids-pub-9021</idno>
		<ptr target="http://nbn-resolving.de/urn:nbn:de:bsz" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Challenges in the Management of Large Corpora</title>
		<editor>
			<persName><forename type="first">Piotr</forename><surname>Bański</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Adrien</forename><surname>Barbaresi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Hanno</forename><surname>Biber</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Evelyn</forename><surname>Breiteneder</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Simon</forename><surname>Clematide</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Marc</forename><surname>Kupietz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Harald</forename><surname>Lüngen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Caroline</forename><surname>Iliadi</surname></persName>
		</editor>
		<meeting>the Workshop on Challenges in the Management of Large Corpora<address><addrLine>Mannheim</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-07">July 2019</date>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title level="m" type="main">OpenWebMath: an open dataset of highquality mathematical web text</title>
		<author>
			<persName><forename type="first">Keiran</forename><surname>Paster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><forename type="middle">Dos</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhangir</forename><surname>Azerbayev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2310.06786" />
		<imprint>
			<date type="published" when="2023-10">October 2023</date>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Asleep at the keyboard? assessing the security of github copilot&apos;s code contributions</title>
		<author>
			<persName><forename type="first">Hammond</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baleegh</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Dolan-Gavitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Karri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 IEEE Symposium on Security and Privacy (SP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="3" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">The RefinedWeb dataset for Falcon LLM: Outperforming curated corpora with web data only</title>
		<author>
			<persName><forename type="first">Guilherme</forename><surname>Penedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Malartic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Hesslow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruxandra</forename><surname>Cojocaru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamza</forename><surname>Alobeidli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Cappelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baptiste</forename><surname>Pannier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ebtesam</forename><surname>Almazrouei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Launay</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=kM5eGcdCzq" />
	</analytic>
	<monogr>
		<title level="m">Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<author>
			<persName><forename type="first">Sida</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eirini</forename><surname>Kalliamvakou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Cihon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mert</forename><surname>Demirer</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2302.06590" />
		<title level="m">The impact of AI on developer productivity: Evidence from GitHub Copilot</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="2" to="39" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">The software heritage graph dataset: Large-scale analysis of public software development history</title>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Pietri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diomidis</forename><surname>Spinellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Zacchiroli</surname></persName>
		</author>
		<idno type="DOI">10.1145/3379597.3387510</idno>
		<ptr target="https://arxiv.org/abs/2011.07824https://www.softwareheritage.org/wp-content/uploads/2021/03/msr-2020-challenge.pdf" />
	</analytic>
	<monogr>
		<title level="m">MSR 2020: The 17th International Conference on Mining Software Repositories</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">The ROOTS search tool: Data transparency for LLMs</title>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paulo</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Laurençon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gérard</forename><surname>Dupont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasha</forename><surname>Luccioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Rogers</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.acl-demo.29</idno>
		<ptr target="https://aclanthology.org/2023.acl-demo.29" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">Danushka</forename><surname>Bollegala</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ruihong</forename><surname>Huang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</editor>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023-07">July 2023</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">34</biblScope>
		</imprint>
	</monogr>
	<note>System Demonstrations)</note>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">GAIA search: Hugging Face and pyserini interoperability for NLP training data exploration</title>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Odunayo</forename><surname>Ogundepo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akintunde</forename><surname>Oladipo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hailey</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.acl-demo.57</idno>
		<ptr target="https://aclanthology.org/2023.acl-demo.57" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">Danushka</forename><surname>Bollegala</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ruihong</forename><surname>Huang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</editor>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023-07">July 2023</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">34</biblScope>
		</imprint>
	</monogr>
	<note>System Demonstrations)</note>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title level="m" type="main">Stable code 3B: Coding on the edge. Stability AI</title>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Pinnaparaju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reshinth</forename><surname>Adithyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duy</forename><surname>Phung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Tow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Baicoianu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Cooper</surname></persName>
		</author>
		<ptr target="https://stability.ai/news/stable-code-2024-llm-code-completion-release" />
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">22</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<title level="m" type="main">The stack v2</title>
		<author>
			<persName><forename type="first">Bigcode</forename><surname>Project</surname></persName>
		</author>
		<ptr target="https://huggingface.co/datasets/bigcode/the-stack-v2/" />
		<imprint>
			<date type="published" when="2024">2024. 2024</date>
			<biblScope unit="page">37</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">CodeNet: a large-scale AI for code dataset for learning a diversity of coding tasks</title>
		<author>
			<persName><forename type="first">Ruchir</forename><surname>Puri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">S</forename><surname>Kung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geert</forename><surname>Janssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giacomo</forename><surname>Domeniconi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Zolotov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Dolby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihir</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lindsey</forename><surname>Decker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veronika</forename><surname>Thost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Buratti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Pujar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shyam</forename><surname>Ramji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulrich</forename><surname>Finkler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><surname>Malaika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederick</forename><surname>Reiss</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=6vZVBkCDrHT" />
	</analytic>
	<monogr>
		<title level="m">Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Redpajama</forename><surname>Wiki</surname></persName>
		</author>
		<ptr target="https://github.com/togethercomputer/RedPajama-Data/tree/rp_v1/data_prep/wiki" />
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Sentence-BERT: Sentence embeddings using siamese BERT-networks</title>
		<author>
			<persName><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1410</idno>
		<ptr target="https://aclanthology.org/D19-1410" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<editor>
			<persName><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</editor>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11">November 2019</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<title level="m" type="main">Codebleu: a method for automatic evaluation of code synthesis</title>
		<author>
			<persName><forename type="first">Daya</forename><surname>Shuo Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuai</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Long</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shujie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neel</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Sundaresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ambrosio</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuai</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName><surname>Ma</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2009.10297" />
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b110">
	<monogr>
		<ptr target="https://rosettacode.org/" />
		<title level="m">Rosetta Code</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="11" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<monogr>
		<title level="m" type="main">Code llama: Open foundation models for code</title>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Baptiste Rozière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabian</forename><surname>Gehring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sten</forename><surname>Gloeckle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Itai</forename><surname>Sootla</surname></persName>
		</author>
		<author>
			<persName><surname>Gat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><surname>Xiaoqing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yossi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingyu</forename><surname>Adi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jérémy</forename><surname>Remez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artyom</forename><surname>Rapin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Kozhevnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joanna</forename><surname>Evtimov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manish</forename><surname>Bitton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristian Canton</forename><surname>Bhatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Ferrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhan</forename><surname>Grattafiori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jade</forename><surname>Défossez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faisal</forename><surname>Copet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Azhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Scialom</surname></persName>
		</author>
		<author>
			<persName><surname>Synnaeve</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2308.12950" />
		<imprint>
			<date type="published" when="2023-08">August 2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>cited on pp. 2, 20, 22, 23, 25, and 31</note>
</biblStruct>

<biblStruct xml:id="b112">
	<monogr>
		<ptr target="https://sanesecurity.com/usage/signatures" />
		<title level="m">Sane Security</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Multitask prompted training enables zero-shot task generalization</title>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lintang</forename><surname>Sutawika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zaid</forename><surname>Alyafeai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Chaffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Stiegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arun</forename><surname>Raja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manan</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saiful Bari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Urmish</forename><surname>Thakker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shanya</forename><surname>Sharma Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eliza</forename><surname>Szczechla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taewoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gunjan</forename><surname>Chhablani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nihal</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debajyoti</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Tian-Jian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matteo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Manica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng Xin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harshit</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Bawden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trishala</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jos</forename><surname>Neeraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abheesht</forename><surname>Rozen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibault</forename><surname>Santilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Fevry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Fries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Teehan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Teven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leo</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><surname>Rush</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=9Vrb9D0WI4" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Analysing mathematical reasoning abilities of neural models</title>
		<author>
			<persName><forename type="first">David</forename><surname>Saxton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=H1" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note>gR5iR5FX</note>
</biblStruct>

<biblStruct xml:id="b115">
	<monogr>
		<title/>
		<author>
			<persName><surname>Scancode</surname></persName>
		</author>
		<ptr target="https://github.com/nexB/scancode-toolkit" />
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<monogr>
		<ptr target="https://scancode-licensedb.aboutcode.org/help.html#license-categories" />
		<title level="m">ScanCode License Categories</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<monogr>
		<title level="m" type="main">BLOOM: A 176b-parameter open-access multilingual language model</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Teven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellie</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suzana</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ilic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Hesslow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Castagné</surname></persName>
		</author>
		<author>
			<persName><forename type="first">François</forename><surname>Sasha Luccioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Yvon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Gallé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Tow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pawan</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Sasanka Ammanamanchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benoît</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Sagot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olatunji</forename><surname>Villanova Del Moral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Ruwase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stas</forename><surname>Bawden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angelina</forename><surname>Bekman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iz</forename><surname>Mcmillan-Major</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huu</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucile</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samson</forename><surname>Saulnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><forename type="middle">Ortiz</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Suarez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Laurençon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Launay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adi</forename><surname>Gokaslan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Simhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alham</forename><surname>Soroa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amit</forename><surname>Fikri Aji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Alfassy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><forename type="middle">Kreisberg</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Nitzav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenghao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Emezue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Klamm</surname></persName>
		</author>
		<author>
			<persName><surname>Leong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Daniel Van Strien</surname></persName>
		</author>
		<author>
			<persName><surname>Ifeoluwa Adelani</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2211.05100</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2211.05100" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<monogr>
		<title level="m" type="main">What language model to train if you have one million gpu hours?</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Teven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucile</forename><surname>Hesslow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stas</forename><surname>Saulnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bekman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Saiful Bari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hady</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Elsahar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><surname>Phang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.15424</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b119">
	<monogr>
		<title level="m" type="main">Text2flow LLM: Automating workflow generation from descriptive text</title>
		<author>
			<persName><surname>Servicenow</surname></persName>
		</author>
		<ptr target="https://downloads.docs.servicenow.com/resource/enus/infocard/text2flow-llm.pdf" />
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">39</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<monogr>
		<title level="m" type="main">Text-to-code LLM: transforming natural language into executable code</title>
		<author>
			<persName><surname>Servicenow</surname></persName>
		</author>
		<ptr target="https://downloads.docs.servicenow.com/resource/enus/infocard/text-to-code-llm.pdf" />
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">39</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<monogr>
		<title level="m" type="main">Fast transformer decoding: One write-head is all you need</title>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<idno>CoRR, abs/1911.02150</idno>
		<ptr target="http://arxiv.org/abs/1911.02150" />
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">20</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">The woman worked as a babysitter: On biases in language generation</title>
		<author>
			<persName><forename type="first">Emily</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Premkumar</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1339</idno>
		<ptr target="https://aclanthology.org/D19-1339" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<editor>
			<persName><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</editor>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11">November 2019</date>
			<biblScope unit="page">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Ten simple rules for helping newcomers become contributors to open projects</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Sholler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Steinmacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denise</forename><surname>Ford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mara</forename><surname>Averick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Hoye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1007296</idno>
		<ptr target="https://doi.org/10.1371/journal.pcbi.1007296" />
	</analytic>
	<monogr>
		<title level="j">PLoS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">37</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<monogr>
		<author>
			<persName><forename type="first">Shivalika</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Freddie</forename><surname>Vargus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Dsouza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Börje</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abinaya</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Yin</forename><surname>Mahendiran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Herumb</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Shandilya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deividas</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Mataciunas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Omahony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramith</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Hettiarachchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marina</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luisa</forename><surname>Machado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Souza Moura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hakimeh</forename><surname>Krzemiński</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irem</forename><surname>Fadaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ifeoma</forename><surname>Ergün</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aisha</forename><surname>Okoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oshan</forename><surname>Alaagib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zaid</forename><surname>Mudannayake</surname></persName>
		</author>
		<author>
			<persName><surname>Alyafeai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minh</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Surya</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emad</forename><forename type="middle">A</forename><surname>Guthikonda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Alghamdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julia</forename><surname>Bartolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmet</forename><surname>Kreutzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marzieh</forename><surname>Üstün</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Fadaee</surname></persName>
		</author>
		<author>
			<persName><surname>Hooker</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2402.06619" />
		<title level="m">Aya dataset: An open-access collection for multilingual instruction tuning</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">37</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b125">
	<monogr>
		<title level="m" type="main">Swh statement on llm for code</title>
		<author>
			<persName><forename type="first">Software</forename><surname>Heritage</surname></persName>
		</author>
		<ptr target="https://www.softwareheritage.org/2023/10/19/swh-statement-on-llm-for-code/" />
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">38</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<monogr>
		<title level="m" type="main">Bulk access terms of use</title>
		<author>
			<persName><forename type="first">Software</forename><surname>Heritage</surname></persName>
		</author>
		<ptr target="https://www.softwareheritage.org/legal/bulk-access-terms-of-use/" />
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">37</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Software</forename><surname>Heritage</surname></persName>
		</author>
		<ptr target="https://www.softwareheritage.org" />
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<monogr>
		<author>
			<persName><forename type="first">Irene</forename><surname>Solaiman</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2302.04844" />
		<title level="m">The gradient of generative AI release: Methods and considerations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>cited on pp. 2, 37, and 38</note>
</biblStruct>

<biblStruct xml:id="b129">
	<monogr>
		<author>
			<persName><forename type="first">Luca</forename><surname>Soldaini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rodney</forename><surname>Kinney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akshita</forename><surname>Bhagia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dustin</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Atkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russell</forename><surname>Authur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Bogin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khyathi</forename><surname>Chandu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Dumas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanai</forename><surname>Elazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valentin</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananya</forename><surname>Harsh Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sachin</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Lucy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinxi</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Magnusson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Crystal</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhilasha</forename><surname>Ravichander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zejiang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emma</forename><surname>Strubell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nishant</forename><surname>Subramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pete</forename><surname>Walsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Groeneveld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2402.00159" />
		<title level="m">Dolma: an open corpus of three trillion tokens for language model pretraining research</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">37</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b130">
	<monogr>
		<ptr target="https://archive.org/details/stackexchange" />
		<title level="m">StackExchange Archive</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<monogr>
		<title level="m" type="main">RoFormer: Enhanced transformer with rotary position embedding</title>
		<author>
			<persName><forename type="first">Jianlin</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengfeng</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Murtadha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunfeng</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2104.09864" />
		<imprint>
			<date type="published" when="2021-04">April 2021</date>
			<biblScope unit="page">20</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Code translation with compiler representations</title>
		<author>
			<persName><forename type="first">Marc</forename><surname>Szafraniec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baptiste</forename><surname>Roziere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugh</forename><forename type="middle">James</forename><surname>Leather</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Labatut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francois</forename><surname>Charton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=XomEU3eNeSQ" />
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Helping code reviewer prioritize: Pinpointing personal data and its processing</title>
		<author>
			<persName><forename type="first">Feiyang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bjarte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Magiel</forename><surname>Østvold</surname></persName>
		</author>
		<author>
			<persName><surname>Bruntink</surname></persName>
		</author>
		<idno type="DOI">10.3233/FAIA230228</idno>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Artificial Intelligence and Applications</title>
		<imprint>
			<biblScope unit="volume">371</biblScope>
			<biblScope unit="page">38</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<monogr>
		<author>
			<persName><forename type="first">Feiyang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bjarte</forename><forename type="middle">M</forename><surname>Østvold</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2401.07316" />
		<title level="m">Finding privacy-relevant source code</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">38</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b135">
	<monogr>
		<title level="m" type="main">The SWHID Specification Project. The SWHID specification</title>
		<ptr target="https://www.swhid.org/" />
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">38</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">RedPajama: an open dataset for training large language models</title>
		<ptr target="https://github.com/togethercomputer/RedPajama-Data" />
	</analytic>
	<monogr>
		<title level="m">Together Computer</title>
		<imprint>
			<date type="published" when="2023-10">October 2023</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<monogr>
		<title level="m" type="main">Llama 2: Open foundation and fine-tuned chat models</title>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amjad</forename><surname>Almahairi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasmine</forename><surname>Babaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolay</forename><surname>Bashlykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumya</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prajjwal</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Bhosale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Bikel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukas</forename><surname>Blecher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristian Canton</forename><surname>Ferrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Esiobu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jude</forename><surname>Fernandes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenyin</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Fuller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vedanuj</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Hartshorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saghar</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hakan</forename><surname>Inan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Kardas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viktor</forename><surname>Kerkez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madian</forename><surname>Khabsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabel</forename><surname>Kloumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artem</forename><surname>Korenev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Punit</forename><surname>Singh Koura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibaut</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenya</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diana</forename><surname>Liskovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinghai</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuning</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Martinet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushkar</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Molybog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Poulton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Reizenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rashi</forename><surname>Rungta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalyan</forename><surname>Saladi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Schelten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruan</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">Michael</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ranjan</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><surname>Xiaoqing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binh</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adina</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Puxin</forename><surname>Xiang Kuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iliyan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuchen</forename><surname>Zarov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Kambadur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurelien</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Stojnic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName><surname>Scialom</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2307.09288" />
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b138">
	<monogr>
		<author>
			<persName><forename type="first">Ahmet</forename><surname>Üstün</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viraat</forename><surname>Aryabumi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng-Xin</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Yin</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D'</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gbemileke</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neel</forename><surname>Onilude</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shivalika</forename><surname>Bhandari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui-Lee</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amr</forename><surname>Ooi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Freddie</forename><surname>Kayid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Vargus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shayne</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marzieh</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julia</forename><surname>Fadaee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Kreutzer</surname></persName>
		</author>
		<author>
			<persName><surname>Hooker</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2402.07827" />
		<title level="m">Aya model: An instruction finetuned open-access multilingual language model</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">37</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Learning from the worst: Dynamically generated datasets to improve online hate detection</title>
		<author>
			<persName><forename type="first">Bertie</forename><surname>Vidgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Thrush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeerak</forename><surname>Waseem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.132</idno>
		<ptr target="https://aclanthology.org/2021.acl-long.132" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<editor>
			<persName><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</editor>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08">August 2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">Software testing with large language models: Survey, landscape, and vision</title>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuchao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunyang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1109/TSE.2024.3368208</idno>
		<ptr target="https://arxiv.org/abs/2307.07221" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Finetuned language models are zero-shot learners</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=gEZrGCozdqR" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Open science is a research accelerator</title>
		<author>
			<persName><surname>Michael Woelfle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Piero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">H</forename><surname>Olliaro</surname></persName>
		</author>
		<author>
			<persName><surname>Todd</surname></persName>
		</author>
		<ptr target="https://www.weforum.org/publications/jobs-of-tomorrow-large-language-models-and-jobs/" />
	</analytic>
	<monogr>
		<title level="m">World Economic Forum. Jobs of tomorrow: Large language models and jobs</title>
		<imprint>
			<date type="published" when="2011">2011. 2024</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="745" to="748" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Lemur: Harmonizing natural language and code for language agents</title>
		<author>
			<persName><forename type="first">Yiheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongjin</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boyu</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weijia</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binyuan</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yitao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianbao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhoujun</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bailin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=hNhwSmtXRh" />
	</analytic>
	<monogr>
		<title level="m">The Twelfth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">37</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">ServiceNow Inc (NYSE: NOW) Q4 earnings: What to expect</title>
		<ptr target="https://finance.yahoo.com/news/servicenow-inc-nyse-now-q4-154816487.html" />
	</analytic>
	<monogr>
		<title level="m">Yahoo Finance</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="2" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<monogr>
		<author>
			<persName><forename type="first">Zhou</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhipeng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jieke</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongsum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donggyun</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lo</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2310.01166" />
		<title level="m">Gotcha! this model uses my code! evaluating membership leakage risks in code models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">38</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b146">
	<monogr>
		<title level="m" type="main">Scaling relationship on learning mathematical reasoning with large language models</title>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengpeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guanting</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keming</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuanqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingren</forename><surname>Zhou</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2308.01825" />
		<imprint>
			<date type="published" when="2023-08">August 2023</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">Gender bias in coreference resolution: Evaluation and debiasing methods</title>
		<author>
			<persName><forename type="first">Jieyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianlu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vicente</forename><surname>Ordonez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-2003</idno>
		<ptr target="https://aclanthology.org/N18-2003" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<editor>
			<persName><forename type="first">Marilyn</forename><surname>Walker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ji</forename><surname>Heng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Amanda</forename><surname>Stent</surname></persName>
		</editor>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-06">June 2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<monogr>
		<author>
			<persName><forename type="first">Terry</forename><surname>Yue Zhuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunyang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenchang</forename><surname>Xing</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2301.12867" />
		<title level="m">Red teaming ChatGPT via jailbreaking: Bias, robustness, reliability and toxicity</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">38</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b149">
	<monogr>
		<title level="m" type="main">Source code data augmentation for deep learning: A survey</title>
		<author>
			<persName><forename type="first">Terry</forename><surname>Yue Zhuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhou</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhensu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yufei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoning</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenchang</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lo</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2305.19915" />
		<imprint>
			<date type="published" when="2023-05">May 2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>cited on pp. 2, 11, and 38</note>
</biblStruct>

<biblStruct xml:id="b150">
	<monogr>
		<title level="m" type="main">Astraios: Parameter-efficient instruction tuning code large language models</title>
		<author>
			<persName><forename type="first">Terry</forename><surname>Yue Zhuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armel</forename><surname>Zebaze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nitchakarn</forename><surname>Suppattarachai ; Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Muennighoff</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2401.00788" />
		<imprint>
			<date type="published" when="2024-08">August 2024</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Leandro von Werra, Harm de Vries</note>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">Ignore List (dockerignore, eslintignore, gitignore, npmignore), INI (cfg, prefs, url)</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">JAR Manifest (mf), Java Properties (properties), Jest Snapshot (snap), JetBrains MPS (mps), JSONLD (jsonld), LiveScript (ls), Makefile (d, make), Mathematica (cdf, nb), MAXScript (ms), mIRC Script (mrc), NASL (inc), nesC (nc), Nunjucks (njk), OpenEdge ABL (p, w), Pascal (&lt;empty extension&gt;, dpr, inc, pp), Perl (al, ph), PLSQL (pck, pls, tps, trg, vw), Protocol Buffer Text Format (pbt), Puppet (&lt;empty extension&gt;), PureBasic (pb), Racket (rkt, rktd), ReScript (res), reStructuredText (rest), Rich Text Format (rtf)</title>
		<meeting><address><addrLine>Roff</addrLine></address></meeting>
		<imprint>
			<date>&lt;empty extension&gt;, 1, 1d, 2, 5, 7, 8, 9. 1d, 2, 3d, 4, 6, 9,</date>
		</imprint>
	</monogr>
	<note>AngelScript (as), AsciiDoc (asc &lt;empty extension&gt; Cabal Config (project), ChucK (ck) C++ Common Lisp (l, sexp) CODEOWNERS (&lt;empty extension&gt; AspectJ (aj), Bison (bison), Boogie (bpl) GLSL (geo) Common Workflow Language (cwl) Glyph Bitmap Distribution Format (bdf), GN (gn) CoNLL-U (conll, conllu), Cue Sheet (cue), CWeb (w), desktop (desktop, in, service), DIGITAL Command Language (com), DTrace (d), edn (edn), Elixir (lock), Factor (factor), GAP (g, gd), Gemfile.lock (lock), Gettext Catalog (pot), Git Config (gitmodules) Roff Manpage (&lt;empty extension&gt; man), Scala (sc), Scilab (tst), SELinux Policy (te), Shell (env), Slash (sl), Smalltalk (cs), SmPL (cocci), SQL (tab), Standard ML (sig), Stata (ihlp, sthlp), SuperCollider (sc), SWIG (i), TeX (aux, ltx, toc), TOML (lock), Turtle (ttl), VBA (frm, frx), Vim Snippet (snippet), Wavefront Material (mtl), Wikitext (wikitext), Windows Registry Entries (reg), wisp (w) World of Warcraft Addon Data (toc), X BitMap (xbm), XML (kml, pt, resx, rss), XML Property List (plist, tmcommand, tmlanguage, tmsnippet, tmtheme), Yacc (yy</note>
</biblStruct>

<biblStruct xml:id="b152">
	<monogr>
		<title level="m" type="main">Excluded Programming Languages</title>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">Microsoft Developer Studio Project,Microsoft Visual Studio Solution,Pickle,PostScript, POV-Ray SDL,Public Key,Pure Data,Raw token data,robots.txt,STL,SubRip Text,SVG,TSV, Unity3D Asset,Wavefront Object,WebVTT,X PixMap A.3 License detection license_file_names =</title>
		<author>
			<persName><forename type="first">Ags</forename><surname>Array</surname></persName>
		</author>
		<author>
			<persName><surname>Script</surname></persName>
		</author>
		<author>
			<persName><surname>Bicep</surname></persName>
		</author>
		<author>
			<persName><surname>Checksums</surname></persName>
		</author>
		<author>
			<persName><surname>Collada</surname></persName>
		</author>
		<author>
			<persName><surname>Csv</surname></persName>
		</author>
		<author>
			<persName><surname>Diff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E-Mail</forename><surname>Directx 3d File</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G-Code</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Gerber</forename><surname>Image</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Revision</forename><surname>Git</surname></persName>
		</author>
		<author>
			<persName><surname>List</surname></persName>
		</author>
		<author>
			<persName><surname>Gnuplot</surname></persName>
		</author>
		<author>
			<persName><surname>Go</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jupyter</forename><surname>Checksums</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kicad</forename><surname>Notebook</surname></persName>
		</author>
		<author>
			<persName><surname>Layout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Legacy</forename><surname>Kicad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kicad</forename><surname>Layout</surname></persName>
		</author>
		<author>
			<persName><surname>Schematic</surname></persName>
		</author>
		<author>
			<persName><surname>Lasso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kernel</forename><surname>Linux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Module</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m"># Artistic.txt &quot;copying(v?)(\d?)</title>
		<imprint/>
	</monogr>
	<note>li[cs]en[cs]e(s?)&quot;, &quot;legal&quot;, &quot;copy(left|right|ing)&quot;, &quot;unlicense&quot;, &quot;[al]?gpl([-_ v]?)(\d\.?\d?)?&quot;, # AGPLv3 &quot;bsd(l?) # MITX &quot;apache # BSDL &quot;mit(x?) # COPYING3, COPYINGv3 &quot;disclaimer&quot;, &quot;eupl&quot;, &quot;gfdl&quot;, &quot;[cm]pl&quot;, &quot;cc0&quot;, &quot;al([-_ v]?)(\d\.?\d)?&quot;, # AL2.0 &quot;about&quot;, &quot;notice&quot;, &quot;readme&quot;, &quot;guidelines&quot;, ] license_file_re = re.compile( rf&quot;^(|.*[-_. ])({&apos;|&apos;.join(license_file_names)})(|[-_.</note>
</biblStruct>

<biblStruct xml:id="b154">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">*</forename></persName>
		</author>
		<author>
			<persName><forename type="first">$</forename></persName>
		</author>
		<idno>re.IGNORECASE</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">NASA-1.3, Naumen, NBPL-1.0, NCSA, Net-SNMP, NetCDF, Newsletr, NICTA-1.0, NIST-PD-fallback, NIST-Software, NLOD-1.0, NLOD-2.0, NRL, NTP, NTP-0, O-UDA-1.0, ODC-By-1.0, OFFIS, OFL-1.0, OFL-1.0-no-RFN, OFL-1.0-RFN, OFL-1.1-no-RFN, OFL-1.1-RFN, OGC-1.0, OGDL-Taiwan-1.0, OGL-Canada-2.0, OGL-UK-1.0, OGL-UK-2.0, OGL-UK-3.0, OGTSL, OLDAP-1.1, OLDAP-1.2, OLDAP-1.3, OLDAP-1.4, OLDAP-2.0, OLDAP-2.0.1, OLDAP-2.1, OLDAP-2</title>
		<author>
			<persName><forename type="first">A</forename><surname>Aal</surname></persName>
		</author>
		<author>
			<persName><surname>Abstyles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amdplpa</forename><surname>Adacore-Doc ; Afmparse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ampas</forename><surname>Aml</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antlr-Pd ;</forename><surname>Baekmuk</surname></persName>
		</author>
		<author>
			<persName><surname>Bahyph</surname></persName>
		</author>
		<author>
			<persName><surname>Barr</surname></persName>
		</author>
		<author>
			<persName><surname>Beerware</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bitstream-Vera ;</forename><surname>Bitstream-Charter</surname></persName>
		</author>
		<author>
			<persName><surname>Eudatagrid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Freebsd-Doc</forename><surname>Fair</surname></persName>
		</author>
		<author>
			<persName><surname>Fsfap</surname></persName>
		</author>
		<author>
			<persName><surname>Fsfullr</surname></persName>
		</author>
		<author>
			<persName><surname>Fsfullrwd</surname></persName>
		</author>
		<author>
			<persName><surname>Ftl</surname></persName>
		</author>
		<author>
			<persName><surname>Gd</surname></persName>
		</author>
		<author>
			<persName><surname>Giftware</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Glwtpl</forename><surname>Glulxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graphics-Gems ;</forename><surname>Jpnic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Json</forename><surname>Kazlib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Knuth-Ctan</forename></persName>
		</author>
		<idno>Unicode-DFS-2016</idno>
	</analytic>
	<monogr>
		<title level="m">Latex2e, Latex2e-translated-notice, Leptonica, Libpng, libpng-2.0, libtiff, Linux-OpenIB, LLVM-exception, LOOP, LPL-1.0, LPL-1.02, LPPL-1.3c, Martin-Birgmeier, metamail, Minpack, MirOS, MIT, MIT-0, MIT-advertising, MIT-CMU, MIT-enna, MITfeh, MIT-Festival, MIT-Modern-Variant, MIT-open-group, MIT-Wu</title>
		<editor>
			<persName><surname>Smlnj</surname></persName>
		</editor>
		<editor>
			<persName><surname>Spencer-86</surname></persName>
		</editor>
		<editor>
			<persName><surname>Spencer-94</surname></persName>
		</editor>
		<editor>
			<persName><surname>Spencer-99</surname></persName>
		</editor>
		<meeting><address><addrLine>MITNFA, mpich2, mplus, MS-LPL, MS-PL, MTLL; 2, OLDAP-2.2.1, OLDAP-2.2.2, OLDAP-2.3, OLDAP-2.4, OLDAP-2.5, OLDAP-2.6, OLDAP-2.7, OLDAP-2.8, OML, OpenSSL; Plexus, PostgreSQL, PSF-2.0, psfrag, psutils, Python-2.0, Python-2.0.1, Qhull, Rdisc, RSA-MD, Ruby, Saxpath, SCEA, SchemeReport, Sendmail, SGI-B-1.1, SGI-B-2.0, SGP; SunPro, Swift-exception, SWL, TCL, TCP-wrappers, TermReadKey, TPDL, TTWL, TU-Berlin-1.0, TU-Berlin-2.0, UCAR</addrLine></address></meeting>
		<imprint>
			<publisher>SSH-short</publisher>
			<date type="published" when="2003">Adobe-2006, Adobe-Glyph, ADSL, AFL-1.1, AFL-1.2, AFL-2.0, AFL-2.1, AFL-3.0. Apache-1.0, Apache-1.1, Apache-2.0, APAFML, App-s2p, Artistic-1.0, Artistic-1.0-cl8, Artistic-1.0-Perl, Artistic-2.0. 1.0, DSDP, dtoa, dvipdfm, ECL-1.0, ECL-2.0, EFL-1.0, EFL-2.0, eGenix, Entessa, EPICS, etalab-2.0. JasPer-2.0,. MulanPSL-1.0, MulanPSL-2.0, Multics, Mup, NAIST-2003</date>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
	<note>Permissive licenses SPDX-recognized license IDs 0BSD GStreamerexception-2005, HaskellReport, HP-1986, HPND, HPND-Markus-Kuhn, HPND-sell-variant, HPND-sellvariant-MIT-disclaimer HTMLTIDY, IBM-pibs, ICU, IJG, IJG-short, ImageMagick, iMatix, Info-ZIP, Intel, Intel-ACPI, ISC, Jam BSD-Source-Code, BSL-1.0, bzip2-1.0.6, Caldera, CC-BY-1.0, CC-BY-2.0, CC-BY-2.5, CC-BY-2.5-AU, CC-BY-3.0, CC-BY-3.0-AT, CC-BY-3.0-DE, CC-BY-3.0-NL, CC-BY-3.0-US, CC-BY-4.0, CDLA-Permissive-1.0, CDLA-Permissive-2.0, CECILL-B, CERN-OHL-1.1, CERN-OHL-1.2, CERN-OHL-P-2.0, CFITSIO, checkmk, ClArtistic, Clips, CMU-Mach UnixCrypt, UPL-1.0, Vim, VSL-1.0, W3C, W3C-19980720, W3C-20150513, w3m, Widget-Workshop, Wsuipa, X11, X11-distribute-modifications-variant, Xdebug-1.03, Xerox, Xfig, XFree86-1.1, xinetd, xlock, Xnet, xpp, XSkat, Zed, Zend-2.0, Zlib, zlib-acknowledgement, ZPL-1.1, ZPL-2.0, ZPL-2.1</note>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">inno-setup, intel-bsd, intel-bsd-2-clause, intel-osl-1989, intel-osl-1993, intel-royalty-free, iso-14496-10, iso-8879, itu, ja-sig, jason-mayes, jasper-1.0, java-app-stub, jdbm-1.00, jdom, jetty, jgraph, jpnic-mdnkit, jpython-1.1, jscheme, jsfromhell, jython, kalle-kaukonen, keith-rule, kerberos, kevan-stannard, kevlin-henney, khronos, kumarrobotics, lcs-telegraphics, ldap-sdk-free-use, libgeotiff, libmib, libmng-2007, libsrv-1.0.2, lil-1, lilo, linux-devicedrivers, linuxbios, linuxhowtos, llnl, logica-1.0, lucre, make-human-exception, matt-gallagher-attribution, matthew-kwan, mattkruse, mediainfo-lib, mgopen-font-license, michael-barr, michigan-disclaimer, mit-1995, mit-license-1998, mit-modification-obligations, mit-nagy, mit-no-advert-export-control, mit-no-trademarks, mit-old-style, mit-old-style-sparse, mit-readme, mit-specification-disclaimer, mit-synopsys, mit-taylor-variant, mit-veillard-variant, mod-dav-1.0, motorola, mpeg-iso, mpeg-ssg, ms-sspl, ms-ws-routing-spec, msj-samplecode, mulanpsl-1.0-en, mulanpsl-2.0-en, mulle-kybernetik, musl-exception, mx4j, netcat, netcomponents, netron, newlib-historical, newran, nice, niels-ferguson, nilsson-historical, nist-srd, node-js, nonexclusive, nortel-dasa, notre-dame, nrl-permission, ntlm, ntpl-origin, nvidia, nvidia-2002, nvidia-gov</title>
		<ptr target="paul-mackerras,paul-mackerras-binary,paul-mackerras-new,paul-mackerras-simplified,paulo-soares,paypal-sdk-2013-2016,pcre,pd-mit,pd-programming,perl-1.0,peter-deutsch-document,philippe-de-muyter" />
	</analytic>
	<monogr>
		<title level="m">gdcl, geoff-kuenning-1993, ghostpdl-permissive, glut, good-boy, greg-roelofs, gregory-pietsch, gtpl-v1, gtplv2, gtpl-v3, happy-bunny, hdf4, hdf5, hdparm, hidapi, historical-ntp, homebrewed, hp-snmp-pp, html5, httpget, ian-kaplan, ian-piumarta, ibm-as-is, ibm-dhcp, ibm-icu, ibm-nwsc, ibm-sample, ibpp, icot-free, idt-notice, ietf, ietf-trust, ilmid, indiana-extreme, infineon-free, info-zip</title>
		<title level="s">boostoriginal, boutell-libgd-2021, bpmn-io, brent-corkum, brian-clapper, brian-gladman, brian-gladman-3-clause, broadcom-cfe, broadcom-linux-timer, brocade-firmware, bruno-podetti, bsd-1-clause-build, bsd-1988, bsd-2-clause-plus-advertizing, bsd-3-clause-devine, bsd-3-clause-fda, bsd-3-clause-jtag, bsd-3-clause-</title>
		<editor>
			<persName><surname>Apple-Attribution-1997</surname></persName>
		</editor>
		<editor>
			<persName><surname>Atkinson-Hyperlegible-Font</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1995-02-01">3dslicer-1.0, 4suite-1.1. bakoma-fonts-1995, bea-2.1, beal-screamer, beri-hw-sw-1.0, bigdigits, bigelow-holmes, biopython, bitzi-pd, blas-2017, bohl-0.2. , cosl, cpm-2022, cpp-core-guidelines, crcalc, cryptopp, csprng, cve-tou, cwe-tou, cximage, d-zlib, damail, dante-treglia, dbad-1.1, delorie-historical, dhtmlab-public, dl-de-by-1-0-de, dl-de-by-1-0-en, dl-de-by-2-0-en, dmalloc, dmtf-2017, docbook, douglas-young, drl-1.1, dropbear, dropbear-2016, dtree, dwtfnmfpl-3.0. -1997-10, info-zip-2001-01, info-zip-2002-02, info-zip-2003-05, info-zip-2004-05, info-zip-2005-02, info-zip-2007-03, info-zip-2009-01,</date>
		</imprint>
	</monogr>
	<note>, dynamic-drive-tou, ecfonts-1.0, egenix-1.0.0, ellis-lab, emit, emx-library, energyplus-bsd, epaperpress, eric-glass, errbot-exception, etalab-2.0-en, fabien-tassin, far-manager-exception, fastbuild-2012-2020, fatfs, fftpack-2004, filament-group-mit, flex-2.5, flora-1.1, font-alias, fpl, fplot, fraunhofer-iso-14496-10, free-art-1.3, freebsdboot, freebsd-first, freemarker, fsf-notice, fujion-exception-to-apache-2.0, gareth-mccaughan, gary-s-brown ScanCode-specific license IDs LicenseRef-scancode-{3com-microcode no-change, bsd-3-clause-no-trademark, bsd-3-clause-sun, bsd-ack-carrot2, bsd-artwork, bsd-atmel, bsd-axis-nomod, bsd-credit, bsd-dpt, bsd-export, bsd-innosys, bsd-mylex, bsd-new-derivative, bsd-new-nomod, bsd-new-tcpdump, bsd-nodisclaimer, bsd-no-disclaimer-unmodified, bsd-original-muscle, bsd-original-voices, bsd-plus-mod-notice, bsdsimplified-darwin, bsd-simplified-intel, bsd-simplified-source, bsd-top, bsd-top-gpl-addition, bsd-unchanged, bsd-unmodified, bsd-x11, bsla-no-advert, bytemark, can-ogl-alberta-2.1, can-ogl-british-columbia-2.0, can-oglnova-scotia-1.0, can-ogl-ontario-1.0, can-ogl-toronto-1.0, careware, carnegie-mellon, cavium-malloc, cc-by-2.0uk, cecill-b-en, cern-attribution-1995, cgic, chicken-dl-0.2, chris-maunder, chris-stoy, classic-vb, clear-bsd-1clause, click-license, cmu-mit, cmu-simple, cmu-template, code-credit-license-1.0.1, code-credit-license-1.1.0, codeguru-permissions, codesourcery-2004, commonj-timer, compass, componentace-jcraft, compuphase-linkingexception nwhm, nysl-0.9982, nysl-0.9982-jp, o-young-jong, oasis-ws-security-spec, object-form-exception-to-mit, odl, odmg, ogc, ogl-1.0a, ogl-canada-2.0-fr, ogl-wpd-3.0, openmarket-fastcgi, openorb-1.0, opensaml-1.0, openssl, opml-1.0, opnl-1.0, opnl-2.0, oreilly-notice, oswego-concurrent, other-permissive, owtchart, ozplb-1.0, ozplb-1.1, paolomessina-2000, paraview-1.2, patent-disclaimer phorum-2.0, php-2.0.2, pine, pngsuite, politepix-pl-1.0, ppp, protobuf, psf-3</note>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">rsa-1990, rsa-cryptoki, rsa-demo, rsa-md4, rtools-util, rute, ryszard-szopa, saas-mit, saf, sash, sata, sbia-b, scancode-acknowledgment, scanlogd-license, scansoft-1.2, scintilla, scribbles, script-asylum, secret-labs-2011, service-comp-arch, sgi-cid-1.0, sgi-glx-1.0, sglib, shital-shah, simpl-1.1, softfloat, softfloat-2.0, softsurfer, sparky, speechworks-1.1, ssleay, ssleay-windows, stanford-pvrg, stlport-2000, stlport-4.5, streambenchmark, stu-nicholls, sun-rpc, sun-source, sunsoft, supervisor, svndiff, swig, symphonysoft, synopsys-mit, synthesis-toolkit, takao-abe, takuya-ooura, tcg-spec-license-v1, tekhvc, tested-software, tex-live, things-imade-public-license, tiger-crypto, tigra-calendar-3.2, tigra-calendar-4.0, tim-janik-2003, timestamp-picker, tso-license, ttcl, ttyp0, tumbolia, twisted-snmp, ubc, unicode, unicode-icu-58, unicode-mappings, unlimitedbinary-use-exception, unpbook, us-govt-unlimited-rights, usrobotics-permissive, utopia, vcalendar, vince, visual-idiot, visual-numerics, vixie-cron, w3c-03-bsd-license, westhawk, whistle, whitecat, wide-license, williamalexander, wingo, wol, wordnet, wrox, ws-addressing-spec, ws-policy-specification, ws-trust-specification</title>
	</analytic>
	<monogr>
		<title level="s">quirksmode, radvd, red-hat-attribution, red-hat-bsd-simplified, reportbug, ricebsd, richardblack, robert-hubley,</title>
		<imprint/>
	</monogr>
	<note>freesoft, purdue-bsd, pybench, pycrypto, pygres-2.2, python-cwi, qlogic-microcode, qpopper, qualcomm-turing wtfnmfpl-1.0, wxwidgets, wxwindows-u-3.0, x11-acer, x11-adobe, x11-adobe-dec, x11-dec1, x11-dec2, x11-doc</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
