- **Objective**: Identify gaps between model predictions \( p_\theta(Y|X) \) and true distribution \( p(Y|X) \) to avoid hallucinations and unsafe actions.
  
- **Key Concept**: Distinguish between aleatoric uncertainty (inherent variability) and epistemic uncertainty (lack of knowledge).

- **Proposed Method**: Train models to predict pairs of independent responses \( (Y_1, Y_2) \) for each input \( X \), allowing the model to "cheat" by observing one response while predicting the other.

- **Second-Order Calibration**: A model is second-order calibrated if it can report the covariance of the true probabilities \( p(Y|X) \) around its predictions, providing a measure of uncertainty.

- **Cheating as a Metric**: The extent to which a model "cheats" (improves predictions by observing another response) indicates its knowledge gaps. 

- **Confidence Intervals**: Construct confidence intervals for \( p(Y|X) \) using second-order calibration, allowing for reliable detection of incorrect responses.

- **Statistical Hallucination Tests**: Develop tests to identify responses with \( p(Y|X) = 0 \) based on the model's predictions and the observed pairs.

- **Training Modification**: Implement a simple modification to standard maximum likelihood training to incentivize second-order calibration.

- **Empirical Validation**: Demonstrate effectiveness on datasets like CIFAR-10H and tasks in synthetic language modeling and partially-observable navigation.

- **Comparison with Existing Techniques**: Show that existing epistemic uncertainty quantification methods often fail to be second-order calibrated, especially under model misspecification.

- **Grouping Loss**: Define grouping loss as the error from averaging predictions across inputs with different true probabilities, which can lead to misleading confidence estimates.

- **Equivalence of Calibration**: Prove that second-order calibration is equivalent to ordinary calibration when using pairs of responses.

- **Application**: Use paired responses to construct nontrivial confidence intervals for binary outcomes without assumptions about the form of \( p(Y|X) \).

- **Diagrammatic Representation**: 
```mermaid
flowchart TD
    A[Model Training] --> B[Predict Pairs (Y1, Y2)]
    B --> C[Allow Cheating]
    C --> D[Measure Cheating]
    D --> E[Estimate Gaps]
    E --> F[Construct Confidence Intervals]
    F --> G[Statistical Hallucination Tests]
```

- **Key Findings**: Pair-based variance estimates are empirically second-order well-calibrated, outperforming existing uncertainty quantification methods with minimal data format changes.