Hereâ€™s a detailed technical explanation and rationale for the decisions made by researchers in the context of proactive agents for multi-turn text-to-image (T2I) generation under uncertainty:

### 1. Decision to Implement Proactive Clarification Questions in T2I Agents
**Rationale:** Users often provide vague or incomplete prompts, leading to suboptimal image generation. By implementing proactive clarification questions, T2I agents can actively engage users to refine their requests, reducing ambiguity and improving the quality of generated images. This approach fosters a more interactive and collaborative experience, allowing the agent to better align with the user's intent.

### 2. Choice of Belief Graph as a Representation of Agent's Understanding
**Rationale:** A belief graph serves as a structured representation of the agent's understanding of user intent, capturing entities, attributes, and relationships. This graph-based approach allows the agent to visualize uncertainty and make informed decisions about which aspects of the prompt require clarification. It enhances interpretability, enabling users to see how their input influences the agent's understanding.

### 3. Selection of LLM for Generating Questions and Updating Prompts
**Rationale:** Large Language Models (LLMs) are adept at natural language understanding and generation, making them suitable for formulating clarification questions and updating prompts based on user feedback. Their ability to generate contextually relevant and coherent text helps maintain a smooth interaction flow, ensuring that the agent can effectively communicate with users.

### 4. Design of the User Interface for Interaction with Belief Graphs
**Rationale:** A user-friendly interface is crucial for facilitating interaction with belief graphs. The design prioritizes clarity and accessibility, allowing users to easily view and edit the agent's understanding of their intent. This transparency empowers users to take control of the generation process, enhancing their overall experience and satisfaction.

### 5. Strategy for Determining Which Attributes to Clarify First
**Rationale:** The strategy focuses on identifying the most uncertain attributes within the belief graph. By prioritizing clarification of these attributes, the agent can efficiently reduce ambiguity and improve the accuracy of generated images. This targeted approach minimizes the number of questions asked while maximizing the relevance of the information gathered.

### 6. Method for Evaluating the Effectiveness of T2I Agents
**Rationale:** The effectiveness of T2I agents is evaluated through a combination of automated evaluations and human studies. Automated evaluations assess the agents' performance in simulated interactions, while human studies provide insights into user satisfaction and perceived utility. This dual approach ensures a comprehensive understanding of the agents' capabilities and areas for improvement.

### 7. Decision to Create the DesignBench Benchmark for Evaluation
**Rationale:** DesignBench was created to provide a standardized evaluation framework for T2I agents, focusing on diverse and aesthetically rich scenes. This benchmark allows for consistent assessment of agent performance across various scenarios, facilitating comparisons with other T2I systems and promoting advancements in the field.

### 8. Choice of Datasets (COCO, ImageInWords) for Testing
**Rationale:** The COCO dataset is widely recognized for its rich annotations and diverse imagery, making it suitable for evaluating T2I agents. ImageInWords complements this by providing high-quality captions that enhance prompt generation. Together, these datasets enable comprehensive testing of the agents' capabilities in generating images from varied prompts.

### 9. Approach to Handle User Intent Ambiguity in Prompts
**Rationale:** The proactive questioning strategy is designed to address user intent ambiguity by seeking clarification on uncertain aspects of the prompt. This method allows the agent to iteratively refine its understanding, ensuring that the generated images align more closely with the user's expectations.

### 10. Decision to Modularize the Agent's Architecture for Component Updates
**Rationale:** A modular architecture allows for flexibility and scalability in the development of T2I agents. By decoupling components, researchers can easily update or replace individual parts (e.g., question-asking strategies, LLMs) without overhauling the entire system. This design choice promotes continuous improvement and adaptation to new advancements in technology.

### 11. Strategy for Integrating User Feedback into the Belief Graph
**Rationale:** User feedback is integrated into the belief graph to refine the agent's understanding of intent. This iterative process ensures that the agent's beliefs evolve based on real user interactions, enhancing the accuracy of subsequent image generations and fostering a more personalized experience.

### 12. Choice of Metrics (e.g., VQAScore) for Assessing Image-Prompt Alignment
**Rationale:** VQAScore is selected as a metric for evaluating the alignment between generated images and user prompts due to its ability to quantify the quality of image generation in relation to user intent. This metric provides a clear and objective measure of the agent's performance, facilitating comparisons across different systems.

### 13. Decision to Conduct Both Human Studies and Automated Evaluations
**Rationale:** Combining human studies with automated evaluations provides a holistic view of the T2I agents' effectiveness. Human studies capture subjective user experiences and preferences, while automated evaluations offer