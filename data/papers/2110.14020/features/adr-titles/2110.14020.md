- Decision on the experimental paradigm: Tandem vs. Forked Tandem
- Choice of reinforcement learning algorithm: Double-DQN
- Selection of environments for empirical analysis: Atari games and Classic Control domains
- Strategy for data distribution management in training
- Approach to handling bootstrapping in passive learning
- Method for evaluating agent performance: evaluation steps and metrics
- Decision on the architecture of the active and passive agents
- Choice of hyperparameters for training the agents
- Framework for analyzing the tandem effect and its contributing factors
- Decision on the number of training iterations and steps per iteration
- Approach to managing randomness and seed variation in experiments
- Strategy for documenting and reporting experimental results
- Decision on the use of confidence intervals in result presentation
- Choice of methods for mitigating extrapolation error
- Framework for comparing active and passive agent performance
- Decision on the role of self-generated data in training
- Approach to analyzing the impact of dataset size and diversity
- Decision on the interpretation of results in the context of existing literature
- Strategy for future work and potential extensions of the research