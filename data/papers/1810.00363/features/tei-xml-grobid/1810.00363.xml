<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Kernel Perspective for Regularizing Deep Neural Networks</title>
				<funder ref="#_v3egGXK">
					<orgName type="full">European Research Council</orgName>
					<orgName type="abbreviated">ERC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Alberto</forename><surname>Bietti</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Equal contribution</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Univ. Grenoble Alpes</orgName>
								<address>
									<settlement>Inria</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Grégoire</forename><surname>Mialon</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Equal contribution</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Univ. Grenoble Alpes</orgName>
								<address>
									<settlement>Inria</settlement>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">LJK</orgName>
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">Grenoble INP</orgName>
								<address>
									<postCode>38000</postCode>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dexiong</forename><surname>Chen</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Univ. Grenoble Alpes</orgName>
								<address>
									<settlement>Inria</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Julien</forename><surname>Mairal</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Univ. Grenoble Alpes</orgName>
								<address>
									<settlement>Inria</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="laboratory">Département d&apos;informatique de l&apos;ENS</orgName>
								<orgName type="institution" key="instit1">ENS</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<postCode>75005</postCode>
									<settlement>Paris</settlement>
									<region>Inria, PSL</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Kernel Perspective for Regularizing Deep Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">843D89962EE990A4ADE5C25C35F146AA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-02-21T16:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a new point of view for regularizing deep neural networks by using the norm of a reproducing kernel Hilbert space (RKHS). Even though this norm cannot be computed, it admits upper and lower approximations leading to various practical strategies. Specifically, this perspective (i) provides a common umbrella for many existing regularization principles, including spectral norm and gradient penalties, or adversarial training, (ii) leads to new effective regularization penalties, and (iii) suggests hybrid strategies combining lower and upper bounds to get better approximations of the RKHS norm. We experimentally show this approach to be effective when learning on small datasets, or to obtain adversarially robust models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Learning predictive models for complex tasks often requires large amounts of annotated data. For instance, convolutional neural networks are huge-dimensional and typically involve more parameters than training samples, which raises several challenges: achieving good generalization with small datasets is indeed difficult, which limits the deployment of such deep models to many tasks where labeled data is scarce, e.g., in biology <ref type="bibr" target="#b11">(Ching et al., 2018)</ref>. Besides, imperceptible adversarial perturbations can significantly degrade the prediction quality <ref type="bibr" target="#b43">(Szegedy et al., 2013;</ref><ref type="bibr" target="#b8">Biggio &amp; Roli, 2018)</ref>. These issues raise the question of regularization as an essential tool to control the complexity of deep models, as well as their stability to small variations of their inputs.</p><p>In this paper, we present a new perspective on regularization of deep networks, by viewing convolutional neural networks (CNNs) as elements of a RKHS following the work of <ref type="bibr" target="#b7">Bietti &amp; Mairal (2019)</ref> on deep convolutional kernels. For such kernels, the RKHS contains indeed deep convolutional networks similar to generic ones-up to smooth approximations of rectified linear units. Such a point of view provides a natural regularization function, the RKHS norm, which allows us to control the variations of the predictive model and to limit its complexity for better generalization. Besides, the norm also acts as a Lipschitz constant, which provides a direct control on the stability to adversarial perturbations.</p><p>In contrast to traditional kernel methods, the RKHS norm cannot be explicitly computed in our setup. Yet, this norm admits numerous approximations-lower bounds and upper bounds-which lead to many strategies for regularization based on penalties, constraints, or combinations thereof. Depending on the chosen approximation, we recover then many existing principles such as spectral norm regularization <ref type="bibr" target="#b12">(Cisse et al., 2017;</ref><ref type="bibr">Yoshida &amp; Miyato, 2017;</ref><ref type="bibr">Miyato et al., 2018a;</ref><ref type="bibr" target="#b37">Sedghi et al., 2019)</ref>, gradient penalties and double backpropagation <ref type="bibr" target="#b13">(Drucker &amp; Le Cun, 1991;</ref><ref type="bibr" target="#b39">Simon-Gabriel et al., 2019;</ref><ref type="bibr" target="#b17">Gulrajani et al., 2017;</ref><ref type="bibr" target="#b33">Roth et al., 2017;</ref><ref type="bibr" target="#b11">2018;</ref><ref type="bibr" target="#b2">Arbel et al., 2018)</ref>, adversarial training <ref type="bibr" target="#b26">(Madry et al., 2018)</ref>, and we also draw links with tangent propagation <ref type="bibr" target="#b38">(Simard et al., 1998)</ref>. For all these principles, we provide a unified viewpoint and theoretical insights, and we also introduce new variants, which we show are effective in practice when learning with few labeled data, or in the presence of adversarial perturbations.</p><p>Moreover, regularization and robustness are tightly linked in our kernel framework. Specifically, some lower bounds on the RKHS norm lead to robust optimization objectives with worst-case 2 perturbations; further, we can extend marginbased generalization bounds in the spirit of <ref type="bibr" target="#b4">Bartlett et al. (2017)</ref>; <ref type="bibr" target="#b10">Boucheron et al. (2005)</ref> to the setting of adversarially robust generalization (see <ref type="bibr" target="#b35">Schmidt et al., 2018)</ref>, where an adversary can perturb test data. We also discuss connections between recent regularization strategies for training generative adversarial networks and approaches to generative modeling based on kernel two-sample tests (MMD) <ref type="bibr" target="#b14">(Dziugaite et al., 2015;</ref><ref type="bibr" target="#b23">Li et al., 2017;</ref><ref type="bibr" target="#b9">Bińkowski et al., 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary of the contributions.</head><p>• We introduce an RKHS perspective for regularizing deep neural networks models which provides a unified view on various practical regularization principles, together with theoretical insight and guarantees; arXiv:1810.00363v4 [stat.ML] 13 May 2019</p><p>• By considering lower bounds to the RKHS norm, we obtain new penalties based on adversarial perturbations, adversarial deformations, or gradient norms of prediction functions, which we show to be effective in practice;</p><p>• Our RKHS point of view suggests combined strategies based on both upper and lower bounds, which we show often perform empirically best in the context of generalization from small image and biological datasets, by providing a tighter control of the RKHS norm.</p><p>Related work. The construction of hierarchical kernels and the study of neural networks in the corresponding RKHS was studied by <ref type="bibr" target="#b27">Mairal (2016)</ref>; <ref type="bibr" target="#b19">Zhang et al. (2016;</ref><ref type="bibr">2017)</ref>; <ref type="bibr" target="#b7">Bietti &amp; Mairal (2019)</ref>. Some of the regularization strategies we obtain from our kernel perspective are variants of previous approaches to adversarial robustness <ref type="bibr" target="#b12">(Cisse et al., 2017;</ref><ref type="bibr" target="#b26">Madry et al., 2018;</ref><ref type="bibr" target="#b39">Simon-Gabriel et al., 2019;</ref><ref type="bibr" target="#b34">Roth et al., 2018)</ref>, to improving generalization <ref type="bibr" target="#b13">(Drucker &amp; Le Cun, 1991;</ref><ref type="bibr">Miyato et al., 2018b;</ref><ref type="bibr" target="#b37">Sedghi et al., 2019;</ref><ref type="bibr" target="#b38">Simard et al., 1998;</ref><ref type="bibr">Yoshida &amp; Miyato, 2017)</ref>, and stable training of generative adversarial networks <ref type="bibr" target="#b33">(Roth et al., 2017;</ref><ref type="bibr" target="#b17">Gulrajani et al., 2017;</ref><ref type="bibr" target="#b2">Arbel et al., 2018;</ref><ref type="bibr">Miyato et al., 2018a)</ref>. The link between robust optimization and regularization was studied by <ref type="bibr">Xu et al. (2009a;</ref><ref type="bibr">b)</ref>, focusing mainly on linear models with quadratic or hinge losses. The notion of adversarial generalization was considered by <ref type="bibr" target="#b35">Schmidt et al. (2018)</ref>, who provide lower bounds on a particular data distribution. <ref type="bibr" target="#b41">Sinha et al. (2018)</ref> provide generalization guarantees in the different setting of distributional robustness; compared to our bound, they consider expected loss instead of classification error, and their bounds do not highlight the dependence on the model complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Regularization of Deep Neural Networks</head><p>In this section, we recall the kernel perspective on deep networks introduced by <ref type="bibr" target="#b7">Bietti &amp; Mairal (2019)</ref>, and present upper and lower bounds on the RKHS norm of a given model, leading to various regularization strategies. For simplicity, we first consider real-valued networks and binary classification, before discussing multi-class extensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Relation between deep networks and RKHSs</head><p>Kernel methods consist of mapping data living in a set X to a RKHS H associated to a positive definite kernel K through a mapping function Φ : X → H, and then learning simple machine learning models in H. Specifically, when considering a real-valued regression or binary classification problem, classical kernel methods find a prediction function f : X → R living in the RKHS which can be written in linear form, i.e., such that f (x) = f, Φ(x) H for all x in X . While explicit mapping to a possibly infinitedimensional space is of course only an abstract mathematical operation, learning f can be done implicitly by com-puting kernel evaluations and typically by using convex programming <ref type="bibr" target="#b36">(Schölkopf &amp; Smola, 2001)</ref>.</p><p>Moreover, the RKHS norm f H acts as a natural regularization function, which controls the variations of model predictions according to the geometry induced by Φ:</p><formula xml:id="formula_0">|f (x) -f (x )| ≤ f H • Φ(x) -Φ(x ) H .</formula><p>(1)</p><p>Unfortunately, our setup does not allow us to use the RKHS norm in a traditional way since evaluating the kernel is intractable. Instead, we propose a different approach that considers explicit parameterized representations of functions contained in the RKHS, given by generic CNNs, and leverage properties of the RKHS and the kernel mapping in order to regularize when learning the network parameters.</p><p>Consider indeed a real-valued deep convolutional network f : X → R, where X is simply R d , with rectified linear unit (ReLU) activations and no bias units. By constructing an appropriate multi-layer hierarchical kernel, <ref type="bibr" target="#b7">Bietti &amp; Mairal (2019)</ref> show that the corresponding RKHS H contains a CNN with the same architecture and parameters as f , but with activations that are smooth approximations of ReLU.</p><p>Although the model predictions might not be strictly equal, we will abuse notation and denote this approximation with smooth ReLU by f as well, with the hope that the regularization procedures derived from the RKHS model will be effective in practice on the original CNN f .</p><p>Besides, the mapping Φ(•) is shown to be non-expansive:</p><formula xml:id="formula_1">Φ(x) -Φ(x ) H ≤ x -x 2 ,<label>(2)</label></formula><p>so that controlling f H provides some robustness to additive 2 -perturbations, by (1). Additionally, with appropriate pooling operations, <ref type="bibr" target="#b7">Bietti &amp; Mairal (2019)</ref> show that the kernel mapping is also stable to deformations, meaning that the RKHS norm also controls robustness to translations and other transformations including scaling and rotations, which can be seen as deformations when they are small.</p><p>In contrast to standard kernel methods, where the RKHS norm is typically available in closed form, this norm is difficult to compute in our setup, and requires approximations. The following sections present upper and lower bounds on f H , with linear convolutional operations denoted by W k for k = 1, . . . , L, where L is the number of layers. Defining θ := {W k : k = 1, . . . , L}, we then leverage these bounds to approximately solve the following penalized or constrained optimization problems on a training set (x i , y i ), i = 1, . . . , n:</p><formula xml:id="formula_2">min θ 1 n n i=1 (y i , f θ (x i )) + λ f θ 2 H or (3) min θ: f θ H ≤C 1 n n i=1 (y i , f θ (x i )).<label>(4)</label></formula><p>We also note that while the construction of <ref type="bibr" target="#b7">Bietti &amp; Mairal (2019)</ref> considers VGG-like networks <ref type="bibr" target="#b40">(Simonyan &amp; Zisserman, 2014)</ref>, the regularization algorithms we obtain in practice can be easily adapted to different architectures such as residual networks <ref type="bibr" target="#b19">(He et al., 2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Exploiting lower bounds of the RKHS norm</head><p>In this section, we devise regularization algorithms by leveraging lower bounds on f H , obtained by relying on the following variational characterization of Hilbert norms:</p><formula xml:id="formula_3">f H = sup u H ≤1 f, u H .</formula><p>At first sight, this definition is not useful since the set U = {u ∈ H : u H ≤ 1} may be infinite-dimensional and the inner products f, u H cannot be computed in general. Thus, we devise tractable lower bound approximations by considering smaller sets Ū ⊂ U .</p><p>Adversarial perturbation penalty. Thanks to the nonexpansiveness of Φ, we can consider the subset Ū ⊂ U defined as</p><formula xml:id="formula_4">Ū = {Φ(x + δ) -Φ(x) : x ∈ X , δ 2 ≤ 1}, leading to the bound f H ≥ f 2 δ := sup x∈X , δ 2≤1 f (x + δ) -f (x),<label>(5)</label></formula><p>which is reminiscent of adversarial perturbations. Adding a regularization parameter &gt; 0 in front of the norm then corresponds to different sizes of perturbations:</p><formula xml:id="formula_5">f H = sup u H ≤ f, u H ≥ sup x∈X , δ 2≤ f (x + δ) -f (x).</formula><p>(6) Using this lower bound or its square as a penalty in the objective (3) when training a CNN provides a way to regularize. Optimizing over adversarial perturbations has been useful to obtain robust models (e.g., the PGD method of <ref type="bibr" target="#b26">Madry et al., 2018</ref>); yet our approach differs in two important ways:</p><p>(i) it involves a penalty that is decoupled from the loss term such that in principle, our penalty could be used beyond the supervised empirical risk paradigm. In contrast, PGD optimizes the robust formulation (7) below, which fits training data while considering perturbations on the loss.</p><p>(ii) our penalty involves a global maximization problem on the input space X , as opposed to only maximizing on perturbations near training data. In practice, optimizing over X is however difficult and instead, we replace X by random mini-batches of examples, yielding further lower bounds on the RKHS norm. These examples may be labeled or not, in contrast to PGD that perturb labeled examples only. When using such a mini-batch, a gradient of the penalty can be obtained by first finding maximizers x, δ (where x is an element of the mini-batch and δ is a perturbation), and then computing gradients of f θ (x + δ) -f θ (x) with respect to θ by using back-propagation. In practice, we compute the perturbations δ for each example x by using a few steps of projected gradient ascent with constant step-lengths.</p><p>Robust optimization yields another lower bound. In some contexts, our penalized approach is related to solving the robust optimization problem</p><formula xml:id="formula_6">min θ 1 n n i=1 sup δ 2≤ (y i , f θ (x i + δ)),<label>(7)</label></formula><p>which is commonly considered for training adversarially robust classifiers <ref type="bibr" target="#b45">(Wong &amp; Kolter, 2018;</ref><ref type="bibr" target="#b26">Madry et al., 2018;</ref><ref type="bibr" target="#b32">Raghunathan et al., 2018)</ref>. In particular, <ref type="bibr">Xu et al. (2009b)</ref> show that the penalized and robust objectives are equivalent in the case of the hinge loss with linear predictors, when the data is non-separable. They also show the equivalence for kernel methods when considering the (intractable) full perturbation set U around each point in the RKHS Φ(x i ), that is, predictions f, Φ(x i ) + u H with u in U . Intuitively, when a training example (x i , y i ) is misclassified, we are in the "linear" part of the hinge loss, such that</p><formula xml:id="formula_7">sup u H ≤ (y i , f, Φ(x i ) + u H ) = (y i , f (x i )) + f H .</formula><p>For other losses such as the logistic loss, a regularization effect is still present even for correctly classified examples, though it may be smaller since the loss has a reduced slope for such points. This leads to an adaptive regularization mechanism that may automatically reduce the amount of regularization when the data is easily separable. However, the robust optimization approach might only encourage local stability around training examples, while the global quantity f H may become large in order to better fit the data. We note that a perfect fit of the data with large complexity does not prevent generalization (see, e.g., <ref type="bibr">Belkin et al., 2018a;</ref><ref type="bibr">b)</ref>; yet, such mechanisms are still poorly understood. Nevertheless, it is easy to show that the robust objective (7) lower bounds the penalized objective with penalty f H .</p><p>Gradient penalties. Taking Ū = { Φ(x)-Φ(y)</p><p>x-y 2 : x, y ∈ X }, which is a subset of U by Eq. (2)-it turns out that this is the same set as for adversarial perturbation penalties, since Φ is homogeneous <ref type="bibr" target="#b7">(Bietti &amp; Mairal, 2019)</ref> and X = R d -we obtain a lower bound based on the Lipschitz constant of f :</p><formula xml:id="formula_8">f H ≥ sup x,y∈X f (x) -f (y) x -y 2 ≥ ∇f := sup x∈X ∇f (x) 2 ,</formula><p>(8) where the second inequality becomes an equality when X is convex, and the supremum is taken over points where f is differentiable. Although we are unaware of previous work using this exact lower bound for a generic regularization penalty, we note that variants replacing the supremum over x by an expectation over data have been recently used to stabilize the training of generative adversarial networks <ref type="bibr" target="#b17">(Gulrajani et al., 2017;</ref><ref type="bibr" target="#b33">Roth et al., 2017)</ref>, and we provide insights in Section 3.2 on the benefits of RKHS regularization in such a setting. Related penalties have been considered in the context of robust optimization, for regularization or robustness, noting that a penalty based on the gradient of the loss function x → (y, f (x)) can give a good approximation of (7) when is small <ref type="bibr" target="#b13">(Drucker &amp; Le Cun, 1991;</ref><ref type="bibr" target="#b25">Lyu et al., 2015;</ref><ref type="bibr" target="#b34">Roth et al., 2018;</ref><ref type="bibr" target="#b39">Simon-Gabriel et al., 2019)</ref>.</p><p>Penalties based on deformation stability. We may also obtain new penalties by considering more exotic sets Ū = {Φ(x) -Φ(x) : x ∈ X , x is a small deformation of x}, where the amount of deformation is dictated by the stability bounds of <ref type="bibr" target="#b7">Bietti &amp; Mairal (2019)</ref> in order to ensure that Ū ⊂ U . More precisely, such bounds depend on the maximum displacement and Jacobian norm of the diffeomorphisms considered. These can be easily computed for various parameterized families of transformations, such as translations, scaling or rotations, leading to simple ways to control the regularization strength through the parameters of these transformations. One can also consider infinitesimal deformations from such parameterized transformations, which approximately yields the tangent propagation regularization strategy of <ref type="bibr" target="#b38">Simard et al. (1998)</ref>. These approaches are detailed in Appendix B. If instead we consider the robust optimization formulation (7), we obtain a form of data augmentation where transformations are optimized instead of sampled, as done by <ref type="bibr" target="#b15">(Engstrom et al., 2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Extensions to multiple classes and beyond</head><p>We now extend the regularization strategies based on lower bounds to multi-valued networks, in order to deal with multiple classes. For that purpose, we consider a multi-class penalty f 1 2</p><formula xml:id="formula_9">H + . . . + f K 2 H for an R K -valued function f = (f 1 , f 2 , . . . , f K ), and we define f 2 δ := K k=1 f k 2 δ and ∇f 2 := K k=1 ∇f k 2 ,</formula><p>where f k δ is the adversarial penalty (5), and ∇f k is defined in (8). For deformation stability penalties, we proceed in a similar manner, and for robust optimization formulations ( <ref type="formula" target="#formula_6">7</ref>), the extension is straightforward, given that multiclass losses such as cross-entropy can be directly optimized in an adversarial training or gradient penalty setup.</p><p>Finally, we note that while the kernel approach we introduce considers the Euclidian geometry in the input space, it is possible to consider heuristic alternatives for other geometries, such as ∞ perturbations, as discussed in Appendix D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Exploiting upper bounds with spectral norms</head><p>Instead of lower bounds, one may use instead the following upper bound from <ref type="bibr">Bietti &amp; Mairal (2019, Proposition 14)</ref>:</p><formula xml:id="formula_10">f H ≤ ω( W 1 , . . . , W L ),<label>(9)</label></formula><p>where ω is increasing in all of its arguments, and W k is the spectral norm of the linear operator W k . Here, we simply consider the spectral norm on the filters, given by W := sup x 2≤1 W x 2 . Other generalization bounds relying on similar quantities have been proposed for controlling complexity <ref type="bibr" target="#b4">(Bartlett et al., 2017;</ref><ref type="bibr" target="#b31">Neyshabur et al., 2018)</ref>, suggesting that using them for regularization is relevant even beyond our kernel perspective, as observed by <ref type="bibr" target="#b12">Cisse et al. (2017)</ref>; <ref type="bibr" target="#b37">Sedghi et al. (2019);</ref><ref type="bibr">Yoshida &amp; Miyato (2017)</ref>.</p><p>Extensions to multiple classes are simple to obtain by simply considering spectral norms up to the last layer.</p><p>Penalizing the spectral norms. One way to control the upper bound ( <ref type="formula" target="#formula_10">9</ref>) when learning a neural network f θ is to consider a regularization penalty based on spectral norms</p><formula xml:id="formula_11">min θ 1 n n i=1 (y i , f θ (x i )) + λ L l=1 W l 2 , (<label>10</label></formula><formula xml:id="formula_12">)</formula><p>where λ is a regularization parameter. To optimize this cost, one can obtain (sub)gradients of the penalty by computing singular vectors associated to the largest singular value of each W l . We consider the method of Yoshida &amp; Miyato (2017), which computes such singular vectors approximately using one or two iterations of the power method, as well as a more costly approach using the full SVD.</p><p>Constraining the spectral norms with a continuation approach. In the constrained setting, we want to optimize:</p><formula xml:id="formula_13">min θ 1 n n i=1 (y i , f θ (x i )) s.t. W l ≤ τ ; l ∈ 1, . . . , L ,</formula><p>where τ is a user-defined constraint. This objective may be optimized by projecting each W l in the spectral norm ball of radius τ after each gradient step. Such a projection is achieved by truncating the singular values to be smaller than τ (see Appendix C). We found that the loss was hardly optimized with this approach, and therefore introduce a continuation approach with an exponentially decaying schedule for τ reaching a constant τ 0 after a few epochs, which we found to be important for good empirical performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Combining upper and lower bounds.</head><p>One advantage of lower bound penalties is that they are independent of the model parameterization, making them flexible enough to use with more complex architectures. In addition, the connection with robust optimization can provide a useful mechanism for adaptive regularization. However, they do not provide a guaranteed control on the RKHS norm, unlike the upper bound strategies. This is particularly true for robust optimization approaches, which may favor small training loss and local stability over global stability through f H . Nevertheless, we observed that our new approaches based on separate penalties sometimes do help in controlling upper bounds as well (see Section 4).</p><p>While these upper bound strategies are useful for limiting model complexity, we found them empirically less effective for robustness (see Section 4.2). However, we observed that combining with lower bound approaches can overcome this weakness, perhaps due to a better control of local stability.</p><p>In particular, such combined approaches often provide the best generalization performance in small data scenarios, as well as better guarantees on adversarially robust generalization thanks to a tighter control of the RKHS norm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Theoretical Guarantees and Insights</head><p>In this section, we study how the kernel perspective allows us to extend standard margin-based generalization bounds to an adversarial setting in order to provide theoretical guarantees on adversarially robust generalization. We then discuss how our kernel approach provides novel interpretations for training generative adversarial networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Guarantees on adversarial generalization</head><p>While various methods have been introduced to empirically gain robustness to adversarial perturbations, the ability to generalize with such perturbations, also known as adversarial generalization <ref type="bibr" target="#b35">(Schmidt et al., 2018)</ref>, still lacks theoretical understanding. Margin-based bounds have been useful to explain the generalization behavior of learning algorithms that can fit the training data well, such as kernel methods, boosting and neural networks <ref type="bibr" target="#b22">(Koltchinskii &amp; Panchenko, 2002;</ref><ref type="bibr" target="#b10">Boucheron et al., 2005;</ref><ref type="bibr" target="#b4">Bartlett et al., 2017)</ref>. Here, we show how such arguments can be adapted to obtain guarantees on adversarial generalization, i.e., on the expected classification error in the presence of an 2 -bounded adversary, based on the RKHS norm of a learned model. For a binary classification task with labels in Y = {-1, 1} and data distribution D, we would like to bound the expected adversarial error of a classifier f , given for some &gt; 0 by err D (f, ) := P (x,y)∼D (∃ δ 2 ≤ : yf (x + δ) &lt; 0).</p><p>(11) Leveraging the fact that f is f H -Lipschitz, we now show how to further bound this quantity using empirical margins, following the usual approach to obtaining margin bounds for kernel methods (e.g., <ref type="bibr" target="#b10">Boucheron et al., 2005)</ref>. Consider a training dataset (x 1 , y 1 ), . . . ,</p><formula xml:id="formula_14">(x n , y n ) ∈ X × Y. Defining L γ n (f ) := 1 n n i=1 1{y i f (x i )</formula><p>&lt; γ}, we have the following bound, proved in Appendix E:</p><p>Proposition 1 (Adversarially robust margin bound). With probability 1 -δ over a dataset {(x i , y i )} i=1,...,n , we have, for all choices of γ &gt; 0 and f ∈ H,</p><formula xml:id="formula_15">err D (f, ) ≤ L γ+2 f H n (f ) + Õ f H B γ √ n ,<label>(12)</label></formula><p>where B =</p><formula xml:id="formula_16">1 n n i=1 K(x i , x i )</formula><p>and Õ hides a term depending logarithmically on f H , γ, and δ.</p><p>When = 0, we obtain the usual margin bound, while &gt; 0 yields a bound on adversarial error err D (f, ), for some neural network f learned from data. Note that other complexity measures based on products of spectral norms may be used instead of f H , as well as multi-class extensions, following <ref type="bibr" target="#b4">Bartlett et al. (2017)</ref>; <ref type="bibr" target="#b31">Neyshabur et al. (2018)</ref>. In concurrent work, <ref type="bibr" target="#b21">Khim &amp; Loh (2018)</ref>; Yin et al. ( <ref type="formula">2019</ref>) derive similar bounds in the context of fully-connected networks. In contrast to these works, which bound complexity of a modified function class, our bound uses the complexity of the original class and leverages smoothness properties of functions to derive the margin bound.</p><p>One can then study the effectiveness of a regularization algorithm by inspecting cumulative distribution (CDF) plots of the normalized margins γi = y i f (x i )/ f H , for different strengths of regularization (an example is given in Figure <ref type="figure" target="#fig_0">2</ref>, Section 4.2). According to the bound (12), one can assess expected adversarial error with -bounded perturbations by looking at the part of the plot to the right of γ = 2 . In particular, the value of the CDF at such a value of γ is representative of the bound for large n (since the second term is negligible), while for smaller n, the best bound is obtained for a larger value of γ, which also suggests that the right side of the plots is indicative of performance on small datasets.</p><p>When the RKHS norm can be well approximated, our bound provides a certificate on test error in the presence of adversaries. While such an approximation is difficult to obtain in general, the guarantee is most useful when lower and upper bounds of the RKHS norm are controlled together.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">New insights on generative adversarial networks</head><p>Generative adversarial networks (GANs) attempt to learn a generator neural network G φ : Z → X , so that the distribution of G φ (z) with z ∼ D z a noise vector resembles a data distribution D x . In this section, we discuss connections between recent regularization techniques for training GANs, and approaches to learning generative models based on a MMD criterion <ref type="bibr" target="#b16">(Gretton et al., 2012)</ref>, in view of our RKHS framework. Our goal is to provide a new insight on these methods, but not necessarily to provide a new one.</p><p>Various recent approaches have relied on regularization strategies on a discriminator network in order to improve the stability of GAN training and the quality of the produced samples. Some of these resemble the approaches presented in Section 2 such as gradient penalties <ref type="bibr" target="#b17">(Gulrajani et al., 2017;</ref><ref type="bibr" target="#b33">Roth et al., 2017)</ref> and spectral norm regularization <ref type="bibr">(Miyato et al., 2018a)</ref>. We provide an RKHS interpretation of these methods as optimizing an MMD distance with the convolutional kernel introduced in Section 2:</p><formula xml:id="formula_17">min φ sup f H ≤1 E x∼Dx [f (x)] -E z∼Dz [f (G φ (z))]. (13)</formula><p>When learning from an empirical distribution over n samples, the MMD criterion is known to have much better sample complexity than the Wasserstein-1 distance considered by <ref type="bibr" target="#b3">Arjovsky et al. (2017)</ref> for high-dimensional data such as images <ref type="bibr" target="#b42">(Sriperumbudur et al., 2012)</ref>. While the MMD approach has been used for training generative models, it generally relies on a generic kernel function, such as a Gaussian kernel, that appears explicitly in the objective <ref type="bibr" target="#b14">(Dziugaite et al., 2015;</ref><ref type="bibr" target="#b23">Li et al., 2017;</ref><ref type="bibr" target="#b9">Bińkowski et al., 2018)</ref>. Although using a learned feature extractor can improve this, the Gaussian kernel might be a poor choice when dealing with natural signals such as images, while the hierarchical kernel we consider in our paper is better suited for this type of data, by providing useful invariance and stability properties. Leveraging the variational form of the MMD (13) with this kernel suggests for instance using convolutional networks as the discriminator f , with constraints on the spectral norms in order to ensure f H ≤ C for some C, as done by <ref type="bibr">Miyato et al. (2018a)</ref> through normalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We tested the regularization strategies presented in Section 2 in the context of improving generalization on small datasets and training robust models. Our goal is to use common architectures used for large datasets and improve their performance in different settings through regularization. Our Pytorch implementation of the various strategies is available at <ref type="url" target="https://github.com/albietz/kernel_reg">https://github.com/albietz/kernel_reg</ref>.</p><p>For the adversarial training strategies, the inner maximization problems are solved using 5 steps of projected gradient ascent with constant step-lengths. In the case of the lower bound penalties f 2 δ and ∇f 2 , we also maximize over examples in the mini-batch, only considering the maximal element when computing gradients with respect to parameters. For the robust optimization problem (7), we use PGD with 2 perturbations, as well as the corresponding 2 (squared) gradient norm penalty on the loss. For the upper bound approaches with spectral norms (SNs), we consider the SN projection strategy with decaying τ , as well as the SN penalty (10), either using power iteration (PI) or a full SVD for computing gradients. We consider the datasets CIFAR10 and MNIST when using a small number of training examples, as well as 102 datasets of biological sequences that suffer from small sample size.</p><p>CIFAR10. In this setting, we use 1 000 and 5 000 examples of the CIFAR10 dataset, with or without data augmentation. We consider a VGG network <ref type="bibr" target="#b40">(Simonyan &amp; Zisserman, 2014)</ref> with 11 layers, as well as a residual network <ref type="bibr" target="#b19">(He et al., 2016)</ref> with 18 layers, which achieve 91% and 93% test accuracy respectively when trained on the full training set with standard data augmentation (horizontal flips + random crops). We do not use batch normalization layers in order to prevent any interaction with spectral norms. Each strategy derived in Section 2 is trained for 500 epochs using SGD with momentum and batch size 128, halving the step-size every 40 epochs. In order to study the potential effectiveness of each method, we assume that a reasonably large validation set is available to select hyper-parameters; thus, we keep 10 000 annotated examples for this purpose. We also show results using a smaller validation set in Appendix A.1.</p><p>Table <ref type="table" target="#tab_0">1</ref> shows the test accuracies on 1 000 examples for upper and lower bound approaches, as well as combined ones. We also include virtual adversarial training (VAT, <ref type="bibr">Miyato et al., 2018b)</ref>. We provide extended tables in Appendix A.1 with additional methods, other geometries, results for 5 000 examples, as well as hypothesis tests for comparing pairs of methods and assessing the significance of our findings. Overall, we find that the combined lower bound + SN constraints approaches often yield better results than either method separately. For lower bound approaches alone, we found our f 2 δ and ∇f 2 penalties to often work best, particularly without data augmentation, while robust optimization strategies can be preferable with data augmentation, perhaps thanks to the adaptive regularization effect discussed earlier, which may be helpful in this easier setting. Gradient penalties often outperform adversarial perturbation strategies, possibly because of the closed form gradients which may improve optimization. We also found that adversarial training strategies tend to poorly control SNs compared to gradient penalties, particularly PGD (see also Section 4.2). SN constraints alone can also work well in some cases, particularly for VGG architectures, and often outperform SN penalties. SN penalties can work well nevertheless and provide computational benefits when using the power iteration variant.</p><p>Infinite MNIST. In order to assess the effectiveness of lower bound penalties based on deformation stability, we consider the Infinite MNIST dataset <ref type="bibr" target="#b24">(Loosli et al., 2007)</ref>, which provides an "infinite" number of transformed generated examples for each of the 60 000 MNIST training digits. Here, we use a 5-layer VGG-like network with average pooling after each 3x3 convolution layer, in order to more closely match the architecture assumptions of <ref type="bibr" target="#b7">Bietti &amp; Mairal (2019)</ref> for deformation stability. We consider two lower bound penalties that leverage the digit transformations in Infinite MNIST: one based on "adversarial" deformations around each digit, denoted f 2 τ ; and a tangent propagation <ref type="bibr" target="#b38">(Simard et al., 1998)</ref> variant, denoted D τ f 2 , which provides an approximation to f 2 τ for small deformations based on gradients along a few tangent vector directions given by deformations (see Appendix B for details). Table <ref type="table" target="#tab_1">2</ref> shows the obtained test accuracy for subsets of MNIST of size 300 and 1 000. Overall, we find that combining both adversarial penalties f 2 τ and f 2 δ performs best, which suggests that it is helpful to obtain tighter lower approximations of the RKHS norm by considering perturbations of Table <ref type="table" target="#tab_5">3</ref>. Regularization on protein homology detection tasks, with or without data augmentation (DA). Fixed hyperparameters are selected using the first half of the datasets, and we report the average auROC50 score on the second half. See Section A.3 in the appendix for more details and statistical testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>No DA DA No weight decay 0.421 0.541 Weight decay 0.432 0.544 SN proj 0.583 0.615 PGD-2 0.488 0.554 grad-2 0.551 0.570 f 2 δ 0.577 0.611 ∇f 2 0.566 0.598 PGD-2 + SN proj 0.615 0.622 grad-2 + SN proj 0.581 0.634 f 2 δ + SN proj 0.631 0.639 ∇f 2 + SN proj 0.576 0.617</p><p>different kinds. Explicitly controlling the spectral norms can further improve performance, as does training on deformed digits, which may yield better margins by exploiting the additional knowledge that small deformations preserve labels. Note that data augmentation alone (with some weight decay) does quite poorly in this case, even compared to our lower bound penalties which do not use deformations.</p><p>Protein homology detection. Remote homology detection between protein sequences is an important problem to understand protein structure. Given a protein sequence, the goal is to predict whether it belongs to a superfamily of interest. We consider the Structural Classification Of Proteins (SCOP) version 1.67 dataset <ref type="bibr" target="#b30">(Murzin et al., 1995)</ref>, which we process as described in Appendix A.3 in order to obtain 102 balanced binary classification tasks with 100 protein sequences each, thus resulting in a low-sample regime. Protein sequences were also cut to 400 amino acids.</p><p>Sequences are represented with a one-hot encoding strategy-that is, a sequence of length l is represented as a binary matrix in {0, 1} 20×l , where 20 is the number of different amino acids (alphabet size of the sequences). Such a structure can then be processed by convolutional neural networks <ref type="bibr" target="#b0">(Alipanahi et al., 2015)</ref>. In this paper, we do not try to optimize the structure of the network for the task, since our goal is only to evaluate the effect of regularization strategies. Therefore, we use a simple convolutional network with 3 convolutional layers followed by global max-pooling and a final fully-connected layer (we use filters of size 5, and a max-pooling layer after the second convolutional layer).</p><p>Training was done using Adam with a learning rate fixed to 0.01, and a weight decay parameter tuned for each method. Since hyper-parameter selection per dataset is difficult due to the low sample size, we use the same parameters across datasets. This allows us to use the first 51 datasets as a validation set for hyper-parameter tuning, and we report</p><p>0.800 0.825 0.850 0.875 0.900 0.925 standard accuracy 0.76 0.78 0.80 0.82 0.84 0.86 adversarial accuracy 2 , test = 0.1 PGD-2 grad-2 |f| 2 | f| 2 PGD-2+ SN proj SN proj SN pen (SVD) clean 0.5 0.6 0.7 0.8 0.9 standard accuracy 0.1 0.2 0.3 0.4 0.5 2 , test = 1.0 Figure 1. Robustness trade-off curves of different regularization methods for VGG11 on CIFAR10. Each plot shows test accuracy vs adversarial test accuracy for 2-bounded, 40-step PGD adversaries with a fixed test. Different points on a curve correspond to training with different regularization strengths. The regularization increases monotonically along a given curve, and the leftmost points correspond to the strongest regularization. For PGD-2 + SN projection, we vary with a fixed τ = 0.8.</p><p>average performance with these fixed choices on the remaining 51 datasets. The standard performance measure for this task is the auROC50 score (area under the ROC curve up to 50% false positives). We note that the selection of hyperparameters has a transductive component, since some of the sequences in the test datasets may also appear in the datasets used for validation (possibly with a different label).</p><p>The results are shown in Table <ref type="table" target="#tab_5">3</ref>. The procedure used for data augmentation (right column) is described in Appendix A.3. We found that the most effective approach is the adversarial perturbation penalty, together with SN constraints. In particular, we found it to outperform the gradient penalty ∇f 2 , perhaps because in this case gradient penalties are only computed on a discrete set of possible points given by one-hot encodings, while adversarial perturbations may increase stability to wider regions, potentially covering different possible encoded sequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Training adversarially robust models</head><p>We consider the same VGG architecture as in Section 4.1, trained on CIFAR10 with data augmentation, with different regularization strategies. Each method is trained for 300 epochs using SGD with momentum and batch size 128, dividing the step-size in half every 30 epochs. This strategy was successful in reaching convergence for all methods.</p><p>Figure <ref type="figure">1</ref> shows the test accuracy of the different methods in the presence of 2 -bounded adversaries, plotted against standard accuracy. We can see that the robust optimization approaches tend to work better in high-accuracy regimes, perhaps because the local stability that they encourage is sufficient on this dataset, while the f 2 δ penalty can be useful in large-perturbation regimes. We find that upper bound approaches alone do not provide robust models, but combining the SN constraint approach with a lower bound strategy (in this case PGD-2 ) helps improve robustness perhaps thanks to a more explicit control of stability. The plots also confirm that gradient penalties on the loss may be preferable for small regularization strengths (they achieve higher accuracy while improving robustness for small test ), while for stronger regularization, the gradient approximation no longer holds and the adversarial training approaches such as PGD (and its combination with SN constraints) are preferred. More experiments confirming these findings are available in Section A.4 of the appendix.</p><p>Norm comparison and adversarial generalization. Note that for PGD, in contrast to other methods, we can see that the product of spectral norms (representative of an upper bound on f H ) increases when the lower bound f δ decreases. This suggests that a network learned with PGD with large may have large RKHS norm, possibly because the approach tries to separate -balls around the training examples, which may require a more complex model than simply separating the training examples (see also <ref type="bibr" target="#b26">Madry et al., 2018)</ref>. This large discrepancy between upper and lower bounds highlights the fact that such models may only be stable locally near training data, though this happens to be enough for robustness on many test examples on CIFAR10.</p><p>In contrast, for other methods, and in particular the lower bound penalties f 2 δ and ∇f 2 , the upper and lower bounds appear more tightly controlled, suggesting a more appropriate control of the RKHS norm. This makes our guarantees on adversarial generalization more meaningful, and thus we may look at the empirical distributions of normalized margins γ obtained using f δ for normalization (as an approximation of f H ), shown in Figure <ref type="figure" target="#fig_0">2</ref> (right). The curves suggest that for small γ, and hence small test , smaller values of λ are preferred, while stronger regularization helps for larger γ, yielding lower test error guarantees in the presence of stronger adversaries according to our bounds in Section 3.1. This qualitative behavior is indeed observed in the results of Figure <ref type="figure">1</ref> on test data for the ∇f 2 penalty. Yin, D., Ramchandran, K., and Bartlett, P. Rademacher complexity for adversarially robust generalization. In Proceedings of the International Conference on Machine Learning (ICML), 2019. Yoshida, Y. and Miyato, T. Spectral norm regularization for improving the generalizability of deep learning. arXiv preprint arXiv:1705.10941, 2017. Zhang, Y., Lee, J. D., and Jordan, M. I. 1 -regularized neural networks are improperly learnable in polynomial time. In Proceedings of the International Conference on Machine Learning (ICML), 2016. Zhang, Y., Liang, P., and Wainwright, M. J. Convexified convolutional neural networks. In Proceedings of the International Conference on Machine Learning (ICML), 2017.</p><p>Section A of this supplementary presents extended results from our experiments, along with statistical tests for assessing the significance of our findings. Section B details our lower bound penalties based on deformations and their relationship to tangent propagation. Section C presents our continuation algorithm for optimization with spectral norm constraints. Section D describes heuristic extensions of our lower bound regularization strategies to non-Euclidian geometries. Finally, Section E provides our proof of the margin bound of Proposition 1 for adversarial generalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Additional Experiment Results</head><p>A.1. CIFAR10</p><p>This section provides more extensive results for the experiments on CIFAR10 from Section 4.1. In particular, Table <ref type="table">4</ref> shows additional experiments on larger subsets of size 5 000, as well as more methods, including different geometries (see Appendix D). The table also reports results obtained when using a smaller validation set of size 1 000. The full hyper-parameter grid is given in Table <ref type="table">6</ref>.</p><p>In order to assess the statistical significance of our results, we repeated the experiments on 10 new random choices of subsets, using the hyperparameters selected on the original subset from Table <ref type="table">4</ref> (except for learning rate, which is selected according to a different validation set for each subset). We then compared pairs of methods using a paired t-test, with p-values shown in Table <ref type="table">5</ref>. In particular, the results strengthen some of our findings, for instance, that ∇f 2 should be preferred to the gradient penalty on the loss when there is no data augmentation, and that combined upper+lower bound approaches tend to outperform the individual upper or lower bound strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Infinite MNIST</head><p>We provide more extensive results for the Infinite MNIST dataset in Table <ref type="table" target="#tab_6">7</ref>, in particular showing more regularization strategies, as well as results with or without data augmentation, marked with ( * ). As in the case of CIFAR10, we use SGD with momentum (fixed to 0.9) for 500 epochs, with initial learning rates in [0.005; 0.05; 0.5], and divide the step-size by 2 every 40 epochs. The full hyper-parameter grid is given in Table <ref type="table" target="#tab_8">9</ref>.</p><p>As in the case of CIFAR10, we report statistical significance tests in Table <ref type="table" target="#tab_7">8</ref> comparing pairs of methods based on 10 different random choices of subsets. In particular, the results confirm that weight decay with data augmentation alone tends to give weaker results than separate penalties, and that the combined penalty f 2 τ + f 2 δ , which combines adversarial perturbations of two different types, outperforms each penalty taken by itself on a single type of perturbation, which emphasizes the benefit of considering perturbations of different natures, perhaps thanks to a tighter lower bound approximation of the RKHS norm. We note that grad-2 ( * ) worked well on some subsets, but poorly on others due to training instabilities, possibly because of the selected hyperparameters which are quite large (and thus likely violate the approximation to the robust optimization objective).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3. Protein homology detection</head><p>Dataset description. Our protein homology detection experiments consider the Structural Classification Of Proteins (SCOP) version 1.67 dataset <ref type="bibr" target="#b30">(Murzin et al., 1995)</ref>, filtered and split following the procedures of <ref type="bibr" target="#b18">(Håndstad et al., 2007)</ref>. Specifically, positive training samples are extracted from one superfamily from which one family is withheld to serve as positive test set, while negative sequences are chosen from outside of the target family's hold and are randomly split into training and test samples in the same ratio as positive samples. This yields 102 superfamily classification tasks, which are generally very class-imbalanced. For each task, we sample 100 class-balanced training samples to use as training set. The positive samples are extended to 50 with Uniref50 using PSI-BLAST <ref type="bibr" target="#b1">(Altschul et al., 1997)</ref> if they are fewer.</p><p>Data augmentation procedure. We consider in our experiments a discrete way of perturbing training samples to perform data augmentation. Specifically, for a given sequence, a perturbed sequence can be obtained by randomly changing some of the characters. Each character in the sequence is switched to a different one, randomly chosen from the alphabet, with some probability p. We fixed this probability to 0.1 throughout the experiments.</p><p>Experimental details and significance tests. In our experiments, we use the Adam optimization algorithm with a learning rate fixed to 0.01 (and β fixed to defaults (0.9, 0.999)), with a batch size of 100 for 300 epochs. The full hyper-parameter grid is given in Table <ref type="table" target="#tab_10">11</ref>. In addition to the average auROC50 scores reported in  comparing pairs of methods in Table <ref type="table" target="#tab_9">10</ref> in order to verify the significance of our findings. The results confirm that the adversarial perturbation penalty and its combination with spectral norm constraints tends to outperform the other approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4. Robustness</head><p>Figure <ref type="figure" target="#fig_2">3</ref> extends Figure <ref type="figure">1</ref> from Section 4.2 to show more methods, adversary strenghts, and different geometries. For combined (PGD-2 + SN projection) approaches, we can see that stronger constraints (i.e., smaller τ ) tend to reduce standard accuracy, likely because it prevents a good fit of the data, but can provide better robustness to strong adversaries ( test = 1). We can see that using the right metric in PGD indeed helps against an ∞ adversary, nevertheless controlling global stability through the RKHS norm as in the f 2 δ and ∇f 2 penalties can still provide some robustness against such adversaries, even with large test . For gradient penalties, we find that the different geometries behave quite similarly, which may suggest that more appropriate optimization algorithms than SGD could be needed to better accommodate the non-smooth case of  </p><formula xml:id="formula_18">2 τ + f 2 δ + SN proj ( * ) grad-2 ( * ) - 1e-02 grad-2 ( * ) f 2 τ + f 2 δ + SN proj ( * ) - - f 2 τ + f 2 δ f 2 δ penalty 1e-07 6e-09 f 2 τ + f 2 δ f 2 τ penalty 2e-06 6e-07 f 2 τ + f 2 δ ( * ) f 2 τ + f 2 δ 2e-03 - f 2 τ + f 2 δ + SN proj ( * ) f 2 τ + f 2 δ 2e-03 2e-04</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Details on Deformation Stability Penalties</head><p>This section provides more details on the deformation stability penalties mentioned in Section 2.2, and the practical versions we use in our experiments on the Infinite MNIST dataset <ref type="bibr" target="#b24">(Loosli et al., 2007)</ref>.</p><p>Stability to deformations. We begin by providing some background on deformation stability, recalling that these can provide new lower bound penalties as explained in Section 2.2. Viewing an element x ∈ X as a signal x(u), where u denotes the location (e.g. a two-dimensional vector for images), we denote by x τ a deformed version of x given by x τ (u) = x(u -τ (u)), where τ is a diffeomorphism. The deformation stability bounds of <ref type="bibr" target="#b7">Bietti &amp; Mairal (2019)</ref> take the form:</p><formula xml:id="formula_19">Φ(x τ ) -Φ(x) H ≤ (C 1 τ ∞ + C 2 ∇τ ∞ ) x ,<label>(14)</label></formula><p>where ∇τ (u) is the Jacobian of τ at location u. Here, C 1 controls translation invariance and typically decreases with the total amount of pooling (i.e., translation invariance more or less corresponds to the resolution at the final layer), while C 2 controls stability to deformations (note that ∇τ = 0 for translations) and is typically smaller when using small patches. We note that the bounds assume linear pooling layers with a certain spatial decay, adapted to the resolution of the current layer; our experiments on Infinite MNIST with deformation stability penalties thus use average pooling layers on 2x2 neighborhoods.</p><p>Adversarial deformation penalty. We can obtain lower bound penalties by exploiting the above stability bounds in a similar manner to the adversarial perturbation penalty introduced in Section 2.2. In particular, assuming a scalar-valued convolutional network f :</p><formula xml:id="formula_20">f 2 τ := sup x∈X ,τ ∈T (f (x τ ) -f (x)) 2 (15)</formula><p>where T is a collection of diffeomorphisms. When the diffeomorphisms in T have bounded norm τ ∞ and Jacobian norm ∇τ ∞ , and assuming X (or, in practice, the training data) is bounded, the stability bound 14 ensures that the set U T = {Φ(x τ ) -Φ(x) : x ∈ X , τ ∈ T } is included in an RKHS ball with some radius r, so that f τ is a lower bound on r f H .</p><p>Tangent gradient penalty. We also consider the following gradient penalty along tangent vectors, which provides an approximation of the above adversarial penalty when considering small, parameterized deformations, and recovers the tangent propagation strategy of <ref type="bibr" target="#b38">Simard et al. (1998)</ref>:</p><formula xml:id="formula_21">D τ f 2 := sup x∈X ∂ α f (x + i α i t x,i ) 2 , (<label>16</label></formula><formula xml:id="formula_22">)</formula><p>where {t x,i } i=1,...,q are tangent vectors at x obtained from a given set of deformations. To see the link with the adversarial deformation penalty 15, consider for simplicity a single deformation, T = {τ 0 }. For small α, we have</p><p>x ατ0 ≈ x + αt x , where t x (u) = τ 0 (u) • ∇x(u),</p><p>where t x denotes the tangent vector of the deformation manifold {ατ 0 : α} at α = 0 <ref type="bibr" target="#b38">(Simard et al., 1998)</ref>. Then,</p><formula xml:id="formula_23">f (x ατ0 ) -f (x) ≈ α∂ α f (x + αt x ) = α ∇f (x), t x .</formula><p>In this case, denoting αT = {ατ 0 }, we have</p><formula xml:id="formula_24">sup x∈X ,τ ∈αT (f (x τ ) -f (x)) 2 ≈ α 2 sup x∈X |∂ α f (x + αt x )| 2 ,</formula><p>so that when α is small, the adversarial penalty can be approximated by α D τ f (note that using αT instead of T in the adversarial penalty would also yield a scaling by α, since the stability bounds imply α times smaller perturbations in the RKHS).</p><p>Practical implementations on Infinite MNIST. In our experiments on Infinite MNIST, we compute f 2 τ by considering 32 random transformations of each digit in a mini-batch of training examples, and taking the maximum over both the example and the transformation. We do this separately for each class, as for the other lower bound penalties f 2 δ and ∇f 2 . For D τ f 2 , we take {t x,i } i=1,...,q with q = 30 to be tangent vectors given by random diffeomorphisms from Infinite MNIST around each example x.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. (left) Comparison of lower and upper bound quantities ( f δ vs the product of spectral norms). (right) CDF plot of normalized empirical margins for the ∇f 2 penalty with different regularization strengths, normalized by f δ . We consider 1000 fixed training examples when computing f δ .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><figDesc>Figure 2 (left) compares lower and upper bound quantities for different regularization strengths.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Robustness trade-off curves of different regularization methods for VGG11 on CIFAR10 (extended version of Figure 1). The plots show test accuracy vs adversarial test accuracy for 2-bounded (top/bottom) or ∞-bounded (middle), 40-step PGD adversaries with a fixed test. Different points on a curve correspond to training with different regularization strengths. The regularization increases monotonically along a given curve, and the leftmost points correspond to the strongest regularization. The bottom plots consider PGD-2 + SN projection, with different fixed values of the constraint radius τ , for varying in PGD.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Regularization on CIFAR10 with 1 000 examples for VGG-11 and ResNet-18. Each entry shows the test accuracy with/without data augmentation when all hyper-parameters are optimized on a validation set. See also Section A.1 in the appendix for additional results and statistical testing.</figDesc><table><row><cell>Method</cell><cell>1k VGG-11</cell><cell>1k ResNet-18</cell></row><row><cell>No weight decay</cell><cell cols="2">50.70 / 43.75 45.23 / 37.12</cell></row><row><cell>Weight decay</cell><cell cols="2">51.32 / 43.95 44.85 / 37.09</cell></row><row><cell>SN penalty (PI)</cell><cell cols="2">54.64 / 45.06 47.01 / 39.63</cell></row><row><cell>SN projection</cell><cell cols="2">54.14 / 46.70 47.12 / 37.28</cell></row><row><cell>VAT</cell><cell cols="2">50.88 / 43.36 47.47 / 42.82</cell></row><row><cell>PGD-2</cell><cell cols="2">51.25 / 44.40 45.80 / 41.87</cell></row><row><cell>grad-2</cell><cell cols="2">55.19 / 43.88 49.30 / 44.65</cell></row><row><cell>f 2 δ penalty ∇f 2 penalty</cell><cell cols="2">51.41 / 45.07 48.73 / 43.72 54.80 / 46.37 48.99 / 44.97</cell></row><row><cell cols="3">PGD-2 + SN proj 54.19 / 46.66 47.47 / 41.25</cell></row><row><cell>grad-2 + SN proj</cell><cell cols="2">55.32 / 46.88 48.73 / 42.78</cell></row><row><cell>f 2 δ + SN proj ∇f 2 + SN proj</cell><cell cols="2">54.02 / 46.72 48.12 / 43.56 55.24 / 46.80 49.06 / 44.92</cell></row><row><cell cols="3">4.1. Improving generalization on small datasets</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Regularization on 300 or 1 000 examples from MNIST, using deformations from Infinite MNIST. ( * ) indicates that random deformations were included as training examples, while f 2 τ and Dτ f 2 use them as part of the regularization penalty. See Section A.2 in the appendix for more results and statistical testing.</figDesc><table><row><cell>Method</cell><cell cols="2">300 VGG 1k VGG</cell></row><row><cell>Weight decay</cell><cell>89.32</cell><cell>94.08</cell></row><row><cell>SN projection</cell><cell>90.69</cell><cell>95.01</cell></row><row><cell>grad-2</cell><cell>93.63</cell><cell>96.67</cell></row><row><cell>f 2 δ penalty ∇f 2 penalty</cell><cell>94.17 94.08</cell><cell>96.99 96.82</cell></row><row><cell>Weight decay ( * )</cell><cell>92.41</cell><cell>95.64</cell></row><row><cell>grad-2 ( * )</cell><cell>95.05</cell><cell>97.48</cell></row><row><cell>Dτ f 2 penalty</cell><cell>94.18</cell><cell>96.98</cell></row><row><cell>f 2 τ penalty</cell><cell>94.42</cell><cell>97.13</cell></row><row><cell>f 2 τ + ∇f 2</cell><cell>94.75</cell><cell>97.40</cell></row><row><cell>f 2 τ + f 2 δ f 2 τ + f 2 δ ( * ) f 2 τ + f 2 δ + SN proj f 2 τ + f 2 δ + SN proj ( * )</cell><cell>95.23 95.53 95.20 95.40</cell><cell>97.66 97.56 97.60 97.77</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 ,</head><label>3</label><figDesc>we perform paired t-tests for</figDesc><table><row><cell cols="2">adversarial accuracy adversarial accuracy</cell><cell cols="2">0.800 0.825 0.850 0.875 0.900 0.925 0.750 0.775 0.800 0.825 0.850 0.875 0.900 2 , test = 0.03 PGD-2 PGD-|f| 2 | f| 2 grad-2 grad-1 SN proj SN pen (SVD) clean 0.5 0.6 0.7 0.8 0.9 0.50 0.55 0.60 0.65 0.70 0.75 0.80 , test = 1/255 PGD-2 PGD-|f| 2 | f| 2 grad-2 grad-1 SN proj SN pen (SVD) clean 0.45 2 , test = 0.03</cell><cell>0.800 0.825 0.850 0.875 0.900 0.925 0.82 0.84 2 , test = 0.1 0.86 0.80 0.78 0.76 0.50 0.55 0.60 0.65 , test = 2/255 0.70 0.45 0.5 0.6 0.7 0.8 0.9</cell><cell>0.70 0.65 0.60 0.55 0.50 0.45 0.5 0.1 0.2 0.3 0.4</cell><cell>0.5 0.5</cell><cell>2 , test = 0.3 0.6 0.7 0.8 , test = 5/255 0.6 0.7 0.8</cell><cell>0.9 0.9</cell><cell>0.5 0.4 0.3 0.2 0.1 0.1 0.2 0.3 0.0</cell><cell>0.5 0.5</cell><cell>2 , test = 1.0 0.6 0.7 0.8 , test = 8/255 0.6 0.7 0.8</cell><cell>0.9 0.9</cell></row><row><cell>adversarial accuracy</cell><cell cols="2">0.76 0.78 0.80 0.82 0.84 0.86 0.88</cell><cell>PGD-2+ SN proj = 1.0 = 1.2 = 1.4 = (PGD-2) clean</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">0.80 0.82 0.84 0.86 0.88 0.90 standard accuracy</cell><cell>0.80 0.82 0.84 0.86 0.88 0.90</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 .</head><label>7</label><figDesc>Test accuracies on subsets of MNIST using deformations from Infinite MNIST. Extended version of Table2. ( * ) indicates that random deformations were included as training examples (i.e., data augmentation), while f 2 τ and Dτ f 2 use them as part of the regularization penalty. As in Table4, we show results obtained using a validation set of size 10 000 (a) and 1 000 (b).</figDesc><table><row><cell cols="2">(a) 10k examples in validation set</cell><cell></cell><cell cols="2">(b) 1k examples in validation set</cell><cell></cell></row><row><cell>Method</cell><cell cols="2">300 VGG 1k VGG</cell><cell>Method</cell><cell cols="2">300 VGG 1k VGG</cell></row><row><cell>Weight decay</cell><cell>89.32</cell><cell>94.08</cell><cell>Weight decay</cell><cell>89.32</cell><cell>93.34</cell></row><row><cell>Weight decay ( * )</cell><cell>92.41</cell><cell>95.64</cell><cell>Weight decay ( * )</cell><cell>91.91</cell><cell>95.73</cell></row><row><cell>SN projection</cell><cell>90.69</cell><cell>95.01</cell><cell>SN projection</cell><cell>90.60</cell><cell>94.83</cell></row><row><cell>SN projection ( * )</cell><cell>92.17</cell><cell>95.88</cell><cell>SN projection ( * )</cell><cell>92.01</cell><cell>95.91</cell></row><row><cell>grad-2</cell><cell>93.63</cell><cell>96.67</cell><cell>grad-2</cell><cell>92.92</cell><cell>96.42</cell></row><row><cell>grad-2 ( * )</cell><cell>95.05</cell><cell>97.48</cell><cell>grad-2 ( * )</cell><cell>94.69</cell><cell>97.48</cell></row><row><cell>f 2 δ penalty f 2 δ penalty ( * ) ∇f 2 penalty</cell><cell>94.17 94.86 94.08</cell><cell>96.99 97.40 96.82</cell><cell>f 2 M penalty f 2 M penalty ( * ) ∇f 2 penalty</cell><cell>93.44 94.57 94.08</cell><cell>96.98 97.14 96.77</cell></row><row><cell>∇f 2 penalty ( * )</cell><cell>94.80</cell><cell>97.29</cell><cell>∇f 2 penalty ( * )</cell><cell>94.50</cell><cell>97.15</cell></row><row><cell>D τ f 2 penalty</cell><cell>94.18</cell><cell>96.98</cell><cell>D τ f 2 penalty</cell><cell>94.03</cell><cell>97.16</cell></row><row><cell>D τ f 2 penalty ( * )</cell><cell>94.91</cell><cell>97.29</cell><cell>D τ f 2 penalty ( * )</cell><cell>94.15</cell><cell>96.64</cell></row><row><cell>f 2 τ penalty f 2 τ penalty ( * ) f 2 τ + ∇f 2 f 2 τ + ∇f 2 ( * ) f 2 τ + f 2 δ f 2 τ + f 2 δ ( * )</cell><cell>94.42 94.83 94.75 95.14 95.23 95.53</cell><cell>97.13 97.25 97.40 97.44 97.66 97.56</cell><cell>f 2 τ penalty f 2 τ penalty ( * ) f 2 τ + ∇f 2 f 2 τ + ∇f 2 ( * ) f 2 τ + f 2 M f 2 τ + f 2 M ( * )</cell><cell>93.53 94.79 94.75 94.43 95.15 95.20</cell><cell>97.13 97.26 97.21 97.42 97.27 97.49</cell></row><row><cell>grad-2 + SN proj</cell><cell>93.89</cell><cell>96.85</cell><cell>grad-2 + SN proj</cell><cell>93.44</cell><cell>96.81</cell></row><row><cell>grad-2 + SN proj ( * )</cell><cell>95.15</cell><cell>97.80</cell><cell>grad-2 + SN proj ( * )</cell><cell>94.05</cell><cell>97.60</cell></row><row><cell>f 2 δ + SN proj f 2 δ + SN proj ( * ) f 2 τ + ∇f 2 + SN proj f 2 τ + ∇f 2 + SN proj ( * ) f 2 τ + f 2 δ + SN proj f 2 τ + f 2 δ + SN proj ( * )</cell><cell>93.97 94.78 95.09 95.03 95.20 95.40</cell><cell>96.89 97.38 97.42 97.27 97.60 97.77</cell><cell>f 2 M + SN proj f 2 M + SN proj ( * ) f 2 τ + ∇f 2 + SN proj f 2 τ + ∇f 2 + SN proj ( * ) f 2 τ + f 2 M + SN proj f 2 τ + f 2 M + SN proj ( * )</cell><cell>93.97 94.69 94.75 94.74 94.78 95.17</cell><cell>96.61 97.33 97.16 97.22 97.49 97.64</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 .</head><label>8</label><figDesc>Paired t-tests comparing pairs of methods, on 10 different random choices of subsets of MNIST. Each cell shows the p-value of the corresponding test. We only show p-values smaller than 0.05. Hyperparameters are fixed to the ones obtained for the results in Table2(selected on a different choice of subset), except for the learning rate which is tuned on a separate validation set for each choice of subset.</figDesc><table><row><cell></cell><cell>Test</cell><cell cols="2">300 VGG 1k VGG</cell></row><row><cell cols="2">grad-2 ( * ) Weight decay ( * )</cell><cell>-</cell><cell>3e-11</cell></row><row><cell cols="2">f 2 τ penalty Weight decay ( * )</cell><cell>2e-08</cell><cell>2e-10</cell></row><row><cell>f 2 τ + f 2 δ</cell><cell>Weight decay ( * )</cell><cell>1e-08</cell><cell>2e-10</cell></row><row><cell>f</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 9 .</head><label>9</label><figDesc>List of hyper-parameters used for each method on Infinite MNIST. For each method, we additionally consider a learning rate parameter in [0.005; 0.05; 0.5]. For combined penalties, the sets of hyperparameters are listed in the same order as in the first column (e.g., the choices of constraint radius are given last).</figDesc><table><row><cell>Method</cell><cell>Grid</cell></row><row><cell>Weight decay</cell><cell>[0; 0.00001; 0.00003; 0.0001; 0.0003; 0.001; 0.003; 0.01; 0.03; 0.1]</cell></row><row><cell>SN projection</cell><cell>[1.0; 1.2; 1.4; 1.6; 1.8]</cell></row><row><cell>grad-2</cell><cell>[0.1; 0.3; 1.0; 3.0; 10.0]</cell></row><row><cell>f 2 δ penalty ∇f 2 penalty</cell><cell>[0.1; 0.3; 1.0; 3.0] [0.0003; 0.001; 0.003; 0.01; 0.03; 0.1; 0.3]</cell></row><row><cell>Dτ f 2 penalty</cell><cell>[0.003; 0.01; 0.03; 0.1; 0.3]</cell></row><row><cell>f 2 τ penalty</cell><cell>[0.03; 0.1; 0.3; 1.0; 3.0]</cell></row><row><cell>f 2 τ + ∇f 2</cell><cell>[0.03; 0.1; 0.3; 1.0] × [0.003; 0.01; 0.03; 0.1]</cell></row><row><cell>f 2 τ + f 2 δ</cell><cell>[0.1; 0.3; 1.0] × [0.03; 0.1]</cell></row><row><cell>grad-2 + SN proj</cell><cell>[0.3; 1.0; 3.0; 10.0; 30.0] × [1.2; 1.6; 2.0]</cell></row><row><cell>f 2 δ + SN proj f 2 τ + ∇f 2 + SN proj</cell><cell>[0.03; 0.1] × [1.2; 1.6; 2.0] [0.03; 0.1; 0.3] × [0.01; 0.03; 0.1] × [1.2; 1.6; 2.0]</cell></row><row><cell>f 2 τ + f 2 δ + SN proj</cell><cell>[0.1; 0.3; 1.0] × [0.03; 0.1] × [1.2; 1.6; 2.0]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 10 .</head><label>10</label><figDesc>Paired t-tests comparing pairs of methods on the 51 test datasets from the set of protein homology detection tasks. Each cell shows the p-value of the corresponding test. We only show p-values smaller than 0.05. We use the same hyperparameters as the ones obtained in the results of Table3.</figDesc><table><row><cell>Test</cell><cell></cell><cell>No DA</cell><cell>DA</cell></row><row><cell cols="2">SN proj Weight decay</cell><cell cols="2">1e-05 4e-05</cell></row><row><cell cols="2">grad-2 Weight decay</cell><cell cols="2">5e-05 5e-02</cell></row><row><cell cols="2">f 2 δ ∇f 2 Weight decay Weight decay</cell><cell cols="2">5e-06 3e-05 9e-06 3e-03</cell></row><row><cell>f 2 δ ∇f 2 grad-2 grad-2</cell><cell></cell><cell>--</cell><cell>4e-03 -</cell></row><row><cell cols="2">grad-2 + SN proj grad-2</cell><cell>-</cell><cell>1e-03</cell></row><row><cell>f 2 δ + SN proj ∇f 2 + SN proj</cell><cell>f 2 δ ∇f 2</cell><cell cols="2">3e-03 5e-02 --</cell></row><row><cell>f 2 δ + SN proj</cell><cell cols="2">∇f 2 + SN proj 8e-05</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 11 .</head><label>11</label><figDesc>List of hyper-parameters used for each method on protein homology detection datasets. For combined penalties, the hyperparameters are the cross-products of each individual method.</figDesc><table><row><cell>Method</cell><cell>Parameter grid</cell></row><row><cell>No weight decay</cell><cell>-</cell></row><row><cell>Weight decay</cell><cell>[0; 0.01; 0.001; 0.0001; 0.00001]</cell></row><row><cell>SN proj</cell><cell>[10; 1.0; 0.1]</cell></row><row><cell>PGD-2</cell><cell>[100.0; 10.0; 1.0; 0.1]</cell></row><row><cell>grad-2</cell><cell>[100.0; 10.0; 1.0; 0.1; 0.01, 0.001]</cell></row><row><cell>f 2 δ ∇f 2</cell><cell>[10.0; 1.0; 0.1] [10.0; 1.0; 0.1; 0.01; 0.001; 0.0001]</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>/ ∞ , or perhaps that both algorithms are actually controlling the same notion of complexity on this dataset.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was supported by the <rs type="funder">ERC</rs> grant number <rs type="grantNumber">714381</rs> (<rs type="projectName">SOLARIS</rs> project) and by the <rs type="institution">MSR-Inria joint centre</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_v3egGXK">
					<idno type="grant-number">714381</idno>
					<orgName type="project" subtype="full">SOLARIS</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Table <ref type="table">4</ref>. Regularization on CIFAR10 with 1 000 or 5 000 examples for . Extended version of Table <ref type="table">1</ref>. Each entry shows the test accuracy with/without data augmentation when all hyper-parameters are optimized on a validation set of size 10 000 (a) or 1 000 (b), and for the epoch with highest validation accuracy, evaluating every 10 epochs (similar to early stopping). <ref type="bibr">(a)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Details on Optimization with Spectral Norms</head><p>This section details our optimization approach presented in Section 2.3 for learning with spectral norm constraints. In particular, we rely on a continuation approach, decreasing the size of the ball constraints during training, towards a final value τ . The method is presented in Algorithm 1. We use an exponentially decreasing schedule for τ , and take κ to be 2 epochs for regularization, and 50 epochs for robustness. In the context of convolutional networks, we simply consider the SVD of a reshaped filter matrix, but we note that alternative approaches based on the singular values of the full convolutional operation may also be used <ref type="bibr" target="#b37">(Sedghi et al., 2019)</ref>.</p><p>Algorithm 1 Stochastic projected gradient with continuation Input: τ , κ, step-sizes η t for t = 1, . . . do Sample mini-batch and compute gradients of the loss w.r.t. each W l , denoted G l t</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Extensions to Non-Euclidian Geometries</head><p>The kernel approach from previous sections is well-suited for input spaces X equipped with the Euclidian distance, thanks to the non-expansiveness property (2) of the kernel mapping. In the case of linear models, this kernel approach corresponds to using 2 -regularization by taking a linear kernel. However, other forms of regularization and geometries can often be useful, for example to encourage sparsity with an 1 regularizer. Such a regularization approach presents tight links with robustness to ∞ perturbations on input data, thanks to the duality relation w 1 = sup u ∞ w, u (see <ref type="bibr">Xu et al., 2009a)</ref>.</p><p>In the context of deep networks, we can leverage such insights to obtain new regularizers, expressed in the same variational form as the lower bounds in Section 2.2, but with different geometries on X . For ∞ perturbations, we obtain</p><p>The Lipschitz regularizer (l.h.s.) can also be taken in an adversarial perturbation form, with ∞ -bounded perturbations δ ∞ ≤ . When considering the corresponding robust optimization problem</p><p>we may consider the PGD approach of <ref type="bibr" target="#b26">Madry et al. (2018)</ref>, or the associated gradient penalty approach with the 1 norm, which is a good approximation when is small <ref type="bibr" target="#b25">(Lyu et al., 2015;</ref><ref type="bibr" target="#b39">Simon-Gabriel et al., 2019)</ref>.</p><p>As most visible in the gradient 1 -norm in ( <ref type="formula">17</ref>), these penalties encourage some sparsity in the gradients of f , which is a reasonable prior for regularization on images, for instance, where we might only want predictions to change based on few salient pixel regions. This can lead to gains in interpretability, as observed by <ref type="bibr" target="#b44">Tsipras et al. (2019)</ref>.</p><p>We note that in the case of linear models, our robust margin bound of Section 3.1 can be adapted to ∞ -perturbations, by leveraging Rademacher complexity bounds for 1 -constrained models <ref type="bibr" target="#b20">(Kakade et al., 2009)</ref>. Obtaining similar bounds for neural networks would be interesting but goes beyond the scope of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Details on Generalization Guarantees</head><p>This section presents the proof of Proposition 1, which relies on standard tools from statistical learning theory (e.g., <ref type="bibr" target="#b10">Boucheron et al., 2005)</ref>.</p><p>Proof. Assume for now that γ is fixed in advance, and let F λ := {f ∈ H : f H ≤ λ}. Note that for all f ∈ F λ we have</p><p>since f H ≤ λ is an upper bound on the Lipschitz constant of f . Consider the function</p><p>and noting that φ is upper bounded by 1 and 1/γ Lipschitz, we can apply similar arguments to <ref type="bibr">(Boucheron et al., 2005, Theorem 4</ref>.1) to obtain, with probability 1 -δ,</p><p>where R n (F λ ) denotes the empirical Rademacher complexity of F λ on the dataset {(x i , y i )} i=1,...,n . Standard upper bounds on empirical Rademacher complexity of kernel classes with bounded RKHS norm yield the following bound</p><p>Note that the bound is still valid with γ ≥ γ instead of γ in the first term of the r.h.s., since L γ n (f ) is non-decreasing as a function of γ.</p><p>In order to establish the final bound, we instantiate the previous bound for values λ i = 2 i and γ j = 2 -j . Defining δ i,j = δ (1+4i 2 )•(1+4j 2 ) , we have that w.p. 1 -δ i,j , for all f ∈ F λi and all γ ≥ γ j , err D (f, ) ≤ L λi +γ</p><p>By a union bound, this event holds jointly for all integers i, j w.p. greater than 1 -δ, since i,j δ i,j ≤ δ. Now consider an arbitrary f ∈ H and γ &gt; 0 and let i = log 2 f H and j = log 2 (1/γ) . We have</p><p>with C( f H , γ) := (1 + 4(log 2 f H ) 2 ) • (1 + 4(log 2 (1/γ)) 2 ). Applying this to the bound in (19) yields the desired result.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Predicting the sequence specificities of dna-and rna-binding proteins by deep learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Alipanahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Delong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Weirauch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature biotechnology</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">831</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Gapped blast and psi-blast: a new generation of protein database search programs</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Altschul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Schäffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Lipman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="3389" to="3402" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On gradient regularizers for MMD GANs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Arbel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Sutherland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bińkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><surname>Wasserstein</surname></persName>
		</author>
		<author>
			<persName><surname>Gan</surname></persName>
		</author>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Telgarsky</surname></persName>
		</author>
		<title level="m">Spectrallynormalized margin bounds for neural networks. In Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Overfitting or perfect fitting? risk bounds for classification and regression rules that interpolate</title>
		<author>
			<persName><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitra</forename></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>a</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">To understand deep learning we need to understand kernel learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mandal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>b</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Group invariance, stability to deformations, and complexity of deep convolutional representations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bietti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research (JMLR)</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">25</biblScope>
			<biblScope unit="page" from="1" to="49" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Wild patterns: Ten years after the rise of adversarial machine learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Biggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Roli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="317" to="331" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Bińkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Sutherland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Arbel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName><surname>Demystifying</surname></persName>
		</author>
		<author>
			<persName><surname>Gans</surname></persName>
		</author>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Theory of classification: A survey of some recent advances</title>
		<author>
			<persName><forename type="first">S</forename><surname>Boucheron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lugosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ESAIM: probability and statistics</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="323" to="375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Opportunities and obstacles for deep learning in biology and medicine</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ching</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of The Royal Society Interface</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">141</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Parseval networks: Improving robustness to adversarial examples</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Double backpropagation increasing generalization performance</title>
		<author>
			<persName><forename type="first">H</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Le Cun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Training generative neural networks via maximum mean discrepancy optimization</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">K</forename><surname>Dziugaite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Uncertainty in Artificial Intelligence (UAI)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">A rotation and a translation suffice: Fooling cnns with simple transformations</title>
		<author>
			<persName><forename type="first">L</forename><surname>Engstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madry</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.02779</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A kernel two-sample test</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Rasch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research (JMLR)</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="723" to="773" />
			<date type="published" when="2012-03">Mar. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Improved training of Wasserstein GANs</title>
		<author>
			<persName><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Motif kernel generated by genetic programming improves remote homology and fold detection</title>
		<author>
			<persName><forename type="first">T</forename><surname>Håndstad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Hestnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Saetrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC bioinformatics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">23</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On the complexity of linear prediction: Risk bounds, margin bounds, and regularization</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sridharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tewari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Khim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-L</forename><surname>Loh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.09519</idno>
		<title level="m">Adversarial risk bounds via function transformation</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Empirical margin distributions and bounding the generalization error of combined classifiers</title>
		<author>
			<persName><forename type="first">V</forename><surname>Koltchinskii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Panchenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="50" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Mmd gan: Towards deeper understanding of moment matching network</title>
		<author>
			<persName><forename type="first">C.-L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Póczos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Training invariant support vector machines using selective sampling</title>
		<author>
			<persName><forename type="first">G</forename><surname>Loosli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Canu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Large Scale Kernel Machines</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Decoste</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="301" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A unified gradient regularization family for adversarial examples</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-N</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Data Mining (ICDM)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Towards deep learning models resistant to adversarial attacks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Madry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Makelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vladu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">End-to-end kernel learning with supervised convolutional kernel networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Spectral normalization for generative adversarial networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kataoka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yoshida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>a</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Virtual adversarial training: a regularization method for supervised and semi-supervised learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-I</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>b</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Scop: a structural classification of proteins database for the investigation of sequences and structures</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Murzin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Brenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hubbard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chothia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of molecular biology</title>
		<imprint>
			<biblScope unit="volume">247</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="536" to="540" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A PAC-Bayesian approach to spectrally-normalized margin bounds for neural networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Neyshabur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhojanapalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Certified defenses against adversarial examples</title>
		<author>
			<persName><forename type="first">A</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Stabilizing training of generative adversarial networks through regularization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Adversarially robust training through structured gradient regularization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.08736</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Adversarially robust generalization requires more data</title>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Santurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Learning with kernels: support vector machines, regularization, optimization, and beyond</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The singular values of convolutional layers</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sedghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Transformation invariance in pattern recognition-tangent distance and tangent propagation</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">Y</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">A</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Victorri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural networks: tricks of the trade</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="239" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">First-order adversarial vulnerability of neural networks and input dimension</title>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Simon-Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ollivier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Certifying some distributional robustness with principled adversarial training</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Namkoong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">On the empirical estimation of integral probability metrics</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Sriperumbudur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fukumizu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Lanckriet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronic Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1550" to="1599" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6199</idno>
		<title level="m">Intriguing properties of neural networks</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Robustness may be at odds with accuracy</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Santurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Engstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Provable defenses against adversarial examples via the convex outer adversarial polytope</title>
		<author>
			<persName><forename type="first">E</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Kolter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Robust regression and lasso</title>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Caramanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mannor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>a</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Robustness and regularization of support vector machines</title>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Caramanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mannor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research (JMLR)</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1485" to="1510" />
			<date type="published" when="2009-07">Jul. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
