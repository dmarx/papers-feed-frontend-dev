- Decision to adopt a kernel perspective for regularizing deep neural networks
- Choice of using RKHS norms for regularization
- Decision to approximate RKHS norms with upper and lower bounds
- Selection of specific regularization principles to unify under the RKHS framework
- Decision to focus on adversarial robustness in the context of regularization
- Choice of using convolutional neural networks (CNNs) as the primary model
- Decision to leverage smooth approximations of ReLU activations
- Choice of optimization strategies for training with small datasets
- Decision to explore hybrid strategies combining upper and lower bounds
- Selection of specific penalties based on adversarial perturbations
- Decision to utilize gradient penalties in the regularization framework
- Choice of multi-class extensions for the proposed methods
- Decision to adapt regularization algorithms for different network architectures
- Choice of using mini-batch optimization for lower bound approximations
- Decision to separate regularization penalties from loss terms in the optimization process
- Choice of theoretical insights to support empirical findings in regularization strategies