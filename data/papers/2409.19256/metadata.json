{
  "arxivId": "2409.19256",
  "title": "HybridFlow: A Flexible and Efficient RLHF Framework",
  "authors": "Guangming Sheng, Chi Zhang, Zilingfeng Ye, Xibin Wu, Wang Zhang, Ru Zhang, Yanghua Peng, Haibin Lin, Chuan Wu",
  "abstract": "Reinforcement Learning from Human Feedback (RLHF) is widely used in Large\nLanguage Model (LLM) alignment. Traditional RL can be modeled as a dataflow,\nwhere each node represents computation of a neural network (NN) and each edge\ndenotes data dependencies between the NNs. RLHF complicates the dataflow by\nexpanding each node into a distributed LLM training or generation program, and\neach edge into a many-to-many multicast. Traditional RL frameworks execute the\ndataflow using a single controller to instruct both intra-node computation and\ninter-node communication, which can be inefficient in RLHF due to large control\ndispatch overhead for distributed intra-node computation. Existing RLHF systems\nadopt a multi-controller paradigm, which can be inflexible due to nesting\ndistributed computation and data communication. We propose HybridFlow, which\ncombines single-controller and multi-controller paradigms in a hybrid manner to\nenable flexible representation and efficient execution of the RLHF dataflow. We\ncarefully design a set of hierarchical APIs that decouple and encapsulate\ncomputation and data dependencies in the complex RLHF dataflow, allowing\nefficient operation orchestration to implement RLHF algorithms and flexible\nmapping of the computation onto various devices. We further design a\n3D-HybridEngine for efficient actor model resharding between training and\ngeneration phases, with zero memory redundancy and significantly reduced\ncommunication overhead. Our experimental results demonstrate\n1.53$\\times$~20.57$\\times$ throughput improvement when running various RLHF\nalgorithms using HybridFlow, as compared with state-of-the-art baselines.\nHybridFlow source code will be available at https://github.com/volcengine/verl.",
  "url": "https://arxiv.org/abs/2409.19256",
  "issue_number": 790,
  "issue_url": "https://github.com/dmarx/papers-feed/issues/790",
  "created_at": "2025-01-05T08:23:20.685734",
  "state": "open",
  "labels": [
    "paper",
    "rating:novote"
  ],
  "total_reading_time_seconds": 14,
  "last_read": "2025-01-05T08:23:20.687827",
  "last_visited": "2025-01-05T08:22:18.012Z",
  "main_tex_file": null,
  "published_date": "2024-09-28T06:20:03Z",
  "arxiv_tags": [
    "cs.LG",
    "cs.DC",
    "I.2"
  ]
}