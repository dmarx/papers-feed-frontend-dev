- Decision to unify computation and communication in a single DSL
- Choice of C++ as the implementation language for CoCoNet
- Design of tensor layouts (sliced, replicated, local) for distributed data representation
- Implementation of fused collective communication operations
- Adoption of semantics preserving transformations for optimization
- Strategy for overlapping computation and communication operations
- Decision to include an autotuner for automatic optimization
- Choice of existing libraries (cuBLAS, cuDNN, NCCL) for backend operations
- Design of the CoCoNet compiler for generating optimized kernels
- Decision to support multiple parallelism strategies (data, model, pipeline)
- Implementation of a scheduling language for execution order specification
- Design of the CoCoNet API for user interaction and program expression
- Decision to focus on performance metrics (time, energy, cost savings) in optimizations
- Choice of specific machine learning models (BERT, GPT-2, GPT-3) for experimentation
- Strategy for handling non-contiguous buffer management in communication operations
- Decision to provide high-level abstractions for user convenience
- Implementation of error handling and debugging mechanisms in CoCoNet
- Design considerations for scalability across different hardware and topologies
- Decision to open-source CoCoNet for community contributions and feedback