- **Introduction to MWT**: Multi-Word Tokenizer (MWT) enhances tokenization by representing frequent multi-word expressions as single tokens, improving computational efficiency in LLMs.
  
- **Benefits of MWT**:
  - **Performance Increase**: Greater coverage of input data within a fixed sequence length.
  - **Inference Speedup**: Reduced sequence length with minimal performance loss, allowing for early truncation.

- **Tokenization Process**:
  - **N-gram Selection**: Identify top-K frequent n-grams from a corpus \( D \) to enrich the tokenizer's vocabulary \( V \).
    - Formula: \( G_K = \{ g_n \in D | f(g_n) \text{ is among the top K} \} \)
  
- **Fast Vocabulary Transfer (FVT)**: 
  - Technique to integrate new n-grams into the embedding matrix without full retraining.
  - Combines existing embeddings to initialize new token embeddings.

- **Experimental Setup**:
  - Models: BERT base and DistilBERT base.
  - Tokenizers compared: \( T_{gen}, T_{1000gen}, T_{2500gen}, T_{5000gen}, T_{100}, T_{1000 100}, T_{2500 100}, T_{5000 100} \).
  - Metrics: Macro-F1 score and inference speedup.

- **Datasets Used**:
  - **ADE**: Adverse Drug Event classification.
  - **LEDGAR**: Legal document classification.
  - **PATENT**: US patent application classification.

- **Results Summary**:
  - MWTs yield compression rates up to 50% in certain datasets.
  - Inference speedup ranges from \( \sim 1.1 \) to \( \sim 1.8 \) depending on the dataset.
  - MWTs maintain performance better under sequence truncation compared to traditional tokenizers.

- **Key Observations**:
  - MWTs are more robust to shorter sequence lengths, allowing for significant speedups.
  - Performance degradation is smoother with MWTs as sequence length decreases.

- **Conclusion**: MWTs provide a promising approach to reduce computational costs in LLMs while maintaining or improving performance, particularly in specialized domains.