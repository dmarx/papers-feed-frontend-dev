<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Unsupervised Learning using Nonequilibrium Thermodynamics</title>
				<funder>
					<orgName type="full">Burroughs-Wellcome</orgName>
				</funder>
				<funder>
					<orgName type="full">Office of Naval Research for funding Jascha Sohl-Dickstein</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2015-11-18">18 Nov 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
							<email>jascha@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Eric</forename><forename type="middle">A</forename><surname>Weiss</surname></persName>
							<email>eaweiss@berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Niru</forename><surname>Maheswaranathan</surname></persName>
							<email>nirum@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Unsupervised Learning using Nonequilibrium Thermodynamics</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2015-11-18">18 Nov 2015</date>
						</imprint>
					</monogr>
					<idno type="MD5">B1390ADDA57BBB669FA958ADD52328C3</idno>
					<idno type="arXiv">arXiv:1503.03585v8[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-02-21T16:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.</p><p>1. extreme flexibility in model structure, 2. exact sampling,</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Historically, probabilistic models suffer from a tradeoff between two conflicting objectives: tractability and flexibility. Models that are tractable can be analytically evaluated and easily fit to data (e.g. a Gaussian or Laplace). However, Proceedings of the 32 nd International Conference on Machine Learning, Lille, France, 2015. JMLR: W&amp;CP volume 37. Copyright 2015 by the author(s).</p><p>these models are unable to aptly describe structure in rich datasets. On the other hand, models that are flexible can be molded to fit structure in arbitrary data. For example, we can define models in terms of any (non-negative) function φ(x) yielding the flexible distribution p (x) = φ(x) Z , where Z is a normalization constant. However, computing this normalization constant is generally intractable. Evaluating, training, or drawing samples from such flexible models typically requires a very expensive Monte Carlo process.</p><p>A variety of analytic approximations exist which ameliorate, but do not remove, this tradeoff-for instance mean field theory and its expansions <ref type="bibr" target="#b47">(T, 1982;</ref><ref type="bibr" target="#b48">Tanaka, 1998)</ref>, variational Bayes <ref type="bibr" target="#b22">(Jordan et al., 1999)</ref>, contrastive divergence <ref type="bibr" target="#b54">(Welling &amp; Hinton, 2002;</ref><ref type="bibr" target="#b16">Hinton, 2002)</ref>, minimum probability flow <ref type="bibr">(Sohl-Dickstein et al., 2011b;</ref><ref type="bibr">a)</ref>, minimum KL contraction <ref type="bibr" target="#b31">(Lyu, 2011)</ref>, proper scoring rules <ref type="bibr" target="#b12">(Gneiting &amp; Raftery, 2007;</ref><ref type="bibr" target="#b36">Parry et al., 2012)</ref>, score matching <ref type="bibr" target="#b18">(Hyvärinen, 2005)</ref>, pseudolikelihood <ref type="bibr" target="#b4">(Besag, 1975)</ref>, loopy belief propagation <ref type="bibr" target="#b33">(Murphy et al., 1999)</ref>, and many, many more. Non-parametric methods <ref type="bibr" target="#b11">(Gershman &amp; Blei, 2012)</ref> can also be very effective<ref type="foot" target="#foot_0">foot_0</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Diffusion probabilistic models</head><p>We present a novel way to define probabilistic models that allows:</p><p>3. easy multiplication with other distributions, e.g. in order to compute a posterior, and 4. the model log likelihood, and the probability of individual states, to be cheaply evaluated.</p><p>Our method uses a Markov chain to gradually convert one distribution into another, an idea used in non-equilibrium statistical physics <ref type="bibr" target="#b19">(Jarzynski, 1997)</ref> and sequential Monte Carlo <ref type="bibr" target="#b34">(Neal, 2001)</ref>. We build a generative Markov chain which converts a simple known distribution (e.g. a Gaussian) into a target (data) distribution using a diffusion process. Rather than use this Markov chain to approximately evaluate a model which has been otherwise defined, we explicitly define the probabilistic model as the endpoint of the Markov chain. Since each step in the diffusion chain has an analytically evaluable probability, the full chain can also be analytically evaluated.</p><p>Learning in this framework involves estimating small perturbations to a diffusion process. Estimating small perturbations is more tractable than explicitly describing the full distribution with a single, non-analytically-normalizable, potential function. Furthermore, since a diffusion process exists for any smooth target distribution, this method can capture data distributions of arbitrary form.</p><p>We demonstrate the utility of these diffusion probabilistic models by training high log likelihood models for a twodimensional swiss roll, binary sequence, handwritten digit (MNIST), and several natural image (CIFAR-10, bark, and dead leaves) datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Relationship to other work</head><p>The wake-sleep algorithm <ref type="bibr" target="#b17">(Hinton, 1995;</ref><ref type="bibr" target="#b8">Dayan et al., 1995)</ref> introduced the idea of training inference and generative probabilistic models against each other. This approach remained largely unexplored for nearly two decades, though with some exceptions <ref type="bibr" target="#b40">(Sminchisescu et al., 2006;</ref><ref type="bibr" target="#b23">Kavukcuoglu et al., 2010)</ref>. There has been a recent explosion of work developing this idea. In <ref type="bibr" target="#b24">(Kingma &amp; Welling, 2013;</ref><ref type="bibr" target="#b14">Gregor et al., 2013;</ref><ref type="bibr" target="#b37">Rezende et al., 2014;</ref><ref type="bibr">Ozair &amp; Bengio, 2014)</ref> variational learning and inference algorithms were developed which allow a flexible generative model and posterior distribution over latent variables to be directly trained against each other.</p><p>The variational bound in these papers is similar to the one used in our training objective and in the earlier work of <ref type="bibr" target="#b40">(Sminchisescu et al., 2006)</ref>. However, our motivation and model form are both quite different, and the present work retains the following differences and advantages relative to these techniques:</p><p>1. We develop our framework using ideas from physics, quasi-static processes, and annealed importance sampling rather than from variational Bayesian methods.</p><p>2. We show how to easily multiply the learned distribution with another probability distribution (eg with a conditional distribution in order to compute a posterior) 3. We address the difficulty that training the inference model can prove particularly challenging in variational inference methods, due to the asymmetry in the objective between the inference and generative models. We restrict the forward (inference) process to a simple functional form, in such a way that the reverse (generative) process will have the same functional form. 4. We train models with thousands of layers (or time steps), rather than only a handful of layers. 5. We provide upper and lower bounds on the entropy production in each layer (or time step)</p><p>There are a number of related techniques for training probabilistic models (summarized below) that develop highly flexible forms for generative models, train stochastic trajectories, or learn the reversal of a Bayesian network. Reweighted wake-sleep <ref type="bibr" target="#b6">(Bornschein &amp; Bengio, 2015)</ref> develops extensions and improved learning rules for the original wake-sleep algorithm. Generative stochastic networks <ref type="bibr" target="#b1">(Bengio &amp; Thibodeau-Laufer, 2013;</ref><ref type="bibr" target="#b55">Yao et al., 2014)</ref> train a Markov kernel to match its equilibrium distribution to the data distribution. Neural autoregressive distribution estimators <ref type="bibr" target="#b27">(Larochelle &amp; Murray, 2011)</ref> (and their recurrent <ref type="bibr">(Uria et al., 2013a)</ref> and deep <ref type="bibr">(Uria et al., 2013b)</ref> extensions) decompose a joint distribution into a sequence of tractable conditional distributions over each dimension. Adversarial networks <ref type="bibr" target="#b13">(Goodfellow et al., 2014)</ref> train a generative model against a classifier which attempts to distinguish generated samples from true data. A similar objective in <ref type="bibr" target="#b39">(Schmidhuber, 1992</ref>) learns a two-way mapping to a representation with marginally independent units. In <ref type="bibr" target="#b38">(Rippel &amp; Adams, 2013;</ref><ref type="bibr" target="#b9">Dinh et al., 2014)</ref> bijective deterministic maps are learned to a latent representation with a simple factorial density function. In <ref type="bibr" target="#b45">(Stuhlmüller et al., 2013)</ref> stochastic inverses are learned for Bayesian networks. Mixtures of conditional Gaussian scale mixtures (MCGSMs) <ref type="bibr" target="#b49">(Theis et al., 2012</ref>) describe a dataset using Gaussian scale mixtures, with parameters which depend on a sequence of causal neighborhoods. There is additionally significant work learning flexible generative mappings from simple latent distributions to data distributions -early examples including <ref type="bibr" target="#b32">(MacKay, 1995)</ref> where neural networks are introduced as generative models, and <ref type="bibr" target="#b5">(Bishop et al., 1998)</ref> where a stochastic manifold mapping is learned from a latent space to the data space. We will compare experimentally against adversarial networks and MCGSMs.</p><p>Related ideas from physics include the Jarzynski equality <ref type="bibr" target="#b19">(Jarzynski, 1997)</ref>, known in machine learning as An-  T ) . The data distribution (left) undergoes Gaussian diffusion, which gradually transforms it into an identity-covariance Gaussian (right). The middle row shows the corresponding time slices from the trained reverse trajectory p x (0•••T ) . An identity-covariance Gaussian (right) undergoes a Gaussian diffusion process with learned mean and covariance functions, and is gradually transformed back into the data distribution (left). The bottom row shows the drift term, fµ x (t) , t -x (t) , for the same reverse diffusion process.</p><formula xml:id="formula_0">t = 0 t = T 2 t = T q x (0•••T ) 2 0 2 2 0 2 2 0 2 2 0 2 2 0 2 2 0 2 p x (0•••T ) 2 0 2 2 0 2 2 0 2 2 0 2 2 0 2 2 0 2 f µ x (t) , t -x (t)</formula><p>nealed Importance Sampling (AIS) <ref type="bibr" target="#b34">(Neal, 2001)</ref>, which uses a Markov chain which slowly converts one distribution into another to compute a ratio of normalizing constants. In <ref type="bibr" target="#b7">(Burda et al., 2014)</ref> it is shown that AIS can also be performed using the reverse rather than forward trajectory. Langevin dynamics <ref type="bibr" target="#b26">(Langevin, 1908)</ref>, which are the stochastic realization of the Fokker-Planck equation, show how to define a Gaussian diffusion process which has any target distribution as its equilibrium. In <ref type="bibr" target="#b46">(Suykens &amp; Vandewalle, 1995)</ref> the Fokker-Planck equation is used to perform stochastic optimization. Finally, the Kolmogorov forward and backward equations <ref type="bibr" target="#b10">(Feller, 1949)</ref> show that for many forward diffusion processes, the reverse diffusion processes can be described using the same functional form.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Algorithm</head><p>Our goal is to define a forward (or inference) diffusion process which converts any complex data distribution into a simple, tractable, distribution, and then learn a finite-time reversal of this diffusion process which defines our generative model distribution (See Figure <ref type="figure" target="#fig_0">1</ref>). We first describe the forward, inference diffusion process. We then show how the reverse, generative diffusion process can be trained and used to evaluate probabilities. We also derive entropy bounds for the reverse process, and show how the learned distributions can be multiplied by any second distribution (e.g. as would be done to compute a posterior when inpainting or denoising an image).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Forward Trajectory</head><p>We label the data distribution q x (0) . The data distribution is gradually converted into a well behaved (analytically tractable) distribution π (y) by repeated application of a Markov diffusion kernel T π (y|y ; β) for π (y), where β is the diffusion rate, π (y) = dy T π (y|y ; β) π (y )</p><p>(1)</p><formula xml:id="formula_1">q x (t) |x (t-1) = T π x (t) |x (t-1) ; β t .</formula><p>(2) The forward trajectory, corresponding to starting at the data distribution and performing T steps of diffusion, is thus</p><formula xml:id="formula_2">t = 0 t = T 2 t = T p x (0•••T ) 0 5</formula><formula xml:id="formula_3">q x (0•••T ) = q x (0) T t=1 q x (t) |x (t-1) (3)</formula><p>For the experiments shown below, q x (t) |x (t-1) corresponds to either Gaussian diffusion into a Gaussian distribution with identity-covariance, or binomial diffusion into an independent binomial distribution. Table <ref type="table">App</ref>.1 gives the diffusion kernels for both Gaussian and binomial distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Reverse Trajectory</head><p>The generative distribution will be trained to describe the same trajectory, but in reverse,</p><formula xml:id="formula_4">p x (T ) = π x (T ) (4) p x (0•••T ) = p x (T ) T t=1 p x (t-1) |x (t) . (5)</formula><p>For both Gaussian and binomial diffusion, for continuous diffusion (limit of small step size β) the reversal of the diffusion process has the identical functional form as the forward process <ref type="bibr" target="#b10">(Feller, 1949)</ref>. Since q x (t) |x (t-1) is a Gaussian (binomial) distribution, and if β t is small, then q x (t-1) |x (t) will also be a Gaussian (binomial) distribution. The longer the trajectory the smaller the diffusion rate β can be made.</p><p>During learning only the mean and covariance for a Gaussian diffusion kernel, or the bit flip probability for a binomial kernel, need be estimated. As shown in Table <ref type="table">App</ref>.1, f µ x (t) , t and f Σ x (t) , t are functions defining the mean and covariance of the reverse Markov transitions for a Gaussian, and f b x (t) , t is a function providing the bit flip probability for a binomial distribution. The computational cost of running this algorithm is the cost of these functions, times the number of time-steps. For all results in this paper, multi-layer perceptrons are used to define these functions. A wide range of regression or function fitting techniques would be applicable however, including nonparameteric methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Model Probability</head><p>The probability the generative model assigns to the data is</p><formula xml:id="formula_5">p x (0) = dx (1•••T ) p x (0•••T ) .<label>(6)</label></formula><p>Naively this integral is intractable -but taking a cue from annealed importance sampling and the Jarzynski equality, we instead evaluate the relative probability of the forward and reverse trajectories, averaged over forward trajectories,</p><formula xml:id="formula_6">p x (0) = dx (1•••T ) p x (0•••T ) q x (1•••T ) |x (0) q x (1•••T ) |x (0) (7) = dx (1•••T ) q x (1•••T ) |x (0) p x (0•••T ) q x (1•••T ) |x (0) (8) = dx (1•••T ) q x (1•••T ) |x (0) • p x (T ) T t=1 p x (t-1) |x (t) q x (t) |x (t-1) .<label>(9)</label></formula><p>This can be evaluated rapidly by averaging over samples from the forward trajectory q x (1•••T ) |x (0) . For infinitesimal β the forward and reverse distribution over trajectories can be made identical (see Section 2.2). If they are identical then only a single sample from q</p><formula xml:id="formula_7">x (1•••T ) |x (0)</formula><p>is required to exactly evaluate the above integral, as can be seen by substitution. This corresponds to the case of a quasi-static process in statistical physics <ref type="bibr" target="#b44">(Spinney &amp; Ford, 2013;</ref><ref type="bibr" target="#b20">Jarzynski, 2011)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Training</head><p>Training amounts to maximizing the model log likelihood,</p><formula xml:id="formula_8">L = dx (0) q x (0) log p x (0) (10) = dx (0) q x (0) • log   dx (1•••T ) q x (1•••T ) |x (0) • p x (T ) T t=1 p(x (t-1) |x (t) ) q(x (t) |x (t-1) )   ,<label>(11)</label></formula><p>which has a lower bound provided by Jensen's inequality,</p><formula xml:id="formula_9">L ≥ dx (0•••T ) q x (0•••T ) • log p x (T ) T t=1 p x (t-1) |x (t) q x (t) |x (t-1) .<label>(12)</label></formula><p>As described in Appendix B, for our diffusion trajectories this reduces to,</p><formula xml:id="formula_10">L ≥ K (13) K = - T t=2 dx (0) dx (t) q x (0) , x (t) • D KL q x (t-1) |x (t) , x (0) p x (t-1) |x (t) + H q X (T ) |X (0) -H q X (1) |X (0) -H p X (T ) . (<label>14</label></formula><formula xml:id="formula_11">)</formula><p>where the entropies and KL divergences can be analytically computed. The derivation of this bound parallels the derivation of the log likelihood bound in variational Bayesian methods.</p><p>As in Section 2.3 if the forward and reverse trajectories are identical, corresponding to a quasi-static process, then the inequality in Equation 13 becomes an equality.</p><p>Training consists of finding the reverse Markov transitions which maximize this lower bound on the log likelihood,</p><formula xml:id="formula_12">p x (t-1) |x (t) = argmax p(x (t-1) |x (t) ) K. (<label>15</label></formula><formula xml:id="formula_13">)</formula><p>The specific targets of estimation for Gaussian and binomial diffusion are given in Table <ref type="table">App</ref>.1.</p><p>Thus, the task of estimating a probability distribution has been reduced to the task of performing regression on the functions which set the mean and covariance of a sequence of Gaussians (or set the state flip probability for a sequence of Bernoulli trials).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1.">SETTING THE DIFFUSION RATE β t</head><p>The choice of β t in the forward trajectory is important for the performance of the trained model. In AIS, the right schedule of intermediate distributions can greatly improve the accuracy of the log partition function estimate <ref type="bibr" target="#b15">(Grosse et al., 2013)</ref>. In thermodynamics the schedule taken when moving between equilibrium distributions determines how much free energy is lost <ref type="bibr" target="#b44">(Spinney &amp; Ford, 2013;</ref><ref type="bibr" target="#b20">Jarzynski, 2011)</ref>.</p><p>In the case of Gaussian diffusion, we learn<ref type="foot" target="#foot_1">foot_1</ref> the forward diffusion schedule β 2•••T by gradient ascent on K. The variance β 1 of the first step is fixed to a small constant to prevent overfitting. The dependence of samples from</p><formula xml:id="formula_14">q x (1•••T ) |x (0) on β 1•••</formula><p>T is made explicit by using 'frozen noise' -as in <ref type="bibr" target="#b24">(Kingma &amp; Welling, 2013)</ref> the noise is treated as an additional auxiliary variable, and held constant while computing partial derivatives of K with respect to the parameters.</p><p>For binomial diffusion, the discrete state space makes gradient ascent with frozen noise impossible. We instead choose the forward diffusion schedule β 1•••T to erase a constant fraction 1 T of the original signal per diffusion step, yielding a diffusion rate of β t = (T -t + 1)</p><p>-1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Multiplying Distributions, and Computing Posteriors</head><p>Tasks such as computing a posterior in order to do signal denoising or inference of missing values requires multiplication of the model distribution p x (0) with a second distribution, or bounded positive function, r x (0) , producing a new distribution p x (0) ∝ p x (0) r x (0) .</p><p>Multiplying distributions is costly and difficult for many techniques, including variational autoencoders, GSNs, NADEs, and most graphical models. However, under a diffusion model it is straightforward, since the second distribution can be treated either as a small perturbation to each step in the diffusion process, or often exactly multiplied into each diffusion step. Figures <ref type="figure">3</ref> and <ref type="figure" target="#fig_3">5</ref> demonstrate the use of a diffusion model to perform denoising and inpainting of natural images. The following sections describe how to multiply distributions in the context of diffusion probabilistic models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.1.">MODIFIED MARGINAL DISTRIBUTIONS</head><p>First, in order to compute p x (0) , we multiply each of the intermediate distributions by a corresponding function r x (t) . We use a tilde above a distribution or Markov transition to denote that it belongs to a trajectory that has been modified in this way. p x (0•••T ) is the modified reverse trajectory, which starts at the distribution p x (T ) = 1 ZT p x (T ) r x (T ) and proceeds through the sequence of intermediate distributions</p><formula xml:id="formula_15">p x (t) = 1 Zt p x (t) r x (t) , (<label>16</label></formula><formula xml:id="formula_16">)</formula><p>where Zt is the normalizing constant for the tth intermediate distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.2.">MODIFIED DIFFUSION STEPS</head><p>The Markov kernel p x (t) | x (t+1) for the reverse diffusion process obeys the equilibrium condition</p><formula xml:id="formula_17">p x (t = dx (t+1) p x t) | x (t+1) p x t+1) . (<label>17</label></formula><formula xml:id="formula_18">)</formula><p>We wish the perturbed Markov kernel p x (t) | x (t+1) to instead obey the equilibrium condition for the perturbed distribution,</p><formula xml:id="formula_19">p x (t) = dx (t+1) p x (t) | x (t+1) p x t+1) ,<label>(18)</label></formula><formula xml:id="formula_20">p x (t) r x (t) Zt = dx (t+1) p x (t) | x (t+1) • p x (t+1) r x (t+1) Zt+1 ,<label>(19)</label></formula><formula xml:id="formula_21">p x (t) = dx (t+1) p x (t) | x (t+1) • Zt r x (t+1) Zt+1 r x (t) p x (t+1) .<label>(20)</label></formula><p>Equation 20 will be satisfied if</p><formula xml:id="formula_22">p x (t) |x (t+1) = p x (t) |x (t+1) Zt+1 r x (t) Zt r x (t+1) .<label>(21)</label></formula><p>Equation 21 may not correspond to a normalized probability distribution, so we choose p x (t) |x (t+1) to be the corresponding normalized distribution where Zt x (t+1) is the normalization constant.</p><formula xml:id="formula_23">p x (t) |x (t+1) = 1 Zt x (t+1) p x (t) |x (t+1) r x (t) ,<label>(22)</label></formula><p>For a Gaussian, each diffusion step is typically very sharply peaked relative to r x (t) , due to its small variance. This means that r(x (t) ) r(x (t+1) )</p><p>can be treated as a small perturbation to p x (t) |x (t+1) . A small perturbation to a Gaussian effects the mean, but not the normalization constant, so in this case Equations 21 and 22 are equivalent (see Appendix C).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.3.">APPLYING r x (t)</head><p>If r x (t) is sufficiently smooth, then it can be treated as a small perturbation to the reverse diffusion kernel p x (t) |x (t+1) . In this case p x (t) |x (t+1) will have an identical functional form to p x (t) |x (t+1) , but with perturbed mean for the Gaussian kernel, or with perturbed flip rate for the binomial kernel. The perturbed diffusion kernels are given in Table <ref type="table">App</ref>.1, and are derived for the Gaussian in Appendix C.</p><p>If r x (t) can be multiplied with a Gaussian (or binomial) distribution in closed form, then it can be directly multiplied with the reverse diffusion kernel p x (t) |x (t+1) in closed form. This applies in the case where r x (t) consists of a delta function for some subset of coordinates, as in the inpainting example in Figure <ref type="figure" target="#fig_3">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.4.">CHOOSING r x (t)</head><p>Typically, r x (t) should be chosen to change slowly over the course of the trajectory. For the experiments in this paper we chose it to be constant,</p><formula xml:id="formula_24">r x (t) = r x (0) . (<label>23</label></formula><formula xml:id="formula_25">)</formula><p>Another convenient choice is r</p><formula xml:id="formula_26">x (t) = r x (0)</formula><p>T -t</p><p>T . Under this second choice r x (t) makes no contribution to the starting distribution for the reverse trajectory. This guarantees that drawing the initial sample from p x (T ) for the reverse trajectory remains straightforward.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.">Entropy of Reverse Process</head><p>Since the forward process is known, we can derive upper and lower bounds on the conditional entropy of each step in the reverse trajectory, and thus on the log likelihood,</p><formula xml:id="formula_27">H q X (t) |X (t-1) + H q X (t-1) |X (0) -H q X (t) |X (0) ≤ H q X (t-1) |X (t) ≤ H q X (t) |X (t-1) , (<label>24</label></formula><formula xml:id="formula_28">)</formula><p>where both the upper and lower bounds depend only on q x (1•••T ) |x (0) , and can be analytically computed. The derivation is provided in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head><p>We train diffusion probabilistic models on a variety of continuous datasets, and a binary dataset. We then demonstrate sampling from the trained model and inpainting of missing data, and compare model performance against other techniques. In all cases the objective function and gradient were computed using Theano <ref type="bibr" target="#b3">(Bergstra &amp; Breuleux, 2010)</ref>. Model training was with SFO <ref type="bibr" target="#b43">(Sohl-Dickstein et al., 2014)</ref>, except for CIFAR-10. CIFAR-10 results used the  <ref type="bibr" target="#b28">(Lazebnik et al., 2005)</ref>. (b) The same image with the central 100×100 pixel region replaced with isotropic Gaussian noise. This is the initialization p x (T ) for the reverse trajectory. (c) The central 100×100 region has been inpainted using a diffusion probabilistic model trained on images of bark, by sampling from the posterior distribution over the missing region conditioned on the rest of the image. Note the long-range spatial structure, for instance in the crack entering on the left side of the inpainted region. The sample from the posterior was generated as described in Section 2.5, where r x (0) was set to a delta function for known data, and a constant for missing data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>K K -L null Swiss Roll 2.35 bits 6.45 bits Binary Heartbeat -2.414 bits/seq.</p><p>12.024 bits/seq. Bark -0.55 bits/pixel 1.5 bits/pixel Dead Leaves 1.489 bits/pixel 3.536 bits/pixel CIFAR-10 3 5.4 ± 0.2 bits/pixel 11.5 ± 0.2 bits/pixel MNIST See table <ref type="table" target="#tab_0">2</ref> Table <ref type="table">1</ref>. The lower bound K on the log likelihood, computed on a holdout set, for each of the trained models. See Equation <ref type="formula" target="#formula_9">12</ref>. The right column is the improvement relative to an isotropic Gaussian or independent binomial distribution. L null is the log likelihood of π x (0) . All datasets except for Binary Heartbeat were scaled by a constant to give them variance 1 before computing log likelihood.</p><p>open source implementation of the algorithm, and RM-Sprop for optimization. The lower bound on the log likelihood provided by our model is reported for all datasets in Table <ref type="table">1</ref>. A reference implementation of the algorithm utilizing Blocks <ref type="bibr" target="#b53">(van Merriënboer et al., 2015)</ref> is available at <ref type="url" target="https://github.com/Sohl-Dickstein/Diffusion-Probabilistic-Models">https://github.com/Sohl-Dickstein/ Diffusion-Probabilistic-Models</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Toy Problems</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">SWISS ROLL</head><p>A diffusion probabilistic model was built of a two dimensional swiss roll distribution, using a radial basis function network to generate f µ x (t) , t and f Σ x (t) , t . As illustrated in Figure <ref type="figure" target="#fig_0">1</ref>, the swiss roll distribution was successfully learned. See Appendix Section D.1.1 for more details.  <ref type="bibr" target="#b49">(Theis et al., 2012)</ref>. MNIST log likelihoods were estimated using the Parzen-window code from <ref type="bibr" target="#b13">(Goodfellow et al., 2014)</ref>, with values given in bits, and show that our performance is comparable to other recent techniques. The perfect model entry was computed by applying the Parzen code to samples from the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">BINARY HEARTBEAT DISTRIBUTION</head><p>A diffusion probabilistic model was trained on simple binary sequences of length 20, where a 1 occurs every 5th time bin, and the remainder of the bins are 0, using a multilayer perceptron to generate the Bernoulli rates f b x (t) , t of the reverse trajectory. The log likelihood under the true distribution is log 2 1 5 = -2.322 bits per sequence. As can be seen in Figure <ref type="figure">2</ref> and Table <ref type="table">1</ref> learning was nearly perfect. See Appendix Section D.1.2 for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Images</head><p>We trained Gaussian diffusion probabilistic models on several image datasets. The multi-scale convolutional archi-tecture shared by these experiments is described in Appendix Section D.2.1, and illustrated in Figure D.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">DATASETS</head><p>MNIST In order to allow a direct comparison against previous work on a simple dataset, we trained on MNIST digits <ref type="bibr" target="#b29">(LeCun &amp; Cortes, 1998)</ref>. Log likelihoods relative to <ref type="bibr" target="#b2">(Bengio et al., 2012;</ref><ref type="bibr" target="#b1">Bengio &amp; Thibodeau-Laufer, 2013;</ref><ref type="bibr" target="#b13">Goodfellow et al., 2014)</ref> are given in Table <ref type="table" target="#tab_0">2</ref>. Samples from the MNIST model are given in Appendix Figure App.1. Our training algorithm provides an asymptotically consistent lower bound on the log likelihood. However most previous reported results on continuous MNIST log likelihood rely on Parzen-window based estimates computed from model samples. For this comparison we therefore estimate MNIST log likelihood using the Parzenwindow code released with <ref type="bibr" target="#b13">(Goodfellow et al., 2014)</ref>.</p><p>CIFAR-10 A probabilistic model was fit to the training images for the CIFAR-10 challenge dataset <ref type="bibr" target="#b25">(Krizhevsky &amp; Hinton, 2009)</ref>. Samples from the trained model are provided in Figure <ref type="figure">3</ref>.</p><p>Dead Leaf Images Dead leaf images <ref type="bibr" target="#b21">(Jeulin, 1997;</ref><ref type="bibr" target="#b30">Lee et al., 2001)</ref> consist of layered occluding circles, drawn from a power law distribution over scales. They have an analytically tractable structure, but capture many of the statistical complexities of natural images, and therefore provide a compelling test case for natural image models. As illustrated in Table <ref type="table" target="#tab_0">2</ref> and Figure <ref type="figure" target="#fig_2">4</ref>, we achieve state of the art performance on the dead leaves dataset.</p><p>Bark Texture Images A probabilistic model was trained on bark texture images (T01-T04) from <ref type="bibr" target="#b28">(Lazebnik et al., 2005)</ref>. For this dataset we demonstrate that it is straightforward to evaluate or generate from a posterior distribution, by inpainting a large region of missing data using a sample from the model posterior in Figure <ref type="figure" target="#fig_3">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>We have introduced a novel algorithm for modeling probability distributions that enables exact sampling and evaluation of probabilities and demonstrated its effectiveness on a variety of toy and real datasets, including challenging natural image datasets. For each of these tests we used a similar basic algorithm, showing that our method can accurately model a wide variety of distributions. Most existing density estimation techniques must sacrifice modeling power in order to stay tractable and efficient, and sampling or evaluation are often extremely expensive. The core of our algorithm consists of estimating the reversal of a Markov diffusion chain which maps data to a noise distribution; as the number of steps is made large, the reversal distribution of each diffusion step becomes simple and easy to estimate. The result is an algorithm that can learn a fit to any data distribution, but which remains tractable to train, exactly sample from, and evaluate, and under which it is straightforward to manipulate conditional and posterior distributions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4. Rewrite in terms of KL divergences and entropies</head><p>We then recognize that several terms are conditional entropies,</p><formula xml:id="formula_29">K = T t=2 dx (0•••T ) q x (0•••T ) log p x (t-1) |x (t) q x (t-1) |x (t) , x (0) + T t=2 H q X (t) |X (0) -H q X (t-1) |X (0) -H p X (T ) (49) = T t=2 dx (0•••T ) q x (0•••T ) log p x (t-1) |x (t) q x (t-1) |x (t) , x (0) + H q X (T ) |X (0) -H q X (1) |X (0) -H p X (T ) . (<label>50</label></formula><formula xml:id="formula_30">)</formula><p>Finally we transform the log ratio of probability distributions into a KL divergence, T ) .</p><formula xml:id="formula_31">K = - T t=2 dx (0) dx (t) q x (0) , x (t) D KL q x (t-1) |x (t) , x (0) p x (t-1) |x (t) (51) + H q X (T ) |X (0) -H q X (1) |X (0) -H p X<label>(</label></formula><p>Note that the entropies can be analytically computed, and the KL divergence can be analytically computed given x (0) and x (t) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gaussian Binomial</head><p>Well behaved (analytically tractable) distribution π x (T ) = N x (T ) ; 0, I B x (T ) ; 0.5</p><formula xml:id="formula_32">Forward diffusion kernel q x (t) |x (t-1) = N x (t) ; x (t-1) √ 1 -β t , Iβ t B x (t) ; x (t-1) (1 -β t ) + 0.5β t Reverse diffusion kernel p x (t-1) |x (t) = N x (t-1) ; f µ x (t) , t , f Σ x (t) , t B x (t-1) ; f b x (t) , t Training targets f µ x (t) , t , f Σ x (t) , t , β 1•••T f b x (t) , t Forward distribution q x (0•••T ) = q x (0) T t=1 q x (t) |x (t-1) Reverse distribution p x (0•••T ) = π x (T ) T t=1 p x (t-1) |x (t) Log likelihood L = dx (0) q x (0) log p x (0)</formula><p>Lower bound on log likelihood K = -</p><formula xml:id="formula_33">T t=2 E q(x (0) ,x (t) ) D KL q x (t-1) |x (t) , x (0) p x (t-1) |x (t) + H q X (T ) |X (0) -H q X (1) |X (0) -H p X (T )</formula><p>Perturbed reverse diffusion kernel p x (t-1) |x (t) = N x (t-1) ; f µ x (t) , t + f Σ x (t) , t</p><formula xml:id="formula_34">∂ log r x (t-1) ∂x (t-1) x (t-1) =fµ(x (t) ,t) , f Σ x (t) , t B x (t-1) i ; c t-1 i d t-1 i x t-1 i d t-1 i +(1-c t-1 i )(1-d t-1 i ) Table App.1.</formula><p>The key equations in this paper for the specific cases of Gaussian and binomial diffusion processes. N (u; µ, Σ) is a Gaussian distribution with mean µ and covariance Σ. B (u; r) is the distribution for a single Bernoulli trial, with u = 1 occurring with probability r, and u = 0 occurring with probability 1 -r. Finally, for the perturbed Bernoulli</p><formula xml:id="formula_35">trials b t i = x (t-1) (1 -βt) + 0.5βt, c t i = f b x (t+1) , t i ,<label>and</label></formula><formula xml:id="formula_36">d t i = r x (t) i = 1</formula><p>, and the distribution is given for a single bit i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Experimental Details</head><p>D.1. Toy Problems D.1.1. SWISS ROLL A probabilistic model was built of a two dimensional swiss roll distribution. The generative model p x (0•••T ) consisted of 40 time steps of Gaussian diffusion initialized at an identity-covariance Gaussian distribution. A (normalized) radial basis function network with a single hidden layer and 16 hidden units was trained to generate the mean and covariance functions f µ x (t) , t and a diagonal f Σ x (t) , t for the reverse trajectory. The top, readout, layer for each function was learned independently for each time step, but for all other layers weights were shared across all time steps and both functions. The top layer output of f Σ x (t) , t was passed through a sigmoid to restrict it between 0 and 1. As can be seen in Figure <ref type="figure" target="#fig_0">1</ref>, the swiss roll distribution was successfully learned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1.2. BINARY HEARTBEAT DISTRIBUTION</head><p>A probabilistic model was trained on simple binary sequences of length 20, where a 1 occurs every 5th time bin, and the remainder of the bins are 0. The generative model consisted of 2000 time steps of binomial diffusion initialized at an independent binomial distribution with the same mean activity as the data (p x (T ) i</p><p>= 1 = 0.2). A multilayer perceptron with sigmoid nonlinearities, 20 input units and three hidden layers with 50 units each was trained to generate the Bernoulli rates f b x (t) , t of the reverse trajectory. The top, readout, layer was learned independently for each time step, but for all other layers weights were shared across all time steps. The top layer output was passed through a sigmoid to restrict it between 0 and 1. As can be seen in Figure <ref type="figure">2</ref>, the heartbeat distribution was successfully learned. The log likelihood under the true generating process is log 2 1 5 = -2.322 bits per sequence. As can be seen in Figure <ref type="figure">2</ref> and Table <ref type="table">1</ref> learning was nearly perfect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2. Images</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2.1. ARCHITECTURE</head><p>Readout In all cases, a convolutional network was used to produce a vector of outputs y i ∈ R 2J for each image pixel i. The entries in y i are divided into two equal sized subsets, y µ and y Σ .</p><p>Temporal Dependence The convolution output y µ is used as per-pixel weighting coefficients in a sum over timedependent "bump" functions, generating an output z µ i ∈ R</p><p>for each pixel i,</p><formula xml:id="formula_37">z µ i = J j=1 y µ ij g j (t) .<label>(62)</label></formula><p>The bump functions consist of</p><formula xml:id="formula_38">g j (t) = exp -1 2w 2 (t -τ j ) 2 J k=1 exp -1 2w 2 (t -τ k ) 2 , (<label>63</label></formula><formula xml:id="formula_39">)</formula><p>where τ j ∈ (0, T ) is the bump center, and w is the spacing between bump centers. z Σ is generated in an identical way, but using y Σ .</p><p>For all image experiments a number of timesteps T = 1000 was used, except for the bark dataset which used T = 500.</p><p>Mean and Variance Finally, these outputs are combined to produce a diffusion mean and variance prediction for each pixel i,</p><formula xml:id="formula_40">Σ ii = σ z Σ i + σ -1 (β t ) , (<label>64</label></formula><formula xml:id="formula_41">) µ i = (x i -z µ i ) (1 -Σ ii ) + z µ i .<label>(65)</label></formula><p>where both Σ and µ are parameterized as a perturbation around the forward diffusion kernel T π x (t) |x (t-1) ; β t , and z µ i is the mean of the equilibrium distribution that would result from applying p x (t-1) |x (t) many times. Σ is restricted to be a diagonal matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-Scale Convolution</head><p>We wish to accomplish goals that are often achieved with pooling networks -specifically, we wish to discover and make use of long-range and multi-scale dependencies in the training data. However, since the network output is a vector of coefficients for every pixel it is important to generate a full resolution rather than down-sampled feature map. We therefore define multi-scale-convolution layers that consist of the following steps:</p><p>1. Perform mean pooling to downsample the image to multiple scales. Downsampling is performed in powers of two. 2. Performing convolution at each scale. 3. Upsample all scales to full resolution, and sum the resulting images. 4. Perform a pointwise nonlinear transformation, consisting of a soft relu (log [1 + exp (•)]).</p><p>The composition of the first three linear operations resembles convolution by a multiscale convolution kernel, up to blocking artifacts introduced by upsampling. This method of achieving multiscale convolution was described in <ref type="bibr" target="#b0">(Barron et al., 2013)</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. The proposed modeling framework trained on 2-d swiss roll data. The top row shows time slices from the forward trajectory q x (0•••T ) . The data distribution (left) undergoes Gaussian diffusion, which gradually transforms it into an identity-covariance Gaus-</figDesc><graphic coords="3,191.97,254.29,87.48,87.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .Figure 3 .</head><label>23</label><figDesc>Figure2. Binary sequence learning via binomial diffusion. A binomial diffusion model was trained on binary 'heartbeat' data, where a pulse occurs every 5th bin. Generated samples (left) are identical to the training data. The sampling procedure consists of initialization at independent binomial noise (right), which is then transformed into the data distribution by a binomial diffusion process, with trained bit flip probabilities. Each row contains an independent sample. For ease of visualization, all samples have been shifted so that a pulse occurs in the first column. In the raw sequence data, the first pulse is uniformly distributed over the first five bins.</figDesc><graphic coords="4,203.43,87.24,58.51,72.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. The proposed framework trained on dead leaf images (Jeulin, 1997; Lee et al., 2001). (a) Example training image. (b) A sample from the previous state of the art natural image model (Theis et al., 2012) trained on identical data, reproduced here with permission. (c) A sample generated by the diffusion model. Note that it demonstrates fairly consistent occlusion relationships, displays a multiscale distribution over object sizes, and produces circle-like objects, especially at smaller scales. As shown in Table 2, the diffusion model has the highest log likelihood on the test set.</figDesc><graphic coords="7,87.22,69.85,122.12,122.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Inpainting. (a) A bark image from<ref type="bibr" target="#b28">(Lazebnik et al., 2005)</ref>. (b) The same image with the central 100×100 pixel region replaced with isotropic Gaussian noise. This is the initialization p x (T ) for the reverse trajectory. (c) The central 100×100 region has been inpainted using a diffusion probabilistic model trained on images of bark, by sampling from the posterior distribution over the missing region conditioned on the rest of the image. Note the long-range spatial structure, for instance in the crack entering on the left side of the inpainted region. The sample from the posterior was generated as described in Section 2.5, where r x (0) was set to a delta function for known data, and a constant for missing data.</figDesc><graphic coords="8,114.85,69.45,104.68,104.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure App. 1 .</head><label>1</label><figDesc>Figure App.1. Samples from a diffusion probabilistic model trained on MNIST digits. Note that unlike many MNIST sample figures, these are true samples rather than the mean of the Gaussian or binomial distribution from which samples would be drawn.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 .</head><label>2</label><figDesc>Log likelihood comparisons to other algorithms. Dead leaves images were evaluated using identical training and test data as in</figDesc><table><row><cell></cell><cell>Log Likelihood</cell></row><row><cell>Dead Leaves</cell><cell></cell></row><row><cell>MCGSM</cell><cell>1.244 bits/pixel</cell></row><row><cell>Diffusion</cell><cell>1.489 bits/pixel</cell></row><row><cell>MNIST</cell><cell></cell></row><row><cell>Stacked CAE</cell><cell>174 ± 2.3 bits</cell></row><row><cell>DBN</cell><cell>199 ± 2.9 bits</cell></row><row><cell>Deep GSN</cell><cell>309 ± 1.6 bits</cell></row><row><cell>Diffusion</cell><cell>317 ± 2.7 bits</cell></row><row><cell cols="2">Adversarial net 325 ± 2.9 bits</cell></row><row><cell>Perfect model</cell><cell>349 ± 3.3 bits</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Non-parametric methods can be seen as transitioning smoothly between tractable and flexible models. For instance, a non-parametric Gaussian mixture model will represent a small amount of data using a single Gaussian, but may represent infinite data as a mixture of an infinite number of Gaussians.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Recent experiments suggest that it is just as effective to instead use the same fixed βt schedule as for binomial diffusion.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>An earlier version of this paper reported higher log likelihood bounds on CIFAR-10. These were the result of the model learning the 8-bit quantization of pixel values in the CIFAR-10 dataset. The log likelihood bounds reported here are instead for data that has been pre-processed by adding uniform noise to remove pixel quantization, as recommended in<ref type="bibr" target="#b50">(Theis et al., 2015)</ref>.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We thank <rs type="person">Lucas Theis</rs>, <rs type="person">Subhaneil Lahiri</rs>, <rs type="person">Ben Poole</rs>, <rs type="person">Diederik P. Kingma</rs>, <rs type="person">Taco Cohen</rs>, <rs type="person">Philip Bachman</rs>, and <rs type="person">Aäron van den Oord</rs> for extremely helpful discussion, and <rs type="person">Ian Goodfellow</rs> for Parzen-window code. We thank <rs type="person">Khan Academy</rs> and the <rs type="funder">Office of Naval Research for funding Jascha Sohl-Dickstein</rs>, and we thank the <rs type="institution">Office of Naval Research</rs> and the <rs type="funder">Burroughs-Wellcome</rs>, Sloan, and <rs type="person">James S. McDonnell</rs> foundations for funding <rs type="person">Surya Ganguli</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. Conditional Entropy Bounds Derivation</head><p>The conditional entropy H q X (t-1) |X (t) of a step in the reverse trajectory is H q X (t-1) , X (t) = H q X (t) , X (t-1)  (25)</p><p>H q X (t-1) |X (t) + H q X (t) = H q X (t) |X (t-1) + H q X (t-1) (26)</p><p>H q X (t-1) |X (t) = H q X (t) |X (t-1) + H q X (t-1) -H q X (t) (27)</p><p>An upper bound on the entropy change can be constructed by observing that π (y) is the maximum entropy distribution. This holds without qualification for the binomial distribution, and holds for variance 1 training data for the Gaussian case.</p><p>For the Gaussian case, training data must therefore be scaled to have unit norm for the following equalities to hold. It need not be whitened. The upper bound is derived as follows,</p><p>A lower bound on the entropy difference can be established by observing that additional steps in a Markov chain do not increase the information available about the initial state in the chain, and thus do not decrease the conditional entropy of the initial state,</p><p>H q X (t-1) -H q X (t) ≥ H q X (0) |X (t-1) + H q X (t-1) -H q X (0) |X (t) -H q X (t) (32)</p><p>H q X (t-1) -H q X (t) ≥ H q X (0) , X (t-1) -H q X (0) , X (t) (33)</p><p>Combining these expressions, we bound the conditional entropy for a single step,</p><p>where both the upper and lower bounds depend only on the conditional forward trajectory q x (1•••T ) |x (0) , and can be analytically computed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Log Likelihood Lower Bound</head><p>The lower bound on the log likelihood is</p><p>We can peel off the contribution from p X (T ) , and rewrite it as an entropy,</p><p>By design, the cross entropy to π x (t) is constant under our diffusion kernels, and equal to the entropy of p x (T ) . Therefore,</p><p>B.2. Remove the edge effect at t = 0</p><p>In order to avoid edge effects, we set the final step of the reverse trajectory to be identical to the corresponding forward diffusion step,</p><p>We then use this equivalence to remove the contribution of the first time-step in the sum,</p><p>where we again used the fact that by design -dx (t) q x (t) log π x (t) = H p X (T ) is a constant for all t.</p><p>B.3. Rewrite in terms of posterior q x (t-1) |x (0)</p><p>Because the forward trajectory is a Markov process,</p><p>Using Bayes' rule we can rewrite this in terms of a posterior and marginals from the forward trajectory,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Perturbed Gaussian Transition</head><p>We wish to compute p x (t-1) | x (t) . For notational simplicity, let µ = f µ x (t) , t , Σ = f Σ x (t) , t , and y = x (t-1) . Using this notation,</p><p>We can rewrite this in terms of energy functions, where E r (y) = -log r (y),</p><p>If E r (y) is smooth relative to 1 2 (y -µ) T Σ -1 (y -µ), then we can approximate it using its Taylor expansion around µ.</p><p>One sufficient condition is that the eigenvalues of the Hessian of E r (y) are everywhere much smaller magnitude than the eigenvalues of Σ -1 . We then have</p><p>where g = ∂Er(y ) ∂y y =µ</p><p>. Plugging this in to the full energy,</p><p>This corresponds to a Gaussian,</p><p>Substituting back in the original formalism, this is,</p><p>∂x (t-1)  t) passes through several layers of multiscale convolution (Section D.2.1). It then passes through several convolutional layers with 1 × 1 kernels. This is equivalent to a dense transformation performed on each pixel. A linear transformation generates coefficients for readout of both mean µ (t) and covariance Σ (t) for each pixel. Finally, a time dependent readout function converts those coefficients into mean and covariance images, as described in Section D.2.1. For CIFAR-10 a dense (or fully connected) pathway was used in parallel to the multi-scale convolutional pathway. For MNIST, the dense pathway was used to the exclusion of the multi-scale convolutional pathway.</p><p>Dense Layers Dense (acting on the full image vector) and kernel-width-1 convolutional (acting separately on the feature vector for each pixel) layers share the same form. They consist of a linear transformation, followed by a tanh nonlinearity.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Volumetric Semantic Segmentation Using Pyramid Context Features</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Biggin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Arbelaez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Knowles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Keranen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCV.2013.428</idno>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE International Conference on Computer Vision</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013-12">December 2013</date>
			<biblScope unit="page" from="3448" to="3455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Thibodeau-Laufer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1306.1091</idno>
		<title level="m">Deep generative stochastic networks trainable by backprop</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mesnil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rifai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1207.4404</idno>
		<title level="m">Better Mixing via Deep Representations</title>
		<imprint>
			<date type="published" when="2012-07">July 2012</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Theano: a CPU and GPU math expression compiler</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Breuleux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Python for Scientific Computing Conference (SciPy)</title>
		<meeting>the Python for Scientific Computing Conference (SciPy)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Statistical Analysis of Non-Lattice Data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Besag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Statistician</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="179" to="195" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">GTM: The generative topographic mapping</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Svensén</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Bornschein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Reweighted</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><surname>Wake</surname></persName>
		</author>
		<title level="m">Sleep. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015-06">June 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.8566</idno>
		<title level="m">Accurate and Conservative Estimates of MRF Log-likelihood using Reverse Annealing</title>
		<imprint>
			<date type="published" when="2014-12">December 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The helmholtz machine</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="889" to="904" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">NICE: Non-linear Independent Components Estimation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.8516</idno>
		<imprint>
			<date type="published" when="2014-10">October 2014</date>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On the theory of stochastic processes, with particular reference to applications</title>
		<author>
			<persName><forename type="first">W</forename><surname>Feller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the [First] Berkeley Symposium on Mathematical Statistics and Probability. The Regents of the University of California</title>
		<meeting>the [First] Berkeley Symposium on Mathematical Statistics and Probability. The Regents of the University of California</meeting>
		<imprint>
			<date type="published" when="1949">1949</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A tutorial on Bayesian nonparametric models</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Strictly proper scoring rules, prediction, and estimation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gneiting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Raftery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">477</biblScope>
			<biblScope unit="page" from="359" to="378" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Generative Adversarial Nets</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1310.8499</idno>
		<title level="m">Deep AutoRegressive Networks</title>
		<imprint>
			<date type="published" when="2013-10">October 2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Annealing between distributions by averaging moments</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2769" to="2777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Training products of experts by minimizing contrastive divergence</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1771" to="1800" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The wake-sleep algorithm for unsupervised neural networks )</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Estimation of non-normalized statistical models using score matching</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="695" to="709" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Equilibrium free-energy differences from nonequilibrium measurements: A master-equation approach</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jarzynski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<date type="published" when="1997-01">January 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Equalities and inequalities: irreversibility and the second law of thermodynamics at the nanoscale</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jarzynski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Condens. Matter Phys</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Dead leaves models: from space tesselation to random functions</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jeulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Symposium on the Advances in the Theory and Applications of Random Sets</title>
		<meeting>of the Symposium on the Advances in the Theory and Applications of Random Sets</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An introduction to variational methods for graphical models</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="183" to="233" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Fast inference in sparse coding algorithms with applications to object recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1010.3467</idno>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Auto-Encoding Variational Bayes</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2013-12">December 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>Computer Science Department University of Toronto Tech</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Sur la théorie du mouvement brownien</title>
		<author>
			<persName><forename type="first">P</forename><surname>Langevin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CR Acad. Sci</title>
		<imprint>
			<biblScope unit="volume">146</biblScope>
			<biblScope unit="page" from="530" to="533" />
			<date type="published" when="1908">1908</date>
			<pubPlace>Paris</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The neural autoregressive distribution estimator</title>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A sparse texture representation using local affine regions. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1265" to="1278" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">The MNIST database of handwritten digits</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Occlusion models for natural images: A statistical study of a scale-invariant dead leaves model</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Unifying Non-Maximum Likelihood Learning Objectives with Minimum KL Contraction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="64" to="72" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Bayesian neural networks and density networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mackay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Loopy belief propagation for approximate inference: An empirical study</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth conference on Uncertainty in artificial intelligence</title>
		<meeting>the Fifteenth conference on Uncertainty in artificial intelligence</meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="467" to="475" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Annealed importance sampling</title>
		<author>
			<persName><forename type="first">R</forename><surname>Neal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and Computing</title>
		<imprint>
			<date type="published" when="2001-01">January 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.0630</idno>
		<title level="m">Deep Directed Generative Autoencoders</title>
		<imprint>
			<date type="published" when="2014-10">October 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Proper local scoring rules</title>
		<author>
			<persName><forename type="first">M</forename><surname>Parry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Dawid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lauritzen</surname></persName>
		</author>
		<author>
			<persName><surname>Others</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="561" to="592" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Stochastic Backpropagation and Approximate Inference in Deep Generative Models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Machine Learning (ICML-14)</title>
		<meeting>the 31st International Conference on Machine Learning (ICML-14)</meeting>
		<imprint>
			<date type="published" when="2014-01">January 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">O</forename><surname>Rippel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><surname>High</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.8516</idno>
		<title level="m">Dimensional Probability Estimation with Deep Density Models</title>
		<imprint>
			<date type="published" when="2013-02">February 2013</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning factorial codes by predictability minimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning joint top-down and bottom-up processes for 3D visual inference</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sminchisescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kanaujia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006">2006. 2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1743" to="1752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">New Method for Parameter Estimation in Probabilistic Models: Minimum Probability Flow</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Battaglino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Deweese</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevLett.107.220601</idno>
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<idno type="ISSN">0031- 9007</idno>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="11" to="14" />
			<date type="published" when="2011-11">November 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Minimum Probability Flow Learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Battaglino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Deweese</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevLett.107.220601</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2011-11">November 2011</date>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="11" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Fast largescale optimization by unifying stochastic gradient and quasi-Newton methods</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Machine Learning (ICML-14)</title>
		<meeting>the 31st International Conference on Machine Learning (ICML-14)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="604" to="612" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Fluctuation Relations : A Pedagogical Overview</title>
		<author>
			<persName><forename type="first">R</forename><surname>Spinney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ford</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1201.6381</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3" to="56" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning stochastic inverses</title>
		<author>
			<persName><forename type="first">A</forename><surname>Stuhlmüller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Nonconvex optimization using a Fokker-Planck learning machine</title>
		<author>
			<persName><forename type="first">J</forename><surname>Suykens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vandewalle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th European Conference on Circuit Theory and Design</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Convergence condition of the TAP equation for the infinite-ranged Ising spin glass model</title>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Phys. A: Math. Gen</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<date type="published" when="1971">1971. 1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Mean-field theory of Boltzmann machine learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Tanaka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters E</title>
		<imprint>
			<date type="published" when="1998-01">January 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Mixtures of conditional Gaussian scale mixtures applied to multiscale image representations</title>
		<author>
			<persName><forename type="first">L</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bethge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">39857</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">A note on the evaluation of generative models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bethge</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.01844</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">RNADE: The real-valued neural autoregressive density-estimator</title>
		<author>
			<persName><forename type="first">B</forename><surname>Uria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Uria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1310.1757</idno>
		<title level="m">A Deep and Tractable Density Estimator</title>
		<imprint>
			<date type="published" when="2013-10">October 2013</date>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">B</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chorowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Serdyuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bogdanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Warde-Farley</forename></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Blocks</surname></persName>
		</author>
		<author>
			<persName><surname>Fuel</surname></persName>
		</author>
		<author>
			<persName><surname>Zenodo</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.17721</idno>
		<imprint>
			<date type="published" when="2015-05">May 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A new learning algorithm for mean field Boltzmann machines</title>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2002-01">January 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">On the Equivalence Between Deep NADE and Generative Stochastic Networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="322" to="336" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
