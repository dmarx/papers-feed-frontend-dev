{
  "arxivId": "1804.03329",
  "title": "Representation Tradeoffs for Hyperbolic Embeddings",
  "authors": "Christopher De Sa, Albert Gu, Christopher R\u00e9, Frederic Sala",
  "abstract": "Hyperbolic embeddings offer excellent quality with few dimensions when\nembedding hierarchical data structures like synonym or type hierarchies. Given\na tree, we give a combinatorial construction that embeds the tree in hyperbolic\nspace with arbitrarily low distortion without using optimization. On WordNet,\nour combinatorial embedding obtains a mean-average-precision of 0.989 with only\ntwo dimensions, while Nickel et al.'s recent construction obtains 0.87 using\n200 dimensions. We provide upper and lower bounds that allow us to characterize\nthe precision-dimensionality tradeoff inherent in any hyperbolic embedding. To\nembed general metric spaces, we propose a hyperbolic generalization of\nmultidimensional scaling (h-MDS). We show how to perform exact recovery of\nhyperbolic points from distances, provide a perturbation analysis, and give a\nrecovery result that allows us to reduce dimensionality. The h-MDS approach\noffers consistently low distortion even with few dimensions across several\ndatasets. Finally, we extract lessons from the algorithms and theory above to\ndesign a PyTorch-based implementation that can handle incomplete information\nand is scalable.",
  "url": "https://arxiv.org/abs/1804.03329",
  "issue_number": 457,
  "issue_url": "https://github.com/dmarx/papers-feed/issues/457",
  "created_at": "2025-01-04T14:49:30.230276",
  "state": "open",
  "labels": [
    "paper",
    "rating:novote"
  ],
  "total_reading_time_seconds": 0,
  "last_read": null,
  "last_visited": "2024-12-29T02:34:35.575Z",
  "main_tex_file": null,
  "published_date": "2018-04-10T03:39:16Z",
  "arxiv_tags": [
    "cs.LG",
    "stat.ML"
  ]
}