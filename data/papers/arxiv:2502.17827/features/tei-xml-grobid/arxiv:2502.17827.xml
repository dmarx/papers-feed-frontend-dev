<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DPGLM: A Semiparametric Bayesian GLM with Inhomogeneous Normalized Random Measures</title>
				<funder ref="#_aYSNyPb">
					<orgName type="full">National Institutes of Health</orgName>
					<orgName type="abbreviated">NIH</orgName>
				</funder>
				<funder ref="#_Zya7xcb">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-02-25">25 Feb 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Entejar</forename><surname>Alam</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistics and Data Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><forename type="middle">J</forename><surname>Rathouz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistics and Data Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Population Health</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Peter</forename><surname>Müller</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistics and Data Sciences</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">University of Texas at Austin</orgName>
								<address>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DPGLM: A Semiparametric Bayesian GLM with Inhomogeneous Normalized Random Measures</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-02-25">25 Feb 2025</date>
						</imprint>
					</monogr>
					<idno type="MD5">79CD5472CB1E9A8CF40B5B242FA0B046</idno>
					<idno type="arXiv">arXiv:2502.17827v1[stat.ME]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-03-18T18:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Dependent Dirichlet process</term>
					<term>Normalized random measures</term>
					<term>Lévy-Khintchine representation</term>
					<term>Density regression</term>
					<term>Semiparametric generalized linear model</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We introduce a varying weight dependent Dirichlet process (DDP) model to implement a semi-parametric GLM. The model extends a recently developed semi-parametric generalized linear model (SPGLM) by adding a nonparametric Bayesian prior on the baseline distribution of the GLM. We show that the resulting model takes the form of an inhomogeneous completely random measure that arises from exponential tilting of a normalized completely random measure. Building on familiar posterior simulation methods for mixtures with respect to normalized random measures we introduce posterior simulation in the resulting semi-parametric GLM model. The proposed methodology is validated through a series of simulation studies and is illustrated using data from a speech intelligibility study.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We introduce a non-parametric Bayesian extension of the semi-parametric GLM defined in <ref type="bibr" target="#b17">Rathouz and Gao [2009]</ref>. Under the proposed model, the marginal distribution of the response, conditional on a given covariate takes the (approximate -to be made more precise later) form of an inhomogeneous normalized random measure (NRM) <ref type="bibr" target="#b18">[Regazzini et al., 2003</ref>].</p><p>The joint model (across covariates x) is a variation of the popular dependent Dirichlet process (DDP) model <ref type="bibr" target="#b11">[MacEachern, 2000;</ref><ref type="bibr" target="#b16">Quintana et al., 2022]</ref>, replacing the marginal DP by an exponentially tilted DP with varying weights across covariates. We discuss the model construction, including representations as NRM and DDP models, and characterize the posterior law. Appropriate extensions of the results in <ref type="bibr" target="#b6">James et al. [2009]</ref> allow for straightforward posterior simulation. We validate the proposed model with a simulation study and illustrate it with an application on speech intelligibiliy development in children across ages 30 to 96 months.</p><p>We build on the semi-parametric GLM introduced in Rathouz and Gao <ref type="bibr">[2009]</ref>. Consider a GLM p x (y) ≡ p(y | x) ∝ exp(θ x y)µ(y)</p><p>(1)</p><p>with continuous response y ∈ Y ⊂ R and a p-dimensional covariate vector x ∈ X and (log)</p><formula xml:id="formula_0">normalization constant b(θ x ) = log Y exp(θ x y)µ(dy).<label>(2)</label></formula><p>In anticipation of the upcoming discussion, we allow µ(y) to be an un-normalized positive measure, implying a baseline density (i.e., when θ x = 0 in (2)) f µ = µ/µ(Y) in the GLM</p><p>(1). While in the classical GLM, the baseline distribution is assumed to be in a parametric family, in the semi-parametric SPGLM model the measure µ(y) itself becomes an unknown parameter. As in the classical GLM, we introduce a linear predictor η = x T β, and a link function g to implicitly define θ by requiring λ ≡ E(y | x) = g -1 (η). That is,</p><formula xml:id="formula_1">λ(x) = E(y | x) = b ′ (θ x ) = Y y exp{θ x y -b(θ x )}µ(dy). (<label>3</label></formula><formula xml:id="formula_2">)</formula><p>Noting that, for given µ, b ′ (θ) is a strictly increasing function of θ and invertible we have</p><formula xml:id="formula_3">θ x = b ′ -1 (λ; µ) def = θ(β, µ, x).</formula><p>Here we added µ to the arguments of b ′ -1 to highlight the dependence on µ. Alternatively, when we want to highlight dependence on β and x, indirectly through λ, we write θ x = θ(β, µ, x).</p><p>The defining characteristic of the SPGLM is a nonparametric baseline or reference distri-bution f µ that replaces a parametric specification in the classical GLM such as a binomial or Poisson model. Keeping f µ nonparametric instead, the analyst needs to only specify the linear predictor and link function, even avoiding a variance function, leaving model specification less onerous than even with quasilikehood (QL) models, while still yielding a valid likelihood function. Beyond the initial introduction of the SPGLM by <ref type="bibr" target="#b17">Rathouz and Gao [2009]</ref>, which focused primarily on the finite support case, <ref type="bibr" target="#b4">Huang [2014]</ref> characterized the SPGLM in the infinite support case, and <ref type="bibr" target="#b13">Maronge et al. [2023]</ref> discussed the use with outcome-dependent or generalized case-control sampling. In <ref type="bibr" target="#b17">Rathouz and Gao [2009]</ref> and <ref type="bibr">Wurm and Rathouz [2018]</ref>, the SPGLM model is referred to as generalized linear density ratio model (GLDRM),</p><p>and Wurm and <ref type="bibr">Rathouz [2018]</ref> fully develop the current ML computational algorithm and, including a working package gldrm on CRAN [Wurm and <ref type="bibr">Rathouz, 2024]</ref>. Despite these developments, there are still many important gaps in the literature. These include inference for application-driven functionals of the fitted models such as exceedance probabilities, which are crucial in clinical diagnosis <ref type="bibr" target="#b15">[Paul et al., 2021]</ref>; natural hazard detection <ref type="bibr" target="#b8">[Kossin et al., 2020]</ref>; financial risk management <ref type="bibr">[Taylor and Yu, 2016]</ref>; conditional quartiles <ref type="bibr">[Davino et al., 2022]</ref> or in general, any decision-making setting. These inference problems are not straightforward to address with maximum likelihood based approaches. In this paper, we set the table to address these gaps by developing a non-parametric Bayesian (BNP) extension of the SPGLM. In this BNP model we introduce µ as an (un-normalized) positive random measure. We use a prior on µ to implicitly define an exponentially tilted DP prior for p x in (1).</p><p>In Section 2.1, we introduce the proposed semiparametric Bayesian extension of the SPGLM, and characterize it as a variation of the popular DDP model in Section 2.2, and in Section 2.3 we show a representation of the implied marginal for one covariate as an inhomogeneous NRM. In Section 3 we characterize the posterior distribution under the DPGLM by showing it to be conditionally conjugate given auxiliary variables similar to the construction used in <ref type="bibr" target="#b6">James et al. [2009]</ref>. Section 4 summarizes a simulation study.</p><p>Section 5 discusses an application, and Section 6 concludes with a final discussion.</p><p>2 The DPGLM Model 2.1 A Bayesian semiparametric SPGLM</p><p>We extend (1)-( <ref type="formula" target="#formula_1">3</ref>) to a Bayesian inference model by adding a prior probability model for all unknown parameters, including in particular the baseline density f µ (•) ≡ µ µ(Y). Prior models for random probability measures like f µ are known as non-parametric Bayesian models (BNP) <ref type="bibr" target="#b3">[Ghosal and Van der Vaart, 2017]</ref>. The most widely used BNP model is the Dirichlet process (DP) prior introduced in the the seminal work of <ref type="bibr" target="#b1">Ferguson [1973]</ref>. The DP prior is characterized by two parameters: a concentration parameter α and a base distribution G 0 . We write G ∼ DP(α, G 0 ). One of the many defining properties of the DP is the stick-breaking representation of <ref type="bibr" target="#b19">Sethuraman [1994]</ref> for G ∼ DP(α, G 0 ) as</p><formula xml:id="formula_4">G(•) ≡ ∞ h=1 s h δ z h (•) (4)</formula><p>with atoms z h iid ∼ G 0 , and weights</p><formula xml:id="formula_5">s h = v h ℓ&lt;h (1 -v ℓ ), where v h iid ∼ Be(1, α).</formula><p>An alternative defining property of the DP prior is as a normalized completely random measure. A completely random measure (CRM) is a random measure µ with the property that the random measures assigned to any two non-overlapping events A, B are independent, <ref type="bibr" target="#b7">Kingman, 1967]</ref>. A CRM is characterized by its</p><formula xml:id="formula_6">that is µ(A) ⊥ µ(B) when A ∩ B = ∅ [</formula><p>Laplace transform E[exp{-h(y)µ(dy)}] for any measurable function h, which in turn is completely characterized by the Lévy intensity ν(ds, dy) that appears in the Lévy-Khintchine representation E e -Y h(y)µ(dy) = exp -</p><formula xml:id="formula_7">R + ×Y</formula><p>1 -e -sh(y) ν(ds, dy) .</p><p>(5)</p><p>If ν factors as ν(s, y) = ρ(s) G 0 (y) the CRM is known as a homogeneous CRM. <ref type="bibr" target="#b18">Regazzini et al. [2003]</ref> introduced the wide class of normalized random measures (NRM) by defining a BNP prior for a random probability measure f µ as µ/µ(Y), with a CRM µ. The DP is a special case of NRM, using a normalized gamma CRM with Lévy intensity ν(ds, dy) = e -s s ds • αG 0 (dy) (6)</p><p>for a DP (α, G 0 ). We use a gamma CRM as prior model for µ in the SPGLM (1), with base measure G 0 on the support Y and concentration parameter α, implying a DP prior on the baseline density f µ . We add a normal prior on β to complete the prior specification</p><formula xml:id="formula_8">µ ∼ Gamma CRM(ν) with ν(ds, dy) = e -s s ds • αG 0 (dy) β ∼ MVN(µ β , Σ β ).<label>(7)</label></formula><p>The two lines of (7) jointly imply a prior on F = {p x : x ∈ X }. We add one more extension by adding a convolution with a continuous kernel K(y i | z i ) and a latent variable z i to define a continuous sampling model for y. Using a symmetric kernel K(•), this does not change the mean regression structure of the GLM, as E(</p><formula xml:id="formula_9">y i | x i ) = E z i |x i {E(y i | x i , z i )} = g -1 (x ′ i β).</formula><p>For reference, we state the complete hierarchical model: In the model statement we introduce notation G x (z) for the sampling model p(z | x) for the latent z i (similar to p x for observed y i in (1)).</p><formula xml:id="formula_10">y i | z i ∼ K(y i | z i ), conditionally independent of x i , µ, β<label>(8)</label></formula><formula xml:id="formula_11">z i | x i = x, µ, β ∼ G x (z i ) ∝ exp(θ x z i )µ(z i ), with b ′ (θ x ) = g -1 (x ′ β) = λ(x) µ ∼ Gamma CRM(ν), with ν(ds, dz) = e -s s ds • αG 0 (dz) β ∼ MVN(µ β , Σ β ) .</formula><p>Recall that θ x = θ x (β, µ) is a derived parameter. We refer to the proposed model (8) as DPGLM. Also, we refer to µ i = µ(z; θ x i ) ≡ exp(θ x i z)µ(z) as the tilted CRM, with tilting parameter θ x i .</p><p>Finally, a note on identifiability in model ( <ref type="formula" target="#formula_10">8</ref>). Consider a pair µ, {θ x ; x ∈ X}, and another one with µ ′ ≡ µ • e cz and {θ ′ x = θ x -c}. All else being equal, the two sets of parameters have identical likelihood. For a meaningful report of inference on µ we will use post-processing to replace µ with µ ≡ µ • e cz , with c to ensure z df µ (z) = m 0 for a fixed m 0 , specified by the analyst. An interesting alternative could be to restrict the prior on µ using a generalized notion of conditioning a DP prior that is introuced in current work by <ref type="bibr" target="#b9">Lee and Lee [2024]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">A varying weights DDP</head><p>MacEachern [2000] first introduced the dependent Dirichlet process (DDP) by extending the DP model to a family of random distributions {G x : x ∈ X }. The construction starts by assuming marginally, for each x, a DP prior for each G x = w xh δ m xh . The desired dependence can then be accomplished by using shared w xh = w h and defining a dependent prior for {m xh , x ∈ X} while maintaning independence across h, as required for the marginal DP prior. This defines the common weights DDP. Alternatively one can use common atoms z h with a dependent prior on varying weights {w xh , x ∈ X} (common atoms DDP), or use varying weights and atoms. See, for example, Quintana et al. [2022] for a review of the many different instances of DDP models. A commonly used version are common weights and Gaussian process (GP) priors for {m xh , x ∈ X}, independently across h [MacEachern, 2000].</p><p>In the proposed DPGLM approach (8), dependence is introduced naturally through weights w xh (defined below) while keeping atoms z h constant across x. Starting from the representation (4) for a (single) DP prior we define G x (z) as follows:</p><formula xml:id="formula_12">G x (z) = exp {θ x z -b(θ x )} µ(z) = exp {θ x z -b(θ x )} ∞ h=1 s h δ z h (z) = ∞ h=1 [exp {θ x z h -b(θ x )} s h ] δ z h (z) = ∞ h=1 w xh δ z h (z), (<label>9</label></formula><formula xml:id="formula_13">)</formula><p>where w xh = exp {θ x z -b(θ x )} s h , depends on x implicitly through θ x . That is, w xh are introduced by exponential tilting of one random measure µ which is shared across all x. The model defines a variation of a DDP model using comon atoms and varying weights. However, the exponential tilting in (9) defines a marginal prior G x beyond a DP model, as we shall discuss next in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">The marginal model</head><p>The implied marginal model G x (z) for given covariate x in (8) can be shown to be an NRM again. This is seen by noting that the Laplace transform of G x takes the form of (5) again, allowing us to recognize the NRM by inspection of the Lévy intensity in (8).</p><p>Proposition 1. [Nieto- <ref type="bibr" target="#b14">Barajas et al., 2004]</ref> Consider the DPGLM with implied marginal distribution G x (z) ∝ exp(θ x z)µ(z), assuming a gamma CRM (6), i.e., µ µ(Y) = f µ ∼ DP(α, G 0 ), and given θ x . Then G x is an inhomogeneous normalized random measure (NRM) with Lévy intensity,</p><formula xml:id="formula_14">ν(ds, dz) = 1 s e -s exp(-θxz) ds • αG 0 (dz)<label>(10)</label></formula><p>The Lévy intensity ν in (10) characterizes an inhomogeneous NRM, with ρ(ds | z) =</p><p>1 s e -s exp (-θxz) ds varying with z.</p><p>The use of the DP prior for f µ makes the result in (10) particularly simple, allowing a closed form expression. A similar result, albeit not necessarily in closed form anymore, is true under any other NRM prior for f µ . For example, <ref type="bibr" target="#b10">Lijoi et al. [2007]</ref> argue for the richer class of normalized generalized gamma, which includes the DP as a special case. One common reason to consider alternatives to the DP prior is the lack of flexibility in modeling the random partition implied by ties of a sample from a DP random measure. In more detail, in the context of ( <ref type="formula" target="#formula_10">8</ref>) the discrete nature of µ(•) gives rise to ties among the z i . Using a DP prior, under θ x = 0 the random partition characterized by the configuration of ties is known as the Chinese restaurant process. It is indexed by a single hyperparameter, α. De Blasi et al. <ref type="bibr">[2013]</ref>, for example, argue that the nature of this random partition is too restrictive for many applications. However, in the context of the DPGLM, the random partition is not an inference target, and we shall never interpret the corresponding clusters, leaving the DP prior as an analytically and computationally appealing prior choice for µ.</p><p>The BNP prior for G x (z) and the kernel in the first two levels of the DPGLM model ( <ref type="formula" target="#formula_10">8</ref>) define a variation of popular BNP mixture models. The use of the particular NRM with Lévy intensity (10) arises naturally in the context of the GLM-style regression with the exponential tilting. Posterior simulation for BNP mixtures with NRM priors on the mixing measure is discussed, for example, in Argiento et al. <ref type="bibr">[2010]</ref>, <ref type="bibr">Barrios et al. [2013]</ref> or <ref type="bibr" target="#b0">Favaro and Teh [2013]</ref>. However, the GLM regression introduces a complication by applying different exponential tilting for each unique covariate x i . This leads to some variations in the posterior characterization and the corresponding posterior simulation algorithms. We next discuss those changes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Posterior characterization</head><formula xml:id="formula_15">Let D n denote the observed data {x i , y i } n i=1 , with x i ∈ X ⊂ R p and y i ∈ Y ⊂ R, and<label>(8)</label></formula><p>adds the latent variables z i . For simplicity we write θ i for θ x i , and define T i as the total mass for the tilted and un-normalized CRM µ i as T i = Y exp(θ i z)µ(dz). We can then adapt the results from Section 2 in <ref type="bibr" target="#b6">James et al. [2009]</ref> to characterize the posterior distribution under the DPGLM model ( <ref type="formula" target="#formula_10">8</ref>).</p><p>We first introduce a data augmentation scheme with auxiliary variables u i , using one auxiliary variable for each unique covariate vector x i . For the moment we assume n unique covariate vectors (and shall comment later on simple modifications to accommodate the more general case). We define</p><formula xml:id="formula_16">u i | T i ≡ T (θ i , µ) ∼ γ i /T i</formula><p>for independent (across i and also from T i ) exponential random variables γ i , implying p(u i |</p><formula xml:id="formula_17">T i ) = Ga(1, T i ) with the parameterization such that E(u i | T i ) = 1/T i .</formula><p>Recall that as a normalizing constant, T i is a function of all model parameters including µ. We first state the conditional posterior for u = (u 1 , . . . , u n ), conditional on z i , but marginalizing w.r.t. µ</p><p>(and thus T i ).</p><formula xml:id="formula_18">Proposition 2. Let θ = (θ 1 , . . . , θ n ) and z = (z 1 , . . . , z n ). Then p(u | θ, z) ∝ exp - Y log 1 + n i=1 u i exp(θ i v) G n (dv) ,</formula><p>where</p><formula xml:id="formula_19">G n = αG 0 + n i=1 δ z i .</formula><p>The proof is implied as part of the proof for the next result. As mentioned, the discrete nature of µ introduces ties in z i . Let {z ⋆ 1 , . . . , z ⋆ k } denote the unique values among the currently imputed {z 1 , . . . , z n }, with multiplicity {n ⋆ 1 , . . . , n ⋆ k }. Then G n in Proposition 2 can be written as</p><formula xml:id="formula_20">G n = αG 0 + k ℓ=1 n ⋆ ℓ δ z ⋆ ℓ . Clearly, k ℓ=1 n ⋆ ℓ = n.</formula><p>Conditional on u and for fixed θ the posterior on µ is a inhomogeneous CRM (but in the following statement, by a slight abuse of notation, we still include θ in the conditioning subset).</p><p>Proposition 3. Let θ = (θ 1 , . . . , θ n ), and z = (z 1 , . . . , z n ) with k unique values z ⋆ ℓ , ℓ = 1, . . . , k, with multiplicities n ⋆ ℓ . Then µ includes atoms at the z ⋆ ℓ with random probability masses J ℓ . Letting µ o denote the remaining part of µ we have</p><formula xml:id="formula_21">µ | u, z, θ d = µ o + k ℓ=1 J ℓ δ z ⋆ ℓ , where 1. µ o d = CRM (ν o ) with Lévy intensity ν o (ds, dz) = 1 s e -{1+ n i=1 u i exp(θ i z)}s ds • αG 0 (dz). 2. Let ψ(z ⋆ ℓ ; u, θ) = 1 + n i=1 u i exp(θ i z ⋆ ℓ ). Then p (J ℓ | u, θ, z ⋆ ℓ , n ⋆ ℓ ) ∝ s n ⋆ ℓ -1 e -{1+ n i=1 u i exp(θ i z ⋆ ℓ )}s ≡ Ga (n ⋆ ℓ , ψ(z ⋆ ℓ ; u, θ)) . ℓ = 1, . . . , k,</formula><p>and µ o and J ℓ are independent given u, θ.</p><p>Proposition 3 shows that given z and u, and for fixed θ, a posteriori µ is again a CRM.</p><p>To be precise, it is a sum of two components. One part is an inhomogeneous CRM µ o = ∞ ℓ=1 J ℓ δ z ℓ with Lévy intensity ν o . The random atoms z ℓ and weights J ℓ can be generated using, for example, the <ref type="bibr" target="#b2">Ferguson and Klass [1972]</ref> algorithm. The second component is a finite discrete measure with gamma distributed random weights J ℓ at fixed atoms z ⋆ ℓ . We update the latent variables z i using their complete conditional distribution:</p><formula xml:id="formula_22">p(z i | µ, θ i ) ∝ K(y i | z i ) ℓ exp(θ i z i ) Jℓ δ zℓ (z i ), where {z ℓ } ℓ≥1 = {z ℓ } ℓ≥1 ∪ {z ⋆ ℓ } k ℓ=1 and { Jℓ } ℓ≥1 = { Jℓ } ℓ≥1 ∪ {J ℓ } k ℓ=1 .</formula><p>There is one important detail about Proposition 3. The result holds for fixed θ. However, in (8) we use instead the derived parameter θ x = θ x (µ). This adds more information on µ, indirectly through θ x (µ). Unfortunately, the result of Proposition 3 hinges on independent sampling with given, fixed exponential tilting, and is not easily extended to using θ x (µ). Instead, we exploit Proposition 3 to implement a Metropolis-Hastings (MH) transition probability. Let θ x = θ x (µ) denote the derived parameters θ x = θ x (µ) implied by the currently imputed CRM µ. Let then q(µ ⋆ | µ) denote the inhomogeneous CRM described in Proposition 3 with fixed θ x = θ x (µ). That is, the described distribution on µ ⋆ under fixed θ implied by the currently imputed µ. We then treat µ ⋆ as a proposal in a MH transition probability and follow up with a MH rejection step with acceptance ratio r. See Appendix A.2 for details of evaluating r.</p><p>Finally, in the general case with possible ties of the covariate vectors x i , one could still use the same results, with n auxiliary variables u i . Alternatively, the following construction could be used with fewer auxiliary variables. Let ξ j , j = 1, . . . , J denote the unique covariate combinations with multiplicities a j . Let then T j denote the normalization constant under covariate x = ξ j . Similar results as above hold, starting with latent variables u j ∼ Ga(a j , T j ).</p><p>We list details of the posterior MCMC simulation in Appendix A.2. Finally, for reporting posterior inference we use post-processing to address lack of likelihood identifiability for f µ .</p><p>Recall the note at the end of Section 2.1 about likelihood identifiability of µ. For more meaningful posterior summaries we report inference on f µ subject to y df µ (y) = m 0 for a fixed m 0 . In practice, the choice of m 0 can be based on prior judgement, or alternatively one can use any measure of central tendency of y, such as the mean or median.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Simulation Studies</head><p>We proceed with simulation studies to evaluate the frequentist operating characteristics inference under the DPGLM model. We aim to address the following key questions: (Q1)</p><p>How does the model perform in terms of predictive accuracy when estimating the baseline density, f µ (y), or the corresponding cumulative distribution function, F µ (y), under various scenarios? (Q2) Do the credible intervals for f µ (y) achieve coverage rates close to their nominal levels? (Q3) Do the credible intervals for β j attain nominal coverage? How is their predictive accuracy?</p><p>We study these questions under realistic sample sizes and simulation truths mimicking the data analysis presented later, in Section 5 using the Speech Intelligibility dataset, with outcomes y ∈ [0, 1].</p><p>Data generating mechanism. We consider the following three scenarios. For each setting, we generate covariates X i ∼ Unif(a, b), with a = -√ 12/4 and b = √ 12/4, implying sd(X i ) = 1/2. We use D n to refer to the observed data {x i , y i } n i=1 .</p><p>• Null case (scenario I): Let f (kde) µ denote a kernel density estimate based on the response data y from the Speech Intelligibility dataset (ignoring covariates). We use f (kde) µ as the simulation truth for the baseline density f µ . We sample y independent of x i.e,</p><formula xml:id="formula_23">y i ∼ f (kde) µ</formula><p>. This setting aims to address Q1 and Q2.</p><p>• Regression (scenario II): We consider the same framework as in setting I, with one modification: The sampling of y now depends on x. Specifically, we sample</p><formula xml:id="formula_24">y i ∼ p(y i | x i ) ∝ exp(θ x i y i )f (kde) µ (y i ), where θ x = b ′ -1 {g -1 (η x )}, with η x = β 0 + x T β.</formula><p>We set β 0 = 0.2 and β 1 = 0.7. This setting aims to address Q1, Q2 and Q3.</p><p>In the following discussion, recall that under the DPGLM the baseline density is a derived</p><formula xml:id="formula_25">parameter f µ = µ/µ(Y).</formula><p>For each setting and under sample sizes n = 25, 50, 100, 250, we generate 100 datasets.</p><p>For each data set we fit the proposed DPGLM model, using a Unif(z -c, z + c) kernel K with c = 0.025 and the prior distributions as in ( <ref type="formula" target="#formula_10">8</ref>) with α = 1 and G 0 = uniform(0, 1).</p><p>We implement MCMC posterior simulation for β and µ using the transition probabilities detailed in A.2; a total of 2, 000 MCMC samples are generated for each data replicate. We discard the first 1, 000 iterations as initial burn-in and use the remaining R = 1, 000 Monte Carlo samples for the results.</p><p>To formalize the questions Q1-Q3 we employ the following performance metrics. For (Q1), we use the Kolmogorov-Smirnov (KS) test statistic D n = sup y |F µ,n (y) -F µ (y)| to measure the goodness of fit in estimating F µ (y). In addition, we calculate the mean integrated squared error (MISE) for the estimation of f µ (y), defined as: MISE = ( fµ (y) -f µ (y)) 2 dy. To ensure valid comparisons, we tilt the posterior samples of f µ (y) to have a common reference mean m 0 , which we set as the simulation ground truth. For (Q2), we compute coverage rates of 95% credible intervals for f µ (y) on a grid of y values, and similarly for β j in (Q3).</p><p>The credible intervals (CIs) are constructed using symmetric quantiles based on posterior samples. Additionally, we introduce the integrated coverage probability (ICP) for a function h(y), defined as ICP = CP(y) F (dy), where CP(y) denotes the coverage probability for h(y) at the point y. This metric, similar to MISE, assesses overall coverage across the range of y. To quantify frequentist bias (or lack thereof), we report posterior estimates averaged across data replicates. For assessing statistical efficiency in frequentist terms, we calculate root-mean-square error (RMSE) and lengths of credible intervals. Additionally, we compare the β estimates under the DPGLM versus those obtained from a beta probability model using the brms [Bayesian Regression Models using 'Stan'] package <ref type="bibr">[Bürkner et al., 2024]</ref>,</p><p>facilitating a evaluation of the more flexible semiparametric GLM structure in the DPGLM as compared to this parametric alternative.</p><p>Results. Figure <ref type="figure">1</ref> shows box plots (over 100 repeat simulations) of KS statistics for both the simulation scenarios, for varying sample sizes. The decrease with increasing sample size is evidence for consistency for F µ (y). Figure <ref type="figure">2</ref> shows Mean Integrated Squared Error   <ref type="bibr" target="#b17">Gao [2009]</ref> as the simulation truth may influence these results; a parametric model as the simulation truth might yield more comparable performance between the two approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Null Case Regression</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Application to Speech Intelligibility Data</head><p>We implement inference under the DPGLM for a data set from a speech intelligibility study for typically developing (TD) children from 30 to 96 months of age (see Figure <ref type="figure" target="#fig_2">4</ref>). The  on the dataset, we refer to <ref type="bibr" target="#b12">Mahr et al. [2020]</ref> and <ref type="bibr" target="#b5">Hustad et al. [2021]</ref>.</p><p>Multi Word Single Word 36 48 60 72 84 96 36 48 60 72 84 96 25 50 75 100 Age (in months) Observed Speech Intelligibility (in %) We carry out two separate analyses for the SW-and MW-MSI, respectively. In both cases, MSI is the response y i for child i, i = 1, . . . , n. Covariates x i are defined to allow for a non-linear regression of y i on age. We use the basis functions of a 3-df natural cubic spline to model MSI as a function of age. This allows the mean to vary flexibly with age.</p><p>We use a logit link in the GLM regression. Next, considering a uniform(z -c, z + c) kernel K with c = 0.025 and the prior distributions as in ( <ref type="formula" target="#formula_10">8</ref>) with α = 1 and G 0 = uniform(0, 1), we fit the proposed DPGLM model for the speech intelligibility study using the MCMC algorithm detailed in A.2, generating a total of 6, 000 MCMC samples. We discard the first 1, 000 iterations as initial burn-in and use the remaining R = 500 Monte Carlo samples, after thinning by a factor of 10, for the following results.</p><p>Results. Figure <ref type="figure" target="#fig_3">5</ref> illustrates the quantile regression curves, q α (x), based on the proposed model for single-word and multi-word intelligibility, accompanied by 95% point-wise uncer-tainty intervals. The curves represent various quantiles (α = 5%, 10%, 25%, 50%, 75%, 90%, and 95%) of speech intelligibility as a function of age in months, indicating that intelligibility improves with age. The wider uncertainty intervals at younger ages reflect greater variability, underscoring the model's effectiveness in capturing nuances of speech development and providing valuable insights for pediatric speech-language pathology. Figure <ref type="figure">6</ref> presents the fitted densities, p(y | x), illustrating the relationship between speech intelligibility (in percentage) as the response variable y and age as the covariate x.</p><p>The heatmap shows how these densities vary across ages, with a gradient from white to blue indicating increased p(y | x). This visualization complements the quantile regression analysis from Figure <ref type="figure" target="#fig_3">5</ref> by reinforcing the trend that older children achieve higher intelligibility scores.</p><p>Multi Word Single Word 36 48 60 72 84 96 36 48 60 72 84 96 25 50 75 100 Age (in months) Speech Intelligibility (in %) Quantiles 5% 10% 25% 50% 75% 90% 95%  intelligibility y meets or exceeds a threshold y 0 . Figure <ref type="figure">8</ref> enhances this analysis by incorporating 95% point-wise uncertainty intervals, providing a clearer understanding of variability in exceedance probabilities at different ages. Together, these visualizations underscore developmental trends in speech intelligibility, highlighting that older children are more likely to achieve higher levels of intelligibility. More importantly, for this methodological development, these results show how, once fitted, our Bayesian implementation of the SPGLM can produce inferences on a variety of useful derived model parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>We have introduced an extension of the GLM family for continuous response data to a semiparametric model with a BNP prior on the baseline distribution. Using a NRM with</p><p>Multi Word Single Word 0 25 50 75 100 0 25 50 75 100 0.00 0.25 0.50 0.75 1.00 Speech Intelligibility (in %) Excceedance Probability Age (in months) 30 60 90 Figure 7: Estimate for exceedance probabilities, p(y ≥ y 0 | x), with speech intelligibility (in percentage) as response y 0 and age (in months) as covariate x. homogeneous Levy intensity as prior model we characterized the posterior distribution using an inhomogeneous NRM. While NRM priors, in particular, the special case of DP priors, are widely used in BNP inference, only few applications naturally give rise to inhomogeneous NRM's. It is interesting to note that this naturally happens with the exponential tilting in the GLM model. One of the limitations of the model is the restricted structure implied by the GLM framework which assumes that the sampling model indexed by different covariates changes only by exponential tilting of the same underlying baseline distribution. While the parsimony of this structure is often desirable, it is also introducing a limitation, by making it more difficult to model certain scenarios. For example, if the sampling model were to include multimodality for extreme values of the covariate, as it might happen for some clinical outcomes, this would be more naturally modeled with more flexible dependent DP models, and difficult to capture with the proposed DPGLM. Multi Word Single Word 0 25 50 75 100 0 25 50 75 100 0.00 0.25 0.50 0.75 1.00 Speech Intelligibility (in %) Excceedance Probability Age (in months) 30 40 50 60 70 80 90 Figure 8: Estimate for exceedance probabilities, p(y ≥ y 0 | x), with 95% point-wise uncertainty intervals for varying ages. Here mean speech intelligibility (in percentage) is considered as response y 0 and age (in months) as covariate x. Several extensions and generalizations of the proposed model could be considered, including extension to multivariate outcomes and for repeated measurements. The latter could include subject specific random effects. For inference with latent variables such as random effects, Bayesian inference is typically more natural and allows easier implementation than, say, maximum likelihood estimation, which can require onerous numerical integration and poses greater challenges in extracting derived parameters, such as marginal (over random effects) trends. Finally, we believe that the Bayesian DPGLM could be an attractive option in data analysis for clinical studies, including planning and sample size arguments for future studies. One particular advantage is the straightforward inference for any desired summary or function of the unknown quantities. One can report inference or plan study designs with focus on any clinically relevant summary, such as exceedance probabilities etc. Taylor, J. W. and Yu, K. (2016). Using auto-regressive logit models to forecast the exceedance probability for financial risk management. Journal of the Royal Statistical Society Series A: Statistics in Society, 179(4):1069-1092. Wurm, M. and Rathouz, P. J. (2024). gldrm: Generalized Linear Density Ratio Models. R package version 1.6. Wurm, M. J. and Rathouz, P. J. (2018). Semiparametric generalized linear models with the gldrm package. The R journal, 10(1):288.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head><p>A.1 Proofs</p><p>We include proofs for Propositions 1 through 3. The proof for proposition 1 is summarized from Nieto- <ref type="bibr" target="#b14">Barajas et al. [2004]</ref>.</p><p>Proof of proposition 1. μ is a gamma completely random measure (CRM) with base measure G 0 on support Y and concentration parameter α. This CRM can be expressed</p><formula xml:id="formula_26">as μ(•) = ∞ ℓ=1 s ℓ δ z ℓ (•)</formula><p>with Levy intensity, ν(ds, dz) = e -s s ds • αG 0 (dz). We thus have μ(Y) ∼ Ga(α, 1), and μ μ(Y) := f µ ∼ DP (α, G 0 ). Under DPGLM, the implied marginal G x (z) for a given x: G x (z) ∼ exp(θ x z)µ(z). For given θ x , we can express the exponentially tilted dz) , where g ⋆ (z) = exp(θ x z)g(z). For any measurable function g, we also have g ⋆ measurable. Using the Levy-Khintchine representation for µ, we get E e -Y g ⋆ (z)µ(dz) = exp -R + ×Y 1 -e -sg ⋆ (z) ν(ds, dz) . Using change of variables s → s ⋆ such that s ⋆ = s exp(θ x z), exp -</p><formula xml:id="formula_27">CRM as µ ⋆ = exp(θ x z)µ(z) = ∞ ℓ=1 s ⋆ ℓ δ z ℓ , where s ⋆ ℓ = exp (θz ℓ ) s ℓ . Note that E e -Y g(z)μ ⋆ (dz) = E e -Y g ⋆ (z)µ(</formula><formula xml:id="formula_28">R + ×Y 1 -e -sg ⋆ (z) ν(ds, dz) = exp - R + ×Y 1 -e -s ⋆ g(z) e -s ⋆ / exp(θxz) s ⋆ ds ⋆ • αG 0 (dz)</formula><p>Combining above, we get the Levy-Khintchine representation for µ ⋆ as This further implies that G x is a non-homogeneous normalized random measure (NRM), which completes the proof.</p><formula xml:id="formula_29">E e -Y g(z)μ ⋆ (dz) = exp - R + ×Y 1 -e -s ⋆ g(z) ν ⋆ (ds ⋆ , dz) ,</formula><p>Proof of proposition 3. We start by defining</p><formula xml:id="formula_30">T i ≡ T i (Y) = T (θ x i ) = exp{b(θ x i )},</formula><p>where b(θ x ) is given in (2). For simplicity, we consider the case of no ties in {z i } n i=1 , which is extended to a general case in later part. First consider n disjoint subsets C 1 , . . . , C n of Y, where we take C i := {z ∈ Y : d(z, z i ) &lt; ϵ}, where d is a distance function and C n+1</p><formula xml:id="formula_31">= Y \ ∪ n i=1 C i . We next denote T i = T i (C i ) = C i exp(θ x i z)µ(dz). We then have E e -Y h(z)µ(dz) | z 1 ∈ C 1 , . . . , z n ∈ C n = e -Y h(z)µ(dz) n i=1 T i (C i ) T i (Y) p(µ)d(µ) n i=1 T i (C i ) T i (Y) p(µ)d(µ) = E e -Y h(z)µ(dz) n i=1 T i T i E n i=1 T i T i = E µ (N ) E µ (D) . (<label>11</label></formula><formula xml:id="formula_32">)</formula><p>We shall get the Laplace functional for the posterior of µ by pushing ϵ → 0 in (11). Next, we derive an explicit expression for the numerator, where by taking h(z) = 0, we get the denominator. Noting that 1</p><formula xml:id="formula_33">T i = R + e -T i u i du i = R + e -Y u i exp(θ i z)µ(dz) du i , we have n i=1 1 T i = R + n n+1 j=1 e -C j n i=1 u i exp(θ i z)µ(dz) du .</formula><p>We can then write N as</p><formula xml:id="formula_34">= n+1 j=1 e -C j h(z)µ(dz) n i=1 T i R + n n+1 j=1 e -C j n i=1 u i exp(θ i z)µ(dz) du = n i=1 T i R + n n+1 j=1 e -C j (h(z)+ n i=1 u i exp(θ i z))µ(dz) du = R + n e -C n+1 (h(z)+ n i=1 u i exp(θ i z))µ(dz) n j=1 - d du j e -C j (h(z)+ n i=1 u i exp(θ i z))µ(dz) du</formula><p>The last line follows from d du j e</p><formula xml:id="formula_35">-C j (h(z)+ n i=1 u i exp(θ i z))µ(dz) = -T j e -C j (h(z)+ n i=1 u i exp(θ i z))µ(dz) .</formula><p>Using Fubini's theorem and choosing ϵ close enough to 0 such that µ(C j ) is independent over where ∆</p><p>⋆(1) u) ρ(ds | z j ), and similarly, C j ∆</p><formula xml:id="formula_36">θ j (u, z) = exp(θ j z) R + se -sη ⋆ (z,u) ρ(ds | z). Upon pushing ϵ → 0, we get C j ∆ ⋆(1) θ j (u, z)• αG 0 (dz) → α exp(θ j z j ) R + se -sη ⋆ (z j ,</formula><p>(1) u) ,</p><formula xml:id="formula_37">θ j (u, z) • αG 0 (dz) → α exp(θ j z j ) R + se -sη(z j ,u) ρ(ds | z j ). Next, noting that 1 -e -sη(z,u) = 1 -e -h(z)s e -{ n i=1 u i exp(θ i z)}s + 1 -e -{ n i=1 u i exp(θ i z)}s , we get exp - S 1 -e -sη(z,u) ν(ds, dz) = exp - S 1 -e -h(z)s ν o (ds, dz) • e -ψ(</formula><p>where ν o (ds, dz) = e -η ⋆ (z,u)s ν(ds, dz) and e -ψ(u) = e [-S {1-e -η ⋆ (z,u)s }ν(ds,dz)] . Let z denote (z 1 , . . . , z n ). Plugging everything in (12), we get</p><formula xml:id="formula_38">E e -Y h(z)µ(dz) | z, u, θ = R + n E µ o e -Y h(z)µ o (dz) n j=1 E J j e -h(z j )J j D(u)e -ψ(u) du R + n D(u)e -ψ(u) du ,<label>(13)</label></formula><p>where</p><formula xml:id="formula_39">D(u) = n j=1 R + se -sη ⋆ (z j ,u) ρ(ds | z j ). Writing µ ⋆ = µ | z, u, θ d = µ o + n j=1 J j δ z j , (<label>13</label></formula><p>) can be expressed as:</p><formula xml:id="formula_40">E e -Y h(z)µ(dz) | z, u, θ = R + n E µ ⋆ e -Y h(z)µ ⋆ (dz) D(u)e -ψ(u) R + n D(u)e -ψ(u) du du,<label>(14)</label></formula><p>where µ o d = CRM (ν o ) with Lévy intensity ν o (ds, dz) = e -η ⋆ (z,u)s ν(ds, dz) = 1 s e -(1+ n i=1 u i exp(θ i z))s ds• αG 0 (dz), and</p><formula xml:id="formula_41">P J j (s | z, u, θ) ∝ se -sη ⋆ (z j ,u) ρ(ds | z j ) = e -s{1+η ⋆ (z j ,u)} . The discrete na- ture of µ introduces ties in z i . Let {z ⋆ 1 , . . . , z ⋆ k } denote the unique values among the cur- rently imputed {z 1 , . . . , z n }, with multiplicity {n ⋆ 1 , . . . , n ⋆ k }. Then P J ℓ (s | u, θ, z ⋆ ℓ , n ⋆ ℓ ) ∝ s n ⋆ ℓ -1 e -(1+ n i=1 u i exp(θ i z ⋆ ℓ ))s ≡ Ga (n ⋆ ℓ , ψ(z ⋆ ℓ ; u, θ)) , ℓ = 1, . . . , k, where ψ(z ⋆ ℓ ; u, θ) = 1 + n i=1 u i exp(θ i z ⋆ ℓ )</formula><p>. This completes the proof.</p><p>constant is b(θ x , µ) = log exp(θ x z)µ(dz), and θ x = b ′ -1 {λ(x)} is the derived parameter.</p><p>Let H denote the CRM finite truncation point in the Ferguson-Klaas algorithm. In the following discussion we use ". . ." in the conditioning set of complete conditional posterior distributions to indicate all other (currently imputed) parameters and the data.</p><p>Step where G n = αG 0 + n j=1 δ z j . Let {z ⋆ 1 , . . . , z ⋆ k } denote the unique values among the currently imputed {z 1 , . . . , z n }, with multiplicity {n ⋆ 1 , . . . , n ⋆ k }. Then G n can be written as G n = αG 0 + k ℓ=1 n ⋆ ℓ δ z ⋆ ℓ . Following <ref type="bibr">Barrios et al. [2013]</ref>, we generate a proposal using a random walk, u j ∼ Gamma δ, δ u j and follow up with a MH acceptance step. The tuning parameter δ(≥ 1) controls the acceptance rate of the MH step.</p><p>Step 3: µ update. Conditional on u and for fixed θ the posterior on µ is a inhomogeneous CRM, as described in Proposition 3. However, θ depends on µ. We therefore can not use the result for a Gibbs sampling transition probability (updating µ by a draw from the complete conditional posterior). Instead we use Proposition 3 to implement a MH transition probability. For the following discussion let π(µ) denote the target posterior distribution of µ. We assume that µ o in Proposition 3 is generated using the Ferguson-Klaas algorithm truncated at a fixed number of H atoms selected by decreasing weights. In that case q as well as the target posterior distribution π(µ) reduce to finite-dimensional distributions with density w.r.t. Lesbegue measure, allowing us to construct a MH transition probability. Let then q(µ ⋆ | µ) denote the inhomogeneous CRM described in Proposition 3. We generate a proposal µ ⋆ ∼ q. In the following expression we will need normalization constants with different combinations of the CRM µ and exponential tilting based on arbitrary θ x , with θ x ̸ = θ x (µ x ), that is, different from the dervived parameter under µ x . We therefore need notation b(θ x , µ) = log Y exp(θ x y)µ(dy) to denote the log normalization constant when CRM µ is used with exponential tilting based on θ x . The proposal µ ⋆ ∼ q is then followed up with a Metropolis-Hastings acceptance step with acceptance ratio s ds αG 0 (dz), where ψ(z) = n i=1 u i exp(θ i z). We write µ o = H h=1 s h δ zh . The random atom locations zh and weights s h are generated using the <ref type="bibr" target="#b2">Ferguson and Klass [1972]</ref> algorithm: it first generates the random weights s h in decreasing order. For that, we sample ξ h ∼ standard Poisson process (PP) of unit rate i.e. ξ 1 , ξ 2 -ξ 1 , . . . iid ∼ Exp(1). Then solve for s h = N -1 (ξ h ), with</p><formula xml:id="formula_42">N (v) = ν o ([v, ∞], Y) = ∞ v Y ν o (ds, dz) = α ∞ v Y</formula><p>e -(ψ(z)+1)s s G 0 (dz) ds .</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure 1: Kolmogorov-Smirnov (KS) statistic values in estimating the baseline CDF, F µ (y), for both the scenarios given in the text. 100 simulation replicates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: (Left panel) Pointwise coverage probabilities for F µ (y), on a grid of y values, for varying sample sizes, under simulation scenario II. (Top right panel) The true baseline cumulative distribution function (CDF) F µ along with the corresponding posterior estimates, averaged over 100 data replicates. (Bottom right panel) The same plot presented on a logarithmic scale for better visualization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Observed data. Mean speech intelligibility (in percentage) for single-word (SW, right panel) and multi-word (MW, left panel) utterances, with age (in months) as a predictor.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Quantile growth curves (solid lines) based on DPGLM model for multi-word (left panel) and single-word (right panel) intelligibility, with 95% point-wise uncertainty intervals (shaded ribbon).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 Figure 6 :</head><label>76</label><figDesc>Figure 7 displays estimates for exceedance probabilities, p(y ≥ y 0 | x), across varying ages x (color shades) and thresholds y 0 (horizontal axis), indicating the likelihood that speech</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><figDesc>with the Levy intensity ν ⋆ (ds, dz) = e -s/ exp(θxz)s ds•αG 0 (dz) = ρ ⋆ (ds | z)•αG 0 (dz). Here ρ ⋆ (ds | z) = e -s/ exp(θxz)s ds depends on atom location z, which characterizes a non-homogeneous CRM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><figDesc>1: β update. The complete conditional for β is π(β | µ, . . .), withlog π(β | µ, . . .) = n i=1 {θ i z i -b(θ i , µ) + log µ(z i )} + log p(β),where p(β) ≡ Normal(µ β , Σ β ) is the β prior. We update β by first obtaining the posterior mode, β ⋆ = arg max β log π(β | µ, . . .), and using the proposalβ ∼ Normal(β ⋆ , Σ ⋆ )1 A β , where Σ ⋆ = n i=1 x i x T i (g ′ (λ i )) 2 b ′′ (θ i ) -1is the inverse Fisher information at (β ⋆ , µ) and A = {β ∈ R p : λ i ∈ Y, for all i}. The proposal is then accepted or rejected via a Metropolis-Hastings (MH) step.Step 2: u update. The complete conditional for u is p(u | µ, . . .) ∝ exp -(θ i v) G n (dv) ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><figDesc>i -θ i )z i -b(θ ⋆ i , µ ⋆ ) + b(θ i , µ) -b(θ ⋆ i , µ) + b(θ i , µ ⋆ )},where θ ⋆ i = θ x i (β, µ ⋆ ) and accept the proposal with probability r ∧ 1. See section A.2.1 for a derivation of r. The details of generating µ ⋆ ∼ q are as follows. In Proposition 3, for fixedθ we generate [µ | u, . . .] d = µ o + k ℓ=1 J ℓ δ z ⋆ ℓ , where(a) µ o ∼ CRM (ν o ) with ν o (ds, dz) = e -(ψ(z)+1)s</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Integrated coverage probability (ICP) for F µ across various sample sizes under simulation scenario II given in the text. 100 simulation replicates.</figDesc><table><row><cell>Sample Size</cell><cell>25</cell><cell>50 100 250</cell></row><row><cell>ICP</cell><cell cols="2">0.91 0.93 0.94 0.95</cell></row><row><cell cols="3">under simulation scenario II, contrasting the proposed DPGLM approach with the Beta</cell></row><row><cell cols="3">probability model implemented via the brms package. The proposed DPGLM exhibits some</cell></row><row><cell cols="3">bias in small samples, however are approximately unbiased in large samples for both β 0</cell></row><row><cell cols="3">and β 1 , with RMSE and credible interval lengths demonstrating substantial reduction from</cell></row><row><cell cols="3">approximately 0.2 to 0.06 and 0.8 to 0.25, respectively, as sample size increases. The coverage</cell></row><row><cell cols="3">probabilities for DPGLM are consistently near the nominal 95% level across all sample sizes.</cell></row></table><note><p>Table 1 reports Integrated Coverage Probability (ICP), showing the same trend as the previous figure. With increasing sample size ICP for F µ also increases, attaining nominal coverage at n = 250.</p><p>Table 2 compares the estimates of regression parameters β j across various sample sizes</p><p>In contrast, the Beta model displays higher overall bias, converging around 0.03 and -0.07 for β 0 and β 1 , respectively, while showing comparable reductions in RMSE and uncertainty interval lengths with increasing sample sizes. Coverage for β 0 in the Beta model remains near 0.95, whereas β 1 coverage decreases substantially with sample size, reaching as low as 0.81 at n = 250, suggesting potential inconsistency in regression parameter estimates. These findings indicate superior precision and reliability of the proposed DPGLM approach across all sample sizes. It is worth noting, however, that the use of SPGLM fromRathouz and    </p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Comparison of β estimates across various sample sizes under simulation scenario II given in the text. 100 simulation replicates for the Proposed DPGLM approach and the Beta probability model using the brms package. 100 simulation replicates.</figDesc><table><row><cell>n</cell><cell>Pars</cell><cell cols="2">Proposed DPGLM</cell><cell></cell><cell></cell><cell cols="2">Beta Model (brms)</cell></row><row><cell></cell><cell cols="4">Bias RMSE Coverage CI Length</cell><cell cols="4">Bias RMSE Coverage CI Length</cell></row><row><cell>25</cell><cell>β 0 0.027</cell><cell>0.217</cell><cell>0.97</cell><cell cols="2">0.834 0.038</cell><cell>0.221</cell><cell>0.96</cell><cell>0.798</cell></row><row><cell></cell><cell>β 1 -0.044</cell><cell>0.170</cell><cell>0.98</cell><cell cols="2">0.799 -0.064</cell><cell>0.174</cell><cell>0.99</cell><cell>0.847</cell></row><row><cell>50</cell><cell>β 0 0.021</cell><cell>0.165</cell><cell>0.93</cell><cell cols="2">0.600 0.027</cell><cell>0.162</cell><cell>0.93</cell><cell>0.543</cell></row><row><cell></cell><cell>β 1 -0.017</cell><cell>0.115</cell><cell>0.97</cell><cell cols="2">0.573 -0.064</cell><cell>0.138</cell><cell>0.96</cell><cell>0.582</cell></row><row><cell>100</cell><cell>β 0 -0.003</cell><cell>0.105</cell><cell>0.94</cell><cell cols="2">0.420 0.027</cell><cell>0.100</cell><cell>0.96</cell><cell>0.384</cell></row><row><cell></cell><cell>β 1 -0.007</cell><cell>0.090</cell><cell>0.96</cell><cell cols="2">0.403 -0.068</cell><cell>0.111</cell><cell>0.92</cell><cell>0.406</cell></row><row><cell>250</cell><cell>β 0 -0.002</cell><cell>0.066</cell><cell>0.95</cell><cell cols="2">0.261 0.027</cell><cell>0.065</cell><cell>0.94</cell><cell>0.241</cell></row><row><cell></cell><cell>β 1 -0.001</cell><cell>0.062</cell><cell>0.95</cell><cell cols="2">0.258 -0.068</cell><cell>0.091</cell><cell>0.81</cell><cell>0.253</cell></row></table><note><p>Notes: True values are β 0 = 0.2 and β 1 = 0.7. Bias = Estimate -True value. Estimates, RMSE (Root Mean Square Error), Coverage Probability, and CI Lengths are averaged over B = 100 data replicates. Abbreviations: n -Sample size; Pars -Parameters.</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>The authors thank <rs type="person">Igor Prünster</rs> (personal communication) for advice on the proof of Proposition 1, and for pointing us to the cited result.</p></div>
			</div>
			<div type="funding">
<div><head>Funding</head><p>This research was supported by the <rs type="funder">National Institutes of Health (NIH)</rs> under grants <rs type="grantNumber">2R01 HL094786</rs> and <rs type="grantNumber">R01DC015653</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_aYSNyPb">
					<idno type="grant-number">2R01 HL094786</idno>
				</org>
				<org type="funding" xml:id="_Zya7xcb">
					<idno type="grant-number">R01DC015653</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material</head><p>References Argiento, R., <ref type="bibr">Guglielmi, A., and Pievatolo, A. (2010)</ref>. Bayesian density estimation and model selection using nonparametric hierarchical mixtures. Computational Statistics &amp; Data Analysis, 54(4):816-832. <ref type="bibr">Barrios, E., Nieto-Barajas, L. E., and Prünster, I. (2013)</ref>. A study of normalized random measures mixture models. Statistical Science, page to appear. Bürkner, P.-C., Gabry, J., Weber, S., <ref type="bibr">Johnson, A., Modrak, M., Badr, H. S., Weber, F., Vehtari, A., Ben-Shachar, M. S., Rabel, H., Mills, S. C., Wild, S., and Popov, V. (2024)</ref>.</p><p>brms: Bayesian Regression Models using 'Stan'. R package version 2.22.0. Davino, C., Dolce, P., <ref type="bibr">Taralli, S., and Vistocco, D. (2022)</ref>. Composite-based path modeling for conditional quantiles prediction. an application to assess health differences at local level in a well-being perspective. Social Indicators Research, 161(2):907-936.</p><p>De Blasi, P., <ref type="bibr">Favaro, S., Lijoi, A., Mena, R. H., Prünster, I., and Ruggiero, M. (2013)</ref>.</p><p>Are gibbs-type priors the most natural generalization of the dirichlet process? IEEE transactions on pattern analysis and machine intelligence, 37(2):212-229. j,</p><p>From (8), we have ν(ds, dz) = ρ(ds | z) • αG 0 (dz). We next define η(z, u) := h(z) + n i=1 u i exp(θ i z) and S = R + × Y = ∪ n+1 j=1 S j , where S j = R + × C j . Using Lévy-Khintchine representation and</p><p>1 -e -sη(z,u) ν(ds, dz) z,u) ν(ds, dz) . We have,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V</head><p>(1)</p><p>1 -e -sη(z,u) ν(ds, dz)</p><p>We denote ∆</p><p>(1)</p><p>T i has the same expression as numerator with h(z) = 0. For ease, we write η</p><p>(1)</p><p>Proof of proposition 2. From ( <ref type="formula">14</ref>), the conditional posterior for u = (u 1 , . . . , u n ), conditional on (z, θ) is given by</p><p>where D(u) = n j=1 R + se -sη ⋆ (z j ,u) ρ(ds | z j ) and e -ψ(u) = e [-S {1-e -η ⋆ (z,u)s }ν(ds,dz)] . Using the theory of Laplace transform, we get</p><p>where G n = αG 0 + n j=1 δ z j . As discussed above in the proof of Proposition 2, the discrete nature of µ introduces ties in z i . Let {z ⋆ 1 , . . . , z ⋆ k } denote the unique values among the currently imputed {z 1 , . . . , z n }, with multiplicity {n ⋆ 1 , . . . , n ⋆ k }. Then G n in ( <ref type="formula">16</ref>) can be written as</p><p>This completes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Posterior MCMC</head><p>We specify the transition probabilities used for Markov chain Monte Carlo (MCMC) posterior simulation under the proposed DPGLM model. We use the same notations as in (8): the model parameters (β, µ) and the latent variables z = (z 1 , . . . , z n ), u = (u 1 , . . . , u n ) represent the current values in the MCMC iteration. We have y i , z i ∈ Y and</p><p>, where η x can be e.g., a linear predictor x T β. Recall that the log-normalizing Next, the random atom locations zh are sampled from the conditional cumulative distribution function</p><p>, which is conditional on the generated random weights s h .</p><p>(b) Let {z ⋆ 1 , . . . , z ⋆ k } denote the unique values among the currently imputed {z 1 , . . . , z n }, with multiplicity {n ⋆ 1 , . . . , n ⋆ k }. Then for fixed atom z ⋆ ℓ , the random weight J ℓ is gener-</p><p>Step 4: z update. The complete conditional for z i is</p><p>where </p><p>), with derived parameter θ * = θ(β, µ * ). Note again that in this proposal distribution the factor θ i in the exponential tilting is not matching the derived parameter θ ⋆ i . The acceptance ratio is</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">MCMC for normalized random measure mixture models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Favaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>page to appear</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A Bayesian analysis of some nonparametric problems</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Ferguson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="page" from="209" to="230" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A representation of independent increment processes without Gaussian components</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Ferguson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Klass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1634" to="1643" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Fundamentals of nonparametric Bayesian inference</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ghosal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Der Vaart</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="volume">44</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Joint estimation of the mean and error distribution in generalized linear models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">505</biblScope>
			<biblScope unit="page" from="186" to="196" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Speech development between 30 and 119 months in typical children i: Intelligibility growth curves for singleword and multiword productions</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Hustad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Mahr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Natzke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Rathouz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Speech, Language, and Hearing Research</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3707" to="3719" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Posterior analysis for normalized random measures with independent increments</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lijoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Prünster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scandinavian Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="76" to="97" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Completely random measures</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kingman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pacific Journal of Mathematics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="78" />
			<date type="published" when="1967">1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Global increase in major tropical cyclone exceedance probability over the past four decades</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Kossin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Knapp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Olander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Velden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="11975" to="11980" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Constrained Dirichlet Process and Functional Condition Model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Syposium on Nonparametric Statistics (ISNPS)</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<pubPlace>Braga, Portugal</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Controlling the reinforcement in Bayesian non-parametric mixture models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lijoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Mena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Prünster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology)</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="715" to="740" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Dependent Dirichlet processes</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Maceachern</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
		<respStmt>
			<orgName>Department of Statistics, The Ohio State University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Longitudinal growth in intelligibility of connected speech from 2 to 8 years in children with cerebral palsy: A novel bayesian approach</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Mahr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Rathouz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Hustad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Speech, Language, and Hearing Research</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2880" to="2893" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Generalized casecontrol sampling under generalized linear models</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Maronge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Schildcrout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Rathouz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="332" to="343" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Normalized random measures driven by increasing additive processes</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Nieto-Barajas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Prünster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="2343" to="2360" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dynamics of Covid-19 mortality and social determinants of health: a spatiotemporal analysis of exceedance probabilities</title>
		<author>
			<persName><forename type="first">R</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Adeyemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pokhrel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Arif</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Epidemiology</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="51" to="58" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The dependent Dirichlet process and related models</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Quintana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Maceachern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="41" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Generalized linear models with unspecified reference distribution</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Rathouz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biostatistics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="205" to="218" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Distributional results for means of normalized random measures with independent increments</title>
		<author>
			<persName><forename type="first">E</forename><surname>Regazzini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lijoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Prünster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="560" to="585" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A constructive definition of Dirichlet priors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sethuraman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistica sinica</title>
		<imprint>
			<biblScope unit="page" from="639" to="650" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
