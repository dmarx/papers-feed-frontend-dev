- Choice of neural network architecture for entropy estimation
- Selection of loss function (cross-entropy) for training
- Decision to extend McAllester and Statos (2020) methodology
- Assumptions about underlying probability distributions
- Method for bias correction in entropy estimation
- Approach for estimating conditional entropy
- Strategy for mutual information estimation
- Use of autoregressive models for transfer entropy estimation
- Evaluation metrics for performance comparison
- Dataset selection for empirical studies
- Handling of large alphabet sizes in estimators
- Techniques for reducing variance in estimations
- Implementation of strong consistency in estimators
- Framework for independence testing using CMI
- Integration of domain knowledge in financial dataset analysis
- Consideration of computational complexity in estimator design
- Documentation of limitations and assumptions in the proposed methods
- Approach for empirical validation of estimators
- Framework for future work and potential improvements
- Decision on software and tools for implementation and testing