- **Entropy Definition**: Quantifies the minimum average number of bits required to represent an event following a probability distribution.
  
- **Key Information-Theoretic Measures**: 
  - **Mutual Information (MI)**: Measures the amount of information obtained about one random variable through another.
  - **Conditional Mutual Information (CMI)**: Measures the amount of information obtained about one random variable given another.

- **Neural Joint Entropy Estimator (NJEE)**: 
  - Combines the chain rule with cross-entropy (CE) loss minimization for joint entropy estimation.
  - Strongly consistent estimator.

- **Conditional NJEE (C-NJEE)**: 
  - Extends NJEE for joint conditional entropy estimation.
  - Useful for estimating CMI and TE.

- **Cross-Entropy (CE)**: 
  - Measures the average number of bits needed to represent an event from one distribution using another distribution.
  - CE is minimized when the two distributions are identical (P = Q).

- **Transfer Entropy (TE)**: 
  - Defined as CMI between the "past" of one time series and the "future" of another, given its "past".
  - Useful in analyzing information flow and causality in time-dependent data.

- **Performance Improvements**: 
  - NJEE outperforms existing methods in small sample sizes relative to large alphabet sizes.
  - C-NJEE shows better results in conditional independence tests and TE estimation tasks.

- **Applications**: 
  - Feature selection, representation learning, and analysis of learning mechanisms in machine learning.
  - Real-world applications in neuroscience, finance, and process control.

- **Limitations of Existing Methods**: 
  - Classic plug-in estimator suffers from negative bias.
  - KNN-based MI estimators can underestimate MI in high-dependency scenarios.

- **Mathematical Notation**: 
  - Let \( X \) be a discrete random variable with alphabet size \( a_x \).
  - Joint entropy \( H(X, Y) = H(X) + H(Y|X) \).
  - Mutual information \( I(X; Y) = H(X) + H(Y) - H(X, Y) \).

- **Empirical Study**: 
  - Demonstrates the effectiveness of NJEE and C-NJEE across various datasets and tasks, including protein datasets and financial time series.

- **Contributions**: 
  - Introduction of NJEE and C-NJEE as strongly consistent estimators.
  - Practical implementation scheme showing superior performance compared to existing methods.