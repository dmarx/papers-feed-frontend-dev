- Decision to use hyperbolic geometry for structured representation learning
- Choice of Poincaré Ball model for hyperbolic space representation
- Adoption of a hyperbolic tree-based representation loss
- Integration of centering loss with the structured regularization
- Selection of Cophenetic Correlation Coefficient (CPCC) as a metric for evaluating hierarchical relationships
- Decision to combine HypStructure with standard task losses
- Choice of datasets for empirical evaluation (e.g., ImageNet, CIFAR)
- Design of experiments to assess generalization performance
- Method for conducting eigenvalue analysis of learned representations
- Decision to focus on low-dimensional representations
- Approach to handle Out-of-Distribution (OOD) detection tasks
- Strategy for qualitative and quantitative assessment of learned features
- Decision to allow for both training from scratch and fine-tuning scenarios
- Choice of optimization techniques for the structured regularization
- Decision to document the limitations of Euclidean space in representing hierarchical data
- Approach to clipping vectors for Poincaré distance computation
- Decision to evaluate the interpretability of learned representations
- Choice of hyperbolic models for comparison in methodology section
- Decision to include a formal analysis of eigenspectrum behavior in structured representations
- Strategy for addressing the loss of information in non-leaf node representations