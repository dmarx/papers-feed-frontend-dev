- **Objective**: Interpret prediction mechanisms of layered neural networks (LNNs) using hierarchical modular representation.
  
- **Key Problems Addressed**:
  - Lack of prior knowledge on optimal resolution for clustering.
  - Inability to determine positive/negative correlations of cluster outputs with input/output dimensions.

- **Proposed Method**:
  - Hierarchical clustering of hidden layer units based on feature vectors derived from correlations with input/output dimensions.
  
- **Training LNN**:
  - LNN function: \( f(x, w) \) where \( w = \{ \omega_{ij}^d, \theta_i^d \} \).
  - Training error: \( E(w) = \frac{1}{n_1} \sum_{n=1}^{n_1} (Y_n - f(X_n, w))^2 \).
  - Regularization: \( H(w) = \frac{1}{n_1} E(w) + \lambda \sum | \omega_{ij}^d | \).

- **Feature Vector Definitions**:
  - **Effect of input on hidden unit**: 
    \[
    v_{in}^{ik} = \frac{E[X_i(n)] - E[X_i] \cdot E[o_k(n)] - E[o_k]}{E[X_i(n)] - E[X_i]^2 \cdot E[o_k(n)] - E[o_k]^2}
    \]
  - **Effect of hidden unit on output**: 
    \[
    v_{out}^{kj} = \frac{E[o_k(n)] - E[o_k] \cdot E[y_j(n)] - E[y_j]}{E[o_k(n)] - E[o_k]^2 \cdot E[y_j(n)] - E[y_j]^2}
    \]
  - **Feature vector**: 
    \[
    v_k = [v_{in}^{1k}, \ldots, v_{in}^{i_0k}, v_{out}^{k1}, \ldots, v_{out}^{kj_0}]
    \]

- **Sign Alignment Algorithm**:
  - Align signs of feature vectors based on cosine similarity to treat units with opposite signs as equivalent.
  
- **Hierarchical Clustering**:
  - Use Ward's method for clustering hidden layer units.
  - Error sum of squares (ESS) defined as:
    \[
    ESS = \sum_{k:u_k \in C_m} v_k^2 - \frac{1}{|C_m|} \sum_{k:u_k \in C_m} v_k^2
    \]
  - Update rule for combining clusters:
    \[
    \Delta ESS = \frac{|C_{m1}| |C_{m2}|}{|C_{m1}| + |C_{m2}|} \left( \frac{1}{|C_{m1}|} \sum_{k:u_k \in C_{m1}} v_k - \frac{1}{|C_{m2}|} \sum_{k:u_k \in C_{m2}} v_k \right)^2
    \]

- **Experimental Validation**:
  - Applied to MNIST and food consumer price indices datasets to demonstrate effectiveness in interpreting LNN mechanisms.