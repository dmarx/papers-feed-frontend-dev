{
  "arxivId": "1710.09412",
  "title": "mixup: Beyond Empirical Risk Minimization",
  "authors": "Hongyi Zhang, Moustapha Cisse, Yann N. Dauphin, David Lopez-Paz",
  "abstract": "Large deep neural networks are powerful, but exhibit undesirable behaviors\nsuch as memorization and sensitivity to adversarial examples. In this work, we\npropose mixup, a simple learning principle to alleviate these issues. In\nessence, mixup trains a neural network on convex combinations of pairs of\nexamples and their labels. By doing so, mixup regularizes the neural network to\nfavor simple linear behavior in-between training examples. Our experiments on\nthe ImageNet-2012, CIFAR-10, CIFAR-100, Google commands and UCI datasets show\nthat mixup improves the generalization of state-of-the-art neural network\narchitectures. We also find that mixup reduces the memorization of corrupt\nlabels, increases the robustness to adversarial examples, and stabilizes the\ntraining of generative adversarial networks.",
  "url": "https://arxiv.org/abs/1710.09412",
  "issue_number": 162,
  "issue_url": "https://github.com/dmarx/papers-feed/issues/162",
  "created_at": "2025-01-05T08:23:56.495087",
  "state": "open",
  "labels": [
    "paper",
    "rating:novote"
  ],
  "total_reading_time_seconds": 0,
  "last_read": null,
  "last_visited": "2024-12-22T17:42:57.473Z",
  "main_tex_file": null,
  "published_date": "2017-10-25T18:30:49Z",
  "arxiv_tags": [
    "cs.LG",
    "stat.ML"
  ]
}