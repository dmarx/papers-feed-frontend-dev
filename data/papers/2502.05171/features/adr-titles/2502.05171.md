- Decision to use a recurrent block for scaling test-time computation
- Choice of latent space reasoning over chain-of-thought approaches
- Selection of a decoder-only transformer architecture
- Design of the prelude, core, and coda functional groups
- Initialization strategy for the latent state
- Use of RMSNorm for normalization in the architecture
- Decision to concatenate initial embedding features in the core block
- Choice of training objective for recurrent models
- Selection of training data and engineering methods
- Decision to implement per-token adaptive compute
- Choice of recurrent iteration sampling strategy during training
- Design of the architecture to support KV-cache sharing
- Decision to track token trajectories in latent space
- Choice of hyperparameters for model scaling (e.g., number of parameters, tokens)
- Decision to explore computation behaviors emerging at scale
- Choice of evaluation benchmarks for model performance assessment
- Decision to incorporate insights from deep thinking literature
- Design choices for the core recurrent block's layer structure
- Decision to use gated SiLU MLP in the architecture
- Choice of embedding scale and matrix for input tokens