- **Torrance Test of Creative Writing (TTCW)**: A framework for evaluating creativity in writing, adapted from the Torrance Test of Creative Thinking (TTCT), focusing on short stories.
  
- **Dimensions of Creativity**: TTCW evaluates four dimensions:
  - **Fluency**: Volume of meaningful ideas produced.
  - **Flexibility**: Diversity of categories within responses.
  - **Originality**: Uniqueness or novelty of answers.
  - **Elaboration**: Depth or granularity of details.

- **TTCW Structure**: Comprises 14 binary tests organized across the four dimensions, designed through expert consensus using the Consensual Assessment Technique (CAT).

- **Expert Evaluation**: 10 creative writing experts assessed 48 stories (12 by professionals, 36 by LLMs) using TTCW, collecting 3 evaluations per story.

- **Findings on LLMs**:
  - LLM-generated stories pass 3-10X fewer TTCW tests than expert-written stories.
  - Average pass rates: 
    - Expert stories: 84.7%
    - ChatGPT: 9%
    - Claude 1.3: 30%

- **Correlation of Assessments**: 
  - Moderate agreement among experts (Fleiss Kappa 0.41).
  - Strong agreement in aggregate evaluations (Pearson correlation 0.69).

- **LLM Performance**: 
  - GPT-4 excels in Originality.
  - Claude 1.3 performs better in Fluency, Flexibility, and Elaboration.

- **Limitations of LLMs**: Current LLMs do not reliably assess creativity as per TTCW; correlations with expert judgments are close to zero.

- **Contributions**:
  - Adaptation of TTCT for creative writing evaluation.
  - Release of a large-scale dataset of 2,000+ TTCW assessments with expert explanations.
  - Insights into distinguishing AI-generated vs. human-written stories.

- **Research Questions**:
  - RQ1: Consistency and reproducibility of TTCW evaluations.
  - RQ2: Comparison of human vs. LLM story evaluations.
  - RQ3: Performance differences among LLMs in TTCW tests.

- **Future Directions**: Potential for using TTCW framework in developing interactive writing support tools.