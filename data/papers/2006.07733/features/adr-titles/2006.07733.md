- Decision to use two neural networks (online and target) for representation learning
- Choice of using a slow-moving average for the target network parameters
- Decision to avoid negative pairs in the training process
- Selection of augmentation strategies for input images
- Choice of architecture (ResNet-50 and ResNet-200) for the online and target networks
- Decision to minimize a similarity loss between online and target projections
- Choice of using a predictor on the online network to prevent collapse
- Decision to evaluate performance using linear evaluation on ImageNet
- Choice of metrics for assessing representation quality (e.g., top-1 accuracy)
- Decision to compare BYOL with existing contrastive methods
- Choice of training protocol and hyperparameters (e.g., learning rate, batch size)
- Decision to implement and share the code and pretrained models on GitHub
- Choice of experimental design for ablation studies
- Decision to focus on robustness to changes in augmentations and batch sizes
- Choice of semi-supervised and transfer learning benchmarks for evaluation
- Decision to hypothesize about the reasons for improved robustness compared to contrastive methods