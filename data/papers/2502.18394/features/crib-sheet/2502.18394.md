- **FFTNet Overview**: An adaptive spectral filtering framework that uses Fast Fourier Transform (FFT) for global token mixing with O(n log n) complexity, addressing the limitations of conventional self-attention.

- **Key Innovation**: Integration of a learnable spectral filter that modulates Fourier coefficients based on a global context vector, allowing dynamic emphasis on salient frequency components.

- **Energy Preservation**: Utilizes Parseval's theorem to ensure energy preservation during transformations, maintaining stability and avoiding information loss.

- **Complexity Comparison**: 
  - Self-attention: O(nÂ²) for pairwise computations.
  - FFTNet: O(n log n) for global mixing, with additional linear overhead for filtering and activation.

- **Method Steps**:
  1. **Fourier Transform**: 
     - Compute \( F = FFT(X) \in \mathbb{C}^{n \times d} \).
  2. **Adaptive Spectral Filtering**:
     - Compute global context vector \( c = \frac{1}{n} \sum_{i=1}^{n} X_i \).
     - Modulation tensor \( \Delta W = MLP(c) \in \mathbb{R}^{n \times d} \).
     - Final filter \( W = W_{\text{base}} + \Delta W \).
     - Apply filtering: \( F = F \odot W \).
  3. **Nonlinear Activation (modReLU)**:
     - \( modReLU(z) = (r + b)e^{i\theta} \) if \( r + b > 0 \), else 0.
     - Apply: \( F = modReLU(F) \).
  4. **Inverse Fourier Transform**:
     - Compute \( Y = IFFT(F) \in \mathbb{R}^{n \times d} \).

- **Theoretical Justification**:
  - **Global Mixing**: FFT captures long-range dependencies efficiently through orthogonal frequency components.
  - **Adaptive Attention**: The learnable filter acts similarly to attention weights without explicit pairwise computations.
  - **Expressivity**: Nonlinear activation enhances the model's ability to capture complex patterns.

- **Computational Complexity Breakdown**:
  - FFT/IFFT: \( O(d \cdot n \log n) \).
  - Adaptive filtering: \( O(d \cdot n) \).
  - Nonlinear activation: \( O(d \cdot n) \).
  - Overall: Dominated by FFT/IFFT, effectively \( O(d \cdot n \log n) \).

- **Experimental Validation**: Demonstrated superior performance on Long Range Arena and ImageNet benchmarks compared to fixed Fourier and standard attention models.

- **Code Repository**: Available at [GitHub - FFTNet](https://github.com/jacobfa/fft).