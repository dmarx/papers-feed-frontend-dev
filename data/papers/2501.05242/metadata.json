{
  "arxivId": "2501.05242",
  "title": "Scaffold-SLAM: Structured 3D Gaussians for Simultaneous Localization and\n  Photorealistic Mapping",
  "authors": "Wen Tianci, Liu Zhiang, Lu Biao, Fang Yongchun",
  "abstract": "3D Gaussian Splatting (3DGS) has recently revolutionized novel view synthesis\nin the Simultaneous Localization and Mapping (SLAM). However, existing SLAM\nmethods utilizing 3DGS have failed to provide high-quality novel view rendering\nfor monocular, stereo, and RGB-D cameras simultaneously. Notably, some methods\nperform well for RGB-D cameras but suffer significant degradation in rendering\nquality for monocular cameras. In this paper, we present Scaffold-SLAM, which\ndelivers simultaneous localization and high-quality photorealistic mapping\nacross monocular, stereo, and RGB-D cameras. We introduce two key innovations\nto achieve this state-of-the-art visual quality. First, we propose\nAppearance-from-Motion embedding, enabling 3D Gaussians to better model image\nappearance variations across different camera poses. Second, we introduce a\nfrequency regularization pyramid to guide the distribution of Gaussians,\nallowing the model to effectively capture finer details in the scene. Extensive\nexperiments on monocular, stereo, and RGB-D datasets demonstrate that\nScaffold-SLAM significantly outperforms state-of-the-art methods in\nphotorealistic mapping quality, e.g., PSNR is 16.76% higher in the TUM RGB-D\ndatasets for monocular cameras.",
  "url": "https://arxiv.org/abs/2501.05242",
  "issue_number": 931,
  "issue_url": "https://github.com/dmarx/papers-feed/issues/931",
  "created_at": "2025-01-11T09:07:19.696624",
  "state": "open",
  "labels": [
    "paper",
    "rating:novote"
  ],
  "total_reading_time_seconds": 3,
  "last_read": "2025-01-11T09:07:19.697839",
  "last_visited": "2025-01-11T09:05:35.504Z",
  "main_tex_file": null,
  "published_date": "2025-01-09T13:50:26Z",
  "arxiv_tags": [
    "cs.CV",
    "68T40(Primary)68T45, 68U99 (Secondary)",
    "I.4.8; I.3.7"
  ]
}