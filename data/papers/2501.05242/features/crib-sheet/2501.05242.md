- **Scaffold-SLAM Overview**: A novel SLAM system achieving simultaneous localization and high-quality photorealistic mapping across monocular, stereo, and RGB-D cameras.

- **Key Innovations**:
  - **Appearance-from-Motion Embedding**: Models appearance variations (exposure, lighting) in a learned low-dimensional latent space, enhancing rendering quality.
  - **Frequency Regularization Pyramid**: Constrains frequencies of rendered images across multiple scales, promoting detail capture in complex regions (edges, textures).

- **Localization and Geometry Mapping**:
  - Utilizes traditional indirect SLAM pipeline for localization.
  - Optimizes camera poses \( R \in SO(3) \) and \( t \in \mathbb{R}^3 \) via motion-only bundle adjustment (BA).
  - Minimizes reprojection error:
    \[
    \{R, t\} = \arg\min_{R_i, t_i} \sum_{i \in X} \rho\left(\|p_j - \pi(R_i P_j + t_i)\|^2_{\Sigma_g}\right)
    \]

- **High-Quality Photorealistic Mapping**:
  - Rendering process based on 3D Gaussian Splatting (3DGS):
    \[
    C(R, t) = \sum_{i \in N} c_i \delta_i \prod_{j=1}^{k} (1 - \delta_j)
    \]
  - Parameters of 3D Gaussians: color \( c \), position \( P \), scaling matrix \( s \), rotation matrix \( q \), opacity \( \alpha \).

- **Appearance-from-Motion Embedding Details**:
  - Each image has a corresponding appearance embedding \( \ell(a)_i \) of length \( n(a) \).
  - Trained using camera poses instead of image indices to improve performance in SLAM tasks.

- **Experimental Validation**:
  - Extensive evaluations demonstrate superior photorealistic mapping quality across monocular, stereo, and RGB-D cameras compared to state-of-the-art methods.

- **Related Work**:
  - Comparison with existing SLAM methods (e.g., Photo-SLAM, GS-SLAM) highlighting limitations in rendering quality and camera type support.

- **Future Work**: Code will be publicly available for further research and development in photorealistic mapping and SLAM systems.