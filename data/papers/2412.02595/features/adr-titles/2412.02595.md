- Decision on dataset size and token count for long-horizon pretraining
- Choice of HTML-to-text extractors (Justext vs. Trafilatura)
- Strategy for global deduplication of tokens
- Approach to heuristic filtering of low-quality tokens
- Implementation of model-based quality labeling pipeline
- Selection of classifiers for quality assessment
- Method for ensembling classifiers to improve quality scoring
- Decision to not apply heuristic filters on high-quality tokens
- Use of synthetic data generation techniques
- Choice of prompts for rephrasing low-quality documents
- Strategy for grouping quality scores into buckets
- Decision on the balance of training data mix during quality evaluation
- Approach to evaluating downstream task performance for quality labeling
- Decision to release the dataset and implementation as open-source
- Guiding principle of shifting from heuristic to learned data processing methods