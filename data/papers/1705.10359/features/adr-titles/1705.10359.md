- Choice of hyperbolic space for embeddings
- Selection of the Poincar√© disk model
- Decision to use negative sampling for efficiency
- Use of backpropagation in hyperbolic coordinates
- Initialization strategy for vector representations
- Choice of objective function for embedding optimization
- Selection of noise distribution for negative sampling
- Decision to extend word2vec architecture to graph data
- Choice of random walk strategy for generating vertex sequences
- Use of hierarchical softmax vs. negative sampling
- Decision on dimensionality of embeddings
- Choice of datasets for experimental validation
- Selection of evaluation metrics for performance assessment
- Decision on training parameters (learning rate, epochs, etc.)
- Choice of activation functions in the neural network
- Decision on regularization techniques to prevent overfitting
- Choice of optimization algorithm for model training
- Decision on handling singularities in hyperbolic coordinates
- Choice of hyperparameters for the model
- Decision on the architecture of the neural network (number of layers, units per layer)