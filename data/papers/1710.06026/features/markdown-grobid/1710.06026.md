# TARGETING INTERVENTIONS IN NETWORKS

## Abstract

## 

We study games in which a network mediates strategic spillovers and externalities among the players. How does a planner optimally target interventions that change individuals' private returns to investment? We analyze this question by decomposing any intervention into orthogonal principal components, which are determined by the network and are ordered according to their associated eigenvalues. There is a close connection between the nature of spillovers and the representation of various principal components in the optimal intervention. In games of strategic complements (substitutes), interventions place more weight on the top (bottom) principal components, which reflect more global (local) network structure. For large budgets, optimal interventions are simple -they involve a single principal component.

We are grateful to the co-editor, Dirk Bergemann, and five anonymous referees for helpful comments. We have also benefited from conversations with

## Introduction

We study games among agents embedded in a network. The action of each agent -e.g., a level of investment or effort -directly affects a subset of others, called neighbors of that agent. This happens through two channels: spillover effects on others' incentives, as well as non-strategic externalities. A utilitarian planner with limited resources can intervene to change individuals' incentives for taking the action. Our goal is to understand how the planner can best target such interventions in view of the network and other primitives of the environment.

We now lay out the elements of the model in more detail. Individuals play a simultaneousmove game with continuous actions. An agent's action confers standalone benefits on that agent independent of anyone else's action, but it also creates spillovers. The intensity of these spillovers is described by a network, with the strength of a link between two individuals reflecting how strongly the action of one affects the marginal benefits experienced by the other. The effects may take the form of strategic complements or strategic substitutes. In addition to standalone benefits and incentive spillovers, there may be positive or negative externalities imposed by network neighbors on each other. 1 Before this game is played, the planner can target some individuals and alter their standalone marginal benefits from status quo levels. The cost of the intervention is increasing in the magnitude of the change and is separable across individuals. The planner seeks to maximize the utilitarian welfare under equilibrium play of the game, subject to a budget constraint. Our results characterize the optimal intervention policy, showing how it depends on the network, the nature of spillovers, the status quo incentives, and the budget.

An intervention on one individual has direct and indirect effects on the incentives of others. These effects depend on the network and on whether the game features strategic substitutes or complements. For example, suppose the planner increases a given individual's standalone marginal benefits to effort, thereby increasing effort by the targeted individual. If actions are strategic complements, this will push up the incentives of the targeted individual's neighbors. That will increase the efforts of the neighbors of these neighbors, and so forth, creating aligned feedback effects throughout the network. In contrast, under strategic substitutes, the same intervention will discourage the individual's neighbors from exerting effort. However, the effect on those neighbors' neighbors will be positive -i.e., in the same direction as the effect on the targeted agent. This interplay between spillovers and network structure makes targeting interventions a complex problem.

At the heart of our approach is a particular way to organize the spillover effects in terms of the principal components of the matrix of interactions. Any change in the vector of standalone (marginal) returns can be expressed in a basis of these principal components. This basis has three special properties: (a) the effects of an intervention along a principal component is proportional to the intervention, scaled by a network multiplier; (b) the "network multiplier" is an eigenvalue of the network corresponding to that principal component; (c) the principal components are orthogonal, so that the effects along various principal components can be treated separately (in a suitable sense). These properties allow us to express the effect of interventions on actions and welfare in a way amenable to a parsimonious characterization of optimal interventions.

Our main result, Theorem 1, characterizes the optimal intervention in terms of how similar it is to various principal components -or, in other words, how strongly represented various principal components are in it. 2 Building on this characterization, Corollary 1 describes how 1 This framework encompasses a number of well-known economic examples from the literature: spillovers in educational/criminal effort [(Ballester, Calvó-Armengol, and Zenou, 2006)](#), research collaboration among firms [(Goyal and Moraga-Gonzalez, 2001)](#b24), local public goods [(Bramoulle and Kranton, 2007)](#b10), investment games and beauty contests [(Angeletos and Pavan, 2007;](#)[Morris and Shin, 2002)](#), and peer effects in smoking [(Jackson et al., 2017)](#). 2 We use the standard notion of cosine similarity: the similarity of two vectors is the cosine of the angle between them in the plane they jointly define.

the representation of various principal components in the optimal intervention is shaped by the nature of the strategic interaction. The principal components can be ordered by their associated eigenvalues (from high to low). In games of strategic complements, the optimal intervention is most similar to the first principal component -the familiar eigenvector centrality -and progressively less similar as we move down the principal components. In games of strategic substitutes, the order is reversed: the optimal intervention is most similar to the last principal component. The "higher" principal components capture the more global structure of the network: this is important for taking advantage of the aligned feedback effects arising under strategic complementarities. The "lower" principal components capture the local structure of the network: they help the planner to target the intervention so that it does not cause crowding out between adjacent neighbors: this is an important concern when actions are strategic substitutes.

We then turn to the study of simple optimal interventions, i.e., ones where the intervention (change in the standalone marginal benefit) for each node is determined by a single network statistic of that node, and invariant to other primitives such as status quo incentives. Propositions 1 and 2 show that for large enough budgets the optimal intervention is simple: in games of strategic complements, the optimal intervention vector is proportional to the first principal component, while in games of strategic substitutes, it is proportional to the last one. [3](#foot_0) Moreover, the network structure determines how large the budget must be for optimal interventions to be simple. In games of strategic complements (substitutes), the important statistic is the gap between the top (bottom) two eigenvalues. When this gap is large, even at moderate budgets the intervention is simple.

Theorem 1 obtains in a setting where the planner knows the status quo standalone marginal benefits of all individuals. Our methods can also be used to study optimal interventions in a setting where the planner does not know these benefits but knows only their distribution. In such a setting, the impact of an intervention on expected social welfare is determined by how it alters the first and second moments of the benefits distribution. Propositions 3 and 4 characterize optimal interventions and show that the key insights about the order of targeting of principal components extend.

We now place the paper in the context of the literature. The intervention problem we study concerns optimal policy in the presence of externalities. Research over the past two decades has deepened our understanding of the empirical structure of networks and the theory of how networks affect strategic behavior. 4 This has led to the study of how policy design should incorporate information about networks. Network interventions are currently See, for example, [Goyal, Moraga, and van der Leij (2006)](#b23), [Ballester, Calvó-Armengol, and Zenou (2006)](#), [Bramoullé, Kranton, and d'Amours (2014)](#), and [Galeotti, Goyal, Jackson, Vega-Redondo, and Yariv (2010)](#b19) an active subject of research not only in economics but also in related disciplines such as computer science, sociology and public health. 5 The main contribution of this paper is methodological. It lies in (i) using the principal components approach to decompose the effect of an intervention on social welfare and (ii) using the structure afforded by this decomposition to characterize optimal interventions. Of special interest is the close relation between the strategic structure (complements or substitutes) and the appropriate principal components to target. 6  The rest of the paper is organized as follows. Section 2 presents the optimal intervention problem. Section 3 sets out how we apply a principal component decomposition to our game. Section 4 characterizes optimal interventions. Section 5 studies a setting where the planner has incomplete information about agents' standalone marginal returns. Section 6 concludes. Appendix A contains the proofs of the main results. The Online Appendix presents the proofs of Propositions 3 and 4 and discusses a number of extensions.

## The model

We consider a simultaneous-move game among individuals N = {1, . . . , n}, where n ≥ 2. Individual i chooses an action, a i ∈ R. The vector of actions is denoted by a ∈ R n . The payoff to individual i depends on this vector, a, the network with adjacency matrix G, and other parameters, described below:

$U i (a, G) = a i b i + β j g ij a j returns from own action - 1 2 a 2$i private costs of own action

$+ P i (a -i , G, b) pure externalities$.

(1)

The private marginal returns from increasing the action a i depend both on i's own action, a i , and on others' actions. The coefficient b i ∈ R corresponds to the part of i's marginal return that is independent of others' actions, and is thus called i's standalone marginal return. The contribution of others' actions to i's marginal return is given by the term β j g ij a j . Here g ij ≥ 0 is a measure of the strength of the interaction between i and j. The parameter β captures strategic interdependencies. If β > 0, then actions are strategic complements; if β < 0, then actions are strategic substitutes. The function P i (a -i , G, b) captures pure externalities -that is, spillovers that do not affect the best response. The first-order condition 5 For a general introduction to the subject, see [Rogers (1983)](#b32), [Kempe, Kleinberg, and Tardos (2003)](#b27), [Borgatti (2006), and](#b9)[Valente (2012)](#b33). Within economics, a prominent early contribution is [Ballester, Calvó-Armengol, and Zenou (2006)](#); recent contributions include [Banerjee, Chandrasekhar, Duflo, and Jackson (2013)](#b6), [Belhaj and Deroian (2017)](#b7), [Bloch and Querou (2013)](#b8), [Candogan, Bimpikis, and Ozdaglar (2012)](#b12), [Demange (2017)](#), [Fainmesser and Galeotti (2017)](#b15), [Galeotti and Goyal (2009)](#b17), [Galeotti and Rogers (2013)](#b20), [Leduc, Jackson, and](#b29)[Johari (2017), and](#b29)[Akbarpour, Malladi, and](#b0)[Saberi (2017)](#b0).

for individual i's action to be a best response is:

$a i = b i + β g ij a j .$Any Nash equilibrium action profile a * of the game satisfies

$[I -βG]a * = b.(2)$We now make two assumptions about the network and the strength of strategic spillovers. Recall that the spectral radius of a matrix is the maximum of its eigenvalues' absolute values.

Assumption 1. The adjacency matrix G is symmetric.[foot_1](#foot_1)

Assumption 2. The spectral radius of βG is less than 1,[foot_2](#foot_2) and all eigenvalues of G are distinct (the latter condition holds generically).

Assumption 2 ensures that (2) is a necessary and sufficient condition for a solution, and also ensures the uniqueness and stability of the Nash equilibrium.[foot_3](#foot_3) Under these assumptions, the unique Nash equilibrium of the game can be characterized by

$a * = [I -βG] -1 b.$(3)

The utilitarian social welfare at equilibrium is given by the sum of the equilibrium utilities:

$W (b, G) = i U i (a * , G).$The planner aims to maximize the utilitarian social welfare at equilibrium. She does this by changing the status quo standalone marginal returns b, to new values, b, subject to a budget constraint on the cost of her intervention. The timing is as follows. The planner moves first and chooses her intervention, and then individuals simultaneously choose actions. The incentive-targeting (IT) problem is given by max

$b W (b, G) (IT) s.t.: a * = [I -βG] -1 b, K(b, b) = i∈N b i -bi 2 ≤ C,$where C is a given budget. The marginal costs of altering the b i are separable across individuals and increasing in the magnitude of the change for each individual. For discussions and extensions on more general cost functions, see the Online Appendix Section OA3.3. In the Online Appendix Section OA3.4, we study a setting in which a planner provides monetary payments to individuals that induce them to change their actions. We show that the resulting optimal intervention problem has the same mathematical structure as the one we study in our basic model. We present two economic applications to illustrate the scope of our model. The first example is a classical investment game, and the second example is a game of providing a local public good.

Example 1 (The investment game). Individual i makes an investment a i at a cost 1 2 a 2 i . The private marginal return on that investment is b i + β j g ij a j , where b i is individual i's standalone marginal return and j g ij a j is the aggregate local effort. The utility of i is

$U i (a, G) = a i b i + β j g ij a j - 1 2 a 2 i .$The case with β > 0 is the canonical case of investment complementarities as in [Ballester et al. (2006)](#). Here, an individual's marginal returns are enhanced when his neighbors work harder; this creates both strategic complementarities and positive externalities. The case of β < 0 corresponds to strategic substitutes and negative externalities; this can be microfounded via a model of competition in a market after the investment decisions a i have been made, as in [Goyal and Moraga-Gonzalez (2001)](#b24).

It can be verified that the equilibrium utilities, U i (a * , G), and the utilitarian social welfare at equilibrium, W (b, G), are as follows:

$U i (a * , G) = 1 2 (a * i ) 2 and W (b, G) = 1 2 (a * ) T a * .$Example 2 (Local public good). Following [Bramoulle and Kranton (2007)](#b10), [Galeotti and Goyal (2010](#b19)[), and Allouch (2015](#b1)[, 2017)](#), we consider a local public goods problem -for instance, collecting non-rival information. Without information-acquisition costs, the optimal amount of information to acquire would be τ .[foot_4](#foot_4) Individual i has an amount bi < τ of information to begin with. He can expend effort to personally acquire additional information, increasing his amount of information to bi + a i . If his neighbors acquire information, then he can also access β j g ij a j , with β ∈ (0, 1] capturing a loss in the transmission of information. The total information that individual i has is

$x i = bi + a i + β j g ij a j .$The utility of i is

$U i (a, G) = - 1 2 (τ -x i ) 2 - 1 2 a 2 i .$This is a game of strategic substitutes and positive externalities. Performing the change of variables b i = [τb i ]/2 and β = -β/2 (with the status quo equal to bi = [τ -bi ]/2) yields a best-response structure exactly as in condition (2). The aggregate equilibrium utility is

$W (b, G) = -(a * ) T a * .$These two canonical examples share a technically convenient property:

Property A. The aggregate equilibrium utility is proportional to the sum of the squares of the equilibrium actions, that is, W (b, G) = w • (a * ) T a * for some w ∈ R, where a * is the Nash equilibrium of the network game.

Online Appendix Section OA2.2 discusses a network beauty contest game inspired by [Morris and Shin (2002)](#) and [Angeletos and Pavan (2007)](#) which also satisfies this property. While Property A facilitates analysis, it is not essential. Online Appendix Section OA3.1 extends the analysis to cover important cases where this property does not hold.

## Principal components

This section introduces a basis for the space of standalone marginal returns and actions in which, under our assumptions on G, strategic effects and the welfare function of interest to the planner both take a simple form.

Fact 1. If G satisfies Assumption 1, then G = U ΛU T , where:

1. Λ is an n × n diagonal matrix whose diagonal entries Λ ll = λ l are the eigenvalues of G (which are real numbers), ordered from greatest to least:

$λ 1 ≥ λ 2 ≥ • • • ≥ λ n . 2.$U is an orthogonal matrix. The th column of U , which we call u , is a real eigenvector of G, namely the eigenvector associated to the eigenvalue λ , which is normalized in the Euclidean norm: u = 1.

For generic G, the decomposition is uniquely determined, except that any column of U is determined only up to multiplication by -1.

An important interpretation of this diagonalization is as a decomposition into principal components. We can think of the columns of G as n data points. The first principal component of G is defined as the n-dimensional vector that minimizes the sum of squares of the distances to the columns of G. The first principal component can therefore be thought of as a fictitious column that "best summarizes" the dataset of all columns of G. To characterize the next principal component, we orthogonally project all columns of G off this vector and repeat this procedure for the new columns. We continue in this way, projecting orthogonally off the (subspace generated by) vectors obtained to date, to find the next principal component. A well-known result is that the eigenvectors of G that diagonalize the matrix (i.e., the columns of U ) are indeed the principal components of G in this sense. Moreover, the eigenvalue corresponding to a given principal component quantifies the residual variation explained by that vector.

Figure [1](#fig_0) illustrates some eigenvectors/principal components of a circle network with 14 nodes and with links all having equal weight given by 1. For each principal component, the color of a node indicates the sign of the entry of that node in that principal component (the color red means negative), while the size of a node indicates the absolute value of that entry. A general feature that is worth noting is that the entries of the top principal components (smaller values of ) are clustered among neighboring nodes, while the bottom principal components (larger values of ) tend to be negatively correlated among neighboring nodes.[foot_5](#foot_5) 3.1. Analysis of the game using principal components. For any vector z ∈ R n , let z = U T z. We will refer to z as the projection of z onto the th principal component, or the magnitude of z in that component. Substituting the expression G = U ΛU T into equation (2), which characterizes equilibrium, we obtain

$[I -βU ΛU T ]a * = b.$Multiplying both sides of this equation by U T gives us an analogue of (3) characterizing the solution of the game:

$[I -βΛ]a * = b ⇐⇒ a * = [I -βΛ] -1 b.$This system is diagonal, and the th diagonal entry of [I -βΛ] -1 is 1 1-βλ . Hence, for every ∈ {1, 2, . . . , n},

$a * = 1 1 -βλ b .(4)$The principal components of G constitute a basis in which strategic effects are easily described.

The equilibrium action a * in the th principal component of G is the product of an amplification factor (determined by the strategic parameter β and the eigenvalue λ ) and b , which is simply the projection of b onto that principal component. Under Assumption 2, for all we have 1βλ > 0. 12 Moreover, when β > 0 (β < 0), the amplification factor is decreasing (increasing) in .

We can also use this to give a formula for equilibrium actions in the original coordinates:

$a * i = 1 1 -βλ u i b .$We close with a definition that will allow us to describe optimal interventions in terms of a standard measure of their similarity to various principal components.

Definition 1. The cosine similarity of two nonzero vectors z and y is

$ρ(z, y) = z • y z y .$This is the cosine of the angle between the two vectors in the plane determined by y and z.

When ρ(z, y) = 1, vector z is a positive scaling of y. When ρ(z, y) = 0, vectors z and y are orthogonal. When ρ(z, y) = -1, vector z is a negative scaling of y.

## Optimal interventions

This section develops a characterization of optimal interventions and studies their properties. We begin by dispensing with a straightforward case of the planner's problem. Recall that under Property A, the planner's payoff as a function of the equilibrium actions a * is W (b, G) = w • (a * ) T a * . If w < 0, the planner wishes to minimize the sum of the squares of the equilibrium actions. In this case, when the budget is large enough, that is, C ≥ b 2 , the planner can allocate resources to ensure that individuals have a zero target action by setting b i = 0 for all i. It follows from the best-response equations that all individuals choose action 0 in equilibrium, and so the planner achieves the first-best. 13 The next assumption implies that the planner's bliss point cannot be achieved, so that there is an interesting optimization problem: Assumption 3. Either w < 0 and C < b , or w > 0.

Let b * solve the incentive-targeting problem (IT), and let y * = b * -b be the vector of changes in individuals' standalone marginal benefits at the optimal intervention. Furthermore, let α = 1 (1βλ ) 2 12 Assumption 2 on the spectral radius implies that βΛ has no entries larger than 1. 13 In the local public good application (recall Example 2) w = -1, and so when C ≥ b , the optimal intervention satisfies b * i = 0. Recalling our change of variables there (b i = [τ -b]/2), the optimal intervention in that case is to modify the endowment of each individual so that everyone accesses the optimal level of the local public good without investing personally. and note that a * = √ α b is the equilibrium action in the th principal component of G (see equation ( [4](#formula_15))).

Theorem 1. Suppose Assumptions 1-3 hold and the network game satisfies Property A. At the optimal intervention, the similarity between y * and principal component u (G) satisfies the following proportionality:

$ρ(y * , u (G)) ∝ ρ( b, u (G)) wα µ -wα , = 1, 2, . . . , n,(5)$where µ, the shadow price of the planner's budget, is uniquely determined as the solution to

$wα µ -wα 2 b2 = C (6)$and satisfies µ > wα for all , so that all denominators are positive.

We briefly sketch the main argument here and interpret the quantities in the formula. Define x = (b -b )/ b as the change of b , relative to b . By rewriting the principal's objective and budget constraints in terms of principal components and plugging in the equilibrium condition (4), we can rewrite the maximization problem as

$max x W (b, G) = wα (1 + x ) 2 b2 s.t. b2 x 2 ≤ C.$If the planner allocates a marginal unit of the budget to principal component , the condition for equality of the marginal return and marginal cost (recalling that µ is the multiplier on the budget constraint) is

$2 b2 • wα (1 + x ) marginal return = 2 b2 • µx marginal cost$.

It follows that wα µ-wα is exactly the value of x at which the marginal return and the marginal cost are equalized.[foot_6](#foot_6) Rewriting x in terms of cosine similarity, that equality implies

$wα µ -wα = x * = y * ρ(y * , u (G)) b ρ( b, u (G)) .$Rearranging this yields the proportionality expression (5) in the theorem. The Langrange multiplier µ is determined by solving the simple equation ( [6](#)). Now, given µ, the similarities ρ(y * , u (G)) determine the direction of the optimal intervention y * . The magnitude of the intervention is found by exhausting the budget. Thus Theorem 1 provides a full characterization of the optimal intervention.

Next, we discuss the formula for the similarities given in expression (5). The similarity between y * and u (G) measures the extent to which principal component u (G) is represented in the optimal intervention y * . Equation (5) tells us that this is proportional to two factors. The first factor, ρ( b, u (G)), is a status quo effect corresponding to the similarity between the th principal component and the status-quo vector b. This factor summarizes how much the initial condition influences the optimal intervention for a given budget. The intuition here is that if a given principal component is strongly represented in the status quo vector of standalone incentives, then -because of the convexity of welfare in the principal component basis -changes in that dimension have a particularly significant effect.

The second factor, wα µ-wα , is determined by two quantities: the eigenvalue corresponding to u (G) (via α = 1 1-βλ ), and the budget C (via the shadow price µ). To focus on this second factor, wα µ-wα , we define the similarity ratio of u (G) to be the fraction

$r * = ρ(y * , u (G)) ρ( b, u (G))$.

Theorem 1 shows that, as we vary , the similarity ratio r * is proportional to wα µ-wα . It follows that the similarity ratio is greater, in absolute value, for the principal components with greater α . Intuitively, those are the components where the intervention makes the largest change relative to the status quo profile of incentives. The ordering of these coefficients corresponds to the eigenvalues in a way that depends on the nature of strategic spillovers: Corollary 1. Suppose Assumptions 1-3 hold and the network game satisfies Property A. If the game is one of strategic complements (β > 0), then |r * | is decreasing in ; if the game is one of strategic substitutes (β < 0), then |r * | is increasing in .

In some problems there may be a nonnegativity constraint on actions, in addition to the constraints in problem (IT). Note that as long as the status quo actions b are positive, this constraint will be respected for all C less than some Ĉ, and so our approach will give information about the relative effects on various components for interventions that are not too large. 4.1. Small and large budgets. The optimal intervention takes especially simple forms in the cases of small and large budgets. From equation (6), we can deduce that the shadow price µ is decreasing in C. For w > 0, it follows that an increase in C raises wα µ-wα and that the principal components with larger α become larger in relative terms as well; in other words, if w > 0 and α > α , then r * /r * is increasing in C. [15](#foot_7) For simplicity of exposition, we suppress the dependence of outcomes on C in the following statement, but note that y * and thus the r * are all functions of C.

Proposition 1. Suppose Assumptions 1-3 hold and the network game satisfies Property A. Then the following hold:

1. As C → 0, in the optimal intervention, r * r * → α α . 2. As C → ∞, in the optimal intervention 2a. If the game has the strategic complements property, β > 0, then the similarity of y * and the first principal component of the network tends to 1, ρ(y * , u 1 (G)) → 1. 2b. If the game has the strategic substitutes property, β < 0, then the similarity of y * and the last principal component of the network tends to 1, ρ(y

$* , u n (G)) → 1.$This result can be understood by recalling equation ( [5](#formula_18)) in Theorem 1. First, consider the case of small C. When the planner's budget becomes small, the shadow price µ tends to ∞.[foot_8](#foot_8) Equation ( [5](#formula_18)) then implies that the similarity ratio of the th principal component becomes proportional to α . Turning now to the case where C grows large, the shadow price converges to wα 1 if β > 0, and to wα n if β < 0 (by equation ( [6](#))). Plugging this into equation ( [5](#formula_18)), we find that in the case of strategic complements, the optimal intervention shifts individuals' standalone marginal returns (very nearly) in proportion to the first principal component of G, so that y * → √ Cu 1 (G). In the case of strategic substitutes, on the other hand, the planner changes individuals' standalone marginal returns (very nearly) in proportion to the last principal component, namely y * → √ Cu n (G).[foot_9](#foot_9) Figure [2](#fig_1) presents optimal targets when the budget is large -in particular, for C = 500. We consider an 11-node undirected network with binary links containing two hubs, L 0 and R 0 , that are connected by an intermediate node M ; the network is depicted in Figure [2(A)](#fig_1). The numbers next to the nodes are the status quo standalone marginal returns. Payoffs are as in Example 1. For the case of strategic complements, we set β = 0.1, and for strategic substitutes we set β = -0.1. Assumptions 1 and 2 are satisfied and Property A holds. The top-left of Figure [2](#fig_1)(B) illustrates the first eigenvector, and the top-right depicts optimal targets in a game with strategic complements. The bottom-left of Figure [2](#fig_1)(B) illustrates the last eigenvector, and the bottom-right depicts the optimal targets when the game has strategic substitutes. The node size represents the size of the intervention, |b * i -bi |; its color represents the sign of the intervention (with green signifying a positive intervention and red indicating a negative intervention).

mations invoked for a large budget C. Assuming that G is generic, if b = 0 then, regardless of the level of C, the entire budget is spent either (i) on changing b 1 (if β > 0) or (ii) on changing b n (if β < 0). To see this, consider the proof of Theorem 1 and set b = 0 in the maximization problem (IT-PC), the principal component version of (IT). Note that if the allocation is not extreme, then the effort can be reallocated profitably among the principal components without changing the cost. In line with part 2 of Proposition 1, for large C, the optimal intervention is guided by the "main" component of the network (corresponding to the largest or smallest eigenvalue). Under strategic complements, this is the first eigenvector of the network, which corresponds to individuals' eigenvector centrality. 18 Intuitively, by increasing the standalone marginal return of each individual in proportion to his eigenvector centrality, the planner targets the individuals in proportion to their global contributions to strategic feedbacks, and this is welfare maximizing.

Under strategic substitutes, optimal targeting is determined by the last eigenvector of the network, corresponding to its smallest eigenvalue. This network component contains information about the local structure of the network: it determines the way to partition the set of nodes into two sets so that most of the links are across individuals in different sets. 19 The optimal intervention increases the standalone marginal returns of all individuals in one set and decreases those of individuals in the other set. The planner wishes to target neighboring nodes asymmetrically, as this reduces possible crowding-out effects that occur due to the strategic substitutes property.

## When are interventions simple?

We have just seen examples illustrating how, with large budgets, the intervention is simple: approximately proportional to just one principal component -the top or bottom one. After defining simplicity formally, our final result in this section characterizes how large the budget must be for this approximation to be a close one.

## Definition 2 (Simple interventions

). An intervention is simple if, for all i ∈ N , 18 Online Appendix Section OA2.1 presents a discussion of eigenvector centrality. 19 The last eigenvector of a graph is useful in determining the bipartiteness of a graph and its chromatic number. [Desai and Rao (1994)](#b14) characterize the smallest eigenvalue of a graph and relate it to the degree of bipartiteness of a graph. [Alon and Kahale (1997)](#b3) relate the last eigenvector to a coloring of the underlying graph, that is, a labeling of nodes by a minimal set of integers such that no neighboring nodes share the same label.

• b i -bi = √ Cu 1 i when the game has the strategic complements property (β > 0),

$• b i -bi = √$Cu n i when the game has the strategic substitutes property (β < 0). Let W * be the aggregate utility under the optimal intervention, and let W s be the aggregate utility under the simple intervention.

Proposition 2. Suppose w > 0, Assumptions 1 and 2 hold, and the network game satisfies Property A.

1. If the game has the strategic complements property, β > 0, then for any > 0, if

$C > 2 b 2 α 2 α 1 -α 2 2 , then W * /W s < 1 + and ρ(y * , √ Cu 1 ) > √ 1 -. 2.$If the game has the strategic substitutes property, β < 0, then for any > 0, if

$C > 2 b 2 α n-1 αn-α n-1 2 , then W * /W s < 1 + and ρ(y * , √ Cu n ) > √ 1 -.$Proposition 2 gives a condition on the size of the budget beyond which (a) simple interventions achieve most of the optimal welfare and (b) the optimal intervention is very similar to the simple intervention. This bound depends on the status quo standalone marginal returns and the structure of the network.

We first discuss the dependence on the status quo benefits. Observe that the first term on the right-hand side of the inequality for C is proportional to b . This inequality is therefore easier to satisfy when the status quo standalone marginal returns are smaller, in the sense of having a smaller norm. The inequality is harder to satisfy when these marginal returns are large and/or heterogeneous. 20  Next, consider the role of the network. Recall that α = (1βλ ) -2 ; thus if β > 0, the term α 2 /(α 1α 2 ) of the inequality is large when λ 1λ 2 , the "spectral gap" of the graph, is small. If β < 0, then the term α n-1 /(α n-1α n ) is small when the "bottom gap" of the graph, the difference λ n-1λ n , is small.

We now examine what network features affect these gaps, and illustrate with examples, depicted in Figure [3](#fig_3). The obstacle to simplicity is a strong dependence on the status quo standalone marginal benefits. This dependence will be strong when two different principal components in the network offer similar amplification (all else equal) of interventions in that component. Which of these principal components receives the planner's focus will depend strongly on the status quo. In such networks, interventions will not be simple for reasonable budgets. The merit of Proposition 2 is to show that small spectral or small bottom gap capture this property of the network. Figure [3](#fig_3) illustrates the role of the network structure in shaping the rate (in terms of the size of the budget C) at which the optimal intervention converges to a simple intervention as we vary C. Under strategic complements, the optimal intervention converges to a simple one faster (as we vary C) in a network that has a large spectral gap. Under strategic substitutes, the optimal intervention converges to a simple one faster (as we vary C) in a network that has a large bottom gap.

We now describe which network properties, at a more intuitive level, correspond to having small and large spectral gaps. First, consider the case of strategic complements. A standard fact is that the two largest eigenvalues can be expressed in terms of the corresponding eigenvectors as follows:

$λ 1 = max u: u =1 ij g ij u i u j λ 2 = max u : u =1 u•u 1 =0 ij g ij u i u j .$Eigenvector u 1 = arg max u: u =1 ij g ij u i u j (corresponding to λ 1 ) assigns the same signsay, positive to all nodes in the network. Clearly, eigenvector u 2 must assign negative values to some of the nodes (as it is orthogonal to u 1 ). In the network on the left side of Figure [4](#)(A) any such assignment will result in many adjacent nodes having opposite sign entries of u 2 ; as a result, many terms in the expression for λ 2 will be negative, and λ 2 will be much smaller than λ 1 , leading to a large spectral gap. In the network on the right side of 4(A), u 2 will have positive-sign entries to nodes in one community and negative-sign entries for nodes in the other community. Because there are few edges between the communities, λ 2 turns out to be almost as large as λ 1 . This will yield a small spectral gap. Thus, spectral gap measures the level of "cohesiveness" of the network, and it is this property that dictates fast convergence to simple interventions. [21](#foot_10)Turning next to strategic substitutes, recall that the smallest two eigenvalues, λ n and λ n-1 , can be written in terms of the corresponding eigenvectors as follows:

$λ n = min u: u =1 ij g ij u i u j λ n-1 = min u : u =1 u•u n =0 ij g ij u i u j .(7)$This tells us that |λ n | is large when the eigenvector u n = arg min u: u =1 ij g ij u i u j (corresponding to λ n ) assigns opposite signs to most pairs of adjacent nodes. In other words, the last eigenvalue is large when nodes can be partitioned into two sets and most of the connections are across sets, and thus |λ n | is maximized in a bipartite graph. The second-smallest eigenvalue of G reflects the extent to which the next-best eigenvector (orthogonal to u n ) is good at solving the same minimization problem. Hence, the bottom gap of G is small when there are two orthogonal ways to partition the network into two sets so that, either way, the "quality" of the bipartition, as measured by ij g ij u i u j , is similar. We illustrate Proposition 2 with a comparison of the two graphs in Figure [4](#)(C). The left-hand graph is bipartite: the last eigenvalue is λ n = -3 and the second last eigenvalue is λ n-1 = -1.64. By contrast, in the graph on the right of Figure [4](#)(C), the bottom eigenvalue λ n = -2.62, while the second lowest is λ n-1 = -2.30. This yields a much smaller bottom gap. [22](#foot_11) This difference in bottom gap is reflected in optimal targeting policy in Figure [4](#)(D): in the graph with large bottom gap, the optimal intervention puts little weight on the eigenvector u n-1 for a relatively small budget; it takes a much larger budget under a small bottom gap. We conclude by noting the influence of the status quo standalone marginal returns in shaping optimal interventions for small budgets. For a small budget C, the cosine similarity of the optimal intervention for non-main network components can be higher than the one for the main component. This is true when the status quo b is similar to some of the non-main network components; see Figures [4(B](#)

## Incomplete information

In the basic model, we assumed that the planner knows the standalone marginal returns of every individual. This section extends the analysis to settings where the planner does not know these parameters. For ease of exposition, we focus on network games that satisfy Property A.

Formally, fix a probability space (Ω, F, P). The planner's belief over states is given by P. This represents the planner's uncertainty, given all her information. The planner has control over the random vector (r.v.) B, that is, a function B : Ω → R n . The choice of B determines the cost of intervention. A realization of the random vector is denoted by b. This realization is common knowledge among individuals when they choose their actions. Thus, the game individuals play is one of complete information. [23](#foot_12) We also define a function K that gives the cost K(B) of implementing the random variable B. [24](#foot_13)We solve the following incomplete-information intervention problem:

$choose r.v. B to maximize E [W (b; G)] (IT-G) s.t. [I -βG]a * = b, K(B) ≤ C.$Note that the intervention problem (IT) under complete information is a special case of a degenerate r.v. B: one in which the planner knows the vector of standalone marginal returns exactly and implements a deterministic adjustment relative to it.

To guide our modeling of the cost of intervention, we now review the features of the distribution of B that matter for aggregate welfare. For network games that satisfy Property A, we can write:

$E [W (b; G)] = wE[(a * ) T a * ] = wE[a T a] = w α E[b ] 2 + Var[b ] .(8)$In words, welfare is determined by the mean and variance of the realized components b ; these in turn are determined by the first and second moments of the chosen random variable B. In view of this, we will consider intervention problems where the planner can modify the mean and the covariance matrix of B, and the cost of intervention depends only on these modifications.

5.1. Mean shifts. We first consider an intervention where there is an arbitrarily distributed vector of standalone marginal returns and the planner's intervention shifts it in a deterministic way. Formally, fix a random variable B, called the status quo, with typical realization b. The planner's policy is given by b = b + y, where y ∈ R n is a deterministic vector. We denote the corresponding random variable by B y . In terms of interpretation, note that implementing this policy does not require knowing b as long as the planner has an instrument that shifts incentives.

Assumption 4. The cost of implementing r.v. B y is

$K(B y ) = i y 2 i ,$and K(B) is ∞ for any other random variable.

In contrast to the analysis of Theorem 1, the vector b is a random variable. But we take the analogue of the cost function used there, noting that in the deterministic setting this formula held with y = b -b.

Proposition 3. Consider problem (IT-G) with the cost of intervention satisfying Assumption 4. Suppose Assumptions 1 and 2 hold and the network game satisfies Property A. The optimal intervention policy B * is equal to B y * , where y * is the optimal intervention in the deterministic problem with b = E[ b] as the status quo vector of standalone marginal returns.

5.2. Intervention on variances. We next consider the case where the planner faces a vector of means, fixed at b, and, subject to that, can choose any random variable B. The difference in the expected welfare for two different interventions B and B depends only on the variance-covariance matrix of B and B. Thus, the planner effectively faces the problem of intervening on variances. We prove a result on optimal intervention for all cost functions satisfying certain symmetries.

Assumption 5. The cost function satisfies two properties: (a)

$K(B) = ∞ if Eb = b; (b) K(B) = K( B) if b -b = O(b -b),$where O is an orthogonal matrix. Analogous to our other notation, we use b for realizations of the random vector with distribution B.

Part (a) is a restriction on feasible interventions, namely a restriction to interventions that are mean-neutral. Part (b) means that rotations of coordinates around the mean do not affect the cost of implementing a given distribution. This assumption gives the cost a directional neutrality, which ensures that our results are driven by the benefits side rather than by asymmetries operating through the costs. For example, let Σ B be the variance-covariance matrix of the random variable B. In particular, σ B

ii is the variance of b i . Suppose that the cost of implementing B with Eb = b is a function of the sum of the variances of the b i :

$K(B) = φ i σ B ii if Eb = b ∞ otherwise. (9$$)$The cost function (9) satisfies property (a) of Assumption 5. Moreover, it satisfies property (b) of Assumption 5 because i σ B ii = trace Σ B ; this trace is the sum of the eigenvalues of Σ B , which is invariant to the transformation defined in (b). [25](#foot_14)Proposition 4 (Variance control). Consider problem (IT-G) with the cost of intervention satisfying Assumption 5. Suppose Assumptions 1 and 2 hold and the network game satisfies Property A. Let the optimal intervention be B * . We have the following: We now provide the intuition for Proposition 4. Shocks to individuals' standalone marginal returns create variability in the players' equilibrium actions. The assumption that the intervention is mean neutral (part (a) of Assumption 5) leaves the planner to control only the variances and covariances of these marginal returns with her intervention. Hence, the solution to the intervention problem describes what the planner should do to induce volatilities in actions that maximize the ex-ante expected welfare.

Suppose first that investments are strategic complements. Then a perfectly correlated shock in individual standalone marginal returns is amplified by strategic interaction. In fact, the type of shock that is most amplifying (at a given size) is the one that is perfectly correlated across individuals, with the magnitude of a given individual's shock proportional to the first principal component (his eigenvector centrality). These shocks are exactly what b * 1 = u 1 (G) • b * captures. Hence, this is the dimension of volatility that the planner most wants to increase if she likes variance in actions (w > 0) and most wants to decrease if she dislikes variance in actions (w < 0). If investments are strategic substitutes, then a perfectly correlated shock does not create a lot of variance in actions: The first-order response of all individuals to an increase in their standalone marginal returns is to increase investment, but that in turn makes all individuals decrease their investment somewhat because of the strategic substitutability with their neighbors. Hence, highly positively correlated shocks do not translate into high volatility. The shock profiles that create most variability in actions are the ones in which neighbors have negatively correlated shocks. A planner that likes variability in actions will then prioritize such shocks. Because the last eigenvector of the system is correlated with those shocks that have opposite effects on neighbors, this is exactly the type of volatility that is of greatest concern, and this is what the planner will focus on most.

Example 3 (Illustration in the case of the circle). Figure [1](#fig_0) depicts six of the eigenvectors/principal components of a circle network with 14 nodes. The first principal component is a positive vector and so B projected on u 1 (G) captures positively correlated shocks across all players. The second principal component (top left panel of Figure [1](#fig_0)) splits the graph into two sides, one with positive entries and the other with negative entries. Hence, B projected on u 2 (G) captures shocks that are highly positively correlated on each side of the circle network, with the two opposite sides of the circle being anti-correlated. As we move along the sequence, we can see that B projected on the th eigenvector represents shocks that are more and more local. At the extreme, B projected on u 14 (G), (bottom-right panel of Figure [1](#fig_0)) captures the component of shocks that is perfectly anti-correlated across neighbors.

## Concluding remarks

We study the problem of a planner who seeks to optimally target incentive changes in a network game. Our framework allows for a broad class of strategic and non-strategic spillovers across neighbors. The main contribution of the paper is methodological: we show that principal components of the network of interaction provide a useful basis for analyzing the effects of an intervention. This decomposition leads to our main result: there is a close relation between the nature of the game (complements or substitutes) and the weight that different principal components receive in the optimal intervention. To develop these ideas in the simplest way, we have focused on a model in which the matrix of interaction is symmetric, the costs of intervention are quadratic, and the intervention itself takes the form of altering the standalone benefits. In the Online Appendix we relax these restrictions and develop extensions of our approach to non-symmetric matrices of interaction, to more general costs of intervention, and to environments where interventions occur via monetary incentives for activity. We also relax Property A, a technical condition which facilitated our basic analysis, and cover a more general class of externalities.

We briefly mention two further applications. In some circumstances, the planner seeks a budget-balanced tax/subsidy scheme in order to improve the economic outcome. In an oligopoly market, for example, a planner could tax some suppliers, thereby increasing their marginal costs, and then use that tax revenue to subsidize other suppliers. The planner will solve a problem similar to the one we have studied here, with the important difference that she will face a different constraint, namely, a budget-balance constraint. In ongoing work, [Galeotti et al. (2018)](#b16) show that the principal component approach that we employed in this paper is useful in deriving the optimal taxation scheme and, in turn, in determining the welfare gains that can be achieved in supply chains.

We have focused on interventions that alter the standalone marginal returns of individuals. Another interesting problem is the study of interventions that alter the matrix of interaction. We hope this paper stimulates further work along these lines.

We transform the maximization problem into the basis given by the principal components of G. To this end, we first rewrite the cost and the objective in the principal components basis, using the fact that norms do not change under the orthogonal transformation U T . (The norm symbol • always refers to the Euclidean norm.) Letting y = b -b,

$K(b, b) = i y 2 i = y 2 2 = y 2$and wa T a = w a 2 = w a 2 = wa T a.

By recalling that, in equilibrium, a * = [I -βΛ] -1 b, and using the definition α = 1

(1-βλ (G)) 2 , the intervention problem (IT) can be rewritten as:

$max b w α b 2 (IT-PC) s.t. y 2 ≤ C.$We now transform the problem so that the control variable is x where x = y / b . We obtain max

$x w α (1 + x ) 2 b2 s.t. b2 x 2 ≤ C$Note that, for all , α are well-defined (by Assumption 1) and strictly positive (by genericity of G). This has two implications. [26](#foot_15)First, at the optimal solution x * the resource constraint problem must bind. To see this, note that Assumption 3 says that either w > 0, or w < 0 and b2 > C. Suppose that at the optimal solution the constraint does not bind. Then, without violating the constraint, we can slightly increase or decrease any x . If w > 0 (resp. w < 0) the increase or the decrease is guaranteed to increase (resp. decrease) the corresponding (x + 1) 2 (since the α are all strictly positive). Second, we show that the optimal solution x * satisfies x * ≥ 0 for every if w > 0, and x * ∈ [-1, 0] for every if w < 0. Suppose w > 0 and, for some , x * < 0. Then [-x * + 1] 2 > [x * + 1] 2 . Since w > 0 and every α is positive, we can raise the aggregate utility without changing the cost by flipping the sign of x * . Analogously, suppose w < 0. It is clear that if x * < -1, then by setting x = -1 the objective improves and the constraint is relaxed; hence, at the optimum, x * ≥ -1. Suppose next that x > 0 for some . Then [-x * + 1] 2 < [x * + 1] 2 . Since w < 0 and every α is positive, we can improve the value of the objective function without changing the cost by flipping the sign of x * .

We now complete the proof. Observe that the Lagrangian corresponding to the maximization problem is

$L = w α (1 + x ) 2 b + µ C - b2 x 2 .$Taking our observation above that the constraint is binding at x = x * , together with the standard results on the Karush-Kuhn-Tucker conditions, the first-order conditions must hold exactly at the optimum with a positive µ:

$0 = ∂L ∂x = 2 b2 [wα (1 + x * ) -µx * ] = 0. (10$$)$We take a generic b such that b = 0 for all . If for some we had µ = wα then the right-hand side of the second equality in (10) would be 2 b2 wα , which, by the generic assumption we just made and the positivity of α , would contradict (10). Thus, the following holds with a nonzero denominator:

x * = wα µwα , and the Lagrange multiplier µ is therefore pinned down by

$w 2 b2 α µ -wα 2 = C. Note finally that ρ(y * , u (G)) = y * • u (G) y * u (G) = y * √ C = b x * √ C = b √ C ρ( b, u (G))x * ∝ ρ( b, u (G))x * .$Proof of Proposition 1. Part 1. From expression 6 of Theorem 1, it follows that if C → 0 then µ → ∞. The result follows by noticing that

$r * r * = α α µ -wα µ -wα .$Part 2. Suppose that β > 0. Using the derivation of the last part of the proof of Theorem 1, we write:

$ρ(y * , u (G)) = b √ C ρ( b, u (G))x * ,$with x * = wα µ-wα . From expression 6 of Theorem 1, it follows that if C → ∞ then µ → wα 1 . This implies that x * → α α 1 -α for all = 1. As a result, if C → ∞ then ρ(y * , u (G)) → 0 for all = 1. Furthermore, we can rewrite expression 6 of Theorem 1 as b ρ( b, u (G))

$x * √ C 2 = 1,$and therefore

$lim C→∞ b ρ( b, u (G)) x * √ C 2 = lim C→∞ b ρ( b, u 1 (G)) x * 1 √ C 2 = 1,$where the first equality follows because x * → α α 1 -α for all = 1. The proof for the case of β < 0 follows the same steps, with the only exception that if C → ∞ then µ → wα n .

Proof of Proposition 2. We first prove the result on welfare and then turn to the result on cosine similarity. Welfare. Consider the case of strategic complementarities, β > 0. Define by x the simple intervention, and note that x1 = √ C/ b1 and that x = 0 for all > 1. The aggregate utility obtained under the simple intervention is:

$W s = b2 α (1 + x ) 2 = b2 1 α 1 x1 (x 1 + 2) + α b2 .$The aggregate utility at the optimal intervention is

$W * = b2 α (1 + x * ) 2 = b2 1 α 1 x * 1 (x * 1 + 2) + =1 b2 α x * (x * + 2) + α b2$Hence

$W * W s = b2 1 α 1 x * 1 (x * 1 + 2) + α b2 b2 1 α 1 x1 (x 1 + 2) + α b2 + =1 b2 α x * (x * + 2) b2 1 α 1 x1 (x 1 + 2) + α b2 ≤ 1 + =1 b2 α x * (x * + 2) b2 1 α 1 x1 (x 1 + 2) + α b2 as x1 ≥ x * 1 ≤ 1 + =1 b2 α x * (x * + 2) b2 1 α 1 x2 1 summands in denominator are positive = 1 + =1 b2 α x * (x * + 2) α 1 C b 2 1 x2 1 = C; see below ≤ 1 + 2α 1 -α 2 α 1 b 2 C α 2 α 1 -α 2 2 see calculation below ≤ 1 + 2 b 2 C α 2 α 1 -α 2 2 .$The fact b 2 1 x2 1 = C, used above, follows because the simple policy allocates the entire budget to changing b 1 . The inequality after that statement follows because

$=1 b2 α x * (x * + 2) ≤ α 2 =1 b2 x * (x * + 2) ordering of the α ≤ α 2 x * 2 (x * 2 + 2) =1 b2 Corollary 1 ≤ α 2 wα 2 µ -wα 2 wα 2 µ -wα 2 + 2 =1 b2 Theorem 1 ≤ α 2 wα 2 wα 1 -wα 2 wα 2 wα 1 -wα 2 + 2 b 2 = α 2 α 1 -α 2 2 (2α 1 -α 2 ) b 2$Hence, the inequality

$C > 2 b 2 α 2 α 1 -α 2 2 is sufficient to establish that W * W s < 1 + .$The proof for the case of strategic substitutes follows the same steps; the only difference is that we use α n instead of α 1 and α n-1 instead of α 2 . Cosine similarity. We now turn to the cosine similarity result. We focus on the case of strategic complements. The proof for the case of strategic substitutes is analogous. We start by writing a useful explicit expression for 

$ρ(∆b * , √ Cu 1 ) = (b * -b) • ( √ Cu 1 ) b * -b √ Cu 1 = (b * -b) • (u 1 ) √ C ,(11)$$* i -bi = w u i α µ -wα b and therefore (b * -b) • u 1 = i u 1 i u i wα µ -wα b = wα µ -wα b (u 1 • u ) = wα 1 µ -wα 1 b1$Hence, using this in equation 11, we can deduce that

$ρ(∆b * , u 1 ) = 1 √ C wα 1 µ -wα 1 b1 ≥ √ 1 - iff wα 1 µ -wα 1 2 b2 1 -C(1 -) ≥ 0. (12$$)$The following lemma shows that the inequality after the "if and only if" follows from our hypothesis that

$C > 2 b 2 α 2 α 1 -α 2 2$, and thus establishing it completes the proof.

$Lemma 1. Assume C > 2 b 2 α 2 α 1 -α 2 2 . Then wα 1 µ -wα 1 2 b2 1 ≥ C(1 -) (13) Proof of Lemma 1. Note that C > 2 b 2 α 2 α 1 -α 2 2 =⇒ C > b 2 α 2 α 1 -α 2 2 ,$and therefore

$C(1 -) < C -b 2 α 2 α 1 -α 2 2 . (14$$)$But then we have the following chain of statements, explained immediately after the display:

$wα 1 µ -wα 1 2 b2 1 -C(1 -) ≥ wα 1 µ -wα 1 2 b2 1 -C + b 2 α 2 α 1 -α 2 2 = wα 1 µ -wα 1 2 b2 1 - wα µ -wα 2 b2 + b 2 α 2 α 1 -α 2 2 = b 2 α 2 α 1 -α 2 2 - =1 wα µ -wα 2 b2 = α 2 α 1 -α 2 2 b2 - =1 wα µ -wα 2 b2 > 0.$The first inequality follows from substituting the upper bound on C(1 -), statement ( [14](#formula_58)) above, which we derived from our initial condition on C. The equality after that follows by substituting the condition on the binding budget constraint at the optimum, which we derived in Theorem 1. The next equality follows by isolating the term for the first component in the sum and by noticing that that cancels with the first term. The next equality follows by noticing that b 2 = b 2 . The final inequality follows because, from the facts that µ > wα 1 and that

$α 1 > α 2 > • • • > α n , we can deduce that for each > 1 wα µ -wα < wα wα 1 -wα = α α 1 -α < α 2 α 1 -α 2$This concludes the proof of Proposition 2.

## ONLINE APPENDIX: ADDITIONAL PROOFS, DISCUSSION AND EXTENSIONS FOR TARGETING INTERVENTIONS IN NETWORKS

Throughout the online appendix, we refer often to sections, results, and equations in the main text and its appendix using the numbering established there. The numbers of sections, results, and equations in this online appendix are all prefixed by OA to distinguish them.

## OA1. Additional Proofs

Proof of Proposition 3. Using expression (8), we can write the dependence of E [W (b; G)] on intervention B y as follows:

$E [W (b; G)] = w α E[ b ] + y 2 + Var[b ] .$Choosing y to maximize this is identical to the problem analyzed in the deterministic setting in the proof of Theorem 1. Thus, defining x = y /b , with b = E[ B ], it satisfies the same conditions at the optimum as those derived in Theorem 1.

Proof of Proposition 4. Given Assumption 5, without loss of generality we can normalize b = 0. Using expression (8) and normalization, we obtain that if the optimal solution is B * the expected welfare obtained is

$E [W (b * ; G)] = w α Var(b * ).$Note that the random variable B * can be written as U T B * , and so the variance-covariance matrix of the random variable B * is Σ B * = U T Σ B * U , where recall that Σ B * is the variancecovariance matrix of the random variable B * . We consider the case of w > 0 and β > 0; the proof of the other cases is analogous and therefore omitted. The expected welfare is a weighted sum of the variances of the principal components, Var(b * ) = Var(u (G) • b * ), and the weight α on the variance of principal component of G is an increasing function of its eigenvalue λ , because β > 0.

Suppose that the claim in Proposition is violated, that is, there exists a , such that < and Var(b * ) < Var(b * ). We construct an alternative intervention that has the same cost and does strictly better. Take the permutation matrix (and therefore an orthogonal matrix) P such that P kk = 1 for all k ∈ { , } and P = P = 1. Define B * * = OB * with O = U P U T . Clearly, O is orthogonal, as U and P are both orthogonal. Hence, by Assumption 5, K(B * ) = K(B * * ). Furthermore, the matrix 

## OA2. Discussion

We discuss the relation of principal components of the matrix of interactions with other related networks statistics (Session OA2.1). We then provide a different economic example, which complements those in our main text, inspired by beauty context games (Session OA2.2).

OA2.1. Principal components and other network measures. First principal component and eigenvector centrality: For ease of exposition, let the network be connected, that is, let G be irreducible. By the Perron-Frobenius Theorem, u[foot_16](#foot_16) (G) is entry-wise positive; indeed, this vector is the Perron vector of the matrix, also known as the vector of individuals' eigenvector centralities. Thus, our results of Section 4 imply that, under strategic complementarities, interventions that aim to maximize the aggregate utility should change individuals' incentives in proportion to their eigenvector centralities.

It is worth comparing this result with results that highlight the importance of Bonacich centrality. Under strategic complements, equilibrium actions are proportional to the individuals' Bonacich centralities in the network [(Ballester et al., 2006)](#). 1 Within the [Ballester et al. (2006)](#) framework, it can easily be verified that if the objective of the planner is linear in the sum of actions, then under a quadratic cost function the planner will target individuals in proportion to their Bonacich centralities (see also [Demange (2017)](#)). Bonacich centrality converges to eigenvector centrality as the spectral radius of βG tends to 1; otherwise the two vectors can be quite different (see, for example, [Calvó-Armengol et al. (2015)](#b39) or [Golub and Lever (2010)](#b43)).

The substantive point is that the objective of our planner when solving the intervention problem (IT) is to maximize the aggregate equilibrium utility, not the sum of actions, and that explains the difference in the targeting strategy. Indeed, our planner's objective (under Property A) can be written as follows (introducing a different constant factor for convenience):

$i u i ∝ 1 n i a 2 i = ā2 + σ 2 a ,$where σ 2 a is the variance of the action profile and a is the mean action. Thus, our planner cares about the sum of actions and also their diversity, simply as a mathematical consequence of her objective. This explains the reason why her policies differ from those that would be in effect if just the mean action were the focus. To reiterate this point, we finally note that if we consider problem (IT) but we assume that the cost of intervention is linear, that is, K(b, b) = i |b i -bi |, then the optimal intervention will target only one individual (see the discussion in Online Appendix Section OA3.3); note that the targeted individual is not necessarily the individual with the highest Bonacich centrality. Last principal component: We have shown that in games with strategic substitutes, for large budgets interventions that aim to maximize the aggregate utility target individuals in proportion to the eigenvector of G associated to the smallest eigenvalue of G, the last principal component.

There is a connection between this result and the work of [Bramoullé et al. (2014)](#). [Bramoullé et al. (2014)](#) study the set of equilibria of a network game with linear best replies and strategic substitutes. They observe that such a game is a potential game, and they derive the potential function explicitly. From this, they can deduce that the smallest eigenvalue of G is crucial for whether the equilibrium is unique, and it is also useful for analyzing the stability of a particular equilibrium. [2](#foot_17) The basic intuition is that the magnitude of the smallest eigenvalue determines how small changes in individuals' actions propagate, via strategic substitutes, in the network. When these amplifications are strong, multiple equilibria can emerge. Relatedly, when these amplifications are strong around an equilibrium, that equilibrium will be unstable.

Our study of the strategic substitutes case is driven by different questions, and delivers different sorts of characterizations. We assume that there is a stable equilibrium which is unique at least locally, and then we characterize optimal interventions in terms of the eigenvectors of G. In general, all the eigenvectors -not just the one associated to the smallest eigenvalue -can matter. Interventions will focus more on the eigenvectors with smaller eigenvalues. When the budget is sufficiently large, the intervention will (in the setting of Section 4) focus on only the smallest-eigenvalue eigenvector. As discussed in Section 4, the network determinants of whether targeting is simple can be quite subtle. To the best of our knowledge, these considerations are all new in the study of network games.

Nevertheless, at an intuitive level there are important points of contact between our intuitions and those of [Bramoullé et al. (2014)](#). In our context, as discussed earlier, our planner likes to move the incentives of adjacent individuals in opposite directions. The eigenvector associated to the smallest eigenvalue emerges as the one identifying the best way to do this at a given cost, and the eigenvalue itself measures how intensely the strategic effects amplify. This "amplification" property involves forces similar to those that make the smallest eigenvalue important to stability and uniqueness in [Bramoullé et al. (2014)](#). Spectral approaches to variance control: [Acemoglu et al. (2016)](#b34) give a general analysis of which network statistics matter for volatility of network equilibria. [Baqaee and Farhi (2017)](#b37) develop a rich macroeconomic analysis relating network measures to aggregate volatility. Though both papers note the importance of eigenvector centrality in (their analogues of) the case of strategic complements, their main focus is on how the curvature of best responses changes the volatility of an aggregate outcome, and which "second order" (curvature-related) network statistics are important. We use the principal components of the network to understand which first-order shocks are most amplified, and how this depends on the nature of strategic interactions. OA2.2. Beauty contest with local interactions. This example is inspired by [Morris and Shin (2002)](#) and [Angeletos and Pavan (2007)](#). Individuals trade off the returns from effort against the costs, as in the first example, but also care about coordinating with others. These considerations are captured in the following payoff:

$U i (a, G) = a i bi + β j g ij a j - 1 2 a 2 i - γ 2 j g ij [a j -a i ] 2 ,$where we assume that β > 0 and γ > 0 and that j g ij = 1 for all i, so the total interaction is the same for each individual. This formulation also relates to the theory of teams and organizational economics (see, for example, [Dessein et al. (2016)](#b41), [Marschak and](#b47)[Radner (1972), and](#b47)[Calvó-Armengol et al. (2015)](#b39)). We may interpret individuals as managers in different divisions within an organization. Each manager selects the action that maximizes the output of the division, given by the first term, but the manager also cares about coordinating with other divisions' actions.[foot_18](#foot_18) This is a game of strategic complements; moreover, an increase in j's action has a positive effect on individual i's utility if and only if a j < a i . It can be verified that the first-order condition for individual i is given by

$a i = bi 1 + γ + bi + γ 1 + γ g ij a j .$By defining β = β+γ 1+γ and b = 1 1+γ b, we obtain a best-response structure exactly as in condition (2). Moreover, the aggregate equilibrium utility is W (b, g) = 1 2 (a * ) T a * . Hence, this game satisfies Property A.

## OA3. Extensions

We now extend our basic model to study settings where (a) Property A is not satisfied (Session OA3.1), (b) the matrix G is non-symmetric (Session OA3.2), (c) the exact quadratic cost specification does not hold (Session OA3.3), and (d) the interventions occur via monetary incentives for activity (Session OA3.4).

OA3.1. General non-strategic externalities. Section 4 characterizes optimal interventions for network games that satisfy Property A. We now relax this assumption. Recall that player i's utility for action profile a is

$U i (a, G) = Ûi (a, G) + P i (a -i , G, b),$where Ûi (a, G) = a i (b i + j g ij a j ) -1 2 a 2 i . At an equilibrium a * , it can be checked that i Ûi (a * , G) ∝ (a * ) T a * . Therefore, a sufficient condition for Property A to be satisfied is that i P i (a * -i , G, b) is also proportional to (a * ) T a * . Examples 1 and 2, as well as the example presented in Section OA2.2, satisfy this property. However, as the next example shows, there are natural environments in which it is violated.

Example OA1 (Social interaction and peer effects). Individual decisions on smoking and alcohol consumption are susceptible to peer effects (see [Jackson et al. (2017)](#) for references to the extensive literature on this subject). For example, an increase in smoking among an adolescent's friends increases her incentives to smoke and, at the same time, has negative effects on her welfare. These considerations are reflected in the following payoff function:

$U i (a, G) = Ûi (a, G) -γ j =i a j ,$where β > 0 and γ is positive and sufficienctly large. It can be checked that the aggregate equilibrium welfare is:

$W (b, G) = 1 2 (a * ) T a * -nγ i a * i , (OA-1)$with a * given by expression (3).[foot_19](#foot_19)

To extend the analysis beyond Property A, we allow the non-strategic externality term P i (a -i , G, b) to take a form that allows for flexible externalities within the linear-quadratic family:

$5 P i (a -i , G) = m 1 j g ij a j + m 2 j g ij a 2 j + m 3 j =i a j + m 4 j =i a j 2 + m 5 j =i a 2 j .$We also make the following assumption on the matrix G:

Assumption OA1. The total interaction is constant across individuals, that is, j g ij = 1 for all i ∈ N .

Using equation ( [3](#)) and Assumption OA1, we can rewrite the expression for the aggregate equilibrium utility as follows:

$W (b, G) = w 1 (a * ) T a * + w 2 n i a * i 2 + w 3 √ n i a * i ,$where w 1 = 1 + m 2 + m 5 + (n -1)m 4 , w 2 = nm 5 (n -2), and

$w 3 = √ n[m 1 + (n -1)m 3 ].$Observe that Property A clearly holds when w 2 = w 3 = 0. On the other hand, if (say) w 1 = w 2 = 0, then the planner's objective is to maximize the sum of the equilibrium actions, which is a fairly different type of objective. A characterization of the optimal intervention when the planner's objective is to maximize the sum of the equilibrium actions can be found in Corollary OA1 below. Under Assumption OA1, the sum of the equilibrium actions is proportional to the sum of the standalone marginal returns. Because u 1 is proportional to the all-ones vector 1, this sum in turn is equal to b 1 .

Together, these facts allow us to extend our earlier analysis to the case of general w 2 and w 3 . First, we can still express the objective function simply in terms of the singular value decomposition; the only difference is that now b 1 will enter both in a quadratic term and in a linear term. In view of this, we first solve the problem (exactly analogously to the previous solution) for a given value of b 1 , and then we optimize over b 1 .

We maintain Assumption 1 and Assumption 2. Recall that player i's utility for action profile a is

$U i (a, G) = Ûi (a, G) + P i (a -i , G, b) where Ûi (a, G) = a i (b i + j g ij a j ) -1 2 a 2 i and P i (a -i , G, b$) is a non-strategic externality term that takes the following form:

$P i (a -i , G) = m 1 j g ij a j + m 2 j g ij a 2 j + m 3 j =i a j + m 4 j =i a j 2 + m 5 j =i a 2 j .$Here we have taken local and global externality terms given by second-order polynomials in actions. (We could also accommodate externalities that depend directly on the b i in the same sort of way, as will become clear in the proof, but we omit this for brevity.)

The implication of Assumption OA1 for our analysis is summarized next.

Lemma OA1. Assumption OA1 implies that:

$1. for any a ∈ R n , i j g ij a j = i a i and i j g ij a 2 j = i a 2 i 2. λ 1 (G) = 1 and u 1 i (G) = √ n for all i 3. i a * i = 1 1-β b i = √ n 1-β b 1 = √ nα 1 b 1 , where a * is equilibrium action profile. 6$The proof of Lemma OA1 is immediate. Using part 1 of Lemma OA1, and that individuals play an equilibrium (actions satisfy expression (3)), we obtain:

$W (b, G) = w 1 (a * ) T a * + w 2 n i a * i 2 + w 3 √ n i a * i ,$with:

$w 1 = 1 + m 2 + m 5 + (n -1)m 4 w 2 = nm 5 (n -2) w 3 = √ n[m 1 + (n -1)m 3 ].$Using the decomposition G = U ΛU T , together with part 2 and part 3 of Lemma OA1, we obtain:

$W (b, G) = w 1 a * T a * + w 2 α 1 b 2 1 + w 3 √ α 1 b 1 .$The intervention problem reads

$max b w 1 a * T a * + w 2 α 1 b 2 1 + w 3 √ α 1 b 1 subject to a * = √ α b (b -b ) 2 ≤ C.$Using the expression for equilibrium actions, we obtain:

$max b w 1 =1 α b 2 + w 2 α 1 b 2 1 + w 3 √ α 1 b 1 subject to (b -b ) 2 ≤ C. Recalling the definition x = b -b b$for every , we finally rewrite the problem as:

$max x w 1 =1 α b2 (1 + x ) 2 + w 2 α 1 b2 1 (1 + x 1 ) 2 + w 3 √ α 1 b1 (1 + x 1 ) subject to b2 x 2 ≤ C.$Theorem OA1 characterizes optimal interventions for two cases: (i) w 1 ≥ 0 and (ii) w 1 < 0 and =2 b2 > C. The extension of the analysis for the remaining case w 1 < 0 and =2 b2 < C is explained in Remark OA1, which is presented after the proof of Theorem OA1. Taken together, Theorem OA1, and Remark OA1 following it, constitute our extension of Theorem 1 to games that do not satisfy Property A.

Theorem OA1. Suppose Assumptions 1, 2 and OA1 hold. Suppose that either: (i) w 1 ≥ 0 or that (ii) w 1 < 0 and =2 b2 > C. The optimal intervention is characterized as follows:

1.

$x * 1 = α 1 µ -(w 1 + w 2 )α 1 w 1 + w 2 + w 3 2 √ α 1 b1 ,$and, for all ≥ 2,

$x * = w 1 α µ -w 1 α .$The shadow price of the planner's budget, µ > (w 1 + w 2 )α 1 , is uniquely determined as the solution of:

$=2 b2 w 1 α µ -w 1 α 2 + b2 1 α 1 µ -(w 1 + w 2 )α 1 2 w 1 + w 2 + w 3 2 √ α 1 b1 2 = C 2. a. For all = 1, x * > 0 if and only if w 1 > 0; b. x * 1 > 0 if and only if w 1 + w 2 + w 3 2 √ α 1 b1 > 0. 2b. If the game has strategic complements, β > 0, then |x * 2 | > |x * 3 | > • • • > |x * n |. If the game has strategic substitutes, β < 0, then |x * 2 | < |x * 3 | < • • • < |x * n |.$3. Suppose w 1 = 0. In the limit as C → 0, µ → ∞ and:

$x * x * → α α for all , = 1 x * 1 x * → α 1 α w 1 + w 2 + w 3 2 √ α 1 b1 for all = 1$4. Suppose the game has strategic complements, β > 0. In the limit as

$C → ∞, µ → max{w 1 α 2 , (w 1 + w 2 )α 1 }, and a. If w 1 α 2 > (w 1 + w 2 )α 1 then x * 1 → α 1 w 1 α 2 -(w 1 + w 2 )α 1 w 1 + w 2 + w 3 2 b1 √ α 1 , |x * 2 | → ∞, |x * | → α α 2 -α for all > 2. b. If w 1 α 2 < (w 1 + w 2 )α 1 then |x * 1 | → ∞ x * → w 1 α (w 1 + w 2 )α 1 -w 1 α for all ≥ 2.$5. Suppose the game has strategic substitutes, β < 0. In the limit as C → ∞, µ → max{w 1 α n , (w 1 + w 2 )α 1 }. Hence: a. If w 1 α n > (w 1 + w 2 )α 1 then:

$x * 1 → α 1 w 1 α n -(w 1 + w 2 )α 1 w 1 + w 2 + w 3 2 b1 √ α 1 , |x * | → α α n -α for all ∈ {2, . . . , n -1}, |x * n | → ∞. b. If w 1 α n < (w 1 + w 2 )α 1 then |x * 1 | → ∞ x * → w 1 α (w 1 + w 2 )α 1 -w 1 α for all ≥ 2.$Before the proof, we briefly explain the sense in which this extends Theorem 1 and associated results in the basic model. The formula for x * in part 1 is a direct generalization of equation ( [5](#formula_18)), with the shadow price characterized by an equation analogous to (6). The monotonicity relations on x * in part 2 correspond to Corollary 1. The small-C analysis of part 3 corresponds to Proposition 1. The large-C analysis in parts 4 and 5 corresponds to the limits studied in Section 4.2.

Proof of Theorem OA1. Part 1. For a given x ∈ R n , define

$K(x 1 ) = (w 1 + w 2 )α 1 b2 1 (1 + x 1 ) 2 + w 3 √ α 1 b1 (1 + x 1 ) C(x 1 ) = C - b2 1 x 2 1 .$The maximization problem can be rewritten as:

$max x w 1 =2 α b2 (1 + x ) 2 + K(x 1 ) subject to =2 b2 x 2 ≤ C(x 1 )$We solve this problem in two steps. First Step. We fix x 1 so that C(x 1 ) ≥ 0; that is,

$x 1 ∈ [-C/ b1 , C/ b1 ]. We then solve max x -1 w 1 =2 α b2 (1 + x ) 2 subject to =2 b2 x 2 ≤ C(x 1 )$In the case in which w 1 = 0 we skip this first step. If w 1 = 0, then we argue in a way exactly analogous to the proof of Theorem 1 that for all = 1,

$x * = w 1 α µ -w 1 α$where, for all = 1, µ ≥ w 1 α and it solves

$=2 b2 w 1 α µ -w 1 α 2 = C(x 1 ).$Note that, for all ≥ 2, x * > 0 if w 1 > 0 and x * < 0 if w 1 < 0.

Note also that if w 1 < 0 the constraint binds: the bliss point (x * = -1 for all = 1) cannot be achieved because C < n =2 b2 .

## Second

Step. Substituting into the objective function the expression for x * , for all ≥ 2, we obtain:

$max x 1 W = w 1 =2 α b2 µ µ -w 1 α 2 + K(x 1 ) subject to =2 b2 w 1 α µ -w 1 α 2 = C(x 1 ) x 1 ∈ - C b1 , Cb1$The following lemma is instrumental to the solution of this problem. It characterizes µ, which is implicitly a function of x 1 . Lemma OA2. From the budget constraint in the above problem it follows that 1. lim

$x 1 →- √ C/ b1 µ = lim x 1 → √ C/ b1 µ = ∞ 2. dµ dx 1 = b2 1 x 1 =2 w 2 1 b2 1 α 2 (µ-w 1 α ) 3 3. dµ dx 1 > 0 if x 1 > 0 and dµ dx 1 < 0 if x 1 < 0; 4. lim x 1 →- √ C/ b1 dµ dx 1 = -∞ and lim x 1 → √ C/ b1 dµ dx 1 = ∞.$Proof of Lemma OA2. The proof of part 1 of Lemma OA2 follows directly by inspection of the budget constraint. Expression 2 in part 2 of Lemma OA2 is derived by implicit differentiation of the budget constraint. Part 3 and part 4 of Lemma OA2 follow by inspection of the expression in part 2, and the fact that µ > w 1 α . This concludes the proof of Lemma OA2.

Lemma OA2 implies that µ as a function of x 1 ∈ -C/ b1 , C b1 is U-shaped; the slope is -∞ at x 1 = -C/ b1 and +∞ at x 1 = C/ b1 ; and it reaches a minimum at x 1 = 0.

For w 1 = 0, taking the derivative of the objective function W in expression (OA-2) with respect to x 1 , we obtain:

$dW dx 1 = -2µ =2 w 2 1 b2 1 α 2 (µ -w 1 α ) 3 dµ dx 1 + 2(w 1 + w 2 )α 1 b2 1 (1 + x 1 ) + w 3 √ α 1 b1 .$Plugging in expression for dµ dx 1 in part 2 of Lemma OA2 we obtain that:

$dW dx 1 = -2µ b2 1 x 1 + 2(w 1 + w 2 )α 1 b2 1 (1 + x 1 ) + w 3 √ α 1 b1 .$Part 1 of Lemma OA2 implies that dW dx 1 → ∞ when x 1 → -√ C/ b1 , whereas dW dx 1 → -∞ when x 1 → √ C/ b1 . Hence, the optimal x 1 must be interior, which implies that dW dx 1 = 0 or, equivalently:

$x * 1 = α 1 µ -(w 1 + w 2 )α 1 w 1 + w 2 + w 3 2 √ α 1 b1 . Substituting x * 1 , in the budget constraint =2 b2 w 1 α µ -w 1 α 2 = C(x * 1 ),$we obtain that the Lagrange multiplier µ must solve:

$=2 b2 w 1 α µ -w 1 α 2 + b2 1 α 1 µ -(w 1 + w 2 )α 1 2 w 1 + w 2 + w 3 2 √ α 1 b1 2 = C.$The conclusion for w 1 = 0 are obtained by taking the limits as w 1 → 0 of the expression x * 1 and the expression determining µ. This concludes the proof of part 1 of Theorem OA1.

Part 2. We have already proved that, for all ≥ 2, x * > 0 if and only if w 1 > 0. We now claim that x * 1 > 0 if and only if w 1 + w 2 + w 3 2 b1 √ α 1 > 0. Suppose, toward a contradiction, that

x * 1 < 0. Suppose, toward a contradiction, that x * 1 < 0. By inspection of the maximization problem max

$x w 1 =2 α b2 (1 + x ) 2 + K(x 1 ) subject to =2 b2 x 2 ≤ C(x 1 ) note that if w 1 + w 2 + w 3 2 b1 √ α 1$> 0 and x * 1 < 0, then, by flipping the sign of x * 1 , K(x 1 ) increases and the constraint is unaltered; this is a contradiction to our initial assumption that x * 1 was optimal.

We have just established that x * 1 > 0. Now, by (OA3.1) above, x * 1 > 0 if and only if

$w 1 + w 2 + w 3 2 b1$√ α 1 > 0. And since

$x * 1 = α 1 µ -(w 1 + w 2 )α 1 w 1 + w 2 + w 3 2 √ α 1 b1$it follows that µ > α 1 (w 1 + w 2 ). Finally, if the game has strategic complements then

$α 2 > • • • > α n and so |x * 2 | > |x * 3 | > • • • > |x * n |$, and if the game has strategic substitutes then

$α 2 < • • • < α n and so |x * 2 | < |x * 3 | < • • • < |x * n |.$Part 3. This follows by using the characterization in part 1 and by noticing that if C → 0 then µ → ∞. Part 4 and Part 5. Both parts follow by using the characterization together with the following fact, which we will now establish. lim C→∞ µ = max{w 1 max{α 2 , α n }, (w 1 + w 2 )α 1 }.

To show this, recall from above that we have the following equation for the Lagrange multiplier:

$=2 b2 w 1 α µ -w 1 α 2 + b2 1 α 1 µ -(w 1 + w 2 )α 1 2 w 1 + w 2 + w 3 2 √ α 1 b1 2 = C$If C tends to ∞ it must be that either the first denominator (µw 1 α ) or the second denominator (µ -(w 1 + w 2 )α 1 ) tends to zero. Concerning the first one, this is true if either w 1 α 2 or w 1 α n (depending on which one is positive) approaches µ. The second denominator tends to 0 if (w 1 + w 2 )α 1 tends to µ. Both denominators are positive by definition of the Lagrange multiplier, so it will be the greater of w 1 max{α 2 , α n } and (w 1 + w 2 )α 1 which tends to µ. This concludes the proof of Theorem OA1.

A special case of Theorem OA1 is one where the planner wants to maximize the sum of equilibrium actions. This occurs when w 1 = w 2 = 0. In this case we obtain Corollary OA1. Suppose Assumption 1, 2 and OA1 hold. Suppose that w 1 = w 2 = 0 and w 3 > 0, i.e., the planner wants to maximize the sum of equilibrium actions. Then the optimal intervention is b

$* = b + u 1 √ C.$Remark OA1. Suppose w 1 < 0 and =2 b 2 < C, in contrast to what was assumed in the theorem. If x 1 is sufficiently small, the solution in Step 1 in the proof of Theorem OA1 entails x = -1 for all ≥ 2. That is, fixing x 1 , the bliss point can be achieved with the remaining budget after the cost of implementing x 1 , namely C(x 1 ), is paid. Thus, when we move to Step 2 and optimize over x 1 , we need to take into account that, for small values of x 1 , Step 1 yields a corner solution. Hence, the analysis of how the network multiplier changes when x 1 changes will need to be adapted accordingly.

## Example OA1, continued. Social interaction and peer effects

We conclude this section by applying Theorem OA1 to Example OA1 from Online Appendix Section OA3.1. In this example w 1 = 1, w 2 = 0 and w 3 = -γ √ n(n -1).

Corollary OA2. The optimal intervention in Example OA1 is characterized by

$x * 1 = α 1 µ -α 1 1 -γ √ n(n -1) 2 √ α 1 b1$and, for all ≥ 2:

x * = α µα where the Lagrange multiplier µ solves

$=2 b2 α µ -α 2 + b2 1 α 1 µ -α 1 2 1 -γ √ n(n -1) 2 √ α 1 b1 2 = C.$Corollary OA3. Consider the optimal intervention in Example OA1. It has the following properties.

1.

$x * 2 > • • • > x * n > 0; x * 1 > 0 if and only γ < 2 √ α 1 b1 √ n(n-1) 2. If C → 0 x * x * → α α , for all , = 1 x * 1 x * → α 1 α 1 -γ √ n(n -1) 2 √ α 1 b1 , for all = 1 3. If C → ∞ then |x * 1 | → ∞ and x * → α (α 1 -α ) for all ≥ 2.$OA3.2. Beyond symmetric and non-negative G. In this subsection we relax the assumption that G is symmetric. Recall that equilibrium actions are determined by:

$a * = [I -βG] -1 b.$When G is not symmetric, we employ the singular value decomposition (SVD) of the matrix M = I -βG. This allows us to obtain an orthogonal decomposition of an intervention useful for examining welfare, analogous to the diagonalization. An SVD of M is defined to be a tuple (U , S, V ) satisfying: M = U SV T , (OA-2) where:

(1) U is an orthogonal n × n matrix whose columns are eigenvectors of M M T ;

(2) V is an orthogonal n × n matrix whose columns are eigenvectors of M T M ;

(3) S is an n × n matrix with all off-diagonal entries equal to zero and nonnegative diagonal entries S ll = s l , which are called singular values of M . As a convention, we order the singular values so that s > s +1 .

It is a standard fact that an SVD exists.[foot_22](#foot_22) For expositions of the SVD, see [Golub and Van Loan (1996)](#b44) and [Horn and Johnson (2012)](#b45). The th left singular vector of M corresponds to the th principal component of M . When G is symmetric, the SVD of M = I -βG can be taken to have U = V , and the SVD basis is one in which G is diagonal. Let a = V T a and b = U T b; then the equilibrium condition implies that:

$a * = 1 s b 2 ,$and therefore the objective function is:

$W (b, G) = w (a * ) T a * = wa * T a * .$It is now apparent that the analysis of the optimal intervention can be carried out in the same way as in Section 4. Theorem 1 applies, with the only difference that now α = 1/s 2 . We can also extend Proposition 1 and Proposition 2. As the budget tends to 0, r * /r * tends to α /α ; on the other hand, when C is very large, the optimal intervention is proportional to the first principal component of M , and a simple intervention that focuses on the first principal component performs (nearly) as well as the optimal intervention. When G is symmetric, the nature of strategic interactions (determined by β) pins down the principal component that most amplifies an intervention. If G is non-symmetric, the singular values s l of M are not equal to 1βλ l , where λ l are the eigenvalues of G; the singular vectors of M are not the eigenvectors of G; and the left and right singular vectors need not be the same.

OA3.3. More general costs of intervention. In Section 4 we solved the optimal intervention problem under a specific cost function. This section discusses some natural properties on a cost function. We then show that our analysis of the optimal intervention extends to the general class of cost functions defined by these properties, as long as the budget is small. We begin by developing properties that a reasonable cost function (b, b) → K(b; b) must satisfy.

## Assumption OA2.

(1) Translation-invariance: For any z ∈ R n , we have

$K(b + z; b + ẑ) = K(b; b), that is., there is a function κ : R n → R such that K(b; b) = κ(b -b).$(2) Symmetry: For any permutation σ of {1, . . . , n}, it is true that κ(y σ(1) , y σ(2) , . . . , y σ(n) ) = κ(y 1 , y 2 , . . . , y n ). (3) Nonnegativity: κ is nonnegative, and κ(0) = 0. (4) Local separability: ∂ 2 κ(y) ∂y i ∂y j = 0 evaluated at 0. (5) Well-behaved second derivative at 0: κ is twice differentiable with ∂ 2 κ ∂y 2 i (0) > 0 for all i.

Translational invariance says that there is no dependence on the starting point. Symmetry across players implies that names don't matter for costs. Nonnegativity implies that the planner cannot extract money from the system: κ(0) = 0 is the definition of the status quo b: it does not cost anything to enact b. Local separability across individuals requires that there are no spillovers in the costs of interventions. This is reasonable, as it ensures that the complementarities we study come from the benefits side and not from the costs of interventions. Finally, the twice-differentiability of the function is a technical assumption to facilitate the analysis, while the positive value of the second derivative at 0 rules out cost functions such as κ(y) = i y 4 i in which the increase in marginal costs at 0 is too slow. Consider a cost function that satisfies Assumption OA2: κ(y) = i κ(y i ), where κ(y) = y 2 +cy 3 e y +c y 4 , with c and c being arbitrary constants. Our main result is that the structure of interventions identified in Section 3.1 carries over to such cost functions as long as the budget is small. Proposition OA1. Consider the intervention problem (IT) with the modification that the cost function satisfies Assumption OA2. Suppose Assumptions 1 and 2 hold and the network game satisfies Property A. At the optimal intervention, if C → 0 we have r * r * → α α . Proof of Proposition OA1. First, we state and prove a lemma. Lemma OA3. Under the conditions of Assumption OA2, on any compact set the function C -1 κ(C 1/2 z) converges uniformly to k z 2 , as C ↓ 0, where k > 0 is some constant. We call the limit G.

Proof. Consider the Taylor expansion of κ around 0 (κ is defined by part (1) of the assumption). We will now study its properties under parts (2) to (5) of Assumption OA2.

(5) ensures that the Taylor expansion exists. Local separability (4) says that there are no terms of the form y i y j . Non-negativity (3) (κ is nonnegative and κ(0) = 0) implies that all first-order terms are zero. Also, (5) says that terms of the form y 2 i must have positive coefficients, and symmetry (2) says that their coefficients must all be the same. We maintain, but do not explicitly write, that welfare is evaluated at a * (y), where a * = [I -βG] -1 ( b + y).

Let y(C) be the solution of problem IT(C), which is unique for small enough C. Then we claim that, as C ↓ 0, we have r

$* r * → α α ,$where the similarity ratios are defined at the optimum y(C).

We will prove the result by studying an equivalent problem using Berge's Theorem of the Maximum. Let y = C -1/2 y. We will now define a re-scaled version of the problem, Ǐ T(C).

$max b C -1 ∆(C 1/2 y) ( Ǐ T(C)) s.t. C -1 κ(C 1/2 y) ≤ 1.$This is clearly equivalent to the original problem. Let y * (C) be the (possibly set-valued) solution for C.

The problem Ǐ T(C) is not yet defined at C = 0, but we now define it there. Let the objective at C = 0 be the limit of C -1 ∆(C 1/2 y) as C ↓ 0, which we call F . Let the constraint be G( y) ≤ 1, where G is from Lemma OA3.

Let us restrict Ǐ T(C) to a compact set K such that the constraint set {y : C -1 κ(C 1/2 y) ≤ 1} is contained in K for all small enough C. Now we claim that the conditions of Berge's Theorem of the Maximum are satisfied: The constraint correspondence is continuous at C = 0 because C -1 κ(C 1/2 y) converges uniformly to G, while the objective function is jointly continuous in its two arguments.

The Theorem of the Maximum therefore implies that the maximized value is continuous at C = 0. Because the convergence of the objective is actually uniform on K by the Lemma, this is possible if and only if y approaches the solution of the problem max b F ( y) s.t. y 2 ≤ 1.

By the same argument, the same point is the limit of the solutions to

$max b C -1 ∆(C 1/2 y) s.t. y 2 ≤ 1.$By Proposition 1, in that limit this satisfies

$r * r * → α α .$We next impose an additional restriction on the structure of the costs of intervention and we show that this new restriction together with Assumption OA2 fully characterizes the cost functions that we used in our main analysis.

Assumption OA3. There is a function f : R + → R + so that κ(sy) = f (s)κ(y).

Proposition OA2. Consider a cost function that satisfies Assumptions OA2 and OA3. There is a function f : R + → R + such that κ(y) = f ( y ).

Proposition OA2 implies that the cost of intervention y is the same as the cost of an intervention obtained as an orthogonal transformation of y; that is κ(y) = κ(Oy) with O be an orthogonal matrix. This allows to rewrite the intervention problem using the orthogonal decomposition of welfare and costs that we employ in Section 4, and all the results developed there extend to this more general environment.

We conclude by taking up the implication of linear costs of intervention. The main result is that with a linear cost function, that is, K(b, b) = i |b i -bi |, the optimal intervention will target a single individual. For ease of exposition, we will restrict attention to Example 1. The analysis can be easily extended to general network games.

We consider the following intervention problem: We now characterize the optimal target for the case of strategic complements, i.e., β > 0. Remark OA2 explains how to extend the analysis for the case of strategic substitutes.

In the case of strategic complements, it is clear that the planner uses all the budget C to increase the standalone marginal benefit of i * , i.e., b * i = bi + C; reducing someone's effort can never help. Thus, the planner changes the status quo b into b = b + C1 i * where 1 i * is a vector of 0 except for entry i * that takes value 1. Let a(1 i ) be the Nash equilibrium when all individuals have b j = 0 and b i = 1, i.e., a(1 i ) = [I -βG] -1 1 i . It is easy to verify that the solution to problem IT-Linear Cost is:

$i * = argmax i a( b + C1 i ) T a( b + C1 i ) -a( b) T a( b) . This is equivalent to i * = argmax i C a(1 i ) 2 a( b) ρ(a(1 i ), a( b)) + C a(1 i ) . (OA-3)$where recall that ρ(a(1 i ), a( b)) is the cosine similarity between vectors a(1 i ) and a( b). There are two characteristics of a player that determines whether the player is a good target. The first characteristic is a(1 i ) . This is the square root of the aggregate equilibrium utility in the game with b = 1 i , i.e., the squared root of a(1 i ) T a(1 i ). So, a player with a high a(1 i ) is a player who induces a large welfare in the game in which he is the only player with positive standalone marginal benefit. We call this the welfare centrality of an individual. It is convenient to express the welfare centrality of individual i in terms of principal components of G. Note that

$a(1 i ) = a(1 i ) = α (u i ) 2 .$Recall that under strategic complement α 1 > α 2 > .. > α n and so an individual with a high welfare centrality is one that is highly represented in the main principal components of the network.

The second factor is ρ(a(1 i ), a( b)). This measures the vector similarity between (i) the equilibrium action profile in the game with b = 1 i ; and (ii) the status quo equilibrium action profile. A player with a large ρ(a(1 i ), a( b)) is a player that, in the game in which he is the 8 Formally, for some z > 0 there is a linear map ϕ : [-z, z] → F such that ϕ(0) = b * . only player with positive standalone marginal benefit, leads a distribution of effort similar to the distribution of effort in the status quo. Small C. Suppose C ≈ 0. Then the optimal target is selected based on the first term of expression (OA-3); that is:

$i * = argmax i a(1 i ) ρ(a(1 i ), a( b))$For small budgets, the optimal intervention focuses on the player who has a large welfare centrality and that, at the same time, leads to a distribution of effort not too different from the status quo equilibrium effort. Large C: For C sufficiently large, the last term of expression (OA-3) dominates and therefore the player that is targeted is the player with the highest welfare centrality.

Remark OA2 (Extension to the case of strategic substitutes). In the case of strategic substitutes, we know for the targeted player i * , b * i * = bi ± C, but we cannot say, a priori, which (positive or negative), and indeed it is easy to provide examples that both can happen. Under this qualification, the analysis developed for the case of strategic complements extends OA3.4. Intervention through monetary incentives. In the basic model presented in Section 2, an intervention alters incentives for individual action through a direct change in marginal benefits/marginal costs. The convexity in the cost of changing these marginal benefits plays a key role in the analysis. In this section we provide a demonstration of how our approach can be applied beyond this cost setting. We do this by using our methods to solve the problem of offering monetary incentives to individuals for choosing between two actions.

Let us reinterpret a node i as a population; thus N = {1, 2, . . . , n} is the set of populations. Within population i, there is a continuum of individuals distributed uniformly in I = [0, τ ]. Each individual in population i chooses whether to take action 1 or to take action 0. A strategy of an individual in population i is a function q i : [0, τ ] → [0, 1] that describes the probability that an individual of type τ i ∈ [0, τ ] chooses action 1. Without loss of generality, we focus on equilibria in which all the players within a population have the same strategy.

The payoff to an individual who chooses action 0 is normalized to 0. If individual τ i takes action 1, then he incurs a cost τ i and gets a benefit that depends on his population's standalone marginal benefit of action 1, b i , and the number of other individuals he meets who have also taken action 1. We assume that the interaction between populations takes the form of random matching, with the following specification: An individual τ i in population i meets someone from population j with probability g ij , and, within population j, τ i meets an individual selected uniformly at random. Suppose τ i meets type τ j , and let q j be the strategy of individuals in population j. Then individual τ i 's payoff for the interaction with the random partner τ j is βq j (τ j ) + b iτ i .

In this expression, βq j (τ j ) represents the payoffs from interacting with peers that have also taken action 1.

First, we show that the conditions for an equilibrium are isomorphic to those of the games we studied in Section 3.1. It is immediate to see that the best reply of each individual in population i is a cutoff strategy: there exists a cutoff a i ∈ I so that q(τ i ) = 1 for all τ i ≤ a i and q(τ i ) = 0 otherwise. The equilibrium condition for these cutoffs is that, for all i ∈ N ,

$β j g ij P [τ j ≤ a * j ] + b i -a * i = 0 ⇐⇒ a i = b i + β τ j g ij a * j .$Denoting by β = β/τ , the equilibrium threshold profile a * solves [I -βG]a * = b.

The equilibrium expected payoff to group i is:

$U i (a * , b) = a * i 0 β j g ij a * j + b i -τ i dτ i = a * i 0 (a * i -τ i ) dτ i = 1 2 a * 2 i ,$where the second equality follows by using the best response of each population. So aggregate equilibrium utility is

$W (b, G) = 1 2 (a * ) T a * .$Suppose the planner, before the players choose their action, commits to the a subsidy scheme. The subsidy scheme depends on realized actions, which are taken after the scheme is announced. More precisely, the planner selects a vector y ∈ R n and offers the following scheme: Subsidizing action 1. If y i > 0 then the planner gives a subsidy of s 1 i (τ i ) = τ i -[a i (y)y i ] to all population i's types τ i ∈ [a i (y)y i , a i (y)] who take action 1. Subsidizing action 0. If y i < 0 then the planner gives a subsidy of s 0 i (τ i ) = [a i (y)+|y i |]-τ i to all τ i ∈ [a i (y), a i (y) + |y i |] who do not adopt the new technology (take action 0).

We make three observations. First, under intervention y the profile of thresholds a(y) is a Nash equilibrium. Furthermore, the planner does not waste resources in the sense that she uses the minimum amount of resources to implement a(y). To see this note that, by construction, the planner provides monetary payments to take action 1 or to take action 0 only to types who need such transfers to satisfy their incentive compatibility constraint. The monetary payments make these incentive compatible constrains just bind. Finally, let 1 y i >0 be an indicator function that takes value 1 if y i > 0 and 0 otherwise, then note that the cost of intervention y is

$K(y) = 1 2 i 1 y i >0 a i (y) a i (y)-y i s 1 i (τ i )dτ i + i (1 -1 y i >0 ) a i (y)+|y i | a i (y) s 0 i (τ i )dτ i = 1 2 i y 2 i$We then consider a planner who intervenes in the system. The planner has complete information about the type of each individual in each population and can subsidize types to take action 1 or to take action 0, in a perfectly targeted manner. In doing this, the planner effectively shifts the b i of some individuals in some populations. The cheapest individuals to influence are those who are close to being indifferent between the two actions, so that they do not need to be paid very much to change their behavior. Indeed, the payment to an individual is proportional to his distance x from the marginal type in equilibrium: Integrating across all the individuals whose actions are changed gives y i 0 x dx, a cost that is quadratic in the magnitude of the change. The intervention problem turns out to be mathematically equivalent to (IT), and so all our results apply.

We can now define the intervention problem of the planner as follows. Starting from the status quo b, the planner chooses intervention y to maximize aggregate equilibrium utility under the constraint that individuals play according to equilibrium and that the cost of the intervention cannot exceed C. Formally, 

$K(y) = 1 2 i y 2 i ≤ C,$Intervention problem (IT-P) is equivalent to the intervention problem (IT) defined in Section 2.

Note that the specific payoff functions we have taken here make the problem isomorphic to the setting of Example 1, but by suitably modifying the payoffs, we could capture more general externalities, along the lines of Online Appendix Section OA3.1.

We focus throughout on maximizing aggregate utility, but we note that the results have applications to other kinds of objectives, such as implementing Pareto improvements. In some cases, interventions will make everyone better off without modification, when positive externalities are strong enough to overcome any negative welfare impacts. However, even when this is not the case, the planner may be able to achieve Pareto improvements. For example, consider a planner who is able to make lump sum transfers -e.g., award or take away discretionary compensation -in addition to any targeted incentives or contingent payments. In such cases, if an improvement in aggregate utility is possible, then the planner can use such transfers to compensate individuals (for instance, those harmed by negative externalities), and achieve a Pareto improvement. In the setting discussed in this subsection, combining lump-sum and action-contingent transfers would then implement a range of Pareto improvements. Even beyond the monetary-incentives setting under consideration here, lump sum transfers may be available to the planner in addition to whatever incentive-targeting scheme is being used, and in such a setting our comments here would apply also.

![Figure 1. (Top) Eigenvectors 2, 4, 6. (Bottom) Eigenvectors 10, 12, 14.]()

![Figure 2. Optimal targets with large budgets]()

![Recall that1 n b 2 is equal to the sum of 1 n i bi 2 (the squared mean of the entries of b) and the sum of squared deviations of the entries of the vector b from their mean.]()

![Figure 3. Spectral gap, bottom gap, and optimal interventions]()

![) and Figure4(D).]()

![Suppose the planner likes variance (i.e., w > 0). If the game has strategic complements (β > 0), then Var(u (G) • b * ) is weakly decreasing in ; if the game has strategic substitutes (β < 0), then Var(u (G) • b * ) is weakly increasing in . 2. Suppose the planner dislikes variance (i.e., w < 0). If the game has strategic complements (β > 0), then Var(u (G) • b * ) is weakly increasing in ; if the game has strategic substitutes (β < 0), then Var(u (G) • b * ) is weakly decreasing in .]()

![where the last equality follows because, at the optimum, b * -b 2 = C. At the optimal intervention, by Theorem 1, b * -b = wα µwα b ; now, using the definition b = U T b, we have that b]()

![B * * = P Σ B * P T and so Var(b * * k ) = Var(b * k ) for all k ∈ { , } and Var(b * * ) = Var(b * ) > Var(b * * ) = Var(b * ). Since α > α intervention B * * does strictly better than B * , a contradiction to our initial hypothesis that B * was optimal. Date Printed. November 12, 2019.]()

![Write y := b -b. Let ∆(y) denote the change in welfare from the status quo. Fix all parameters of the problem, and recall the main optimization problem:]()

![) T a * (IT-Linear Cost) s.t. a * = [I -βG] -1 b, K(b; b) = i∈N |b i -bi | ≤ C, Proposition OA3. The solution to problem IT-Linear Cost has the property that there exists i * such that b * i = bi * and b * i = bi for al i = i * . Proof of Proposition OA3. Define W (b) = a(b) T a(b). Let F be the set of feasible b, those satisfying the budget constraint K(b; b) ≤ C. Suppose the conclusion does not hold and let b * be the optimum, with W * = W (b * ). Then, because by hypothesis the optimum is not at an extreme point, F contains a line segment L such that b * is in the interior of L. 8Now restrict attention to a plane P containing this L and the origin. Note that L is contained in a convex setE = {b : W (b) ≤ W * }.The point b * is contained in the interior of L; thus b * is in the interior of E. On the other hand, b * must be on the (elliptical) boundary of E because U is strictly increasing in each component (by irreducibility of the network) and continuous. This is a contradiction.]()

![. [I -βG]a = b + y,]()

In similarity terms, this means that the optimal intervention has a cosine similarity of nearly 1 to the first or last principal component (depending on the case), and a similarity of nearly 0 to all other principal components.

We extend our analysis to more general G in the Online Appendix Section OA3.2.

An equivalent condition is for |β| to be less than the reciprocal of the spectral radius of G.

SeeBallester et al. (2006)  andBramoullé et al. (2014)  for detailed discussions of this assumption and the interpretation of the solution given by (3).

This can be taken to be the maximum amount of information available; equilibrium acquisitions will always be less than this.

The circle network is nongeneric in that eigenvectors are not uniquely determined, but an arbitrarily small perturbation of G will select a unique basis very close to the one depicted.

It can be verified that the ratio for every ∈ {1, . . . , n -1}, x /x +1 is increasing (decreasing) in β for the case of strategic complements (substitutes): thus the intensity of the strategic interaction shapes the relative importance of different principal components.

Analogously, when w < 0, wα µ-wα and r * /r * are both decreasing in C.

As costs are quadratic, small relaxation in the budget around zero can have a large impact on aggregate welfare.

When individuals' initial standalone marginal returns are zero ( b = 0), we can dispense with the approxi-

See[Hartfiel and Meyer (1998)](#b25),[Levin et al. (2009)](#b30), and[Golub and Jackson (2012)](#b21) for discussions and further citations to the literature on spectral gaps.

Intuitively, because u n does not correspond to a perfect bipartition, it is easier for a vector orthogonal to u n to achieve a similarly low value of ij g ij u i u j .

It is possible to go further and allow for incomplete information among the individuals about each other's b i . We do not pursue this substantial generalization here; see[Golub and Morris (2017)](#b22) and[Lambert et al. (2018)](#b28) for analyses in this direction.

The domain of this function is the set of all random vectors taking values in R n defined on our probability space.

When we look at the variance-covariance matrix of b defined by b -b = O(b -b), the variance-covariance matrix becomes OΣO T , and this has the same eigenvalues and therefore the same trace.

Note that if Assumption 3 does not hold (that is, w < 0 and b2 ≤ C) then the optimal solution is x * = -1 for all . This is what we ruled out with Assumption 3, before Theorem 1.

For a different economic context in which eigenvector centrality reflects equilibrium outcomes, see also[Elliott and Golub (2018)](#b42).

For stability of equilibrium, what is relevant is the magnitude of the smallest eigenvalue of an appropriately defined subgraph of G.

A similar analysis can be adapted to a standard (local) beauty contest game in whichU i (a, G) = -(a ibi ) 2γ j g ij [a ja i ] 2 .Here, we focus on a modification of the standard beauty contest game that makes the mapping to our formulation easier to present.

In this specification the last (externality) term is a global term. We can easily accommodate local negative externalities by replacing that term with j g ij a j .

We can also accommodate externalities that depend directly on the b i , but we omit this for brevity.

The last equality follows because α 1 = 1/(1βλ 1 ) 2 , and assumption OA1 implies that λ 1 = 1.

The decomposition is uniquely determined up to a permutation that (i) reorders the singular values of M and correspondingly reorders the columns of U and V , and (ii) flips the sign of any column of U and V .

