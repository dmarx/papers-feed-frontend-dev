<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Complex Momentum for Optimization in Games</title>
				<funder>
					<orgName type="full">Province of Ontario</orgName>
				</funder>
				<funder ref="#_DYFKXDk">
					<orgName type="full">NSERC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2021-06-01">1 Jun 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jonathan</forename><surname>Lorraine</surname></persName>
							<email>lorraine@cs.toronto.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Acuna</surname></persName>
							<email>davidj@cs.toronto.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><surname>Vicol</surname></persName>
							<email>pvicol@cs.toronto.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Duvenaud</surname></persName>
							<email>duvenaud@cs.toronto.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Complex Momentum for Optimization in Games</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-06-01">1 Jun 2021</date>
						</imprint>
					</monogr>
					<idno type="MD5">E5403C37E335DC382D946C9C71F0CA81</idno>
					<idno type="arXiv">arXiv:2102.08431v2[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-02-28T01:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We generalize gradient descent with momentum for optimization in differentiable games to have complex-valued momentum. We give theoretical motivation for our method by proving convergence on bilinear zero-sum games for simultaneous and alternating updates. Our method gives real-valued parameter updates, making it a drop-in replacement for standard optimizers. We empirically demonstrate that complex-valued momentum can improve convergence in realistic adversarial games-like generative adversarial networks-by showing we can find better solutions with an almost identical computational cost. We also show a practical generalization to a complex-valued Adam variant, which we use to train BigGAN to better inception scores on CIFAR-10.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Gradient-based optimization has been critical for the success of machine learning, updating a single set of parameters to minimize a single loss. A growing number of applications require learning in games, which generalize single-objective optimization. Common examples are GANs <ref type="bibr" target="#b0">[1]</ref>, actor-critic models <ref type="bibr" target="#b1">[2]</ref>, curriculum learning <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref>, hyperparameter optimization <ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref>, adversarial examples <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>, learning models <ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref>, domain adversarial adaptation <ref type="bibr" target="#b14">[15]</ref>, neural architecture search <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>, and meta-learning <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>.</p><p>Games consist of multiple players, each with parameters and objectives. We often want solutions where no player gains from changing their strategy unilaterally, e.g., Nash equilibria <ref type="bibr" target="#b19">[20]</ref> or Stackelberg equilibria <ref type="bibr" target="#b20">[21]</ref>. Classical gradient-based learning often fails to find these equilibria due to rotational dynamics <ref type="bibr" target="#b21">[22]</ref>. Numerous saddle point finding algorithms for zero-sum games have been proposed <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>. <ref type="bibr" target="#b24">[25]</ref> generalizes GD with momentum to games, showing we can use a negative momentum to converge if the eigenvalues of the Jacobian of the gradient vector field have a large imaginary part. We use the terminology in <ref type="bibr" target="#b24">[25]</ref> and say (purely) cooperative or adversarial games for games with (purely) real or imaginary eigenvalues. Setups like GANs are not purely adversarial, but rather have both purely cooperative and adversarial eigenspaces -i.e., eigenspaces with purely real or imaginary eigenvalues. In cooperative eigenspaces, the players do not interfere with each other.</p><p>We want solutions that converge with simultaneous and alternating updates in purely adversarial games -a setup where existing momentum methods fail. Also, we want solutions that are robust to different mixtures of adversarial and cooperative eigenspaces, because this depends on the games eigendecomposition which can be intractable. To solve this we unify and generalize existing momentum methods <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b24">25]</ref> to recurrently linked momentum -a setup with multiple recurrently linked momentum buffers with potentially negative coefficients shown in Figure <ref type="figure" target="#fig_5">2c</ref>.</p><p>We show that selecting two of these recurrently linked buffers with appropriate momentum coefficients can be interpreted as the real and imaginary parts of a single complex buffer and complex momentum coefficient -see Figure <ref type="figure" target="#fig_5">2d</ref>. This setup (a) allows us to converge in adversarial games with simultaneous updates, (b) only introduces one new optimizer parameter -the phase or arg of our momentum, (c) allows us to gain intuitions via complex analysis, (d) is trivial to implement in libraries supporting complex arithmetic, and (e) robustly converges for different eigenspace mixtures.</p><p>Intuitively, our complex buffer stores historical gradient information, oscillating between adding or subtracting at a frequency dictated by the momentum coefficient. Classical momentum only adds gradients, and negative momentum changes between adding or subtracting each iteration, while we oscillate at an arbitrary (fixed) frequency -see Figure <ref type="figure" target="#fig_2">4a</ref>. This reduces rotational dynamics during training by canceling out opposing updates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contributions</head><p>• We provide generalizations and variants of classical <ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref>, negative <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b29">30]</ref>, and aggregated <ref type="bibr" target="#b25">[26]</ref> momentum for learning in differentiable games. • We show our methods converges on adversarial games -including bilinear zero-sum games and the Dirac-GAN -with simultaneous and alternating updates. • We illustrate a robustness during optimization, converging faster and over a larger range of mixtures of cooperative and adversarial games than existing first-order methods. • We give a practical extension of our method to a complex-valued Adam <ref type="bibr" target="#b30">[31]</ref> variant, which we use to train a BigGAN <ref type="bibr" target="#b31">[32]</ref> on CIFAR-10, improving <ref type="bibr" target="#b31">[32]</ref>'s inception scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Actual JAX implementation: changes in green mass = .8 + .3j def momentum ( step_size, mass ): ... def update ( i, g, state ):</p><p>x, velocity = state velocity = mass * velocity + g x =x -jnp.real ( step_size ( i )* velocity ) return x, velocity ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1:</head><p>How to modify JAX's SGD with momentum here to use complex momentum. The only changes are in green. jnp.real gets the real part of step_size times the momentum buffer (called velocity here). We use a complex mass for our method in this case β " |β| exppi argpβqq " 0.9 exppi π {8q « .8 `.3i.</p><p>Appendix Table <ref type="table">2</ref> summarizes our notation. Consider the optimization problem: θ ˚:" arg min θ Lpθq (1) We can find local minima of loss L using (stochastic) gradient descent with step size α. We denote the loss gradient at parameters θ j by g j :"gpθ j q:"∇ θ Lpθq| θ j .</p><p>θ j`1 " θ j ´αg j (SGD) Momentum can generalize SGD. For example, Polyak's Heavy Ball <ref type="bibr" target="#b26">[27]</ref>:</p><p>θ j`1 " θ j ´αg j `βpθ j ´θj´1 q (2) Which can be equivalently written with momentum buffer µ j " pθ j ´θj´1 q {α. µ j`1 " βµ j ´gj , θ j`1 " θ j `αµ j`1 (SGDm) We can also generalize SGDm to aggregated momentum <ref type="bibr" target="#b25">[26]</ref>, shown in Appendix Algorithm 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Game Formulations</head><p>Another class of problems is learning in games, which includes problems like generative adversarial networks (GANs) <ref type="bibr" target="#b0">[1]</ref>. We focus on 2-player games -with players denoted by A and B-where each player minimizes their loss L A , L B with their parameters θ A P R d A , θ B P R d B . Solutions to 2-player games -which are assumed unique for simplicity -can be defined as:</p><formula xml:id="formula_0">θ Å :" arg min θ A L A pθ A ,θ B q, θ B :" arg min θ B L B pθ Å ,θ B q<label>(3</label></formula><p>) In deep learning, losses are non-convex with many parameters, so we often focus on finding local solutions. If we have a player ordering, then we have a Stackelberg game. For example, in GANs, the generator is the leader, and the discriminator is the follower. In hyperparameter optimization, the hyperparameters are the leader, and the network parameters are the follower. If θ B pθ A q denotes player B's best-response function, then Stackelberg game solutions can be defined as:</p><formula xml:id="formula_1">θ A ˚:" arg min θ A L A pθ A ,θ B pθ A qq, θ B pθ A q :" arg min θ B L B pθ A ,θ B q<label>(4</label></formula><p>) If L A and L B are differentiable in θ A and θ B we say the game is differentiable. We may be able to approximately find θ Å efficiently if we can do SGD on:</p><formula xml:id="formula_2">L Å pθ A q :" L A pθ A , θ B pθ A qq<label>(5)</label></formula><p>Unfortunately, SGD would require computing dL Å{dθ A , which often requires dθ B{dθ A , but θ B pθ A q and its Jacobian are typically intractable. A common optimization algorithm to analyze for finding solutions is simultaneous SGD (SimSGD) -sometimes called gradient descent ascent for zero-sum gameswhere g j A :" g A pθ j A , θ j B q and g j B :" g B pθ j A , θ j B q are estimators for</p><formula xml:id="formula_3">∇ θ A L A | θ j A ,θ j B and ∇ θ B L B | θ j A ,θ j B : θ j`1 A " θ j A ´αg j A , θ j`1 B " θ j B ´αg j B (SimSGD)</formula><p>We simplify notation with the concatenated or joint-parameters ω :" rθ A , θ B s P R d and the jointgradient vector field ĝ : R d Ñ R d , which at the j th iteration is the joint-gradient denoted: ĝj :" ĝpω j q :" rg A pω j q, g B pω j qs " rg j A , g j B s (6) We extend to n-player games by treating ω and ĝ as concatenations of the players' parameters and loss gradients, allowing for a concise expression of the SimSGD update with momentum (SimSGDm): µ j`1 " βµ j ´ĝ j , ω j`1 " ω j `αµ j`1 (SimSGDm) <ref type="bibr" target="#b24">[25]</ref> show classical momentum choices of β P r0, 1q do not improve solution speed over SimSGD in some games, while negative momentum helps if the Jacobian of the joint-gradient vector field ∇ ω ĝ has complex eigenvalues. Thus, for purely adversarial games with imaginary eigenvalues, any non-negative momentum and step size will not converge. For cooperative games -i.e., minimization -∇ ω ĝ has strictly real eigenvalues because it is a losses Hessian, so classical momentum works well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Limitations of Existing Methods</head><p>Higher-order: Methods using higher-order gradients are often harder to parallelize across GPUs, <ref type="bibr" target="#b32">[33]</ref>, get attracted to bad saddle points <ref type="bibr" target="#b33">[34]</ref>, require estimators for inverse Hessians <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36]</ref>, are complicated to implement, have numerous optimizer parameters, and can be more expensive in iteration and memory cost <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref><ref type="bibr" target="#b39">[40]</ref>. Instead, we focus on first-order methods.</p><p>First-order: Some first-order methods such as extragradient <ref type="bibr" target="#b40">[41]</ref> require a second, costly, gradient evaluation per step. Similarly, methods alternating player updates are bottlenecked by waiting until after the first player's gradient is used to evaluate the second player's gradient. But, many deep learning setups can parallelize computation of both players' gradients, making alternating updates effectively cost another gradient evaluation. We want a method which updates with the effective cost of one gradient evaluation. Also, simultaneous updates are a standard choice in some settings <ref type="bibr" target="#b14">[15]</ref>.</p><p>Robust convergence: We want our method to converge in purely adversarial game's with simultaneous updates -a setup where existing momentum methods fail <ref type="bibr" target="#b24">[25]</ref>. Furthermore, computing a games eigendecomposition is often infeasibly expensive, so we want methods that robustly converge over different mixtures of adversarial and cooperative eigenspaces. We are particularly interested in eigenspace mixtures that that are relevant during GAN training -see Figure <ref type="figure">7</ref> and Appendix Figure <ref type="figure" target="#fig_9">9</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Coming up with our Method</head><p>Combining existing methods: Given the preceding limitations, we would like a robust first-order method using a single, simultaneous gradient evaluation. We looked at combining aggregated <ref type="bibr" target="#b25">[26]</ref> with negative <ref type="bibr" target="#b24">[25]</ref> momentum by allowing negative coefficients, because these methods are firstorder and use a single gradient evaluation -see Figure <ref type="figure" target="#fig_5">2b</ref>. Also, aggregated momentum provides robustness during optimization by converging quickly on problems with wide range of conditioning, while negative momentum works in adversarial setups. We hoped to combine their benefits, gaining robustness to different mixtures of adversarial and cooperative eigenspaces. However, with this setup we could not find solutions that converge with simultaneous updates in purely adversarial games.</p><p>Generalize to allow solutions: We generalized the setup to allow recurrent connections between momentum buffers, with potentially negative coefficients -see Figure <ref type="figure" target="#fig_5">2c</ref> and Appendix Algorithm 4.</p><p>There are optimizer parameters so this converges with simultaneous updates in purely adversarial games, while being first-order with a single gradient evaluation -see Corollary 1. However, in general, this setup could introduce many optimizer parameters, have unintuitive behavior, and not be amenable to analysis. So, we choose a special case of this method to help solve these problems. Figure <ref type="figure" target="#fig_5">2</ref>: We show computational diagrams for momentum variants simultaneously updating all players parameters, which update the momentum buffers µ at iteration j `1 with coefficient β via µ j`1 " pβµ j ´gradientq. Our parameter update is a linear combination of the momentum buffers weighted by step sizes α. (a) Classical momentum <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b28">29]</ref>, with a single buffer and coefficient β P r0, 1q. (b) Aggregated momentum <ref type="bibr" target="#b25">[26]</ref> which adds multiple buffers with different coefficients.</p><p>(c) Recurrently linked momentum, which adds cross-buffer coefficients and updates the buffers with µ j`1 pkq " p ř l β pl,kq µ j plq ´gradientq. We allow β pl,kq to be negative like negative momentum <ref type="bibr" target="#b24">[25]</ref> for solutions with simultaneous updates in adversarial games. (d) Complex momentum is a special case of recurrently linked momentum with two buffers and β p1,1q " β p2,2q " pβq, β p1,2q " ´βp2,1q " pβq.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analyzing other recurrently linked momentum setups is an open problem.</head><p>A simple solution: With two momentum buffers and correctly chosen recurrent weights, we can interpret our buffers as the real and imaginary part of one complex buffer -see Figure <ref type="figure" target="#fig_5">2d</ref>. This method is (a) capable of converging in purely adversarial games with simultaneous updates -Corollary 1, (b) only introduces one new optimizer parameter -the phase of the momentum coefficient, (c) is tractable to analyze and have intuitions for with Euler's formula -ex., Eq. ( <ref type="formula" target="#formula_6">8</ref>), (d) is trivial to implement in libraries supporting complex arithmetic -see Figure <ref type="figure" target="#fig_8">1</ref>, and (e) can be robust to games with different mixtures of cooperative and adversarial eigenspaces -see Figure <ref type="figure">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Complex Momentum</head><p>We describe our proposed method, where the momentum coefficient β P C, step size α P R, momentum buffer µ P C d , and player parameters ω P R d . The simultaneous (or Jacobi) update is: µ j`1 " βµ j ´ĝ j , ω j`1 " ω j ` pαµ j`1 q (SimCM)</p><p>There are many ways to get a real-valued update from µ P C, but we only consider updates equivalent to classical momentum when β P R. Specifically, we simply update the parameters using the real component of the momentum: pµq.</p><p>Algorithm 1 (SimCM) Momentum</p><p>1: β, α P C, µ P C d , ω 0 P R d 2: for i " 1 . . . N do 3:</p><p>µ j`1 " βµ j ´ĝ j 4:</p><p>ω j`1 " ω j ` pαµ j`1 q return ω N</p><p>We show the SimCM update in Algorithm 1 and visualize it in Figure <ref type="figure" target="#fig_5">2d</ref>. We also show the alternating (or Gauss-Seidel) update, which is common for GAN training:</p><formula xml:id="formula_4">µ j`1</formula><p>A " βµ j A ´ĝ A pω j q, θ j`1 A " θ j A ` pαµ j`1 A q (AltCM)</p><formula xml:id="formula_5">µ j`1 B " βµ j B ´ĝ B pθ j`1 A , θ j B q, θ j`1 B " θ j B ` pαµ j`1 B q</formula><p>Generalizing negative momentum: Consider the negative momentum from <ref type="bibr" target="#b24">[25]</ref>: ω j`1 " ω j άĝ j `βpω j ´ωj´1 q. Expanding (SimCM) with µ j " pω j ´ωj´1 q {α for real momentum shows the negative momentum method of <ref type="bibr" target="#b24">[25]</ref> is a special case of our method: ω j`1 " ω j ` pαpβ pω j ´ωj´1 q {α ´ĝ j qq " ω j ´αĝ j `βpω j ´ωj´1 q (7)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dynamics of Complex Momentum</head><p>For simplicity, we assume Numpy-style <ref type="bibr" target="#b42">[43]</ref> component-wise broadcasting for operations like taking the real-part pzq of vector z " rz 1 , . . . , z n s P C n , with proofs in the Appendix.</p><p>Expanding the buffer updates with the polar components of β gives intuition for complex momentum: µ j`1 " βµ j ´ĝ j ðñ µ j`1 " βpβp¨¨¨q ´ĝ j´1 q ´ĝ j ðñ µ j`1 " ´k"j ÿ k"0 β k ĝj´k ðñ pµ j`1 q " ´k"j ÿ k"0 |β| k cospk argpβqqĝ j´k , pµ j`1 q " ´k"j ÿ k"0</p><formula xml:id="formula_6">|β| k sinpk argpβqqĝ j´k<label>(8)</label></formula><p>The final line is simply by Euler's formula <ref type="bibr" target="#b25">(26)</ref>. From (8) we can see β controls the momentum buffer µ by having |β| dictate prior gradient decay rates, while argpβq controls oscillation frequency between adding and subtracting prior gradients, which we visualize in Figure <ref type="figure" target="#fig_2">4a</ref>.</p><p>Discriminator Generator Norm of joint-gradient }ĝ}  We show the real part of our momentum buffer -which dictates the parameter update -at the 50 th iteration pµ 50 q dependence on past gradients ĝk for k " 1 . . . 50. The momentum magnitude is fixed to |β| " 0.9 as in Figure <ref type="figure" target="#fig_1">3</ref>. Euler's formula is used in <ref type="bibr" target="#b7">(8)</ref> to for finding dependence or coefficient of ĝk via pµ 50 q " ´řk"50 k"0 |β| k cospk argpβqqĝ j´k . Complex momentum allows smooth changes in the buffers dependence on past gradients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Momentum phase argpβq</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Momentum magnitude |β|</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of steps to converge</head><p>Figure <ref type="figure" target="#fig_2">4</ref>(b): How many steps simultaneous complex momentum on a Dirac-GAN takes for a set solution distance. We fix step size α " 0.1 as in Figure <ref type="figure" target="#fig_1">3</ref>, while varying the phase and magnitude of our momentum β " |β| exppi argpβqq. There is a red star at the optima, dashed red lines at real β, and a dashed magenta line for simultaneous gradient descent. There are no real-valued β that converge for this -or any α with simultaneous updates <ref type="bibr" target="#b24">[25]</ref>. Appendix Figure <ref type="figure">8</ref> compares this with alternating updates (AltCM).</p><p>Expanding the parameter updates with the Cartesian components of α and β is key for Theorem 1, which characterizes the convergence rate: µ j`1 " βµ j ´ĝ j ðñ pµ j`1 q " pβq pµ j q´ pβq pµ j q´ pĝ j q, pµ j`1 q " pβq pµ j q` pβq pµ j q (9)</p><p>ω j`1 " ω j ` pαµ j`1 q ðñ ω j`1 " ω j ´αĝ j ` pαβq pµ j q´ pαβq pµ j q (10)</p><p>So, we can write the next iterate with a fixed-point operator: r pµ j`1 q, pµ j`1 q,ω j`1 s" F α,β pr pµ j q, pµ j q,ω j sq (11) ( <ref type="formula">9</ref>) and ( <ref type="formula">10</ref>) allow us to write the Jacobian of F α,β which can be used to bound convergence rates near fixed points, which we name the Jacobian of the augmented dynamics of buffer µ and joint-parameters ω and denote with:</p><formula xml:id="formula_7">R :" ∇ rµ,ωs F α,β " « pβqI ´ pβqI ´∇ω ĝ pβqI pβqI 0 pαβqI ´ pαβqI I ´α∇ ω ĝff<label>(12)</label></formula><p>So, for quadratic losses our parameters evolve via: r pµ j`1 q, pµ j`1 q,ω j`1 s J " R r pµ j q, pµ j q,ω j s J</p><p>We can bound convergence rates by looking at the spectrum of R with Theorem 1.</p><p>Theorem 1 (Consequence of Prop. 4.4.1 <ref type="bibr" target="#b43">[44]</ref>). Convergence rate of complex momentum: If the spectral radius ρpRq " ρp∇ rµ,ωs F α,β q ă 1, then, for rµ, ωs in a neighborhood of rµ ˚, ω ˚s, the distance of rµ j , ω j s to the stationary point rµ ˚, ω ˚s converges at a linear rate OppρpRq` q j q, @ ą 0.</p><p>Here, linear convergence means lim jÑ8 }ω j`1 ´ω˚} {}ω j ´ω˚} P p0, 1q, where ω ˚is a fixed point. We should select optimization parameters α, β so that the augmented dynamics spectral radius SppRpα, βqq ă 1-with the dependence on α and β now explicit. We may want to express SppRpα, βqq in terms of the spectrum Spp∇ ω ĝq, as in Theorem 3 in <ref type="bibr" target="#b24">[25]</ref>:</p><formula xml:id="formula_9">f pSpp∇ ω ĝq, α, βq " SppRpα, βqq<label>(14)</label></formula><p>We provide a Mathematica command in Appendix A.2 for a cubic polynomial p characterizing f with coefficients that are functions of α, β &amp; λ P Spp∇ ω ĝq, whose roots are eigenvalues of R, which we use in subsequent results. <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b25">26]</ref> mention that in practice we do not know the condition number, eigenvalues -or the mixture of cooperative and adversarial eigenspaces -of a set of functions that we are optimizing, so we try to design algorithms which work over a large range. Sharing this motivation, we consider convergence behavior on games ranging from purely adversarial to cooperative.</p><p>In Section 4.2 at every non-real β we could select α and |β| so Algorithm 1 converges. We define almost-positive to mean argpβq " for small , and show there are almost-positive β which converge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corollary 1 (Convergence of Complex Momentum).</head><p>There exist α P R, β P C so Algorithm 1 converges for bilinear zero-sum games. More-so, for small (we show for " π 16 ), if argpβq " (i.e., almost-positive) or argpβq " π ´ (i.e., almost-negative), then we can select α, |β| to converge.</p><p>Why show this? Our result complements <ref type="bibr" target="#b24">[25]</ref> who show that for all real α, β Algorithm 1 does not converge. We include the proof for bilinear zero-sum games, but the result generalizes to some games that are purely adversarial near fixed points, like Dirac GANs <ref type="bibr" target="#b33">[34]</ref>. The result's second part shows evidence there is a sense in which the only β that do not converge are real (with simultaneous updates on purely adversarial games). It also suggests a form of robustness, because almost-positive β can approach acceleration in cooperative eigenspaces, while converging in adversarial eigenspaces, so almost-positive β may be desirable when we have games with an uncertain or variable mixtures of real and imaginary eigenvalues like GANs. Sections 4.2, 4.3, and 4.4 investigate this further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">What about Acceleration?</head><p>With classical momentum, finding the step size α and momentum β to optimize the convergence rate tractable if 0 ă l ď L and Spp∇ ω ĝq P rl, Ls d [46] -i.e., we have an l-strongly convex and L-Lipschitz loss. The conditioning κ " L {l can characterize problem difficulty. Gradient descent with an appropriate α can achieve a convergence rate of κ´1 κ`1 , but using momentum with appropriate pα ˚, β ˚q can achieve an accelerated rate of ρ ˚" ? κ´1 ? κ`1 . However, there is no consensus for constraining Spp∇ ω ĝq in games for tractable and useful results. Candidate constraints include monotonic vector fields generalizing notions of convexity, or vector fields with bounded eigenvalue norms capturing a kind of sensitivity <ref type="bibr" target="#b46">[47]</ref>. Figure <ref type="figure">7</ref> shows Spp∇ ω ĝq for a GAN -we can attribute some eigenvectors to a single player's parameters. The discriminator can be responsible for the largest and smallest norm eigenvalues, suggesting we may benefit from varying α and β for each player as done in Section 4.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Implementing Complex Momentum</head><p>Complex momentum is trivial to implement with libraries supporting complex arithmetic like JAX <ref type="bibr" target="#b47">[48]</ref> or Pytorch <ref type="bibr" target="#b48">[49]</ref>. Given an SGD implementation, we often only need to change a few lines of code -see Figure <ref type="figure" target="#fig_8">1</ref>. Also, ( <ref type="formula">9</ref>) and ( <ref type="formula">10</ref>) can be easily used to implement Algorithm 1 in a library without complex arithmetic. More sophisticated optimizers like Adam can trivially support complex optimizer parameters with real-valued updates, which we explore in Section 4.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Scope and Limitations</head><p>For some games, we need higher than first-order information to converge -ex., pure-response games <ref type="bibr" target="#b6">[7]</ref> -because the first-order information for a player is identically zero. So, momentum methods only using first-order info will not converge in general. However, we can combine methods with second-order information and momentum algorithms <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9]</ref>. Complex momentum's computational cost is almost identical to classical and negative momentum, except we now have a buffer with twice as many real parameters. We require one more optimization hyperparameter than classical momentum, which we provide an initial guess for in Section 4.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We investigate complex momentum's performance in training GANs and games with different mixtures of cooperative and adversarial eigenspaces, showing improvements over standard baselines. Code for experiments will be available on publication, with reproducibility details in Appendix C.</p><p>Overview: We start with a purely adversarial Dirac-GAN and zero-sum games, which have known solutions ω ˚" pθ Å , θ B q and spectrums Spp∇ ω ĝq, so we can assess convergence rates. Next, we evaluate GANs generating 2D distributions, because they are simple enough to train with a plain, alternating SGD. Finally, we look at scaling to larger-scale GANs on images which have brittle optimization, and require optimizers like Adam. Complex momentum provides benefits in each setup.</p><p>We only compare to first-order optimization methods, despite there being various second-order methods due limitations discussed in Section 2.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Optimization in Purely Adversarial Games</head><p>Here, we consider the optimizing the Dirac-GAN objective, which is surprisingly hard and where many classical optimization methods fail, because Spp∇ ω ĝq is imaginary near solutions:</p><formula xml:id="formula_10">min x max y ´logp1 `expp´xyqq ´logp2q<label>(15)</label></formula><p>Figure <ref type="figure" target="#fig_1">3</ref> empirically verifies convergence rates given by Theorem 1 with <ref type="bibr" target="#b13">(14)</ref>, by showing the optimization trajectories with simultaneous updates.</p><p>Figure <ref type="figure" target="#fig_2">4b</ref> investigates how the components of the momentum β affect convergence rates with simultaneous updates and a fixed step size. The best β was almost-positive (i.e., argpβq " for small ). We repeat this experiment with alternating updates in Appendix Figure <ref type="figure">8</ref>, which are standard in GAN training. There, almost-positive momentum is best (but negative momentum also converges), and the benefit of alternating updates can depend on if we can parallelize player gradient evaluations. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">How Adversarialness Affects Convergence Rates</head><p>Here, we compare optimization with first-order methods for purely adversarial, cooperative, and mixed games. We use the following game, allowing us to easily interpolate between these regimes: min Max adversarialness γ max Figure <ref type="figure">5</ref>: We compare first-order methods convergence rates on the game in <ref type="bibr" target="#b15">(16)</ref>, with A " B 1 " B 2 diagonal and entries linearly spaced in r 1 {4, 4s. We interpolate from purely cooperative to a mixture of purely cooperative and adversarial eigenspaces in Spp∇ ω ĝq by making γ diagonal with γ j " U r0, γ max s, inducing j th eigenvalue pair to have argpλ j q « ˘γj π 2 . So, γ max controls the largest possible eigenvalue arg or max adversarialness. Every method generalizes gradient descentascent (GDA) by adding an optimizer parameter, tuned via grid search. Positive momentum and negative momentum do not converge if there are purely adversarial eigenspaces (i.e., γ max " 1). Almostpositive momentum argpβq " ą 0 like π {8 allows us to approach the acceleration of positive momentum if sufficiently cooperative (i.e., γ max ă 0.5), while still converging if there are purely adversarial eigenspaces (i.e., γ max " 1). Tuning argpβq with complex momentum performs competitively with extragradient (EG), optimistic gradient (OG) for any adversarialness -ex., argpβq " π {2 does well if there are purely adversarial eigenspaces (i.e., γ max " 1).</p><p>If γ " I the game is purely adversarial, while if the γ " 0 the game is purely cooperative.</p><p>Figure <ref type="figure">6</ref> explores SppRq in purely adversarial games for a range of α, β, generalizing Figure <ref type="figure" target="#fig_2">4</ref> in <ref type="bibr" target="#b24">[25]</ref>. At every non-real β-i.e., argpβq ‰ π or 0-we could select α, |β| that converge.</p><p>Figure <ref type="figure">5</ref> compares first-order algorithms as we interpolate from the purely cooperative games (i.e., minimization) to mixtures of purely adversarial and cooperative eigenspaces, because this setup range can occur during GAN training -see Figure <ref type="figure">7</ref>. Our baselines are simultaneous SGD (or gradient descent-ascent (GDA)), extragradient (EG) <ref type="bibr" target="#b40">[41]</ref>, optimistic gradient (OG) <ref type="bibr" target="#b49">[50]</ref><ref type="bibr" target="#b50">[51]</ref><ref type="bibr" target="#b51">[52]</ref>, and momentum variants. We added extrapolation parameters for EG and OG so they are competitive with momentum -see Appendix Section C.3. We show how many gradient evaluations for a set solution distance, and EG costs two evaluations per update. We optimize convergence rates for each game and method by grid search, as is common for optimization parameters in deep learning.</p><p>Takeaway: In the cooperative regime -i.e., γ max ă .5 or max λPSpp∇ω ĝq | argpλq| ă π {4the best method is classical, positive momentum, otherwise we benefit from a method for learning in games. If we have purely adversarial eigenspaces then GDA, positive and negative momentum fail to converge, while EG, OG, and complex momentum can converge. In games like GANs, our eigendecomposition is infeasible to compute and changes during training -see Appendix Figure <ref type="figure" target="#fig_9">9</ref> -so we want an optimizer that converges robustly. Choosing any non-real momentum β allows robust convergence for every eigenspace mixture. More so, almost-positive momentum β allows us to approach acceleration when cooperative, while still converging if there are purely adversarial eigenspaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Training GANs on 2D Distributions</head><p>Here, we investigate improving GAN training using alternating gradient descent updates with complex momentum. We look at alternating updates, because they are standard in GAN training <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b52">53]</ref>. It is not clear how EG and OG generalize to alternating updates, so we use positive and negative momentum as our baselines. We train to generate a 2D mixture of Gaussians, because more complicated distribution require more complicated optimizers than SGD. Figure <ref type="figure" target="#fig_8">1</ref> shows all changes necessary to use the JAX momentum optimizer for our updates, with full details in Appendix C.4. We evaluate the log-likelihood of GAN samples under the mixture as an imperfect proxy for matching.</p><p>Appendix Figure <ref type="figure" target="#fig_8">10</ref> shows heatmaps for tuning argpβq and |β| with select step sizes. Takeaway: The best momentum was found at the almost-positive β « 0.7 exppi π {8q with step size α " 0.03, and for each α we tested a broad range of non-real β outperformed any real β. This suggests we may be able to often improve GAN training with alternating updates and complex momentum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Training BigGAN with a Complex Adam</head><p>Here, we investigate improving larger-scale GAN training with complex momentum. However, largerscale GANs train with more complicated optimizers than gradient descent -like Adam <ref type="bibr" target="#b30">[31]</ref> -and have notoriously brittle optimization. We look at training BigGAN <ref type="bibr" target="#b31">[32]</ref> on CIFAR-10 [54], but were unable to succeed with optimizers other than <ref type="bibr" target="#b31">[32]</ref>-supplied setups, due to brittle optimization. So, we attempted to change procedure minimally by taking <ref type="bibr" target="#b31">[32]</ref>-supplied code here which was trained with Adam, and making the β 1 parameter -analogous to momentum -complex. The modified complex Adam is shown in Algorithm 2, where the momentum bias correction is removed to better match our theory. It is an open question on how to best carry over the design of Adam (or other optimizers) to the complex setting. Training each BigGAN took 10 hours on an NVIDIA T4 GPU, so Figure <ref type="figure" target="#fig_12">12a</ref> and Table <ref type="table">1</ref> took about 1000 and 600 GPU hours respectively.</p><p>Figure <ref type="figure" target="#fig_12">12a</ref> shows a grid search over argpβ 1 q and |β 1 | for a BigGAN trained with Algorithm 2. We only changed β 1 for the discriminator's optimizer. Takeaway: The best momentum was at the almostpositive β 1 « 0.8 exppi π {8q, whose samples are in Appendix Figure <ref type="figure" target="#fig_10">11b</ref>. We tested the best momentum value over 10 seeds against the author-provided baseline in Appendix Figure <ref type="figure" target="#fig_12">12b</ref>, with the results summarized in Table <ref type="table">1</ref>. <ref type="bibr" target="#b31">[32]</ref> reported a single inception score (IS) on CIFAR-10 of 9.22, but the best we could reproduce over the seeds with the provided PyTorch code and settings was 9.10. Complex momentum improves the best IS found with 9.25p`.15 over author code, `.03 author reportedq. We trained a real momentum |β 1 | " 0.8 to see if the improvement was solely from tuning the momentum magnitude. This occasionally failed to train and decreased the best IS over re-runs, showing we benefit from a non-zero argpβ 1 q.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">A Practical Initial Guess for Optimizer Parameter argpβq</head><p>Here, we propose a practical initial guess for our new hyperparameter argpβq. Corollary 1 shows we can use almost-real momentum coefficients (i.e., argpβq is close to 0). Figure <ref type="figure">5</ref> shows almost-positive β approach acceleration in cooperative eigenspaces, while converging in all eigenspaces. Figure <ref type="figure">7</ref> shows GANs can have both cooperative and adversarial eigenspaces. Figures <ref type="figure" target="#fig_8">10</ref> and <ref type="figure" target="#fig_12">12a</ref> do a grid search over argpβq for GANs, finding that almost-positive argpβq « π {8 works in both cases. Also, by minimally changing argpβq from 0 to a small , we can minimally change other hyperparameters in our model, which is useful to adapt existing, brittle setups like in GANs. Based on this, we propose an initial guess of argpβq " for a small ą 0, where " π {8 worked in our GAN experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 Complex Adam variant without momentum bias-correction</head><p>1: β 1 P C, β 2 P r0,1q 2: α P R `, P R 3:</p><p>for j " 1 . . . N do 4: µ j`1 " β 1 µ j ´gj 5: v j`1 " β 2 v j `p1´β 2 qpg j q 2 6: vj`1 " v j`1 1´pβ2q j 7: ω j`1 " ω j `α pµ j q ? vj`</p><p>1 ` return ω N CIFAR-10 BigGAN Best IS for 10 seeds Discriminator β 1 Min Max 0 -[32]'s default 8.9 9.1 0.8 exppi π {8q -ours 8.96p`.06q 9.25p`.15q 0.8 3.12p´5.78q 9.05p´0.05q Table <ref type="table">1</ref>: We display the best inception scores (IS) found over 10 runs for training BigGAN on CIFAR-10 with various optimizer settings. We use a complex Adam variant outlined in Algorithm 2, where we only tuned β 1 for the discriminator. The best parameters found in Figure <ref type="figure" target="#fig_12">12a</ref> were β 1 " 0.8 exppi π {8q, which improved the min and max IS from our runs of the BigGAN authors baseline, which was the SoTA optimizer in this setting to best of our knowledge. We tested β 1 " 0.8 to see if the gain was solely from tuning |β 1 |, which occasionally failed and decreased the best IS. Does eigenvector point at a player?</p><p>Figure <ref type="figure">7</ref>: A log-polar coordinate visualization reveals structure in the spectrum for a GAN at the end of the training on a 2D mixture of Gaussians with a 1-layer (disc)riminator and (gen)erator, so the joint-parameters ω P R 723 . It is difficult to see structure by graphing the Cartesian (i.e., and ) parts of eigenvalues, because they span orders of magnitude, while being positive and negative. Appendix Figure <ref type="figure" target="#fig_9">9</ref> shows the spectrum through training.</p><p>There is a mixture of many cooperative (i.e., real or argpλq « 0, ˘π) and some adversarial (i.e., imaginary or argpλq « ˘π 2 ) eigenvalues, so -contrary to what the name may suggest -generative adversarial networks are not purely adversarial. We may benefit from optimizers leveraging this structure like complex momentum. Eigenvalues are colored if the associated eigenvector is mostly in one player's part of the joint-parameter space -see Appendix Figure <ref type="figure" target="#fig_9">9</ref> for details on this. Many eigenvectors lie mostly in the the space of (or point at) a one player. The structure of the set of eigenvalues for the disc. Accelerated first-order methods: A broad body of work exists using momentum-type methods <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b55">56]</ref>, with a recent focus on deep learning <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b56">[57]</ref><ref type="bibr" target="#b57">[58]</ref><ref type="bibr" target="#b58">[59]</ref><ref type="bibr" target="#b59">[60]</ref>. But, these works focus on momentum for minimization as opposed to in games.</p><p>Learning in games: Various works approximate response-gradients -some by differentiating through optimization <ref type="bibr" target="#b60">[61,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b61">62]</ref>. Multiple works try to leverage game eigenstructure during optimization <ref type="bibr">[63-65, 39, 66, 67]</ref>.</p><p>First-order methods in games: In some games, we can get away with using only first-order methods - <ref type="bibr">[68-72, 47, 73, 74]</ref> discuss when and how these methods work. <ref type="bibr" target="#b24">[25]</ref> is the closest work to ours, showing a negative momentum can help in some games. <ref type="bibr" target="#b29">[30]</ref> note the suboptimality of negative momentum in a class of games. <ref type="bibr" target="#b74">[75,</ref><ref type="bibr" target="#b75">76]</ref> investigate acceleration in some games.</p><p>Bilinear zero-sum games: <ref type="bibr" target="#b76">[77]</ref> study the convergence of gradient methods in bilinear zero-sum games. Their analysis extends <ref type="bibr" target="#b24">[25]</ref>, showing that we can achieve faster convergence by having separate step sizes and momentum for each player or tuning the extragradient step size. <ref type="bibr" target="#b77">[78]</ref> provide convergence guarantees for games satisfying a sufficiently bilinear condition.</p><p>Learning in GANs: Various works try to make GAN training easier with methods leveraging the game structure <ref type="bibr">[79-81, 53, 82]</ref>. <ref type="bibr" target="#b82">[83]</ref> approximate the discriminator's response function by differentiating through optimization. <ref type="bibr" target="#b33">[34]</ref> find solutions by minimizing the norm of the players' updates. Both of these methods and various others <ref type="bibr" target="#b83">[84]</ref><ref type="bibr" target="#b84">[85]</ref><ref type="bibr" target="#b85">[86]</ref> require higher-order information. <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b86">87,</ref><ref type="bibr" target="#b87">88]</ref> look at first-order methods. <ref type="bibr" target="#b41">[42]</ref> explore problems for GAN training convergence and <ref type="bibr" target="#b21">[22]</ref> show that GANs have significant rotations affecting learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper we provided a generalization of existing momentum methods for learning in differentiable games by allowing a complex-valued momentum with real-valued updates. We showed that our method robustly converges in games with a different range of mixtures of cooperative and adversarial eigenspaces than current first-order methods. We also presented a practical generalization of our method to the Adam optimizer, which we used to improve BigGAN training. More generally, we highlight and lay groundwork for investigating optimizers which work well with various mixtures of cooperative and competitive dynamics in games.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Societal Impact</head><p>Our main contribution in this work is methodological -specifically, a scalable algorithm for optimizing in games. Since our focus is on improving optimization methods, we do not expect there to be direct negative societal impacts from this contribution.</p><p>Table 2: Notation SGD Stochastic Gradient Descent CM Complex Momentum SGDm, SimSGDm, . . . . . . with momentum SimSGD, SimCM Simultaneous . . . AltSGD, AltCM Alternating . . . GAN Generative Adversarial Network [1] EG Extragradient [41] OG Optimistic Gradient [52] IS Inception Score [89] :" Defined to be equal to x, y, z, ¨¨¨P C Scalars x, y, z, ¨¨¨P C n Vectors X, Y , Z, ¨¨¨P C nˆn Matrices X J The transpose of matrix X I The identity matrix pzq, pzq The real or imaginary component of z P C i The imaginary unit. z P C ùñ z " pzq `i pzq s z The complex conjugate of z P C |z| :" ? zs z The magnitude or modulus of z P C argpzq The argument or phase of z P C ùñ z " |z| exppi argpzqq z P C is almost-positive argpzq " for small respectively A, B A symbol for the outer/inner players d A , d B P N</p><p>The number of weights for the outer/inner players θ A symbol for the parameters or weights of a player</p><formula xml:id="formula_11">θ A P R d A , θ B P R d B</formula><p>The outer/inner parameters or weights L : R n Ñ R A symbol for a loss</p><formula xml:id="formula_12">L A pθ A , θ B q, L B pθ A , θ B q</formula><p>The outer/inner losses -</p><formula xml:id="formula_13">R d A `dB Þ Ñ R g A pθ A , θ B q, g B pθ A , θ B q</formula><p>Gradient of outer/inner losses w.r.t. their weights in R d A {d B θ Bpθ A q :" arg min</p><formula xml:id="formula_14">θ B L B pθ A ,θ B q</formula><p>The best-response of the inner player to the outer player</p><formula xml:id="formula_15">L Å pθ A q :" L A pθ A ,θ B pθ A qq</formula><p>The outer loss with a best-responding inner player θ Å :" arg min</p><formula xml:id="formula_16">θ A L Å pθ A q</formula><p>Outer optimal weights with a best-responding inner player</p><formula xml:id="formula_17">d :" d A `dB</formula><p>The combined number of weights for both players ω :" rθ A , θ B s P R d A concatenation of the outer/inner weights ĝpωq :" rg A pωq, g B pωqs P R d A concatenation of the outer/inner gradients ω 0 " rθ 0 A , θ 0 B s P R d</p><p>The initial parameter values j An iteration number ĝj :" ĝpω j q P R d</p><p>The joint-gradient vector field at weights ω j ∇ ω ĝj :" ∇ ω ĝ| ω j P R dˆd The Jacobian of the joint-gradient ĝ at weights ω j α P C</p><p>The step size or learning rate β P C The momentum coefficient</p><formula xml:id="formula_18">β 1 P C</formula><p>The first momentum parameter for Adam µ P C d</p><p>The momentum buffer λ P C Notation for an arbitrary eigenvalue SppM q P C n</p><p>The spectrum -or set of eigenvalues -of M P R nˆn Purely adversarial/cooperative game Spp∇ ω ĝq is purely real/imaginary ρpM q :" max zPSppM q |z|</p><p>The spectral radius in R `of M P R nˆn F α,β prµ, ωsq Fixed point op. for CM, or augmented learning dynamics R :" ∇ rµ,ωs F α,β P R 3dˆ3d</p><p>Jacobian of the augmented learning dynamics in Corollary 1 α ˚, β ˚:" arg min α,β</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ρpRpα,βqq</head><p>The optimal step size and momentum coefficient</p><formula xml:id="formula_19">ρ ˚:" ρpRpα ˚, β ˚qq</formula><p>The optimal spectral radius or convergence rate κ :" max Spp∇ωgq min Spp∇ωgq Condition number, for convex single-objective optimization σ 2 min pM q :" max SppM J M q The minimum singular value of a matrix M</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Supporting Results</head><p>First, some basic results about complex numbers that are used: z " pzq `i pzq " |z| exppi argpzqq</p><p>s z " pzq ´i pzq " |z| expp´i argpzqq (18) exppizq `expp´izq " 2 cospzq (</p><formula xml:id="formula_21">Ě z 1 z 2 " s z 1 s z 2 (20) 1 {2pz `s zq " pzq<label>19)</label></formula><p>) pz 1 z 2 q " pz 1 q pz 2 q ´ pz 1 q pz 2 q (22) z 1 `z2 " p pz 1 q ` pz 2 qq `ip pz 1 q ` pz 2 qq (23) z 1 z 2 " p pz 1 q pz 2 q ´ pz 1 q pz 2 qq `ip pz 1 q pz 2 q ` pz 1 q pz 2 qq (24)</p><formula xml:id="formula_23">z 1 z 2 " |z 1 ||z 2 | exppipargpz 1 q `argpz 2 qqq (25) z k " |z| k exppi argpzqkq " |z| k pcospk argpzqq `i sinpk argpzqq<label>(26)</label></formula><p>This Lemma shows how we expand the complex-valued momentum buffer µ into its Cartesian components as in <ref type="bibr" target="#b8">(9)</ref>. Lemma 1. µ j`1 " βµ j ´ĝ j ðñ pµ j`1 q " pβq pµ j q ´ pβq pµ j q ´ pĝ j q, pµ j`1 q " pβq pµ j q ` pβq pµ j q ´ pĝ j q Proof. µ j`1 " βµ j ´ĝ j ðñ µ j`1 " p pβq `i pβqq ` pµ j q `i pµ j q ˘´´ pĝ j q `i pĝ j q ðñ µ j`1 " ` pβq pµ j q ´ pβq pµ j q ˘ì ` pβq pµ j q ` pβq pµ j q ˘´´ pĝ j q `i pĝ j q ðñ µ j`1 "</p><p>´ pβq pµ j q ´ pβq pµ j q ´ pĝ j q ¯ì</p><p>´ pβq pµ j q ` pβq pµ j q ´ pĝ j q ðñ pµ j`1 q " pβq pµ j q´ pβq pµ j q´ pĝ j q, pµ j`1 q " pβq pµ j q` pβq pµ j q´ pĝ j q</p><p>We further assume pĝ j q is 0 -i.e., our gradients are real-valued. This Lemma shows how we can decompose the joint-parameters ω at the next iterate as a linear combination of the joint-parameters, joint-gradient, and Cartesian components of the momentum-buffer at the current iterate as in <ref type="bibr" target="#b9">(10)</ref>. Lemma 2. ω j`1 " ω j ` pαµ j`1 q ðñ ω j`1 " ω j ´ pαqĝ j ` pαβq pµ j q ´ pαβq pµ j q Proof. pαµ j`1 q " ` pαq pµ j`1 q ´ pαq pµ j`1 q "</p><p>´ pαq</p><p>´ pβq pµ j q ´ pβq pµ j q ´ĝ j ¯´ pαq ` pβq pµ j q ` pβq pµ j q ˘"</p><p>´ pαqĝ j `` pαq ` pβq pµ j q ´ pβq pµ j q ˘´ pαq ` pβq pµ j q ` pβq pµ j q ˘"</p><p>´ pαqĝ j `p pαq pβq ´ pαq pβqq pµ j q ´p pαq pβq ` pαq pβqq pµ j q " ´ pαqĝ j ` pαβq pµ j q ´ pαβq pµ j q Thus, ω j`1 " ω j ` pαµ j`1 q ðñ ω j`1 " ω j ´ pαqĝ j ` pαβq pµ j q ´ pαβq pµ j q A.1 Theorem 1 Proof Sketch Theorem 1 (Consequence of Prop. 4.4.1 <ref type="bibr" target="#b43">[44]</ref>). Convergence rate of complex momentum: If the spectral radius ρpRq " ρp∇ rµ,ωs F α,β q ă 1, then, for rµ, ωs in a neighborhood of rµ ˚, ω ˚s, the distance of rµ j , ω j s to the stationary point rµ ˚, ω ˚s converges at a linear rate OppρpRq` q j q, @ ą 0.</p><p>Proof. We reproduce the proof for a simpler case of quadratic games, which is simple case of <ref type="bibr" target="#b26">[27]</ref>'s well-known method for analyzing the convergence of iterative methods. <ref type="bibr" target="#b43">[44]</ref> generalizes this result from quadratic games to when we are sufficiently close to any stationary point.</p><p>For quadratic games, we have that ĝj " p∇ ω ĝq J ω j . Well, by Lemma 1 and Lemma 2 we have:</p><formula xml:id="formula_24">¨ pµ j`1 q pµ j`1 q ω j`1 ‚" R ¨ pµ j q pµ j q ω j ‚<label>(27)</label></formula><p>By telescoping the recurrence for the j th augmented parameters:</p><formula xml:id="formula_25">¨ pµ j q pµ j q ω j ‚" R j ¨ pµ 0 q pµ 0 q ω 0 ‚<label>(28)</label></formula><p>We can compare µ j with the value it converges to µ ˚which exists if R is contractive. We do the same with ω. Because µ ˚" Rµ ˚" R j µ ˚:</p><formula xml:id="formula_26">¨ pµ j q ´ pµ ˚q pµ j q ´ pµ ˚q ω j ´ω˚‚ " R j ¨ pµ 0 q ´ pµ ˚q pµ 0 q ´ pµ ˚q ω 0 ´ω˚‚<label>(29)</label></formula><p>By taking norms:</p><formula xml:id="formula_27">› › › › › › ¨ pµ j q ´ pµ ˚q pµ j q ´ pµ ˚q ω j ´ω˚‚ › › › › › › 2 " › › › › › › R j ¨ pµ 0 q ´ pµ ˚q pµ 0 q ´ pµ ˚q ω 0 ´ω˚‚ › › › › › › 2<label>(30)</label></formula><p>ùñ</p><formula xml:id="formula_28">› › › › › › ¨ pµ j q ´ pµ ˚q pµ j q ´ pµ ˚q ω j ´ω˚‚ › › › › › › 2 ď › › R j › › 2 › › › › › › ¨ pµ 0 q ´ pµ ˚q pµ 0 q ´ pµ ˚q ω 0 ´ω˚‚ › › › › › › 2<label>(31)</label></formula><p>With Lemma 11 from <ref type="bibr" target="#b89">[90]</ref>, we have there exists a matrix norm @ ą 0 such that:</p><formula xml:id="formula_29">}R j } ď pρ pRq ` q j<label>(32)</label></formula><p>We also have an equivalence of norms in finite-dimensional spaces. So for all norms }¨}, DC ě B ą 0 such that:</p><formula xml:id="formula_30">B}R j } ď }R j } 2 ď C}R j }<label>(33)</label></formula><p>Combining ( <ref type="formula" target="#formula_29">32</ref>) and <ref type="bibr" target="#b32">(33)</ref> we have:</p><formula xml:id="formula_31">› › › › › › ¨ pµ j q ´ pµ ˚q pµ j q ´ pµ ˚q ω j ´ω˚‚ › › › › › › 2 ď C pρ pRq ` q j › › › › › › ¨ pµ 0 q ´ pµ ˚q pµ 0 q ´ pµ ˚q ω 0 ´ω˚‚ › › › › › › 2<label>(34)</label></formula><p>So, we have:</p><formula xml:id="formula_32">› › › › › › ¨ pµ j q ´ pµ ˚q pµ j q ´ pµ ˚q ω j ´ω˚‚ › › › › › › 2 " OppρpRq ` q j q<label>(35)</label></formula><p>Thus, we converge linearly with a rate of OpρpRq ` q.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Characterizing the Augmented Dynamics Eigenvalues</head><p>Here, we present polynomials whose roots are the eigenvalues of our the Jacobian of our augmented dynamics SppRq, given the eigenvalues of the Jacobian of the joint-gradient vector field Spp∇ ω ĝq.</p><p>We use a similar decomposition as <ref type="bibr" target="#b24">[25]</ref>.</p><p>We can expand ∇ ω ĝ " P T P ´1 where T is an upper-triangular matrix and λ i is an eigenvalue of ∇ ω ĝ. The command gives us the polynomial associated with eigenvalue λ k " r `iu:</p><formula xml:id="formula_33">p k pxq " ´a2 x`a 2 `acrx`iacux`2ax 2 ´2ax´b 2 x`b 2 `bdrx`ibdux´crx 2 ´icux 2 ´x3 `x2<label>(38)</label></formula><p>Consider the case where λ k is imaginary -i.e, r " 0 -which is true in all purely adversarial and bilinear zero-sum games. Then <ref type="bibr" target="#b37">(38)</ref> simplifies to:</p><formula xml:id="formula_34">p k pxq " ´a2 x `a2 `iacux `2ax 2 ´2ax ´b2 x `b2 `ibdux ´icux 2 ´x3 `x2<label>(39)</label></formula><p>Our complex λ k come in conjugate pairs where λ k " u k i and λk " ´uk i. <ref type="bibr" target="#b38">(39)</ref> has the same roots for λ k and λk , which can be verified by writing the roots with the cubic formula. This corresponds to spiraling around the solution in either a clockwise or counterclockwise direction. Thus, we restrict to analyzing λ k where u k is positive without loss of generality.</p><p>If we make the step size α real -i.e., d " 0 -then (39) simplifies to:</p><formula xml:id="formula_35">p k pxq " xp´a 2 `iacu ´2a ´b2 q `a2 `x2 p2a ´icu `1q `b2 ´x3<label>(40)</label></formula><p>Using a heuristic from single-objective optimization, we look at making step size proportional to the inverse of the magnitude of eigenvalue k -i.e., α k " α 1 |λ k | " α 1 u k . With this, (40) simplifies to:</p><formula xml:id="formula_36">p k pxq " xp´a 2 `iaα 1 ´2a ´b2 q `a2 `x2 p2a ´iα 1 `1q `b2 ´x3<label>(41)</label></formula><p>Notably, in <ref type="bibr" target="#b40">(41)</ref> there is no dependence on the components of imaginary eigenvalue λ k " r `iu " 0 `iu, by selecting a α that is proportional to the eigenvalues inverse magnitude. We can simplify further with a 2 `b2 " |β| 2 :</p><formula xml:id="formula_37">p k pxq " xp pβqpiα 1 ´2q ´|β| 2 q `x2 p2 pβq ´iα 1 `1q `|β| 2 ´x3<label>(42)</label></formula><p>We could expand this in polar form for β by noting pβq " |β| cospargpβqq:</p><formula xml:id="formula_38">p k pxq " xp|β| cospargpβqqpiα 1 ´2q ´|β| 2 q `x2 p2|β| cospargpβqq ´iα 1 `1q `|β| 2 ´x3 (43)</formula><p>We can simplify further by considering an imaginary β -i.e., pβq " 0 or cospargpβqq " 0:</p><formula xml:id="formula_39">p k pxq " |β| 2 ´x|β| 2 ´x2 piα 1 ´1q ´x3<label>(44)</label></formula><p>The roots of these polynomials can be trivially evaluated numerically or symbolically with the by plugging in β, α, and λ k then using the cubic formula. This section can be easily modified for the eigenvalues of the augmented dynamics for variants of complex momentum by defining the appropriate R and modifying the Mathematica command to get the characteristic polynomial for each component, which can be evaluated if it is a sufficiently low degree using known formulas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Convergence Bounds</head><p>Corollary 1 (Convergence of Complex Momentum). There exist α P R, β P C so Algorithm 1 converges for bilinear zero-sum games. More-so, for small (we show for " π 16 ), if argpβq " (i.e., almost-positive) or argpβq " π ´ (i.e., almost-negative), then we can select α, |β| to converge.</p><p>Proof. Note that Theorem 1 bounds the convergence rate of Algorithm 1 by SppRq. Also, <ref type="bibr" target="#b39">(40)</ref> gives a formula for 3 eigenvalues in SppRq given α, β, and an eigenvalue λ P Spp∇ ω ĝq. The formula works by giving outputting a cubic polynomial whose roots are eigenvalues of SppRq, which can be trivially evaluated with the cubic formula.</p><p>We denote the k th eigenspace of Spp∇ ω ĝq with eigenvalue λ k " ic k and |c 1 | ď ¨¨¨ď |c n |, because bilinear zero-sum games have purely imaginary eigenvalues due to ∇ ω ĝ being antisymmetric. Eigenvalues come in a conjugate pairs, where λk " ip´c k q If we select momentum coefficient β " |β| exppi argpβqq and step size α k "</p><formula xml:id="formula_40">α 1 k |c k | ,</formula><p>and use that λ P Spp∇ ω ĝq are imaginary, then -as shown in Appendix Section A.2 -(40) simplifies to: p k pxq " xp|β| cospargpβqqpiα 1 k ´2q ´|β| 2 q `x2 p2|β| cospargpβqq ´iα 1 k `1q `|β| 2 ´x3 (45) So, with these parameter selections, the convergence rate of Algorithm 1 in the k th eigenspace is bounded by the largest root of (45). First, consider argpβq " π ´ , where " π 16 . We select α 1 k " 0.75 (equivalently, α k " 0.75 |c k | ) and |β| " 0.986 via grid search. Using the cubic formula on the associated ppxq from (45) the maximum magnitude root has size « 0.9998 ă 1, so this selection converges in the k th eigenspace. So, selecting: α ď min k α k (46) " min k 0.75 c k (47) " 0.75 max k c k (48) " 0.75 }∇ ω ĝ} 2</p><p>with β " 0.986 exppipπ ´ qq will converge in each eigenspace. Now, consider argpβq " " π 16 with α 1 k " 0.025 and |β| " 0.9. Using the cubic formula on the associated ppxq from (45) the maximum magnitude root has size « 0.973 ă 1, so this selection converges in the k th eigenspace. So, selecting:</p><formula xml:id="formula_42">α ď min k α k<label>(50)</label></formula><p>"</p><formula xml:id="formula_43">min k 0.025 c k (51) " 0.025 max k c k (52) " 0.025 }∇ ω ĝ} 2<label>(53)</label></formula><p>with β " 0.9 exppi q will converge in each eigenspace.</p><p>Thus, for any of the choices of argpβq we can select α, |β| that converges in every eigenspace, and thus converges.</p><p>In the preceding proof, our prescribed selection of α depends on knowing the largest norm eigenvalue of Spp∇ ω ĝq, because our selections of α 9</p><p>1 }∇ω ĝ}2 . We may not have access to largest norm eigenvalue of Spp∇ ω ĝq in-practice. Nonetheless, this shows that a parameter selection exists to converge, even if it may be difficult to find. Often, in convex optimization we describe choices of α, β in terms of the largest and smallest norm eigenvalues of Spp∇ ω ĝq (i.e. the Hessian of the loss) <ref type="bibr" target="#b90">[91]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Algorithms</head><p>Here, we include additional algorithms, which may be of use to some readers. Algorithm 3 show aggregated momentum <ref type="bibr" target="#b25">[26]</ref>. Algorithm 4 shows the recurrently linked momentum that generalizes and unifies aggregated momentum with negative momentum <ref type="bibr" target="#b24">[25]</ref>. Algorithm 5 shows our algorithm with alternating updates, which we use for training GANs. Algorithm 6 shows our method with all real-valued objects, if one wants to implement complex momentum in a library that does not support complex arithmetic. Algorithm 3 Aggregated Momentum 1: Select number of buffers K P N 2: Select β pkq P r0, 1q for k " 1 . . . K 3: Select α pkq P R `for k " 1 . . . K 4: Initialize µ 0 pkq for k " 1 . . . K 5: for j " 1 . . . N do 6:</p><p>for k " 1 . . . K do 7:</p><formula xml:id="formula_44">µ j`1</formula><p>pkq " β pkq µ j pkq ´ĝ j 8:</p><formula xml:id="formula_45">ω j`1 " ω j `řK k"1 α pkq µ j`</formula><p>1 pkq return ω N Algorithm 4 Recurrently Linked Momentum 1: Select number of buffers K P N 2: Select β pl,kq P R for l " 1 . . . K and k " 1 . . . K 3: Select α pkq P R `for k " 1 . . . K 4: Initialize µ 0 pkq for k " 1 . . . K 5: for j " 1 . . . N do 6:</p><p>for k " 1 . . . K do 7:</p><formula xml:id="formula_46">µ j`1</formula><p>pkq " ř l β pl,kq µ j plq ´ĝ j 8:</p><formula xml:id="formula_47">ω j`1 " ω j `řK k"1 α pkq µ j`1 pkq return ω N Algorithm 5 (AltCM) Momentum 1: Select β P C, α P R 2: Initialize µ 0 A , µ 0 B 3: for j " 1 . . . N do 4: µ j`1 A " βµ j A ´gj A 5: θ j`1 A " θ j A ` pαµ j`1 A q 6: µ j`1 B " βµ j B ´gB pθ j`1 A , θ j B q 7: θ j`1 B " θ j B ` pαµ j`1 B q return ω N Algorithm 6 (SimCM) Complex Momentum -R valued 1:</formula><p>Select pβq, pβq, pαq, pαq P R 2: Select pβq, pβq, pαq, pαq P R 3: Initialize pµq 0 , pµq 0 4: for j " 1 . . . N do 5: pµ j`1 q " pβq pµ j q ´ pβq pµ j q ´ĝ j 6: pµ j`1 q " pβq pµ j q ` pβq pµ j q 7: ω j`1 " ω j ´ pαqĝ j ` pαβq pµ j q´ pαβq pµ j q return ω N</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Complex Momentum in PyTorch</head><p>Our method can be easily implemented in PyTorch 1.6+ by using complex tensors. The only necessary change to the SGD with momentum optimizer is extracting the real-component from momentum buffer as with JAX -see here.</p><p>In older versions of Pytorch, we can use a tensor to represent the momentum buffer µ, step size α, and momentum coefficient β. Specifically, we represent the real and imaginary components of the complex number independently. Then, we redefine the operations __add__ and __mult__ to satisfy the rules of complex arithmetic -i.e., equations ( <ref type="formula">23</ref>) and <ref type="bibr" target="#b23">(24)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Optimization in Purely Adversarial Games</head><p>We include the alternating update version of Figure <ref type="figure" target="#fig_2">4b</ref> in Figure <ref type="figure">8</ref>, which allows us to contrast simultaneous and alternating updates. With alternating updates on a Dirac-GAN for α " 0.1 the best value for the momentum coefficient β was complex, but we could converge with real, negative momentum. Simultaneous updates may be a competitive choice with alternating updates, only if alternating updates cost two gradient evaluations per step, which is common in deep learning setups. " }v1:337}1 }v}1 . If this ratio is near 1 (or 0) and say the eigenvector mostly points at D (or G). The blue eigenvector mostly points at G, while the orange eigenvector is unclear. Finding useful ways to attribute eigenvalues to players is an open problem. Bottom: The spectrum of the Jacobian of the joint-gradient Spp∇ ω ĝj q is shown in log-polar coordinates, because it is difficult to see structure when graphing in Cartesian (i.e., and ) coordinates, due to eigenvalues spanning orders of magnitude, while being positive and negative. The end of training is when we stop making progress on the log-likelihood. We have imaginary eigenvalues at argpλq " ˘π{2, positive eigenvalues at argpλq " 0, and negative eigenvalues at argpλq " ˘π. Takeaway: There is a banded structure for the coloring of the eigenvalues that persists through training. We may want different optimizer parameters for the discriminator and generator, due to asymmetry in their associated eigenvalues. Also, the magnitude of the eigenvalues grows during training, and the args spread out indicating the game can change eigenstructure near solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Momentum phase argpβq</head><p>Step size α " 0.001</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Momentum Magnitude |β|</head><p>Step Size α " 0.003 NLL, lower = better Figure <ref type="figure" target="#fig_8">10</ref>: Heatmaps of the negative log-likelihood (NLL) for tuning argpβq, |β| with various fixed α on a 2D mixture of Gaussians GAN. We highlight the best performing cell in red, which had argpβq « π {8. Runs equivalent to alternating SGD are shown in a magenta box. We compare to negative momentum with alternating updates as in <ref type="bibr" target="#b24">[25]</ref> in the top row with argpβq " π. Left: Tuning the momentum with α " 0.001. Right: Tuning the momentum with α " 0.003.    <ref type="table">1</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Complex momentum helps correct rotational dynamics when training a Dirac-GAN [42].Left: Parameter trajectories with step size α " 0.1 and momentum β " 0.9 exppi π {8q. We include the classical, real and positive momentum which diverges for any step size. Right: The distance from optimum, which has a linear convergence rate matching our prediction with Theorem 1 and (14).</figDesc><graphic coords="4,120.12,523.49,203.15,158.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4</head><label>4</label><figDesc>Figure4(a): We show the real part of our momentum buffer -which dictates the parameter update -at the 50 th iteration pµ 50 q dependence on past gradients ĝk for k " 1 . . . 50. The momentum magnitude is fixed to |β| " 0.9 as in Figure3. Euler's formula is used in<ref type="bibr" target="#b7">(8)</ref> to for finding dependence or coefficient of ĝk via pµ 50 q " ´řk"50 k"0 |β| k cospk argpβqqĝ j´k . Complex momentum allows smooth changes in the buffers dependence on past gradients.</figDesc><graphic coords="5,287.50,20.06,214.81,164.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>pSppRqq argpβq " 0 argpβq " π 4 Figure 6 :</head><label>46</label><figDesc>Figure6: The spectrum of the augmented learning dynamics R is shown, whose spectral norm is the convergence rate in Theorem 1. Each image is a different momentum phase argpβq for a range of α,|β| P r0,1s. The opacity of an eigenvalue (eig) is the step size α and the color corresponds to momentum magnitude |β|. A red unit circle shows where all eigs must lie to converge for a fixed α, β. If the max eig norm ă 1, we draw a green circle whose radius is our convergence rate and a green star at the associated eig. Notably, at every non-real β we can select α,|β| for convergence. The eigs are symmetric over the x-axis, and eigs near pλq " 1 dictate convergence rate. Eigs near the center are due to state augmentation, have small magnitudes, and do not impact convergence rate. Simultaneous gradient descent corresponds to the magenta values where |β| " 0.</figDesc><graphic coords="7,118.64,62.90,173.74,69.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>x</head><figDesc>J pγAqy `xJ ppI ´γqB 1 qx ´yJ ppI ´γqB 2 qy (16) = 0 (classical) arg( ) = 8 (ours) arg( ) = 2 (ours) arg( ) = (negative) EG OG GDA # grad. eval. to converge</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>2 π</head><label>2</label><figDesc>Phase of eigenvalue argpλqSpectrum of Jacobian of joint-grad Spp∇ ω ĝj q for GAN Log-magnitude of eigenvalue logp|λ|q disc.unsure gen.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><figDesc>Figure7: A log-polar coordinate visualization reveals structure in the spectrum for a GAN at the end of the training on a 2D mixture of Gaussians with a 1-layer (disc)riminator and (gen)erator, so the joint-parameters ω P R 723 . It is difficult to see structure by graphing the Cartesian (i.e., and ) parts of eigenvalues, because they span orders of magnitude, while being positive and negative. Appendix Figure9shows the spectrum through training. There is a mixture of many cooperative (i.e., real or argpλq « 0, ˘π) and some adversarial (i.e., imaginary or argpλq « ˘π 2 ) eigenvalues, so -contrary to what the name may suggest -generative adversarial networks are not purely adversarial. We may benefit from optimizers leveraging this structure like complex momentum. Eigenvalues are colored if the associated eigenvector is mostly in one player's part of the joint-parameter space -see Appendix Figure9for details on this. Many eigenvectors lie mostly in the the space of (or point at) a one player. The structure of the set of eigenvalues for the disc. (green) is different than the gen. (red), but further investigation of this is an open problem. Notably, this may motivate separate optimizer choices for each player as in Section 4.4.</figDesc><graphic coords="9,284.49,76.84,204.13,157.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><figDesc>up into components for each eigenvalue, giving us submatrices R k P C 3ˆ3 : the characteristic polynomial of R k with the following Mathematica command, where we use substitute the symbols r `iu " λ k , a " pβq, b " pβq, c " pαq, and d " pαq. CharacteristicPolynomial[{{a, -b, -(r + u I)}, {b, a, 0}, {a c -b d, -(b c + a d), 1 -c (r + u I)}}, x]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>C. 1</head><label>1</label><figDesc>Computing Infrastructure and RuntimeFor the purely adversarial experiments in Sections 4.1 and 4.2, we do our computing in CPU. Training each 2D GAN in Section 4.3 takes 2 hours and we can train 10 simultaneously on an NVIDIA T4 GPU. Training each CIFAR GAN in Section 4.4 takes 10 hours and we can only train 1 model per NVIDIA T4 GPU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: These plots investigate the spectrum of the Jacobian of the joint-gradient for the GAN in Figure 7 through training. The spectrum is key for bounding convergence rates in learning algorithms. Top left: The Jacobian ∇ ω ĝ for a GAN on a 2D mixture of Gaussians with a two-layer, fully-connected 16 hidden unit discriminator (D) and generator (G) at the end of training. In the concatenated parameters ω P R 723 , the first 337 are for D, while the last 386 are for G. We display the log of the absolute value of each component plus " 10 ´10 . The upper left and lower right quadrants are the Hessian of D and G's losses respectively. Top Right: We visualize two randomly sampled eigenvectors from ∇ ω ĝ. The first part of the parameters is for the discriminator, while the second part is for the generator. Given an eigenvalue with eigenvector v, we roughly approximate attributing eigenvectors to players by calculating how much of it lies in D's parameter space with }v 1:|D| }1 }v}1</figDesc><graphic coords="22,123.64,277.28,205.44,158.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 11 (</head><label>11</label><figDesc>Figure 11(a): Mixture of Gaussian samples from GAN with the best hyperparameters from the heatmaps in Appendix Figure 10</figDesc><graphic coords="23,99.38,269.42,208.48,156.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 11 ( 1 q</head><label>111</label><figDesc>Figure 11(b): Class-conditional CIFAR-10 samples from GAN with the best hyperparameters from the heatmap in 12a</figDesc><graphic coords="23,318.39,159.34,251.45,251.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 12 (</head><label>12</label><figDesc>Figure 12(a): The inception score (IS) for a grid search on argpβ1q and |β1| for training Big-GAN on CIFAR-10 with the Adam variant in Algorithm 2. The β1 is complex for the discriminator, while the generator's optimizer is fixed to authorsupplied defaults. Red points are runs that failed to train to the minimum IS in the color bar. The vertical magenta line denotes runs equivalent to alternating SGD. Negative momentum failed to train for any momentum magnitude |β1| ą .5, so we do not display it for more resolution near values of interest.</figDesc><graphic coords="23,120.75,466.59,159.00,121.68" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>Resources used in preparing this research were provided, in part, by the <rs type="funder">Province of Ontario</rs>, the <rs type="institution">Government of Canada through CIFAR</rs>, and companies sponsoring the <rs type="institution">Vector Institute</rs>. <rs type="person">Paul Vicol</rs> was supported by an <rs type="funder">NSERC</rs> <rs type="grantName">PGS-D Scholarship</rs>. We thank <rs type="person">Guodong Zhang</rs>, <rs type="person">Guojun Zhang</rs>, <rs type="person">James Lucas</rs>, <rs type="person">Romina Abachi</rs>, <rs type="person">Jonah Phillion</rs>, <rs type="person">Will Grathwohl</rs>, <rs type="person">Jakob Foerster</rs>, <rs type="person">Murat Erdogdu</rs>, <rs type="person">Ken Jackson</rs>, and <rs type="person">Ioannis Mitliagkis</rs> for feedback and helpful discussion.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_DYFKXDk">
					<orgName type="grant-name">PGS-D Scholarship</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Momentum phase argpβq</head><p>SimCM for # grad. eval. = # steps</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Momentum Magnitude |β|</head><p>AltCM for # grad. eval.</p><p># grad. eval. to converge AltCM for # steps # steps to converge Figure <ref type="figure">8</ref>: We show many steps and gradient evaluations, both simultaneous and alternating complex momentum on a Dirac-GAN take for a set solution distance. We fix step size α " 0.1 as in Figure <ref type="figure">3</ref>, while varying the phase and magnitude of our momentum β " |β| exppi argpβqq. There is a red star at the optima, dashed red lines at real β, and a dashed magenta line for simultaneous or alternating gradient descent. We only display color for convergent setups. Left: Simultaneous complex momentum (SimCM). This is the same as Figure <ref type="figure">4b</ref>, which we repeat to contrast with alternating updates. There are no real-valued β that converge for this -or any -α with simultaneous updates <ref type="bibr" target="#b24">[25]</ref>. Simultaneous updates can parallelize gradient computation for all players at each step, thus costing only one gradient evaluation per step for many deep learning setups. The best rate of convergence per step and gradient evaluation is « 0.955. Middle: Alternating complex momentum (AltCM), where we show how many gradient evaluations -as opposed to steps -to reach a set solution distance. Alternating updates are bottlenecked by waiting for first player's update to compute the second players update, effectively costing two gradient evaluations per step for many deep learning setups. Negative momentum can converge here, as shown by <ref type="bibr" target="#b24">[25]</ref>, but the best momentum is still complex. Also, Alternating updates can make the momentum phase argpβq choice less sensitive to our convergence. The best rate of convergence per gradient evaluation is « 0.965. Right: AltCM, where we show how many steps to reach a set solution distance. The best rate of convergence per step is « 0.931. Takeaway: If we can parallelize computation of both players gradients we can benefit from SimCM, however if we can not then AltCM can converge more quickly and for a broader set of optimizer parameters. In any case, the best solution uses a complex momentum β for this α.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 How Adversarialness Affects Convergence Rates</head><p>We include the extragradient (EG) update with extrapolation parameter α 1 and step size α:</p><p>and the optimistic gradient (OG) update with extrapolation parameter α 1 and step size α:</p><p>Often, EG and OG are used with α " α 1 , however we found that this constraint crippled these methods in cooperative games (i.e., minimization). As such, we tuned the extrapolation parameter α 1 separately from the step size α, so EG and OG were competitive baselines.</p><p>We include Figure <ref type="figure">9</ref> which investigates a GANs spectrum throughout training, and elaborates on the information that is shown in Figure <ref type="figure">7</ref>. This shows that there are many real and imaginary eigenvalues, so GAN training is neither purely cooperative or purely adversarial. Also, the structure of the set of eigenvalues for the discriminator is different than the generator, which may motivate separate optimizer choices. The structure between the players persists through training, but the eigenvalues grow in magnitude and spread out their phases. This indicates how adversarial the game is can change during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4 Training GANs on 2D Distributions</head><p>For 2D distributions, the data is generated by sampling from a mixture of 8 Gaussian distributions, which are distributed uniformly around the unit circle.</p><p>For the GAN, we use a fully-connected network with 4 hidden ReLU <ref type="bibr" target="#b91">[92]</ref> layers with 256 hidden units. We chose this architecture to be the same as <ref type="bibr" target="#b24">[25]</ref>. Our noise source for the generator is a 4D Gaussian. We trained the models for 100 000 iterations. The performance of the optimizer settings is evaluated by computing the negative log-likelihood of a batch of 100 000 generated 2D samples.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
	<note>Cited on pages 1, 2, 8, and 15</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Connecting generative adversarial networks and actor-critic methods</title>
		<author>
			<persName><forename type="first">David</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.01945</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on page 1</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Emergent tool use from multi-agent autocurricula</title>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ingmar</forename><surname>Kanitscheider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todor</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Glenn</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bob</forename><surname>Mcgrew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Mordatch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Cited on page 1</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Open-ended learning in symmetric zero-sum games</title>
		<author>
			<persName><forename type="first">David</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marta</forename><surname>Garnelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoram</forename><surname>Bachrach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Czarnecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Perolat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thore</forename><surname>Graepel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="434" to="443" />
		</imprint>
	</monogr>
	<note>Not cited.</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Intrinsic motivation and automatic curricula via asymmetric self-play</title>
		<author>
			<persName><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Kostrikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Cited on page 1</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Lorraine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.09419</idno>
		<title level="m">Stochastic hyperparameter optimization through hypernetworks</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on page 1</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Optimizing millions of hyperparameters by implicit differentiation</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Lorraine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Vicol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1540" to="1552" />
		</imprint>
	</monogr>
	<note>Cited on page 6</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Self-tuning networks: Bilevel optimization of hyperparameters using structured best-response functions</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Mackay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Vicol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><surname>Lorraine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><surname>Grosse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Not cited.</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Aniruddh</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maithra</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.03037</idno>
		<title level="m">Teaching with commentaries</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on pages 1 and 6</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Joey</forename><surname>Avishek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gauthier</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Gidel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andre</forename><surname>Berrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Cianflone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Lacoste-Julien</surname></persName>
		</author>
		<author>
			<persName><surname>Hamilton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.00720</idno>
		<title level="m">Adversarial example games</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on page 1</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Adversarial examples: Attacks and defenses for deep learning</title>
		<author>
			<persName><forename type="first">Xiaoyong</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qile</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolin</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2805" to="2824" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Cited on page 1</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A game theoretic framework for model based reinforcement learning</title>
		<author>
			<persName><forename type="first">Aravind</forename><surname>Rajeswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Mordatch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikash</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.07804</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on page 1</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Romina</forename><surname>Abachi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Ghavamzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir-Massoud</forename><surname>Farahmand</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.00030</idno>
		<title level="m">Policy-aware model learning for policy gradient methods</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Not cited.</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A Lagrangian method for inverse problems in reinforcement learning. lis.csail.mit.edu/pubs</title>
		<author>
			<persName><forename type="first">Pierre-Luc</forename><surname>Bacon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Gehring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Animashree</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emma</forename><surname>Brunskill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Cited on page 1</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">f-domain-adversarial learning: Theory and algorithms for unsupervised domain adaptation with neural networks</title>
		<author>
			<persName><forename type="first">David</forename><surname>Acuna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guojun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><forename type="middle">T</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=WqXAKcwfZtI" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>Cited on pages 1 and 3</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Gradient-based optimization of neural network architecture</title>
		<author>
			<persName><forename type="first">Will</forename><surname>Grathwohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elliot</forename><surname>Creager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seyed</forename><surname>Kamyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seyed</forename><surname>Ghasemipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Cited on page 1</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">George</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Lorraine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.00438</idno>
		<title level="m">Understanding neural architecture search techniques</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on page 1</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Meta-learning for semi-supervised few-shot classification</title>
		<author>
			<persName><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eleni</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.00676</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on page 1</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Flexible few-shot learning with contextual similarity</title>
		<author>
			<persName><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eleni</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuan-Chieh</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xaq</forename><surname>Pitkow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><forename type="middle">S</forename><surname>Tolias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.05895</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on page 1</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Theory of Games and Economic Behavior</title>
		<author>
			<persName><forename type="first">Oskar</forename><surname>Morgenstern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Von Neumann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1953">1953</date>
			<publisher>Princeton University Press</publisher>
		</imprint>
	</monogr>
	<note>Cited on page 1</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Market Structure and Equilibrium</title>
		<author>
			<persName><forename type="first">Heinrich</forename><surname>Von</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stackelberg</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
	<note>Cited on page 1</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A closer look at the optimization landscapes of generative adversarial networks</title>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Berard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gauthier</forename><surname>Gidel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amjad</forename><surname>Almahairi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Lacoste-Julien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Cited on pages 1 and 9</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Joseph Arrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hirofumi</forename><surname>Azawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonid</forename><surname>Hurwicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hirofumi</forename><surname>Uzawa</surname></persName>
		</author>
		<title level="m">Studies in Linear and Non-Linear Programming</title>
		<imprint>
			<publisher>Stanford University Press</publisher>
			<date type="published" when="1958">1958</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>Cited on page 1</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Adaptive game playing using multiplicative weights</title>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Games and Economic Behavior</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="79" to="103" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note>Cited on page 1</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Negative momentum for improved game dynamics</title>
		<author>
			<persName><surname>Gauthier Gidel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Askari</forename><surname>Reyhane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Hemmat</surname></persName>
		</author>
		<author>
			<persName><surname>Pezeshki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Rémi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Priol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Lacoste-Julien</surname></persName>
		</author>
		<author>
			<persName><surname>Mitliagkas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 22nd International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1802" to="1811" />
		</imprint>
	</monogr>
	<note>Cited on pages 1, 2, 3, 4, 5, 6, 7, 9, 18, 20, 21, and 23</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Aggregated momentum: Stability through passive damping</title>
		<author>
			<persName><forename type="first">James</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengyang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><surname>Grosse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Cited on pages 1, 2, 3, 5, and 20</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Some methods of speeding up the convergence of iteration methods</title>
		<author>
			<persName><forename type="first">T</forename><surname>Boris</surname></persName>
		</author>
		<author>
			<persName><surname>Polyak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">USSR Computational Mathematics and Mathematical Physics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
	<note>Cited on pages 2, 3, 9, and 17</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A method for solving the convex programming problem with convergence rate o (1/kˆ2)</title>
		<author>
			<persName><forename type="first">E</forename><surname>Yurii</surname></persName>
		</author>
		<author>
			<persName><surname>Nesterov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dokl. Akad. Nauk SSSR</title>
		<imprint>
			<biblScope unit="volume">269</biblScope>
			<biblScope unit="page" from="543" to="547" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On the importance of initialization and momentum in deep learning</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1139" to="1147" />
		</imprint>
	</monogr>
	<note>Cited on pages 2, 3, and 9</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">On the suboptimality of negative momentum for minimax optimization</title>
		<author>
			<persName><forename type="first">Guodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanhao</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.07459</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on pages 2 and 9</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on pages 2 and 8</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Large scale gan training for high fidelity natural image synthesis</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Cited on pages 2 and 8</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Largescale distributed second-order optimization using kronecker-factored approximate curvature for deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">Kazuki</forename><surname>Osawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yohei</forename><surname>Tsuji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuichiro</forename><surname>Ueno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akira</forename><surname>Naruse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rio</forename><surname>Yokota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satoshi</forename><surname>Matsuoka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="12359" to="12367" />
		</imprint>
	</monogr>
	<note>Cited on page 3</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The numerics of GANs</title>
		<author>
			<persName><forename type="first">Lars</forename><surname>Mescheder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1825" to="1835" />
		</imprint>
	</monogr>
	<note>Cited on pages 3, 6, and 9</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Competitive gradient descent</title>
		<author>
			<persName><forename type="first">Florian</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anima</forename><surname>Anandkumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="7623" to="7633" />
		</imprint>
	</monogr>
	<note>Cited on page 3</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">On solving minimax optimization locally: A follow-theridge approach</title>
		<author>
			<persName><forename type="first">Yuanhao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Cited on page 3</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">Reyhane</forename><surname>Askari Hemmat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amartya</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Mitliagkas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.13846</idno>
		<title level="m">Lead: Least-action dynamics for min-max optimization</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on page 3</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Florian</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anima</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Houman</forename><surname>Owhadi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.10179</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">Competitive mirror descent. arXiv preprint</note>
	<note>Cited on page 3</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">Marian</forename><surname>Wojciech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gauthier</forename><surname>Czarnecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Gidel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><surname>Tracey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shayegan</forename><surname>Tuyls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Omidshafiei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName><surname>Jaderberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.09468</idno>
		<title level="m">Real world games look like spinning tops</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">Guojun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiwen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Poupart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaoliang</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.14592</idno>
		<title level="m">Newton-type methods for minimax optimization</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on page 3</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The extragradient method for finding saddle points and other problems</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Korpelevich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Matecon</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="747" to="756" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
	<note>Cited on pages 3, 7, and 15</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Which training methods for gans do actually converge</title>
		<author>
			<persName><forename type="first">Lars</forename><surname>Mescheder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine learning (ICML)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3481" to="3490" />
		</imprint>
	</monogr>
	<note>Cited on pages 4 and 9</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Array programming with numpy</title>
		<author>
			<persName><forename type="first">K</forename><surname>Charles R Harris</surname></persName>
		</author>
		<author>
			<persName><surname>Jarrod Millman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stéfan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ralf</forename><surname>Van Der Walt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pauli</forename><surname>Gommers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Virtanen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Wieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathaniel</forename><forename type="middle">J</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">585</biblScope>
			<biblScope unit="issue">7825</biblScope>
			<biblScope unit="page" from="357" to="362" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Cited on page 4</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Nonlinear Programming</title>
		<author>
			<persName><surname>Bertsekas</surname></persName>
			<affiliation>
				<orgName type="collaboration">Athena Scientific</orgName>
			</affiliation>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>Cited on pages 5 and 17</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Adaptive restart for accelerated gradient schemes</title>
		<author>
			<persName><forename type="first">O'</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emmanuel</forename><surname>Donoghue</surname></persName>
		</author>
		<author>
			<persName><surname>Candes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations of computational mathematics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="715" to="732" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>Cited on page 5</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Why momentum really works</title>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Distill</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>Cited on page 6</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A tight and unified analysis of gradient-based methods for a whole spectrum of differentiable games</title>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Waïss Azizian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Mitliagkas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gauthier</forename><surname>Lacoste-Julien</surname></persName>
		</author>
		<author>
			<persName><surname>Gidel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2863" to="2873" />
		</imprint>
	</monogr>
	<note>Cited on pages 6 and 9</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">JAX: composable transformations of Python+NumPy programs</title>
		<author>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">James</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Leary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dougal</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Skye</forename><surname>Wanderman-Milne</surname></persName>
		</author>
		<ptr target="http://github.com/google/jax" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Cited on page 6</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Automatic differentiation in PyTorch</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Openreview</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>Cited on page 6</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Online optimization with gradual variations</title>
		<author>
			<persName><forename type="first">Chao-Kai</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianbao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chia-Jung</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehrdad</forename><surname>Mahdavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chi-Jen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shenghuo</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">JMLR Workshop and Conference Proceedings</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="6" to="7" />
		</imprint>
	</monogr>
	<note>Conference on Learning Theory Cited on page 7</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Optimization, learning, and games with predictable sequences</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Rakhlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Sridharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on Neural Information Processing Systems</title>
		<meeting>the 26th International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="3066" to="3074" />
		</imprint>
	</monogr>
	<note>Not cited.</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Training gans with optimism</title>
		<author>
			<persName><forename type="first">Constantinos</forename><surname>Daskalakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasilis</forename><surname>Syrgkanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoyang</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR 2018)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Cited on pages 7, 9, and 15</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Latent optimisation for generative adversarial networks</title>
		<author>
			<persName><forename type="first">Yan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><surname>Logan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.00953</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on pages 8 and 9</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>Cited on page 8</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Introductory lectures on convex optimization: A basic course</title>
		<author>
			<persName><forename type="first">Yurii</forename><surname>Nesterov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Springer Science &amp; Business Media</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Paulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><forename type="middle">O</forename><surname>'donoghue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Doucet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.05042</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Hamiltonian descent methods. arXiv preprint</note>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Mitliagkas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03471</idno>
		<title level="m">Yellowfin and the art of momentum tuning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">On empirical comparisons of optimizers for deep learning</title>
		<author>
			<persName><forename type="first">Dami</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">J</forename><surname>Shallue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Nado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaehoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.05446</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Not cited.</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<author>
			<persName><forename type="first">James</forename><surname>Michael R Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.08610</idno>
		<title level="m">Lookahead optimizer: k steps forward, 1 step back</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Not cited.</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Self-tuning stochastic optimization with curvature-aware gradient filtering</title>
		<author>
			<persName><forename type="first">Dami</forename><surname>Ricky Tq Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukas</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Balles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName><surname>Hennig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.04803</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Learning with opponent-learning awareness</title>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Foerster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maruan</forename><surname>Richard Y Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shimon</forename><surname>Al-Shedivat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Whiteson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><surname>Mordatch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Autonomous Agents and MultiAgent Systems</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="122" to="130" />
		</imprint>
	</monogr>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Gradient-based hyperparameter optimization through reversible learning</title>
		<author>
			<persName><forename type="first">Dougal</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2113" to="2122" />
		</imprint>
	</monogr>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Differentiable game mechanics</title>
		<author>
			<persName><forename type="first">Alistair</forename><surname>Letcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Racaniere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><forename type="middle">N</forename><surname>Foerster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><surname>Tuyls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thore</forename><surname>Graepel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">84</biblScope>
			<biblScope unit="page" from="1" to="40" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">From chaos to order: Symmetry and conservation laws in game dynamics</title>
		<author>
			<persName><forename type="first">Sai</forename><surname>Ganesh Nagarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgios</forename><surname>Piliouras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7186" to="7196" />
		</imprint>
	</monogr>
	<note>Not cited.</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Navigating the landscape of multiplayer games</title>
		<author>
			<persName><forename type="first">Shayegan</forename><surname>Omidshafiei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><surname>Tuyls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><forename type="middle">M</forename><surname>Czarnecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><forename type="middle">C</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Rowland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerome</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Hennes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Pérolat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bart</forename><forename type="middle">De</forename><surname>Vylder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<author>
			<persName><forename type="first">David</forename><surname>Gauthier Gidel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marian</forename><surname>Czarnecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marta</forename><surname>Garnelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoram</forename><surname>Bachrach</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.05820</idno>
		<title level="m">Minimax theorem for latent games or: How i learned to stop worrying about mixed-nash and love neural nets</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<author>
			<persName><forename type="first">Julien</forename><surname>Perolat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Remi</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Baptiste</forename><surname>Lespiau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shayegan</forename><surname>Omidshafiei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Rowland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Burch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Anthony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bart</forename><forename type="middle">De</forename><surname>Vylder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.08456</idno>
		<title level="m">From poincarz&apos;e recurrence to convergence in imperfect information games: Finding equilibrium via regularization</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Don&apos;t fix what ain&apos;t broke: Nearoptimal local convergence of alternating gradient descent-ascent for minimax optimization</title>
		<author>
			<persName><forename type="first">Guodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanhao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Lessard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><surname>Grosse</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.09468</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">A unified analysis of first-order methods for smooth games via integral quadratic constraints</title>
		<author>
			<persName><forename type="first">Guodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuchao</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Lessard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><surname>Grosse</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.11359</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Not cited.</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Linear lower bounds and conditioning of differentiable games</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Ibrahim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Waıss</forename><surname>Azizian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gauthier</forename><surname>Gidel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Mitliagkas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4583" to="4593" />
		</imprint>
	</monogr>
	<note>Not cited.</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Finite regret and cycles with fixed step-size via alternating gradient descent-ascent</title>
		<author>
			<persName><forename type="first">Gauthier</forename><surname>James P Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgios</forename><surname>Gidel</surname></persName>
		</author>
		<author>
			<persName><surname>Piliouras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Learning Theory</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="391" to="407" />
		</imprint>
	</monogr>
	<note>Not cited.</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">What is local optimality in nonconvex-nonconcave minimax optimization</title>
		<author>
			<persName><forename type="first">Chi</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Praneeth</forename><surname>Netrapalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4880" to="4889" />
		</imprint>
	</monogr>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Solving a class of non-convex min-max games using iterative first order methods</title>
		<author>
			<persName><forename type="first">Maziar</forename><surname>Maher Nouiehed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianjian</forename><surname>Sanjabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><forename type="middle">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meisam</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>Razaviyayn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="14934" to="14942" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<author>
			<persName><forename type="first">Guojun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Poupart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaoliang</forename><surname>Yu</surname></persName>
		</author>
		<title level="m">Optimality and stability in non-convex smooth games. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page">2002</biblScope>
		</imprint>
	</monogr>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Accelerating smooth games by manipulating spectral shapes</title>
		<author>
			<persName><forename type="first">Waïss</forename><surname>Azizian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Damien</forename><surname>Scieur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Mitliagkas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Lacoste-Julien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gauthier</forename><surname>Gidel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.00602</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Average-case acceleration for bilinear games and normal matrices</title>
		<author>
			<persName><forename type="first">Carles</forename><surname>Domingo-Enrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabian</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Damien</forename><surname>Scieur</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.02076</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Convergence of gradient methods on bilinear zero-sum games</title>
		<author>
			<persName><forename type="first">Guojun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaoliang</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Stochastic hamiltonian gradient methods for smooth games</title>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Loizou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Berard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexia</forename><surname>Jolicoeur-Martineau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Lacoste-Julien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Mitliagkas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6370" to="6381" />
		</imprint>
	</monogr>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Towards better understanding of adaptive gradient algorithms in generative adversarial nets</title>
		<author>
			<persName><forename type="first">Mingrui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youssef</forename><surname>Mroueh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerret</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Payel</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianbao</forename><surname>Yang</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=SJxIm0VtwH" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Training gans with centripetal acceleration</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu-Hong</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizhi</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optimization Methods and Software</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="955" to="973" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Not cited.</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Multi-objective training of generative adversarial networks with multiple discriminators</title>
		<author>
			<persName><forename type="first">Isabela</forename><surname>Albuquerque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">João</forename><surname>Monteiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thang</forename><surname>Doan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Breandan</forename><surname>Considine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiago</forename><surname>Falk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Mitliagkas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="202" to="211" />
		</imprint>
	</monogr>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Finding mixed nash equilibria of generative adversarial networks</title>
		<author>
			<persName><forename type="first">Ya-Ping</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Volkan</forename><surname>Cevher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2810" to="2819" />
		</imprint>
	</monogr>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Unrolled generative adversarial networks</title>
		<author>
			<persName><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02163</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Training generative adversarial networks by solving ordinary differential equations</title>
		<author>
			<persName><forename type="first">Chongli</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jost</forename><surname>Tobias Springenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.15040</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<author>
			<persName><forename type="first">Florian</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongkai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anima</forename><surname>Anandkumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.05852</idno>
		<title level="m">Implicit competitive regularization in gans</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Not cited.</note>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<author>
			<persName><forename type="first">Alexia</forename><surname>Jolicoeur-Martineau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Mitliagkas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.06922</idno>
		<title level="m">Connections between support vector machines, wasserstein distance and gradient-penalty gans</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">A variational inequality perspective on generative adversarial networks</title>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Gauthier Gidel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaëtan</forename><surname>Berard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Vignoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><surname>Lacoste-Julien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Reducing noise in gan training with variance reduced extragradient</title>
		<author>
			<persName><forename type="first">Tatjana</forename><surname>Chavdarova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gauthier</forename><surname>Gidel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francois</forename><surname>Fleuret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Lacoste-Julien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on Neural Information Processing Systems, number CONF</title>
		<meeting>the international conference on Neural Information Processing Systems, number CONF</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Cited on page 9</note>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Improved techniques for training GANs</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vicki</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2234" to="2242" />
		</imprint>
	</monogr>
	<note>Cited on page 15</note>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<author>
			<persName><forename type="first">Simon</forename><surname>Foucart</surname></persName>
		</author>
		<ptr target="https://www.math.drexel.edu/~foucart/TeachingFiles/F12/M504Lect6.pdf" />
		<title level="m">Matrix norm and spectral radius</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2020" to="2025" />
		</imprint>
	</monogr>
	<note>Cited on page 17</note>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">P</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lieven</forename><surname>Vandenberghe</surname></persName>
		</author>
		<title level="m">Convex optimization</title>
		<imprint>
			<publisher>Cambridge university press</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>Cited on page 19</note>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Digital selection and analogue amplification coexist in a cortex-inspired silicon circuit</title>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Richard Hr Hahnloser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Misha</forename><forename type="middle">A</forename><surname>Sarpeshkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rodney</forename><forename type="middle">J</forename><surname>Mahowald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Douglas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seung</forename><surname>Sebastian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">405</biblScope>
			<biblScope unit="issue">6789</biblScope>
			<biblScope unit="page" from="947" to="951" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note>Cited on page 21</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
