The research on complex momentum for optimization in differentiable games presents a significant advancement in the field of machine learning, particularly in the context of adversarial settings like Generative Adversarial Networks (GANs). Below is a detailed technical explanation of the researchers' decisions regarding various aspects of their work:

### Complex Momentum Overview
The introduction of complex-valued momentum generalizes traditional gradient descent with momentum, allowing for more nuanced updates in optimization problems characterized by multiple players, such as in differentiable games. The rationale behind using complex momentum lies in its ability to capture both the magnitude and phase of updates, which can be particularly beneficial in scenarios where the optimization landscape is complex and multi-dimensional. This approach enables the algorithm to oscillate between adding and subtracting gradients, thus potentially improving convergence rates in adversarial settings.

### Convergence Proof
The researchers provide a convergence proof for bilinear zero-sum games under both simultaneous and alternating updates. This is crucial because classical momentum methods often struggle in purely adversarial contexts where the eigenvalues of the gradient vector field can be complex. By proving convergence in these scenarios, the researchers address a significant limitation of existing methods, demonstrating that their complex momentum approach can effectively navigate the challenges posed by the game's dynamics.

### Real-Valued Updates
Despite the use of complex momentum, the method ensures that the parameter updates remain real-valued. This compatibility with standard optimizers is essential for practical implementation, as it allows the new method to be integrated seamlessly into existing frameworks without requiring extensive modifications. The researchers achieve this by extracting the real part of the complex momentum during updates, thus maintaining the integrity of the optimization process while leveraging the benefits of complex analysis.

### Empirical Results
The empirical results presented in the research indicate that complex momentum leads to improved convergence in adversarial settings, such as GANs, without incurring additional computational costs. This is a significant finding, as it suggests that the new method can yield better solutions while remaining efficient. The researchers likely conducted extensive experiments to validate their claims, comparing the performance of their complex momentum approach against traditional methods and demonstrating its advantages in terms of convergence speed and solution quality.

### Complex-Valued Adam Variant
The introduction of a complex-valued variant of the Adam optimizer represents a practical extension of the researchers' work. By applying this variant to train BigGAN on CIFAR-10, they show that complex momentum can enhance performance metrics like inception scores. This extension is particularly valuable as Adam is widely used in deep learning, and providing a complex-valued version allows practitioners to leverage the benefits of complex momentum in a familiar optimization framework.

### Game Dynamics
The discussion on game dynamics emphasizes the necessity for convergence solutions in purely adversarial games, where classical methods often fail. The researchers highlight that many real-world applications, such as GANs, involve a mixture of cooperative and adversarial dynamics. By addressing these dynamics, the proposed method offers a more robust solution that can adapt to varying game conditions, thus broadening its applicability.

### Recurrently Linked Momentum
The concept of recurrently linked momentum, which involves multiple momentum buffers with negative coefficients, allows for a more flexible and robust convergence strategy. This setup enables the algorithm to handle different eigenspace mixtures effectively, which is particularly relevant in complex optimization landscapes. The researchers' decision to explore this approach stems from the need to create a method that can adapt to the intricacies of various game dynamics without sacrificing convergence properties.

### Momentum Coefficients
Introducing the phase (arg) of the momentum as a new optimizer parameter is a novel approach that aids in oscillating updates. This decision is grounded in the understanding that controlling the phase can help mitigate rotational dynamics during training, which is a common issue in adversarial settings. By allowing for oscillation, the researchers enhance the algorithm's ability to navigate the optimization landscape more effectively.

### Implementation in JAX
The provision of a JAX implementation example demonstrates the researchers' commitment to practical applicability. By highlighting the minimal changes required to incorporate complex momentum into existing stochastic gradient descent (SGD) frameworks, they make it easier for practitioners to adopt their method. This practical focus is essential for ensuring that the research has a tangible impact on the field.

### Simultaneous Updates
The emphasis on the method's ability to perform simultaneous updates effectively is crucial, as many deep learning applications benefit from this approach. By demonstrating that their complex momentum method can handle simultaneous updates, the researchers address a key limitation of classical methods, which often require sequential updates that can slow down convergence.

### Eigenvalue Considerations
The discussion on eigenvalues and their role in determining the behavior of momentum methods in cooperative versus adversarial games is a critical aspect of the research. By analyzing how eigenvalues influence convergence, the researchers provide valuable insights into the theoretical underpinnings of their method, reinforcing its validity and effectiveness in various game scenarios.

### Algorithmic Notation
The algorithmic notation provided for simultaneous updates with complex momentum succinctly captures the essence of the proposed method. The notation clearly delineates the update rules, making it easier for readers to understand and implement the algorithm in practice.

### Figures and