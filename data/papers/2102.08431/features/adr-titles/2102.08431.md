- Decision to generalize gradient descent with complex-valued momentum
- Choice of bilinear zero-sum games for theoretical convergence proof
- Adoption of simultaneous and alternating update strategies
- Implementation of complex-valued Adam variant
- Selection of recurrently linked momentum buffers
- Use of negative momentum coefficients for convergence in adversarial games
- Decision to focus on first-order methods for optimization
- Choice to utilize real-valued parameter updates
- Adoption of complex analysis for gaining intuitions
- Decision to implement in libraries supporting complex arithmetic
- Choice of optimizer parameters for robustness in different eigenspace mixtures
- Decision to empirically validate improvements in GAN training
- Selection of CIFAR-10 for testing BigGAN performance
- Decision to document limitations of existing momentum methods
- Choice to analyze the behavior of recurrently linked momentum setups
- Decision to simplify the implementation for practical use in deep learning frameworks