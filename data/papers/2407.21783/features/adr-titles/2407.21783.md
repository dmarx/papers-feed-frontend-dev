- Decision on model architecture (dense Transformer vs. mixture-of-experts)
- Choice of pre-training tasks (next-word prediction, captioning)
- Data curation and filtering methods for pre-training
- Selection of training corpus size and diversity
- Implementation of multilingual support strategies
- Approach to scaling model size and training duration
- Techniques for managing training complexity
- Post-training procedure design (SFT, RS, DPO)
- Quality assurance processes for pre-training and post-training data
- Heuristic filtering methods for low-quality document removal
- Use of model-based quality classifiers for data selection
- Integration of multimodal capabilities (image, video, speech)
- Design of vision and speech adapter training processes
- Strategies for handling personally identifiable information (PII)
- Decisions on safety measures and content filtering
- Release strategy for Llama 3 models and licensing considerations
- Evaluation metrics and benchmarks for model performance assessment
- Human evaluation methodologies for model comparison
- Balancing helpfulness and harmlessness in model outputs
- Experimental design for multimodal model capabilities