<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Social-RAG: Retrieving from Group Interactions to Socially Ground AI Generation</title>
				<funder ref="#_R4SRtPU">
					<orgName type="full">Allen Institute for Artificial Intelligence</orgName>
				</funder>
				<funder>
					<orgName type="full">Microsoft&apos;s New Future of Work Initiative</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-02-19">19 Feb 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ruotong</forename><surname>Wang</surname></persName>
							<email>ruotongw@cs.washington.edu</email>
						</author>
						<author>
							<persName><forename type="first">Xinyi</forename><surname>Zhou</surname></persName>
							<email>xzhou@cs.washington.edu</email>
						</author>
						<author>
							<persName><forename type="first">Lin</forename><surname>Qiu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Joseph</forename><forename type="middle">Chee</forename><surname>Chang</surname></persName>
							<email>josephc@allenai.org</email>
						</author>
						<author>
							<persName><forename type="first">Jonathan</forename><surname>Bragg</surname></persName>
							<email>jbragg@allenai.org</email>
						</author>
						<author>
							<persName><forename type="first">Amy</forename><forename type="middle">X</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Washington Seattle</orgName>
								<address>
									<settlement>Washington</settlement>
									<country>United States Xinyi Zhou</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Washington Seattle</orgName>
								<address>
									<settlement>Washington</settlement>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Lin Qiu</orgName>
								<orgName type="institution" key="instit2">University of Washington Seattle</orgName>
								<address>
									<settlement>Washington</settlement>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Joseph Chee Chang</orgName>
								<orgName type="institution" key="instit2">Allen Institute of AI Seattle</orgName>
								<address>
									<settlement>Washington</settlement>
									<country>United States Jonathan Bragg</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Allen Institute of AI Seattle</orgName>
								<address>
									<settlement>Washington</settlement>
									<country>United States Amy X. Zhang</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">University of Washington Seattle</orgName>
								<address>
									<settlement>Washington New York</settlement>
									<region>NY</region>
									<country>United States USA, 25 pages</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Social-RAG: Retrieving from Group Interactions to Socially Ground AI Generation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-02-19">19 Feb 2025</date>
						</imprint>
					</monogr>
					<idno type="MD5">A80737461A696FA2A9139586919952FD</idno>
					<idno type="DOI">10.1145/3706598.3713749</idno>
					<idno type="arXiv">arXiv:2411.02353v2[cs.HC]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-02-28T01:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>AI agent</term>
					<term>group communication</term>
					<term>retrieval augmented generation</term>
					<term>recommender systems</term>
					<term>large language models</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Figure 1: We introduce Social-RAG, a workflow for LLM-based AI agents to generate content aligned with group interests and norms.</p><p>Step 1 involves collecting and indexing the group's conversation history into a social knowledge base. When tasked with making a post, relevant item suggestions (e.g., papers) and signals (e.g., group's topical interests) are retrieved and ranked (Step 2). Social-RAG then feeds these signals as context into an LLM to generate a socially grounded message (Step 3). The message is posted to group channels, where it can collect feedback that also gets indexed (Step 4).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>AI-enabled agents are increasingly being deployed in online social environments, including group conversational and collaborative spaces. They serve as assistants, facilitators, or collaborators to support varied tasks such as conversation summarization <ref type="bibr" target="#b76">[77]</ref>, brainstorming <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b64">65]</ref>, and conflict resolution <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b67">68]</ref>. These agents often leverage AI to insert automated messages into group spaces where human-human conversation and interaction naturally occur; for instance, they can post messages to facilitate collaborative learning in group chat channels <ref type="bibr" target="#b6">[7]</ref> or post cues in brainstorming meetings to inspire new directions for discussion <ref type="bibr" target="#b57">[58]</ref>.</p><p>While these interjections may offer benefits such as providing useful information to groups or fostering prosocial group dynamics <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>, they can easily become unhelpful or even annoying to group members, who use the same space to communicate with each other <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7]</ref>. These systems often abide by rigid message templates and rules defined by system designers, limiting their ability to adapt their content to align with evolving group preferences and specific social contexts <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b40">41]</ref>. And when they inevitably fail, existing systems often do not provide easy ways for group members to give feedback in the moment <ref type="bibr" target="#b4">[5]</ref>. As a result, without proper integration into a group's social environment, AI-generated messages can be perceived as irrelevant <ref type="bibr" target="#b78">[79]</ref> or intrusive <ref type="bibr" target="#b54">[55]</ref>, eventually leading users to ignore the messages or even abandon the system <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b57">58]</ref>.</p><p>Recent advances in large language models (LLMs) can generate more flexible and human-like text than templated messages <ref type="bibr" target="#b71">[72]</ref>. However, these systems often lack the social knowledge required to align their generated content to group preferences. Retrievalaugmented generation (RAG) techniques augment LLMs by incorporating external knowledge that may not be part of the training data <ref type="bibr" target="#b35">[36]</ref>. We find that most RAG applications curate and retrieve factual knowledge from external sources (e.g., web content, domainspecific documents) to produce fact-based or domain-specific outputs <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b32">33]</ref>. Little work to date explores how to augment LLMs with social knowledge to generate contextually relevant and socially aligned output in multi-user environments.</p><p>In this work, we propose Social-RAG, a workflow for LLM-based AI agents that takes social signals (e.g., topical preferences) gleaned from prior interactions between group members and between members and the AI agent to contextualize and adapt the agent's generation (Figure <ref type="figure">1</ref>). Much like how traditional RAG pipelines use factual knowledge bases to improve factual grounding, Social-RAG retrieves and processes "social facts" from a social knowledge base to improve an agent's social grounding. As such knowledge can be difficult to ascertain without tedious user input <ref type="bibr" target="#b0">[1]</ref>, we instead leverage the rich history of social interactions between group members commonly stored in group spaces and devise strategies for parsing and retrieving meaningful social information from this history. Group spaces also have many affordances for members to give each other social feedback (e.g., reactions and replies) that can be repurposed for members to give feedback to the agent.</p><p>To test Social-RAG in a real-world social setting, we built Pa-perPing, an AI agent that proactively posts scholarly paper recommendations and LLM-generated explanations into group chat spaces dedicated to research labs or projects. We chose this test bed due to the collaborative nature of scientific research <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b30">31]</ref>,</p><p>where exchanging and discussing scholarly articles is common practice and important for conducting high-quality research <ref type="bibr" target="#b23">[24]</ref>; further, rapid growth in publications motivates researchers' need to identify relevant papers. Indeed, in two formative studies with 39 researchers, we found that researchers frequently recommend papers in group chats by targeting a specific member or relating them to prior conversations; they also leverage affordances such as emoji reactions and threaded replies to react to each other's recommendations. In addition to creating a rich repository for learning people's interests, this existing social behavior also informs PaperPing's design and how it selects relevant social signals.</p><p>PaperPing was deployed for three months in 18 pre-existing Slack channels with a range of social dynamics (e.g., number of participants and frequency of messages), with total exposure to over 500 researchers. We find that PaperPing effectively learns researchers' individual and group preferences with minimum upfront effort from users. Users considered its LLM-synthesized messages to be contextually relevant, outperforming generic paper summaries in explaining a paper recommendation to their group. Moreover, PaperPing fits into existing group practices without disrupting group dynamics and fosters the ability of users to reach common ground. Our deployment also surfaced areas needing additional investigation, such as how to balance group versus individual preferences. We conclude by discussing the broader implications of Social-RAG for designing more adaptive and socially aware AI systems in diverse collaborative settings as well as how to apply our strategies for social grounding in additional contexts.</p><p>In summary, our work contributes:</p><p>• A novel workflow, Social-RAG, for augmenting LLM-based AI agents with social knowledge extracted from past and ongoing group interactions, enabling agents to generate content aligned with the group's interests and norms. • PaperPing, an AI agent that uses the Social-RAG workflow to proactively post relevant scholarly paper recommendations to a group chat channel with LLM-generated explanations that are contextualized to the group. • Formative studies with 39 researchers that provide input on how researchers socially interact when discussing academic papers as well as their preferences for an AI agent that recommends papers, which we use to inform the design of PaperPing. • A field deployment of PaperPing on 18 Slack channels reaching over 500 researchers, demonstrating the effectiveness and limitations of Social-RAG in real-world contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK 2.1 AI-enabled Systems in Group Social Spaces</head><p>Interactive agents such as chatbots, conversational agents, and virtual assistants have been deployed in group spaces to aid team productivity, providing support on tasks such as conversation summarization <ref type="bibr" target="#b76">[77]</ref>, idea generation <ref type="bibr" target="#b57">[58]</ref>, and collaborative search <ref type="bibr" target="#b3">[4]</ref>. They also assist in enhancing group interpersonal dynamics, e.g., by supporting conflict resolution <ref type="bibr" target="#b17">[18]</ref> or encouraging balanced human participation <ref type="bibr" target="#b13">[14]</ref>. Increasingly, these agents appear as yet another member of a group, interjecting in group conversations to post messages offering facilitation support <ref type="bibr" target="#b13">[14]</ref> or sharing information to enhance decision-making <ref type="bibr" target="#b82">[83]</ref>.</p><p>Despite their benefits, AI interjections in group spaces can be perceived as disruptive due to the timing, relevance, and delivery of their content <ref type="bibr" target="#b4">[5]</ref>, affecting ongoing group discussion <ref type="bibr" target="#b82">[83]</ref>. Researchers have highlighted the importance of designing AI agents that are socially aware and capable of adapting to the context in which they operate <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b61">62]</ref>. Yet actually achieving this goal can be challenging due partly to the sociotechnical gap, a fundamental issue for computer-supported cooperative work (CSCW) systems that often lack the flexibility to reflect complex social needs <ref type="bibr" target="#b0">[1]</ref>.</p><p>Researchers have explored ways to build agents that are sensitive to group dynamics, such as member participation (e.g., speech frequency <ref type="bibr" target="#b14">[15]</ref>, gaze <ref type="bibr" target="#b55">[56]</ref>) and individual or collective preferences (e.g., opinions expressed <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>). Some research shows that agents that demonstrate their awareness of human behavior and learn from human behavior are perceived as more natural and trustworthy <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b79">80]</ref>, and thus more likely to positively affect team dynamics <ref type="bibr" target="#b82">[83]</ref>. Similarly, Avula et al. finds that proactive agents should provide clear justifications for their actions that can demonstrate their social awareness, as unprompted suggestions may not be immediately understood or valued by group members <ref type="bibr" target="#b4">[5]</ref>. However, developing socially aware AI agents remains challenging due to the complexity of human social interactions and the difficulty of fully capturing and responding to them through an AI system <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b57">58]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Strategies for Aligning AI Agents to a Group</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Direct Elicitation of Group Preferences.</head><p>A straightforward method to customize AI agents to a group's context is to allow users to explicitly indicate their preferences to agents. For example, Agarwal et al. developed an agent that polls group members' opinions before sending facilitation messages to the group <ref type="bibr" target="#b1">[2]</ref>. Conversational group recommendation systems also explicitly learn about users' goals through a multi-turn dialog <ref type="bibr" target="#b45">[46]</ref><ref type="bibr" target="#b46">[47]</ref><ref type="bibr" target="#b47">[48]</ref><ref type="bibr" target="#b69">70]</ref>. Studies that use this method show that continuous and interactive feedback mechanisms lead to better alignment with user expectations <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b18">19]</ref>.</p><p>However, explicit feedback often requires users to invest prohibitively high upfront effort, exclusively for the purpose of informing systems about their preferences. As a result, users see the benefits of the system only after substantial effort, making systems suffer from a 'cold start problem' and hindering their adoption <ref type="bibr" target="#b47">[48]</ref>. Moreover, frequent interactions in group spaces that are solely for steering the system could potentially disrupt group dynamics (e.g., a too frequent poll prompt) <ref type="bibr" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Learning Group Preferences from Activity Traces.</head><p>A unique asset of real-world groups is their rich group communication history, which captures the process of individual and team activities. As a result, researchers have explored using this history to make inferences about individual and group preferences <ref type="bibr" target="#b62">[63]</ref> and to inform interactive systems that facilitate team processes, such as peer evaluation <ref type="bibr" target="#b63">[64]</ref> and information summarization <ref type="bibr" target="#b77">[78]</ref>. Researchers have also explored the design of AI systems that leverage human social interaction. For instance, Krishna et al. showed that collective activity traces of whether users respond to agents' questions can teach an AI agent to ask socially appropriate questions <ref type="bibr" target="#b31">[32]</ref>. Others have explored providing agents with contextual information about a group gathered from documents and ongoing conversations to facilitate social awareness <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b50">51]</ref>.</p><p>Despite their potential, many current strategies for contextualizing agents were validated only in controlled lab environments <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b13">14]</ref> or using a Wizard-of-Oz approach <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b58">59]</ref>. Researchers have yet to explore how AI agents can continuously monitor group interactions to adapt their messages to suit the preferences of diverse teams in the wild. Our work takes this next step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Designing AI Agent</head><p>Behavior to Fit Social Norms. Many existing agents are developed with rule-based algorithms or pre-defined language templates that aim to universally apply to different deployment contexts as opposed to aligning to the social norms of that context <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b13">14]</ref>. As a result, agents can struggle to convince users of their relevance and utility <ref type="bibr" target="#b40">[41]</ref>. The capabilities of large language models (LLMs) for flexibly generating human-understandable text <ref type="bibr" target="#b51">[52]</ref> open up new potential for agents to integrate more naturally into multi-user shared spaces. Researchers have explored using LLMs to enable personalized interactions that cater to different individuals. For example, Ha et al. <ref type="bibr" target="#b19">[20]</ref> created personalized agent personas with distinct expertise to increase the relevance of the information shared with users. Lian et al. <ref type="bibr" target="#b37">[38]</ref> explored the potential for LLMs to act as personalized recommenders and to tailor explanations to individual user needs.</p><p>Despite this promise, integrating LLM agents into practical multiuser systems remains a challenge. Traditional LLM agents are trained or fine-tuned on datasets representing general world knowledge, which are not necessarily tailored to the preferences and backgrounds of specific groups. In fact, current LLMs predominantly focus on informational content instead of social factors <ref type="bibr" target="#b22">[23]</ref> and thus show limited abilities to reason about social knowledge (e.g., speaker intention, social proximity of speaker and receiver) <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b36">37]</ref>. Moreover, natural language processing (NLP) research has shown that LLMs often lack social intelligence (i.e., cognitive intelligence, situational intelligence, and behavioral intelligence) <ref type="bibr" target="#b71">[72]</ref>. These factors limit their capability to understand and interpret the dynamics of a group's conversation and subsequently generate responses that are natural to the group's context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4">Retrieval Augmented Generation (RAG).</head><p>One way to augment LLM generation with knowledge not in the training data is via retrieval augmented generation (RAG) <ref type="bibr" target="#b35">[36]</ref>. RAG was originally proposed to address the issue of LLMs lacking access to a constantly expanding and changing body of knowledge, leading to false information ("hallucinations") in the context of NLP tasks such as question answering <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b70">71]</ref> and fact checking <ref type="bibr" target="#b74">[75,</ref><ref type="bibr" target="#b80">81]</ref>. Therefore, most RAG systems are typically built using web data <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b70">71,</ref><ref type="bibr" target="#b80">81]</ref> or pre-compiled static document corpora or knowledge bases, such as Wikipedia <ref type="bibr" target="#b65">[66]</ref> or a domain-specific corpora <ref type="bibr">[26-28, 74, 75]</ref>. Leveraging information retrieval (IR) techniques such as BM25 <ref type="bibr" target="#b59">[60]</ref> or semantic embeddings <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b72">73]</ref>, these systems retrieve relevant documents to include in their prompts. A plethora of recent human-computer interaction (HCI) research leverages RAG to build interactive systems that more effectively support knowledgeintensive tasks, such as sensemaking <ref type="bibr" target="#b39">[40]</ref>, decision-making <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b73">74]</ref>, or brainstorming <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27]</ref>. However, scant research has explored how RAG can be used towards addressing the sociotechnical gap.</p><p>More closely related to our work, research has used RAG to personalize text generation by retrieving data from personal interaction histories <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b75">76]</ref>. However, these applications have been limited to individual users and often require explicit, textbased cues from past interactions to infer user needs <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b56">57]</ref>. In contrast, in group contexts, social knowledge is often implicitly embedded in observable social interactions (e.g., emoji reactions to messages) because explicit preference elicitation can be disruptive in shared spaces <ref type="bibr" target="#b1">[2]</ref>. As a result, additional inference is needed to interpret such implicit signals, and existing RAG techniques, such as embedding textual messages, retrieving based on textual similarity, or directly injecting group messages into prompt contexts, cannot capture and apply social knowledge effectively.</p><p>In contrast to prior work and informed by our study of specific user needs in a group setting, this paper proposes to (1) dynamically curate a database of social facts learned from past and ongoing interactions in an online group and (2) leverage RAG techniques to build an AI agent that can generate socially grounded messages to interact with group members.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">SOCIAL-RAG: SOCIALLY GROUNDING AI GENERATION VIA RETRIEVAL FROM GROUP INTERACTIONS</head><p>In the following, we describe design goals for our workflow that are drawn from prior work and through building, iterating on, and using a prototype AI agent (described in more detail in Section 4).</p><p>We then describe the steps of our workflow, including the curation of a social knowledge base gleaned from group interactions and the retrieval pipeline for real-time zero-shot learning for message generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Design Goals</head><p>Our design goals are informed by prior literature as well as a research through design (RtD) approach <ref type="bibr" target="#b81">[82]</ref>, where we iteratively designed and built a prototype LLM-based AI agent over the course of 18 months that we deployed to solicit user feedback in our own social spaces. In Section 4, we provide details of our final system and evaluation. Though we built the system for a specific task and social context, the process of iteratively working through design requirements helped us gain insights into the broader question of how to best leverage existing group social information and infrastructure to align an AI agent to a group. DG1: Contextualize suggestions in the group's social history. Research has shown that tailored explanations that convey the relevance of AI suggestions <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b38">39]</ref> and citations to past social interactions <ref type="bibr" target="#b11">[12]</ref> can improve users' trust in and acceptance of AI agents. With access to a group's social history, we can use the same approach to contextualize AI suggestions to the group.</p><p>DG2: Integrate AI content into the group without disturbing existing group social practices. Although the AI agent will be interacting with a group in its shared social space, it should not crowd out existing productive human-human interactions (e.g., by posting overly long messages). Poor integration could result in an undesirable group outcome, such as discouraging discussion or making users leave for other channels.</p><p>DG3: Minimize upfront user effort for specifying preferences to the AI and also enable continued improvement. Many existing AI agents require explicit preference choices from users (e.g., by polling users' opinions <ref type="bibr" target="#b1">[2]</ref>), which can be tedious. We can learn from prior group interaction data to determine preferences, reducing user effort needed to bootstrap the agent. We can also lower barriers to user feedback for additional adaptation by leveraging the existing affordances of the space and existing common behaviors of users.</p><p>DG4: Promote transparency of information shared between humans and the agent to maintain common ground in the group. Maintaining common ground is essential for productive asynchronous collaboration <ref type="bibr" target="#b48">[49]</ref>. Thus, agent communication to the group, even when targeted to specific members, should occur in the shared group space. Users' feedback to the agent should also be visible to others to ensure transparency and help group members learn and respect each other's preferences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Social-RAG Workflow</head><p>We now describe the steps of the Social-RAG workflow (Figure <ref type="figure">1</ref>) in detail and explain how they instantiate our four design goals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.2.1</head><p>Step 1: Collect and index content from group interactions to create a social knowledge base. The first step involves determining how to leverage a group's pre-existing interaction history to populate a social knowledge base, minimizing upfront user effort (DG3). Depending on the specific goal of the AI agent's interjection and technical feasibility, the scope of relevant items in the history could vary. For instance, given a bot that recommends the latest news items to a group that likes to discuss the news, prior messages discussing news-related topics and news articles posted by group members could be collected as an indication of group members' interests. In addition, group members' reactions and engagement around these messages could signal the preferences of more group members. For example, if a group chat had an active discussion about an article, then it is possible that another article on a similar topic could inspire future conversations.</p><p>After collecting relevant posts, they must be parsed to extract indexable items for an algorithm to retrieve since we found that simply providing snippets of raw conversation history as context to an LLM performed poorly. Items to be extracted could include any relevant information for suggestions, such as an article URL for a bot that recommends articles. How to index an item depends on what aspects of the item should be used to determine relevance. For instance, news articles could be indexed by the semantic embedding of the article title.</p><p>Next, each item is associated with additional information. Each item should initially be associated with the posts that mention it. Additional context, such as the sentiment of the message or reactions to it, could also be stored to better identify the direction of preference, as opposed to simply interest. Additional metadata about each item could be gathered from external data sources or through additional analysis (e.g., the publisher of an article or its main topics). Indexed items can also be associated with the group members that mention or interact with the entity so that the agent knows who in the group would be most interested.</p><p>This index can now be used to improve the underlying suggestions that the AI agent provides to better target the group. For instance, when recommending a new article to the group, a news recommendation bot could query the index to determine whether the article might be interesting to the group (i.e., if the group has discussed similar articles) and recommend only those articles that return the most results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.2.2</head><p>Step 2: Retrieve social signals from knowledge base and contextualize AI explanations. After the agent decides on a suggestion to post, it can use the social knowledge base to help explain the relevance of the suggestion to the group (DG1). We present three categories of social signals that can be retrieved and how those signals contextualize AI suggestions in different ways:</p><p>Cite relevant prior posts in group history. Given an index of items previously mentioned and the posts from which they came, the agent can retrieve a prior post discussing similar items. The agent could cite this prior message and its associated thread of discussion when suggesting a new item to explain its relevance. The citation could then link to the prior post, enabling members to investigate the connection and establish trust in the agent's suggestions; this is akin to how traditional RAG systems cite the sources from which they retrieved information in their generation. The ability to see older relevant discussions also reminds group members of what was already discussed to further establish common ground (DG4) for continuing discussion. For instance, an AI agent that makes automated pull requests (PRs) in a code repository with suggested code edits could link to prior PRs that recently edited the same piece of code or is attempting to fix the same problem.</p><p>Highlight relevant metadata in an explanation. Each item in our index can be associated with one or more pieces of metadata gathered from external data sources. From this information, the agent can determine what metadata is potentially interesting to the group by storing and retrieving counts of how often an item with that metadata was mentioned. For instance, if group members in the past have shared many news articles from a particular writer or publisher, they might be more interested in a new article if they know that it is also from that writer or publisher. Thus, when a new item is set to be suggested to the group, the agent can also determine whether any particular metadata about it should be mentioned when explaining the suggestion.</p><p>Mention relevant group members. Finally, each item in our index can be associated with one or more specific group members who posted about the item or reacted or responded to a post about that item. When a new item is set to be suggested, the agent can determine as a signal of interest which items it is most similar to and which group members interacted with those items. Additionally, it could use external data sources with other information about group members to determine connections to specific group members. Then, the AI agent can @-mention specific group members as another explanation of relevance when posting to the group. Alerting all group members of specific members' interests could potentially encourage them to interact with the agent's message in the channel and make them aware of each other's interests (DG4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.2.3</head><p>Step 3: Rank social signals and generate a succinct message for the AI agent to post. In this step, we gather all relevant social signals associated with a suggestion and combine them into a message for the agent to post. Our goal is to craft messages that naturally suit the existing human-human conversational cadence in the social space (DG2). To achieve this goal, we leverage LLMs (1) to flexibly generate a message in natural language mimicking existing group dialogue and (2) to summarize social signals in a succinct way to avoid overwhelming group members. We take the social signals gathered in the last step and the original suggested item and provide them as context to an LLM, along with instructions and examples of how the AI agent should provide its suggestion and explanation. For instance, the prompt could ask for a specific format, length, or tone. If the prior step resulted in many social signals retrieved, we can use heuristics to select one or a few most relevant signals to provide as context or simply provide all information to the LLM and let it determine what to retain to form a short explanation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.2.4</head><p>Step 4: Post generated message to social channel and collect and index group reactions. Finally, with an LLM generation in hand, the AI agent can post the message in the group channel for all members to see (DG4). At this point, as with any other humangenerated post, members can interact with the post, such as by reacting or replying to it. These interactions can also be collected and indexed (similar to how group member posts are collected and indexed in Step 1). Not only does enabling group reactions to the post serve as a way to further learn about other group members' preferences (DG4), but by leveraging the existing affordances of the social space, we provide an easy and more natural way to give feedback to the AI agent for additional adaptation (DG3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">THE PAPERPING SYSTEM</head><p>We implement the Social-RAG workflow in a system called Pa-perPing, which automates academic paper recommendations in a scholarly group chat context. We chose this as our test setting due to the highly collaborative nature of scientific research, which often involves regular, information-dense communication among collaborators <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b49">50]</ref>, much of which occurs today using digital tools. We also chose to focus on paper recommendations since academic papers play an important role in facilitating knowledge sharing, fostering collaboration, and informing decision making in scientific team communication. The process of discovering and searching through papers is often open ended and opportunistic <ref type="bibr" target="#b44">[45]</ref>. Finally, paper recommendations often come from social networks <ref type="bibr" target="#b66">[67]</ref>, and researchers commonly form groups for the purpose of sharing and exchanging relevant research literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Formative Studies</head><p>We first describe two formative studies we conducted with scholars to identify (1) if and how they use social channels to discuss and recommend papers to each other, and (2) their preferences for an automated paper recommendation bot. Findings from these studies motivate and inform the system design of PaperPing, including the specific social signals (e.g., paper metadata) we choose to capture about each paper and the design of automated messages (e.g., format, tone). Our study was reviewed and deemed exempt by our university's Institutional Review Board (IRB).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Procedure and Participants.</head><p>In our first study, we interviewed 13 researchers who regularly discuss research in group chat channels. The participants were part of research project and interest groups, such as a lab discussion channel, focused mainly in the areas of HCI and NLP. The interviews lasted 19 minutes to 1 hour, and we asked participants about their motivations and considerations when sharing scientific literature and their experiences with literature recommendations. We analyzed the interview transcripts using inductive coding and clustered the codes into common themes.</p><p>In the second study, we conducted a survey with 26 participants from two active research discussion channels on Slack, consisting of a mix of research scientists, professors, PhD students, and undergraduate students. In the survey, we asked participants to compare different styles of Slack messages that recommend academic papers in order to surface people's preferred message presentation in an academic Slack setting. These styles varied across several dimensions, including tone (neutral vs. enthusiastic, promotional language, humor), use of emojis, and formatting (single block of text vs. bulleted format, use of text highlighting such as bold). Finally, we asked participants to indicate their preferences for pairs of messages showcasing different styles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Results</head><p>. Researchers regularly share papers with each other in group chat. In project-specific channels, interviewees share papers that directly support specific goals, such as answering research method questions or illustrating ideas to team members. These shared papers play a crucial role in shaping the research project by providing potential citations, serving as model papers, and enhancing collaboration by ensuring consensus of perspective. In interest-based channels, papers are shared for their general relevance to the group's common interests; although not shared in response to specific questions, these papers spark new conversations and facilitate relationship building among like-minded researchers.</p><p>When sharing papers, researchers attempt to connect the papers with group context. Interviewees who post paper recommendations mentioned that they like to contextualize the recommendation in the discussion. For example, P1 often highlights specific quotes or explains reasons for sharing the paper. They also use @-mentions to draw the attention of relevant individuals to specific papers. Interviewees looked at prior papers that were shared and group engagement about them to determine what kinds of papers to share, how to share, and the frequency of sharing. However, some said it currently takes too much effort to craft a message explaining a paper recommendation, calling it "free labor." They are occasionally hesitant to write their own paper summaries since they often recommend papers without having fully read them and worry about providing an inaccurate summary. Some junior scholars also worry about interrupting group dynamics or taking too much space with papers that may be perceived to be low quality or irrelevant to their groups.</p><p>Researchers reading papers recommendations prefer short and neutral explanations. Survey participants overwhelmingly preferred straightforward and neutral Slack messages when introducing academic papers in their channels. Messages with minimal formatting and without text decoration or humor were favored, as seen in the strong preference for neutral tone (92.3%) and simple formatting (96.2%). Promotional language and humor were particularly unpopular, with only 15.4% and 7.7% of participants supporting those styles, respectively. While there was some division on emoji usage-undergraduates were more receptive (60%) compared to PhD-level participants (43%)-the overall trend leaned toward simplicity and clarity.</p><p>Researchers prefer quick ways to acknowledge paper recommendations. When responding to papers that others shared in chat, interviewees commonly use emojis and quick comments to indicate their interest as a way to show appreciation and encourage others to continue to share. Emojis are liked because they are "unobtrusive and don't take space. "</p><p>4.1.3 Summary. Our findings motivate the utility of a paper recommendation bot that posts in group chat since researchers already perform this activity but occasionally find it difficult to do so easily and succinctly. In terms of bot design, interviewees provide examples of ways they connect their recommendation to the group; these inform the social signals we implement into PaperPing from the Social-RAG workflow. In addition, our findings guide our effort to design bot interjections that are short and unobtrusive and to give feedback to the bot that is quick and easy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">PaperPing Example User Scenario</head><p>Figure <ref type="figure" target="#fig_0">2</ref> demonstrates how users interact with PaperPing. As an example scenario, imagine that Kara leads an interdisciplinary research group consisting of PhD students, postdocs, and undergraduate researchers. The group also shares common interests. To help the group keep current with the latest research, Kara encourages everyone to share and discuss relevant papers in their group chat on Slack. Upon learning about PaperPing, Kara introduces it to her group to help them stay informed about the latest literature without adding to their workload. She set the recommendation frequency to be once every other day. One day, PaperPing notifies the group of a new paper recommendation. The message includes a brief explanation that highlights the connection between the recommended paper and their recent chat, citing a previous discussion thread for reference. The message is also personalized with an @-mention to her postdoc Ryan since he has previously reacted positively to similar papers. Ryan views the linked previous discussion to gain more context and has some new thoughts about a question that confused the group in previous discussions. He shares his thoughts under the latest paper recommendation while @-mentioning other relevant students and up-voting the bot's post. Kara sees the discussion and contributes another paper that she recently encountered and thought relevant. The team continues to interact with PaperPing and with each other as recommendations arrive. Over time, the positive feedback and ongoing interactions from the group help PaperPing refine its knowledge of the team's preferences, recommending more relevant papers and providing more targeted explanations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">PaperPing Process and Features</head><p>Building on findings from our formative interviews and survey, we describe in more detail PaperPing's process and features specific to our academic paper recommendation use case (Figure <ref type="figure">3</ref>).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.3.1</head><p>Step 1. To create a social knowledge base from prior chat history, PaperPing parses prior messages to extract links to academic papers shared by others. It converts these links into an embedding for each paper to store in a vector database, along with the messages mentioning that paper, message authors, and when messages were posted. In addition, it collects users' emoji reactions to the message, noting which emojis have a positive versus negative sentiment (e.g., thumbs up as a positive reaction) and any comments in the thread under the message.</p><p>PaperPing also links this paper database with external data sources that provide additional relevant metadata. In particular, it collects author names on the paper, their affiliations, the papers they cite and that cite them, and the venue in which the paper is published. Finally, PaperPing optionally allows users to link their group chat account to their academic publication record, letting it know the user's affiliations and publication history.</p><p>When PaperPing prepares to make a recommendation, it sends to an off-the-shelf paper recommender system recent items from this paper database that have (1) received positive emoji reactions, or (2) one or more comments in response from a group member. (1) Connections from the new paper to previously shared papers in the chat channel, looking for potential topic overlaps, citation relationships, or common authorships. ( <ref type="formula">2</ref>) Metadata items about the paper, such as authors or publisher, that have some connection to prior interactions in the chat channel; for example, if an author of the new paper was previously mentioned in the group chat history, it will identify the author's name as a social signal. (3) Team members who might be interested in the paper based on their previous interactions in the chat channel. These align with the three types of social signals discussed in Section 3.2.2. If it retrieves many social signals from this step, PaperPing uses heuristics developed over several months of piloting to rank and select only a few that it deems the most important. See the Appendix for a detailed list of retrievable social signals implemented in PaperPing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Step 3.</head><p>As Figure <ref type="figure" target="#fig_3">4</ref> shows, PaperPing uses chains of LLM prompts to turn the retrieved information into a natural language explanation. The prompt chains are dynamically constructed based on the availability of social signals from Step 2. PaperPing uses one prompt for each group of social signals before using one final prompt to succinctly summarize the information and implement a friendly and informative tone. This approach lets the output address meaningful connections between the recommended paper and the channel context while reducing hallucinations. We iteratively developed these prompts by piloting our prototype in two channels we participate in that are not part of the deployment study. The Appendix provides the specific LLM prompts we used.</p><p>Our LLM prompt set instructs the generation to take the following format. The generation first introduces the paper using a contextualized explanation based on the preceding social signals. Whenever the explanation mentions a user, it will also @-mention the user, unless it has already done so recently. When there is a relevant previously mentioned paper, the explanation also cites the previous thread that mentions the paper; this citation is linked, allowing group members to easily view the previous thread. Finally, the explanation also provides the paper's meta information, such as title, author name, venue, etc., in a structured format separate from the contextualized explanation. The text design came from feedback from formative study participants and pilot users. For example, users indicated that they prefer to see keywords bolded in the explanation to help them skim through the text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.3.4</head><p>Step 4. The message gets posted in the group channel, after which group members can provide an emoji reaction or reply to the message to give feedback. Group members can adjust the frequency of recommendations to daily, once every other day, or weekly based on their individual preference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">PaperPing System Implementation</head><p>PaperPing is implemented as a Slack application, with recommendations arriving in the group conversation as chat messages from the PaperPing bot account. It is built with the Slack Web API. The backend server is built in Node.js and interfaces with a PostgresSQL database. PaperPing leverages the Semantic Scholar Recommendation API 1 to select paper recommendations based on a group's interests and prior interactions. To retrieve the paper's metadata, SPECTER embeddings for each paper <ref type="bibr" target="#b9">[10]</ref>, and citations from the citation graph, PaperPing uses the public Semantic Scholar Academic Graph API. Finally, PaperPing uses GPT4-turbo-preview through the OpenAI API for all text generation with an LLM.</p><p>1 <ref type="url" target="https://api.semanticscholar.org/api-docs/recommendations">https://api.semanticscholar.org/api-docs/recommendations</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">FIELD DEPLOYMENT</head><p>We conducted a three-month field study where we deployed Pa-perPing in 18 Slack channels, collectively reaching over 500 channel members. From these channels, we collected in-depth feedback from 28 members via exit interviews and questionnaires and an offline evaluation task. Three participants (P8, P23, P24) were members of multiple channels that installed PaperPing, while all others were in only one participating channel. All but one channel installed PaperPing for at least 3 months; members of that channel, who decided to discontinue the study after one week, were still invited to debrief about their experience, and their feedback is also reported below. Eleven channels continued to use PaperPing voluntarily for more than six months after the study concluded. The study was reviewed and deemed exempt by our university's IRB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Research Questions</head><p>Our research questions are based on our designs goals for Social-RAG (Section 3.1). We focus on identifying how channel members perceive and interact with PaperPing's suggestions and how Paper-Ping affects group dynamics. In particular, our research questions include:</p><p>•  Via social media advertisement and word-ofmouth, we recruited a total of 28 participants from 18 channels (Table <ref type="table" target="#tab_0">1</ref>) to participate in interviews for our deployment study, ranging from junior PhD students to professors across various domains (e.g., AI, HCI, NLP, Programming Languages). The channels included group research labs, reading groups, project teams, and course channels, with sizes ranging from 2 to over 200 members each. These channels had varying levels of paper-sharing activities prior to installing the bot, ranging from 0 to over 5 papers per week. We paid participants who participated in both the interview and offline evaluation (N=24) $50 Tango gift cards and those who participated in only the offline evaluation (N=4) $25 Tango gift cards.</p><p>Eighteen of our participants were interviewed before launching the tool in their channel. No participants were required to interact with PaperPing during the length of the study. We additionally recruited 10 participants for interviews after the tool had been installed in their channel for a period of time by sending recruitment messages to the channel. These participants included those who indicated that they had not thus far used PaperPing much.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Installing PaperPing in channels.</head><p>We invited participants who volunteered to be their channel's contact person to an onboarding session, where we explained PaperPing's key features and guided them through installation and setup. To set up, participants selected a recommendation frequency suited to their channel's norms (e.g., once a week). We also invited participants to share several papers in the channels to seed PaperPing if the channel did not have much of a conversation history. Upon installation, PaperPing introduced itself to the group with a brief message, highlighting core features such as link sharing and emoji reactions. During the study, we sent check-in surveys every few weeks to all paid participants. These surveys captured recent memorable positive and negative experiences, which we used in post-study interviews to help participants recall their experiences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.2.3</head><p>Exit interview and questionnaire. After using PaperPing for at least 3 months, we invited our 28 participants to reflect on their experience in an exit interview lasting 30-75 minutes. During the session, they first completed the offline evaluation task (below), after which they discussed their experience in a semi-structured interview focusing on their perceptions of PaperPing's alignment with their individual and group preferences and its impact on group dynamics.</p><p>Finally, they completed a questionnaire containing Likert scale questions about their overall satisfaction in and the usability of PaperPing. We developed survey questions by reviewing prior work on the evaluation of conversational AI tools <ref type="bibr" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.4">Offline evaluation task.</head><p>We designed an offline comparative experiment to examine the effect of different variations of messages on participants' experiences. In the task, we presented four variations of explanations for papers (see Figure <ref type="figure" target="#fig_6">5</ref>). Specifically, Condition 4 (LLM synthesis of social grounding information and paper summary) shows PaperPing's messages posted in the Slack channel. Condition 1 (TLDR), Condition 2 (social grounding information presented in template form), Condition 3 (social grounding information and paper summary information presented in template form) each explore a different component of a generated message and their effects on users' perception. Each participant was asked to evaluate five papers that were randomly selected from the recommendations that they had received in the channel. Each paper was shown in four variations (Figure <ref type="figure" target="#fig_6">5</ref>), presented in random order. For each variation, participants rated Likert scale questions, such as whether the explanation was concise, interesting, or helped them understand the relevance to the group. After seeing all four variations, they selected the variations that best suited their own and group preferences, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Data Collection and Analysis</head><p>5.3.1 Qualitative coding for exit interviews. We took detailed memos during the interview process and discussed emerging themes in regular project meetings. We used Dovetail 2 to transcribe the interviews, which produced transcriptions that were linked to audio and video recordings. During the coding process, we referred back to the original video recordings when transcripts were ambiguous or inaccurate. We analyzed the data following the guidance of reflective thematic analysis <ref type="bibr" target="#b5">[6]</ref>, wherein we first developed codes based on the research questions and emerging themes in the memos and added new codes as they emerged in the analysis process. The final codebook contained 35 codes focused on: alignment of recommendations with participants' preferences, the effectiveness of the social signals, and PaperPing's impact on social dynamics; examples include: relevance to individual preference, conciseness of explanations, and individual willingness to engage with PaperPing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Statistical analysis of offline evaluation task ratings.</head><p>PaperPing made 832 recommendations in 18 channels during the deployment study. We randomly selected 136 of these papers and collected 540 observations from 28 participants in the offline evaluation task. Participants' ratings for this task were treated as ordinal variables and analyzed using a mixed ordinal logistic regression, where variations were fixed effects and participants were treated as random effects. We calculated the pairwise differences between the four conditions and applied Tukey correction. We also applied a Holm correction for testing multiple hypotheses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">Usage logs. To gain insight into how people interact with</head><p>PaperPing in real-world settings, we collected and analyzed paperrelated activities (e.g., reactions and comments to shared papers) within each channel, until all participants in the channel had completed the offline evaluation tasks and exit interviews. Notably, while we captured activities around papers shared via common academic platforms (e.g., ACM Digital Library, Semantic Scholar, arXiv), we were unable to track papers shared through social media links (e.g., X, LinkedIn posts).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1">PaperPing effectively learns individual and group preferences with minimal user effort (DG1, DG3).</head><p>PaperPing recommends papers that suit individual and group preferences and that directly benefit ongoing research. PaperPing's messages were considered relevant and aligned well with researchers' personal and group preferences. In the offline evaluation, 59.6% of the 136 reviewed recommendations were marked as relevant to participants' individual preferences, and 75.7% were marked as relevant to groups' preferences (Figure <ref type="figure" target="#fig_7">6</ref>). Moreover, 82% of participants agreed that PaperPing helped them discover papers they would not have found otherwise. Over half (54%) of the participants thought PaperPing's suggestions aligned with their interests, which is comparable to those who consider recommendations from other channel members to be relevant. In fact, PaperPing's suggestions were able to directly benefit researchers' ongoing research. Participants considered benchmark papers suggested by PaperPing 2 <ref type="url" target="https://dovetail.com/">https://dovetail.com/</ref> in their research (P8, P11): "We definitely use the papers that are suggested." Several participants (P5, P15, P16) appreciated PaperPing's ability to surface relevant papers in fast-moving fields. Compared to general-purpose literature discovery tools, PaperPing was considered more helpful since it is "seeded" and "ha[s] a good sense of the topics and research communities that I want to read papers from" (P3). P11 echoed: "With PaperPing we can focus our time and energy on our own paper." Indicating one's preference to PaperPing involves minimum effort. While PaperPing suggests relevant content that brings practical benefits, researchers agreed that indicating their interests to Paper-Ping was a natural process without being effortful. In the post-study questionnaire, 88% of participants agreed that using PaperPing required little effort. Sharing paper links in the channel was the most frequently used method to communicate interests to PaperPing. Participants appreciated that these feedback mechanisms fit into their existing workflows. P3 described reading and sharing papers in channels to be a "natural part of my day-to-day interaction of being on Slack." P4 also thought that reacting to papers in group chats is a natural interaction: "it feels social...other people also are interested in this, and they also react to this." P20 described group members' emoji reactions and comments as a form of "collective annotation. "</p><p>Limitations of existing feedback mechanisms. Despite promising results, we observed several limitations of PaperPing's existing feedback mechanisms. In less active groups, PaperPing struggled to gather sufficient signals, leading to less accurate recommendations. P10 mentioned: "there are definitely more interests that we have, but we just didn't put in [these in] the channel, so PaperPing wasn't able to pick up the signal." P5 and P13 both wished their group members had reacted to papers more frequently to better inform PaperPing about their groups' interests. Moreover, diverse group norms about using emojis could introduce ambiguity in the interpretation of the feedback. For example, P8 noted that in their channel, "the reaction was more for acknowledgment as opposed to indicating that the paper is very useful." Further, although PaperPing considers all papers shared in the past in order to have more data to be able to use, it struggled to reflect interest shifts in a timely manner: "It's hard to branch out into super new papers...it feels like the types of papers that [it] recommend[s] don't change too much over time" (P1).</p><p>For groups with diverse interests, the tension between individual and group interests also poses challenges. P4 observed: "even paper shared by my lab mates I don't relate to most of the time." As a result, PaperPing sometimes "overfits" to certain channel members' interests (P5). The misalignment could further turn into barriers for users with unique interests to share papers. P17 felt uncomfortable sharing papers that diverged from the group's primary focus, which represented the interests of only active members in the channel.</p><p>Despite recognizing PaperPing's usefulness, participants did not see it as a replacement for paper recommendations from other human channel members. As P3 describes: "PaperPing is not a replacement. It's an addition to the practice of people sharing with other people." Participants noted that PaperPing did complement human recommendations in its timeliness, broad coverage, and ability to tie back to previous discussions. P8 shared: "there are some papers that</p><p>4% 7% 25% 75% 75% 29% 21% 18% 46% 7% 7% 18% 86% 75% 54% 7% 18% 29% 4% 11% 18% 4% 89% 82% 54% 54% 7% 7% 29% 43% 18% 46% 50% 32% 29% Design Goal 1: Contextualize suggestions in group Design Goal 2: Integrate into group without disturbance Design 3: user efforts in preference elicitation Design 4: Establish common ground in group Strongly disagree Strongly agree Disagree Neutral Responses 25 0 50 100% PaperPing helps assess paper relevance PaperPing sufficient explanations People explain recs sufficiently I would recommend PaperPing to I want to continue PaperPing PaperPing integrates w/ group dynamics I often engage w/ people' s recs I often engage w/ PaperPing' s recs Interacting w/ PaperPing requires minimal efforts PaperPing helped me find new papers People' s recs align w/ my preferences PaperPing' s recs align w/ my preferences [PaperPing] suggested that I think people just missed or they didn't suggest it in the group. [PaperPing] helps have a better picture of the ongoing work related to the project." P4 observed that PaperPing offered more diverse and more timely recommendations than they would typically receive from human group members. However, participants continue to place more trust in human recommendations and find they want to verify recommendations from PaperPing. For example, P8's comparison of papers from PaperPing, arXiv, and other human members further illustrated this sentiment: "Pa-perPing is more helpful than browsing arXiv since the topics are more focused, but I still feel like I have to briefly judge whether I wanna actually read it or not. Whereas if a person who is familiar with our project suggested it, I would definitely read it without having to consider it again."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.2">Social explanations contextualize suggestions in group context (DG1).</head><p>Social signals in explanations help contextualize the recommendation in social context. To adapt AI suggestions to groups' social contexts, PaperPing explained each paper recommendation bysummarizing paper content and its relevance to the group. These explanations helped participants assess paper relevance (75% agree) and were perceived as sufficient by most participants (75% agree). In contrast, only 29% of participants' explanations provided by other channel members were sufficient (Figure <ref type="figure" target="#fig_7">6</ref>). In the offline evaluation, explanations with social signals (PaperPing's LLM synthesis and Template+TLDR) were rated as being significantly more helpful for conveying relevance to the group compared to the TLDRs, which only summarized paper content (𝑝 &lt; 0.001 for both comparisons; see Figure <ref type="figure" target="#fig_8">7</ref>).</p><p>In the interviews, participants shared how social signals helped them determine a paper's relevance. For example, P10 and P11 mentioned inferring paper relevance by using the importance of the linked paper (i.e., similar or cited by the recommended paper) and the presence of shared authors highlighted in the explanation. Others also mentioned using the channel engagement of the linked paper highlighted in the explanation to determine paper importance: "three thumbs up versus one neutral reaction makes a difference" (P4). P17 noted that social signals could be more helpful than paper content summaries in determining relevance: "I only need to glance at the people who are mentioned; I don't even need to go through the summary of the paper to know how relevant this paper is to me." This can be especially helpful for junior scholars like P21, who have less expertise on the topic compared to other channel members: "I don't have as much background on the main topic of the channel, so social signals were helpful for me in understanding why it'd be relevant for me to read." As P21 summarized: "social signals provided a more contextual way of understanding how the recommended paper related to a past paper."</p><p>Social signals also foster group members' trust in PaperPing's suggestions. P8 offered that social signals provided transparency into PaperPing's actions: "the fact that there are correct links to who reacted to or who suggested what helps you to trust that...the information is being considered in an accurate or relevant way." The association with specific group members highlighted in the explanations made P17 more receptive to PaperPing's suggestions not immediately relevant to them: "if PaperPing mentioned a person who's not in my small group or who I don't work with, I know this paper is not relevant to me but is relevant to the larger group." PaperPing's LLM synthesis is informative and natural but could lead to unreliable interpretation. Participants thought PaperPing's LLM-synthesized explanations could introduce paper content in personalized and contextualized ways and surface connections that The "template" messages (Condition 2) were consistently rated lower than PaperPing's LLM synthesis (Condition 4) and Template+TLDR (Condition 3) across all questions (𝑝&lt;0.001), except for conciseness. The "template" messages (Condition 2) were also rated lower than TLDR (Condition 1) across all questions (𝑝&lt;0.001), except for conciseness and on "explanation helps assess paper relevance to group.". Additionally, explanations with social signals (PaperPing's LLM synthesis (Condition 4) and Template+TLDR (Condition 3)) were rated significantly more helpful on "explanation helps assess paper relevance to group" compared to the TLDRs, which only summarized paper content (𝑝&lt;0.001 for both comparisons). We observed no statistical significance in other comparisons.</p><p>might otherwise be missed. P3 appreciated the LLM explanations that highlighted the novelty of the recommended paper beyond its findings. P5 and P13 valued the explanations and connections with their interests that they had not previously considered: "That made me decide that I could take a look at the recommended paper" (P13). However, some participants found LLM explanations to be too speculative or ambiguous. P10 noted that LLM synthesis could overly compress information, making the explanations unclear. P12 also found LLM explanations to be too generic: "It highlighted the similarities between two papers but can be too broad, like 'boosting computer visual models.' That's what every single paper is about." Indeed, the usefulness of social signals relies on the prerequisite of having a clear summary of the paper's content. This is evident in our offline evaluation, where the template condition (Condition 2) was consistently rated lower than both PaperPing's LLM synthesis (Condition 4) and Template with TLDR (Condition 3) across all evaluation questions except conciseness (𝑝 &lt; 0.001 for all comparisons; see Figure <ref type="figure" target="#fig_8">7</ref>). It was also rated lower than TLDR (Condition 1) on all questions (𝑝 &lt; 0.001) but conciseness and helpfulness in assessing relevance to the group. For many researchers, a clear summary of the paper is considered to be a "more reliable source of information" (P7) compared to inferred social signals (P1, P2, P7, P15).</p><p>Participants also noted that PaperPing's awareness of individual and group context could still be insufficient. For example, P10 found that explanations occasionally highlighted connections that were misaligned with their interests: "it has its own understanding of why and sometimes that leads to inaccuracy or irrelevance." P17 noted that PaperPing could miss group context cues and offer redundant information: "Everyone in the group already knows [popular machine learning model] and has been following the different versions. It's just like announcing a new iPhone; you don't really need to introduce the iPhone 14, iPhone 13 before that. You can just say, 'Here's the new iPhone 15. '" Participants P6 and P18 observed that the LLM's interpretation of emoji reactions in explanations could be awkward and inaccurate: "It feels like it's trying to derive the conclusions when not having enough data points." (P1); they would prefer to see the exact emoji to better understand the nuances of the reactions, especially given the diverse norms of emoji usage across groups. Due to these uncertainties in LLM interpretations, participants, including P10, preferred the TLDR+template explanations (Condition 3) because "It felt a little bit more objective." P14 also preferred forming their own interpretations after reading a paper instead of relying on PaperPing's interpretation.</p><p>Challenges involved in translating social explanations to personal relevance. Though social signals can help contextualize a paper's relevance to the group, participants P1 and P19 noted the challenge of translating them to their personal interests. As P19 explained: "If I decided to open up that paper, those reasons are all related to myself." Seeing PaperPing's social explanations related to other group members could help them infer the paper's relevance to themselves, but P1 considers it challenging to do the translation: "We have very diverse interests, and people have different standards for liking. I don't know how they relate to my own standards." Indeed, the utility of social signals in explanations varies across individual members in groups. P17 and P22 found references to past papers confusing if they had joined the channel later or forgotten the shared context: "To me that shared context was lost" (P17). P22 highlighted that "shared context from working in the same team towards the same goal" was essential for them to find information Notably, only activities around papers shared via common academic platforms (e.g., ACM Digital Library, Semantic Scholar) are captured. We were unable to track papers shared through social media links (e.g., X, LinkedIn posts).</p><p>about relevance to specific members to be helpful: "if I had not been there in person or if I didn't know these people, then I don't know how much it would help."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.4.3</head><p>For most groups, PaperPing does not disrupt existing social practices (DG2). PaperPing generally fits in well with a group's dynamics, as more than half of the participants believe (54% strongly agree or agree). 86% of participants indicated they would recommend PaperPing to others, and 75% expressed a desire to continue using PaperPing in their channels. In fact, 11 out of the 18 participating channels are still voluntarily using PaperPing as of this writing, more than six months after the conclusion of our study. As P4 described: "PaperPing feels natural to me. It doesn't disrupt the natural flow of the conversation in the channel." P1 described PaperPing as "an invited robot guest in the group's space, adopting to groups' norms rather than trying to make the group adapt to it." They elaborated: "It doesn't really feel out of place. It recommends things in a message and links back to previous threads just like any other member." P23 echoed the sentiment: "PaperPing's behavior didn't interfere with anything. It didn't disrupt the natural conversation." Indeed, the usage logs of Channel #7 and Channel #1, which P23, P1, and P4 belong to, respectively, along with other channels, indicate that members continued to engage with both papers shared by their peers and those recommended by PaperPing (Figure <ref type="figure" target="#fig_9">8</ref>(a) and (b)). Notably, in Channel #7, recommendations from human members remained the dominant source of paper sharing, whereas in Channel #1, PaperPing became the primary source of paper recommendations.</p><p>P4 appreciated the pace of posting: "The frequency is nice. I didn't feel like I was annoyed by the bot or anything." P8 and P11 noted that PaperPing's contextualized, natural language explanations made it feel more human. Participants including P16 and P21 also liked the concise and stylized summary with key information bolded: "I like bolded text in the explanations. [It is] especially helpful for Slack messages, allowing me to skim it first and then...decide if you want to read it." (P21) However, other participants found PaperPing's explanations could be verbose: "If there's a huge chunk of text in Slack, I tend to glance at the first sentence or maybe word. If it's not important, then I just dismiss it." (P15). The chunk of text could potentially bury human conversations if not posted at an ideal time (P23). This highlights a limitation of PaperPing that emerged in the field study, which we observed in two participating channels (Figure <ref type="figure" target="#fig_10">8(d)</ref>). While channel members could set the posting frequency, PaperPing's scheduled messages sometimes overwhelmed users, inadvertently crowding out human interactions, particularly when existing social norms around engagement are fragile. We discuss this limitation and its design implications in the Discussion Section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.4">PaperPing fosters common ground within groups (DG4).</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Social signals help facilitate the establishment of common ground.</head><p>PaperPing not only suggests useful and relevant information without disrupting channels but also plays a social-facilitator role by exposing group members to each other's interests and fostering common ground within groups. Participants noted that social signals, such as tagging relevant members and referencing prior discussions and engagements, could lead to potential follow-up interactions and foster group cohesion. As P14 reflected, "The social signal is the strongest aspect because it shows relevance to me or to my group, which helps me understand my group pattern to some extent." Participants appreciated how PaperPing's social signals facilitated group members learning more about each others' interests. As P3 shared, 'The recommendations and the social signals helped me realize my group members were interested in this type of research." Integrated into existing social spaces and practices, PaperPing encourages researchers to develop further interactions among each other. As P14 mentioned, "PaperPing is a part of a chat group with other members. I get to understand the interests of other people. It's a part of a practice that I already have in real life, and it has a lot of potential to assist and support in connecting better with [each] other." P10, a member in a large research lab channel, also sees PaperPing's explanations as opportunities to develop long-term collaborations: "Just having it [PaperPing] in the group is helpful for me to know what other people's interest is. Even the interest is slightly different, seeing some new things from related fields is helpful for me to learn what other people are working on, common things that we work on, and things that we could be chatting about."</p><p>PaperPing reinvigorates activity in inactive channels but does not necessarily establish norms. Several participating channels were lab groups that wanted to encourage paper-sharing but have not to date been successful. In these inactive channels where there was little conversation among members, PaperPing helped revive activity by posting recommendations and tagging members to prompt engagement. Participants felt that PaperPing "Keep[s] the channel alive" (P3, P14). As P14 described: "Whenever there was new message, I would look at it." P10 observed that PaperPing prompted more from channel members: "The channel hasn't been active at all half a year or more. PaperPing definitely prompts some other people to post. At least I'm seeing two or three other people who have posted on this channel." Indeed, P8 thought that PaperPing served as a reminder for other human members to engage: "It reminded people to send paper recommendations. We have always been encouraged to do that, but people tend[ed] to forget previously. Seeing PaperPing's recommendation every two days in the channel reminded people." The usage log of Channel #7, to which P8 belongs, shows that channel members' frequency of sharing and reacting to papers increased after PaperPing joined the channel (Figure <ref type="figure" target="#fig_10">8(a)</ref>). P13 added that PaperPing incentivized them to contribute more: "It made me feel my reactions or activities in the channel are being seen and are going somewhere, which gets me excited to contribute. It will be captured by PaperPing, and sometime later it is going to give me a reward." Participants also noted that tagging specific channel members is an effective way to keep people engaged; P5 usually skims through PaperPing's posts, but "If my name is tagged, I would read a little more into it." However, participants also noted that PaperPing did not establish new norms, such as having discussions about papers in groups, that were not previously established practices. Only 25% of the participants self-reported often engaging with PaperPing's recommendations, compared to 50% of the participants who self-reported often engaging with other human recommendations (Figure <ref type="figure" target="#fig_7">6</ref>). P15 observed that although PaperPing was helpful in suggesting relevant papers, this did not lead to more paper discussions in the channel. In fact, several other channels also show a similar engagement pattern with Channel #4, to which P15 belongs (see Figure <ref type="figure" target="#fig_10">8(c)</ref>). These channels often have little social history or established norms, with several created right before the study or inactive for an extended period of time. Instead of fostering a social space, these groups used PaperPing to create a feed of paper recommendations, which members checked regularly but only engaged with passively. The lack of extrinsic incentives could be one reason for less engagement with PaperPing's recommendation. Although we disclosed PaperPing's feedback mechanism to the whole group upon installation, P8 noted that some group members could be unaware that their engagement could inform future recommendations and thus were not incentivized to engage. Even when aware of the mechanism, participants could still be hesitant to engage because of the lack of potential follow-up interactions with PaperPing: "I know PaperPing won't respond." Participants also agreed that respected human members were more effective at encouraging engagement than PaperPing alone. P4 observed that their channel became more receptive to PaperPing's recommendations and had more engagement after their advisor reacted to one of the posts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION</head><p>Our evaluations of PaperPing showed that an agent that is augmented with Social-RAG can deliver contextually relevant and socially aligned messages. PaperPing's strategies to convey relevance to groups, such as referencing prior discussions and highlighting group members' interests, effectively contextualized the message to suit group social norms (DG1). Its ability to learn interests based on past paper sharing history and input ongoing feedback via emoji reactions, comments, and shared links let users provide continuous feedback with minimal effort (DG3). Users' interactions with Pa-perPing (e.g., receiving messages in group chats) naturally suited their existing social practices (DG2) and helped them understand other group members' interests, occasionally even reviving group activity (DG4).</p><p>Nonetheless, participants expressed interest in even more nuanced levels of social awareness, such as improvements in distinguishing between group and individual preferences (DG1), tailoring the verbosity and tone of messages based on group norms (DG2), and enabling more group-specific feedback mechanisms (DG3). Based on our findings, we discuss the implications for future systems that plan to support socially nuanced text generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Bootstrapping Social Grounding with Past and Ongoing Group Interactions</head><p>The use of past and ongoing group interactions as a basis for social grounding is a core advantage of Social-RAG. In contrast to explicit preference elicitation, which requires significant user effort <ref type="bibr" target="#b47">[48]</ref> and risks disrupting group dynamics <ref type="bibr" target="#b1">[2]</ref>, Social-RAG infers user preferences from past and ongoing group social interactions without requiring additional user labor. Leveraging collected user preferences, or social facts, Social-RAG uses an LLM to generate contextually relevant messages. For this, we developed techniques to curate and maintain a social knowledge base from past and ongoing group interactions. For example, the PaperPing system preserves the connection between extracted items (e.g., shared papers) and their social contexts (e.g., reactions and comments from others) when indexing group conversation history into the social knowledge base. These preserved connections enable further social inference in the Social-RAG workflow. We also proposed complementing the off-the-shelf retrieval methods typically used in traditional RAG systems (e.g., semantic embeddings <ref type="bibr" target="#b35">[36]</ref>) with empirically validated heuristics to guide the retrieval and interpretation of social knowledge. This hybrid approach, which combines heuristics with off-the-shelf embedding methods, is also starting to show promise in recent RAG applications in other contexts that require more complex reasoning (e.g., UI linting <ref type="bibr" target="#b42">[43]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Costs and Benefits of Different Levels of Group Social Grounding</head><p>Grounding systems in their social contexts has been highlighted as a major design requirement for both classic social computing systems <ref type="bibr" target="#b0">[1]</ref> and recent LLM-powered systems <ref type="bibr" target="#b68">[69]</ref>. However, realizing and implementing social grounding effectively remains an open challenge <ref type="bibr" target="#b68">[69]</ref>. We contribute to this ongoing discussion by reflecting on the different levels of social grounding of generated text in a group setting based on our experience of developing Social-RAG and implementing PaperPing. Different levels may require different amounts of resources and considerations and could potentially lead to different benefits.</p><p>No social grounding. At the lowest level, a one-size-fits-all system could apply uniform behavior across all groups, relying on generic templates or heuristics (e.g., generate template text that is likely acceptable across all settings). This level of grounding is resource friendly and predictable, but it lacks the ability to adapt to specific social contexts.</p><p>Category-level social grounding. A system could pre-define more detailed rule-based heuristics to generate content for groups based on their broad characteristics, informed by empirical observations. For example, in the deployment of PaperPing, we observed that groups working on active research projects would prefer exhaustively exploring closely related papers on certain topics, but interest-based reading groups would prefer exploring diverse sets of papers. However, it would be challenging for systems at this level to adapt to nuanced differences in similar categories.</p><p>Group-level social grounding. Further, a system could tailor its output to group-specific preferences and norms. In Social-RAG and PaperPing, we demonstrate that past and ongoing conversations in a group could effectively inform AI systems about the group's implicit topical preferences. A system at this level could also consider adapting the cadence and tone of generated messages to make them less intrusive to groups.</p><p>Individual-level grounding. Finally, a system could target and tailor its messages to specific group members (e.g., via mentions). While individual-level grounding could increase engagement and encourage understanding among group members, a system at this level needs to carefully design the balance between individual preferences and group preferences as well as carefully navigate power dynamics to behave in a socially appropriate way.</p><p>To more concretely illustrate the above, we can position Pa-perPing (i.e., Condition 4 in the offline evaluation) within this framework: Selecting which paper to recommend is grounded at the group-level by pooling all previously shared papers as the input to a recommender system. This gives group members access to papers of both common and individual interest. The generated explanations were tailored at both the group and individual level, with relevant members being mentioned. This promoted engagement with PaperPing as well as awareness of specific member's interests to all group members.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">The Tension of Group vs. Individual Preferences</head><p>As previously noted, a key design consideration for a socially grounded system is how to balance group-and individual-level personalization. Empirical observations from our 3 months deployment showed that within the same group, individuals might have different preferences for explanations relative to each other or even prefer different messages. For example, members who are more familiar with a recommended paper might prefer explanations that are more in-depth compared to other members. One way to address this tension is by aligning the generation with an "average group" preference. Future systems could consider experimenting with different ways to aggregate individual preferences that optimize various goals. Another option is to scaffold the explanation, e.g., starting with a more generic explanation tailored to all members and following with in-depth explanations tailored to individual members. However, if such modifications are made, the potential risk of diminishing common ground among members must be carefully considered (DG4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">The Impact of Proactive Agents on Group Social Dynamics</head><p>Another key design goal of a socially grounded system is ensuring that AI agents enhance rather than crowd out desirable humanhuman interactions. In our deployment of PaperPing, we observed varied impacts on group dynamics. In some cases (Figure <ref type="figure" target="#fig_9">8</ref>(a) and (b)), PaperPing had a positive influence. Channel members became more active in sharing and reacting to papers or offloading paper-sharing to PaperPing while continuing to engage through reactions or comments. This suggests that AI agents can play a beneficial role in group spaces by taking on tedious tasks while preserving human engagement. However, as seen in Figure <ref type="figure" target="#fig_9">8</ref>(c), the presence of PaperPing alone did not automatically foster new social norms (e.g., active paper discussion), particularly when human members primarily valued receiving recommendations over engaging in conversations. Moreover, in some cases (Figure <ref type="figure" target="#fig_9">8</ref>(d)), a mismatch between PaperPing's scheduled posts and the natural pace of group interactions could overwhelm the channel, leading to disengagement and abandonment of the space. Overall, these observed patterns point to a promising future of AI agents taking on pro-social roles in groups but highlight the importance of designing agents that can flexibly adapt their content and behavior (e.g., pacing and timing of posting) to different group dynamics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">LIMITATIONS</head><p>While our participants found PaperPing to be useful in real-world online chat groups, our field deployment also highlighted limitations of our current implementation of Social-RAG that can inform interesting future work. Specifically, observable social interactions in conversation history may not fully capture group dynamics or offline interactions, potentially leading to biased or inaccurate interpretations of preferences and norms. For example, in less active groups, PaperPing had fewer social signals to work with (e.g., shared papers, user reactions, and comments) and produced lower quality recommendations and explanations. Similarly, as group dynamics evolve over long periods of time, the relevance of past interactions may become stale or diminish even for active groups. Some participants reported finding it hard to shift to new topics, and some even created a new channel to indicate new interests to PaperPing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">FUTURE WORK</head><p>While this work focused on leveraging social signals to tailor the right information with the most relevant social context, future work could consider additionally tailoring the tone of explanations, how many details to include, group posting cadence, etc. Similarly, the current implementation of PaperPing focuses on aligning with a group's topical preferences, but one could also extend the workflow to account for, say, social hierarchies. The challenge would be to explore relevant social signals to extract from the group's interaction history and find ways to effectively use them as part of the context for LLMs to generate socially appropriate messages. Another area of future work would be to explore more flexible ways to adapt to a group's communication norms. For example, we currently hard-coded how the system interprets emoji feedback from users (e.g., a thumbs-up emoji indicates positive interest in the paper), a method informed by the norms observed in the formative interviews. However, our deployment study showed that a few individuals or groups did not follow this assumption (e.g., using a thumbs-up emoji only as an acknowledgment). Future work could explore how agents could more flexibly interpret social signals based on observation of groups' past social interactions. In sum, the flexibility to ground different aspects of a system at varying levels offers significant opportunities for creating more socially aware and contextually relevant AI agents. However, it also requires thoughtful design choices and a deep understanding of the social dynamics occurring within target groups.</p><p>As with any system designed to be embedded in social spaces, learning from interactions introduces privacy concerns. One way to mitigate these is to limit the scope of what the system is allowed to learn from. For example, we made the conscious decision to allow PaperPing to access user interactions only on messages where a research paper was shared. This is a trade-off between privacy concerns and how well our system can learn from interactions between members. Future work could provide greater user control over which aspects of their interactions are used to inform AI-generated content, potentially through customizable privacy settings or explicit consent mechanisms.</p><p>Further, PaperPing does not currently allow users to manually insert into or edit the collected social signals. Future work could explore ways to encourage and facilitate user engagement in less active groups as well as complement Social-RAG with direct elicitation techniques to support scenarios where the group needed to make more drastic changes to its preferences (e.g., when switching focus to a new project.)</p><p>Finally, exploring Social-RAG in other collaborative spaces and scenarios that are rich with social interaction histories is also an exciting future direction. For example, in Reddit communities, a misinformation correction bot empowered by Social-RAG could generate explanations that are best suited to each community's norms in order to convey trust. Specifically, when retrieving external documents, the system could learn about the types of sources (e.g., governmental vs. journalistic) that are often shared and trusted by the community as indicated by the sentiment of replies; when generating posts, the system could learn from successful debunking strategies that were used in the past by members. Another example of a Social-RAG system could be a meeting summary tool that can generate summaries and tag the most relevant team members for awareness. The tool could analyze past documents to understand team members' interests based on signals, such as contribution history and viewing frequency, or analyze meeting information, such as speaking frequency in discussions of different topics or speaker roles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">CONCLUSION</head><p>This work introduced a novel LLM workflow, Social-RAG, that enables AI agents to ground their generation in the social context of group interactions. By retrieving and leveraging "social facts" from past and ongoing group interactions, Social-RAG enables AI agents to dynamically adapt their outputs to group norms and preferences with minimum user effort. We instantiated this workflow in Paper-Ping, an AI agent that recommends scholarly papers and generates contextually tailored explanations in research group chats. Our 3-month deployments of PaperPing in 18 Slack channels demonstrated Social-RAG's ability to adapt to diverse group dynamics, fostering trust and common ground while minimizing disruption to existing social practices. Overall, our work demonstrates Social-RAG's potential to address the social-technical gap in designing adaptive and socially aware AI systems by introducing strategies to retrieve implicit group dynamics and generate contextually aligned content. Social-RAG moves us closer to a future with a more natural and effective integration of AI agents in collaborative environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A PROMPTS DESIGNED FOR PAPERPING</head><p>To anonymize, social context information in the following examples is hypothetical. The paper abstracts in the example prompts have been shortened for readability in this appendix. The actual prompts contained the full abstracts.</p><p>Prompt 1 in Fig. <ref type="figure" target="#fig_3">4</ref> (before adaption):</p><p>1</p><p>You are a helpful assistant for paper summarization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>↩→ 2</head><p>The paper has the following details:</p><p>3 * Abstract: [ABSTRACT_OF_RECOMMENDED_PAPER] 4 * Authors: [AUTHORS_OF_RECOMMENDED_PAPER] 5 In your summarization, you must 6 * Congratulate the following authors: [AUTHOR_NAME_TO_CONGRATULATE]. ↩→ 7 * Mention the following authors: [AUTHOR_NAME_TO_HIGHLIGHT]. ↩→ 8 * Mention [AUTHOR_AFFILIATION_TO_HIGHLIGHT]. 9 * Mention the paper's conference or journal: [VENUE_TO_HIGHLIGHT]. ↩→ 10 * Keep your output less than [CHARACTER_LIMIT] characters. ↩→ 11 * Be informative. 12 * If applicable, be specific about the numbers in the abstract that may refer to the proposed method's performance. ↩→ ↩→ Example Prompt 1 (after adaption): 1 You are a helpful assistant for paper summarization. ↩→ 2 The paper has the following details: 3 * Abstract: {By simply composing prompts, developers can prototype novel generative applications...[remainder of the abstract omitted for readability]} ↩→ ↩→ ↩→ 4 * Authors: Tae Soo Kim, Yoonjoo Lee, Jamin Shin, Young-Ho Kim, Juho Kim ↩→ 5 In your summarization, you must 6 * Congratulate the following authors: Tae Soo Kim. ↩→ 7 * Mention the following authors: Juho Kim. 8 * Keep your output less than 350 characters. 9 * Be informative. 10 * If applicable, be specific about the numbers in the abstract that may refer to the proposed method's performance. ↩→ ↩→ Output of example Prompt 1: Congratulations to @tsk and team, including Juho Kim, on developing EvalLM! This system aids in refining LLM prompts by evaluating outputs against user-defined criteria, showing a 59% reduction in needed revisions. It enables examining twice as many outputs, enhancing prompt development efficiency. Prompt 2 in Fig. 4 (before adaption): 1 You are a helpful assistant. 2 Title: [TITLE_OF_RECOMMENDED_PAPER] 3 Abstract: [ABSTRACT_OF_RECOMMENDED_PAPER] 4 Title: [TITLE_OF_RELEVANT_PAPER] 5 Abstract: [ABSTRACT_OF_PREVIOUS_PAPER] 6 The first paragraph of your answer should explain and specify the relationship between [TITLE_OF_RECOMMENDED_PAPER] and [TITLE_OF_RELEVANT_PAPER]. Be informative. ↩→ ↩→ ↩→ 7 * In this first paragraph of your answer, you must explain and specify how [TITLE_OF_RECOMMENDED_PAPER] is related to [TITLE_OF_RELEVANT_PAPER] in one short sentence. ↩→ ↩→ ↩→ ↩→ 8 * In this first paragraph of your answer, you must start with "This paper might be related to [TITLE_OF_RELEVANT_PAPER] because". ↩→ ↩→ 9 * In this first paragraph of your answer, you must specify how [TITLE_OF_RECOMMENDED_PAPER] cites [TITLE_OF_RELEVANT_PAPER] in one short sentence. The content from [TITLE_OF_RECOMMENDED_PAPER] that cites [TITLE_OF_RELEVANT_PAPER]: [CITATION_CONTEXT]. ↩→ ↩→ ↩→ ↩→ ↩→ ↩→ 10 * In this first paragraph of your answer, you must mention the following shared authors of the two papers: [SHARED_AUTHOR_NAMES]. ↩→ ↩→ 11 * The first paragraph should have no more than [CHARACTER_LIMIT_P1] characters. ↩→ 12 The message from [USERNAME] who shared [TITLE_OF_RELEVANT_PAPER]: [MESSAGE] ↩→ 13 People's comments about [TITLE_OF_RELEVANT_PAPER]: [COMMENTS] ↩→ 14 People's reactions about [TITLE_OF_RELEVANT_PAPER]: [EMOJIS] ↩→ The second paragraph of your answer should specify what people think about [TITLE_OF_RELEVANT_PAPER] and who these people are. Be informative. ↩→ ↩→ ↩→ 16 * In this second paragraph of your answer, you must start with "thoughts about [TITLE_OF_RELEVANT_PAPER]". Note that user A 'cc' user B means that A thought [TITLE_OF_RELEVANT_PAPER] is related to B's research, projects, or interests. Thoughts would not be negative. ↩→ ↩→ ↩→ ↩→ ↩→ ↩→ 17 * In this second paragraph of your answer, you must appreciate that [USERNAME] shared [TITLE_OF_RELEVANT_PAPER]. ↩→ ↩→ 18 * In this second paragraph of your answer, you must NOT add in-line citations and citation numbers. ↩→ ↩→ 19 * The second paragraph should have no more than [CHARACTER_LIMIT_P2] characters. ↩→ 20 Your answer should replace [TITLE_OF_RECOMMENDED_PAPER] with "this paper". ↩→ ↩→ Example Prompt 2 (after adaption): 1 You are a helpful assistant. 2 Title: EvalLM: Interactive Evaluation of Large Language Model Prompts on User-Defined Criteria ↩→ ↩→ 3 Abstract: {By simply composing prompts, developers can prototype novel generative applications...[remainder of the abstract omitted for readability]} ↩→ ↩→ ↩→ 4 The first paragraph of your answer should explain and specify the relationship between EvalLM: Interactive Evaluation of Large Language Model Prompts on User-Defined Criteria and Herding AI Cats: Lessons from Designing a Chatbot by Prompting GPT-3. Be informative. ↩→ ↩→ ↩→ ↩→ ↩→ 5 * In this first paragraph of your answer, you must explain and specify how EvalLM: Interactive Evaluation of Large Language Model Prompts on User-Defined Criteria is related to Herding AI Cats: Lessons from Designing a Chatbot by Prompting GPT-3 in one short sentence. ↩→ ↩→ ↩→ ↩→ ↩→ ↩→ 6 * In this first paragraph of your answer, you must start with "This paper might be related to Herding AI Cats: Lessons from Designing a Chatbot by Prompting GPT-3 because". ↩→ ↩→ ↩→ 7 * In this first paragraph of your answer, you must specify how EvalLM: Interactive Evaluation of Large Language Model Prompts on User-Defined Criteria cites Herding AI Cats: Lessons from Designing a Chatbot by Prompting GPT-3 in one short sentence. The content from EvalLM: Interactive Evaluation of Large Language Model Prompts on User-Defined Criteria that cites Herding AI Cats: Lessons from Designing a Chatbot by Prompting GPT-3: {However, most designers (P1-7) mentioned how they were unsure about how they should revise their prompts' wellknown challenge with LLM prompts <ref type="bibr" target="#b71">[72]</ref>., However, as the space of possible natural language instructions is near infinite, designers need to test as many possibilities as possible to identify high-performing prompts <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b71">72]</ref>.", "As LLMs are non-deterministic and even partial changes in a prompt can significantly influence generated outputs <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b40">41]</ref>, designers need to iterate on their prompts multiple times to achieve satisfactory results <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b71">72,</ref><ref type="bibr" target="#b72">73]</ref>., to automatically generate, evaluate, and revise outputs that satisfy the criteria--without the designer needing to "herd" the LLM themselves <ref type="bibr" target="#b71">[72]</ref>.}.   5 Abstract: [ABSTRACT_OF_RELEVANT_USER_SHARED_PAPER] ↩→ 6 Your answer should explain and specify how [TITLE_OF_RECOMMENDED_PAPER] is related to and different from [TITLE_OF_PAPER_SHARED_BY_RELEVANT_USER] with no more than 300 characters. If two papers are irrelevant, you should answer "NONE". Your answer must start with "This paper is related to '[TITLE_OF_PAPER_SHARED_BY_RELEVANT_USER]' because both papers". Be informative. ↩→ ↩→ ↩→ ↩→ ↩→ ↩→ ↩→ ↩→ ↩→ Example Prompt 3 (after adaption): 1 You are a helpful assistant in finding the relationships between two papers. ↩→ 2 Title: EvalLM: Interactive Evaluation of Large Language Model Prompts on User-Defined Criteria ↩→ ↩→ 3 Abstract: {By simply composing prompts, developers can prototype novel generative applications...[remainder of the abstract omitted for readability]} ↩→ ↩→ ↩→ 4 Title: Safer-Instruct: Aligning Language Models with Automated Preference Data ↩→ 5 Abstract: {Reinforcement Learning from Human Feedback (RLHF) is a vital strategy for enhancing model...[remainder of the abstract omitted for readability]} ↩→ ↩→ ↩→ 6 Your answer should explain and specify how EvalLM: Interactive Evaluation of Large Language Model Prompts on User-Defined Criteria is related to and different from Safer-Instruct: Aligning Language Models with Automated Preference Data with no more than 300 characters. If two papers are irrelevant, you should answer "NONE". Your answer must start with "This paper is related to Safer-Instruct: Aligning Language Models with Automated Preference Data because both". Be informative. ↩→ ↩→ ↩→ ↩→ ↩→ ↩→ ↩→ ↩→ ↩→ ↩→ ↩→ Output of example Prompt 3: This paper is related to Safer-Instruct: Aligning Language Models with Automated Preference Data because both focus on improving LLMs' outputs. EvalLM refines prompts via user feedback, while Safer-Instruct automates preference data generation for safer AI.   -The text explains why a paper might be related to another paper or why a user might be interested in a paper, which is often after (does not include) the keywords such as "because" and "due to".</p><p>↩→ ↩→ ↩→ ↩→ 14 You should not bold the following text: 15 -[TITLE_OF_RELEVANT_PAPER] 16 -[TITLE_OF_PAPER_SHARED_BY_RELEVANT_USER] 17 -[RELEVANT_USER_SLACK_ID] Example Prompt 4 (after adaption): 1 You are a helpful assistant for paper summarization. ↩→ 2 {Congratulations to @tsk and team, including Juho Kim, on developing EvalLM! This system aids in refining LLM prompts by evaluating outputs against user-defined criteria, showing a 59% reduction in needed revisions. It enables examining twice as many outputs, enhancing prompt development efficiency. This paper might be interesting to @xinyiz because @xinyiz've liked Safer-Instruct: Aligning Language Models with Automated Preference Data; improving LLMs' outputs. EvalLM refines prompts via user feedback, while Safer-Instruct automates preference data generation for safer AI.} ↩→ ↩→ ↩→ ↩→ ↩→ ↩→ ↩→ ↩→ ↩→ ↩→ ↩→ ↩→ ↩→ 3 First, you are required to shorten the above content with no more than 386 characters. Note that: ↩→ ↩→ 4 -The shortened content must contain the following strings: Safer-Instruct: Aligning Language Models with Automated Preference Data ↩→ ↩→ ↩→ 5 -The shortened content must contain the following strings: @anonymity ↩→ 6 -Do not remove any person's name (with or without '@'), institution's name, number, and conference/journal's name. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>11</head><p>-The text explains why a paper might be related to another paper or why a user might be interested in a paper, which is often after (does not include) the keywords such as "because" and "due to".</p><p>↩→ ↩→ ↩→ ↩→ 12 You should not bold the following text: 13 -Safer-Instruct: Aligning Language Models with Automated Preference Data ↩→ 14 -@anonymity Output of example Prompt 4, where the title in blue is clickable and links to the article's Semantic Scholar page in our deployment: Congrats to @tsk, Juho Kim on EvalLM, reducing prompt revisions by 59% and doubling output examination. It refines LLM prompts with user feedback. This might interest @anonymity, who liked EvalLM: Interactive Evaluation of Large Language Model Prompts..., for its focus on improving LLM outputs through automated preference data for safer AI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B SOCIAL SIGNALS USED IN PAPERPING</head><p>See Table <ref type="table" target="#tab_6">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C NUMBERS OF INTERACTIONS IN EACH CHANNEL</head><p>See Table <ref type="table" target="#tab_7">3</ref>. Congrats @{UserSlackID} h2 -Was the paper's author mentioned recently in the channel?</p><p>{AuthorName} also authored {K} papers that you've discussed in the past three months in the channel h3 -Does the author's affiliation overlap with a channel member's affiliation?</p><p>A paper from {AuthorAffiliation} h4 -Was the paper's venue mentioned recently in the channel? (i.e., Does the venue show up at least once in the past 3 months among papers posted, reacted to, or replied to by at least one human user?) You've reacted positively to other papers from CHI Paper Connections (II) This paper might be related to another paper in the channel, because... h5 -What is the relationship between two papers? (i.e., Does one cite the other? Do they have shared authors? Are two papers semantically relevant?) Cites: The Participatory Turn in AI Design: Theoretical Foundations and the Current State of Practice (@anonymity shared in a thread), for its methodology: This shift in design strategy transformed the participatory design's user-centered goal from "consulting" to "ownership," aligning with the principles outlined in <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b24">25]</ref> h6 -How did channel members react and reply to another paper? (If two papers are relevant, such reactions and replies could infer how channel members would react and reply to the recommended paper.) Shared authors: 3 paper authors, Tae Soo Kim, Juho Kim, and Yoonjoo Lee, also contributed to Cells, Generators, and Lenses: Design Framework for Object Oriented Interaction with Large Language Models that @anonymity1 shared in a thread, with 1 reply from @anonymity2 ("I like that the paper... ") h7 -Was another paper authored by a channel member? Related paper: Redefining Qualitative Analysis in the AI Era: Utilizing ChatGPT for Efficient Thematic Analysis that @scholar shared in a thread which received 2 replies and 3 reactions User Connections (III) This paper might be interesting to someone in the channel, because... h8 -Is the paper relevant to a channel member? (i.e., Is the paper's semantic embedding similar to that of papers already of interest to a channel member?)</p><p>Possibly of interest to @anonymity h9 -What is the relationship between a user's interests and the recommended paper? (i.e., Has the user liked a previous paper that's similar? Cites or is cited by this paper? Shares the same authors?)</p><p>Possibly of interest to @anonymity, because... -you've liked several similar papers in the channel you've liked several of James's papers in the channel you've liked several CHI papers in the channel several of your publications are similar you've cited similar papers before </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A demonstration of how users interact with Paper-Ping. Channel members share paper links, react to papers shared by other members or PaperPing and comment on shared papers. After gathering and processing this information, PaperPing sends new contextually grounded paper recommendations, with explanations of how the recommended papers are relevant to the channel. It also provides links to previous related discussions and includes meta-information about the recommended papers in the recommendation message.</figDesc><graphic coords="6,324.59,83.68,226.98,393.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Step 1 :Figure 3 :</head><label>13</label><figDesc>Figure 3: The PaperPing implementation, leveraging the Social RAG workflow. PaperPing extracts relevant social information from two data sources: the Semantic Scholar knowledge base, providing paper content, paper-author connections, and citation graphs; and Slack chat history, which includes previously mentioned papers, emoji reactions, comments, and user interactions (Step 1). PaperPing then retrieves relevant social signals from the data using three heuristics (relevant metadata, the most similar and discussed prior paper in the chat, and the member most likely to be interested) developed over a three-month iterative design process (Step 2). Next, PaperPing uses chains of LLM prompts to turn the retrieved social signals into a natural language explanation (Step 3). Finally, PaperPing posts the message to research group channels, where group members can provide emoji reactions or reply to the message to give feedback (Step 4).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The PaperPing prompts pipeline (Condition 4). The pipeline starts with social signals leading to three prompts: Prompt 1 highlights paper content; Prompt 2 highlights relevance to a previous paper; and Prompt 3 highlights relevance to a channel member. Finally, outputs from these prompts feed into Prompt 4, which synthesizes the information and adjusts the style, resulting in the final output.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>4. 3 . 2</head><label>32</label><figDesc>Step 2. After accessing a paper, PaperPing next retrieves social signals related to it. It focuses on three groups of social signals:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><figDesc>RQ1: How effective and effortful are PaperPing's feedback mechanisms in eliciting individual and group interests? How relevant are PaperPing's suggestions? (DG3) • RQ2: How effective are the social explanations in contextualizing PaperPing's suggestions? (DG1) • RQ3: How does PaperPing affect existing social practices in the channels? (DG2) • RQ4: What impact do PaperPing's suggestions have on channels' establishing common ground? (DG4)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Four PaperPing conditions shown in the offline evaluation task and example explanations. Names are anonymized.</figDesc><graphic coords="10,53.80,83.68,504.39,206.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Results from post-study questionnaire. Responses are grouped based on the four design goals. We present the original questions posed by the questionnaire in the appendix.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Results of our offline evaluation. Error bars show standard errors of the mean (SEM).The "template" messages (Condition 2) were consistently rated lower than PaperPing's LLM synthesis (Condition 4) and Template+TLDR (Condition 3) across all questions (𝑝&lt;0.001), except for conciseness. The "template" messages (Condition 2) were also rated lower than TLDR (Condition 1) across all questions (𝑝&lt;0.001), except for conciseness and on "explanation helps assess paper relevance to group.". Additionally, explanations with social signals (PaperPing's LLM synthesis (Condition 4) and Template+TLDR (Condition 3)) were rated significantly more helpful on "explanation helps assess paper relevance to group" compared to the TLDRs, which only summarized paper content (𝑝&lt;0.001 for both comparisons). We observed no statistical significance in other comparisons.</figDesc><graphic coords="13,104.24,83.68,403.51,189.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :</head><label>8</label><figDesc>Figure8: Representitive patterns of usage PaperPing during the deployment study. The y-axis represents the cumulative counts of usage in channel, and the x-axis represents the days since PaperPing's first recommendation. Notably, only activities around papers shared via common academic platforms (e.g., ACM Digital Library, Semantic Scholar) are captured. We were unable to track papers shared through social media links (e.g., X, LinkedIn posts).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>8 *</head><label>8</label><figDesc>The first paragraph should have no more than 425 characters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>↩→ 9 Your 1</head><label>91</label><figDesc>answer should replace EvalLM: Interactive Evaluation of Large Language Model Prompts on User-Defined Criteria with "this paper".↩→ ↩→Output of example Prompt 2: This paper might be related to Herding AI Cats: Lessons from Designing a Chatbot by Prompting GPT-3 because it cites the challenges in revising prompts, the need for extensive testing, and the iterative nature of achieving satisfactory results, referencing the concept of "herding" LLMs as discussed in the cited work.Prompt 3 in Fig.4(before adaption):You are a helpful assistant in finding the relationships between two papers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>↩→ 2 Title: [TITLE_OF_RECOMMENDED_PAPER] 3 Abstract: [ABSTRACT_OF_RECOMMENDED_PAPER] 4</head><label>234</label><figDesc>Title:[TITLE_OF_PAPER_SHARED_BY_RELEVANT_USER]   </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Prompt 4 in Fig. 4 ( 1</head><label>41</label><figDesc>before adaption):You are a helpful assistant for paper summarization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>↩→ 2 [PROMPT_123_OUTPUTS] 3 First 4 - 5 - 6 - 7 - 8 - 9 - 11 You should only bold the following text: 12 -</head><label>234567891112</label><figDesc>, you are required to shorten the above content with no more than [CHARACTER_LIMIT] characters. Note that: ↩→ ↩→ The shortened content must contain the following strings: [TITLE_OF_RELEVANT_PAPER] ↩→ The shortened content must contain the following strings: [TITLE_OF_PAPER_SHARED_BY_RELEVANT_USER] ↩→ ↩→ The shortened content must contain the following strings: [RELEVANT_USER_SLACK_ID] ↩→ Two papers are mentioned in [PROMPT_2_OUTPUT]. When you specify people's reactions or comments about [TITLE_OF_RELEVANT_PAPER], you should focus more on who reacted or commented and how these reactions or comments infer the potential reactions or comments about another paper based on the two papers' similarities than people's reactions or comments about [TITLE_OF_RELEVANT_PAPER]. Do not remove any person's name (with or without '@'), institution's name, number, and conference/journal's name. ↩→ ↩→ Do not change the content's tone when it is low-confidence. ↩→ 10 Second, you are required to bold at most three key phrases of the shortened content by adding ONE '*' to the left of the bolded text and ONE '*' to the right of the bolded text. The text tells what a paper is about.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>13</head><label>13</label></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>↩→ ↩→ 7 - 8 9 10 -</head><label>78910</label><figDesc>Do not change the content's tone when it is low-confidence.↩→Second, you are required to bold at most three key phrases of the shortened content by adding ONE '*' to the left of the bolded text and ONE '*' to the right of the bolded text.You should only bold the following text:The text tells what a paper is about.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="1,89.11,247.33,433.75,174.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Participant information by channel type and recommendation frequency. Participants marked with an asterisk (*) participated asynchronously in the offline evaluation task without joining the exit interview. Duration counts the time from the installation of PaperPing until all participants in the channel had completed the study. While not counted in the study duration, 11 channels continued to use PaperPing voluntarily for more than six months after the study concluded.</figDesc><table><row><cell>Index Channel Type</cell><cell cols="2">Channel Size Frequency of Recommendation Study Duration (weeks) Participants</cell></row><row><cell>1 Lab channel</cell><cell>31-100 every-other-day</cell><cell>14 P1, P2, P4</cell></row><row><cell>2 Common interest</cell><cell>2-10 every-other-day</cell><cell>14 P3, P5</cell></row><row><cell>3 Lab channel</cell><cell>100+ weekly</cell><cell>21 P12, P17</cell></row><row><cell>4 Lab channel</cell><cell>31-100 weekly</cell><cell>18 P10, P15</cell></row><row><cell>5 Project</cell><cell>2-10 every-other-day</cell><cell>24 P8, P23</cell></row><row><cell>6 Project</cell><cell>2-10 every-other-day</cell><cell>24 P8, P23</cell></row><row><cell>7 Lab channel</cell><cell>10-30 every-other-day</cell><cell>24 P8, P23</cell></row><row><cell>8 Project</cell><cell>2-10 every-other-day</cell><cell>24 P8, P23</cell></row><row><cell>9 Lab channel</cell><cell>2-10 every-other-day</cell><cell>24 P14, P20</cell></row><row><cell>10 Project</cell><cell>2-10 daily</cell><cell>23 P11</cell></row><row><cell>11 Seminar</cell><cell>31-100 weekly</cell><cell>16 P16, P9</cell></row><row><cell>12 Seminar</cell><cell>31-100 every-other-day</cell><cell>23 P13, P18, P19</cell></row><row><cell>13 Common interest</cell><cell>10-30 weekly</cell><cell>10 P24</cell></row><row><cell>14 Lab channel</cell><cell>10-30 weekly</cell><cell>15 P24</cell></row><row><cell>15 Lab channel</cell><cell>10-30 daily</cell><cell>2 P6, P7</cell></row><row><cell>16 Common interest</cell><cell>10-30 weekly</cell><cell>23 P21. P25*</cell></row><row><cell>17 Common interest</cell><cell>10-30 weekly</cell><cell>24 P26*, P27*</cell></row><row><cell>18 Common interest</cell><cell>10-30 every-other-day-&gt;weekly</cell><cell>22 P22, P28*</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2 :</head><label>2</label><figDesc>Social signals used in PaperPingIs the paper's author a channel member? (i.e., Does the author show up at least once in the past 3 months among papers posted, reacted to, or replied to by at least one human user?)</figDesc><table><row><cell>Category</cell><cell>Heuristic</cell><cell>Example message</cell></row><row><cell></cell><cell>h1 -</cell><cell></cell></row><row><cell>Recommended Paper</cell><cell></cell><cell></cell></row><row><cell>Information (I) This</cell><cell></cell><cell></cell></row><row><cell>paper is about...</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 :</head><label>3</label><figDesc>Numbers of Interactions in Each Channel</figDesc><table><row><cell></cell><cell># human</cell><cell># human</cell><cell># emojis</cell><cell># emojis</cell><cell># comments</cell><cell># comments</cell><cell>#</cell></row><row><cell>Channel index</cell><cell>recs before</cell><cell>recs after</cell><cell>before</cell><cell>after</cell><cell>before</cell><cell>after</cell><cell>PaperPing</cell></row><row><cell></cell><cell>PaperPing</cell><cell>PaperPing</cell><cell>PaperPing</cell><cell>PaperPing</cell><cell>PaperPing</cell><cell>PaperPing</cell><cell>recs</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>We would like to thank the study participants for their valuable insights and the anonymous reviewers for their helpful feedback. We would also like to thank <rs type="person">Chuqiao Sun</rs> and <rs type="person">Yangtian Yan</rs> for their help in refining the figures in this paper. The work is supported by grants from the <rs type="funder">Allen Institute for Artificial Intelligence</rs> (<rs type="grantNumber">Ai2</rs>) and <rs type="funder">Microsoft's New Future of Work Initiative</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_R4SRtPU">
					<idno type="grant-number">Ai2</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<author>
			<persName><surname>Mark S Ackerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The intellectual challenge of CSCW: the gap between social requirements and technical feasibility</title>
		<imprint>
			<date type="published" when="2000">2000. 2000</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="179" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">Dhruv</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Farhana</forename><surname>Shahid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Vashistha</surname></persName>
		</author>
		<idno type="DOI">10.1145/3687030</idno>
		<ptr target="https://doi.org/10.1145/3687030" />
		<title level="m">Conversational Agents to Facilitate Deliberation on Harmful Content in WhatsApp Groups</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Embedding Search into a Conversational Platform to Support Collaborative Search</title>
		<author>
			<persName><forename type="first">Sandeep</forename><surname>Avula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Arguello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Capra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Dodson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhui</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filip</forename><surname>Radlinski</surname></persName>
		</author>
		<idno type="DOI">10.1145/3295750.3298928</idno>
		<ptr target="https://doi.org/10.1145/3295750.3298928" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Human Information Interaction and Retrieval (CHIIR &apos;19)</title>
		<meeting>the 2019 Conference on Human Information Interaction and Retrieval (CHIIR &apos;19)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="15" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">SearchBots: User Engagement with ChatBots during Collaborative Search</title>
		<author>
			<persName><forename type="first">Sandeep</forename><surname>Avula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gordon</forename><surname>Chadwick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Arguello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Capra</surname></persName>
		</author>
		<idno type="DOI">10.1145/3176349.3176380</idno>
		<ptr target="https://doi.org/10.1145/3176349.3176380" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Human Information Interaction &amp; Retrieval (CHIIR &apos;18)</title>
		<meeting>the 2018 Conference on Human Information Interaction &amp; Retrieval (CHIIR &apos;18)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="52" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The Effects of System Initiative during Conversational Collaborative Search</title>
		<author>
			<persName><forename type="first">Sandeep</forename><surname>Avula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bogeum</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Arguello</surname></persName>
		</author>
		<idno type="DOI">10.1145/3512913</idno>
		<ptr target="https://doi.org/10.1145/3512913" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">30</biblScope>
			<date type="published" when="2022-04">2022. April 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Reflecting on reflexive thematic analysis</title>
		<author>
			<persName><forename type="first">Virginia</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victoria</forename><surname>Clarke</surname></persName>
		</author>
		<idno type="DOI">10.1080/2159676X.2019.1628806</idno>
		<ptr target="https://doi.org/10.1080/2159676X.2019.1628806" />
	</analytic>
	<monogr>
		<title level="m">Publisher: Routledge _eprint</title>
		<imprint>
			<date type="published" when="2019-08">2019. Aug. 2019</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="589" to="597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Advancing Knowledge Together: Integrating Large Language Model-based Conversational AI in Small Group Collaborative Learning</title>
		<author>
			<persName><forename type="first">Zhenyao</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seehee</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nia</forename><surname>Nixon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shayan</forename><surname>Doroudi</surname></persName>
		</author>
		<idno type="DOI">10.1145/3613905.3650868</idno>
		<ptr target="https://doi.org/10.1145/3613905.3650868" />
	</analytic>
	<monogr>
		<title level="m">Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems (CHI EA &apos;24)</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Enhancing AI-Assisted Group Decision Making through LLM-Powered Devil&apos;s Advocate</title>
		<author>
			<persName><forename type="first">Chun-Wei</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuoran</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuoyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Yin</surname></persName>
		</author>
		<idno type="DOI">10.1145/3640543.3645199</idno>
		<ptr target="https://doi.org/10.1145/3640543.3645199" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Intelligent User Interfaces (IUI &apos;24)</title>
		<meeting>the 29th International Conference on Intelligent User Interfaces (IUI &apos;24)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="103" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Minje</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxin</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sagar</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Jurgens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Choi</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxin</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sagar</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Jurgens</surname></persName>
		</author>
		<ptr target="https://api.semanticscholar.org/CorpusID" />
		<title level="m">CorpusID:258865939 nd Social Knowledge? Evaluating the Sociability of Large Language Models with SocKET Benchmark. In Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">258865939</biblScope>
		</imprint>
	</monogr>
	<note>booktitle=Conference on Empirical Methods in Natural Language Processing, year=2023 Do LLMs Understa@inproceedingsChoi2023DoLU, title=Do LLMs Understand Social Knowledge? Evaluating the Sociability of Large Language Models with SocKET Benchmark</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.07180</idno>
		<title level="m">Specter: Document-level representation learning using citation-informed transformers</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Integrating Collaboration and Leadership in Conversational Group Recommender Systems</title>
		<author>
			<persName><forename type="first">David</forename><surname>Contreras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Salamó</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ludovico</forename><surname>Boratto</surname></persName>
		</author>
		<idno type="DOI">10.1145/3462759</idno>
		<ptr target="https://doi.org/10.1145/3462759" />
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1" to="41" />
			<date type="published" when="2021-08">2021. Aug. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Comparing How a Chatbot References User Utterances from Previous Chatting Sessions: An Investigation of Users&apos; Privacy Concerns and Perceptions</title>
		<author>
			<persName><forename type="first">Rhys</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi-Chieh</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><forename type="middle">Tsang</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>Ooi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Conference on Human-Agent Interaction</title>
		<meeting>the 11th International Conference on Human-Agent Interaction</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="105" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">AI Agents as Team Members: Effects on Satisfaction, Conflict, Trustworthiness, and Willingness to Work With</title>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">R</forename><surname>Dennis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akshat</forename><surname>Lakhiwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Agrim</forename><surname>Sachdeva</surname></persName>
		</author>
		<idno type="DOI">10.1080/07421222.2023.2196773</idno>
		<ptr target="https://doi.org/10.1080/07421222.2023.2196773" />
	</analytic>
	<monogr>
		<title level="m">Publisher: Routledge _eprint</title>
		<imprint>
			<date type="published" when="2023-04">2023. April 2023</date>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="307" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">How Should the Agent Communicate to the Group? Communication Strategies of a Conversational Agent in Group Chat Discussions</title>
		<author>
			<persName><forename type="first">Jin</forename><surname>Hyo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ha-Kyung</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaewook</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><forename type="middle">P</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>Bailey</surname></persName>
		</author>
		<idno type="DOI">10.1145/3555112</idno>
		<ptr target="https://doi.org/10.1145/3555112" />
	</analytic>
	<monogr>
		<title level="j">Proc. ACM Hum.-Comput. Interact</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">23</biblScope>
			<date type="published" when="2022-11">2022. Nov. 2022</date>
		</imprint>
	</monogr>
	<note>CSCW</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">To Err is AI: Imperfect Interventions and Repair in a Conversational Agent Facilitating Group Chat Discussions</title>
		<author>
			<persName><forename type="first">Jin</forename><surname>Hyo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ha-Kyung</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pooja</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaewook</forename><surname>Tetali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><forename type="middle">P</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>Bailey</surname></persName>
		</author>
		<idno type="DOI">10.1145/3579532</idno>
		<ptr target="https://doi.org/10.1145/3579532" />
	</analytic>
	<monogr>
		<title level="j">Proc. ACM Hum.-Comput. Interact</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">23</biblScope>
			<date type="published" when="2023-04">2023. April 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Expanding explainability: Towards social transparency in ai systems</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Upol Ehsan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Vera Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">O</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><forename type="middle">D</forename><surname>Riedl</surname></persName>
		</author>
		<author>
			<persName><surname>Weisz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 CHI conference on human factors in computing systems</title>
		<meeting>the 2021 CHI conference on human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">RARR: Researching and revising what language models say, using language models</title>
		<author>
			<persName><forename type="first">Luyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuyun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arun</forename><surname>Tejasvi Chaganty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yicheng</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ni</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongrae</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Da-Cheng</forename><surname>Juan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="16477" to="16508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">AI-Driven Mediation Strategies for Audience Depolarisation in Online Debates</title>
		<author>
			<persName><forename type="first">Jarod</forename><surname>Govers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduardo</forename><surname>Velloso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vassilis</forename><surname>Kostakos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jorge</forename><surname>Goncalves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Interactive multi-party critiquing for group recommendation</title>
		<author>
			<persName><forename type="first">Francesca</forename><surname>Guzzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robin</forename><surname>Burke</surname></persName>
		</author>
		<idno type="DOI">10.1145/2043932.2043980</idno>
		<ptr target="https://doi.org/10.1145/2043932.2043980" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth ACM conference on Recommender systems (RecSys &apos;11)</title>
		<meeting>the fifth ACM conference on Recommender systems (RecSys &apos;11)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="265" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">CloChat: Understanding How People Customize, Interact, and Experience Personas in Large Language Models</title>
		<author>
			<persName><forename type="first">Juhye</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyeon</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daeun</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinwook</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changhoon</forename><surname>Oh</surname></persName>
		</author>
		<idno type="DOI">10.1145/3613904.3642472</idno>
		<ptr target="https://doi.org/10.1145/3613904.3642472" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &apos;24)</title>
		<meeting>the CHI Conference on Human Factors in Computing Systems (CHI &apos;24)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">AI and the Future of Collaborative Work: Group Ideation with an LLM in a Virtual Canvas</title>
		<author>
			<persName><forename type="first">Jessica</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Houde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Darío</forename><surname>Andrés</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silva</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">I</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><forename type="middle">D</forename><surname>Weisz</surname></persName>
		</author>
		<idno type="DOI">10.1145/3663384.3663398</idno>
		<ptr target="https://doi.org/10.1145/3663384.3663398" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Annual Meeting of the Symposium on Human-Computer Interaction for Work (CHIWORK &apos;24)</title>
		<meeting>the 3rd Annual Meeting of the Symposium on Human-Computer Interaction for Work (CHIWORK &apos;24)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">My agent understands me better&quot;: Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents</title>
		<author>
			<persName><forename type="first">Yuki</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haruki</forename><surname>Tamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Homei</forename><surname>Miyashita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The Importance of Modeling Social Factors of Language: Theory and Practice</title>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diyi</forename><surname>Yang</surname></persName>
		</author>
		<ptr target="https://api.semanticscholar.org/CorpusID" />
	</analytic>
	<monogr>
		<title level="m">North American Chapter</title>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">235097460</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Supporting scientific collaboration: Methods, tools and concepts</title>
		<author>
			<persName><forename type="first">Marina</forename><surname>Jirotka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charlotte</forename><forename type="middle">P</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gary</forename><forename type="middle">M</forename><surname>Olson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Supported Cooperative Work (CSCW)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="667" to="715" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Understanding the Impact of Long-Term Memory on Self-Disclosure with Large Language Model-Driven Chatbots for Public Health Intervention</title>
		<author>
			<persName><forename type="first">Eunkyung</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuin</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sohyun</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Young-Ho</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">BioSpark: An End-to-End Generative System for Biological-Analogical Inspirations and Ideation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hyeonsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolas</forename><surname>Chuan-En Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aniket</forename><surname>Martelaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan-Ying</forename><surname>Kittur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Synergi: A Mixed-Initiative System for Scholarly Synthesis and Sensemaking</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hyeonsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tongshuang</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">Chee</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aniket</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><surname>Kittur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology</title>
		<meeting>the 36th Annual ACM Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Codeaid: Evaluating a classroom deployment of an llm-based programming assistant that balances student and educator needs</title>
		<author>
			<persName><forename type="first">Runlong</forename><surname>Majeed Kazemitabaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoning</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Austin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Henley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Denny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michelle</forename><surname>Craig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tovi</forename><surname>Grossman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Moderator Chatbot for Deliberative Discussion: Effects of Discussion Structure and Discussant Facilitation</title>
		<author>
			<persName><forename type="first">Soomin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinsu</forename><surname>Eun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Seering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joonhwan</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1145/3449161</idno>
		<ptr target="https://doi.org/10.1145/3449161" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="87" />
			<date type="published" when="2021-04">2021. April 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Patterns of contact and communication in scientific research collaboration</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Kraut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carmen</forename><surname>Egido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jolene</forename><surname>Galegher</surname></persName>
		</author>
		<idno type="DOI">10.1145/62266.62267</idno>
		<ptr target="https://doi.org/10.1145/62266.62267" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1988 ACM conference on Computer-supported cooperative work (CSCW &apos;88)</title>
		<meeting>the 1988 ACM conference on Computer-supported cooperative work (CSCW &apos;88)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Relationships and tasks in scientific research collaborations</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Kraut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jolene</forename><surname>Galegher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carmen</forename><surname>Egido</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1986 ACM conference on Computer-supported cooperative work</title>
		<meeting>the 1986 ACM conference on Computer-supported cooperative work</meeting>
		<imprint>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="229" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Socially situated artificial intelligence enables learning from human interaction</title>
		<author>
			<persName><forename type="first">Ranjay</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donsuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2115730119</idno>
		<ptr target="https://doi.org/10.1073/pnas.2115730119Publisher" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page">2115730119</biblScope>
			<date type="published" when="2022-09">2022. Sept. 2022</date>
			<publisher>Proceedings of the National Academy of Sciences</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">PaperWeaver: Enriching Topical Paper Alerts by Contextualizing Recommended Papers with User-collected Papers</title>
		<author>
			<persName><forename type="first">Yoonjoo</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hyeonsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juho</forename><surname>Latzke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">Chee</forename><surname>Bragg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pao</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><surname>Siangliulue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Dapie: Interactive step-by-step explanatory dialogues to answer children&apos;s why and how questions</title>
		<author>
			<persName><forename type="first">Yoonjoo</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tae</forename><surname>Soo Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungdong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yohan</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juho</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2023 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Putting Things into Context: Generative AI-Enabled Context Personalization for Vocabulary Learning Improves Learning Motivation</title>
		<author>
			<persName><forename type="first">Joanne</forename><surname>Leong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pat</forename><surname>Pataranutaporn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valdemar</forename><surname>Danry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Perteneder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaoli</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pattie</forename><surname>Maes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Retrieval-augmented generation for knowledge-intensive nlp tasks</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heinrich</forename><surname>Küttler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="9459" to="9474" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Social Intelligence Data Infrastructure: Structuring the Present and Navigating the Future</title>
		<author>
			<persName><forename type="first">Minzhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiyan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caleb</forename><surname>Ziems</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diyi</forename><surname>Yang</surname></persName>
		</author>
		<idno>ArXiv abs/2403.14659</idno>
		<ptr target="https://api.semanticscholar.org/CorpusID" />
		<imprint>
			<date type="published" when="2024">2024. 2024</date>
			<biblScope unit="page">268667546</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">RecAI: Leveraging Large Language Models for Next-Generation Recommender Systems</title>
		<author>
			<persName><forename type="first">Jianxun</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxuan</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<idno type="DOI">10.1145/3589335.3651242</idno>
		<ptr target="https://doi.org/10.1145/3589335.3651242" />
	</analytic>
	<monogr>
		<title level="m">Companion Proceedings of the ACM Web Conference 2024 (WWW &apos;24)</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1031" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">What Can You Do? Studying Social-Agent Orientation and Agent Proactive Interactions with an Agent for Employees</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">Vera</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Werner</forename><surname>Geyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">Sadat</forename><surname>Shami</surname></persName>
		</author>
		<idno type="DOI">10.1145/2901790.2901842</idno>
		<ptr target="https://doi.org/10.1145/2901790.2901842" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM Conference on Designing Interactive Systems (DIS &apos;16)</title>
		<meeting>the 2016 ACM Conference on Designing Interactive Systems (DIS &apos;16)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="264" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Selenite: Scaffolding Online Sensemaking with Comprehensive Overviews Elicited from Large Language Models</title>
		<author>
			<persName><forename type="first">Xieyang</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tongshuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianying</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franklin</forename><forename type="middle">Mingzhe</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aniket</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brad</forename><forename type="middle">A</forename><surname>Kittur</surname></persName>
		</author>
		<author>
			<persName><surname>Myers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Compeer: A generative conversational agent for proactive peer support</title>
		<author>
			<persName><forename type="first">Tianjian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongzheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingbo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenhui</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology</title>
		<meeting>the 37th Annual ACM Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Unblind Text Inputs: Predicting Hint-text of Text Input in Mobile Apps via LLM</title>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunyang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengzhuo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boyu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuekai</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">AI Is Not Enough: A Hybrid Technical Approach to AI Adoption in UI Linting With Heuristics</title>
		<author>
			<persName><forename type="first">Yuwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiffany</forename><surname>Knearem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shona</forename><surname>Dutta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Blass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clara</forename><surname>Kliman-Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Bentley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">When not to trust language models: Investigating effectiveness of parametric and non-parametric memories</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Mallen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akari</forename><surname>Asai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajarshi</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="9802" to="9822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Exploratory Search for Scientific Articles</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">R</forename><surname>Nedumov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Kuznetsov</surname></persName>
		</author>
		<idno type="DOI">10.1134/S0361768819070089</idno>
		<ptr target="https://doi.org/10.1134/S0361768819070089" />
	</analytic>
	<monogr>
		<title level="j">Programming and Computer Software</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="405" to="416" />
			<date type="published" when="2019-12">2019. Dec. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Conversational Group Recommender Systems</title>
		<author>
			<persName><forename type="first">Thuy</forename><surname>Ngoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nguyen</forename></persName>
		</author>
		<idno type="DOI">10.1145/3079628.3079704</idno>
		<ptr target="https://doi.org/10.1145/3079628.3079704" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Conference on User Modeling, Adaptation and Personalization (UMAP &apos;17)</title>
		<meeting>the 25th Conference on User Modeling, Adaptation and Personalization (UMAP &apos;17)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="331" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A Chat-Based Group Recommender System for Tourism</title>
		<author>
			<persName><forename type="first">Thuy</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Ngoc</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Ricci</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-51168-9_2</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-51168-9_2" />
	</analytic>
	<monogr>
		<title level="m">Information and Communication Technologies in Tourism</title>
		<editor>
			<persName><forename type="first">Roland</forename><surname>Schegg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Brigitte</forename><surname>Stangl</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="17" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Dynamic elicitation of user preferences in a chat-based group recommender system</title>
		<author>
			<persName><forename type="first">Thuy</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Ngoc</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Ricci</surname></persName>
		</author>
		<idno type="DOI">10.1145/3019612.3019764</idno>
		<ptr target="https://doi.org/10.1145/3019612.3019764" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Symposium on Applied Computing (SAC &apos;17)</title>
		<meeting>the Symposium on Applied Computing (SAC &apos;17)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1685" to="1692" />
		</imprint>
	</monogr>
	<note>Association for Computing Machinery</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Distance matters</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judith</forename><forename type="middle">S</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName><surname>Olson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human-computer interaction</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="139" to="178" />
			<date type="published" when="2000">2000. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Who Has Plots?</title>
		<author>
			<persName><forename type="first">Drew</forename><surname>Paine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charlotte</forename><forename type="middle">P</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Contextualizing Scientific Software, Practice, and Visualizations. Proceedings of the ACM on human-computer interaction</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">The CoExplorer Technology Probe: A Generative AI-Powered Adaptive Interface to Support Intentionality in Planning and Running Video Meetings</title>
		<author>
			<persName><forename type="first">Gun</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">(</forename><surname>Warren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">)</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Payod</forename><surname>Panda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lev</forename><surname>Tankelevitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Rintel</surname></persName>
		</author>
		<idno type="DOI">10.1145/3643834.3661507</idno>
		<ptr target="https://doi.org/10.1145/3643834.3661507" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2024 ACM Designing Interactive Systems Conference (DIS &apos;24)</title>
		<meeting>the 2024 ACM Designing Interactive Systems Conference (DIS &apos;24)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1638" to="1657" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Generative agents: Interactive simulacra of human behavior</title>
		<author>
			<persName><forename type="first">Sung</forename><surname>Joon</surname></persName>
		</author>
		<author>
			<persName><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O'</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carrie</forename><forename type="middle">Jun</forename><surname>Brien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meredith</forename><forename type="middle">Ringel</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology</title>
		<meeting>the 36th Annual ACM Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Check your facts and try again: Improving large language models with external knowledge and automated feedback</title>
		<author>
			<persName><forename type="first">Baolin</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiuyuan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Liden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhou</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.12813</idno>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">When to interrupt: A comparative analysis of interruption timings within collaborative communication tasks</title>
		<author>
			<persName><forename type="first">Nia</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Griffin</forename><surname>Romigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhiksha</forename><surname>Raj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Human Factors and System Interactions: Proceedings of the AHFE 2016 International Conference on Human Factors and System Interactions</title>
		<meeting><address><addrLine>Florida, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2017. July 27-31, 2016</date>
			<biblScope unit="page" from="177" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Embodied Mediation in Group Ideation -A Gestural Robot Can Facilitate Consensus-Building</title>
		<author>
			<persName><forename type="first">Tuan</forename><surname>Vu Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">H</forename><surname>Weisswange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Hassenzahl</surname></persName>
		</author>
		<idno type="DOI">10.1145/3643834.3660696</idno>
		<ptr target="https://doi.org/10.1145/3643834.3660696" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2024 ACM Designing Interactive Systems Conference (DIS &apos;24)</title>
		<meeting>the 2024 ACM Designing Interactive Systems Conference (DIS &apos;24)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="2611" to="2632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">The Arizona Water Chatbot: Helping Residents Navigate a Water Uncertain Future One Response at a Time</title>
		<author>
			<persName><forename type="first">Briana</forename><surname>Rajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Carradini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Lauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Exploring the potential for generative ai-based conversational cues for real-time collaborative ideation</title>
		<author>
			<persName><forename type="first">Jude</forename><surname>Rayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhruv</forename><surname>Kanetkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuewen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srishti</forename><surname>Palani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haijun</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">P</forename><surname>Dow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference on Creativity &amp; Cognition</title>
		<meeting>the 16th Conference on Creativity &amp; Cognition</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="117" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Addressing Loneliness and Isolation in Older Adults: Proactive Affective Agents Provide Better Support</title>
		<author>
			<persName><forename type="first">Lazlo</forename><surname>Ring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barbara</forename><surname>Barry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathleen</forename><surname>Totzke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Bickmore</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACII.2013.17</idno>
		<ptr target="https://doi.org/10.1109/ACII.2013.17ISSN" />
	</analytic>
	<monogr>
		<title level="m">2013 Humaine Association Conference on Affective Computing and Intelligent Interaction</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2156" to="8111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">The probabilistic relevance framework: BM25 and beyond</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends® in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="333" to="389" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<author>
			<persName><forename type="first">Krishna</forename><surname>Sayana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raghavendra</forename><surname>Vasudeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuri</forename><surname>Vasilevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liam</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hubert</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ambarish</forename><surname>Jash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sukhdeep</forename><surname>Sodhi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2410.16780</idno>
		<title level="m">Beyond Retrieval: Generating Narratives in Conversational Recommender Systems</title>
		<imprint>
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Beyond Dyadic Interactions: Considering Chatbots as Community Members</title>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Seering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michal</forename><surname>Luria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoff</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Hammer</surname></persName>
		</author>
		<idno type="DOI">10.1145/3290605.3300680</idno>
		<ptr target="https://doi.org/10.1145/3290605.3300680" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (CHI &apos;19)</title>
		<meeting>the 2019 CHI Conference on Human Factors in Computing Systems (CHI &apos;19)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Making Sense of Strangers&apos; Expertise from Signals in Digital Artifacts</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">Sadat</forename><surname>Shami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kate</forename><surname>Ehrlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geri</forename><surname>Gay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><forename type="middle">T</forename><surname>Hancock</surname></persName>
		</author>
		<idno type="DOI">10.1145/1518701.1518713</idno>
		<ptr target="https://doi.org/10.1145/1518701.1518713" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI &apos;09)</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems (CHI &apos;09)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="69" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">The Value of Activity Traces in Peer Evaluations: An Experimental Study</title>
		<author>
			<persName><forename type="first">Wendy</forename><surname>Wenxuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sneha</forename><forename type="middle">R</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hari</forename><surname>Krishna Kumaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><forename type="middle">P</forename><surname>Sundaram</surname></persName>
		</author>
		<author>
			<persName><surname>Bailey</surname></persName>
		</author>
		<idno type="DOI">10.1145/3579627</idno>
		<ptr target="https://doi.org/10.1145/3579627" />
	</analytic>
	<monogr>
		<title level="j">Proc. ACM Hum.-Comput. Interact</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="151" />
			<date type="published" when="2023-04">2023. April 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">IntroBot: Exploring the use of chatbot-assisted familiarization in online collaborative groups</title>
		<author>
			<persName><forename type="first">Donghoon</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soomin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruoxi</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joonhwan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gary</forename><surname>Hsieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2023 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Retrieval Augmentation Reduces Hallucination in Conversation</title>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Spencer</forename><surname>Poff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3784" to="3803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Mitigating Barriers to Public Social Interaction with Meronymous Communication</title>
		<author>
			<persName><forename type="first">Nouran</forename><surname>Soliman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hyeonsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Latzke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">Chee</forename><surname>Bragg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amy</forename><forename type="middle">Xian</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Karger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">AI can help humans find common ground in democratic deliberation</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Henry Tessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Michiel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Bakker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannah</forename><surname>Jarrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><forename type="middle">J</forename><surname>Sheahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raphael</forename><surname>Chadwick</surname></persName>
		</author>
		<author>
			<persName><surname>Koster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">386</biblScope>
			<biblScope unit="page">2852</biblScope>
			<date type="published" when="2024">2024</date>
			<pubPlace>Georgina Evans, Lucy Campbell-Gillingham, Tantum Collins, David C Parkes</pubPlace>
		</imprint>
	</monogr>
	<note>et al. 2024</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Imagining a future of designing with ai: Dynamic grounding, constructive negotiation, and sustainable motivation</title>
		<author>
			<persName><forename type="first">Priyan</forename><surname>Vaithilingam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Arawjo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><forename type="middle">L</forename><surname>Glassman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2024 ACM Designing Interactive Systems Conference</title>
		<meeting>the 2024 ACM Designing Interactive Systems Conference</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="289" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Music Recommendation System for Shared Environments</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Bracaioli</forename><surname>João</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><forename type="middle">N</forename><surname>Vitório</surname></persName>
		</author>
		<author>
			<persName><surname>Silla</surname></persName>
		</author>
		<idno type="DOI">10.1109/IWSSIP58668.2023.10180270</idno>
		<ptr target="https://doi.org/10.1109/IWSSIP58668.2023.10180270" />
	</analytic>
	<monogr>
		<title level="m">2023 30th International Conference on Systems, Signals and Image Processing</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<author>
			<persName><forename type="first">Tu</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Tar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun-Hsuan</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.03214</idno>
		<title level="m">FreshLLMs: Refreshing Large Language Models with Search Engine Augmentation</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<author>
			<persName><forename type="first">Diyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caleb</forename><surname>Ziems</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Held</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omar</forename><surname>Shaikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Michael S Bernstein</surname></persName>
		</author>
		<author>
			<persName><surname>Mitchell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2404.04204</idno>
		<title level="m">Social Skill Training with Large Language Models</title>
		<imprint>
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">AQuA: Automated Question-Answering in Software Tutorial Videos with Visual Anchors</title>
		<author>
			<persName><forename type="first">Saelyne</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jo</forename><surname>Vermeulen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Fitzmaurice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Matejka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">To Search or To Gen? Exploring the Synergy between Generative AI and Web Search in Programming</title>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicole</forename><surname>Sultanum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Evidence-Driven Retrieval Augmented Response Generation for Online Misinformation</title>
		<author>
			<persName><forename type="first">Zhenrui</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huimin</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yimeng</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lanyu</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2024 Conference of the North American Chapter</title>
		<meeting>the 2024 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5628" to="5643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">PersonaRAG: Enhancing Retrieval-Augmented Generation Systems with User-Centric Agents</title>
		<author>
			<persName><forename type="first">Saber</forename><surname>Zerhoudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Granitzer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2407.09394</idno>
		<imprint>
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Making Sense of Group Chat through Collaborative Tagging and Summarization</title>
		<author>
			<persName><forename type="first">Amy</forename><forename type="middle">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Cranshaw</surname></persName>
		</author>
		<idno type="DOI">10.1145/3274465</idno>
		<ptr target="https://doi.org/10.1145/3274465" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="196" />
			<date type="published" when="2018-11">2018. Nov. 2018</date>
		</imprint>
	</monogr>
	<note>CSCW</note>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Making Sense of Group Chat through Collaborative Tagging and Summarization</title>
		<author>
			<persName><forename type="first">Amy</forename><forename type="middle">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Cranshaw</surname></persName>
		</author>
		<idno type="DOI">10.1145/3274465</idno>
		<ptr target="https://doi.org/10.1145/3274465" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="196" />
			<date type="published" when="2018-11">2018. Nov. 2018</date>
		</imprint>
	</monogr>
	<note>CSCW</note>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<author>
			<persName><forename type="first">Xuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zifeng</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">See-Kiong</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.12639</idno>
		<title level="m">Ask-before-Plan: Proactive Language Agents for Real-World Planning</title>
		<imprint>
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Beyond Words: Infusing Conversational Agents with Human-like Typing Behaviors</title>
		<author>
			<persName><forename type="first">Jijie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhan</forename><surname>Hu</surname></persName>
		</author>
		<idno type="DOI">10.1145/3640794.3665560</idno>
		<ptr target="https://doi.org/10.1145/3640794.3665560" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th ACM Conference on Conversational User Interfaces (CUI &apos;24)</title>
		<meeting>the 6th ACM Conference on Conversational User Interfaces (CUI &apos;24)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<author>
			<persName><forename type="first">Xinyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amy</forename><forename type="middle">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Althoff</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.11169</idno>
		<title level="m">Correcting misinformation on social media with a large language model</title>
		<imprint>
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Research through design as a method for interaction design research in HCI</title>
		<author>
			<persName><forename type="first">John</forename><surname>Zimmerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jodi</forename><surname>Forlizzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shelley</forename><surname>Evenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on Human factors in computing systems</title>
		<meeting>the SIGCHI conference on Human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="493" to="502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<author>
			<persName><forename type="first">Josie</forename><surname>Zvelebilova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saiph</forename><surname>Savage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Riedl</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2407.17489v1" />
		<title level="m">Collective Attention in Human-AI Teams</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
