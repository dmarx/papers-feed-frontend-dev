<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pay Attention: a Call to Regulate the Attention Market and Prevent Algorithmic Emotional Governance</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-02-26">26 Feb 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Franck</forename><surname>Michel</surname></persName>
							<email>franck.michel@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<country>Inria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fabien</forename><surname>Gandon</surname></persName>
							<email>fabien.gandon@inria.fr</email>
							<affiliation key="aff1">
								<orgName type="institution">University Côte d&apos;Azur</orgName>
								<address>
									<settlement>Inria</settlement>
									<region>CNRS</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Pay Attention: a Call to Regulate the Attention Market and Prevent Algorithmic Emotional Governance</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-02-26">26 Feb 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">9C26221A020ED17FD82D6F5D1133E2C9</idno>
					<idno type="arXiv">arXiv:2402.16670v1[cs.SI]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-02-21T16:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Over the last 70 years, we, humans, have created an economic market where attention is being captured and turned into money thanks to advertising. During the last two decades, leveraging research in psychology, sociology, neuroscience and other domains, Web platforms have brought the process of capturing attention to an unprecedented scale. With the initial commonplace goal of making targeted advertising more effective, the generalization of attentioncapturing techniques and their use of cognitive biases and emotions have multiple detrimental side effects such as polarizing opinions, spreading false information and threatening public health, economies and democracies. This is clearly a case where the Web is not used for the common good and where, in fact, all its users become a vulnerable population. This paper brings together contributions from a wide range of disciplines to analyze current practices and consequences thereof. Through a set of propositions and principles that could be used do drive further works, it calls for actions against these practices competing to capture our attention on the Web, as it would be unsustainable for a civilization to allow attention to be wasted with impunity on a world-wide scale.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">An unsustainable attention market</head><p>Since the advent of mass market in the 50's, media and advertisement providers have relentlessly tried to figure out effective methods to capture our attention and turn it into revenue. During the last two decades, supported by advances in artificial intelligence (AI), major online social media and Web platforms have brought this process of capturing attention to an unprecedented scale. Based almost exclusively on advertising revenues, their business model consists in providing free services that, in return, collect behavioral traces. This data is then used to maximize the impact of advertisements on users by 1 ensuring their mental availability at the time of being shown the advertisement, and 2 ensuring that the message meets their interests, beliefs and moods (i.e. targeted advertising). Based on research in psychology, sociology and neuroscience, several actors including online social media, games and Web platforms have engineered techniques capable of very effectively plundering our "available brain time" <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b26">27]</ref>. We can distinguish two broad categories of such techniques. Firstly, some techniques are explicitly designed to leverage cognitive biases as a means to capture attention. For instance, the likes collected after posting content activate the brain's dopaminergic pathways (involved in the reward system) and tap into our need for social approval, giving "bright dings of pseudopleasure" <ref type="bibr" target="#b36">[37]</ref>; notifications of smartphone applications feed our appetite for novelty and surprise such that it is difficult to resist the urge to check them; the pull-to-refresh mechanism <ref type="bibr" target="#b36">[37]</ref>, alike slot machines, exploits the variable reward pattern whereby each time we pull down the screen we may get an update or nothing at all; infinite scrolling (of news, posts or videos...) traps us because of our fear of missing out important information (FOMO) to the point that we can hardly break the flow; automatic video chaining replaces a deliberate action to continue watching with a required action to stop watching, and entails a frustrating feeling of incompleteness when stopped; etc. Similarly, some techniques harness dark patterns <ref type="foot" target="#foot_0">1</ref>  <ref type="bibr" target="#b25">[26]</ref> to manipulate users into taking actions or decisions they wouldn't take otherwise. This is typically the case when one accepts all notifications of an application without really noticing it, while deactivating notifications would require an additional, less intuitive, series of actions.</p><p>Secondly, recent advances in machine learning allow the training of content recommendation algorithms on massive online behavioral data. These algorithms learn to recommend content that not only captures attention but also increases user engagement <ref type="foot" target="#foot_1">2</ref> . They discover the content's key features that help predict whether such content will effectively attract users' attention, and typically end up selecting content related to conflictuality, fear or sexuality <ref type="bibr" target="#b9">[10]</ref>. They also learn to exploit humans' negativity bias <ref type="bibr" target="#b61">[61,</ref><ref type="bibr" target="#b59">59]</ref> and, as a consequence, content conveying high-arousal negative emotions (such as anger, resentment, indignation and disgust) are more likely to be read and eventually shared online than those conveying other emotions <ref type="bibr" target="#b50">[50,</ref><ref type="bibr" target="#b34">35]</ref>. Concerningly enough, false information (a broad term including misinformation and other forms of disin-formation) typically relies on such negative emotions as a trick to foster sharing. Finally, recommendation systems may do all this without it being explicit in the features they select, nor in the succinct feedback that some of them happen to provide <ref type="foot" target="#foot_2">3</ref> .</p><p>Since the amount of attention available is both limited and precious, it would be unsustainable for a civilization to waste it with impunity for questionable or futile purposes <ref type="bibr" target="#b9">[10]</ref>. Today, we might precisely be at that moment: while mental time has become a new oil, we have created an attention economy and subsequent attention markets <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref> that, although sustainable from an economic point of view, may be unsustainable from a civilization point of view. From these first references, let us define what the term "attention market" refers to in this article.</p><p>Definition 1.1 (Attention market) Economic environment where businesses compete to capture and retain the resource represented by people's focused mental engagement that we call attention.</p><p>The attention market treats attention as a tradable commodity and involves multiple actors: from producers (the end users whose attention is the resource), to content creators whose work is used to capture the attention, brokers who trade and monetize the attention, and consumers who use it for their purposes such as exposing users to advertisements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>❈</head><p>In this article, we propose a discussion aimed at spurring introspection and debate within the computer science community. In line with the Web Science Manifesto <ref type="bibr" target="#b5">[6]</ref> calling for interdisciplinary approaches to prepare the future of the Web, we bring together and synthesize the conclusions of more than 70 papers and books from a wide range of disciplines to analyze the practices and drifts of these systems designed to capture attention on a worldwide scale. We make the point that, with the initial commonplace goal of making targeted advertising more effective, the generalization of attention-capturing techniques and their use of negative emotions tends to foster radicalization and polarization, amplify the dissemination of false information, spur the emergence of populism, and eventually put a threat on democracies and human societies in general.</p><p>Promoting awareness about these issues, this paper is directly related to UN's Sustainable Development Goal<ref type="foot" target="#foot_3">foot_3</ref> (SDG) 16 "Peace, Justice, and Strong Institutions", since it suggests actions to combat the instrumentalization of negative emotions, the associated false information that mechanically increase the level of anger and resentment among populations, and it promotes "societies that respect the right (...) to freedom of expression, and access to information" <ref type="foot" target="#foot_4">5</ref> . By pointing to the rise of populism worldwide, it addresses the connected question of how to strengthen institutions. The paper is also relevant with respect to SDG 3 "Good Health and Well-being" considering the aggravating effects of online social media on mental health, and the public health issues caused by false information (e.g. during the Covid-19 pandemics).</p><p>So far, the public and private research in computer science has invested large efforts in dealing with some aspects of the problem like radicalization, violent speech and false information. These works rely on post hoc measures such as content detection, deletion or downgrading. Nevertheless, we argue that additional measures must be considered to actively prevent the issues that stem from attention capturing rather than only mitigating their impact after they have occurred. Presumably, such measures would be political as well as technical, meaning that this socio-technical problematic situation calls for socio-technical solutions. And although the measures may not be associated with immediate research opportunities for the computer science community, we believe that the potential impacts are crucial enough for the community to be fully aware of, and actively involved in, this reflection.</p><p>In the rest of this paper we will first review the general principles of recommendation systems and the consequences of the recommendation loop that they implement (section 2). Then, we will explain how having recommendation systems harness emotions can lead to detrimental situations including what we shall name an algorithmic emotional governance (section 3). We will touch upon the threat to creative jobs (section 4) and then review some known post hoc measures (section 5), before discussing preventive measures to reclaim our attention (section 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Users in the loop... of recommendation systems</head><p>Content recommendation algorithms are a key component of a wide range of applications, including social media, search engines and major Web platforms in general. Through many applications they have changed our lives, helping us to be more efficient, assisting us in daily tasks, or improving our education and information. In a number of other applications however, the truth in not so bright. In the case of social media for instance, they are presented to us as if designed to provide us with content that matches our needs and desires, while what they really seek is to maximize the attention we pay to their hosting platform and advertisements thereof. Through the training process, recommendation algorithms automatically learn to extract from massive behavioral traces the content's features that most effectively capture our attention and maximize our continuous engagement with the platform. For instance, they can learn that some categories of topics, such as conflictuality, fear or sexuality, irresistibly attract our attention <ref type="bibr" target="#b9">[10]</ref>, and thus lean toward recommending these particular categories. They can also learn to select content tailored for a certain user by taking into account the content's features (topics, source, emotions conveyed...) and its adequacy with the user's profile (interests, inclinations, past behavior...). This adequacy likely involves many other features that are not transparent since the platforms rarely inform users about how and for which purpose their personalized feed was composed. This is underlined in a study by DeVito <ref type="bibr" target="#b17">[18]</ref> who analyzed Facebook's patents, press releases, and Securities and Exchange Commission filings, to identify "the set of algorithmic values that drive the News Feed". Some of the features he identified are objective, i.e. they can be observed or measured: friend relationships, explicitly expressed user interests, prior engagement, post age and page relationships. By contrast, other features are up to interpretation and thus raise multiple questions: implicitly expressed user preferences (what are the signals of such implicit expression?), platform priorities (what are they and who decides them?), content quality (what are the quality criterion?).</p><p>Finally, it may seem that recommendation algorithms learn to leverage psychological traits and cognitive biases. Yet, it is important to stress that the algorithm does not discover such things as a psychological trait or a cognitive bias itself. Rather, it discovers the features that enable it to exploit what psychologists would describe as a trait or bias. Such criteria are not explicitly formulated, they may not even be explicable nor verifiable. They remain implicit in the models unless a study be carried out a posteriori, that would surface the biases that emerge from the recommendations. This is yet another example where AI techniques without explanations nor feedback are problematic.</p><p>Another specificity of recommendation algorithms is that they tend to implement a self-reinforcing loop that we define as follows: Definition 2.1 (Self-reinforcing recommendation loop) The continuous cycle of recommendation systems providing personalized suggestions to a user based on data collected from their preferences and behaviors and integrating these to further recommendations.</p><p>A classical self-reinforcing recommendation loop is illustrated in figure <ref type="figure">1:</ref> 1 The algorithms recommend content to the user. <ref type="bibr" target="#b1">2</ref> The behavior of the user is captured, possibly partially due to the focus of the platform and the limited choices that the interface offers, and possibly biased due to the fact that these choices may be oriented, again by the interest of the platform and the chosen interface. 3 The algorithms integrate these reactions in future recommendations. As a result, the reactions of the user will reinforce the recommendation and propagation of the attached content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Connect</head><p>Select <ref type="bibr" target="#b0">(1)</ref> Perceive &amp; React Trace (2) A.I. processing <ref type="bibr" target="#b2">(3)</ref> Figure <ref type="figure">1</ref>: The self-reinforcing recommendation loop of platforms: the ellipses are activities on the user side, the boxes are activities on the platform side. Select and Trace are grey boxes because only partially observable. The A.I. processing is, more than often, a black box for the end-user.</p><p>Of course there are externalities to that loop, that can increase its impact. Smartphones, for example, provide additional means to profile users by tracking their every moves, making recommendation even more efficient and targeted to the point that it competes and sometimes takes over more traditional ways of advertising <ref type="bibr" target="#b65">[65]</ref>. Another (detrimental) externality of this loop is that it opens the door to spoofing tech-niques and other malevolent actors intentionally biasing usage traces to "hijack" recommendation systems. Indeed, as soon as a process is known and documented, it runs the risk of being diverted from its original purpose and manipulated beyond its original objectives. For instance, fake reviews and reactions alter recommendations; black hat techniques of SEO (Search Engine Optimization) such as hidden texts, link farms, cloaking 6 or text spinning are disapproved by search engines as they impact the recommendations they make by unduly increasing the ranking of targeted pages or avoiding their downgrading.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>❈</head><p>As a result, the fact that a few recommendation systems influence a significant fraction of the human population may have a number of detrimental side effects on their users and our societies at large. A first side effect is that recommendation algorithms tend to lock users in an informational space in accordance with their tastes and beliefs, a "filter bubble" <ref type="bibr" target="#b45">[45]</ref> that confines them to a "cognitive comfort zone" and activates their confirmation bias as they are faced with information which seems to go towards the same directions or conclusions <ref type="bibr" target="#b55">[55,</ref><ref type="bibr" target="#b33">34]</ref> Eventually, users are no longer confronted with contradiction, debate nor disturbing facts or ideas, and this algorithmic amplification tends to be a powerful driver of the radicalization and polarization of opinions, leading to extremist ideas in some cases <ref type="bibr" target="#b74">[74]</ref>.</p><p>Furthermore, at a time where we need to change our behaviors (e.g. over-consumption of goods and energy) and redirect our attention to important matters (e.g. climate change), we should question whether recommendation algorithms make the right recommendations, and for whom. Considering the billions of users caught in recommendation loops everyday 7 , it is important to continuously monitor how and for what purpose these systems capture our attention. Because when our attention is spent on a content chosen by these platforms, it is lost for anything else.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Algorithmic Emotional Governance</head><p>Considering the platform's recommendation loop introduced in section 2, we now want to stress that, directly or indirectly, emotions are a key feature of the selected recommendations. In fact, the whole attention market could be seen as driven by a complex equation involving, at least, emotions, cognitive biases and content recommendation algorithms. This could lead to what we will call here an algorithmic emotional governance merging two concepts: emotional governance <ref type="bibr" target="#b48">[48]</ref> which is the informed management of the emotional dynamics of the governed population, and algorithmic governance <ref type="bibr" target="#b54">[54]</ref> which is a governance of our societies based on the algorithmic processing of massive data. 6 Cloaking denotes a technique in which the content presented to a search engine crawler is different from that presented to an actual user. It aims at deceiving search engines so they display the page that they would otherwise downgrade or dismiss. Adapted from <ref type="url" target="https://en.wikipedia.org/wiki/Cloaking">https://en.wikipedia.org/wiki/Cloaking</ref>. 7 In 2018, Google revealed that 70% of the time spent watching videos on Youtube is about videos recommended by Youtube's algorithms. <ref type="url" target="https://qz.com/1178125/youtubes-recommendations-drive-70-of-what-we-watch">https://qz.com/1178125/youtubes-recommendations-drive-70-of-what-we-watch</ref>  Emotions are a powerful attractor of our attention, especially emotions with a high negative valence <ref type="bibr" target="#b61">[61]</ref>. As a result, information that arouses anger, fear, indignation, resentment, frustration or disgust is among those that most effectively catch our attention <ref type="bibr" target="#b50">[50,</ref><ref type="bibr" target="#b34">35</ref>]. An explanation is that witnessing others' negative emotions activates our comparison bias and subjects us to some sort of injunction to take sides, to show our emotional response, and hence publicly demonstrate our "irreproachable morality" <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b9">10]</ref>. Note that catching attention and increasing user engagement are different things, and although high-arousal negative emotions catch attention more efficiently than other emotions, it remains unclear whether they induce a higher user engagement on social media. In some cases a higher sharing rate of information conveying positive emotions was observed <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b35">36]</ref>. Nevertheless, in several contributions, researchers showed the overwhelming impact of emotions in argumentation and debates and the means to detect them <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b68">68,</ref><ref type="bibr" target="#b3">4]</ref>, and it has also been shown that anger spreads faster on social media than any other emotion <ref type="bibr" target="#b20">[21]</ref>. Note that this attraction for negative content can be observed in completely different domains, e.g. in literature where the anti-utopian and dystopian fiction genres became more prominent within the utopian genre <ref type="bibr" target="#b38">[39]</ref>.</p><p>Combined together, the construction of filter bubbles by recommendation systems and the ability of these systems to learn the content's features that trigger a particular emotional response in a particular individual, can lead to some form of polarisation and end up trapping users in radicalization pathways. Consider the supporter of a sports club: it is because the system chooses the right topic (e.g. the right sport), the right content (e.g. an article about an opponent club) and the right tone and emotion (e.g. mocking criticism) that an emotion is provoked, followed by a registered reaction (like, comment, repost) and, over time, a potential polarisation is developed such as hatred for the opponent's supporters.</p><p>Recommendation after recommendation, the filter bubble becomes an opinion bubble where users are isolated from discrepant opinions, and eventually an emotion bubble where they are maintained in certain emotional states as the result of optimized recommendations. In the end, the complex interaction of negative emotions, cognitive biases (e.g. negativity bias and impulsive tendency to show indignation) and recommendation algorithms leads to an emotional escalation. Often, this escalation is further worsened by the affordances offered by the platforms, that tend to make exchanges ever briefer and more simplistic: How to express a nuanced reflection in a 280-character tweet? How to underline a doubt when the only available choices are essentially limited to / (and sometimes )? How to agree with one part of a post and disagree with another one when this post is treated as a monolithic block by the interface that only offers the options / / ? This extreme discretization of choices adds to the mechanisms at work and reinforces the polarization of opinions and communities. Some dark patterns are even intentionally employed to make some actions easy and some more difficult: for instance, in Facebook the button to like a post is always visible whereas the option to report a post is at the bottom of a submenu, a pattern falling in the category known as "longer than necessary" <ref type="bibr" target="#b6">[7]</ref>.</p><p>Eventually, nuance, doubt or agnosticism are mechanically made invisible because the low emotional response that they induce simply downgrades their ranking. It is imperative to have an opinion, preferably definite and cleaving. Amplified by digital disinhibition 8 <ref type="bibr" target="#b63">[63]</ref>, this emotional escalation can lead to outpourings of violence and hatred whose outcome is sometimes tragic as attested by the suicide attempts of teenagers being cyberbullied <ref type="bibr" target="#b56">[56]</ref>. Moreover, the full consequences of triggering or regulating emotions on our cognitive functions in general and on memory in particular remain to be studied extensively <ref type="bibr" target="#b49">[49]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>❈</head><p>We just described the combined effect of emotions, cognitive biases and recommendation algorithms, which is at work whatever the type of content a platform serves. But things get even worse when it comes specifically to false information. False information are frequently meant to arouse strong negative emotions <ref type="bibr" target="#b75">[75]</ref>, and the combination with cognitive biases and recommendation algorithms provides them with a particularly fertile ground and a formidable cognitive efficiency <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b37">38]</ref>. Some studies reported that negatively biased fake news enhance users' willingness to share them <ref type="bibr" target="#b13">[14]</ref>, and reveal a positive correlation between the virality of fake news and the anger they carry <ref type="bibr" target="#b11">[12]</ref>. Another study contended that falsehood spreads "significantly farther, faster, deeper, and more broadly than the truth" on social media <ref type="bibr" target="#b69">[69]</ref>, which underlines that recommendation of content arousing negative emotions does not only induce local individual reaction: it creates a chain reaction leveraging the network effect of social media to spread that "content-emotion" couple through the acquaintance links. Other studies reported that recommendation algorithms mechanically tend to favor false information conveying divisive ideas, shocking events and negative emotions <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref>. This type of content entails a felt injunction to take sides and compulsively spread shocking information rather than appealing to critical thinking, questioning its veracity and verifying its source. And since this information is often relayed by acquaintances, the social proof bias <ref type="bibr" target="#b12">[13]</ref> entices users to deem it credible and trustworthy.</p><p>Concerningly, the contents we are exposed to leave a trace in our implicit memory: although we cannot recall seeing it, it may impact our choices for several months <ref type="bibr" target="#b14">[15]</ref>. Even more concerning is the fact that, due to the negativity bias, negative information leaves a longer memory trace than positive information. Therefore, even when a false information is denied or rectified, there remains a negative feeling that stems from the strong emotional response it triggered in the first place. Repeated again and again, associated with representations of the world that summon conspiracy theories, reinforced under the pressure of filter and emotion bubbles, propelled by the network effect, such information gradually and insidiously un-dermines our trust in the elites (scholars, experts, journalists, politicians, etc.), entails risks for public health <ref type="bibr" target="#b72">[72,</ref><ref type="bibr" target="#b51">51]</ref>, and spurs the emergence of extreme ideas and populism that eventually undermine democracies <ref type="bibr" target="#b74">[74,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b22">23]</ref>, among other pitfalls.</p><p>Finally, let us stress that if "previous studies have shown how personality, values, emotions and vulnerability of users affect their likelihood to propagate misinformation" <ref type="bibr" target="#b21">[22]</ref>, in this section we only considered an average user without any particular health condition. But we should envisage more complex situations when it comes to users with disabilities or mental disorders e.g. depression, anxiety, compulsive shopping disorder, paranoia, FOMO, FOBO <ref type="foot" target="#foot_5">9</ref> ... Let us just mention one specific condition: the attention deficit (AD) disorder. There is evidence that AD symptoms could be worsened by the use of digital media and their attention-grabbing applications, and more importantly that these applications could provoke AD among people without previous record of such a disorder <ref type="bibr" target="#b47">[47]</ref>. To the very least, more research is needed in this respect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Attention, attention, all thinkers</head><p>We firstly intended this section for all the scientists reading this paper, concurring with the article of David R. Smith: "Attention, attention: your most valuable scientific assets are under attack" <ref type="bibr" target="#b60">[60]</ref>. In this article, Smith calls for attention to what media platforms are doing to research and the academic domain. Indeed, even the most informed scientists and engineers are not immune to these problems <ref type="bibr" target="#b36">[37]</ref> such that digital contraptions (as Smith calls them) are contributing to academic attention deficit disorder <ref type="bibr" target="#b60">[60]</ref>. In fact, concentration but also boredom, mind-wandering and daydreaming times are vital to creative thinking. Many of us experienced the sudden burst of an idea in the middle of a relaxing moment. Attentioncapturing systems steal these moments from all of us and hamper the creativity process of wondering minds <ref type="bibr" target="#b77">[77]</ref>.</p><p>Of course these remarks can be generalized to many other activities requiring concentration, creativity and imagination, and one could wonder what digital contraptions are doing to politics, healthcare or education, for instance. To mention just one example, countless information media now report the cases of Youtubers experiencing a burnout <ref type="bibr" target="#b46">[46]</ref>, or musicians complaining that they spend more time making Tiktok videos to promote their music than actually creating music <ref type="bibr" target="#b57">[57,</ref><ref type="bibr" target="#b73">73]</ref>. This reveals that, to hook and keep the attention of content consumers, platforms also exercise some sort of visibility tyranny over content creators.</p><p>In other words: attention, attention, thinkers, we need to redesign the systems for our own needs, rather than the other way around, especially in creative jobs since the true currency of these jobs are ideas <ref type="bibr" target="#b60">[60]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Known Post Hoc Counter-measures</head><p>Among the various issues raised in the previous sections, the questions of false information, radicalization, hateful speech and bullying are among the most concerning, and therefore have been extensively addressed by the research community <ref type="bibr" target="#b58">[58]</ref>. In <ref type="bibr" target="#b21">[22]</ref> authors identified three different points where recommendation systems can be adapted to tackle these issues: 1 pre recommendation, 2 within the recommendation model, and 3 post recommendation. Most of the current counter-measures to deal with false information lie in this third category. Below we touch upon some of them.</p><p>Firstly, to dyke the spread of false information as well as inappropriate content such as bullying, hateful or violent speech, social media and content hosting platforms have obligations that vary depending on the legislation and its jurisdiction <ref type="bibr" target="#b23">[24]</ref>. Measures range from content deletion and suspension of users spreading inappropriate content, to re-ranking of recommended items before presenting them to the user <ref type="bibr" target="#b21">[22]</ref>, flagging to indicate potentially deceptive content, etc. Yet, despite these various approaches, progress is still necessary. For instance, subtle violent content may be hard to detect as soon as it does not contain explicit hateful or violent terms, or when it uses sarcasm <ref type="bibr" target="#b43">[44]</ref>. Conversely, content may be erroneously assessed as abusive or illicit although it is in fact using irony to convey perfectly acceptable ideas. An in-depth analysis of implicit and subtlety in linguistic content remains an open question <ref type="bibr" target="#b43">[44]</ref>.</p><p>In addition, any action must carefully consider the dangers of transferring regulation and enforcement to private companies. <ref type="bibr" target="#b62">[62]</ref> argue that over-filtering content is just as dangerous as letting bad content spread. Indeed, deletion and filtering may deviate from initial purpose to over-censorship of content if it becomes safer for the platforms to do so than take a risk of being sued. Furthermore, assessing the trustworthiness of information raises multiple ethical and political concerns: Who decides what is true or false? According to which criteria? Under whose control? Secondly, to mitigate the effect of false information, multiple post hoc measures rely on the impact of additional corrective content. For <ref type="bibr" target="#b70">[70]</ref>, pointing to a coherent alternative explanation, with references to expert and highly credible factual sources, remains a solid starting point. The authors describe the strategy of "observational correction" leveraging the fact that users who witness the correction of a misinformation item, but have not directly engaged with that item, are less affected by cognitive dissonance and are therefore more amenable to correction. This is consistent with the findings of <ref type="bibr" target="#b7">[8]</ref> who suggest that exposing users to related stories that correct a post that contained misinformation will significantly reduce misperceptions. The impact of the correction can be further reinforced by explicitly pointing to the demographic similarity between the user and the authors of opposing content <ref type="bibr" target="#b24">[25]</ref>, which taps into the homophily effect <ref type="foot" target="#foot_6">10</ref> . In other words, we are more likely to accept the correction when it comes from someone who is socially close to us, e.g. having the same professional activity or background. <ref type="bibr" target="#b70">[70]</ref> also suggest to multiply correction actions for each targeted content to reinforce the effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Reclaiming our attention</head><p>The methods presented in the previous section all have one thing in common: they deal with the problems in a post hoc manner, that is, after these problems have occurred, with all the limitations that come with this "coming after". To go further however, we need to figure out measures, may they be legal, political or technical, capable of preventing the attention from being looted in the first place. More importantly, we need to consider this reflection not only from the perspective of regulating the attention consumers (the platforms and multiple intermediaries), but also from the perspective of the producers (the end-users) who want to reclaim their attention, especially in times when our attention is needed on a number of urgent matters. This involves actively preventing recommendation systems from finding ways to exploit our inner limitations and manipulate us through sometime ancient and deeply embedded structures of our brain (e.g. our striatum) <ref type="bibr" target="#b8">[9]</ref>.</p><p>Below we formulate a set of propositions stemming from the observations and findings reported in the previous sections. We organize them around the challenges that they address, together with suggestions made by other authors from multiple disciplines. Finally we extract from them a set of empirical principles that could be used do drive further works on good practices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">The carrot and the stick</head><p>Taking the example of false information, <ref type="bibr" target="#b70">[70]</ref> insist on the fact that a posteriori corrections are not sufficient and must happen as early as possible, that is, before misperceptions are entrenched. Besides, avoiding the algorithmic amplification effect of such information by recommendation systems requires to mitigate the popularity effect before its happens <ref type="bibr" target="#b21">[22]</ref>. But if online social media are required by law to combat false information, they have conflicting incentive to do it, not to say no incentive at all. Indeed, as we described in section 3, false information largely relies on negative emotions to capture users' attention. As such, they are very effective in fostering user engagement which is what online social media strive to obtain. Consequently, from an economic point of view, it is counterproductive for online social media to prevent the spread of false information. More generally, it is counter-productive for platforms to mitigate the popularity effect, mitigate the impact of negative emotions, or reduce filter bubbles and the subsequent polarization of opinions.</p><p>The authors of <ref type="bibr" target="#b41">[42]</ref> suggest to rethink existing trade regulation laws such as antitrust and fair competition laws under the new realm of attention markets. They propose to enforce taxes on attention consumption to "disincentivize attention intermediaries from vacuuming up as much attention as possible", for instance by restraining the amount of advertisements that can be shown to a user, or reducing the deductibility of advertising expenditures from the companies' revenues to alleviate their taxes. They also propose to regulate the attention costs that can be charged, with the idea that if attention becomes less lucrative then financial resources will be redirected towards more lucrative markets, thus reducing the amount of attention being captured and traded.</p><p>In other words, things would not change without strong in-centives on one side, and disincentives on the other. We can summarize this in the following general principle:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>principle of the right incentive</head><p>At a Web governance level, we must leverage legal and economic means to drive platforms' practices towards desirable behaviours, while penalizing undesired behaviours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Usage regulation</head><p>Some of the measures meant to regulate the attention market lie in the way the services are consumed. Some legal measures could be taken to enforce a regulation of the daily use of Web platforms. As has already been done in some countries, laws could be voted to limit the daily time spent by users on certain services, especially among the youngest <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b10">11]</ref>.</p><p>Another simple measure applies to video streaming platforms, that consists in imposing few-second pauses between videos. This apparently naive technique may actually shatter the infinite feed trap by giving users the short amount of time they need to realize that they have been in an attention tunnel for a while, and that they want to "reclaim" their attention. This can be generalized by formulating the following principle:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>principle of supported due diligence</head><p>All means should be provided to foster and update the due diligence of users. In particular they should always be made aware of their options to escape the systems' loops, processes and goals.</p><p>Policy makers could also tackle the problem of attention fragmentation entailed by the multiple, often invasive, notifications that smartphone applications raise. Whenever a notification occurs, users are tempted to interrupt their current activity, check the reason of the notification, possibly react to it, before eventually returning to their activity. It has been shown that switching our attention between tasks or contexts has a cost: it is time-consuming and creates a more error prone context <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b52">52]</ref>. Furthermore it has even been shown that the mere presence of such devices, although turned off, impairs our cognitive capacity <ref type="bibr" target="#b71">[71]</ref>. In a way similar to the European General Data Protection Regulation (GDPR) <ref type="foot" target="#foot_7">11</ref> which imposes the consent of users for the use of cookies, law could impose that smartphone applications obtain users' explicit and informed consent for the notifications that they raise, and deactivate them by default ("opt-in only"). Hence the following principle:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>principle of opt-in by default</head><p>Recommendation and notification services should be turned off by default and only turned on on demand and after informed consent and preference setting This could be complemented by more punitive measures, as proposed in <ref type="bibr" target="#b40">[41]</ref>, for instance by demonetizing and forbidding collaboration with platforms that do not follow the rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Content recommendation monitoring</head><p>The echo-chamber effect of recommendation algorithms is at the root of multiple examples of polarization and radicalization. It could be mitigated by imposing a certain share of non-recommended content, content that is outside of the user's interests, or content that originates from users they are not acquainted with. In this respect, some approaches lie in the second category proposed by <ref type="bibr" target="#b21">[22]</ref>, i.e. modifications "within the recommendation" system. For instance, the same authors suggest using clustering approaches to assemble the contacts of the user according to different levels of similarity with the user, and leverage these groups to increase the diversity of recommendations while maintaining a certain coherence and similarity. <ref type="bibr" target="#b19">[20]</ref> propose a method to come up with relevant recommendations while reducing the likelihood of enticing the user towards radicalization pathways. Also, to counter the misuse and abuse of anger, indignation or fear, which are often associated with false information, platforms could be required to carry out sentiment analysis on every content in order to keep the amount of recommendations associated to negative emotions below a given threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>principle of balanced recommendations</head><p>Recommendation-based platforms should prevent the over specialization of recommendations w.r.t. all features and should support monitoring and preventing the formation of bubbles of any type (opinion, source, emotion, etc.).</p><p>Moreover, there exists an asymmetry of visibility between the viral spreading of an information that was proven to be false or misleading, and the denial or rectification of that information. The denial of a false information usually puts forward a pondered, nuanced position that appeals to reasoning and facts (logos) over emotion (pathos). Hence, it does not trigger an emotional response compared to the one generated by the false information in the first place, and it is therefore silently downgraded by recommendation algorithms. This is commonly summarized by the so-called Bradolini's law which states that "the amount of energy needed to refute false information is an order of magnitude bigger than that needed to produce it." As a result, users who propagate false information often never get to know about their mistake. <ref type="bibr" target="#b67">[67]</ref> insist on the fact that it is critical to jointly address content-checking and digital virality. Thus, to counterbalance this visibility asymmetry, social media could be required to impose on the denial/rectification of a false information a visibility equivalent to that of the initial information, for instance, by ensuring that the population who was exposed to the false information be exposed to the denial too. A warning could also be presented to users who propagated this false information in order to increase their awareness. Of course, this type of measure could be coupled with other post recommendation measures such as strategies involving the observational correction or demographic similarity presented in section 5. More generally, one has to figure out how we can use recommendation systems to recommend counter measures, i.e. we could train a recommendation system to learn the most relevant content and the most impactful entries in the acquaintance network to inject a counter measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>principle of balanced visibility</head><p>Recommendation-based platforms should ensure that preventive and corrective measures have a visibility at least equal to the visibility of the problems being prevented or corrected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Affordances and interaction design</head><p>As discussed in section 3, the affordances of platforms are optimized towards extremely brief and basic exchanges, leaving no room for nuance, pondering, doubt nor substantiated reasoning. Interfaces could be redesigned to facilitate non-binary reactions, starting with a range of nuanced emotions. Rather than implementing deceptive dark patterns, they could rely on nudges to gently drive users towards critical thinking, and by valuing/rewarding this kind of behavior. <ref type="bibr" target="#b0">[1]</ref> recommend engaging users in the validation of content before sharing it, both manually and with automated analysis methods on content and context. For instance, X (formerly Twitter) asks confirmation before retweeting the link to an article that the user did not click. Similarly, interfaces could encourage users to comment on content instead of merely clicking , or , and they could question a user about whether they really want to share or support a content associated to strong negative emotions or for which a counter-measure was triggered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>principle of benevolent interaction design</head><p>Affordances and interactions should be designed and evaluated with the well-being of end-users in mind first.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Societal impact and educational mission</head><p>We, as a society, could decide that large online social media, because of their influence on the society, public opinion, public health and economy, can no longer be considered as sheer private companies regulated by markets law only. Instead, they could be seen as digital commons and be assigned a specific status that would endow them with a societal mission including an educational purpose, for instance. As an example, they could instruct users in detecting false or misleading information, they could promote content meant to increase awareness w.r.t. attention mechanisms and cognitive biases, foster critical thinking and "distill" the scientific method, etc. On the same page, authors of <ref type="bibr" target="#b0">[1]</ref> insist on the need for civic education, and <ref type="bibr" target="#b42">[43]</ref> recommend integrating democratic values into the algorithms that impact our lives, especially the ones participating in an algorithmic governance (e.g. platform used for debates, for information, for legal actions, educational orientation) which, in our case, means going beyond the optimization of user engagement and attention catching, and including ethical criteria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>principle of digital commons preservation</head><p>When a digital service, platform or resource reaches the potential of having a world-wide impact on human societies, it must be assigned the status of digital common and must be subjected to preservation rules and policies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Feedback and transparency enforcement</head><p>Since one of the pitfalls we identified is the fact that users are being caught by the recommendation loops, approaches such as quantified self and lifelog could be specialized to the case of recommendation-based platforms, in order to foster awareness and introspection. Self-tracking tools could provide users with usage metrics and feedback with respect to the total time spent on the platform, the total exposure to negative news, etc. This could be a way to counter the fact that online sharing of fake news increases with social media fatigue <ref type="bibr" target="#b64">[64]</ref>. Indicators could inform users about the diversity of the recommendations they are shown, and make them aware of low-diversity risks. For instance the fact that "90% of the content one sees come from 10% of one's contacts or are on the same topic" may indicate that one is experiencing a filter bubble. We summarize this in the principle below where user's reflexivity is the ability of users to be self-aware of their usage and engagement with the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>principle of continuous reflexivity</head><p>Users must be provided a continuously updated feedback on their usage of the system and on themselves to support their reflexivity and maintain an up-to-date informed consent.</p><p>Among other measures, the European Digital Services Act <ref type="bibr" target="#b66">[66]</ref>, that took effect in August 2023, requires that platforms set up mechanisms to explain the reasons that led to recommending a certain content, and to offer users an alternative recommendation not based on profiling. Such measures are especially crucial when coupling AI and the Web since we need to set transparency and explanation as a prerequisite to any approach, to ensure the awareness and informed consent of, potentially, billions of users <ref type="bibr" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>principle of full user awareness</head><p>Users must be made aware of all the features and motivations leading to a recommendation, before and when it is provided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.7">Build on existing practices</head><p>Finally, and although it may seem obvious, one rule is worth remembering: to review and take inspiration from existing best practices in other domains. In most jurisdictions there exist advertising laws to protect consumers, ensure they remain able to make informed decisions, and more generally to maintain a level playing field<ref type="foot" target="#foot_8">foot_8</ref> between all players. Most countries regulate advertising through legislations that target different forms of false, misleading or deceptive advertising contents and claims, and forbid a whole range of practices (unsubstantiated comparison, forged testimonial, puffery, misleading packaging/label, unsolicited commercial messages, alleged contests and sweepstakes, etc.). The work and literature on regulating advertising should be reviewed and built-upon in regulating the attention market at large. This topic is also close to that of clickbaits that are recommended links designed to attract attention and to entice users to follow them while being typically deceptive, sensationalized, or otherwise misleading. Clickbaits are not just teasers but headlines with an element of dishonesty, "using enticements that do not accurately reflect the content being delivered" <ref type="foot" target="#foot_9">13</ref> . As far as we know, there is no regulation of clickbait practices on the Web, although some of these techniques bear similarities with the misleading or deceptive advertisement practices that we just mentioned and that, on the contrary, are regulated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>principle of best practice transfer</head><p>Methods and tools used to regulate similar situations in relevant domains should be surveyed, benchmarked and systematically considered as input to a Web governance.</p><p>To give another example coming from a completely different angle, we know that parenting practices in terms of TV viewing have an impact on the behaviour of young watchers <ref type="bibr" target="#b2">[3]</ref>. Again, approaches and good practices in this domain, and more generally in educating and parenting in the digital media age <ref type="bibr" target="#b15">[16]</ref>, must be considered in the case of "Web viewing" in general and when addressing the problem of attention capturing in particular.</p><p>More generally speaking, we need to put in place a governance bodies, starting with the Web and AI, that are prepared to tackle new problematic practices and regulate them, as is done in other areas of activity. And we also need to keep a constant watch on these other areas, if only to draw inspiration from the initiatives and feedback they have on similar issues. Taking the example of the video game industry, there is evidence of a relationship between "loot box" <ref type="foot" target="#foot_10">14</ref> spending and gambling addiction <ref type="bibr" target="#b76">[76]</ref>, and that a loot box is psychologically akin to gambling <ref type="bibr" target="#b18">[19]</ref> and can result in addictive behaviors and endangered players. The way to study and address that unwanted exploitation of our behaviors is inspirational for other problematic practices on the Web such as those we surveyed.</p><p>7 Thank you for... your attention AI is domain-independent. It is being applied in all our areas of interest: information, business, money, politics, employment, sports, games, sex etc. And the worldwide deployment of these techniques, partly due to its coupling with the Web, could have detrimental consequences in all these areas alike, unless properly regulated. This is a commonplace observation but it is the reason why, to prevent such detrimental effects, an ethical AI approach to AI governance must be multidisciplinary and interdisciplinary.</p><p>With this mindset, this paper brought together conclusions from more than 70 articles and books from different disciplines (psychology, sociology, neuroscience, politics, legal domain, computer science, education, etc.) to analyze and call for actions against the current practices competing to capture our attention in several "Web Wild West corners". The problem is both critical and complex, and authors of <ref type="bibr" target="#b33">[34]</ref> defend the need for a "nuanced multidimensional view of how social media use may shape information consumption" and they urge us to consider "the complex variety in social media platforms [and the] considerable variation in observed impacts among them". In <ref type="bibr" target="#b21">[22]</ref> authors add that "This research requires to navigate the careful tension between privacy, security, economic interests, censorship and cultural differences, and requires to be addressed from multiple disciplines that can assess not only the technological aspect, but also the individual and the social one (...) There is ample room for investigation (...), opening a novel, exciting and interdisciplinary line of research."</p><p>At the same time, the problem is getting worse with every technological innovation. The pervasiveness of smartphones in our lives has further reinforced the effectiveness of these techniques that can now grab our attention at every moment of the day, and in particular these moments that were previously those of boredom, waiting, daydreaming or intellectual strolling. As we pointed out in section 4, these moments are known to be necessary to spur imagination and creativity. In the continuation of smartphones, smart objects and the resulting internet of things and Web of things will only make things worse.</p><p>Recommendation systems that learn to predict us effectively learn to manipulate us, and to be predictable is to lose freedom. Everyday we fuel the predictors in exchange for immediate satisfaction and instant pleasure, this amounts to continually mortgaging our freedom. Besides, these systems that compete for our attention end up pressuring us to consume and to react more and more quickly to their recommendations. And, as we know, acceleration is a form of alienation <ref type="bibr" target="#b53">[53]</ref>.</p><p>In another context and to address our own human limitations, <ref type="bibr" target="#b9">[10]</ref> recommended to find ways to increase our overall level of consciousness and reclaim the power of long-term reflection. Our leaders and role models 15 struggle to embody the values of patience, conscience and moderation <ref type="bibr" target="#b9">[10]</ref>, but our computer systems rarely drive us in that direction either. On the contrary, current AI applications are pushing us not to use our conscience, but to play their automation game. Yet there is no reason for these systems to live in our mind rent free and it is urgent to redesign them so they regularly push us to take a step back, to be more conscious of what we are doing, viewing, saying, spreading, etc. The challenge is to (re)take and (re)give time for awareness, attention and reflection: we need to (re)take that source of freedom. And for this, we proposed a non-exhaustive first set of principles to (re)design Web applications and inscribe in them a set of agreed-upon values.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Definition 3 . 1 (</head><label>31</label><figDesc>Algorithmic emotional governance) The governance of societies based on algorithms processing massive data to harness the emotional dynamics of the governed population.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The legal definition in California is "A user interface is a dark pattern if the interface has the effect of substantially subverting or impairing user autonomy, decision-making, or choice. A business's intent in designing the interface is not determinative in whether the user interface is a dark pattern, but a factor to be considered." CPRA § 7004 (c)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>There are multiple definitions of user engagement. In the context of social media, this typically refers to the fact that a user would interact with a content: e.g. like, comment or repost it. Engagement is usually public in that it leaves public traces on the platform, unlike sheer content consumption that remains private<ref type="bibr" target="#b50">[50]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>For instance, a recommendation system may tell us "you liked this movie, you may also like this one". But we don't know what features were selected to recommend this one: Do they have an actor in common? Did my contacts like both of them? etc.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>https://www.un.org/sustainabledevelopment/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>https://www.un.org/sustainabledevelopment/peace-justice/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_5"><p>Fear of Better Options: the inability to choose when faced with a multitude of options.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_6"><p>Homophily: the tendency to associate with similar others.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_7"><p>GeneralData Protection Regulation (GDPR) https://gdpr-info.eu/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_8"><p>Metaphor denoting the fact that, in business, all players compete fairly, i.e. they all play by the same set of rules. https://en.wikipedia.org/wiki/Level playing field</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_9"><p>Definition adapted from https://en.wikipedia.org/wiki/Clickbait</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_10"><p>"loot boxes" are video game items with randomized contents that can be paid for with real-world money.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Algorithmdriven populism: An introduction [Populizm oparty na algorytmach. Wprowadzenie</title>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Abreu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leandro</forename><surname>Ayres Franc ¸a</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Archives of Criminology</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>Archiwum Kryminologii</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Cognitive attraction and online misinformation</title>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Acerbi</surname></persName>
		</author>
		<idno type="DOI">10.1057/s41599-019-0224-y</idno>
	</analytic>
	<monogr>
		<title level="m">Palgrave Communica-15 A role model is a person</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
	<note>whom others look at as an example to be imitated. tions 5.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Parental Influences on Youth Television Viewing</title>
		<author>
			<persName><forename type="first">Danielle</forename><forename type="middle">T</forename><surname>Barradas</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jpeds.2007.04.069</idno>
	</analytic>
	<monogr>
		<title level="j">The Journal of Pediatrics</title>
		<idno type="ISSN">0022-3476</idno>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="page" from="369" to="373" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A Pragma-Semantic Analysis of the Emotion/Sentiment Relation in Debates</title>
		<author>
			<persName><surname>Valerio Basile</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Workshop on Artificial Intelligence and Cognition co-located with the Joint Multi-Conference on Human-Level Artificial Intelligence (HLAI 2016)</title>
		<meeting>the 4th International Workshop on Artificial Intelligence and Cognition co-located with the Joint Multi-Conference on Human-Level Artificial Intelligence (HLAI 2016)<address><addrLine>New York City, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">July 16-17, 2016. 2016</date>
			<biblScope unit="volume">1895</biblScope>
			<biblScope unit="page" from="117" to="123" />
		</imprint>
	</monogr>
	<note>CEUR Workshop Proceedings. CEUR-WS.org</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Emotions in Argumentation: an Empirical Evaluation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Sahbi</forename><surname>Benlamine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Fourth International Joint Conference on Artificial Intelligence<address><addrLine>Buenos Aires, Argentina</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2015">July 25-31, 2015. 2015</date>
			<biblScope unit="volume">2015</biblScope>
			<biblScope unit="page" from="156" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Web Futures: Inclusive, Intelligent, Sustainable The 2020 Manifesto for Web Science</title>
		<author>
			<persName><forename type="first">Bettina</forename><surname>Berendt</surname></persName>
		</author>
		<idno type="DOI">10.4230/DagMan.9.1.1</idno>
	</analytic>
	<monogr>
		<title level="j">Dagstuhl Manifestos</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Guidelines 03/2022 on deceptive design patterns in social media platform interfaces: how to recognise and avoid them -v2/0</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>European Data Protection Board</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Tech. rep</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">That Was Wrong: The Correction of MisinformationThrough Related Stories Functionality in Social Media</title>
		<author>
			<persName><forename type="first">Leticia</forename><surname>Bode</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><forename type="middle">K</forename><surname>Vraga</surname></persName>
		</author>
		<idno type="DOI">10.1111/jcom.12166</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Communication</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="619" to="638" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Le Bug humain: Pourquoi notre cerveau nous pousse à détruire la planète et comment l&apos;en empêcher</title>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Bohler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robert Laffont</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Apocalypse cognitive. Presses Universitaires de France</title>
		<author>
			<persName><forename type="first">Gérald</forename><surname>Bronner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Much easier to say no&apos;: Irish town unites in smartphone ban for young children</title>
		<author>
			<persName><forename type="first">Rory</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rory</forename><surname>Carroll Ireland Correspondent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Guardian</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Anger can make fake news viral online</title>
		<author>
			<persName><forename type="first">Yuwei</forename><surname>Chuai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jichang</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.3389/fphy.2022.970174</idno>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Physics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">970174</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Influence: Science and practice</title>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">B</forename><surname>Cialdini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Pearson Education</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fake News Going Viral: The Mediating Effect Of Negative Emotions</title>
		<author>
			<persName><forename type="first">Nicoleta</forename><surname>Corbu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Media Literacy and Academic Research</title>
		<idno type="ISSN">2585-8726</idno>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="58" to="87" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The Long-Term Effects of E-Advertising: The Influence of Internet Pop-ups Viewed at a Low Level of Attention in Implicit Memory</title>
		<author>
			<persName><forename type="first">Didier</forename><surname>Courbet</surname></persName>
		</author>
		<idno type="DOI">10.1111/jcc4.12035</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer-Mediated Communication</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="274" to="293" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Parenting and Digital Media</title>
		<author>
			<persName><forename type="first">Sarah</forename><forename type="middle">M</forename><surname>Coyne</surname></persName>
		</author>
		<idno type="DOI">10.1542/peds.2016-1758N</idno>
	</analytic>
	<monogr>
		<title level="j">Pediatrics 140.Supplement</title>
		<idno type="ISSN">0031-4005</idno>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="112" to="S116" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Moral outrage in the digital age</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Crockett</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-017-0213-3</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<idno type="ISSN">2397-3374</idno>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="769" to="771" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">From editors to algorithms: A values-based approach to understanding story selection in the Facebook news feed</title>
		<author>
			<persName><forename type="first">A</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><surname>Devito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital journalism</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="753" to="773" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Video game loot boxes are psychologically akin to gambling</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Drummond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">D</forename><surname>Sauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature human behaviour</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="530" to="532" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Rewiring What-to-Watch-Next Recommendations to Reduce Radicalization Pathways</title>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Fabbri</surname></persName>
		</author>
		<idno type="DOI">10.1145/3485447.3512143</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Web Conference 2022. WWW &apos;22</title>
		<meeting>the ACM Web Conference 2022. WWW &apos;22<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2719" to="2728" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Anger Is More Influential than Joy: Sentiment Correlation in Weibo</title>
		<author>
			<persName><forename type="first">Rui</forename><surname>Fan</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0110184</idno>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<idno type="ISSN">1932-6203</idno>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">110184</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Analysing the Effect of Recommendation Algorithms on the Amplification of Misinformation</title>
		<author>
			<persName><forename type="first">Miriam</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alejandro</forename><surname>Bellogín</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iván</forename><surname>Cantador</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2103.14748</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Social media, education, and the rise of populist Euroscepticism</title>
		<author>
			<persName><forename type="first">Piergiuseppe</forename><surname>Fortunato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Pecoraro</surname></persName>
		</author>
		<idno type="DOI">10.1057/s41599-022-01317-y</idno>
	</analytic>
	<monogr>
		<title level="j">Humanities and Social Sciences Communications</title>
		<idno type="ISSN">2662-9992</idno>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">A guide to antimisinformation actions around the world</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Funke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniela</forename><surname>Flamini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Undermining the corrective effects of media-based political fact checking? The role of contextual cues and naıove theory</title>
		<author>
			<persName><forename type="first">Kelly</forename><surname>Garrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><forename type="middle">C</forename><surname>Nisbet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><forename type="middle">K</forename><surname>Lynch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Communication</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="617" to="637" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Mapping the Landscape of Dark Patterns Scholarship: A Systematic Literature Review</title>
		<author>
			<persName><forename type="first">Colin</forename><forename type="middle">M</forename><surname>Gray</surname></persName>
		</author>
		<idno type="DOI">10.1145/3563703.3596635</idno>
	</analytic>
	<monogr>
		<title level="m">Designing Interactive Systems Conference</title>
		<meeting><address><addrLine>Pittsburgh PA USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="188" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">How Technology is Hijacking Your Mind -from a Former Insider</title>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Harris</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On the economics of superabundant information and scarce attention</title>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Hefti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Heinke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OEconomia. History, Methodology, Philosophy</title>
		<idno type="ISSN">2113-5207</idno>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="76" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The Attention Economy</title>
		<author>
			<persName><forename type="first">F</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mads</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName><surname>Vestergaard</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-00813-0_1</idno>
	</analytic>
	<monogr>
		<title level="m">Reality Lost: Markets of Attention, Misinformation and Manipulation</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m">GlobalData Thematic Intelligence. Social media, algorithms, and populism</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Mental set and shift</title>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jersild</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1927">1927</date>
			<publisher>Columbia university</publisher>
			<biblScope unit="volume">89</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">Alex</forename><surname>Kantrowitz</surname></persName>
		</author>
		<title level="m">5 Ways China is Mandating Social Media Changes</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Picture This: The Influence of Emotionally Valenced Images, On Attention, Selection, and Sharing of Social Media News</title>
		<author>
			<persName><forename type="first">Kate</forename><surname>Keib</surname></persName>
		</author>
		<idno type="DOI">10.1080/15213269.2017.1378108</idno>
	</analytic>
	<monogr>
		<title level="j">Media Psychology</title>
		<idno type="ISSN">1521-3269</idno>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1532" to="1785" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Understanding Echo Chambers and Filter Bubbles: The Impact of Social Media on Diversification and Partisan Shifts in News Consumption</title>
		<author>
			<persName><forename type="first">Brent</forename><surname>Kitchens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><forename type="middle">L</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Gray</surname></persName>
		</author>
		<idno type="DOI">10.25300/MISQ/2020/16371</idno>
	</analytic>
	<monogr>
		<title level="j">MIS Quarterly</title>
		<idno type="ISSN">02767783, 21629730</idno>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="1619" to="1649" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">May I have your Attention, please? An eye tracking study on emotional social media comments</title>
		<author>
			<persName><forename type="first">Susann</forename><surname>Kohout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanne</forename><surname>Kruikemeier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bert</forename><forename type="middle">N</forename><surname>Bakker</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2022.107495</idno>
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<idno type="ISSN">0747-5632</idno>
		<imprint>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page">107495</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Association for Computing Machinery</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName><surname>Kramer</surname></persName>
		</author>
		<idno type="DOI">10.1145/2207676.2207787</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. CHI &apos;12</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems. CHI &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">ISBN</biblScope>
			<biblScope unit="page" from="978" to="979" />
		</imprint>
	</monogr>
	<note>The spread of emotion via Facebook</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Our minds can be hijacked&apos;: the tech insiders who fear a smartphone dystopia</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Guardian</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Reliance on emotion promotes belief in fake news</title>
		<author>
			<persName><forename type="first">Cameron</forename><surname>Martel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gordon</forename><surname>Pennycook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">G</forename><surname>Rand</surname></persName>
		</author>
		<idno type="DOI">10.1186/s41235-020-00252-3</idno>
	</analytic>
	<monogr>
		<title level="j">Cognitive Research: Principles and Implications</title>
		<idno type="ISSN">2365-7464</idno>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">47</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A bibliometric analysis of utopian literature</title>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Burgos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mascarell</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ES Review. Spanish Journal of English Studies</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="77" to="103" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Task switching</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Monsell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Trends in cognitive sciences</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="134" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Populism: A very short introduction</title>
		<author>
			<persName><forename type="first">Cas</forename><surname>Mudde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristóbal</forename><surname>Rovira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaltwasser</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Regulating Attention Markets</title>
		<author>
			<persName><surname>John M Newman</surname></persName>
		</author>
		<idno type="DOI">10.2139/ssrn.3423487</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
		<respStmt>
			<orgName>University of Miami Legal Studies Research Paper</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Weapons of math destruction: How big data increases inequality and threatens democracy</title>
		<author>
			<persName><forename type="first">O'</forename><surname>Cathy</surname></persName>
		</author>
		<author>
			<persName><surname>Neil</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<pubPlace>Crown</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">An In-depth Analysis of Implicit and Subtle Hate Speech Messages</title>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Ocampo</surname></persName>
		</author>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
		</imprint>
	</monogr>
	<note>Proceedings of the 17th Conference of the European Chapter of the</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Croatia</forename><surname>Dubrovnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="1997" to="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">The filter bubble: How the new personalized web is changing what we read and how we think</title>
		<author>
			<persName><forename type="first">Eli</forename><surname>Pariser</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<pubPlace>Penguin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The YouTube stars heading for burnout: &apos;The most fun job imaginable became deeply bleak</title>
		<author>
			<persName><forename type="first">Simon</forename><surname>Parkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Guardian</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Association of Digital Media Use With Subsequent Symptoms of Attention-Deficit/Hyperactivity Disorder Among Adolescents</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chaelin</surname></persName>
		</author>
		<author>
			<persName><surname>Ra</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.2018.8931</idno>
	</analytic>
	<monogr>
		<title level="j">JAMA</title>
		<idno type="ISSN">0098-7484</idno>
		<imprint>
			<biblScope unit="volume">320</biblScope>
			<biblScope unit="page" from="255" to="263" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Emotional governance: Politics, media and terror</title>
		<author>
			<persName><forename type="first">Barry</forename><surname>Richards</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Emotion regulation and memory: the cognitive costs of keeping one&apos;s cool</title>
		<author>
			<persName><forename type="first">Jane</forename><forename type="middle">M</forename><surname>Richards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">J</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of personality and social psychology</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page">410</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Negativity drives online news consumption</title>
		<author>
			<persName><forename type="first">Claire</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-023-01538-4</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<idno type="ISSN">2397-3374</idno>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="812" to="822" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">The impact of fake news on social media and its influence on health during the COVID-19 pandemic: a systematic review</title>
		<author>
			<persName><forename type="first">Yasmim</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rocha</forename></persName>
		</author>
		<idno type="DOI">10.1007/s10389-021-01658-z</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Public Health</title>
		<idno type="ISSN">1613-2238</idno>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1007" to="1016" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Costs of a predictible switch between simple cognitive tasks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><surname>Monsell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of experimental psychology: General</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page">207</biblScope>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Aliénation et accélération: vers une théorie critique de la modernité tardive</title>
		<author>
			<persName><forename type="first">Hartmut</forename><surname>Rosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Chaumont</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>La découverte</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Gouvernementalité algorithmique et perspectives d&apos;émancipation</title>
		<author>
			<persName><forename type="first">Antoinette</forename><surname>Rouvroy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Berns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Réseaux</title>
		<imprint>
			<biblScope unit="volume">177</biblScope>
			<biblScope unit="page" from="163" to="196" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Social Influence and Unfollowing Accelerate the Emergence of Echo Chambers</title>
		<author>
			<persName><forename type="first">Kazutoshi</forename><surname>Sasahara</surname></persName>
		</author>
		<idno type="DOI">10.1007/s42001-020-00084-7</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Social Science</title>
		<idno type="ISSN">2432-2717</idno>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="2432" to="2725" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Cyberbullying and Adolescent Suicide</title>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Schonfeld</surname></persName>
		</author>
		<idno type="DOI">10.29158/JAAPL.220078-22</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Academy of Psychiatry and the Law Online</title>
		<idno type="ISSN">1093-6793</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Making TikTok Videos Leaves Musicians Feeling Burnout</title>
		<author>
			<persName><forename type="first">Neil</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wall Street Journal</title>
		<idno type="ISSN">0099-9660</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Combating Fake News: A Survey on Identification and Mitigation Techniques</title>
		<author>
			<persName><forename type="first">Karishma</forename><surname>Sharma</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.1901.06437</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<author>
			<persName><forename type="first">Michael</forename><surname>Siegrist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gorge</forename><surname>Cvetkovich</surname></persName>
		</author>
		<idno type="DOI">10.1111/0272-4332.211102</idno>
	</analytic>
	<monogr>
		<title level="m">Better negative than positive? Evidence of a bias for negative information about possible health dangers</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="199" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Attention, attention: your most valuable scientific assets are under attack</title>
		<author>
			<persName><forename type="first">R</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.15252/embr.201745684</idno>
		<imprint/>
	</monogr>
	<note>In: EMBO reports 19.3 (2018), e45684</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Cross-national evidence of a negativity bias in psychophysiological reactions to news</title>
		<author>
			<persName><forename type="first">Stuart</forename><surname>Soroka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Fournier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lilach</forename><surname>Nir</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1908369116</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences</title>
		<meeting>the National Academy of Sciences</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1091" to="6490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Are algorithms a threat to democracy? The rise of intermediaries: A challenge for public discourse</title>
		<author>
			<persName><forename type="first">Birgit</forename><surname>Stark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithm Watch</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">The Online Disinhibition Effect</title>
		<author>
			<persName><forename type="first">John</forename><surname>Suler</surname></persName>
		</author>
		<idno type="DOI">10.1089/1094931041291295</idno>
	</analytic>
	<monogr>
		<title level="j">Cy-berPsychology &amp; Behavior</title>
		<idno type="ISSN">1094-9313</idno>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="321" to="326" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Why do people share fake news? Associations between the dark side of social media use and fake news sharing behavior</title>
		<author>
			<persName><forename type="first">Shalini</forename><surname>Talwar</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jretconser.2019.05.026</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Retailing and Consumer Services</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="72" to="82" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">No time to kill: How smartphone is pushing chewing gum out of fashion</title>
	</analytic>
	<monogr>
		<title level="j">The Economic Times</title>
		<idno type="ISSN">0013-0389</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Regulation (EU) 2022/2065 of the European Parliament and of the Council of 19 October 2022 on a Single Market For Digital Services and amending Directive 2000/31/EC (Digital Services Act)</title>
	</analytic>
	<monogr>
		<title level="j">Official Journal of the European Union</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>European Union</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">From fake to junk news: The data politics of online virality</title>
		<author>
			<persName><forename type="first">Tommaso</forename><surname>Venturini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data politics. Routledge</title>
		<imprint>
			<biblScope unit="page" from="123" to="144" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Assessing Persuasion in Argumentation through Emotions and Mental States</title>
		<author>
			<persName><forename type="first">Serena</forename><surname>Villata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-First International Florida Artificial Intelligence Research Society Conference, FLAIRS 2018</title>
		<meeting>the Thirty-First International Florida Artificial Intelligence Research Society Conference, FLAIRS 2018<address><addrLine>Melbourne, Florida, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018">May 21-23 2018. 2018</date>
			<biblScope unit="page" from="134" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">The spread of true and false news online</title>
		<author>
			<persName><forename type="first">Soroush</forename><surname>Vosoughi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deb</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sinan</forename><surname>Aral</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.aap9559</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<idno type="ISSN">0036-8075</idno>
		<imprint>
			<biblScope unit="volume">359</biblScope>
			<biblScope unit="page" from="1095" to="9203" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Correction as a solution for health misinformation on social media</title>
		<author>
			<persName><forename type="first">K</forename><surname>Emily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leticia</forename><surname>Vraga</surname></persName>
		</author>
		<author>
			<persName><surname>Bode</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Public Health</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="278" to="S280" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>S</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Brain drain: The mere presence of one&apos;s own smartphone reduces available cognitive capacity</title>
		<author>
			<persName><forename type="first">Adrian F</forename><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Association for Consumer Research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="140" to="154" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">The spread of medical fake news in social media -The pilot quantitative study</title>
		<author>
			<persName><forename type="first">M</forename><surname>Przemyslaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wioleta</forename><surname>Waszak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alicja</forename><surname>Kasprzycka-Waszak</surname></persName>
		</author>
		<author>
			<persName><surname>Kubanek</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.hlpt.2018.03.002</idno>
	</analytic>
	<monogr>
		<title level="j">Health Policy and Technology</title>
		<idno type="ISSN">2211-8837</idno>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="118" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">TikTok&apos;s music influence is &apos;exhausting&apos; artists and marketers alike as the industry grapples with the pressure to go viral</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Whateley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Recommender systems and the amplification of extremist content</title>
		<author>
			<persName><forename type="first">Joe</forename><surname>Whittaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internet Policy Review</title>
		<idno type="ISSN">2197-6775</idno>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">On Sentiment of Online Fake News</title>
		<author>
			<persName><forename type="first">Razieh</forename><surname>Nokhbeh Zaeem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengjing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Suzanne</forename><surname>Barber</surname></persName>
		</author>
		<idno type="DOI">10.1109/ASONAM49781.2020.9381323</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="760" to="767" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Video game loot boxes are linked to problem gambling: Results of a large-scale survey</title>
		<author>
			<persName><forename type="first">David</forename><surname>Zendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Cairns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">206767</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Bored and brilliant: How time spent doing nothing changes everything</title>
		<author>
			<persName><forename type="first">Manoush</forename><surname>Zomorodi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pan Macmillan</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
