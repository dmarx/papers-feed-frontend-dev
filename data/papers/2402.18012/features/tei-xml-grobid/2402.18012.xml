<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Diffusion Models as Constrained Samplers for Optimization with Unknown Constraints</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-10-21">21 Oct 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Lingkai</forename><surname>Kong</surname></persName>
							<email>&lt;lkkong@gatech.edu&gt;</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ENS</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">PSL University</orgName>
								<address>
									<addrLine>6 UCSD</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuanqi</forename><surname>Du</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ENS</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">PSL University</orgName>
								<address>
									<addrLine>6 UCSD</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wenhao</forename><surname>Mu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ENS</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">PSL University</orgName>
								<address>
									<addrLine>6 UCSD</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kirill</forename><surname>Neklyudov</surname></persName>
							<email>&lt;k.necludov@gmail.com&gt;.</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ENS</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">PSL University</orgName>
								<address>
									<addrLine>6 UCSD</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Valentin</forename><surname>De Bortoli</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ENS</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">PSL University</orgName>
								<address>
									<addrLine>6 UCSD</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Haorui</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ENS</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">PSL University</orgName>
								<address>
									<addrLine>6 UCSD</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dongxia</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ENS</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">PSL University</orgName>
								<address>
									<addrLine>6 UCSD</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aaron</forename><surname>Ferber</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ENS</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">PSL University</orgName>
								<address>
									<addrLine>6 UCSD</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yi-An</forename><surname>Ma</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ENS</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">PSL University</orgName>
								<address>
									<addrLine>6 UCSD</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Carla</forename><forename type="middle">P</forename><surname>Gomes</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ENS</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">PSL University</orgName>
								<address>
									<addrLine>6 UCSD</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chao</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ENS</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">PSL University</orgName>
								<address>
									<addrLine>6 UCSD</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Georgia</forename><surname>Tech</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ENS</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">PSL University</orgName>
								<address>
									<addrLine>6 UCSD</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Cornell</forename><surname>University</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ENS</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">PSL University</orgName>
								<address>
									<addrLine>6 UCSD</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Université</forename><surname>De Montréal</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ENS</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">PSL University</orgName>
								<address>
									<addrLine>6 UCSD</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Diffusion Models as Constrained Samplers for Optimization with Unknown Constraints</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-10-21">21 Oct 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">F542D09863E3AB0EB83CF7215E413E4D</idno>
					<idno type="arXiv">arXiv:2402.18012v3[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-02-21T16:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Addressing real-world optimization problems becomes particularly challenging when analytic objective functions or constraints are unavailable. While numerous studies have addressed the issue of unknown objectives, limited research has focused on scenarios where feasibility constraints are not given explicitly. Overlooking these constraints can lead to spurious solutions that are unrealistic in practice. To deal with such unknown constraints, we propose to perform optimization within the data manifold using diffusion models. To constrain the optimization process to the data manifold, we reformulate the original optimization problem as a sampling problem from the product of the Boltzmann distribution defined by the objective function and the data distribution learned by the diffusion model. Depending on the differentiability of the objective function, we propose two different sampling methods. For differentiable objectives, we propose a two-stage framework that begins with a guided diffusion process for warm-up, followed by a Langevin dynamics stage for further correction. For non-differentiable objectives, we propose an iterative importance sampling strategy using the diffusion model as the proposal distribution. Comprehensive experiments on a synthetic dataset, six real-world black-box optimization datasets, and a multi-objective molecule optimization dataset show that our method achieves better or comparable performance with previous state-of-the-art baselines.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Optimization problems are ubiquitous in real-world applications when approaching search problems <ref type="bibr" target="#b6">[7]</ref>, partial differential equations <ref type="bibr" target="#b52">[53]</ref>, molecular design <ref type="bibr" target="#b88">[89]</ref>. While significant advancements have been made in resolving a broad spectrum of abstract optimization problems with analytically known objective functions and constraints <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b83">84,</ref><ref type="bibr" target="#b79">80]</ref>, optimization in real-world scenarios remains challenging since the exact nature of the objective is often unknown, and access to constraints is limited <ref type="bibr" target="#b22">[23]</ref>. For example, it is challenging to incorporate the closed-form constraints on a molecule to be synthesizable or design an objective function for target chemical properties.</p><p>Previous studies have identified problems with unknown objective functions as black-box optimization problems <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b0">1]</ref>. In such scenarios, the only way to obtain the objective value is through running a simulation <ref type="bibr" target="#b67">[68]</ref> or conducting a real-world experiment <ref type="bibr" target="#b90">[91]</ref>, which might be expensive and nondifferentiable. A prevalent approach to this challenge involves learning a surrogate model with available data to approximate the objective function which can be implemented in either an online <ref type="bibr" target="#b91">[92,</ref><ref type="bibr" target="#b89">90,</ref><ref type="bibr" target="#b97">98]</ref> or offline manner <ref type="bibr" target="#b104">[105,</ref><ref type="bibr" target="#b105">106]</ref>.</p><p>However, there is a significant lack of research focused on scenarios where analytic constraints are absent. The only works that deal with unknown constraints are from the derivative-free optimization community <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b77">78]</ref>. However, these methods can only be applied to simple low-dimensional problems and cannot be applied to more complex problems such as molecule and protein optimization. In practice, overlooking these feasibility constraints during optimization can result in spurious solutions. For instance, the optimization process might yield a molecule with the desired chemical property but cannot be physically synthesized <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b29">30]</ref>, which would require restarting the optimization from different initializations <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b53">54]</ref>.</p><p>To restrict the search space to the set of feasible solutions, we propose to perform optimization within the support of the data distribution or the data manifold. Indeed, in practice, one usually has an extensive set of samples satisfying the necessary constraints even when the constraints are not given explicitly. For instance, the set of synthesizable molecules can be described by the distribution of natural products <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b109">110]</ref>. To learn the data distribution, we focus on using diffusion models, which recently demonstrated the state-of-the-art performance in image modeling <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b96">97]</ref>, video generation <ref type="bibr" target="#b47">[48]</ref>, and 3D synthesis <ref type="bibr" target="#b81">[82]</ref>. Moreover, <ref type="bibr" target="#b80">[81,</ref><ref type="bibr" target="#b23">24]</ref> theoretically demonstrated that diffusion models can learn the data distributed on a lower dimensional manifold embedded in the representation space, which is often the case of the feasibility constraints.</p><p>To constrain the optimization process to the data manifold, we reformulate the original optimization problem as a sampling problem from the product of two densities: i) a Boltzmann density with energy defined by the objective function and ii) the density of the data distribution. The former concentrates around the global minimizers in the limit of zero temperature <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b38">39]</ref>, while the latter removes the non-feasible solutions by yielding the zero target density outside the data manifold. Depending on whether the objective function is differentiable or non-differentiable, we propose two different sampling methods. When the objective function is differentiable, we propose a two-stage sampling strategy: (i) a guided diffusion process acts as a warm-up stage to provide initialization of data samples on the manifold, and (ii) we ensure convergence to the target distribution via Markov Chain Monte Carlo (MCMC). When the objective is non-differentiable, we propose an iterative importance sampling strategy using diffusion models to gradually improve the proposal distribution.</p><p>The main contributions of this work are: <ref type="bibr" target="#b0">(1)</ref> We reformulate the problem of optimization under unknown constraints as a sampling problem from the product of the data distribution and the Boltzmann distribution defined by the objective function. <ref type="bibr" target="#b1">(2)</ref> We propose two different sampling methods with diffusion models, depending on the differentiability of the objective function. (3) Empirically, we validate the effectiveness of our proposed framework on a synthetic toy example, six real-world offline black-box optimization tasks as well as a multi-objective molecule optimization task. We find that our method, named DIFFOPT, can outperform state-of-the-art methods or achieve competitive performance across these tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Problem definition. Consider an optimization problem with objective function h : R d → R. Additionally, we consider a feasible set C, which is a subset of R d .</p><p>Our goal is to find the set of minimizers {x ⋆ i } M i=1 of the objective h within the feasible set C. This can be expressed as the following constrained optimization problem {x ⋆ i } M i=1 = arg min x∈C h(x). However, in our specific scenario, the explicit formulation of the feasible set C is unavailable. Instead, we can access a set of points D = {x i } N i=1 sampled independently from the feasible set C. Optimization via sampling. If we do not consider the constraints, under mild assumption, the optimization process is equivalent to sample from a Boltzmann distribution q β (x) ∝ exp[-βh(x)], in the limit where β → ∞, where β is an inverse temperature parameter. This is the result of the following proposition which can be found in <ref type="bibr" target="#b51">[52,</ref><ref type="bibr">Theorem 2.1]</ref>. Proposition 1. Assume that h ∈ C 3 (R d , R). Assume that {x ⋆ i } M i=1 is the set of minimizers of h. Let p be a density on R d such that there exists i 0 ∈ {1, . . . , M } with p(x ⋆ i0 ) &gt; 0. Then Q β the distribution with density w.r.t the Lebesgue measure ∝ q β (x)p(x) weakly converges to Q ∞ as β → ∞ and we have that</p><formula xml:id="formula_0">Q ∞ = M i=1 a i δ x ⋆ i / M i=1 a i ,<label>(a)</label></formula><p>Diffusion model</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Unconstrained sampling</head><p>DiffOPT Minimizer (b)</p><p>Figure <ref type="figure">1</ref>: Constrained optimization as a sampling from the product of densities. That is, we minimize the objective function h(x) (red stars denote the minimizers) within the feasible set C, which is given by samples {x i } N i=1 ∼ p(x). This problem is equivalent to sampling from the density π β (x) ∝ p(x) exp[-βh(x)], which concentrates around minimizers of h(x) within the feasible set C. The distribution we sample from is shown on the left and the trajectory we take to sample is shown on the right.</p><formula xml:id="formula_1">with a i = p(x ⋆ i ) det(∇ 2 h(x ⋆ i )) -1/2 .</formula><p>Based on this proposition, <ref type="bibr" target="#b38">[39]</ref> proposed a tempered method for global optimization. However, the proposed temperature schedule scales logarithmically with the number of steps; hence, the total number of iterations scales exponentially, hindering this method's straightforward application. In practice, we can sample from the density with the target high β, see <ref type="bibr" target="#b82">[83,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b24">25]</ref>.</p><p>Product of Experts. To constrain our optimization procedure to the feasible set C, we propose to model the target density as a product of experts <ref type="bibr" target="#b46">[47]</ref>, a modeling approach representing the "unanimous vote" of independent models. Given the density models of m ∈ N "experts" {q i (x)} m i=1 , the target density of their product is defined as</p><formula xml:id="formula_2">π(x) ∝ m i=1 q i (x) .</formula><p>Hence, if one of the experts yields zero density at x, the total density of the product at x is zero.</p><p>Diffusion Models. Given a dataset D = {x i } N i=1 ∼ p data (x) ⊗N with p data concentrated on the feasible set C, we will learn a generative model p such that p ≈ p data using a diffusion model <ref type="bibr" target="#b92">[93,</ref><ref type="bibr" target="#b95">96,</ref><ref type="bibr" target="#b48">49]</ref>. The density p will then be used in our product of experts model to enforce the feasibility constraints, see Section 3.1. In diffusion models, we first simulate a forward noising process starting from data distribution p 0 (x) = p data (x) which converges to the standard Gaussian distribution p T (x) ≈ N (0, Id) as T → ∞. The forward process is defined by the following stochastic differential equation (SDE)</p><formula xml:id="formula_3">dx t = f (x t , t)dt + g(t)dw t , x 0 ∼ p data (x), 0 ≤ t ≤ T ,</formula><p>where f : R d → R d is a vector-valued drift function, g(t) : R → R is a scalar-valued diffusion coefficient, and (w t ) t≥0 is a d-dimensional Brownian motion. Then, under mild assumptions, the reverse process that generates data from normal noise follows the backward SDE <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b1">2]</ref> </p><formula xml:id="formula_4">dx t = -f (x t , τ ) + g 2 (τ )∇ x log p τ (x t ) dt + g(τ )dw t ,</formula><p>where τ = T -t and ∇ x log p τ (x) is the score function which is modeled by a time-dependent neural network via the score matching objective</p><formula xml:id="formula_5">E t λ(t)E x 0 E x t |x 0 ∥s θ (x t , t) -∇ x log p t|0 (x t |x 0 )∥ 2 2</formula><p>, where p t|0 (x t |x 0 ) is the conditional density of the forward SDE starting at x 0 , and λ(t) &gt; 0 is a weighting function. Under assumptions on f and g, there exists α, σ such that for any t ∈ [0, T ], x t = α t x 0 + σ t ε, where ε ∼ N (0, Id), and therefore one does not need to integrate the forward SDE to sample (x 0 , x t ). Recent works have shown that diffusion models can detect the underlying data manifold supporting the data distribution <ref type="bibr" target="#b80">[81,</ref><ref type="bibr" target="#b23">24]</ref>. This justifies the use of the output distribution of a diffusion model as a way to identify the feasible set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Method</head><p>In this section, we present our method, DIFFOPT. First, we formulate the optimization process as a sampling problem from the product of the data distribution concentrated on the manifold and the Boltzmann distribution defined by the objective function. Then we propose two sampling methods with diffusion models for different types of objective functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Constrained Optimization as Sampling from Product of Experts</head><p>We recall that q β (x) ∝ exp[-βh(x)], where h is the objective function. While it is possible to sample directly from q β (x), the generated samples may fall outside of the feasible set C, defined by the dataset D. To address this, we opt to sample from the product of the data distribution and the Bolzmann distribution induced by the objective function. Explicitly, our goal is to sample from a distribution π β (x) defined as</p><formula xml:id="formula_6">π β (x) ∝ p(x)q β (x).<label>(1)</label></formula><p>Using Proposition 1, we have that π β concentrates on the feasible minimizers of h as β → +∞.</p><p>It should be noted that Equation (1) satisfies the following properties: (a) it assigns high likelihoods to points x that simultaneously exhibit sufficiently high likelihoods under both the base distributions p(x) and q β (x); (b) it assigns low likelihoods to points x that display close-to-zero likelihood under either one or both of these base distributions. This approach ensures that the generated samples not only remain within the confines of the data manifold but also achieve low objective values.</p><p>In practice, the objective function h can be either differentiable or non-differentiable. In the following sections, we will propose two sampling methods using diffusion models, for each type respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Differentiable Objective: Two-stage Sampling with Optimization-guided Diffusion</head><p>Under mild assumptions, the following SDE converges to π β w.r.t. the total variation distance <ref type="bibr" target="#b85">[86]</ref> </p><formula xml:id="formula_7">dx t = ∇ x log π β (x t )dt + √ 2dw t .<label>(2)</label></formula><p>where the gradient of the unnormalized log-density can be conveniently expressed as the sum of the scores, i.e., ∇ x log π β (x) = ∇ x log p(x) + ∇ x log q β (x). Furthermore, one can introduce a Metropolis-Hastings (MH) correction step to guarantee convergence to the target distribution when using discretized version of Equation (2) <ref type="bibr" target="#b30">[31]</ref>, which is known as the Metropolis-Adjusted-Langevin-Algorithm (MALA) <ref type="bibr" target="#b40">[41]</ref>. We provide more details for both algorithms in Appendix C.</p><p>Theoretically, sampling from the density in Equation ( <ref type="formula" target="#formula_6">1</ref>) can be done via MALA. However, in practice, the efficiency of this algorithm significantly depends on the choice of the initial distribution and the step size schedule. The latter is heavily linked with the Lipschitz constant of log q β which controls the stability of the algorithm. Large values of β, necessary to get accurate minimizers, also yield large Lipschitz constants which in turn impose small stepsizes. Moreover, the gradient of the log-density can be undefined outside the feasibility set C.</p><p>To circumvent these practical issues, we propose sampling in two stages: a warm-up stage and a sampling stage. The former aims to provide a good initialization for the sampling stage. The sampling stage follows the Langevin dynamics for further correction. The pseudocode for both stages is provided in Appendix D.</p><p>Stage I: Warm-up with guided diffusion. In imaging inverse problems, it is customary to consider guided diffusion models to enforce some external condition, see <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b93">94,</ref><ref type="bibr" target="#b116">117]</ref>. In our setting, we adopt a similar strategy where the guidance term is given by βh, i.e., we consider</p><formula xml:id="formula_8">dx t = [-f (x t , τ ) + g 2 (τ )s θ (x t , τ ) -β∇h(x t )]dt + g(τ )dw t , τ = T -t.<label>(3)</label></formula><p>Theorem 1. Under assumptions on p, h, we denote p β T -t the distribution of Equation (3) at time t and there exists C &gt; 0 such that for any</p><formula xml:id="formula_9">x ∈ R d (1/C)p β 0 (x) ≤ p β 0 (x) ≤ C pβ 0 (x)</formula><p>, where p β 0 is the output of the warm-up guided diffusion process and pβ 0 (x) = p 0 (x) exp[log(β 0 )W β 0 (x)], with W β 0 (x) = ∆h(x) + ⟨∇ log p β 0 (x), ∇h(x)⟩ and β 0 is the inverse temperature parameter at the end of the process The proof is postponed to Appendix H. As an immediate consequence of Theorem 1, we have that lim β0→∞ p β 0 (x ⋆ ) = +∞ for every local strict minimizer x ⋆ of h within the support of p 0 (x), and lim β0→∞ p β 0 (x ⋆ ) = 0 for x ⋆ outside the support of p 0 (x), see Appendix H. That is, p β 0 concentrates on the feasible local minimizers of h as β 0 → +∞.</p><p>Theorem 1 indicates that the guided diffusion process in the first stage yields a more effectively initialized distribution within the data manifold, bounded both above and below by a product of experts related to the original constrained optimization problem. However, it is known that guided diffusion cannot accurately sample from the product of experts q β <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b35">36]</ref>, see more details in Appendix E. While additional contrastive training of a surrogate objective has been proposed <ref type="bibr" target="#b72">[73]</ref>, in this work, we do not consider such complex corrections. Instead, we rely on ideas from MCMC literature to ensure convergence.</p><p>Stage II: Further correction with Langevin dynamics. In the second stage, we further use Langevin dynamics for accurate sampling from π β (x). The gradient of the log-density of the data distribution ∇ log p(x) can be obtained by setting the time of the score function to 0, i.e., s θ (x, 0). The unadjusted Langevin algorithm is then given by</p><formula xml:id="formula_10">x k+1 = x k + (s θ (x k , 0) -β∇ x h(x k ))∆t + √ 2∆tz,</formula><p>where ∆t is the step size and z comes from a Gaussian distribution. In practice, we find that a constant β is enough for this stage. When using the score-based parameterization s θ (x, t), we cannot access the unnormalized log-density of the distribution. Therefore, we cannot use the MH correction step. Although the sampler is not exact without MH correction, it performs well in practice.</p><p>To further incorporate the MH correction step, we can adopt an energy-based parameterization following <ref type="bibr" target="#b28">[29]</ref>:</p><formula xml:id="formula_11">E θ (x, t) = -1 2 ∥NN θ (x, t)∥ 2</formula><p>, where E θ (x, t) is the energy function of the data distribution, and NN θ (x, t) is a vector-output neural network. An additional benefit of MH correction is that it can enforce hard constraints. If x k+1 is outside the data distribution (p(x) = 0), this point cannot be accepted. We provide more details of this energy-based parameterization in Appendix G.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Non-differentiable Objective: Iterative Importance Sampling with Diffusion Models</head><p>When gradients of the objective function are unavailable, we can use self-normalized importance sampling (SNIS) <ref type="bibr" target="#b86">[87]</ref>, which is easy and fast to implement. SNIS first proposes several particles from a proposal distribution. Then, resample the particles according to their weights, calculated as the ratio of the target density to the proposal density.</p><p>However, the performance of SNIS is heavily determined by the proposal distribution. A good proposal distribution should be close to the target distribution. To address this, we employ an iterative importance sampling with diffusion models to improve the initial proposal distribution. The pseudocode of our derivative-free sampling algorithm is provided in Appendix F.</p><p>Initialization with SNIS. We begin by randomly sampling S particles {x 0 s } S s=1 from the diffusion model p θ (x), assigning each particle a weight w 0 s = π β (x 0 s ) p θ (x 0 s ) = q β (x 0 s ). We then resample S particles based on the normalized weights w0 s = w 0 s S j=1 w 0 j using multinomial sampling with replacement.</p><p>Diffusion-guided proposal for iterative importance sampling. At the k-th iteration, we have S particles {x k-1 s } S s=1 resampled from the previous iteration. The key insight of our method is that these resampled particles form a proposal distribution closer to the target distribution. However, these resampled particles tend to be repetitive and lack diversity. To address this, we use a diffusion model to diversify the resampled particles, ensuring that the proposal distribution remains diverse and closely approximates the target distribution. Henceforth, we will use x k s and x k s,0 interchangeably to refer to the particle at time 0. We also omit the arrows denoting forward/reverse process of diffusion models for simplicity.</p><p>The diversify process works as follows: we first add noise to the particles x k-1 s,0 through a forward diffusion process until a randomly sampled time t to get x k-1 s,t ∼ p t|0 (x k-1 s,t |x k-1 s,0 ). Then we denoise them back to obtain new particles x k s,0 ∼ p 0|t (x k s,0 |x k-1 s,t ). This proposal can be written as</p><formula xml:id="formula_12">Q(x k s |x k-1 s ) = p t|0 (x k-1 s,t |x k-1 s,0 )p 0|t (x k s,0 |x k-1 s,t ) dx k-1 s,t .</formula><p>We use the Monte Carlo method to compute the marginalization by drawing J samples x k-1 s,t,j for each particle:</p><formula xml:id="formula_13">Q(x k s |x k-1 s ) ≈ 1 J J j=1 p 0|t (x k s,0 |x k-1 s,t,j ).</formula><p>Sampling x k-1 s,t,j is straightforward as the forward process in diffusion models admits a closed-form conditional Gaussian distribution:</p><formula xml:id="formula_14">p t|0 (x k-1 s,t |x k-1 s,0 ) = N (x k-1 s,t |α t x k-1 s,0 , σ 2 t Id). Following [95], we approximate p(x k s,0 |x k-1 s,t ) as N ( x k-1 s,t,j +σts θ (x k-1 s,t,j ,t) αt , σ 2 t 1+σt Id). The marginalization Q(x k s</formula><p>) is computed by enumerating all the particles from last iteration, i.e., 1</p><formula xml:id="formula_15">S S s ′ =1 Q(x k s |x k-1 s ′ ). Each particle is assigned a weight w k s = π β (x k s ) Q(x k s )</formula><p>. We then resample S particles based on the normalized weights. This process is iterated for K steps.</p><p>Note that by involving only resampling and diffusion models in each iteration, we can ensure staying within the data manifold, thereby satisfying hard constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>Diffusion models and data manifold. Diffusion models have demonstrated impressive performance in various generative modeling tasks, such as image generation <ref type="bibr" target="#b96">[97,</ref><ref type="bibr" target="#b48">49]</ref>, video generation <ref type="bibr" target="#b47">[48]</ref>, and protein synthesis <ref type="bibr" target="#b111">[112,</ref><ref type="bibr" target="#b41">42]</ref>. Several studies reveal diffusion models implicitly learn the data manifold <ref type="bibr" target="#b80">[81,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b112">113]</ref>. This feature of diffusion models has been used to estimate the intrinsic dimension of the data manifold in <ref type="bibr" target="#b98">[99]</ref>. Moreover, the concentration of the samples on a manifold can be observed through the singularity of the score function. This phenomenon is well-understood from a theoretical point of view and has been acknowledged in <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b16">17]</ref>.</p><p>Optimization as sampling problems. Numerous studies have investigated the relationship between optimization and sampling <ref type="bibr" target="#b73">[74,</ref><ref type="bibr" target="#b99">100,</ref><ref type="bibr" target="#b107">108,</ref><ref type="bibr" target="#b113">114,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19]</ref>. Sampling-based methods have been successfully applied in various applications of stochastic optimization when the solution space is too large to search exhaustively <ref type="bibr" target="#b66">[67]</ref> or when the objective function exhibits noise <ref type="bibr" target="#b10">[11]</ref> or countless local optima <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b12">13]</ref>. A prominent solution to global optimization is through sampling with Langevin dynamics <ref type="bibr" target="#b38">[39]</ref>, which simulates the evolution of particles driven by a potential energy function. Furthermore, simulated annealing <ref type="bibr" target="#b58">[59]</ref> employs local thermal fluctuations enforced by Metropolis-Hastings updates to escape local minima <ref type="bibr" target="#b75">[76,</ref><ref type="bibr" target="#b43">44]</ref>. More recently, <ref type="bibr" target="#b119">[120]</ref> employs generative flow networks to amortize the cost of the sampling process for combinatorial optimization with both closed-form objectives and constraints.</p><p>Learning for optimization. Recently, there has been a growing trend of adopting machine learning methods for optimization tasks. The first branch of work is model-based optimization, which focuses on learning a surrogate model for the black-box objective function. This model can be developed in either an online <ref type="bibr" target="#b91">[92,</ref><ref type="bibr" target="#b89">90,</ref><ref type="bibr" target="#b97">98,</ref><ref type="bibr" target="#b120">121]</ref>, or an offline manner <ref type="bibr" target="#b117">[118,</ref><ref type="bibr" target="#b106">107,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b118">119]</ref>. Additionally, some research <ref type="bibr" target="#b64">[65,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b57">58]</ref> has explored the learning of stochastic inverse mappings from function values to the input domain, utilizing generative models such as generative adversarial nets <ref type="bibr" target="#b39">[40]</ref> and diffusion models <ref type="bibr" target="#b96">[97,</ref><ref type="bibr" target="#b48">49]</ref>.</p><p>The second branch, known as "Learning to Optimize", involves training a neural network to address fully specified optimization problems. In these works, a model is trained using a distribution of homogeneous instances, to achieve generalization on similar unseen instances. Various learning paradigms have been used in this context, including supervised learning <ref type="bibr" target="#b70">[71,</ref><ref type="bibr" target="#b36">37]</ref>, reinforcement learning <ref type="bibr" target="#b68">[69,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b60">61]</ref>, unsupervised learning <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b110">111,</ref><ref type="bibr" target="#b76">77]</ref>, and generative modeling <ref type="bibr" target="#b100">[101,</ref><ref type="bibr" target="#b69">70]</ref>. Several surveys <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b74">75]</ref> have covered different facets of this research area. In contrast to our approach, these works typically involve explicitly defined objectives and constraints.</p><p>Optimization under unknown constraints. Existing work on optimization under unknown constraints are based on derivative-free optimization methods, such as generalized pattern search <ref type="bibr" target="#b2">[3]</ref>, mesh adaptive direct search <ref type="bibr" target="#b3">[4]</ref>, line search <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b71">72]</ref>, the Frank-Wolfe algorithm <ref type="bibr" target="#b108">[109]</ref>, and stochastic zeroth-order constraint extrapolation <ref type="bibr" target="#b77">[78]</ref>.</p><p>However, these works differ from ours and are not directly comparable. First, the settings are different-they require oracle evaluation of whether a proposed solution violates constraints during the optimization process, whereas we do not need this. We only require data samples from the feasible set. Second, these works are hardly applied to the high-dimensional problems that we focus on, such as molecule optimization, protein design, and robot morphology optimization.</p><p>Step 1</p><p>Step 10</p><p>Step 100</p><p>Step 500</p><p>Step 1000 Step 1</p><p>Step 10</p><p>Step 100</p><p>Step 500</p><p>Step 1000 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiment</head><p>In this section, we conduct experiments on (1) a synthetic Branin task, (2) six real-world offline black-box optimization tasks, and (3) a multi-objective molecule optimization task. Finally, we do ablation studies to verify the effectiveness of each model design of DIFFOPT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Synthetic Branin Function Optimization</head><p>We first validate our model on a synthetic Branin task. The Branin function <ref type="bibr" target="#b26">[27]</ref> is given as</p><formula xml:id="formula_16">f (x 1 , x 2 ) = a(x 2 -bx 2 1 + cx 1 -r) 2 + s(1 -t)cos(x 1 ) + s, where a = 1, b = 5.1 4π 2 , c = 5 π , r = 6, s = 10, t = 1 8π</formula><p>. The function has three global minimas, (-π, 12.275), (π, 2.275), and (9.42478, 2.475).</p><p>Optimization with unknown constraints. To assess the capability of DIFFOPT in optimizing functions under unknown constraints, we generate a dataset of 6,000 points, uniformly distributed within the feasible domain shaped like an oval. An effective optimizer is expected to infer the feasible space from the dataset and yield solutions strictly within the permissible region, i.e., (-π, 12.275) and (π, 2.275). We train a diffusion model with Variance Preserving (VP) SDE <ref type="bibr" target="#b96">[97]</ref> on this dataset. More details of the experimental setup are provided in Appendix I. Figure <ref type="figure" target="#fig_0">2</ref> illustrates the sampling trajectory of DIFFOPT, clearly demonstrating its capability in guiding the samples towards the optimal points confined to the feasible space.</p><p>Compatible with additional known constraints. Our framework is also adaptable to scenarios with additional, known constraints C ′ . In such instances, we introduce an extra objective function whose Boltzmann density is uniform within the constraint bounds and 0 otherwise, i.e., q ′ (x) ∝ exp[β ′ • I(x ∈ C ′ )], with I(•) being the indicator function. To demonstrate this capability, we incorporate a closed-form linear constraint alongside the implicit constraint represented by the dataset. This new constraint narrows the feasible solutions to only (π, 2.275). As depicted in Figure <ref type="figure" target="#fig_1">3</ref>, DIFFOPT effectively navigates towards the sole viable minimizer within the constrained space delineated by the data-driven and explicitly stated constraints. This feature is particularly beneficial in practical applications, such as molecular optimization, where imposing additional spatial or structure constraints might be necessary during optimizing binding affinities with different protein targets <ref type="bibr" target="#b29">[30]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Offline Black-box Optimization</head><p>We further evaluate DIFFOPT on the offline black-box optimization task, wherein a logged dataset is utilized to train a surrogate model that approximates the objective function. The surrogate model is Table 2: Results on the multi-objective molecule optimization task. Sum denotes the total objective (QED + GSK3B -SA). SA is normalized from the range 1-10 to 0-1. We report the mean and standard deviation across five random seeds. The best results are bolded, and the second best is underlined. Top-1 denotes the best solution found, and Top-10 denotes the average of the best ten solutions found. Invalidity denotes the number of invalid molecules in the 1000 generated samples.</p><p>trained on finite data and may have large fitness errors beyond the data distribution. At inference time, if we directly apply gradient ascent on the surrogate objective, it may produce out-of-distribution designs that "fool" the learned surrogate model into outputting a high value. Therefore, we need to constrain the optimization process within the data distribution because the trained surrogate is only reliable within this range. However, this data distribution constraints cannot be expressed analytically, and therefore this task can be viewed as an instance of optimization with unknown constraints.</p><p>Following <ref type="bibr" target="#b63">[64]</ref>, we conduct evaluation on six tasks of DesignBench <ref type="bibr" target="#b105">[106]</ref>. Superconductor is to optimize for finding a superconducting material with high critical temperature. Ant nad D'Kitty is to optimize the robot morphology. TFBind8 and TFBind10 are to find a DNA sequence that maximizes binding affinity with specific transcription factors. ChEMBL is to optimize the drugs for a particular chemical property.</p><p>Baselines. We compare DIFFOPT with multiple baselines, including gradient ascent, Bayesian optimization (GP-qEI) <ref type="bibr" target="#b63">[64]</ref>, REINFORCE <ref type="bibr" target="#b101">[102]</ref>, evolutionary algorithm (CAM-ES) <ref type="bibr" target="#b42">[43]</ref>, and recent methods like MINS <ref type="bibr" target="#b64">[65]</ref>, COMs <ref type="bibr" target="#b104">[105]</ref>, CbAS <ref type="bibr" target="#b11">[12]</ref> and DDOM <ref type="bibr" target="#b63">[64]</ref>. We follow <ref type="bibr" target="#b63">[64]</ref> and set the sampling budget as 256. More details of the experimental setups are provided in Appendix I.</p><p>Results. Table <ref type="table" target="#tab_0">1</ref> shows the performance on the six datasets for all the methods. As we can see, DIFFOPT achieves an average rank of 2.0, the best among all the methods. We achieve the best result on 4 tasks. Particularly, in the Superconductor task, DIFFOPT surpasses all baseline methods by a significant margin, improving upon the closest competitor by 9.6%. The exceptional performance of DIFFOPT is primarily due to its application of a diffusion model to learn the valid data manifold directly from the data set, thus rendering the optimization process significantly more reliable. In contrast, the gradient ascent method, which relies solely on optimizing the trained surrogate model, is prone to settle on suboptimal solutions. Moreover, while DDOM <ref type="bibr" target="#b63">[64]</ref> employs a conditional diffusion model to learn an inverse mapping from objective values to the input space, its ability to generate samples is confined to the maximum values present in the offline dataset. This limitation restricts its ability to identify global maximizers within the feasible space. The experimental results also demonstrate that DIFFOPT can consistently outperform DDOM except for the Ant Dataset. On Ant, we find that the suboptimal performance of DIFFOPT is because the surrogate model is extremely difficult to train. We provide more analyses in Appendix J.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Multi-objective Molecule Optimization</head><p>An additional advantage of incorporating the data distribution constraints for offline black-box optimization is their direct impact on enhancing the validity of generated solutions. However, it's worth noting that DesignBench lacks a specific metric for assessing validity. Therefore, we further test on a multi-objective molecule optimization task and extend our evaluation to include validity. In this task, we have three objectives: the maximization of the quantitative estimate of drug-likeness (QED), and the activity against glycogen synthase kinase three beta enzyme (GSK3B), and the minimization of the synthetic accessibility score (SA). Following <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b31">32]</ref>, we utilize a pre-trained autoencoder from <ref type="bibr" target="#b54">[55]</ref> to map discrete molecular structures into a continuous low-dimensional latent space and train neural networks as proxy functions for predicting molecular properties to guide the optimization. The detailed experimental setups are provided in Appendix I.</p><p>Results. For each method, we generate 1,000 candidate solutions, evaluating the three objective metrics solely on those that are valid. As we can see from Table <ref type="table">2</ref>, DIFFOPT can achieve the best validity performance among all the methods. In terms of optimization performance, DIFFOPT can achieve the best overall objective value. We further report the average of the top 10 solutions found by each model and find that DiffOPT is also reliable in this scenario. This multi-objective optimization setting is particularly challenging, as different objectives can conflict with each other. The superior performance of DIFFOPT is because we formulate the optimization problem as a sample problem from the product of experts, which is easy for compositions of various objectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Derivative-free Optimization</head><p>Hypervolume In this subsection, we explore the scenario where the objective function is not differentiable and examine the effectiveness of the proposed iterative importance sampling with diffusion models. We continue using the molecule optimization task. Here, we do not train a surrogate objective using offline data but instead directly use the oracle function from Rdkit <ref type="bibr" target="#b84">[85]</ref>. We compare our method with evolutionary algorithm (EA; <ref type="bibr" target="#b42">[43]</ref>), which is a common technique in derivative-free multi-objective optimization. Additionally, we compare our method with one-step importance sampling (IS) using diffusion models as the proposal distribution. Table <ref type="table" target="#tab_2">3</ref> provides the performance of all the methods. As we can see, DIFFOPT can achieve the best hypervolume and validity among all the methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Ablation Study</head><p>In this section, we conduct ablation studies to explore the two-stage sampling. We also study the impact of annealing strategies and sample efficiency of DIFFOPT in Appendix K. Impact of two-stage sampling. Table <ref type="table" target="#tab_3">4</ref> shows the impact of two-stage sampling on performance. Our findings reveal that even after the initial stage, DIFFOPT outperforms the top-performing baseline on both datasets. Relying solely on Langevin dynamics, without the warm-up phase of guided diffusion, results in significantly poorer results. This aligns with our discussion in Section 3.2, where we attributed this failure to factors such as the starting distribution, the schedule for step size adjustments, and the challenges posed by undefined gradients outside the feasible set. Integrating both stages yields a performance improvement as the initial stage can provide a better initialization within the data manifold for the later stage (Theorem 1). Adding the MH correction step further enhances results, leading to the best performance observed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we propose DIFFOPT to solve optimization problems where analytic constraints are unavailable. We learn the unknown feasible space from data using a diffusion model and then reformulate the original problem as a sampling problem from the product of (i) the density of the data distribution learned by the diffusion model and (ii) the Boltzmann density defined by the objective function. For differentiable objectives, we propose a two-stage framework consisting of a guided diffusion stage for warm-up and a Langevin dynamics stage for further correction. For non-differentiable objectives, we propose an iterative importance sampling method with diffusion models as the proposal distribution. Our experiments validate the effectiveness of DIFFOPT. Due to the space limit, we discuss limitations and future work in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Pseudocode of the</head><p>Two-Stage Sampling 17 E Illustration of Why Guided Diffusion Cannot Sample from the Product of Experts 17 F Pseudocode of the Proposed Derivative-free Sampling 18 G Energy-based Parameterization 18 H End Distribution of the Warm-up Stage 19 I Experiment Details 22 I.1 Computing Infrastructure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 I.2 Synthetic Branin Experiment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 I.3 Offline Black-box Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 I.4 Multi-objective Molecule Optimization . . . . . . . . . . . . . . . . . . . . . . . 23 J Analysis on Ant Dataset 24 K Additional Ablation Studies 25</p><p>A Limitations and Future Work</p><p>We discuss limitations and possible extensions of DIFFOPT. (i) Manifold preserving. The guided diffusion may deviate from the manifold that the score network is trained, leading to error accumulations. One approach to mitigate this is to incorporate manifold constraints during the guided diffusion phase <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b45">46]</ref>. (ii) Online learning. We have applied DIFFOPT in the offline black-box optimization (BBO) setting. Considering the unknown constraints not only benefits the offline setting but also helps the online BBO. In the context of online BBO, we propose molecules and subsequently receive evaluations from the ground-truth simulator at each iteration to train the surrogate objective. Proposing a higher proportion of valid molecules can significantly increase the sampling efficiency of training the surrogate objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Broader Impacts</head><p>Optimization techniques can be used to solve a wide range of real-world problems, from decision making (planning, reasoning, and scheduling), to solving PDEs, and to designing new drugs and materials. The method we present in this paper extends the scope of the previous study to a more realistic setting where (partial) constraints for optimization problems are unknown, but we have access to samples from the feasible space. We expect that by learning the feasible set from data, our work can bring a positive impact to the community in accelerating solving real-world optimization problems and finding more realistic solutions. However, care should be taken to prevent the method from being used in harmful settings, such as optimizing drugs to enhance detrimental side effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C (Metropolis-adjusted) Langevin Dynamics.</head><p>Langevin dynamics is a class of Markov Chain Monte Carlo (MCMC) algorithms that aims to generate samples from an unnormalized density π(x) by simulating the differential equation</p><formula xml:id="formula_17">dx t = ∇ x log π(x t )dt + √ 2dw t .<label>(4)</label></formula><p>Theoretically, the continuous SDE of Equation ( <ref type="formula" target="#formula_17">4</ref>) is able to draw exact samples from π(x). However, in practice, one needs to discretize the SDE using numerical methods such as the Euler-Maruyama method <ref type="bibr" target="#b59">[60]</ref> for simulation. The Euler-Maruyama approximation of Equation ( <ref type="formula" target="#formula_17">4</ref>) is given by</p><formula xml:id="formula_18">x t+∆t = x t + ∇ log π(x) + √ 2∆tz, z ∼ N (0, 1), (<label>5</label></formula><formula xml:id="formula_19">)</formula><p>where ∆t is the step size. By drawing x 0 from an initial distribution and then simulating the dynamics in Equation ( <ref type="formula" target="#formula_17">4</ref>), we can generate samples from π(x) after a 'burn-in' period. This algorithm is known as the Unadjusted Langevin Algorithm (ULA) <ref type="bibr" target="#b85">[86]</ref>, which requires ∇ log π(x) to be L-Lipschitz for stability.</p><p>The ULA always accepts the new sample proposed by Equation ( <ref type="formula" target="#formula_18">5</ref>). In contrast, to mitigate the discretization error when using a large step size, the Metropolis-adjusted Langevin Algorithm (MALA) <ref type="bibr" target="#b40">[41]</ref> uses the Metropolis-Hastings algorithm to accept or reject the proposed sample. Specifically, we first generate a proposed update x with Equation ( <ref type="formula" target="#formula_17">4</ref>), then with probability min(1, π(x)N (x|x+∆t•∇ x log π(x),2∆t) π(x)N (x|x+∆t•∇x log π(x),2∆t) ), we set x t+∆t = x, otherwise x t+∆ = x t . We provide the pseudocode of both algorithms in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Sampling via the (Metropolis-Adjusted) Langevin dynamics</head><p>Require: unnormalized density π(x), step size ∆t 1: x ∼ initial distribution 2: X = ∅ 3: for number of iterations do 4:</p><formula xml:id="formula_20">x = x + ∇ x log π(x)∆t + √ 2∆t • z, z ∼ N (0<label>, 1) 5:</label></formula><p>if applying Metropolis-Hastings test then 6:</p><p>u ∼ Uniform[0, 1]</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7:</head><p>log P accept = log π(x)N (x|x+∆t•∇ x log π(x),2∆t) π(x)N (x|x+∆t•∇x log π(x),2∆t)</p><p>8:</p><p>if log P accept &gt; log u, then x ← x 9:</p><p>else 10:</p><p>x ← x 11:</p><p>end if</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>12:</head><p>X ← X ∪ x 13: end for 14: Return X</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Pseudocode of the Two-Stage Sampling</head><p>The pseudocode for the proposed two-stage sampling method is provided in Algorithm 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Illustration of Why Guided Diffusion Cannot Sample from the Product of Experts</head><p>The primary limitation of relying solely on Stage I is its inability to theoretically sample from our desired true target distribution, the product of distributions π β ∝ p(x)q β (x). This is because the score of the diffused marginal distribution does not directly correspond to the aggregate of the scores from each individual distribution,</p><formula xml:id="formula_21">∇ x log π t β (x t ) = ∇ x log p 0 (x 0 )q β (x 0 )p t|0 (x t |x 0 )dx 0 ̸ = ∇ x log q β (x t ) + ∇ x log p 0 (x 0 )p t|0 (x t |x 0 )dx 0 , pt<label>(</label></formula><p>xt) t &gt; 0, where p t|0 (x t |x 0 ) is the conditional density of the forward SDE starting at x 0 . Algorithm 2 Sampling via DIFFOPT for differentiable objective Require: inverse temperature schedule β(t), diffusion volatility schedule g(t) and drift f (x, t), score model s θ (x t , t), energy function of the data distribution E θ (x, t) if applying the MH correction. 1: X ← ∅ 2: Sample x 0 ∼ N (0, Id) 3: // Stage I: Warm-up with guided diffusion. 4: for t = 0, . . . , T do 5:</p><p>Draw z ∼ N (0, Id), define τ = T -t 6:</p><formula xml:id="formula_22">x t+∆t ← x t + [-f (x t , τ ) + g 2 (τ )s θ (x t , τ ) 7: -β(τ )∇ xt h(x t )]∆t + g(τ )</formula><p>√ ∆tz 8: end for 9: // Stage II: Further correction with Langevin dynamics. 10: for t = T, . . . , T ′ do 11:</p><p>Draw z ∼ N (0, Id)</p><formula xml:id="formula_23">12: x ← x + [s θ (x, 0) -β∇h(x)]∆t + √ 2∆tz 13:</formula><p>if applying Metropolis-Hastings test then 14:</p><formula xml:id="formula_24">u ∼ Uniform[0, 1]</formula><p>15:</p><formula xml:id="formula_25">ℓ θ (x) = E θ (x, 0) -βh(x)</formula><p>16:</p><formula xml:id="formula_26">ℓ θ (x) = E θ (x, 0) -βh(x) 17: ℓ(x, x) = -∥x -x -∆t[s θ (x, 0) -β∇h(x)]∥ 2 18: ℓ(x, x) = -∥x -x -∆t[s θ (x, 0) -β∇h(x)]∥ 2</formula><p>19:</p><formula xml:id="formula_27">ℓ acc = ℓ θ (x) -ℓ θ (x) + (ℓ(x, x) -ℓ(x, x))/(2∆t) 20:</formula><p>if ℓ acc &gt; log(u), then x ← x 21:</p><p>else 22:</p><p>x ← x 23:</p><p>end if</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>24:</head><p>X ← X ∪ {x} 25: end for 26: Return X Therefore we have to include Langevin dynamics (Stage II) as an optional stage to correct the bias introduced in Stage I. This stage can provide a theoretical guarantee for drawing exact samples from the product of distributions, despite the empirical observation that it offers only marginal performance improvements.</p><p>It's important to note that Stage I is essential because its output focuses on feasible minimizers under specific conditions, offering an improved initialization for Langevin dynamics. This has been demonstrated in our ablation study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Pseudocode of the Proposed Derivative-free Sampling</head><p>The pseudocode of our derivative-free sampling algorithm is provided in Algorithm 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Energy-based Parameterization</head><p>In a standard diffusion model, we learn the score of the data distribution directly as s θ (x, t) = ∇ log p t (x). This parameterization can be used for ULA, which only requires gradients of loglikelihood. However, to incorporate the Metropolis-Hastings (MH) correction step, access to the unnormalized density of the data distribution is necessary to calculate the acceptance probability.</p><p>To enable the use of MH correction, we can instead learn the energy function of the data distribution, i.e., p(x, t) ∝ e E θ (x,t) . The simplest approach is to use a scalar-output neural network, denoted as NN θ (x, t) : R d × R → R, to parameterize E θ (x, t). By taking the gradient of this energy function with respect to the input x, we can derive the score of the data distribution. However, existing works have shown that this parameterization can cause difficulties during model training <ref type="bibr" target="#b87">[88]</ref>. Following the approach by <ref type="bibr" target="#b28">[29]</ref>, we define the energy function as</p><formula xml:id="formula_28">E θ (x, t) = -1 2 |NN θ (x, t)| 2 2</formula><p>, where NN θ (x, t) is a vector-output neural network mapping from R d × R to R. Consequently, the score of the data distribution is represented as s θ (x, t) = -NN θ (x, t)∇ x NN θ (x, t).</p><p>Algorithm 3 Sampling via DIFFOPT for non-differentiable objective Require: inverse temperature schedule β(t), diffusion volatility schedule g(t) and drift f (x, t), score model s θ (x t , t). 1: // Initialization 2: Sample S particles {x 0 s } S s=1 from diffusion model 3: Compute w 0 s Add noise to the particle by forward diffusion until time t:</p><formula xml:id="formula_29">= π β (x 0 s ) p θ (x 0 s ) = q β (x 0 s )</formula><formula xml:id="formula_30">x k-1 s,t ∼ p t|0 (x k-1 s,t |x k-1 s,0 ) 12:</formula><p>Denoise the particle through backward diffusion:</p><formula xml:id="formula_31">x k s,0 ∼ p 0|t (x k s,0 |x k-1 s,t ) 13: Sample x k-1 s,t,j ∼ p t|0 (x k-1 s,t |x k-1 s,0 ) = N (x k-1 s,t |α t x k-1 s,0 , σ 2 t 1+σt</formula><p>Id) for J times 14:</p><formula xml:id="formula_32">Q(x k s |x k-1 s ) ≈ 1 J J j=1 N xs,t,j +σts θ (x k-1 s,t,j ,t) αt , σ 2 t 1+σt Id 15: Marginalize to get Q(x k s ) ≈ 1 S S s=1 Q(x k s |x k-1 s ) 16:</formula><p>end for</p><formula xml:id="formula_33">17: Compute w k s = π β (x k s ) Q(x k s ) for each particle 18:</formula><p>Normalize the weight for each particle:</p><formula xml:id="formula_34">wk s = w k s S j=1 w k j 19:</formula><p>Resample M particles {x k s } S s=1 according to the weights 20: end for 21: Return X</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H End Distribution of the Warm-up Stage</head><p>In this section, we study in further detail the warm-up stage of DIFFOPT. We recall that we consider a process of the following form</p><formula xml:id="formula_35">dy β t = [-f (y β t , 1-t)+g(1-t) 2 ∇ log p 1-t (y β t )-β(1-t)∇h(y β t )]dt+g(1-t)dw t , y β 0 ∼ x T<label>(6</label></formula><p>) where T = 1 and p t is the density w.r.t. Lebesgue measure of the distribution of x t where</p><formula xml:id="formula_36">dx t = f (t, x t )dt + g(t)dw t , x 0 ∼ p 0 .<label>(7)</label></formula><p>We recall that under mild assumption <ref type="bibr" target="#b14">[15]</ref>, we have that</p><formula xml:id="formula_37">(ŷ t ) t∈[0,1] = (x 1-t ) t∈[0,1] satisfies dŷ t = [-f (ŷ t , 1 -t) + g(1 -t) 2 ∇ log p 1-t (ŷ t )]dt + g(1 -t)dw t , ŷ0 = x T .</formula><p>Let us highlight some differences between ( <ref type="formula" target="#formula_35">6</ref>) and the warm-up process described in Algorithm 2. First, we note that we do not consider an approximation of the score but the real score function ∇ log p t . In addition, we do not consider a discretization of ( <ref type="formula" target="#formula_35">6</ref>). This difference is mainly technical. The discretization of diffusion processes is a well-studied topic, and we refer to <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b16">17]</ref> for a thorough investigation. Our contribution to this work is orthogonal as we are interested in the role of h on the distribution. Our main result is Proposition 4 and details how the end distribution of the warm-up process concentrates on the minimizers of h, which also support the data distribution p 0 .</p><p>We first show that under assumptions on h, q β T , the density w.r.t. the Lebesgue measure of y T has the same support as p 0 . We denote by supp(p 0 ) the support of p 0 . We consider the following assumption. Assumption 1. We have that for any t ∈ [0, 1], g(t) = g(0) and f (t, x) = -γ 0 x with γ 0 &gt; 0. Assume that p 0 has bounded support, i.e. there exists R &gt; 0 such that supp(p 0 ) ⊂ B(0, R) with B(0, R) the ball with center 0. In addition, assume that h is Lipschitz.</p><p>Then, we have the following proposition. This can also be rewritten as</p><formula xml:id="formula_38">∂ t p β t + ⟨f t -g 2 t ∇ log p β t , ∇p β t ⟩ + div(f t -g 2 t ∇ log p t )p β t + (g 2 t /2)∆p β t + div(β t ∇hp β t ) = 0.<label>(10</label></formula><p>) Finally, this can be rewritten as</p><formula xml:id="formula_39">∂ t p β t +⟨f t -g 2 t ∇ log p t , ∇p β t ⟩+(g 2 t /2)∆p β t +div(f t -g 2 t ∇ log p t )p β t +β t {⟨∇h, ∇ log p β t ⟩+∆h}p β t = 0.</formula><p>In what follows, we denote</p><formula xml:id="formula_40">µ t = f t -g 2 t ∇ log p t , V t = div(f t -g 2 t ∇ log p t ), W β t = ⟨∇h, ∇ log p β t ⟩ + ∆h.<label>(11</label></formula><p>) Hence, using <ref type="bibr" target="#b9">(10)</ref> we have</p><formula xml:id="formula_41">∂p β t + ⟨µ t , ∇ log p β t ⟩ + (g 2 t /2)∆p β t + V t p β t + β t W β t p β t = 0.<label>(12</label></formula><p>) Similarly, using <ref type="bibr" target="#b8">(9)</ref> we have</p><formula xml:id="formula_42">∂p t + ⟨µ t , ∇ log p t ⟩ + (g 2 t /2)∆p t + V t p t = 0.<label>(13)</label></formula><p>Therefore, combining (13), A2 and [79, Theorem 7.13] we get that for any</p><formula xml:id="formula_43">x ∈ R d p 0 (x) = E[exp[ 1 0 V t (z t )dt]p T (z T ) | z 0 = x],</formula><p>with dz t = µ t dt + g t dw t and z 0 = x. Similarly, combining <ref type="bibr" target="#b11">(12)</ref>, A2 and [79, Theorem 7.13] we get that for any</p><formula xml:id="formula_44">x ∈ R d p β 0 (x) = E[exp[ 1 0 V t (z t )dt] exp[ 1 0 β t W β t (z t )dt]p T (z T ) | z 0 = x].<label>(14)</label></formula><p>Using ( <ref type="formula" target="#formula_40">11</ref>), we have that</p><formula xml:id="formula_45">1 0 β t W β t (z t )dt = 1 0 β t {⟨∇h, ∇ log p β t ⟩ + ∆h}(z t )dt. Hence, we have 1 0 β t W β t (z t )dt = log(β 0 ){⟨∇h, ∇ log p β 0 ⟩ + ∆h}(z 0 ) + 1 0 β t (W β t (z t ) -W β 0 (z 0 ))dt. Using A2 we have that -C ≤ 1 0 β t W β t (z t )dt -log(β 0 ){⟨∇h, ∇ log p β 0 ⟩ + ∆h}(z 0 ) ≤ C . Hence, -C+log(β 0 ){⟨∇h, ∇ log p β 0 ⟩+∆h}(z 0 ) ≤ 1 0 β t W β t (z t )dt ≤ C+log(β 0 ){⟨∇h, ∇ log p β 0 ⟩+∆h}(z 0 )</formula><p>. Combining this result with <ref type="bibr" target="#b13">(14)</ref> we get that for any</p><formula xml:id="formula_46">x ∈ R d p β 0 (x) ≤ E[exp[ 1 0 V t (z t )dt]p T (z T ) | z 0 = x] exp[log(β 0 ){⟨∇h, ∇ log p β 0 + ∆h⟩}(x)] exp[C] = p 0 (x) exp[log(β 0 ){⟨∇h, ∇ log p β 0 + ∆h⟩}(x)] exp[C]. Similarly, we have for any x ∈ R d p β 0 (x) ≥ p 0 (x) exp[log(β 0 ){⟨∇h, ∇ log p β 0 ⟩ + ∆h}(x)] exp[-C],</formula><p>which concludes the proof.</p><p>In Proposition 3, we show that the output distribution of the warm-up process is upper and lower bounded by a product of experts comprised of (i) p 0 which ensures the feasibility conditions (ii) exp[log(β 0 )W β 0 ] related to the optimization of the objective. While Proposition 3 gives an explicit form for p β 0 , it does not provide insights on the properties of this distribution. However, we can still infer some limiting properties.</p><formula xml:id="formula_47">Proposition 4. If x ⋆ is a local strict minimizer of h in the support of p 0 then lim β0→∞ p β 0 (x ⋆ ) = +∞. If x ⋆ is a local strict minimizer of h not in the support of p 0 then lim β0→∞ p β 0 (x ⋆ ) = 0.</formula><p>Proof. The case where x ⋆ is not in support of p 0 is trivial using Proposition 3. We now assume that x ⋆ is in the support of p 0 . Using Proposition 3 and that ∇h(x ⋆ ) = 0 and ∆h(x ⋆ ) &gt; 0 since the local minimizer x ⋆ is strict, we get that lim β0→∞ p β 0 (x ⋆ ) = +∞, which concludes the proof.</p><p>In particular, Proposition 4 shows that the limit distribution of y β T concentrates around the minimizers of h, which is the expected behavior of increasing the inverse temperature. What is also interesting is that we only target the minimizers of h, which are inside the support of p 0 . This is our primary goal, which is constrained optimization of h.</p><p>• TFBind10: DNA sequence optimization. Similar to TFBind8, this task aims to find the DNA sequence of length ten that has the maximum binding affinity with transcription factor SIX6_REF_R1. The design space consists of all possible designs of nucleotides. The size of the dataset is 10,000, with a dimension of 10. Since the affinity for the entire design space is available, it uses the ground truth as a direct oracle. • ChEMBL: molecule activity optimization. This task aims to find molecules with a high MCHC value when paired with assay CHEMBL3885882. The dataset consists of 441 samples of dimension 31.</p><p>Baselines. We compare with eight baselines on DesignBench tasks. The results of all the baselines are from <ref type="bibr" target="#b63">[64]</ref>. Gradient ascent learns a surrogate model of the objective function and generates the optimal solution by iteratively performing gradient ascent on the surrogate model. CbAS learns a density model in the design space coupled with a surrogate model of the objective function. It iteratively generates samples and refines the density model on the new samples during training. GP-qEI fits a Gaussian Process on the offline dataset. It employs the quasi-Expected-Inprovement (qEI) acquisition function from Botorch <ref type="bibr" target="#b4">[5]</ref> for Bayesian optimization. MINS learns an inverse map from objective value back to design space using a Generative Adversarial Network (GAN). It then obtains optimal solutions through conditional generation. REINFORCE parameterizes a distribution over the design space and adjusts this distribution in a direction that maximizes the efficacy of the surrogate model. COMS learns a conservative surrogate model by regularizing the adversarial samples. It then utilizes gradient ascent to discover the optimal solution. CMAES enhances a distribution over the optimal design by adapting the covariance matrix according to the highest-scoring samples selected by the surrogate model. DDOM learns a conditional diffusion model to learn an inverse mapping from the objective value to the input space.</p><p>Implementation details. We build the score network s θ using a simple feed-forward network. This network consists of two hidden layers, each with a width of 1024 units, and employs ReLU as the activation function. The forward process is a Variance Preserving (VP) SDE <ref type="bibr" target="#b96">[97]</ref>. We set the noise variance limits to a minimum of 0.01 and a maximum of 2.0.</p><p>For the surrogate models, we explore various network architectures tailored to different datasets, including Long short-term memory (LSTM) <ref type="bibr" target="#b49">[50]</ref>, Gaussian Fourier Network, and Deep Kernel Learning (DKL) <ref type="bibr" target="#b114">[115,</ref><ref type="bibr" target="#b115">116]</ref>. LSTM network uses a single-layer LSTM unit with a hidden dimension of 1024, followed by 1 hidden layer with a dimension of 1024, utilizing ReLU as the activation function. In the Gaussian Fourier regressor, Gaussian Fourier embeddings <ref type="bibr" target="#b102">[103]</ref> are applied to the inputs x and t. These embeddings are then processed through a feed-forward network with 3 hidden layers, each of 1024 width, utilizing Tanh as the activation function. This regressor is time-dependent, and its training objective follows the method used by <ref type="bibr" target="#b96">[97]</ref> for training time-dependent classifiers in conditional generation. For DKL, we use the ApproximateGP class in Gpytorch<ref type="foot" target="#foot_0">foot_0</ref> , which consists of a deep feature extractor and a Gaussian process (GP). The feature extractor is a simple feed-forward network consisting of 2 hidden layers with a width of 500 and 50, respectively, and ReLU activations.</p><p>The GP uses radial basis function (RBF) kernel.</p><p>We use a fixed learning rate of 0.001 and a batch size of 128 for both the diffusion and surrogate models. During testing, we follow the evaluation protocol from the <ref type="bibr" target="#b63">[64]</ref>, sampling 256 candidate solutions. We apply different annealing strategies for different datasets. Specifically, we apply exponential annealing for TFBind8, superconductor, D'Kitty, and ChEMBL. The exponential annealing strategy is defined as</p><formula xml:id="formula_48">β(τ ) = β max [1 -exp(-100(T -τ ))]</formula><p>, where τ = T -t, and a constant β for Ant and TFBind10. Though exponential annealing usually exhibits better performance, we leave the exploration of exponential annealing on TFBind10 and D'Kitty for future work due to time limit. The step size ∆t is 0.001 for the first stage, and 0.0001 for the second stage.</p><p>Detailed hyperparameters and network architectures for each dataset are provided in Table <ref type="table">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I.4 Multi-objective Molecule Optimization</head><p>Dataset details. We curate the dataset by encoding 10000 molecules (randomly selected) from the ChEMBL dataset <ref type="bibr" target="#b37">[38]</ref> with HierVAE <ref type="bibr" target="#b54">[55]</ref>, a commonly used molecule generative model based on VAE, which takes a hierarchical procedure in generating molecules by building blocks. Since Annealing strategy β max Surrogate model TFBind8 Exponential 200 Gaussian Fourier TFBind10 Constant 20 Gaussian Fourier Superconductor Exponential 100 Gaussian Fourier Ant Exponential 30 Gaussian Fourier D'Kitty Constant 3e4 DKL ChEMBL Exponential 100 LSTM Table <ref type="table">5</ref>: Implementation details on design-bench. β max is the value of β at the end of the annealing process. Oracle details. We evaluate three commonly used molecule optimization oracles including synthesis accessibility (SA), quantitative evaluation of drug-likeness (QED) and activity again target GSK3B from RDKit <ref type="bibr" target="#b65">[66]</ref> and TDC <ref type="bibr" target="#b50">[51]</ref>. All three oracles take as input a SMILES string representation of a molecule and return a scalar value of the property. The oracles are non-differentiable.</p><p>Implementation details. We build the score network s θ of the diffusion model using a 2-layer MLP architecture. This network features 1024 hidden dimensions and utilizes the ReLU activation function.</p><p>The forward process adheres to a Variance Preserving (VP) SDE proposed by <ref type="bibr" target="#b96">[97]</ref>. We calibrate the noise variance within this model, setting its minimum at 0.01 and maximum at 2.0.</p><p>For the surrogate model of the objective function, we use the ApproximateGP class in Gpytorch<ref type="foot" target="#foot_1">foot_1</ref> , which consists of a deep feature extractor and a Gaussian process. The feature extractor is a simple feed-forward network with two hidden layers, having widths of 500 and 50, respectively, and both employ ReLU activation functions. Regarding model optimization, we apply a fixed learning rate of 0.001 for the diffusion model and 0.01 for the surrogate model. Additionally, we set a batch size of 128 and conduct training over 1000 epochs for both models. For the sampling process, we use a consistent inverse temperature β = 10<ref type="foot" target="#foot_2">foot_2</ref> for all the three objectives. The step size ∆t is 0.001 for the first stage, and 0.0001 for the second stage.</p><p>We sample 1000 candidate solutions at test time for all the methods. For DDOM <ref type="bibr" target="#b63">[64]</ref>, we use their implementation 4 . For other baselines, we use the implementations provided by DesignBench <ref type="foot" target="#foot_3">5</ref> . We tune the hyper-parameters of all the baselines as suggested in their papers.</p><p>For derivative-free optimization, the number of iterations is set to 100 for both the evolutionary algorithm and DIFFOPT. The number of particles for all methods remains the same as before, i.e., 1000.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J Analysis on Ant Dataset</head><p>As shown in Table <ref type="table" target="#tab_0">1</ref>, DIFFOPT can only achieve subpar performance on the Ant dataset. This underperformance is primarily due to the difficulty in training the surrogate objective function. An illustration of this challenge is provided in Figure <ref type="figure">5</ref>, where the training loss of the surrogate objective    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>K Additional Ablation Studies</head><p>Impact of annealing strategies. We study the influence of different annealing strategies for β during the guided diffusion stage, focusing on the superconductor and TFBind8 datasets. We explore three strategies: constant, linear annealing, and exponential annealing. Figure <ref type="figure" target="#fig_5">6</ref>(a) presents the performance across various diffusion steps. We find that our method is not particularly sensitive to the annealing strategies. However, it is worth noting that exponential annealing exhibits a marginal performance advantage over the others.</p><p>We also investigate how the value of β at the end of annealing, denoted as β max , affects model performance in Figure <ref type="figure" target="#fig_5">6</ref>(b). We find that increasing β max initially leads to better performance. However, beyond a certain threshold, performance begins to decrease. It is noteworthy that the optimal value varies across different annealing strategies. Particularly, at β max = 0, the model reverts to a pure diffusion process, exhibiting the lowest performance due to the lack of guidance from the objective function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sample efficiency</head><p>We explore the sample efficiency of DIFFOPT at both training and testing stages. Figure <ref type="figure" target="#fig_6">7</ref> shows the performance of various methods versus the ratio of training data on Superconductor, TFBind8 and multi-objective molecule optimization. As we can see, on all the three datasets, DiffOPT can outperform all.</p><p>Our method is also sample efficient during inference. Figure <ref type="figure" target="#fig_7">8</ref> shows the performance versus number of samples at inference stage. Notably, on both Superconductor and TFBind8, DiffOPT consistently outperforms all the baseline methods for various sample sizes during inference.</p><p>It is also important to highlight that our method consistently achieves much greater sample efficiency than DDOM at both training and inference stages, despite both approaches leveraging diffusion models.</p><p>NeurIPS Paper Checklist</p><p>1. Claims Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: In this paper, we propose a new sampler using diffusion models for optimization under unknown constraints. Guidelines: • The answer NA means that the abstract and introduction do not include the claims made in the paper. • The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. • The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. • It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. 2. Limitations Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes]</p><p>We have discussed the limitations and future work in Appendix A. Guidelines:</p><p>• The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. • The authors are encouraged to create a separate "Limitations" section in their paper.</p><p>• The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. • The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. • The authors should reflect on the factors that influence the performance of the approach.</p><p>For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. • The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. • If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. • While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Theory Assumptions and Proofs</head><p>Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: We provide the complete proof of Theorem 1 in Appendix H. Guidelines:</p><p>• The answer NA means that paper does not include experiments requiring code.</p><p>• Please see the NeurIPS code and data submission guidelines (<ref type="url" target="https://nips.cc/public/guides/CodeSubmissionPolicy">https://nips.cc/ public/guides/CodeSubmissionPolicy</ref>) for more details. • While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). • The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (<ref type="url" target="https://nips.cc/public/guides/CodeSubmissionPolicy">https: //nips.cc/public/guides/CodeSubmissionPolicy</ref>) for more details. • The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. • The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. • At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). • Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experimental Setting/Details</head><p>Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: We provide all the details in Appendix I. Guidelines:</p><p>• The answer NA means that the paper does not include experiments.</p><p>• The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. • The full details can be provided either with the code, in appendix, or as supplemental material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Experiment Statistical Significance</head><p>Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: Error bars have been provided for all results. Guidelines:</p><p>• The answer NA means that the paper does not include experiments.</p><p>• The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. • The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). • The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) • The assumptions made should be given (e.g., Normally distributed errors). • It should be clear whether the error bar is the standard deviation or the standard error of the mean. • It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. • For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).</p><p>• The paper should discuss whether and how consent was obtained from people whose asset is used.</p><p>• At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. 14. Crowdsourcing and Research with Human Subjects Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: • The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. • Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. • According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. 15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: • The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. • Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.</p><p>• We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. • For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Sampling trajectory of DiffOPT in the synthetic Branin experiment with unknown constraints. Red stars denote the minimizes, and the blue region denotes the feasible space from which training data is sampled. DIFFOPT can effectively navigate towards the two feasible minimizers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Sampling trajectory of DiffOPT in the synthetic Branin experiment with additional known constraints. Red stars denote the minimizers, the blue region denotes the feasible space from which training data is sampled and the pink region denotes the feasible space defined by the added given constraints. DIFFOPT can effectively navigate towards the unique minimizer at the intersection of the two feasible spaces.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>for each particle 4 : 5 : 8 :</head><label>458</label><figDesc>Normalize the weight w0 s =Resample S particles {x 0 s } S s=1 according to the weights 6: // Iterative Importance Sampling 7:for k = 1, • • • , K + 1 do Sample t ∼ U[0, T ]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>1/ 31 / 1 Figure 5 :</head><label>3115</label><figDesc>Figure 5: Training loss of the surrogate objective on Ant dataset validity is important for molecules, we ensure HierVAE can decode all the randomly selected encoded molecules. We split all the datasets into training and validation sets by 9:1.</figDesc><graphic coords="24,214.69,190.24,184.27,96.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Impact of annealing strategies and β max in the guided diffusion stage. β max is the value of β at the end of annealing.</figDesc><graphic coords="25,114.09,221.98,379.40,92.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Impact of the number of training data.</figDesc><graphic coords="25,114.10,341.38,378.41,140.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Impact of the number of samples at testing time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Results of offline black-box optimization on DesignBench. We report the mean and standard deviation across five random seeds. The best results are bolded, and the second best is underlined.</figDesc><table><row><cell>Baseline</cell><cell>TFBind8</cell><cell cols="5">TFBind10 Superconductor</cell><cell></cell><cell>Ant</cell><cell cols="2">D'Kitty</cell><cell>ChEMBL</cell><cell>Mean Rank</cell></row><row><cell>Dataset Best</cell><cell>0.439</cell><cell cols="2">0.00532</cell><cell></cell><cell>74.0</cell><cell></cell><cell></cell><cell>165.326</cell><cell cols="2">199.231</cell><cell>383.7e3</cell><cell>-</cell></row><row><cell>CbAS</cell><cell cols="3">0.958±0.018 0.761±0.067</cell><cell></cell><cell cols="2">83.178±15.372</cell><cell></cell><cell>468.711±14.593</cell><cell cols="2">213.917±19.863</cell><cell>389.0e3±0.5e3</cell><cell>6.33</cell></row><row><cell>GP-qEI</cell><cell cols="3">0.824±0.086 0.675±0.043</cell><cell></cell><cell cols="2">92.686±3.944</cell><cell></cell><cell>480.049±0.000</cell><cell cols="2">213.816±0.000</cell><cell>388.1e3±0.0</cell><cell>7.17</cell></row><row><cell>CMA-ES</cell><cell cols="3">0.933±0.035 0.848±0.136</cell><cell></cell><cell cols="2">90.821±0.661</cell><cell cols="2">1016.409±906.407</cell><cell cols="2">4.700±2.230</cell><cell>388.4e3±0.4e3</cell><cell>5.17</cell></row><row><cell cols="4">Gradient Ascent 0.981±0.010 0.770±0.154</cell><cell></cell><cell cols="2">93.252±0.886</cell><cell cols="2">-54.955±33.482</cell><cell cols="2">226.491±21.120</cell><cell>390.1e3±2.0e3</cell><cell>4.33</cell></row><row><cell>REINFORCE</cell><cell cols="3">0.959±0.013 0.692±0.113</cell><cell></cell><cell cols="2">89.469±3.093</cell><cell cols="4">-131.907±41.003 -301.866±246.284 388.4e3±2.1e3</cell><cell>7.33</cell></row><row><cell>MINs</cell><cell cols="3">0.938±0.047 0.770±0.177</cell><cell></cell><cell cols="2">89.027±3.093</cell><cell></cell><cell>533.636±17.938</cell><cell cols="2">272.675±11.069</cell><cell>391.0e3±0.2e3</cell><cell>4.50</cell></row><row><cell>COMs</cell><cell cols="3">0.964±0.020 0.750±0.078</cell><cell></cell><cell cols="2">78.178±6.179</cell><cell></cell><cell>540.603±20.205</cell><cell cols="2">277.888±7.799</cell><cell>390.2e3±0.5e3</cell><cell>4.50</cell></row><row><cell>DDOM</cell><cell cols="3">0.971±0.005 0.885±0.367</cell><cell></cell><cell cols="2">103.600±8.139</cell><cell></cell><cell>548.227±11.725</cell><cell cols="2">250.529±10.992</cell><cell>388.0e3±1.1e3</cell><cell>3.67</cell></row><row><cell>Ours</cell><cell cols="3">0.987 ±0.014 0.924±0.224</cell><cell></cell><cell cols="2">113.545±5.322</cell><cell></cell><cell>493.191±18.165</cell><cell cols="2">261.673±3.486</cell><cell>391.1e3±3.4e3</cell><cell>2.00</cell></row><row><cell></cell><cell>QED ↑</cell><cell>SA ↓</cell><cell cols="2">Top-1</cell><cell>GSK3B ↑</cell><cell>Sum ↑</cell><cell></cell><cell>QED ↑</cell><cell>SA ↓</cell><cell>Top-10 GSK3B ↑</cell><cell>Sum ↑</cell><cell>Invalidity ↓</cell></row><row><cell>Dataset Mean</cell><cell>0.598</cell><cell>0.204</cell><cell></cell><cell></cell><cell>0.045</cell><cell>0.439</cell><cell></cell><cell>0.598</cell><cell>0.204</cell><cell>0.045</cell><cell>0.439</cell><cell>0</cell></row><row><cell>Dataset Sum Best</cell><cell>0.846</cell><cell>0.159</cell><cell></cell><cell></cell><cell>0.99</cell><cell>1.677</cell><cell></cell><cell>0.771</cell><cell>0.129</cell><cell>0.877</cell><cell>1.519</cell><cell>0</cell></row><row><cell>Dataset Best</cell><cell>0.947</cell><cell>0.030</cell><cell></cell><cell></cell><cell>0.99</cell><cell>1.907</cell><cell></cell><cell>0.945</cell><cell>0.204</cell><cell>0.947</cell><cell>1.688</cell><cell>0</cell></row><row><cell>DDOM</cell><cell>0.790±0.023</cell><cell cols="2">0.124±0.007</cell><cell cols="2">0.856±0.046</cell><cell cols="2">1.521±0.063</cell><cell>0.747±0.033</cell><cell cols="2">0.141±0.006</cell><cell>0.695±0.021</cell><cell>1.301±0.037</cell><cell>63.60±3.61</cell></row><row><cell>Gradient Ascent</cell><cell>0.834±0.025</cell><cell cols="2">0.130±0.024</cell><cell cols="2">0.784±0.152</cell><cell cols="2">1.487±0.150</cell><cell>0.674±0.043</cell><cell cols="2">0.134±0.010</cell><cell>0.678±0.047</cell><cell>1.218±0.091</cell><cell>80.00±19.20</cell></row><row><cell>GP-qEI</cell><cell>0.784±0.059</cell><cell cols="2">0.149±0.034</cell><cell cols="2">0.551±0.106</cell><cell cols="2">1.186±0.089</cell><cell>0.743±0.032</cell><cell cols="2">0.147±0.010</cell><cell>0.370±0.057</cell><cell>0.966±0.028</cell><cell>63.80±7.62</cell></row><row><cell>MINs</cell><cell>0.795±0.156</cell><cell cols="2">0.163±0.027</cell><cell cols="2">0.466±0.249</cell><cell cols="2">1.097±0.200</cell><cell cols="3">0.838±0.059 0.145±0.029</cell><cell>0.273±0.149</cell><cell>0.966±0.108</cell><cell>38.20±24.66</cell></row><row><cell>REINFORCE</cell><cell cols="5">0.865±0.047 0.083±0.013 0.062±0.069</cell><cell cols="2">0.843±0.027</cell><cell cols="3">0.816±0.056 0.079±0.009 0.085±0.072</cell><cell>0.822±0.026</cell><cell>53.40±106.80</cell></row><row><cell>CbAS</cell><cell>0.762±0.119</cell><cell cols="2">0.138±0.046</cell><cell cols="2">0.681±0.077</cell><cell cols="2">1.305±0.049</cell><cell>0.687±0.035</cell><cell cols="2">0.153±0.010</cell><cell>0.593±0.078</cell><cell>1.126±0.059</cell><cell>46.80±13.90</cell></row><row><cell>CMA-ES</cell><cell>0.446±0.011</cell><cell cols="2">0.207±0.122</cell><cell cols="2">0.012±0.004</cell><cell cols="2">0.250±0.128</cell><cell>0.435±0.033</cell><cell cols="2">0.230±0.169</cell><cell>0.008±0.001</cell><cell>0.212±0.205</cell><cell>880.00±59.25</cell></row><row><cell>Ours</cell><cell>0.798±0.023</cell><cell cols="6">0.100±0.031 0.944±0.023 1.641±0.018</cell><cell>0.786±0.003</cell><cell cols="2">0.100±0.006 0.866±0.035 1.552±0.031</cell><cell>35.80±1.46</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Results of derivative-free optimization on the multi-objective molecule optimization task.</figDesc><table><row><cell></cell><cell></cell><cell>↑ Invalidity ↓</cell></row><row><cell>EA</cell><cell>0.558±0.029</cell><cell>37.6±8.73</cell></row><row><cell>IS</cell><cell>0.493±0.108</cell><cell>0.0±0.0</cell></row><row><cell cols="2">Ours 0.590±0.060</cell><cell>0.0±0.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Stage II + MH 114.945 ± 3.615 0.989 ± 0.021Ablation study on the two-stage sampling.</figDesc><table><row><cell></cell><cell>Superconductor</cell><cell>TFBind8</cell></row><row><cell>Best Baseline</cell><cell cols="2">103.600 ± 8.139 0.981 ± 0.010</cell></row><row><cell>Only Stage I</cell><cell cols="2">112.038 ± 6.783 0.984 ± 0.012</cell></row><row><cell>Only Stage II</cell><cell>92.432 ± 8.635</cell><cell>0.951 ± 0.028</cell></row><row><cell>Stage I + Stage II</cell><cell cols="2">113.545 ± 5.322 0.987 ± 0.014</cell></row><row><cell>Stage I +</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>https://docs.gpytorch.ai/en/stable/_modules/gpytorch/models/approximate_gp.html# ApproximateGP</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>https://docs.gpytorch.ai/en/stable/_modules/gpytorch/models/approximate_gp.html# ApproximateGP</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>https://github.com/siddarthk97/ddom</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>https://github.com/brandontrabucco/design-bench</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix for DIFFOPT</head><p>A Limitations and Future <ref type="bibr">Work 16</ref> B Broader <ref type="bibr">Impacts 16</ref> C (Metropolis-adjusted) Langevin Dynamics.</p><p>Proposition 2. Assume A1. Then, we have that for any β &gt; 0, y β T ∈ supp(p 0 ).</p><p>Proof. This directly applies to the results of <ref type="bibr" target="#b80">[81]</ref>. First, we have that [81, Assumption 1, Assumption 2] are satisfied using A1, [81, <ref type="bibr">Lemma 1]</ref> and the second part of <ref type="bibr" target="#b80">[81,</ref><ref type="bibr">Theorem 2]</ref>. We conclude using the first part of <ref type="bibr" target="#b80">[81,</ref><ref type="bibr">Theorem 2]</ref>.</p><p>In Proposition 2, we show that the guided reconstructed scheme used for warm-up <ref type="bibr" target="#b5">(6)</ref> cannot discover minimizers outside the support of p 0 . In Proposition 4, we will show that we concentrate on the minimizers inside the support of p 0 under additional assumptions.</p><p>Next, we make the following assumption, which is mostly technical. We denote q β t the distribution of y β t for any t ∈ [0, 1]. We also denote (p β 1-t ) t∈[0,1] = (q β t ) t∈[0,1] . Assumption 2. We have that h ∈ C ∞ (R d , R). In addition, C &gt; 0 exists such that for any x ∈ R d , we have a.s.</p><p>with dz t = {f t -g 2 t ∇ log p t ⟩dt + dw t , z 0 = x, W t = ⟨∇ log p β t , ∇h⟩ + ∆h and β t ≡ β(1 -t). For t ∈ [0, 1] and x ∈ R d V t = div(f t -g 2 t ∇ log p t ), W β t = ⟨∇h, ∇ log p β t ⟩ + ∆h. Assume that V and W β are continuous and bounded on [0, 1] × R d . Assume that (p t ) t∈[0,1] and (p β t ) t∈[0,1] are strong solutions to their associated Fokker-Planck equations.</p><p>We do not claim that we verify this hypothesis in this paper. Proving A2 is out of the scope of this work, and we mainly use it to 1) control high-order terms and 2) provide sufficient conditions to apply the Feynman-Kac theorem <ref type="bibr" target="#b78">[79,</ref><ref type="bibr">Theorem 7.13</ref>] and the Fokker-Planck equation. The bound in (8) controls the regularity of the W β t (z t ). Given that (under some mild regularity assumption),</p><p>and some constant C &gt; 0 (independent of t). Therefore, we get that ( <ref type="formula">8</ref>) is true in expectation under some regularity assumption. We conjecture that the almost sure bound we require is unnecessary and that moment bounds should be enough. We leave this study for future work. Proposition 3. Assume A2. For any x ∈ R d , let pβ 0 (x) be given by pβ 0 (x) = p 0 (x) exp[log(β 0 ){∆h(x) + ⟨∇ log p β 0 (x), ∇h(x)⟩}], where p β 0 is the distribution of y β T and β 0 is the inverse temperature at the end of the process. Then there exists C 0 &gt; 0 such that for any</p><p>Proof. First, for any t ∈ [0, 1] we denote p t the density of x t where (x t ) t∈[0,1] is given by <ref type="bibr" target="#b6">(7)</ref>. Similarly, we denote q β t the distribution of y β t for any τ 0 &gt; 0 and t ∈ [0, 1]. Finally, we denote</p><p>In what follows, we fix t 0 &gt; 0. Using A2 we have that for any t ∈ [0, 1]</p><p>2)∆p t . Therefore, we have that for any t ∈ [0, 1]</p><p>2)∆p t = 0. This can also be rewritten as</p><p>where we have used that div(∇ log p t p t ) = ∆p t . Similarly, we have that  We consider the commonly used Branin function as a synthetic toy example that takes the following form (illustrated in Figure <ref type="figure">4</ref>):</p><p>. The Branin function f (x 1 , x 2 ) has three global minimas located at points (-π, 12.275), (π, 2.275), and (9.42478, 2.475) with a value of 0.397887. Dataset details. We curate 6, 000 data points by sampling uniformly in an ellipse region with center (-0.2, 7.5) and semi-axis lengths (3.6, 8.0) as training data (the blue region in Figure <ref type="figure">2</ref>). It is tilted counterclockwise by 25 degrees, ensuring that it covers two minimizers of the function: (-π, 12.275) and (π, 2.275). It is worth noting that sampling points (x 1 , x 2 ) to construct the training dataset are irrelevant to the objective value f (x 1 , x 2 ). For the experiment with additional known constraints, we introduce two constraints x 2 ≤ 3 2 x 1 + 15 2 and x 2 ≤ -3 2 x 1 + 15 (the pink region in Figure <ref type="figure">2</ref>) to further narrow down the feasible solution to (π, 2.275). We split the dataset into training and validation sets by 9:1.</p><p>Implementation details. We build the score network s θ of the diffusion model with a 2-layer MLP architecture with 1024 hidden dimensions and ReLU activation function. The forward process is a Variance Preserving (VP) SDE <ref type="bibr" target="#b96">[97]</ref>. We set the minimum and maximum values of noise variance to be 0.01 and 2.0, respectively. We employ a fixed learning rate of 0.001, a batch size of 128, and 1000 epochs for model training. At test time, we sample 500 candidate solutions. We use a constant inverse temperature β = 5 for the Boltzmann distribution induced by the objective function. For the distribution induced by the additional known constraints, we set β ′ = 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I.3 Offline Black-box Optimization</head><p>Dataset details. DesignBench <ref type="bibr" target="#b105">[106]</ref> is an offline black-box optimization benchmark for realworld optimization tasks. Following <ref type="bibr" target="#b63">[64]</ref>, we use three continuous tasks: Superconductor, D'Kitty Morphology and Ant Morphology, and three discrete tasks: TFBind8, TFBind10, and ChEMBL. Consistent with <ref type="bibr" target="#b63">[64]</ref>, we exclude NAS due to its significant computational resource demands. We also exclude Hopper as it is known to be buggy (see Appendix C in <ref type="bibr" target="#b63">[64]</ref>). We split the dataset into training and validation sets by 9:1.</p><p>• Superconductor: materials optimization. This task aims to search for materials with high critical temperatures. The dataset contains 17,014 vectors with 86 components representing the number of atoms of each chemical element in the formula. The provided oracle function is a pre-trained random forest regression model. • D'Kitty Morphology: robot morphology optimization. This task aims to optimize the parameters of a D'Kitty robot, such as size, orientation, and location of the limbs, to make it suitable for a specific navigation task. The dataset size is 10,004, and the parameter dimension is 56. It uses MuJoCO <ref type="bibr" target="#b103">[104]</ref>, a robot simulator, as the oracle function. • Ant Morphology: robot morphology optimization. Similar to D'Kitty, this task aims to optimize the parameters of a quadruped robot to move as fast as possible. It consists of 10,004 data, and the parameter dimension is 60. It also uses MuJoCo as the oracle function. • TFBind8: DNA sequence optimization. This task aims to find the DNA sequence of length eight with the maximum binding affinity with transcription factor SIX6_REF_R1. The design space is the space of sequences of nucleotides represented as categorical variables.</p><p>The size of the dataset is 32,898, with a dimension of 8. The ground truth serves as a direct oracle since the affinity for the entire design space is available.</p><p>• The answer NA means that the paper does not include theoretical results.</p><p>• All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced. • All assumptions should be clearly stated or referenced in the statement of any theorems.</p><p>• The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. • Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. • Theorems and Lemmas that the proof relies upon should be properly referenced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Result Reproducibility</head><p>Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)?</p><p>Answer: [Yes] Justification: We have provided all experimental details in Appendix I. Guidelines:</p><p>• The answer NA means that the paper does not include experiments.</p><p>• If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. • If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. • Depending on the contribution, reproducibility can be accomplished in various ways.</p><p>For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. • While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility.</p><p>In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Open access to data and code</head><p>Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: <ref type="bibr">[No]</ref> Justification: We will release the code upon acceptance. The links to the datasets have been provided in the paper. Guidelines:</p><p>• If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Experiments Compute Resources</head><p>Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: All the computing infrastructure information has been provided in Appendix I.1. Guidelines:</p><p>• The answer NA means that the paper does not include experiments.</p><p>• The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. • The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. • The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Code Of Ethics</head><p>Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics <ref type="url" target="https://neurips.cc/public/EthicsGuidelines">https://neurips.cc/public/EthicsGuidelines</ref>? Answer: [Yes] Justification: We conform with the NeurIPS code of Ethics. Guidelines:</p><p>• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.</p><p>• If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. • The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.">Broader Impacts</head><p>Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: We have discussed both potential positive societal impacts and negative societal impacts of this work in Appendix B. Guidelines:</p><p>• The answer NA means that there is no societal impact of the work performed.</p><p>• If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. • Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. • The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. • The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.</p><p>• If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">Safeguards</head><p>Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: This paper poses no such risks. Guidelines:</p><p>• The answer NA means that the paper poses no such risks.</p><p>• Released models that have a high risk for misuse or dual-use should be released with necessary to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. • Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. • We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.</p><p>12. Licenses for existing assets Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: We have cited all the code, data, and models used in our paper. Guidelines:</p><p>• The answer NA means that the paper does not use existing assets.</p><p>• The authors should cite the original paper that produced the code package or dataset.</p><p>• The authors should state which version of the asset is used and, if possible, include a URL. • The name of the license (e.g., CC-BY 4.0) should be included for each asset.</p><p>• For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. • If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. • For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. • If this information is not available online, the authors are encouraged to reach out to the asset's creators.</p><p>13. New Assets Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: This paper does not release new assets. Guidelines:</p><p>• The answer NA means that the paper does not release new assets.</p><p>• Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Two decades of blackbox optimization applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Alarie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Audet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Gheribi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kokkolaras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Le</forename><surname>Digabel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURO Journal on Computational Optimization</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Reverse-time diffusion equation models</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Stochastic Processes and their Applications</title>
		<imprint>
			<date type="published" when="1982">1982</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="313" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A pattern search filter method for nonlinear programming without derivatives</title>
		<author>
			<persName><forename type="first">C</forename><surname>Audet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Dennis</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="980" to="1010" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Mesh adaptive direct search algorithms for constrained optimization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Audet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Dennis</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on optimization</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="188" to="217" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Botorch: Programmable bayesian optimization in pytorch</title>
		<author>
			<persName><forename type="first">M</forename><surname>Baladat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Karrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Daulton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Letham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bakshy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Natural product total synthesis: as exciting as ever and here to stay</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Baran</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Linear programming and network flows</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Bazaraa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Jarvis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Sherali</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Machine learning for combinatorial optimization: a methodological tour d&apos;horizon</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lodi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Prouvost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="405" to="421" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Linear convergence bounds for diffusion models via stochastic localization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Benton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">De</forename><surname>Bortoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Deligiannidis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.03686</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vandenberghe</surname></persName>
		</author>
		<title level="m">Convex optimization</title>
		<imprint>
			<publisher>Cambridge university press</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Sequential sampling in noisy environments</title>
		<author>
			<persName><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Parallel Problem Solving from Nature</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="202" to="211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Conditioning by adaptive sampling for robust design</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Brookes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Listgarten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Gradient sampling methods for nonsmooth optimization. Numerical nonsmooth optimization: State of the art algorithms</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Curtis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Overton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Simões</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="201" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A robust gradient sampling algorithm for nonsmooth, nonconvex optimization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Overton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="751" to="779" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Time reversal of diffusion processes under a finite entropy condition</title>
		<author>
			<persName><forename type="first">P</forename><surname>Cattiaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Conforti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gentil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Léonard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annales de l&apos;Institut Henri Poincaré (B) Probabilités et Statistiques</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="1844" to="1881" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>Institut Henri Poincaré</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Coates</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.02931</idno>
		<title level="m">Bidirectional learning for offline model-based biological sequence design</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chewi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Salim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.11215</idno>
		<title level="m">Sampling is as easy as learning the score: theory for diffusion models with minimal data assumptions</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">The Interplay between Sampling and Optimization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
		<respStmt>
			<orgName>University of California, Berkeley</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Stochastic gradient and langevin processes</title>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1810" to="1819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Klasky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Ye</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.14687</idno>
		<title level="m">Diffusion posterior sampling for general noisy inverse problems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Improving diffusion models for inverse problems using manifold constraints</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="25683" to="25696" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Score diffusion models without early stopping: finite fisher information is all you need</title>
		<author>
			<persName><forename type="first">G</forename><surname>Conforti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Durmus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Silveri</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.12240</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Introduction to derivative-free optimization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Conn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Scheinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">N</forename><surname>Vicente</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">De</forename><surname>Bortoli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.05314</idno>
		<title level="m">Convergence of denoising diffusion models under the manifold hypothesis</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">On quantitative laplace-type convergence results for some exponential probability measures</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">De</forename><surname>Bortoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Desolneux</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.12922</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>with two applications</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Diffusion schrödinger bridge with applications to score-based generative modeling</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">De</forename><surname>Bortoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thornton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="17695" to="17709" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">The global optimization problem: an introduction. Towards Global Optimiation 2</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C W</forename><surname>Dixon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1978">1978</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A flexible diffusion model</title>
		<author>
			<persName><forename type="first">W</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="8678" to="8696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Reduce, reuse, recycle: Compositional generation with energy-based diffusion models and mcmc</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Durkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Strudel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Grathwohl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="8489" to="8510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Molgensurvey: A systematic survey in machine learning models for molecule design</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.14500</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">On the geometric convergence for mala under verifiable conditions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Durmus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">É</forename><surname>Moulines</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.01951</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Limo: Latent inceptionism for targeted molecule generation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Eckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yu</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="5777" to="5792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A linesearch-based derivative-free approach for nonsmooth constrained optimization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Fasano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liuzzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lucidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Rinaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM journal on optimization</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="959" to="992" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Offline model-based optimization via normalized maximum likelihood estimation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The synthesizability of molecules proposed by generative models</title>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Coley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and modeling</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5714" to="5723" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Compositional sculpting of iterative generative processes</title>
		<author>
			<persName><forename type="first">T</forename><surname>Garipov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Peuter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kaski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-seventh Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Exact combinatorial optimization with graph convolutional neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gasse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chételat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ferroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lodi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Chembl: a large-scale bioactivity database for drug discovery</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gaulton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Bellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Bento</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hersey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Light</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mcglinchey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Michalovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Al-Lazikani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1100" to="D1107" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Recursive stochastic algorithms for global optimization in rˆd</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Gelfand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Mitter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Control and Optimization</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="999" to="1018" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Representations of knowledge in complex systems</title>
		<author>
			<persName><forename type="first">U</forename><surname>Grenander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="549" to="581" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Protein design with guided discrete diffusion</title>
		<author>
			<persName><forename type="first">N</forename><surname>Gruver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Stanton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G J</forename><surname>Rudner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Hotzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lafrance-Vanasse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rajpal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-seventh Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The CMA evolution strategy: A comparing review</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Towards a New Evolutionary Computation</title>
		<imprint>
			<biblScope unit="page" from="75" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Monte carlo sampling methods using markov chains and their applications</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Hastings</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Time reversal of diffusions. The Annals of Probability</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">G</forename><surname>Haussmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pardoux</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="1188" to="1205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Murata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Takida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Uesaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mitsufuji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Kolter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.16424</idno>
		<title level="m">Manifold preserving guided diffusion</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Training products of experts by minimizing contrastive divergence</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1771" to="1800" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Imagen video: High definition video generation with diffusion models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Saharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Whang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gritsenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.02303</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6840" to="6851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Therapeutics data commons: Machine learning datasets and tasks for drug discovery and development</title>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Roohani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Coley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Laplace&apos;s method revisited: weak convergence of probability measures. The Annals of Probability</title>
		<author>
			<persName><forename type="first">C.-R</forename><surname>Hwang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980">1980</date>
			<biblScope unit="page" from="1177" to="1182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Inverse problems for partial differential equations</title>
		<author>
			<persName><forename type="first">V</forename><surname>Isakov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">127</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Gflownets for ai-driven scientific discovery</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Deleu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hartford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hernandez-Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital Discovery</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="557" to="577" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Hierarchical generation of molecular graphs using structural motifs</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4839" to="4848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Erdos goes neural: an unsupervised learning framework for combinatorial optimization on graphs</title>
		<author>
			<persName><forename type="first">N</forename><surname>Karalias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Loukas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6659" to="6672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Learning combinatorial optimization algorithms over graphs</title>
		<author>
			<persName><forename type="first">E</forename><surname>Khalil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dilkina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Bootstrapped training of score-conditioned generator for offline design of biological sequences</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Berto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.03111</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Optimization by simulated annealing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Gelatt</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Vecchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">science</title>
		<imprint>
			<biblScope unit="volume">220</biblScope>
			<biblScope unit="issue">4598</biblScope>
			<biblScope unit="page" from="671" to="680" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Kloeden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Platen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Kloeden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Platen</surname></persName>
		</author>
		<title level="m">Stochastic differential equations</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Attention, learn to solve routing problems</title>
		<author>
			<persName><forename type="first">W</forename><surname>Kool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Van Hoof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">End-to-end constrained optimization learning: A survey</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kotary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fioretto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Van Hentenryck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wilder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Self-referencing embedded strings (selfies): A 100% robust molecular string representation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Krenn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Häse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Friederich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning: Science and Technology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">45024</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Diffusion models for black-box optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Krishnamoorthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mashkaria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Grover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Model inversion networks for model-based optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">G</forename><surname>Landrum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tosco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kelley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nadineschneider</surname></persName>
		</author>
		<author>
			<persName><surname>Vianello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dalke</surname></persName>
		</author>
		<author>
			<persName><surname>Cole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alexandersavelyev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Swain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Turk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vaucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kawashima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wójcikowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Probst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cosgrove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Berenger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jlvarjo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>O'boyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Fuller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doliathgavid</forename><surname>Sforna</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020-03">Mar. 2020</date>
		</imprint>
	</monogr>
	<note>rdkit/rdkit: 2020_03_1 (q1 2020) release</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">The vehicle routing problem with stochastic travel times</title>
		<author>
			<persName><forename type="first">G</forename><surname>Laporte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Louveaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mercure</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation science</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="161" to="170" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Derivative-free optimization methods</title>
		<author>
			<persName><forename type="first">J</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Menickelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Wild</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Numerica</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="287" to="404" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Learning to optimize</title>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">From distribution learning in training to gradient search in testing for combinatorial optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Combinatorial optimization with graph convolutional networks and guided tree search</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="page">31</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">A derivative-free approach to constrained multiobjective nonsmooth optimization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Liuzzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lucidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Rinaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on optimization</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2744" to="2774" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Contrastive energy prediction for exact energy-guided diffusion sampling in offline reinforcement learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="22825" to="22855" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Sampling can be faster than optimization</title>
		<author>
			<persName><forename type="first">Y.-A</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Flammarion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences</title>
		<meeting>the National Academy of Sciences</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="20881" to="20885" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Reinforcement learning for combinatorial optimization: A survey</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mazyavkina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sviridov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ivanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Burnaev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Operations Research</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page">105400</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Equation of state calculations by fast computing machines</title>
		<author>
			<persName><forename type="first">N</forename><surname>Metropolis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Rosenbluth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Rosenbluth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Teller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Teller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The journal of chemical physics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1087" to="1092" />
			<date type="published" when="1953">1953</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Unsupervised learning for solving the travelling salesman problem</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Gomes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.10538</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Stochastic zeroth-order functional constrained optimization: Oracle complexity and applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Balasubramanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">INFORMS Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="256" to="272" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Stochastic differential equations: an introduction with applications</title>
		<author>
			<persName><forename type="first">B</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Operational research: Methods and applications</title>
		<author>
			<persName><forename type="first">F</forename><surname>Petropoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Laporte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Aktas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Alumur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Archetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ayhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Battarra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Bennell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Bourjolly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Boylan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Operational Research Society</title>
		<imprint>
			<biblScope unit="page" from="1" to="195" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Score-based generative models detect manifolds</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pidstrigach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="35852" to="35865" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mildenhall</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.14988</idno>
		<title level="m">Dreamfusion: Text-to-3d using 2d diffusion</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Non-convex learning via stochastic gradient langevin dynamics: a nonasymptotic analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Raginsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rakhlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Telgarsky</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Learning Theory</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1674" to="1703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Engineering optimization: theory and practice</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Rao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<ptr target="http://www.rdkit.org" />
		<title level="m">RDKit: Open-source cheminformatics</title>
		<imprint>
			<date type="published" when="2013-04">-April-2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Exponential convergence of langevin distributions and their discrete approximations</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">O</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Tweedie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bernoulli</title>
		<imprint>
			<biblScope unit="page" from="341" to="363" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Y</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kroese</surname></persName>
		</author>
		<title level="m">Simulation and the Monte Carlo method</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Should ebms model the energy or the score?</title>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Energy Based Models Workshop-ICLR 2021</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Inverse molecular design using machine learning: Generative models for matter engineering</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sanchez-Lengeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">361</biblScope>
			<biblScope unit="issue">6400</biblScope>
			<biblScope unit="page" from="360" to="365" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Taking the human out of the loop: A review of bayesian optimization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Shahriari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">De</forename><surname>Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="148" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Bayesian reaction optimization as a tool for chemical synthesis</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Shields</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Parasram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Damani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I M</forename><surname>Alvarado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Janey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Doyle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">590</biblScope>
			<biblScope unit="issue">7844</biblScope>
			<biblScope unit="page" from="89" to="96" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Practical bayesian optimization of machine learning algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="page">25</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Deep unsupervised learning using nonequilibrium thermodynamics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Maheswaranathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2256" to="2265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Pseudoinverse-guided diffusion models for inverse problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mardani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Lossguided diffusion models for plug-and-play controllable generation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mardani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vahdat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="32483" to="32498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Generative modeling by estimating gradients of the data distribution</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Score-based generative modeling through stochastic differential equations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Gaussian process optimization in the bandit setting: no regret and experimental design</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Seeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on International Conference on Machine Learning</title>
		<meeting>the 27th International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1015" to="1022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title level="m" type="main">Your diffusion model secretly knows the dimension of the data manifold</title>
		<author>
			<persName><forename type="first">J</forename><surname>Stanczuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Batzolis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Deveney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-B</forename><surname>Schönlieb</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.12611</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Stochastic gradient descent as approximate bayesian inference</title>
		<author>
			<persName><forename type="first">M</forename><surname>Stephan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">134</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">DIFUSCO: Graph-based diffusion solvers for combinatorial optimization</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-seventh Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Policy gradient methods for reinforcement learning with function approximation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mansour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Fourier features let networks learn high frequency functions in low dimensional domains</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tancik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mildenhall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fridovich-Keil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ramamoorthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="7537" to="7547" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Mujoco: A physics engine for model-based control</title>
		<author>
			<persName><forename type="first">E</forename><surname>Todorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Erez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tassa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="5026" to="5033" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Conservative objective models for effective offline model-based optimization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Trabucco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Design-bench: Benchmarks for data-driven offline model-based optimization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Trabucco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="21658" to="21676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Conservative objective models for effective offline model-based optimization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Trabucco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="10358" to="10368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">From optimization to sampling through gradient flows</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Trillos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sanz-Alonso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NOTICES OF THE AMERICAN MATHEMATICAL SOCIETY</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Safe convex learning under uncertain constraints</title>
		<author>
			<persName><forename type="first">I</forename><surname>Usmanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kamgarpour</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">The 22nd International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2106" to="2114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Syba: Bayesian estimation of synthetic accessibility of organic compounds</title>
		<author>
			<persName><forename type="first">M</forename><surname>Voršilák</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kolář</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Čmelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Svozil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of cheminformatics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Unsupervised learning for combinatorial optimization with principled objective relaxation</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="31444" to="31458" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">De novo design of protein structure and function with rfdiffusion</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Juergens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Trippe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Eisenach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ahern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Borst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Ragotte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Milles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">620</biblScope>
			<biblScope unit="issue">7976</biblScope>
			<biblScope unit="page" from="1089" to="1100" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<monogr>
		<title level="m" type="main">Score-based generative models learn manifold-like structures with constrained mixing</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Wenliang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Moran</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.09952</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Sampling as optimization in the space of measures: The langevin dynamics as a composite optimization problem</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wibisono</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Learning Theory</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2093" to="3027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Deep kernel learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Artificial intelligence and statistics</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="370" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Stochastic variational deep kernel learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<monogr>
		<title level="m" type="main">Practical and asymptotically exact conditional sampling in diffusion models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Trippe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Naesseth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Cunningham</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.17775</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Roma: Robust model adaptation for offline model-based optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="4619" to="4631" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Importance-aware co-teaching for offline model-based optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Neiswanger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-seventh Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Let the flows tell: Solving graph combinatorial problems with GFlownets</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Malkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-seventh Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Unifying likelihood-free inference with blackbox optimization and beyond</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
