- **Generative Recommendation (GR)**: A paradigm that tokenizes user actions into discrete patterns for autoregressive generation of recommendations.
  
- **Context-Aware Tokenization**: ActionPiece improves upon existing methods by incorporating context into the tokenization process, allowing the same action to be represented differently based on surrounding actions.

- **Action Representation**: Each action is represented as a set of item features, denoted as \( A_j \) for item \( i_j \), where \( A_j = \{f_{j,1}, f_{j,2}, \ldots, f_{j,m}\} \).

- **Vocabulary Construction**:
  - **Initial Tokens**: Start with unique item features as initial tokens.
  - **Merge Rules**: Iteratively merge co-occurring token pairs based on weighted counts to form new tokens.
  - **Algorithm 1**: Outline for vocabulary construction:
    ```
    1: Initialize vocabulary V ← V0
    2: R ← ∅
    3: while |V| < Q do
    4:   count(•, •) ← Count(S ′ , V)
    5:   Select (cu, cv) ← arg max (ci,cj) count(ci, cj)
    6:   S ′ ← Update(S ′ , {(cu, cv) → cnew})
    7:   R ← R ∪ {(cu, cv) → cnew}
    8:   V ← V ∪ {cnew}
    9: end while
    ```

- **Set Permutation Regularization**: Introduces variations in token sequences by permuting features within each set, enhancing model robustness and training data diversity.

- **Performance Improvement**: ActionPiece outperforms existing methods, improving NDCG@10 by 6.00% to 12.82% on public datasets.

- **Action Sequence Representation**: The input action sequence is represented as \( S' = \{A_1, A_2, \ldots, A_t\} \), where each \( A_i \) is an unordered set of features.

- **Generative Task**: The goal is to predict the next item \( i_{t+1} \) based on the historical action sequence \( S \).

- **Token Sequence Output**: The tokenizer maps the input action sequence \( S' \) to a token sequence \( C = \{c_1, c_2, \ldots, c_l\} \), where \( l > t \).

- **Contextual Relationships**: Emphasizes the importance of contextual relationships among actions, which can significantly affect user intent and recommendation quality.

- **Comparison with Language Modeling**: Draws parallels between action tokenization and subword-level tokenization in language models, highlighting the evolution from context-independent to context-aware methods.