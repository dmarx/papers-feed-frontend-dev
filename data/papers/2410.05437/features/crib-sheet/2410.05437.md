- **ESPACE Overview**: Eigen Static Principal Activation Component Estimation (ESPACE) is a compression technique for LLMs based on activation dimensionality reduction, projecting activations onto a static set of principal components.

- **Key Contributions**:
  - Projects activation tensors onto a pre-calibrated orthonormal matrix, reducing dimensionality while keeping weight matrices intact.
  - Achieves model compression through matrix multiplication associativity, allowing for weight decomposition as a byproduct.
  - Theoretical derivation of optimal projection matrices to minimize mean squared error and forward propagated noise.

- **Compression Performance**:
  - Achieves ~50% compression on models like GPT3, Llama2, and Nemotron4 with minimal accuracy loss (e.g., 0.18 increase in perplexity on GPT3-22B).
  - At lower compression rates (20%-40%), can improve model performance (e.g., 0.38 decrease in perplexity for GPT3-8B).

- **Latency Reduction**: ESPACE reduces GEMM execution time and prefill inference latency by 35%-45%, translating to up to ~40% faster time to first token on existing hardware.

- **Matrix Multiplication Notation**:
  - General form: \( Y = W^T X \)
    - \( W \): weight matrix (size \( K \times N \))
    - \( X \): input activation tensor (size \( K \times M \))
    - \( Y \): output activation tensor (size \( N \times M \))

- **Activation Projection**:
  - Approximation: \( Y \approx W^T P P^T X \)
    - \( P \): static orthonormal projection matrix (size \( K \times L \), where \( L << K \))
    - \( P^T P = I_{L \times L} \), but \( PP^T \neq I_{K \times K} \)

- **Training and Inference**:
  - During training: \( Y = W^T P P^T X \) (weights \( W^T \) are trainable, \( P \) is static).
  - During inference: \( Y = P^T W^T P^T X \) (requires pre-computed matrices \( P \) and \( P^T W \)).

- **Comparison with Existing Techniques**:
  - ESPACE is distinct from weight-centric tensor decomposition methods (e.g., KnGPT, TSVD) as it focuses on activation decomposition.
  - Addresses limitations of prior methods by maintaining weight expressivity during retraining.

- **Future Directions**: Suggests exploring the combination of ESPACE with other compression techniques (e.g., quantization, pruning) for enhanced performance.