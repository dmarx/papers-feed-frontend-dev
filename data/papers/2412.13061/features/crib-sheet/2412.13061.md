- **VidTok Overview**
  - A versatile video tokenizer designed for both continuous and discrete tokenizations.
  - Addresses redundancy in pixel-level representations by encoding video content into compact latent tokens.

- **Key Advancements**
  - **Model Architecture**: Utilizes 2D convolutions for spatial processing and AlphaBlender for temporal processing, reducing computational complexity while maintaining quality.
  - **Finite Scalar Quantization (FSQ)**: Integrates FSQ to mitigate training instability and codebook collapse associated with traditional Vector Quantization (VQ).
  - **Training Strategies**: Employs a two-stage training process (pre-training on low-resolution, fine-tuning on high-resolution) and utilizes reduced frame rates for improved motion representation.

- **Performance Metrics**
  - Achieves superior results in PSNR, SSIM, LPIPS, and FVD across multiple benchmarks, including MCL-JCV.

- **Tokenization Types**
  - **Discrete Tokenization**: Maps input images to a latent space, quantizing representations using a codebook, reducing error accumulation in autoregressive generation.
  - **Continuous Tokenization**: Offers higher reconstruction fidelity, often used with diffusion models for enhanced output quality.

- **Model Architecture Details**
  - **Encoder-Decoder Structure**: 
    - Encoder (E) compresses video data into latent tokens.
    - Decoder (D) reconstructs tokens back into pixel space.
    - Regularizer (R) applied in latent space to prevent overfitting.
  - **Mathematical Representation**:
    - Input video: \( X = \{x_1, x_2, ..., x_N\} \in \mathbb{R}^{N \times 3 \times H \times W} \)
    - Compressed latent representation: \( Z = R(E(X)) \)
    - Reconstructed video: \( X = D(Z) \)

- **AlphaBlender Operator**
  - Blends two inputs \( x_1 \) and \( x_2 \) using a parameter \( \alpha \):
    \[
    x = \alpha \cdot x_1 + (1 - \alpha) \cdot x_2
    \]
  - In VidTok, \( \alpha \) is set as \( \text{Sigmoid}(0.2) \).

- **Causal Processing**
  - In causal scenarios, the first frame is treated independently, allowing the tokenizer to function as both an image and video tokenizer.

- **Experimental Validation**
  - Results demonstrate that VidTok outperforms existing models in both discrete and continuous tokenization tasks, confirming the effectiveness of the proposed advancements.