- Decision to use a two-stage approach for unlearning in GANs
- Choice of feedback-based unlearning framework
- Selection of negative and positive samples for adaptation and unlearning
- Implementation of a repulsion regularizer during the unlearning stage
- Decision to adapt a pre-trained GAN instead of retraining from scratch
- Choice of datasets for validation (MNIST, AFHQ, CelebA-HQ)
- Theoretical justification using a Bayesian framework
- Decision to focus on high-fidelity GANs like StyleGAN
- Choice of metrics for evaluating the quality of generated samples
- Decision to operate in few-shot settings for user feedback
- Assumptions about the interpretability of parameter space directions
- Decision to validate the method through comprehensive experiments
- Choice of adversarial loss for training during the unlearning stage
- Decision to explore both class-level and feature-level unlearning tasks
- Assumptions regarding the impact of unlearning on correlated features
- Decision to make code and implementation publicly available on GitHub