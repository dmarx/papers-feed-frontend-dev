<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adapt then Unlearn: Exploring Parameter Space Semantics for Unlearning in Generative Adversarial Networks</title>
				<funder>
					<orgName type="full">Infosys Foundation Young investigator award</orgName>
				</funder>
				<funder ref="#_KfVJsX9">
					<orgName type="full">Indian Institute of Science</orgName>
				</funder>
				<funder>
					<orgName type="full">MoE Fellowship</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-02-12">12 Feb 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Piyush</forename><surname>Tiwary</surname></persName>
							<email>piyushtiwary@iisc.ac.in</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Electrical Communication Engineering</orgName>
								<orgName type="department" key="dep2">Department of Electrical Engineering</orgName>
								<orgName type="institution" key="instit1">Indian Institute of Science</orgName>
								<orgName type="institution" key="instit2">Indian Institute of Technology</orgName>
								<address>
									<settlement>Patna</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Atri</forename><surname>Guha</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Electrical Communication Engineering</orgName>
								<orgName type="department" key="dep2">Department of Electrical Communication Engineering</orgName>
								<orgName type="institution" key="instit1">Indian Institute of Science</orgName>
								<orgName type="institution" key="instit2">Indian Institute of Science</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Adapt then Unlearn: Exploring Parameter Space Semantics for Unlearning in Generative Adversarial Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-02-12">12 Feb 2025</date>
						</imprint>
					</monogr>
					<idno type="MD5">75891715D6C5BBDE21AD11D46D7CE486</idno>
					<idno type="arXiv">arXiv:2309.14054v2[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-03-16T06:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Owing to the growing concerns about privacy and regulatory compliance, it is desirable to regulate the output of generative models. To that end, the objective of this work is to prevent the generation of outputs containing undesired features from a pre-trained Generative Adversarial Network (GAN) where the underlying training data set is inaccessible. Our approach is inspired by the observation that the parameter space of GANs exhibits meaningful directions that can be leveraged to suppress specific undesired features. However, such directions usually result in the degradation of the quality of generated samples. Our proposed two-stage method, known as 'Adapt-then-Unlearn,' excels at unlearning such undesirable features while also maintaining the quality of generated samples. In the initial stage, we adapt a pre-trained GAN on a set of negative samples (containing undesired features) provided by the user. Subsequently, we train the original pre-trained GAN using positive samples, along with a repulsion regularizer. This regularizer encourages the learned model parameters to move away from the parameters of the adapted model (first stage) while not degrading the generation quality. We provide theoretical insights into the proposed method. To the best of our knowledge, our approach stands as the first method addressing unlearning within the realm of high-fidelity GANs (such as StyleGAN). We validate the effectiveness of our method through comprehensive experiments, encompassing both class-level unlearning on the MNIST and AFHQ dataset and feature-level unlearning tasks on the CelebA-HQ dataset. Our code and implementation is available at: <ref type="url" target="https://github.com/atriguha/Adapt_Unlearn">https://github.com/atriguha/Adapt_Unlearn</ref>.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Unlearning</head><p>Recent advancements in deep generative models such as Generative Adversarial Networks (GANs) <ref type="bibr" target="#b21">(Goodfellow et al., 2014;</ref><ref type="bibr" target="#b1">Arjovsky et al., 2017;</ref><ref type="bibr">Karras et al., 2018b;</ref><ref type="bibr">a;</ref><ref type="bibr" target="#b20">2020)</ref> and Diffusion models <ref type="bibr" target="#b26">(Ho et al., 2020;</ref><ref type="bibr" target="#b62">Song &amp; Ermon, 2019;</ref><ref type="bibr" target="#b63">Song et al., 2021)</ref> have showcased remarkable performance in diverse tasks, from generating high-fidelity images <ref type="bibr">(Karras et al., 2018a;</ref><ref type="bibr" target="#b20">2020;</ref><ref type="bibr">2021)</ref> to text-to-image translations <ref type="bibr" target="#b58">(Ramesh et al., 2021;</ref><ref type="bibr">2022;</ref><ref type="bibr" target="#b60">Rombach et al., 2022)</ref>. Consequently, these models find application in various fields, including but not limited to medical imaging <ref type="bibr" target="#b7">(Celard et al., 2023;</ref><ref type="bibr" target="#b68">Varoquaux &amp; Cheplygina, 2022;</ref><ref type="bibr">Tiwary et al., 2024a)</ref>, remote sensing <ref type="bibr" target="#b2">(Ball et al., 2017;</ref><ref type="bibr" target="#b0">Adegun et al., 2023)</ref>, hyperspectral imagery <ref type="bibr" target="#b29">(Jia et al., 2021;</ref><ref type="bibr" target="#b71">Wang et al., 2023)</ref>, and many others <ref type="bibr" target="#b10">(Choudhary et al., 2022;</ref><ref type="bibr" target="#b82">Yang &amp; Xu, 2021;</ref><ref type="bibr" target="#b42">Liu et al., 2021;</ref><ref type="bibr">Tiwary et al., 2024b)</ref>. However, the extensive incorporation of data with possible undesired features or inherent biases cause these models to generate violent, racial, or explicit content which poses significant concerns <ref type="bibr" target="#b67">(Tommasi et al., 2017)</ref>. Thus, these models are subject to regulatory measures <ref type="bibr" target="#b69">(Voigt &amp; dem Bussche, 2017;</ref><ref type="bibr" target="#b20">Goldman, 2020)</ref>. Identifying and eliminating these undesired features from the model's knowledge representation poses a challenging task. The framework of Machine Unlearning <ref type="bibr" target="#b81">(Xu et al., 2020;</ref><ref type="bibr">Nguyen et al., 2022b)</ref> tries to solve this problem by removing specific training data points containing undesired feature from the pre-trained model. Specifically, machine unlearning refers to the task of forgetting the learned information <ref type="bibr" target="#b61">(Sekhari et al., 2021;</ref><ref type="bibr" target="#b44">Ma et al., 2022;</ref><ref type="bibr" target="#b83">Ye et al., 2022;</ref><ref type="bibr" target="#b5">Cao &amp; Yang, 2015;</ref><ref type="bibr" target="#b19">Golatkar et al., 2021;</ref><ref type="bibr">2020a;</ref><ref type="bibr" target="#b15">Ginart et al., 2019;</ref><ref type="bibr">Golatkar et al., 2020b)</ref>, or erasing the influence of specific data subset of the training dataset from a trained model in response to a user request <ref type="bibr">(Wu et al., 2020a;</ref><ref type="bibr" target="#b23">Guo et al., 2020;</ref><ref type="bibr" target="#b22">Graves et al., 2021;</ref><ref type="bibr" target="#b76">Wu et al., 2022;</ref><ref type="bibr">2020b;</ref><ref type="bibr" target="#b11">Chourasia &amp; Shah, 2023)</ref>.</p><p>The task of unlearning can be challenging because we aim to 'unlearn' a specific undesired feature without negatively impacting the previously acquired knowledge. In other words, unlearning could lead to Catastrophic Forgetting <ref type="bibr" target="#b15">(Ginart et al., 2019;</ref><ref type="bibr">Nguyen et al., 2022a;</ref><ref type="bibr">Golatkar et al., 2020b)</ref> which would significantly deteriorate the performance of the model. Further, the level of difficulty faced in the process of unlearning may vary depending on the specific features of the data that one is required to unlearn. For example, unlearning a particular class (e.g. class of digit '9' in MNIST) could be relatively easier than unlearning a more subtle feature (e.g. beard feature in CelebA). This is because the classes in MNIST are quite distinct and don't necessarily share correlated features. Whereas, in the CelebA <ref type="bibr" target="#b43">(Liu et al., 2015)</ref> dataset, the feature of having a beard is closely linked to the concept of gender. So, unlearning this subtle feature while retaining other correlated features such as gender, poses an increasingly difficult challenge. It is important to mention that re-training the model from scratch without the undesired input data is not feasible in this setting due unavailability of the training dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Motivation and Contribution</head><p>In this work, we try to solve the problem of unlearning undesired feature in pre-trained generative adversarial networks (GANs) without having access to the training data used for pre-training the GAN. We operate under the feedback-based unlearning framework, where we start with a pre-trained GAN. A user is given a set of generated samples from this GAN. The user chooses a subset of generated samples and identifies them as 'undesirable' (negative samples). The feedback-based approach is similar to RLHF in LLMs or human-inloop settings in general <ref type="bibr" target="#b84">(Ziegler et al., 2019;</ref><ref type="bibr" target="#b12">Christiano et al., 2017;</ref><ref type="bibr" target="#b37">Lambert et al., 2022)</ref>. The objective of the process of unlearning is to prevent the generation of undesirable characteristics, as identified by the user. We propose to unlearn the undesired features by following a two-step approach. In the first step, we adapt the pre-trained generator to the undesired features by using the samples marked as undesired by the user (negative samples). This ensures that the 'adapted' generator exclusively generates samples that possess the undesired features. In the next step, we unlearn the undesired features from the original GAN by using the samples that weren't marked as undesired by the user (positive samples). While unlearning, we add a repulsion loss that encourages the parameters of the generator to stay away from the parameters of the adapted generator (obtained from first step) while also making sure that the quality of generated samples does not deteriorate. We provide theoretical justification for the proposed method by using a bayesian framework. Particularly, we show that the proposed method leads to contrastive-divergence kind of objective desired for unlearning. We call the proposed two-stage process 'Adapt-then-Unlearn'. An overview of the proposed method is shown in figure <ref type="figure" target="#fig_0">1 (a)</ref>.</p><p>Our approach hinges in realizing interpretable and meaningful directions within the parameter space of a pre-trained GAN generator, as discussed in <ref type="bibr" target="#b8">(Cherepkov et al., 2021)</ref>. In particular, the first stage of the proposed method leads to adapted parameters that exclusively generate negative samples. While the parameters of the original pre-trained generator generate both positive as well as negative samples. Hence, the difference between the parameters of adapted generator and the paramters of original generator can be interpreted as the direction in parameter space that leads to a decrease in the generation of negative samples. Given this, it is sensible to move away from the original parameters in this direction to further reduce the generation of negative samples. This observation is shown in figure 1 (b). However, it's worth noting that such extrapolation doesn't ensure the preservation of other image features' quality. In fact, deviations too far from the original parameters may hamper the smoothness of the latent space, potentially leading to a deterioration in the overall generation quality (see last columns of figure 1 (b)). Inspired by this observation, during unlearning stage, we propose to train the generator using adversarial loss while encouraging the generator parameters to be away from the parameters of the adapted generator by employing a repulsion regularization.</p><formula xml:id="formula_0">G θ G G θ P G θ N G θ G Pre-</formula><p>We provide a visual illustration of the proposed method on Mixture of Gaussian (MoG) dataset with eight centers in figure <ref type="figure" target="#fig_0">1 (c</ref>). The first column shows the original training dataset and the samples generated by the pre-trained GAN. The second column shows the negative samples provided during feedback and the samples generated by the adapted generator. We can see that the adapted generator exclusively generates samples from the negative modes of MoG. Lastly, in the third column, we see the positive samples and the samples generated after unlearning the negative modes. We clearly observe that after unlearning (via the proposed method), the generator unlearns the negative modes and generates samples from the rest of the modes. This gives a proof-of-concept for the proposed method.</p><p>We summarize our contribution as follows:</p><p>• We introduce a two-stage approach for machine unlearning in GANs. In the first stage, our method adapts the pre-trained GAN to the negative samples. In the second stage, we train the GAN using a repulsion loss, ensuring that the generator's parameters diverge from those of the adapted GAN in stage 1.</p><p>• By design, our method can operate in practical few-shot settings where the user provides a very small amount of negative samples.</p><p>• We provide theoretical justification for the proposed method by showing that the proposed regularization leads to contrastive-divergence kind of objectives appropriate for unlearning.</p><p>• The proposed method is thoroughly tested on multiple datasets, considering various types of unlearning scenarios such as class-level unlearning and feature-level unlearning. Throughout these tests, we empirically observe that the quality of the generated samples is not compromised.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Machine Unlearning</head><p>Unlearning can be naively done by removing the unwanted data subset from the training dataset and then retraining the model from scratch. However, retraining is computationally costly and becomes impossible if the unlearning request comes recursively for single data points. The task of recursively 'unlearning' i.e. removing information of a single data point in an online manner (also known as decremental learning) for the SVM algorithm was introduced in <ref type="bibr" target="#b6">(Cauwenberghs &amp; Poggio, 2000)</ref>. However, when multiple data points are added or removed, these algorithms become slow because they need to be applied to each data point individually. To address this, <ref type="bibr" target="#b30">(Karasuyama &amp; Takeuchi, 2009)</ref> introduced a newer type of SVM training algorithm that can efficiently update an SVM model when multiple data points are added or removed simultaneously. Later, inspired by the problem of protecting user privacy <ref type="bibr" target="#b5">(Cao &amp; Yang, 2015)</ref> developed efficient ways to delete data from certain statistical query algorithms and coined the term "machine unlearning". The works of <ref type="bibr" target="#b15">(Ginart et al., 2019)</ref> extended the idea of unlearning to more complicated algorithms such k-means clustering and also proposed the first definition of effective data deletion that can be applied to randomized algorithms, in terms of statistical indistinguishability. Depending upon this statistical indistinguishability criteria machine unlearning processes are widely classified into exact unlearning <ref type="bibr" target="#b15">(Ginart et al., 2019;</ref><ref type="bibr" target="#b4">Brophy &amp; Lowd, 2021)</ref> and approximate unlearning methods <ref type="bibr" target="#b50">(Neel et al., 2021;</ref><ref type="bibr" target="#b52">Nguyen et al., 2020)</ref>. The goal of exact unlearning is to exactly match the parameter distributions of the unlearned model and the retrained model where as, in approximate unlearning, the distributions of the unlearned and retrained model's parameters are close to some small multiplicative and additive terms <ref type="bibr" target="#b50">(Neel et al., 2021)</ref>. To extend the idea of unlearning or efficient data deletion for non-convex models such as deep neural networks <ref type="bibr">(Golatkar et al., 2020b)</ref> proposed a scrubbing mechanism for approximate unlearning in deep neural networks. A more efficient method of unlearning in deep networks is proposed by <ref type="bibr" target="#b16">(Goel et al., 2022)</ref> where the initial layers of deep networks are frozen while the last few layers are finetuned on the filtered dataset. Further to achieve the goal of exact unlearning <ref type="bibr" target="#b28">(Jia et al., 2023)</ref> exploit the model sparsification technique via weight pruning.</p><p>Even though all of these methods achieve unlearning in supervised deep networks, the generalization of these methods for state-of-the-art high-fidelity GANs is unexplored.</p><p>Few methods like cascaded unlearning <ref type="bibr" target="#b64">(Sun et al., 2023)</ref> and data redaction <ref type="bibr" target="#b35">(Kong &amp; Chaudhuri, 2023)</ref> try to prevent generation of undesired features in GANs, however, their methods operate primarily on very primitive DC-GAN as opposed to high-fidelity GANs like StyleGAN which is the focus of this work. While <ref type="bibr" target="#b64">Sun et al. (2023)</ref> also show result on StyleGAN, there are several significant differences compared to the proposed method. First, there is a fundamental difference in the unlearning setting between <ref type="bibr" target="#b64">Sun et al. (2023)</ref> and our method. To reduce the generation of undesired samples, <ref type="bibr" target="#b64">Sun et al. (2023)</ref> proposes to forget undesired samples from the training dataset. Specifically, they assume access to samples from the training dataset. This is somewhat restrictive since users typically don't have access to the training data <ref type="bibr" target="#b13">(Chundawat1 et al., 2023;</ref><ref type="bibr" target="#b22">Graves et al., 2021)</ref>. Further, in terms of methodology, <ref type="bibr" target="#b64">Sun et al. (2023)</ref> propose to patch the latent space of the GAN with representative samples. They suggest various strategies for generating these representative samples, such as using 'average samples' or 'other class samples' (cf. Section 4.3 of their paper). However, imposing such constraints on the latent space may lead to suboptimal latent-space semantics, potentially harming the quality of generated images. To address this, we avoid manipulating the latent space directly. Instead, we focus on parameter-space semantics, where we identify generator parameters that produce undesired samples (Stage-1: Negative Adaptation), and then retrain the GAN to avoid these parameters (Stage-2: Unlearning Phase). Additionally, since the latent space naturally adjusts based on changes in the parameter space (as shown in figure 1 (b)), we find it sufficient to focus on parameter-space semantics alone, as it automatically handles latent-space semantics as well. To the best of our knowledge, these insights into parameter-space semantics have not been explored in the context of unlearning, making our approach novel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Few-Shot Generative Domain Adaptation</head><p>The area of few-shot generative domain adaptation deals with the problem where a pre-trained generative model is adapted to a target domain using very few samples. A general strategy to do this is to fine-tune the model on target data using appropriate regularizers. Eg. <ref type="bibr" target="#b72">Wang et al. (2018)</ref> observed that using a single pre-trained GAN for fine-tuning is good enough for adaptation. However, due to the limited amount of target data, this could lead to mode collapse, hence <ref type="bibr" target="#b55">Noguchi &amp; Harada (2019)</ref> proposed to fine-tune only the batch statistics of the model. Although, such a strategy can be very restrictive in practice. To overcome this issue, <ref type="bibr" target="#b73">Wang et al. (2020)</ref> proposed to append a 'miner' network before the generator. They propose a two-stage framework, where the miner network is first trained to transform the input latent space to capture the target domain distribution then the whole pipeline is re-trained using target data. While these fine-tuning based methods give equal weightage to all the parameters of the generator, <ref type="bibr" target="#b41">Li et al. (2020)</ref> proposed to fine-tune the parameter using Elastic Weight Consolidation (EWC). Particularly, EWC is used to penalize large changes in important parameters. This importance is quantified using Fisher-information while adapting the pre-trained GAN. <ref type="bibr" target="#b47">Mo et al. (2020)</ref> showed that fine-tuning a GAN by freezing the lower layers of discriminator is good enough in few-shot setting. Recently, a string of work <ref type="bibr" target="#b56">(Ojha et al., 2021;</ref><ref type="bibr" target="#b79">Xiao et al., 2022;</ref><ref type="bibr" target="#b39">Lee et al., 2021)</ref> focuses on few-shot adaptation by preserving the cross-domain correspondence. Lastly, <ref type="bibr" target="#b48">Mondal et al. (2022)</ref> suggested an inference-time optimization approach where a they prepend a latent-learner, and the latent-learner is optimized every time a new set of images are to be generated from target domain.</p><p>As mentioned earlier, our approach involves an adaptation stage, where we adapt the pre-trained GAN to the negative samples provided by the user. In practice, the amount of negative samples provided by the user is very less hence such an adaptation falls under the category of few-shot generative domain adaptation. Hence, we make use of EWC <ref type="bibr" target="#b41">(Li et al., 2020)</ref> for this adaptation phase (cf. Section 3.2 for details).</p><p>3 Proposed Methodology</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Formulation and Method Overview</head><p>Consider the generator G θ G of a pre-trained GAN with parameters θ G and an implicit generator distribution</p><formula xml:id="formula_1">p G (y). The GAN is trained using a dataset D = {x i } |D| i=1</formula><p>, where x i iid ∼ p data (x). Using the feedbackbased framework <ref type="bibr" target="#b49">(Moon et al., 2023)</ref>, we obtain a few negative and positive samples, marked by the user. Specifically, the user is provided with n samples S = {y i } n i=1 where y i are the generated samples from the pre-trained GAN, i.e., y i iid ∼ p G (y). The user identifies a subset of these samples S n = {y i } i∈sn , as negative samples or samples with undesired features, and the rest of the samples S p = {y i } i∈sp as positive samples or samples that don't possess the undesired features. Here, s p and s n are index sets such that</p><formula xml:id="formula_2">s p ∪ s n = {1, 2, . . . , n} and s p ∩ s n = ϕ. Formally, {y i } i∈sn iid ∼ p N (y) and {y i } i∈sp iid ∼ p G\N (y), where, p N (y)</formula><p>is the implicit generator distribution on negative samples and p G\N (y) is the implicit generator distribution after removing support of negative samples. Given this, the goal of unlearning is to learn the parameters θ P such that the generator G θ P generates only positive samples. In other words, the parameters θ P should lead to unlearning of the undesired features.</p><p>Our approach involves two stages: In Stage 1, we adapt the pre-trained generator G θ G on the user-marked negative samples. This step gives us the parameters θ N such that G θ N generates only negative samples. In Stage 2, we unlearn the undesired features by training the original generator G θ G on positive samples using the usual adversarial loss while adding an additional regularization term that makes sure that the learned parameter is far from θ N . We call this regularization term repulsion loss as it repels the learned parameters from θ N .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Stage-1: Negative Adaptation</head><p>The aim of the first stage of our method is to obtain parameter θ N such that the generator G θ N only generates negative samples (S n ). However, one thing to note here is that the number of negative samples marked by the user |S n | might be much less in number (of the order of tens or a few hundred). Directly adapting a pretrained GAN with a much smaller amount of samples could lead to catastrophic forgetting <ref type="bibr" target="#b45">(McClelland et al., 1995;</ref><ref type="bibr" target="#b46">McCloskey &amp; Cohen, 1989)</ref>. To address this issue, we employ a few-shot GAN adaptation technique, namely, Elastic Weight Consolidation (EWC) <ref type="bibr" target="#b41">(Li et al., 2020)</ref>, mainly because of its simplicity and ease of implementation. EWC-based adaptation relies on the simple observation that the 'rate of change' of weights is different for different layers. Further, this 'rate of change' is observed to be inversely proportional to the Fisher information, F of the corresponding weights, which can used for penalizing changes in weights in different layers.</p><p>In our context, we want to adapt the pre-trained GAN on the negative samples. Hence, the optimal parameter θ N for the adapted GAN can be obtained by solving the following optimization problem:</p><formula xml:id="formula_3">θ N , ϕ N = arg min θ max ϕ L adv + γL adapt (1)</formula><p>where,</p><formula xml:id="formula_4">L adv = E x∼p N (x) [log D ϕ (x)] + E z∼p Z (z) [log(1 -D ϕ (G θ (z)))]<label>(2)</label></formula><formula xml:id="formula_5">L adapt = λ i F i (θ i -θ G,i ), F = E - ∂ 2 ∂θ 2 G L θ G (S n ) (3)</formula><p>Here, p Z (z) is the standard Gaussian prior, and L θ G (S n ) refers to the log-likelihood function for the samples S n generated by the GAN with parameters θ G . Specifically, L θ G (S n ) = log p θ G (S n ) which is the log-likelihood of the negative samples under the generator's distribution with parameter θ G . This term can be estimated by calculating the binary cross-entropy of the discriminator's output, D ϕ (S n ), as shown in <ref type="bibr" target="#b41">(Li et al., 2020)</ref>. In practice, we train multiple instances of the generator to obtain multiple θ N . Specifically, given the negative samples S n , we adapt the pre-trained GAN k times to obtain {θ j N } k j=1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Stage-2: Unlearning</head><p>In the second stage of our method, the actual unlearning of undesired features takes place. In particular, this stage is motivated by the observation that there exist meaningful directions in the parameter space of the generator, shown in figure 1 (b). However, such extrapolation-based schemes could lead to degradation in the quality of generated images.</p><p>Nevertheless, the above observation indicates that traversing away from θ N helps us to erase or unlearn the undesired features. Therefore, we ask the following question: Can we transverse in the parameter space of a generator in such a way the parameters remain far from θ N while making sure that the quality of generated samples doesn't degrade? To solve this problem, we make use of the positive samples S p provided by the user. Particularly, we propose to train the given GAN on the positive samples while incorporating a repulsion loss component that 'repels' or keeps the learned parameters away from θ N . Mathematically, we obtain the parameters after unlearning θ P by solving the following optimization problem:</p><formula xml:id="formula_6">θ P , ϕ P = arg min θ max ϕ L ′ adv + γL repulsion (4)</formula><p>where,</p><formula xml:id="formula_7">L ′ adv = E x∼p G\N (x) [log D ϕ (x)] + E z∼p Z (z) [log(1 -D ϕ (G θ (z)))] (5)</formula><p>Here, L repulsion is the repulsion loss. The repulsion loss is chosen such that it encourages the learned parameters to be far from θ N obtained from Stage-1. Further, L ′ adv encourages the parameters to capture the desired distribution p G\N (x). Hence, the combination of these two terms makes sure that we transverse in the parameter space maintaining the quality of generated samples while unlearning the undesired features as well.</p><p>We emphasize that L ′ adv is different from L adv used in Stage-1. Specifically, the two adversarial terms serve different purposes: (i) L adv is utilized during the Negative Adaptation Phase (Stage-1) to adapt the original GAN to the negative samples (S n ), and (ii) L ′ adv is applied during the Unlearning Phase (Stage-2) to retrain the original GAN on positive samples (S p ), which are the samples not marked as undesired.</p><p>Note: Our method requires users to identify or annotate negative samples, i.e., those containing undesired features. This annotation serves to adapt the GAN to negative samples during the Negative Adaptation phase and subsequently retrain it on positive samples during the Unlearning phase. While human feedback is one approach for obtaining these samples, other methods, such as curating datasets of positive and negative samples, can also be employed. However, curating such datasets can be challenging, especially when the feature, concept, or class to be unlearned is subtle or complex and is not readily annotated in standard datasets. In such scenarios, users may need to create a custom dataset. By contrast, our current approach leverages human feedback to annotate readily available samples generated by the GAN, reducing the need for external dataset creation. Nonetheless, if a pre-curated dataset of positive and negative samples is available, our method can be easily adapted to use it. The GAN can be trained on this dataset to obtain the negative parameters θ N , which can then be utilized in the Unlearning phase. We demonstrate few results using such approach in Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm: Adapt-then-Unlearn</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stage-1: Negative Adaptation</head><p>Stage-2: Unlearning Required: Pre-trained parameters (θ G , ϕ D ), Negative samples (S n ), Number of adapted models (k). Initialize: j ← 0</p><formula xml:id="formula_8">Required: Pre-trained parameters (θ G , ϕ D ), Posi- tive samples (S p ), Adapted models (θ N = {θ j N } k j=1 ). Initialize: θ P ← θ G , ϕ P ← ϕ D 1: while j ≤ k do 2: θ ← θ G , ϕ ← ϕ D 3: repeat 4: Sample x ∼ S n and z ∼ N (0, I) 5: L adv ← log D ϕ (x) + log (1 -D ϕ (G θ (z))) 6: L adapt ← λ i F i (θ i -θ G,i ) 7: θ ← θ -η∇ θ (L adv + L adapt ) 8: until convergence 9: θ j N ← θ 10: j ← j + 1 11: end while 1: repeat 2:</formula><p>Sample x ∼ S p and z ∼ N (0, I)</p><formula xml:id="formula_9">3: L ′ adv ← log D ϕ (x) + log (1 -D ϕ (G θ (z))) 4:</formula><p>Choose L repulsion from Eq. 6</p><formula xml:id="formula_10">5: θ ← θ -η∇ θ (L ′ adv + L repulsion ) 6: until convergence</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Choice of Repulsion Loss</head><p>As mentioned above, the repulsion loss should encourage the learned parameter to traverse away from θ N obtained from the negative adaptation stage. Here, we note that the repulsion term operates in parameterspace of the generator. There is a lineage of research work in Bayesian learning called Deep Ensembles, where multiple MAP estimates of a network are used to approximate full-data posterior <ref type="bibr" target="#b40">(Levin et al., 1990;</ref><ref type="bibr" target="#b24">Hansen &amp; Salamon, 1990;</ref><ref type="bibr" target="#b3">Breiman, 1996;</ref><ref type="bibr" target="#b36">Lakshminarayanan et al., 2017;</ref><ref type="bibr" target="#b57">Ovadia et al., 2019;</ref><ref type="bibr" target="#b75">Wilson &amp; Izmailov, 2020;</ref><ref type="bibr" target="#b14">D'Angelo &amp; Fortuin, 2021)</ref>. However, if the members of an ensemble are not diverse enough, then the posterior approximation might not capture the multi-modal nature of full-data posterior. As a consequence, there are several methods proposed to increase the diversity of the members of the ensemble <ref type="bibr" target="#b27">(Huang et al., 2016;</ref><ref type="bibr" target="#b70">Von Oswald et al., 2020;</ref><ref type="bibr" target="#b14">D'Angelo &amp; Fortuin, 2021;</ref><ref type="bibr" target="#b74">Wenzel et al., 2020;</ref><ref type="bibr" target="#b14">D'Angelo &amp; Fortuin, 2021)</ref>.</p><p>Inspired by these developments, we make use of the technique proposed in D' <ref type="bibr">Angelo &amp; Fortuin (2021)</ref> where the members of an ensemble interact with each other through a repulsive force that encourages diversity in the ensemble. Particularly, we explore three choices for repulsion loss:</p><formula xml:id="formula_11">L repulsion =      L IL2 repulsion = 1 ||θ-θ N || 2 2 (Inverse ℓ2 loss) L NL2 repulsion = -||θ -θ N || 2 2 (Negative ℓ2 loss) L EL2 repulsion = exp(-α||θ -θ N || 2 2 ) (Exponential negative ℓ2 loss) (6)</formula><p>It can be seen that minimization of all of these choices will force θ to be away from θ N , consequently serving our purpose. In fact, in general, one can use any function of ∥θ -θ N ∥ 2 2 that has a global maxima at θ N as a choice for repulsion loss. In this work, we work with the above mentioned choices. An algorithmic overview of Stage-1 Negative Adaptation is presented in Algorithms 11 and Stage-2 Unlearning is presented in Algorithm 6</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Theoretical Discussion</head><p>In this section, we present theoretical insights into the proposed method. Inspired by the work in Nguyen et al. ( <ref type="formula">2020</ref>), we operate in Bayesian setting for these claims and make use of widely used Laplace approximation around relevant parameters. Specifically, we demonstrate that for an optimal discriminator, the proposed regularization term combined with the adversarial term results in a contrastive divergence-like objective (a difference of two divergence terms). This encourages the generator to capture the implicit distribution of the pre-trained generator without the support of negative samples while maximizing the divergence between the parameter distribution of the post-unlearning generator and that of the generator which produces negative samples (Theorem 1). This result is shown in . Further, we show the relation between the parameter space divergence and data space divergence (Claim 1).</p><p>For this, let Θ denote the parameter space of a generator network. Let θ G ∈ Θ be the parameter of a pre-trained generator with an implicit distribution p X G (x) over the data space<ref type="foot" target="#foot_0">foot_0</ref> . Further, consider two distributions p Θ N (θ) and p Θ U (θ) over Θ, where the latter is a learnable distribution and the former is such that for z ∼ p Z (z) the corresponding generated samples from manifested generator G θ (z) ∼ p X N (x). In other words, samples from p Θ N (θ) lead to the generation of negative samples. Theorem 1. Consider the distributions p Θ N (θ) and p Θ U (θ) to be Gaussian, i.e., p Θ N (θ) =</p><formula xml:id="formula_12">1 |2πΣ| d/2 exp 1 2 (θ -θ N ) T Σ -1 (θ -θ N ) and p Θ U (θ) = 1 |2πΣ| d/2 exp 1 2 (θ -θ P ) T Σ -1 (θ -θ P )</formula><p>, where Σ = I, θ N and θ P are the mean parameters and θ P is learnable. Then statements (1 -3) hold for the following optimization problem:</p><formula xml:id="formula_13">min θ P max ϕ E x∼p G\N (x) [log D ϕ (x)] + E z∼p Z θ∼p U [log(1 -D ϕ (G θ (z)))] + L repulsion (7)</formula><p>1. for L repulsion = L IL2 repulsion , solving Eq. 7 leads to p Θ U that minimizes</p><formula xml:id="formula_14">D JSD (p X G\N || p X U ) + D KL (p Θ U || p Θ N ) -1</formula><p>2. for L repulsion = L NL2 repulsion , solving Eq. 7 leads to p Θ U that minimizes</p><formula xml:id="formula_15">D JSD (p X G\N || p X U ) -D KL (p Θ U || p Θ N )</formula><p>3. for L repulsion = L EL2 repulsion , solving Eq. 7 leads to p Θ U that minimizes</p><formula xml:id="formula_16">D JSD (p X G\N || p X U ) -D H (p Θ U || p Θ N )</formula><p>where, D KL (• || •) and D H (• || •) denote KL divergence and Hellinger divergence, and G θ (z) ∼ p X U (•) denotes the implicit distribution of generator when z ∼ p Z and θ ∼ p Θ U .</p><p>The proof for the aforementioned result is relatively straightforward; for the sake of completeness, we include the proof in the Appendix. It is evident from the above result that the unlearning phase of the proposed method, assuming a Gaussian parameter distribution, achieves two objectives: (a) minimizing the Jensen-Shannon Divergence between the learned data distribution (p X U ) and the implicit generator distribution after removing the support of negative samples (p X G\N ), and (b) maximizing a suitable divergence measure between the parameter distribution during unlearning (p Θ U ) and the parameter distribution that leads to the generation of negative samples (p Θ N ). While (a) is relatively straightforward, (b) provides valuable insights into the effect of the regularization term, which is particularly interesting. The regularization term ensures that the current parameter distribution moves away from the one responsible for generating undesired features, effectively aligning with the primary goal of unlearning. Furthermore, this behavior has been shown to be crucial for unlearning in Bayesian settings, as demonstrated in <ref type="bibr" target="#b52">Nguyen et al. (2020)</ref>. Essentially, this aligns with the desired outcome of unlearning, ensuring that the model captures only the desired support of the distribution.</p><p>An interesting observation from the above result is that utilizing L NL2 repulsion or L EL2 repulsion results in an objective akin to contrastive divergence, i.e., it entails the difference between two divergences. However, these two divergence metrics operate on distributions in distinct spaces: the first divergence operates in the data space, while the second operates in parameter space. This prompts a natural question: how does the divergence in parameter space relate to the corresponding distribution in data space? We address this question in the following claim.</p><p>Claim 1. For any general f -divergence D f (• | •), and a given latent vector, the following inequality holds:</p><formula xml:id="formula_17">D JSD (p X G\N || p X U ) -D f (p Θ U || p Θ N ) ≤ D JSD (p X G\N || p X U ) -D f (p X U || p X N )<label>(8)</label></formula><p>Above result relies on simple application of data-processing inequality. The proof is provided in Appendix.</p><p>Since, KL and Hellinger divergence are both instances of f -divergence, the above result holds for Statements 2 and 3 of Theorem 1. Hence, we see that the while using L NL2 repulsion or L EL2 repulsion , the corresponding data space objectives act as upper bounds to the parameter space objectives. With these insights, we end the theoretical discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>An unlearning algorithm should ensure that the generator should not generate images containing the undesired (or unlearnt) feature. For our experiments, we consider two types of unlearning settings: (i) Class-level unlearning and (ii) Feature-level unlearning. The primary difference between the two type of unlearning lies in the nature of the associations. In feature-level unlearning, an image can exhibit multiple features simultaneously, whereas in class-level unlearning, an image from one class cannot belong to any other class. In other words, if each feature is treated as a class, feature-level unlearning allows an image to belong to multiple classes, while class-level unlearning restricts an image to a single class. For instance, a person with bangs can be either male or female, but a digit labeled as 'one' cannot simultaneously belong to any other class.</p><p>We use MNIST dataset <ref type="bibr" target="#b38">(LeCun et al., 1998)</ref> and AFHQ dataset <ref type="bibr" target="#b9">(Choi et al., 2020)</ref> for class-level unlearning. MNIST consists of 60, 000 28 × 28 dimensional black and white images of handwritten digits. For our experiments, we take three-digit classes: 1, 4, and 8 for unlearning. AFHQ consists of 15, 000 high-quality animal face images at 512 × 512 resolution with three categories: cat, dog and wildlife. We unlearn each class one at a time in our experiments. Similarly, we use CelebA-HQ dataset <ref type="bibr" target="#b43">(Liu et al., 2015)</ref> for feature-level unlearning. CelebA-HQ contains 30, 000 RGB high-quality celebrity face images of dimension 256 × 256. Here, we unlearn the following subtle features: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental Details</head><p>Training Details: We use one of the state-of-the-art and widely used high-fidelity StyleGAN2 <ref type="bibr" target="#b33">(Karras et al., 2020)</ref> for demonstrating the performance of the proposed method on the tasks mentioned in previous section. The StyleGAN is trained on the entire MNIST, AFHQ and CelebA-HQ datasets to obtain the pre-trained GAN from which we desire to unlearn specific features. The training details of StyleGAN2 are given in Supplementary Section A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Unlearning Details:</head><p>In our experiments, we employ a pre-trained classifier as a proxy for human to obtain user feedback. Specifically, we pre-train the classifier to classify a given image as desired or undesired (depending upon the feature under consideration). We classify 1, 000 generated images from pre-trained GAN as positive and negative samples using the pre-trained classifier. The generated samples containing the undesired features are marked as negative samples and the rest of the images are marked as positive samples. These samples are then used in Stage-1 and Stage-2 of the proposed method for unlearning as described in Section 3. We evaluate our result using all the choices of repulsion loss as mentioned in Eq. 6. For reproducibility, we provide all the hyper-parameters and training details in Supplementary Section A. The original FID of the GAN after training is as follows-MNIST: 5.4, AFHQ: 8.1, CelebA-HQ: 5.3. We mention these in caption of each table wherever necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Baselines and Evaluation Metrics</head><p>Baselines: To the best of our knowledge, ours is one of the first works that addresses the problem of unlearning in high-fidelity generator models such as StyleGAN2. Hence, we evaluate and compare our method with all the candidates for repulsion loss presented in Eq. 6. Further, we also include the results with extrapolation in the parameter space as demonstrated in figure <ref type="figure" target="#fig_0">1 (b</ref>). We include recent unlearning baselines tailored for classification, easily adaptable to generative tasks. Specifically, we incorporate EU-k, CF-k, and ℓ1-sparse <ref type="bibr" target="#b16">(Goel et al., 2022;</ref><ref type="bibr" target="#b28">Jia et al., 2023)</ref> for comparison, with detailed information in the Supplementary section A.4. Additionally, we assess our method against GAN adaptation to positive samples, utilizing recent generative few-shot adaptation methods like EWC, CDC, and RSSA <ref type="bibr" target="#b41">(Li et al., 2020;</ref><ref type="bibr" target="#b56">Ojha et al., 2021;</ref><ref type="bibr" target="#b79">Xiao et al., 2022)</ref> as baselines. Apart from the above baselines, we also mention the results obtained from training a GAN from scratch on only desirable data present in the dataset. This model acts as the gold standard, however, due to unavailability of underlying dataset, this is not practical. Nonetheless, we mention it in our tables for completeness. We evaluate the performance of each method across three independent runs and report the result in the form of mean ± std. dev. × 100, where, (S n ) θ G and (S n ) θ P represent the number of negative samples generated by the original GAN and the GAN after unlearning respectively. We generate 15,000 random samples from both GANs and employ a pre-trained classifier (as detailed in Section 5.2) to identify the negative samples. PUL provides a quantitative measure of the extent of the unlearning algorithm in eliminating the undesired feature from the GAN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Original Samples Extrapolation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Fréchet Inception Distance (FID):</head><p>While PUL quantifies the degree of unlearning, it does not assess the quality of samples generated by the GAN post-unlearning. Hence, we calculate the FID <ref type="bibr" target="#b25">(Heusel et al., 2017)</ref> between the generated samples and the original dataset without the undesired samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Retraining FID (Ret-FID):</head><p>To resemble the retrained GAN, we compute the FID between the outputs of the GAN after unlearning and the GAN trained from scratch on the dataset obtained after eliminating undesired features.</p><p>Please note that the original dataset is unavailable during the unlearning process. Consequently, the use of the original dataset is solely for evaluation purposes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Unlearning Results</head><p>We present our results and observations on MNIST, AFHQ and CelebA-HQ in Table <ref type="table" target="#tab_0">1</ref>, 2, 3 respectively. We observe that the choice of L EL2 repulsion as repulsion loss provides the highest PUL in most of the cases Table 3: PUL (↑), FID (↓), and Ret-FID (↓) after unlearning CelebA-HQ features. FID of pre-trained GAN: 5.3. Method Bangs Hat Bald Eyeglasses PUL FID Ret-FID PUL FID Ret-FID PUL FID Ret-FID PUL FID Ret-FID Retraining 84.47 ± 1.49 7.58 ± 0.06 N/A 98.65 ± 0.03 6.35 ± 0.10 N/A 72.13 ± 0.07 7.18 ± 0.08 N/A 58.57 ± 0.04 6.50 ± 0.77 N/A CF-k 18.60 ± 2.30 9.65 ± 0.15 7.70 ± 0.27 15.22 ± 0.05 9.58 ± 0.09 7.57 ± 0.05 48.17 ± 1.76 9.30 ± 0.12 7.37 ± 0.06 16.41 ± 0.73 9.49 ± 0.15 6.79 ± 0.06 EU-k 20.08 ± 1.35 9.03 ± 0.23 7.38 ± 0.06 17.96 ± 1.54 9.40 ± 0.21 7.16 ± 0.05 52.18 ± 0.53 9.03 ± 0.06 6.92 ± 0.05 16.41 ± 1.33 9.39 ± 0.04 6.85 ± 0.85 ℓ1-Sparse 75.78 ± 1.48 16.20 ± 0.24 13.77 ± 0.46 59.01 ± 1.67 8.61 ± 0.09 5.66 ± 0.09 67.26 ± 0.19 16.27 ± 0.73 14.14 ± 0.59 82.30 ± 1.96 15.95 ± 0.02 12.36 ± 0.32 EWC 76.24 ± 2.14 9.64 ± 0.05 6.69 ± 0.03 74.14 ± 0.78 9.06 ± 0.22 6.44 ± 0.08 55.70 ± 2.57 9.32 ± 0.07 6.77 ± 0.04 46.51 ± 0.57 9.19 ± 0.04 6.56 ± 0.01 CDC 83.76 ± 0.12 34.66 ± 1.94 24.67 ± 0.02 85.23 ± 0.77 23.48 ± 0.12 17.46 ± 0.22 90.10 ± 0.37 26.96 ± 0.02 17.99 ± 0.09 91.65 ± 0.31 36.66 ± 0.02 30.08 ± 0.27 RSSA 32.07 ± 0.58 17.79 ± 0.02 15.99 ± 0.08 22.70 ± 1.47 18.83 ± 0.08 14.87 ± 0.16 31.70 ± 1.89 20.35 ± 0.34 18.63 ± 0.01 26.21 ± 0.17 22.24 ± 0.16 18.09 ± 0.02 Extrapolation 89.54 ± 0.09 11.54 ± 0.07 11.02 ± 0.06 94.35 ± 0.12 12.18 ± 0.04 10.12 ± 0.07 94.44 ± 0.34 23.44 ± 0.02 26.40 ± 0.30 92.80 ± 0.14 23.70 ± 0.07 19.10 ± 0.10 L NL2 repulsion (Ours) 90.41 ± 0.19 11.92 ± 0.46 8.69 ± 0.05 93.99 ± 1.70 9.60 ± 0.25 6.44 ± 0.11 97.13 ± 1.42 14.70 ± 0.55 9.03 ± 0.13 83.76 ± 3.21 12.81 ± 0.88 7.93 ± 0.99 L IL2 repulsion (Ours) 84.05 ± 1.03 13.09 ± 0.10 9.07 ± 0.18 94.00 ± 0.75 11.31 ± 0.06 7.25 ± 0.13 83.51 ± 2.18 12.94 ± 0.89 9.87 ± 0.04 75.23 ± 6.25 13.12 ± 0.78 6.11 ± 0.24 L EL2 repulsion (Ours) 90.45 ± 1.02 11.16 ± 0.08 7.94 ± 0.32 94.40 ± 2.19 9.45 ± 0.96 6.31 ± 0.64 93.97 ± 2.65 11.07 ± 0.86 7.83 ± 0.05 93.63 ± 0.42 9.66 ± 0.58 9.84 ± 0.23</p><p>for both the datasets. Further, it also provides the best FID and Ret-FID as compared to other choices of repulsion loss. L NL2 repulsion is stands out to be the second best in these metrics for most of the cases. Further, we observe that across all datasets, the classification unlearning baselines perform very poorly on all metrics for unlearning in GANs. This tells us that methods proposed for unlearning in classification are not suited for unlearning in generative tasks. And lastly, we find that few-shot adaptation baselines, give relatively poor results when compared to the proposed method. This observation indicates that it is not enough to just adapt the GAN on the positive samples for unlearning, one needs to go further and use additional regularization to unlearn the undesired features.</p><p>For MNIST, we observe in Table <ref type="table" target="#tab_0">1</ref> that the proposed method with L EL2 repulsion as repulsion loss consistently provides a PUL of above 95% while giving the best FID and Ret-FID compared to other methods. We also observe that Extrapolation in parameter space leads to significant PUL albeit the FID and Ret-FID are considerably worse compared to proposed method under different repulsion loss. This shows that the proposed method decently solves the task of unlearning at class-level.</p><p>We make similar observations for high-resolution AFHQ dataset as well. One can see that the proposed method provides highest PUL in all the cases, while maintaining the FID as well as Ret-FID. We observe highest PUL while unlearning the 'Cat' class while lowest PUL is observed in 'Dog' class.</p><p>Lastly, for feature-level unlearning results on CelebA-HQ, it can be seen that the proposed method with L EL2 repulsion as repulsion loss consistently provides a PUL of above 90%, illustrating significant unlearning of undesired features. Further, the FID and Ret-FID using L EL2 repulsion stand out to be the best among all the methods with significant PUL.</p><p>We also observe some drop in FID across all dataset after unlearning. E.g., the FID of the samples generated by the unlearnt GAN (on Hats) using L EL2 repulsion drops by about 4.15 points while it drops by 4.3 and 6.01 points while using L NL2 repulsion and L IL2 repulsion as compared to the pre-trained GAN. On the other hand, Extrapolation in parameter space leads to a drop of 6.88 poinits in FID. This further validates the need of repulsion regularizer to maintain the generation quality. This observation is consistent across all datasets and features. This supports our claim that extrapolation might unlearn the undesired feature, however, it deteriorates the quality of generated samples significantly.</p><p>Another interesting observation from the above results is that the classification unlearning baselines consistently provide lower PUL, albeit with slightly better FID and Ret-FID. This tells us that these baselines while capable of unlearning in classification tasks, fail to nudge the generator appropriately for desired unlearning task. Leading to a suboptimal generator which still generates undesired samples, without compromising on the quality of the generated samples.</p><p>The visual illustration of these methods for AFHQ and CelebA-HQ are shown in figure <ref type="figure" target="#fig_1">2</ref> and figure <ref type="figure" target="#fig_2">3</ref> respectively. Here, we observe that the proposed method effectively unlearns the undesired feature. Moreover, it can be seen that the unlearning through extrapolation leads to the unlearning of correlated features as well. E.g. Bangs are correlated with female attributes. It can be seen that the unlearning of Bangs through extrapolation also leads to the unlearning of female feature which is not desired. However, unlearning through the proposed method unlearns Bangs only, while keeping the other features as it is. Similar observations could be made for AFHQ, where extrapolation leads to some minor artifacts in generates samples, whereas proposed method generates plausible images without any artifacts. Similar visual results for MNIST is provided in Supplementary Section B. We also provide visualization of random samples generated from original GAN and the GAN after unlearning in Supplementary Section F to give a qualitative idea of the generation quality.</p><p>Another aspect of unlearning that we explore in our work is the effect of unlearning on other features. Particularly, unlearning an undesired feature should not disturb the other features. For this we generate samples from pre-trained and post-unlearning GANs. Then, we calculate the occurrence of specific features within the two GANs and report the percentage change in these numbers. These results could be found in Section E of Supplementary. As discussed in Section 3, the approach of first adapting the model to negative samples followed by applying the repulsion loss during the Unlearning phase can also be extended to scenarios where curated datasets of positive and negative samples are available. We demonstrate this in Section D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Comparison with DC-GAN Baselines</head><p>As previously mentioned, our proposed method operates with high-fidelity GANs. Nonetheless, in addition to the tailored baselines, a few previous methods aim to unlearn undesired features in more primitive GANs, such as DC-GANs, on low-resolution images. Notably, the methods proposed in <ref type="bibr" target="#b64">Sun et al. (2023)</ref> and <ref type="bibr" target="#b35">Kong &amp; Chaudhuri (2023)</ref> are highly relevant to our work. However, they primarily operate on DC-GAN. To ensure a fair comparison, we implement our method on DC-GAN and evaluate it against these baselines using the MNIST dataset (with L EL2 repulsion ). Specifically, we compare our approach to the cascaded unlearning algorithm (CUA) from <ref type="bibr" target="#b64">Sun et al. (2023)</ref> and the data redaction method using validity data (DRed) from <ref type="bibr" target="#b35">Kong &amp; Chaudhuri (2023)</ref>. Our findings are summarized in</p><p>Table 4. The results indicate that our method Published in Transactions on Machine Learning Research (02/2025)  outperforms both baselines across all metrics in all scenarios. All methods performed well on PUL, with our method achieving the best PUL, followed by DRed and then CUA in most cases. A similar trend is observed in the FID scores. Although DRed is a close competitor to our proposed method, our approach yields a significantly better Ret-FID than DRed, suggesting that the post-unlearning GAN using our method is closer to the gold standard compared to DRed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Ablation Study</head><p>Lastly, we present the ablation study to observe the effect of repulsion loss. In particular, we see if adapting the pre-trained GAN only on the positive samples leads to desired levels of unlearning. Our observations on CelebA-HQ for Bangs and Hats are presented in Table <ref type="table" target="#tab_5">5</ref>. Here, we use L EL2 repulsion as repulsion loss. It can be seen that only using adversarial loss doesn't lead to significant unlearning of undesired feature. E.g. using repulsion loss provides and increase of about 10.56% and 9.72% in PUL. The FID increases by minor 0.66 point on Bangs while it decreases by 0.21 points on Hats. Hence, we conclude that repulsion loss is indeed crucial for unlearning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We propose a novel unlearning method designed for high-fidelity GANs. Our approach is distinguished via its unique ability to operate in zero-shot scenario, entirely independent of the original data on which GAN is trained. We operate under feedback-based framework in two stages. The initial stage adapts the pre-trained GAN on the negative samples whereas the later stage unlearns the undesired feature by adapting on positive samples along with a repulsion regularizer. A notable advantage of our approach is its capability to conduct the unlearning process without significantly impacting other desirable features. We firmly believe that our work represents a substantial advancement in the field of unlearning within deep generative models. This progress holds particular relevance in addressing critical societal concerns, particularly those related to the generation of biased, racial, or harmful content by these models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitation and Future Work:</head><p>We note that our study does not address aspects like 'toxicity' due to the absence of annotated datasets with explicit characteristics. Despite this limitation, it's crucial to emphasize that our explored features are subtle and interconnected. For example, subtle details like hairstyles (e.g., bangs) are strongly linked to gender, and characteristics like baldness correlate with physical appearance, also associated with gender. Additionally, attributes such as hats and eyeglasses are tied to accessories. Though not the primary focus for unlearning, these features hold potential utility for such purposes.</p><p>In future, we aspire to provide rigorous theoretical guarantees to such methods making them more dependable and safe for deployment. Moreover, the approach proposed in this work is inherently generic and can be applied to any model exhibiting parameter-space semantics. This opens up the possibility of extending such techniques to more powerful generative models, such as Diffusion models and Flow-based models. However, applying this method to iterative models like diffusion models would require a thorough investigation of their parameter-space semantics. Additionally, developing an effective strategy for negative adaptation in these models remains an open research challenge, unlike GANs, where few-shot generative adaptation is relatively well-studied. Nonetheless, this represents a promising avenue for modern generative models, and we leave this exploration for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Broader Impact Statement</head><p>Machine unlearning has emerged as a crucial tool for addressing privacy concerns and mitigating harmful biases in AI systems. Our method advances this field by enabling selective feature removal from pre-trained GANs without requiring access to the original training data. This capability is particularly valuable for correcting deployed models that may generate problematic or biased content, making AI systems more ethical and socially responsible. While our approach currently focuses on GANs, its success demonstrates the potential for developing similar techniques for other generative models, contributing to the broader goal of creating AI systems that can be refined and corrected post-deployment to better serve society's needs.</p><p>EU-k and CF-k <ref type="bibr" target="#b16">(Goel et al., 2022)</ref> propose to train just the last k layers of the model from scratch (in EU-k) or from pre-trained initialization (in CF-k) for unlearning on the positive samples. We employ the same strategy to GANs directly with k = 10 layers. Further, ℓ1-sparse <ref type="bibr" target="#b28">(Jia et al., 2023)</ref> proposes to use sparse weights for fine-tuning to unlearn the undesired features. To this end, they propose to use ℓ-1 regularization while fine-tuning. Hence, for our case, we fine-tune the model on positive samples by adding an ℓ-1 regularization on weights of the network.</p><p>For the few-shot adaptation baselines, we directly employ the provided open-source codebase of CDC<ref type="foot" target="#foot_4">foot_4</ref> and<ref type="foot" target="#foot_5">foot_5</ref> for adaptation on positive samples to obtain results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B MNIST Qualitative Results</head><p>We present visual illustration of images generated after unlearning using various methods in figure <ref type="figure" target="#fig_3">4</ref>. Here, we unlearn class of digits 1, 4, and 8. We observe that all the proposed methods effectively unlearn the undesired classes. Moreover, it can be seen that although extrapolation leads to unlearning, it does so at the expense of the quality of the generated images. In contrast, the quality of the generated images after unlearning using the proposed method leads to unlearning with plausible image quality. We refer the reader the reader to main text for quantitative evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Class 1 Class 4</head><p>Class 8 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Original Samples Extrapolation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Proofs</head><p>Proof of Theorem 1. The said objective function is given by-</p><formula xml:id="formula_18">min θ P max ϕ E x∼p X G\N [log D ϕ (x)] + E z∼p Z θ∼p Θ U [log(1 -D ϕ (G θ (z)))] + L repulsion ≡ min θ P max ϕ E x∼p X G\N [log D ϕ (x)] + E x∼p X U [log(1 -D ϕ (x))] + L repulsion (9)</formula><p>Since ϕ depends only on the first two terms of Eq. 9, the optimal discriminator as obtained in Goodfellow et al.</p><p>(</p><formula xml:id="formula_19">) is given as D ϕ * = p X G\N p X G\N +p X U .<label>2014</label></formula><p>Substituting this in Eq. 9 and using standard results from <ref type="bibr" target="#b21">Goodfellow et al. (2014)</ref> gives -</p><formula xml:id="formula_20">min θ P D JSD (p X G\N ||p X U ) + L repulsion (10) L repulsion = L IL2 repulsion : Since p Θ N (θ) = 1 |2πΣ| d/2 exp 1 2 (θ -θ N ) T Σ -1 (θ -θ N ) and p Θ U (θ) = 1 |2πΣ| d/2 exp 1 2 (θ -θ P ) T Σ -1 (θ -θ P ) are both Gaussian distributions, then D KL (p Θ U ||p Θ N ) = ∥θ P -θ N ∥ 2 =⇒ [D KL (p Θ U ||p Θ N )] -1 = 1 ∥θ P -θ N ∥ 2 = L IL2 repulsion .</formula><p>Substituting in the above we get -</p><formula xml:id="formula_21">min θ P D JSD (p X G\N ||p X U ) + [D KL (p Θ U ||p Θ N )] -1 (11) L repulsion = L NL2 repulsion : Similar to above argument, D KL (p Θ U ||p Θ N ) = ∥θ P -θ N ∥ 2 =⇒ -D KL (p Θ U ||p Θ N ) = -∥θ P -θ N ∥ 2 = L NL2</formula><p>repulsion . Substituting in the above we get -</p><formula xml:id="formula_22">min θ P D JSD (p X G\N ||p X U ) -D KL (p Θ U ||p Θ N )<label>(12)</label></formula><p>L repulsion = L EL2 repulsion : Again, since p Θ N and p Θ U follow Gaussian distribution, the Hellinger divergence between two Gaussian distribution is a shifted negative Manhabolis distance between the means of the two distributions, i.e., D</p><formula xml:id="formula_23">H (p Θ U ||p Θ N ) = 1 -exp (-∥θ P -θ N ∥ 2 ) =⇒ 1 -D H (p Θ U ||p Θ N ) = exp (-∥θ P -θ N ∥ 2 ) = L EL2</formula><p>repulsion . Substituting in above we get -</p><formula xml:id="formula_24">min θ P D JSD (p X G\N ||p X U ) -D H (p Θ U ||p Θ N ) + 1 (13) ≡ min θ P D JSD (p X G\N ||p X U ) -D H (p Θ U ||p Θ N )<label>(14)</label></formula><p>This completes the proof of all the three statements.</p><p>Proof of Claim 1. For a given latent vector, θ → G θ (z) is a map from parameter space to generated sample in the data space. Hence, we can use data-processing inequality to obtain -</p><formula xml:id="formula_25">D f (p X U ||p X N ) ≤ D f (p Θ U ||p Θ N ) (15) =⇒ D JSD (p X G\N ||p X U ) -D f (p Θ U ||p Θ N ) ≤ D JSD (p X G\N ||p X U ) -D f (p X U ||p X N )<label>(16)</label></formula><p>This completes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Results with Curated Datasets</head><p>As explained in the main paper, our method requires users to identify or annotate negative samples under feedback-based framework. This annotation is used to adapt the GAN to negative samples during the Negative Adaptation phase and subsequently retrain it on positive samples during the Unlearning phase.</p><p>While human feedback is one approach to obtain these samples, curated datasets of positive and negative samples can also serve this purpose.</p><p>Curating datasets, however, can be challenging, particularly when the feature, concept, or class to be unlearned is subtle or complex and not readily available in standard datasets. In such cases, users may need to create a custom dataset. By contrast, our human-feedback approach involves annotating samples generated by the GAN, reducing the need for external dataset creation. Nevertheless, if a curated dataset of positive and negative samples is available, our method can be seamlessly adapted to utilize it.</p><p>To demonstrate this, we conduct experiments on all three datasets (MNIST, AFHQ, and CelebA-HQ) using curated dataset samples in both the Negative Adaptation and Unlearning phases. Specifically, for the Negative Adaptation phase, we use samples from the original dataset that were pre-annotated with the undesired feature or label. For instance, in the CelebA-HQ dataset, we selected all samples with a positive label for the undesired feature (e.g., Bangs). The GAN is then adapted to these samples using the training objective described in Section 3.2 (Eq. 1 of the main paper) to obtain the parameters θ N . In the Unlearning phase, the GAN was retrained on the remaining dataset samples using the objective described in Section 3.3 (Eq. 4).</p><p>We performed these experiments on MNIST (unlearning 'Class 8'), AFHQ (unlearning 'Cat'), and CelebA-HQ (unlearning 'Bangs'). The results of these experiments are summarized in Table <ref type="table" target="#tab_6">6</ref>, comparing the performance of using curated dataset samples against GAN-generated samples. As shown in Table <ref type="table" target="#tab_6">6</ref>, using curated dataset samples during the Negative Adaptation phase achieves performance comparable to that of GAN-generated samples. This demonstrates the flexibility of our method, allowing users to choose the most convenient approach depending on the availability of datasets. These results will be included in the supplementary material to provide further clarity on this point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Effect on other features after Unlearning</head><p>As previously discussed, the unlearning procedure aims to exclusively erase undesired features without impacting other features. Consequently, it becomes imperative to assess whether the unlearning process exerts any influence on other features. To address this concern, we introduce plots illustrating the percentage change in the presence of other features.</p><p>Specifically, we undertake the generation of 15, 000 random samples from both the pre-trained GAN and the GAN after the unlearning procedure. Subsequently, employing the pre-trained classifiers (for comprehensive details, please refer to the Supplementary), we calculate the occurrence of specific features within the two GANs. We report the percentage change in these numbers to demonstrate how has the unlearning process affected this feature. Hence, a lower percentage change is better as it means that the other features are not affected after unlearning. This experiment is repeated across multiple features, and our findings after unlearning Bangs in CelebA-HQ are depicted in figure <ref type="figure">5</ref>. We observe that for all the features, unlearning via extrapolation leads to significant changes in other features. Whereas, unlearning via the proposed method leads to minor changes in the features. For instance, since Bangs are highly correlated with gender, we observe that unlearning Bangs via extrapolation leads to an increase in Males. However, unlearning via the proposed method leads to minor changes in the number of samples with Male features. This shows that the proposed method is effective in erasing the undesired feature while preserving other features. It can be observed that in majority of the cases, extrapolation leads to significant change in the features, indicating that unlearning via extrapolation leads to significant change in other features as well. This also indicates that extrapolation leads to unlearning of several correlated features. On the other hand, we observe that unlearning using the proposed method with L EL2 repulsion gives the least change in most of the cases. This illustrates the efficacy of the proposed method in preserving features other than the unlearnt feature.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: (a) Block diagram of the proposed method: Stage-1: Negative Adaptation of the GAN to negative samples received from user feedback and Stage-2: Unlearning of the original GAN using the positive samples with a repulsion loss. (b) Illustrating linear interpolation and extrapolation in parameter space for unlearning undesired features. We observe that in the extrapolation region, undesired features are suppressed, but the quality of generated samples deteriorates. (c) An example of results obtained using our method on Mixture of Gaussian (MoG) dataset, where we unlearn two centers provided in negative samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Results of Unlearning different classes on AFHQ dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Results of Unlearning different features on CelebA dataset.</figDesc><graphic coords="11,101.74,296.08,77.99,51.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Results of Unlearning undesired feature (class) via different methods. The undesired class contains digits 1(top row), 4(second row), 8 (bottom row).</figDesc><graphic coords="21,284.36,333.38,67.06,134.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>PUL (↑), FID (↓), and Ret-FID (↓) after unlearning MNIST classes. FID of pre-trained GAN: 5.4.</figDesc><table><row><cell>Method</cell><cell></cell><cell>Class 1</cell><cell></cell><cell></cell><cell>Class 4</cell><cell></cell><cell></cell><cell>Class 8</cell><cell></cell></row><row><cell></cell><cell>PUL</cell><cell>FID</cell><cell>Ret-FID</cell><cell>PUL</cell><cell>FID</cell><cell>Ret-FID</cell><cell>PUL</cell><cell>FID</cell><cell>Ret-FID</cell></row><row><cell>Retraining</cell><cell>98.80 ± 0.09</cell><cell>4.94 ± 0.04</cell><cell>N/A</cell><cell>98.58 ± 0.28</cell><cell>5.24 ± 0.09</cell><cell>N/A</cell><cell>99.72 ± 0.01</cell><cell>4.80 ± 0.11</cell><cell>N/A</cell></row><row><cell>CF-k</cell><cell>18.60 ± 2.30</cell><cell cols="2">92.88 ± 0.51 89.05 ± 0.93</cell><cell>7.71 ± 0.18</cell><cell cols="2">33.61 ± 0.93 30.76 ± 0.86</cell><cell>16.03 ± 0.09</cell><cell cols="2">36.67 ± 1.98 33.14 ± 0.74</cell></row><row><cell>EU-k</cell><cell>31.77 ± 1.56</cell><cell cols="2">15.34 ± 0.01 14.05 ± 0.17</cell><cell>17.59 ± 3.31</cell><cell>8.80 ± 0.08</cell><cell>7.84 ± 0.24</cell><cell>21.66 ± 0.70</cell><cell>8.92 ± 0.77</cell><cell>7.10 ± 0.10</cell></row><row><cell>ℓ1-Sparse</cell><cell>91.84 ± 0.55</cell><cell cols="2">22.17 ± 0.14 17.87 ± 0.42</cell><cell>94.16 ± 0.06</cell><cell cols="2">23.24 ± 0.59 17.25 ± 0.22</cell><cell>95.42 ± 0.01</cell><cell cols="2">22.23 ± 0.05 16.83 ± 0.13</cell></row><row><cell>EWC</cell><cell>90.93 ± 0.46</cell><cell>7.18 ± 0.08</cell><cell>5.10 ± 0.01</cell><cell>82.78 ± 1.02</cell><cell>9.34 ± 0.08</cell><cell>5.91 ± 0.04</cell><cell>92.70 ± 0.81</cell><cell>9.35 ± 0.04</cell><cell>6.03 ± 0.04</cell></row><row><cell>CDC</cell><cell>90.70 ± 0.16</cell><cell cols="2">20.85 ± 0.49 17.51 ± 1.86</cell><cell>42.39 ± 0.66</cell><cell cols="2">17.82 ± 1.99 12.39 ± 2.32</cell><cell>18.86 ± 0.92</cell><cell cols="2">11.18 ± 2.28 12.38 ± 3.73</cell></row><row><cell>RSSA</cell><cell>38.36 ± 0.09</cell><cell cols="2">12.70 ± 0.17 13.54 ± 0.40</cell><cell>71.96 ± 0.21</cell><cell cols="2">25.41 ± 0.06 19.08 ± 0.59</cell><cell>79.54 ± 0.32</cell><cell cols="2">34.59 ± 0.26 25.33 ± 0.39</cell></row><row><cell>Extrapolation</cell><cell>95.10 ± 0.69</cell><cell cols="2">41.39 ± 1.76 42.98 ± 0.68</cell><cell>94.50 ± 0.05</cell><cell cols="2">17.90 ± 0.35 27.81 ± 0.37</cell><cell>90.90 ± 0.12</cell><cell cols="2">45.79 ± 0.29 44.30 ± 0.40</cell></row><row><cell>L NL2 repulsion (Ours)</cell><cell>97.85 ± 2.25</cell><cell>9.69 ± 0.07</cell><cell>6.70 ± 0.25</cell><cell>93.03 ± 0.70</cell><cell cols="2">10.50 ± 0.34 6.26 ± 0.12</cell><cell>97.92 ± 0.67</cell><cell>9.95 ± 0.17</cell><cell>6.70 ± 0.18</cell></row><row><cell>L IL2 repulsion (Ours)</cell><cell>92.97 ± 0.48</cell><cell cols="2">13.06 ± 0.46 16.55 ± 0.54</cell><cell>90.39 ± 1.36</cell><cell cols="5">15.54 ± 0.05 8.64 ± 0.90 98.28 ± 0.55 9.72 ± 0.31 11.64 ± 0.46</cell></row><row><cell cols="3">L EL2 repulsion (Ours) 99.32 ± 0.43 9.65 ± 0.21</cell><cell cols="4">6.29 ± 0.18 96.23 ± 0.54 10.24 ± 0.19 5.80 ± 0.04</cell><cell>95.22 ± 0.55</cell><cell>8.89 ± 0.52</cell><cell>5.68 ± 0.10</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>PUL (↑), FID (↓), and Ret-FID (↓) after unlearning AFHQ classes. FID of pre-trained GAN: 8.1.</figDesc><table><row><cell>Method</cell><cell></cell><cell>Cat</cell><cell></cell><cell></cell><cell>Dog</cell><cell></cell><cell></cell><cell>Wild</cell><cell></cell></row><row><cell></cell><cell>PUL</cell><cell>FID</cell><cell>Ret-FID</cell><cell>PUL</cell><cell>FID</cell><cell>Ret-FID</cell><cell>PUL</cell><cell>FID</cell><cell>Ret-FID</cell></row><row><cell>Retraining</cell><cell>93.37 ± 0.23</cell><cell>12.45 ± 0.16</cell><cell>N/A</cell><cell>85.96 ± 0.21</cell><cell>5.71 ± 0.43</cell><cell>N/A</cell><cell>88.60 ± 0.22</cell><cell>15.24 ± 0.24</cell><cell>N/A</cell></row><row><cell>CF-k</cell><cell>15.74 ± 0.41</cell><cell cols="2">42.91 ± 0.33 37.34 ± 0.29</cell><cell>13.12 ± 0.12</cell><cell cols="2">64.50 ± 0.58 65.72 ± 2.31</cell><cell>16.40 ± 0.55</cell><cell cols="2">35.56 ± 0.11 34.47 ± 0.94</cell></row><row><cell>EU-k</cell><cell>16.08 ± 0.28</cell><cell cols="2">43.21 ± 0.25 37.62 ± 0.42</cell><cell>10.30 ± 0.13</cell><cell cols="2">32.69 ± 0.23 31.40 ± 0.36</cell><cell>16.63 ± 0.84</cell><cell cols="2">35.80 ± 0.39 32.55 ± 0.14</cell></row><row><cell>ℓ1-Sparse</cell><cell>86.25 ± 1.35</cell><cell cols="2">25.73 ± 0.05 14.96 ± 0.11</cell><cell>68.21 ± 0.15</cell><cell cols="2">19.54 ± 0.53 15.10 ± 0.85</cell><cell>84.05 ± 0.45</cell><cell cols="2">37.63 ± 0.52 21.80 ± 0.16</cell></row><row><cell>EWC</cell><cell>90.58 ± 1.54</cell><cell cols="2">15.30 ± 0.98 8.29 ± 0.04</cell><cell>68.79 ± 0.08</cell><cell cols="2">10.38 ± 1.08 8.50 ± 0.35</cell><cell>73.44 ± 0.16</cell><cell cols="2">16.32 ± 0.08 14.38 ± 0.01</cell></row><row><cell>CDC</cell><cell>28.57 ± 0.43</cell><cell cols="2">59.76 ± 0.40 49.93 ± 1.02</cell><cell>9.60 ± 0.24</cell><cell cols="2">47.85 ± 0.53 46.79 ± 0.67</cell><cell>6.51 ± 0.13</cell><cell cols="2">42.17 ± 0.19 36.95 ± 0.28</cell></row><row><cell>RSSA</cell><cell>66.86 ± 0.22</cell><cell cols="2">59.88 ± 0.35 46.80 ± 0.62</cell><cell>54.54 ± 0.36</cell><cell cols="2">55.06 ± 0.20 53.24 ± 0.34</cell><cell>43.99 ± 0.72</cell><cell cols="2">60.95 ± 0.45 44.20 ± 0.32</cell></row><row><cell>Extrapolation</cell><cell>90.64 ± 0.33</cell><cell cols="2">45.89 ± 2.60 38.87 ± 1.93</cell><cell>82.08 ± 1.02</cell><cell cols="2">25.54 ± 1.19 24.98 ± 1.35</cell><cell>84.45 ± 0.11</cell><cell cols="2">45.98 ± 2.66 41.86 ± 1.99</cell></row><row><cell>L NL2 repulsion (Ours)</cell><cell>94.28 ± 0.17</cell><cell cols="2">16.29 ± 0.06 8.93 ± 1.23</cell><cell>75.33 ± 0.35</cell><cell>8.62 ± 0.08</cell><cell>5.96 ± 0.45</cell><cell>82.82 ± 0.77</cell><cell cols="2">17.69 ± 0.18 14.89 ± 0.13</cell></row><row><cell>L IL2 repulsion (Ours)</cell><cell>90.93 ± 0.51</cell><cell cols="2">20.69 ± 0.04 9.86 ± 0.08</cell><cell>76.53 ± 0.51</cell><cell>9.37 ± 1.06</cell><cell>6.84 ± 0.10</cell><cell>80.96 ± 0.18</cell><cell cols="2">22.70 ± 0.11 13.76 ± 0.12</cell></row><row><cell>L EL2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>repulsion (Ours) 95.76 ± 0.25 16.50 ± 0.12 8.17 ± 0.14 79.21 ± 0.18 9.31 ± 0.14 7.13 ± 0.12 89.09 ± 0.25 19.67 ± 0.69 14.90 ± 0.65</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Comparison of the proposed method against DC-GAN baselines</figDesc><table><row><cell cols="2">Method Metrics</cell><cell>Class 1</cell><cell>Class 4</cell><cell>Class 8</cell></row><row><cell></cell><cell>PUL</cell><cell>96.12 ± 1.21</cell><cell>95.49 ± 0.37</cell><cell>97.34 ± 1.21</cell></row><row><cell>CUA</cell><cell>FID</cell><cell>12.73 ± 0.48</cell><cell>11.61 ± 1.81</cell><cell>13.09 ± 1.03</cell></row><row><cell></cell><cell>Ret-FID</cell><cell>11.02 ± 1.52</cell><cell>11.57 ± 0.79</cell><cell>10.09 ± 1.21</cell></row><row><cell></cell><cell>PUL</cell><cell>98.13 ± 0.12</cell><cell>97.70 ± 0.26</cell><cell>96.54 ± 0.23</cell></row><row><cell>DRed</cell><cell>FID</cell><cell>11.72 ± 1.29</cell><cell>12.82 ± 1.11</cell><cell>10.32 ± 0.82</cell></row><row><cell></cell><cell>Ret-FID</cell><cell>8.72 ± 0.72</cell><cell>8.93 ± 0.86</cell><cell>10.12 ± 1.41</cell></row><row><cell></cell><cell>PUL</cell><cell cols="3">98.76 ± 0.56 99.18 ± 0.28 98.72 ± 0.42</cell></row><row><cell>Ours</cell><cell>FID</cell><cell>10.37 ± 0.94</cell><cell cols="2">9.72 ± 1.33 10.27 ± 0.82</cell></row><row><cell></cell><cell>Ret-FID</cell><cell>6.32 ± 0.43</cell><cell>7.23 ± 1.28</cell><cell>7.66 ± 1.30</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Effect on PUL (↑), FID (↓), and Ret-FID (↓) with and without repulsion loss.</figDesc><table><row><cell cols="2">Features Metrics</cell><cell>L ′ adv</cell><cell>L</cell><cell>′ adv + L EL2 repulsion</cell></row><row><cell></cell><cell>PUL</cell><cell>79.89 ± 0.49</cell><cell></cell><cell>90.45 ± 1.01</cell></row><row><cell>Bangs</cell><cell>FID</cell><cell>10.06 ± 0.24</cell><cell></cell><cell>11.16 ± 0.08</cell></row><row><cell></cell><cell>Ret-FID</cell><cell>8.69 ± 0.04</cell><cell></cell><cell>7.94 ± 0.32</cell></row><row><cell></cell><cell>PUL</cell><cell>84.68 ± 3.89</cell><cell></cell><cell>94.40 ± 2.19</cell></row><row><cell>Hat</cell><cell>FID</cell><cell>9.66 ± 0.16</cell><cell></cell><cell>9.45 ± 0.96</cell></row><row><cell></cell><cell>Ret-FID</cell><cell>6.45 ± 0.08</cell><cell></cell><cell>6.04 ± 0.02</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Comparison of results using curated dataset samples versus GAN-generated samples for negative adaptation. PUL (↑), FID (↓), and Ret-FID (↓).± 1.20 7.79 ± 0.86 10.7 ± 0.52 94.26 ± 1.08 11.88 ± 0.81 6.13 ± 1.66 90.40 ± 0.91 10.04 ± 0.49 6.05 ± 1.25 w/ GAN samples (using L EL2 repulsion ) 95.22 ± 0.34 8.80 ± 0.52 5.68 ± 0.10 95.76 ± 0.25 16.50 ± 0.12 8.17 ± 0.14 90.45 ± 1.02 11.16 ± 0.08 7.94 ± 0.32</figDesc><table><row><cell>Method</cell><cell></cell><cell cols="2">MNIST (Class 8)</cell><cell></cell><cell>AFHQ (Cat)</cell><cell></cell><cell cols="3">CelebA-HQ (Bangs)</cell></row><row><cell></cell><cell>PUL</cell><cell>FID</cell><cell>Ret-FID</cell><cell>PUL</cell><cell>FID</cell><cell>Ret-FID</cell><cell>PUL</cell><cell>FID</cell><cell>Ret-FID</cell></row><row><cell>w/ dataset samples</cell><cell>97.30</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>For convenience, we use superscript X and Θ to denote a distribution in data space and parameter space respectively. We use the data space distribution from previous section as it is with a superscript X for this distinction.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://github.com/rosinality/stylegan2-pytorch</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://github.com/csinva/gan-vae-pretrained-pytorch/tree/master/mnist_classifier</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>https://github.com/rgkannan676/Recognition-and-Classification-of-Facial-Attributes/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>https://github.com/utkarshojha/few-shot-gan-adaptation</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>https://github.com/StevenShaw1999/RSSA</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was supported (in part for setting up the GPU compute) by the <rs type="funder">Indian Institute of Science</rs> through a start-up grant. Piyush is supported by <rs type="grantName">Government of India via Prime Minister's Research Fellowship</rs>. Atri contributed to this work as part of Uplink: <rs type="programName">IKDD Research Internship Program</rs>. Subhodip is supported by <rs type="funder">MoE Fellowship</rs>. Prathosh is supported by <rs type="funder">Infosys Foundation Young investigator award</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_KfVJsX9">
					<orgName type="grant-name">Government of India via Prime Minister&apos;s Research Fellowship</orgName>
					<orgName type="program" subtype="full">IKDD Research Internship Program</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Training Details</head><p>Here, we provide the details pertaining to the proposed method. Specifically, we provide the details of the pre-trained GANs and pre-trained Classifiers used in the proposed method. We also provide details pertaining to the training strategy used during Unlearning. All the experiments are performed on RTX-A6000 GPUs with 48GB memory. Our code and implementation is available at: <ref type="url" target="https://github.com/atriguha/Adapt_Unlearn">https://github.com/ atriguha/Adapt_Unlearn</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Details of Pre-trained GAN</head><p>As mentioned in the main text, we use the famous StyleGAN2 architecture to obtain the pre-trained GAN.</p><p>We use the open-source pytorch repository 2 for implementation. We resize the MNIST images to 32 × 32 and CelebA-HQ images to 256×256 to fit in the StyleGAN2 architecture. The latent space dimension for MNIST and CelebA-HQ is consequently set to 128 × 1 and 512 × 1. We train the GAN using the non-saturating adversarial loss along with path-regularization for training. We use default optimizers and hyperparameters as provided in the code for training. We train the GAN for 2 × 10 5 and 3.6 × 10 5 epochs for MNIST and CelebA-HQ respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Details of Pre-trained Classifiers</head><p>We use pre-trained classifiers to simulate the process of obtaining the feedback. More specifically, the feedbacks (positive and negative samples) are obtained by passing the generated samples (from the pretrained GAN) through these pre-trained classifiers. The classifier classifies the generated samples into positive and negative samples. Furthermore, the classifiers are also employed for obtaining the evaluation metrics as discussed in Section-4.3 of the main text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MNIST:</head><p>We use simple LeNet model <ref type="bibr" target="#b38">(LeCun et al., 1998)</ref> for classification among different digits of MNIST dataset 3 . The model is trained with a batch-size of 256 using Adam optimizer with a learning rate of 2 × 10 -3 , β 1 = 0.9 and β 2 = 0.999. The model is trained for a resolution of 32 × 32 same as the pre-trained GAN for 12 epochs. After training the classifier has an accuracy of 99.07% on the test split of MNIST dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CelebA-HQ:</head><p>We use ResNext50 model <ref type="bibr" target="#b80">(Xie et al., 2017)</ref> for classification among different facial attributes contained in CelebA 4 . Note that we train the classifier on normal CelebA as the ground truth values are available for it. The classifier is trained with a batch-size of 64 using Adamax optimizer with a learning rate of 2 × 10 -3 , β 1 = 0.9 and β 2 = 0.999. The model is trained for a resolution of 256 × 256 for 10 epochs. We also employ image augmentation techniques such as horizontal flip, image resize, and cropping to improve the performance of the classifier. The trained model exhibits a test accuracy of 91.93%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Unlearning Hyper-parameters</head><p>Here we mention the hyper-parameters pertaining to the proposed negative adaptation and unlearning stages. As mentioned, we use an EWC regularizer during adaptation to avoid overfitting. The value of λ (Eq.3) is set to 5 × 10 8 for all the experiments. Further, γ (Eq.5) is chosen between 0.1, 1 and 10 when L IL2 repulsion and L NL2 repulsion are chosen as repulsion loss. It is varied between 10 and 500 when L EL2 repulsion is chosen as repulsion loss. Further, the value of α for L EL2 repulsion (Eq.7) is varied between 0.1 and 0.001. These values are chosen and adjusted to ensure that both the loss components L ′ adv and L repulsion are minimized properly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Details of Baselines</head><p>Here, we present the details pertaining to the baselines presented in  A lower percentage change denotes that the method has successfully preserved that feature after unlearning. Here, we clip the bar to 100% if the percentage change in that feature is more than 100% to make the plots legible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Visualization of Generated samples</head><p>Here, we provide visualization of random samples generated from the original GAN and the GAN after unlearning to give an intuitive/qualitative idea of generation quality. We provide the results by using L EL2 repulsion as it gives the best performance in most of the cases. These results are presented for all the datasets in figure <ref type="figure">6</ref>, 7, 8. While the results in Section 5.4 provide quantitative idea of generation quality, these visualizations provide qualitative idea of the same.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Original GAN Cat Dog Wild</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Original GAN Bangs Hats</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bald head Eyeglass</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Review of deep learning methods for remote sensing satellite images classification: experimental survey and comparative analysis</title>
		<author>
			<persName><forename type="first">Adekanmi</forename><surname>Adeyinka Adegun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serestina</forename><surname>Viriri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jules-Raymond</forename><surname>Tapamo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Big Data</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">93</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Wasserstein generative adversarial networks</title>
		<author>
			<persName><forename type="first">Tmartin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICML</title>
		<meeting>of ICML</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Comprehensive survey of deep learning in remote sensing: theories, tools, and challenges for the community</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">E</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><forename type="middle">T</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chee</forename><surname>Seng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of applied remote sensing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="42609" to="042609" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Bagging predictors</title>
		<author>
			<persName><forename type="first">Leo</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="123" to="140" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Machine unlearning for random forests</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Brophy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Lowd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICML</title>
		<meeting>of ICML</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Towards making systems forget with machine unlearning</title>
		<author>
			<persName><forename type="first">Yinzhi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junfeng</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Symposium on Security and Privacy</title>
		<meeting>of IEEE Symposium on Security and Privacy</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Incremental and decremental support vector machine learning</title>
		<author>
			<persName><forename type="first">Gert</forename><surname>Cauwenberghs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomaso</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NIPS</title>
		<meeting>of NIPS</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A survey on deep learning applied to medical images: from simple artificial neural networks to generative models</title>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Celard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>El Iglesias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rubén</forename><surname>Sorribes-Fdez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seara</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vieira</surname></persName>
		</author>
		<author>
			<persName><surname>Borrajo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2291" to="2323" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Navigating the gan parameter space for semantic image editing</title>
		<author>
			<persName><forename type="first">Anton</forename><surname>Cherepkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrey</forename><surname>Voynov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artem</forename><surname>Babenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3671" to="3680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Stargan v2: Diverse image synthesis for multiple domains</title>
		<author>
			<persName><forename type="first">Yunjey</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youngjung</forename><surname>Uh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaejun</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jung-Woo</forename><surname>Ha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Recent advances and applications of deep learning methods in materials science</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Kamal Choudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chi</forename><surname>Decost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anubhav</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesca</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Tavazza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheol</forename><forename type="middle">Woo</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alok</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankit</forename><surname>Choudhary</surname></persName>
		</author>
		<author>
			<persName><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><surname>Billinge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Materials</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">59</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Forget unlearning: Towards true data-deletion in machine learning</title>
		<author>
			<persName><forename type="first">Rishav</forename><surname>Chourasia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICML</title>
		<meeting>of ICML</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning from human preferences</title>
		<author>
			<persName><forename type="first">Jan</forename><surname>Paul F Christiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Leike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miljan</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shane</forename><surname>Martic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Legg</surname></persName>
		</author>
		<author>
			<persName><surname>Amodei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Zero-shot machine unlearning</title>
		<author>
			<persName><surname>Vikram S Chundawat1</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Murari</forename><surname>Ayush K Tarun1</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohan</forename><surname>Mandal</surname></persName>
		</author>
		<author>
			<persName><surname>Kankanhalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Repulsive deep ensembles are bayesian</title>
		<author>
			<persName><forename type="first">D'</forename><surname>Francesco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Angelo</surname></persName>
		</author>
		<author>
			<persName><surname>Fortuin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="3451" to="3465" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Making ai forget you: Data deletion in machine learning</title>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Ginart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melody</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Valiant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">Y</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NIPS</title>
		<meeting>of NIPS</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Towards adversarial evaluations for inexact machine unlearning</title>
		<author>
			<persName><forename type="first">Shashwat</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ameya</forename><surname>Prabhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amartya</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ser-Nam</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ponnurangam</forename><surname>Kumaraguru</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Forgetting outside the box: Scrubbing deep networks of information accessible from input-output observations</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Golatkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Achille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ECCV</title>
		<meeting>of ECCV</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Eternal sunshine of the spotless net: Selective forgetting in deep networks</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Golatkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Achille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CVPR</title>
		<meeting>of CVPR</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Mixedprivacy forgetting in deep networks</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Golatkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Achille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avinash</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marzia</forename><surname>Polito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CVPR</title>
		<meeting>of CVPR</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">An introduction to the california consumer privacy act (ccpa)</title>
		<author>
			<persName><forename type="first">E</forename><surname>Goldman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
		<respStmt>
			<orgName>Santa Clara Univ. Legal Studies Research Paper</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NeuRIPS</title>
		<meeting>of NeuRIPS</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Amnesiac machine learning</title>
		<author>
			<persName><forename type="first">Laura</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vineel</forename><surname>Nagisetty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Ganesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of AAAI</title>
		<meeting>of AAAI</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Certified data removal from machine learning models</title>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Awni</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICML</title>
		<meeting>of ICML</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Neural network ensembles</title>
		<author>
			<persName><forename type="first">Lars</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Salamon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="993" to="1001" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances in neural information processing systems</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Heusel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hubert</forename><surname>Ramsauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Nessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ajay</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NeuRIPS</title>
		<meeting>of NeuRIPS</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Snapshot ensembles: Train 1, get m for free</title>
		<author>
			<persName><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoff</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">E</forename><surname>Hopcroft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Model sparsification can simplify machine unlearning</title>
		<author>
			<persName><forename type="first">Jinghan</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiancheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parikshit</forename><surname>Ram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuguang</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaowen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranay</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sijia</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A survey: Deep learning for hyperspectral image classification with few labeled samples</title>
		<author>
			<persName><forename type="first">Sen</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuguo</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhijie</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nanying</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiqi</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">448</biblScope>
			<biblScope unit="page" from="179" to="204" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multiple incremental decremental learning of support vector machines</title>
		<author>
			<persName><forename type="first">Masayuki</forename><surname>Karasuyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ichiro</forename><surname>Takeuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NIPS</title>
		<meeting>of NIPS</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A style-based generator architecture for generative adversarial networks</title>
		<author>
			<persName><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CVPR</title>
		<meeting>of CVPR</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Progressive growing of gans for improved quality, stability, and variation</title>
		<author>
			<persName><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICLR</title>
		<meeting>of ICLR</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Analyzing and improving the image quality of stylegan</title>
		<author>
			<persName><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miika</forename><surname>Aittala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janne</forename><surname>Hellsten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CVPR</title>
		<meeting>of CVPR</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Alias-free generative adversarial networks</title>
		<author>
			<persName><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miika</forename><surname>Aittala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Härkönen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janne</forename><surname>Hellsten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="852" to="863" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Data redaction from pre-trained gans</title>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kamalika</forename><surname>Chaudhuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="638" to="677" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Simple and scalable predictive uncertainty estimation using deep ensembles</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Balaji Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName><surname>Blundell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Illustrating reinforcement learning from human feedback (rlhf)</title>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis</forename><surname>Castricato</surname></persName>
		</author>
		<ptr target="https://huggingface.co/blog/rlhf" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Leandro von Werra, and Alex Havrilla Hugging Face Blog</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Contrastive learning for cross-domain correspondence in few-shot image generation</title>
		<author>
			<persName><forename type="first">Hyuk-Gi</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gi-Cheon</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang-Hoon</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han-Wool</forename><surname>Sul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Byoung-Tak</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Workshop on Controllable Generative Modeling in Language and Vision (CtrlGen) at NeurIPS 2021</title>
		<meeting>Workshop on Controllable Generative Modeling in Language and Vision (CtrlGen) at NeurIPS 2021</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A statistical approach to learning and generalization in layered neural networks</title>
		<author>
			<persName><forename type="first">Esther</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naftali</forename><surname>Tishby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><forename type="middle">A</forename><surname>Solla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1568" to="1574" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Few-shot Image Generation with Elastic Weight Consolidation</title>
		<author>
			<persName><forename type="first">Yijun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingwan (cynthia)</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eli</forename><surname>Shechtman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NeurIPS</title>
		<meeting>of NeurIPS</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A survey on applications of deep learning in microscopy image analysis</title>
		<author>
			<persName><forename type="first">Zhichao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luhong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jincheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiuyu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Ablameyko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaozheng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingke</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in biology and medicine</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page">104523</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Deep learning face attributes in the wild</title>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learn to forget: Machine unlearning via neuron masking</title>
		<author>
			<persName><forename type="first">Zhuo</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ximeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kui</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Transactions on Dependable and Secure Computing</title>
		<meeting>of IEEE Transactions on Dependable and Secure Computing</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory</title>
		<author>
			<persName><forename type="first">Bruce</forename><forename type="middle">L</forename><surname>James L Mcclelland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Randall C O'</forename><surname>Mcnaughton</surname></persName>
		</author>
		<author>
			<persName><surname>Reilly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="page">102</biblScope>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Catastrophic interference in connectionist networks: The sequential learning problem</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neal</forename><forename type="middle">J</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychology of learning and motivation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="109" to="165" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Freeze the Discriminator: a Simple Baseline for Fine-Tuning GANs</title>
		<author>
			<persName><forename type="first">Sangwoo</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minsu</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinwoo</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR AI for Content Creation Workshop</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Few-shot cross-domain image generation via inference-time latent-code learning</title>
		<author>
			<persName><forename type="first">Arnab</forename><surname>Kumar Mondal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piyush</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parag</forename><surname>Singla</surname></persName>
		</author>
		<author>
			<persName><surname>Prathosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Feature unlearning for pre-trained gans and vaes</title>
		<author>
			<persName><forename type="first">Saemi</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seunghyuk</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongwoo</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Descent-to-delete: Gradient-based methods for machine unlearning</title>
		<author>
			<persName><forename type="first">Seth</forename><surname>Neel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saeed</forename><surname>Sharifi-Malvajerdi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ALT</title>
		<meeting>of ALT</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Published in Transactions on Machine Learning Research</title>
		<imprint>
			<date type="published" when="2025-02">02/2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Variational bayesian unlearning</title>
		<author>
			<persName><forename type="first">Phong</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan Kian Hsiang</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName><surname>Jaillet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NIPS</title>
		<meeting>of NIPS</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Markov chain monte carlo-based machine unlearning: Unlearning what needs to be forgotten</title>
		<author>
			<persName><forename type="first">Phong</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryutaro</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><surname>Oikawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mun</forename><surname>Dinil Mon Divakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Choon Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hsiang</forename><surname>Kian</surname></persName>
		</author>
		<author>
			<persName><surname>Low</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ASIA CCS</title>
		<meeting>of ASIA CCS</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<author>
			<persName><forename type="first">Thanh</forename><surname>Tam Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thanh</forename><forename type="middle">Trung</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phi</forename><surname>Le Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan Wee-Chung</forename><surname>Liew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongzhi</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Viet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hung</forename><surname>Nguyen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.02299</idno>
		<title level="m">A survey of machine unlearning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Image Generation From Small Datasets via Batch Statistics Adaptation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Noguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICCV</title>
		<meeting>of ICCV</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Few-shot image generation via cross-domain correspondence</title>
		<author>
			<persName><forename type="first">Utkarsh</forename><surname>Ojha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yijun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jae</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eli</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CVPR</title>
		<meeting>of CVPR</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Can you trust your model&apos;s uncertainty? evaluating predictive uncertainty under dataset shift</title>
		<author>
			<persName><forename type="first">Yaniv</forename><surname>Ovadia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Fertig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Nado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Sculley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Balaji</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jasper</forename><surname>Snoek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="page">32</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Zero-shot text-to-image generation</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Pavlov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="8821" to="8831" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Hierarchical text-conditional image generation with clip latents</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Casey</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.06125</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">High-resolution image synthesis with latent diffusion models</title>
		<author>
			<persName><forename type="first">Robin</forename><surname>Rombach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Blattmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Lorenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Björn</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="10684" to="10695" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Remember what you want to forget: Algorithms for machine unlearnings</title>
		<author>
			<persName><forename type="first">Ayush</forename><surname>Sekhari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jayadev</forename><surname>Acharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gautam</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananda</forename><surname>Theertha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suresh</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NeurIPS</title>
		<meeting>of NeurIPS</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Generative modeling by estimating gradients of the data distribution</title>
		<author>
			<persName><forename type="first">Yan</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NeuRIPS</title>
		<meeting>of NeuRIPS</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Score-based generative modeling through stochastic differential equations</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diederik</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICLR</title>
		<meeting>of ICLR</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Generative adversarial networks unlearning</title>
		<author>
			<persName><forename type="first">Hui</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianqing</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanlei</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.09881</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Cycle consistent twin energy-based models for image-to-image translation</title>
		<author>
			<persName><forename type="first">Piyush</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kinjawl</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Prathosh</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.media.2023.103031</idno>
		<ptr target="https://www.sciencedirect.com/science/article/pii/S1361841523002918" />
	</analytic>
	<monogr>
		<title level="j">Medical Image Analysis</title>
		<idno type="ISSN">1361-8415</idno>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page">103031</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Bayesian pseudo-coresets via contrastive divergence</title>
		<author>
			<persName><forename type="first">Piyush</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kumar</forename><surname>Shubham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vivek</surname></persName>
		</author>
		<author>
			<persName><surname>Kashyap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Prathosh</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=SHsR2VOOKv" />
	</analytic>
	<monogr>
		<title level="m">The 40th Conference on Uncertainty in Artificial Intelligence, 2024b</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<author>
			<persName><forename type="first">Tatiana</forename><surname>Tommasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Novi</forename><surname>Patricia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tinne</forename><surname>Tuytelaars</surname></persName>
		</author>
		<title level="m">Advances in Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Machine learning for medical imaging: methodological failures and recommendations for the future</title>
		<author>
			<persName><forename type="first">Gaël</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veronika</forename><surname>Cheplygina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NPJ digital medicine</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">48</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">The EU general data protection regulation (GDPR)</title>
		<author>
			<persName><forename type="first">P</forename><surname>Voigt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Von</surname></persName>
		</author>
		<author>
			<persName><surname>Bussche</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>Published in Transactions on Machine Learning Research (02/2025</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Neural networks with late-phase weights</title>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Von</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oswald</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Seijin</forename><surname>Kobayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joao</forename><surname>Sacramento</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Meulemans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Henning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><forename type="middle">F</forename><surname>Grewe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Hyperspectral image super-resolution meets deep learning: A survey and perspective</title>
		<author>
			<persName><forename type="first">Xinya</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qian</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingsong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiayi</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/CAA Journal of Automatica Sinica</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1664" to="1687" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Transferring GANs: generating images from limited data</title>
		<author>
			<persName><forename type="first">Yaxing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenshen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Herranz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joost</forename><surname>Van De Weijer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abel</forename><surname>Gonzalez-Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bogdan</forename><surname>Raducanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ECCV</title>
		<meeting>of ECCV</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">MineGAN: effective knowledge transfer from GANs to target domains with few images</title>
		<author>
			<persName><forename type="first">Yaxing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abel</forename><surname>Gonzalez-Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Berga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Herranz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fahad</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joost</forename><surname>Van De Weijer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CVPR</title>
		<meeting>of CVPR</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Hyperparameter ensembles for robustness and uncertainty quantification</title>
		<author>
			<persName><forename type="first">Florian</forename><surname>Wenzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jasper</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dustin</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rodolphe</forename><surname>Jenatton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6514" to="6527" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Bayesian deep learning and a probabilistic perspective of generalization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pavel</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><surname>Izmailov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="4697" to="4708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Puma: Performance unchanged model augmentation for training data removal</title>
		<author>
			<persName><forename type="first">Ga</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masoud</forename><surname>Hashemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Srinivasa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of AAAI</title>
		<meeting>of AAAI</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Deltagrad: Rapid retraining of machine learning models</title>
		<author>
			<persName><forename type="first">Yinjun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edgar</forename><surname>Dobriban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><forename type="middle">B</forename><surname>Davidson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICML</title>
		<meeting>of ICML</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Priu: A provenance-based approach for incrementally updating regression models</title>
		<author>
			<persName><forename type="first">Yinjun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Val</forename><surname>Tannen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><forename type="middle">B</forename><surname>Davidson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGMOD</title>
		<meeting>of SIGMOD</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Few shot generative model adaption via relaxed spatial structural alignment</title>
		<author>
			<persName><forename type="first">Jiayu</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaofei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng-Jun</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingming</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="11204" to="11213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1492" to="1500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Machine unlearning: A survey</title>
		<author>
			<persName><forename type="first">Heng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianqing</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lefeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanlei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Applications of deep-learning approaches in horticultural research: a review</title>
		<author>
			<persName><forename type="first">Biyun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Horticulture Research</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Learning with recoverable forgetting</title>
		<author>
			<persName><forename type="first">Jingwen</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Songhua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingli</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinchao</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ECCV</title>
		<meeting>of ECCV</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Fine-tuning language models from human preferences</title>
		<author>
			<persName><forename type="first">M</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nisan</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Stiennon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">F</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Christiano</surname></persName>
		</author>
		<author>
			<persName><surname>Irving</surname></persName>
		</author>
		<idno>CoRR, abs/1909.08593</idno>
		<ptr target="http://arxiv.org/abs/1909.08593" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
