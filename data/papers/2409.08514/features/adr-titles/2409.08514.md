- Decision to use a GAN framework for audio restoration
- Choice of Roformer for frequency band sequence modeling
- Implementation of a frequency band split module
- Design of the band-sequence modeling module
- Use of TCN for temporal feature modeling
- Selection of RMSNorm for normalization in fully connected layers
- Adoption of Gated Linear Units (GLUs) as activation functions
- Decision to employ a multi-resolution STFT discriminator
- Choice of Least Squares GAN (LSGAN) loss for discriminator training
- Design of the composite loss function for the generator
- Decision to integrate MUSDB18-HQ and MoisesDB datasets for training and evaluation
- Implementation of real-time data augmentation techniques
- Choice of causal convolution for streaming processing capability
- Decision to focus on preserving low-frequency information during restoration
- Selection of hyperparameters for balancing loss components in training
- Design of the band-reconstruction module for spectrogram conversion
- Decision to utilize gain-shape representations for sub-band spectrograms
- Choice of evaluation metrics for performance comparison with existing models
- Decision to support various compression rates in audio restoration
- Implementation of a Source Activity Detector (SAD) for data preprocessing