{
  "arxivId": "2308.10792",
  "title": "Instruction Tuning for Large Language Models: A Survey",
  "authors": "Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tianwei Zhang, Fei Wu, Guoyin Wang",
  "abstract": "This paper surveys research works in the quickly advancing field of\ninstruction tuning (IT), which can also be referred to as supervised\nfine-tuning (SFT)\\footnote{In this paper, unless specified otherwise,\nsupervised fine-tuning (SFT) and instruction tuning (IT) are used\ninterchangeably.}, a crucial technique to enhance the capabilities and\ncontrollability of large language models (LLMs). Instruction tuning refers to\nthe process of further training LLMs on a dataset consisting of\n\\textsc{(instruction, output)} pairs in a supervised fashion, which bridges the\ngap between the next-word prediction objective of LLMs and the users' objective\nof having LLMs adhere to human instructions. In this work, we make a systematic\nreview of the literature, including the general methodology of SFT, the\nconstruction of SFT datasets, the training of SFT models, and applications to\ndifferent modalities, domains and application, along with analysis on aspects\nthat influence the outcome of SFT (e.g., generation of instruction outputs,\nsize of the instruction dataset, etc). We also review the potential pitfalls of\nSFT along with criticism against it, along with efforts pointing out current\ndeficiencies of existing strategies and suggest some avenues for fruitful\nresearch. Project Page: github.com/xiaoya-li/Instruction-Tuning-Survey",
  "url": "https://arxiv.org/abs/2308.10792",
  "issue_number": 841,
  "issue_url": "https://github.com/dmarx/papers-feed/issues/841",
  "created_at": "2025-01-06T23:16:44.633238",
  "state": "open",
  "labels": [
    "paper",
    "rating:novote"
  ],
  "total_reading_time_seconds": 20,
  "last_read": "2025-01-06T23:26:59.522369",
  "last_visited": "2025-01-06T23:25:42.652000+00:00",
  "main_tex_file": null,
  "published_date": "2023-08-21T15:35:16Z",
  "arxiv_tags": [
    "cs.CL",
    "cs.AI",
    "cs.LG"
  ]
}