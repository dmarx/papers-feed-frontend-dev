{
  "arxivId": "2208.11665",
  "title": "Statistical exploration of the Manifold Hypothesis",
  "authors": "Nick Whiteley, Annie Gray, Patrick Rubin-Delanchy",
  "abstract": "The Manifold Hypothesis is a widely accepted tenet of Machine Learning which\nasserts that nominally high-dimensional data are in fact concentrated near a\nlow-dimensional manifold, embedded in high-dimensional space. This phenomenon\nis observed empirically in many real world situations, has led to development\nof a wide range of statistical methods in the last few decades, and has been\nsuggested as a key factor in the success of modern AI technologies. We show\nthat rich and sometimes intricate manifold structure in data can emerge from a\ngeneric and remarkably simple statistical model -- the Latent Metric Model --\nvia elementary concepts such as latent variables, correlation and stationarity.\nThis establishes a general statistical explanation for why the Manifold\nHypothesis seems to hold in so many situations. Informed by the Latent Metric\nModel we derive procedures to discover and interpret the geometry of\nhigh-dimensional data, and explore hypotheses about the data generating\nmechanism. These procedures operate under minimal assumptions and make use of\nwell known, scaleable graph-analytic algorithms.",
  "url": "https://arxiv.org/abs/2208.11665",
  "issue_number": 452,
  "issue_url": "https://github.com/dmarx/papers-feed/issues/452",
  "created_at": "2025-01-04T14:49:42.245960",
  "state": "open",
  "labels": [
    "paper",
    "rating:downvote"
  ],
  "total_reading_time_seconds": 0,
  "last_read": null,
  "last_visited": "2024-12-29T02:26:31.276Z",
  "main_tex_file": null,
  "published_date": "2022-08-24T17:00:16Z",
  "arxiv_tags": [
    "stat.ME",
    "cs.LG",
    "stat.ML",
    "62R20, 62R40, 62G05, 62G20, 62R07, 62-08, 62H25, 62H30"
  ]
}