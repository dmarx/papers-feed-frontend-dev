- Decision to use mutual information as a metric for interface evaluation
- Choice of unsupervised learning approach for interface training
- Selection of reinforcement learning for interface optimization
- Decision to conduct a large-scale observational study for validation
- Choice of diverse command modalities for user interaction
- Decision to initialize the interface randomly
- Assumption that intuitive interfaces lead to less noisy commands
- Decision to evaluate interface effectiveness through correlation with ground-truth metrics
- Choice of specific user study tasks (2D cursor control, Lunar Lander game)
- Decision to use a small-scale user study for real-time interface adaptation
- Choice of data collection methods for user command signals
- Decision to split observational data into training and validation sets
- Assumption regarding the relationship between user adaptation and interface intuitiveness
- Decision to penalize conditional entropy in the mutual information formulation
- Choice of algorithm for optimizing mutual information lower bounds
- Decision to focus on human-in-the-loop training for interface learning
- Assumption about the generalizability of findings across different interface types
- Decision to analyze the impact of interface design on user performance metrics
- Choice of metrics for evaluating user command noise levels
- Decision to explore the scalability of the MIMI algorithm to complex tasks