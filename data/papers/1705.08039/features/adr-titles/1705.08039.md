- Choice of hyperbolic space for embeddings
- Selection of the Poincar√© ball model
- Use of Riemannian optimization for learning embeddings
- Assumption of latent hierarchical structure in data
- Decision to operate in an unsupervised learning setting
- Design of the loss function for embedding optimization
- Dimensionality of the embedding space
- Parallelization strategy for optimization
- Evaluation metrics for comparing embeddings
- Handling of missing data in embeddings
- Experimental validation on specific datasets (e.g., WORDNET, collaboration networks)
- Comparison with Euclidean embeddings
- Insights gained from hierarchical relationships in embeddings
- Scalability considerations for large datasets
- Trade-offs between representation capacity and computational efficiency