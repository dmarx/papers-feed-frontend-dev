- Decision to use state-space models (SSMs) for time series modeling
- Choice of companion matrix parameterization for SSMs
- Adoption of a closed-loop approach for long horizon forecasting
- Implementation of a shift plus low-rank decomposition for efficiency
- Selection of specific benchmarks for performance evaluation
- Decision to focus on autoregressive processes in time series
- Choice of deep learning layers to enhance SSM expressivity
- Use of gradient descent for training SSM parameters
- Design of the SpaceTime architecture as a multi-layer encoder-decoder
- Decision to evaluate both classification and forecasting tasks
- Choice of input sequence representation for SSMs
- Implementation of a recurrent input generation mechanism
- Decision to optimize memory and compute for forward pass
- Selection of performance metrics (AUROC, MSE) for evaluation
- Decision to compare against existing models (Transformers, LSTMs)
- Choice of experimental setup for synthetic and real-world data
- Decision to document the limitations of prior deep SSM approaches
- Choice of equal contribution among authors based on competition results
- Decision to structure the model for subquadratic time and space complexity
- Choice of specific training data (e.g., ETTh1) for benchmarking efficiency