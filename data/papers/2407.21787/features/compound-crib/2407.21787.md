### Detailed Technical Explanations and Justifications

#### Inference Compute Scaling

**Repeated Sampling as a Method to Scale Inference Compute:**
The decision to employ repeated sampling as a method for scaling inference compute stems from the observation that traditional single-attempt inference often limits the performance of large language models (LLMs). By generating multiple candidate solutions for a given problem, researchers can leverage the probabilistic nature of LLMs to explore a broader solution space. This approach allows for the identification of correct solutions that may not be apparent from a single output, thereby enhancing reasoning performance across various tasks.

#### Key Metrics

**Coverage:**
Coverage is defined as the fraction of problems solved by any generated sample. This metric is crucial because it quantifies the effectiveness of the sampling strategy. As the number of samples increases, the likelihood of generating at least one correct solution also increases, leading to higher coverage. This relationship is particularly important in tasks where the solution space is large or complex, as it allows researchers to assess the scalability of their approach.

**Precision:**
Precision measures the ability to identify correct samples from the generated candidates. High precision is essential for ensuring that the solutions selected from the sampled candidates are indeed correct. This metric becomes increasingly important in scenarios where the number of samples is high, as it helps to filter out noise and focus on the most promising candidates.

#### Performance Improvement

The performance improvement observed with DeepSeek-Coder-V2-Instruct on SWE-bench Lite, where the success rate increased from 15.9% with one sample to 56% with 250 samples, illustrates the effectiveness of repeated sampling. This significant leap not only surpasses the previous state-of-the-art performance of 43% but also highlights the potential of repeated sampling to amplify the capabilities of LLMs, particularly in practical applications like software engineering.

#### Scaling Laws

The observation that coverage often follows a log-linear relationship with the number of samples suggests the existence of scaling laws for inference compute. This log-linear relationship can be modeled using an exponentiated power law, indicating that as the number of samples increases, the returns in terms of coverage also increase, albeit at a diminishing rate. This insight is valuable for researchers and practitioners as it provides a framework for predicting performance improvements based on sample budgets.

#### Task Categories

The categorization of tasks into GSM8K, MATH, MiniF2F-MATH, CodeContests, and SWE-bench Lite allows for a structured analysis of the effectiveness of repeated sampling across different domains. Each task presents unique challenges, and the presence of automatic verifiers in some categories (e.g., MiniF2F-MATH and SWE-bench Lite) enables a more straightforward assessment of coverage and precision.

#### Verification Tools

The use of automatic verifiers, such as unit tests and proof checkers, enhances precision by providing a reliable means of validating candidate solutions. In tasks where such verifiers are available, the correlation between coverage improvements and success rates is direct and significant. Conversely, in the absence of automatic verifiers, traditional methods like majority voting and reward models tend to plateau, indicating their limitations in effectively leveraging large sample sizes.

#### Sample Budget Impact

The findings regarding sample budget impact reveal that smaller models can outperform larger models when given more samples. This insight is critical for optimizing resource allocation, as it suggests that in certain scenarios, it may be more cost-effective to utilize a smaller model with a higher sample count rather than a larger model with fewer samples. This approach maximizes coverage while minimizing inference costs.

#### Experimental Findings

The experimental results demonstrate a clear trend: coverage increases significantly with repeated sampling. For instance, Gemma-2B's coverage on CodeContests increased from 0.02% with one sample to 7.1% with 10,000 samples. This stark contrast underscores the potential of repeated sampling to unlock the capabilities of LLMs, particularly in challenging domains.

#### Cost-Effectiveness

The cost-effectiveness of repeated sampling is a compelling rationale for its adoption. By maximizing coverage while minimizing inference costs, researchers can achieve better performance without incurring the high computational expenses associated with larger models. This aspect is particularly relevant in real-world applications where budget constraints are a consideration.

#### Mathematical Representation

The coverage calculation formula provides a quantitative basis for evaluating the effectiveness of repeated sampling. By calculating the pass rate based on the number of correct samples, researchers can systematically assess the impact of different sampling strategies on model performance.

#### Figures and Results

Figures illustrating the repeated sampling procedure, coverage improvements, and trends across model sizes provide visual evidence of the effectiveness of the proposed approach. These visualizations help to communicate the findings clearly and support the conclusions drawn from the experimental data.

#### Conclusion

In conclusion, the decision to utilize repeated sampling as a strategy for enhancing LLM performance is well-justified by the observed improvements in coverage and precision across various tasks. The approach not only provides a viable means of scaling inference compute but also offers a cost-effective alternative to relying solely on larger models. The insights gained from this research have significant implications for the future