- Decision to explore repeated sampling as a method for scaling inference compute
- Choice of tasks for evaluation (GSM8K, MATH, MiniF2F-MATH, CodeContests, SWE-bench Lite)
- Selection of metrics for success rate and coverage
- Use of automatic verifiers for certain tasks
- Implementation of positive temperature sampling for candidate generation
- Decision to model the relationship between coverage and number of samples with an exponentiated power law
- Choice of verification methods (majority voting, reward models) for non-automated tasks
- Strategy for balancing model size and sample count for cost-effectiveness
- Decision to use specific models (DeepSeek-Coder-V2-Instruct, Llama-3) for experiments
- Approach to data collection and unbiased estimation for coverage calculation
- Decision to focus on pass-fail tasks for evaluating candidate solutions
- Choice of programming language (Python3) for CodeContests solutions
- Decision to document findings and observations systematically across experiments
- Assumptions about the scalability of inference compute in relation to model performance
- Decision to analyze the cost implications of repeated sampling versus single samples from larger models
- Choice of experimental design to assess the effectiveness of repeated sampling across different domains