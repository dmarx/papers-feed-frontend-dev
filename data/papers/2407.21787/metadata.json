{
  "arxivId": "2407.21787",
  "title": "Large Language Monkeys: Scaling Inference Compute with Repeated Sampling",
  "authors": "Bradley Brown, Jordan Juravsky, Ryan Ehrlich, Ronald Clark, Quoc V. Le, Christopher R\u00e9, Azalia Mirhoseini",
  "abstract": "Scaling the amount of compute used to train language models has dramatically\nimproved their capabilities. However, when it comes to inference, we often\nlimit models to making only one attempt at a problem. Here, we explore\ninference compute as another axis for scaling, using the simple technique of\nrepeatedly sampling candidate solutions from a model. Across multiple tasks and\nmodels, we observe that coverage -- the fraction of problems that are solved by\nany generated sample -- scales with the number of samples over four orders of\nmagnitude. Interestingly, the relationship between coverage and the number of\nsamples is often log-linear and can be modelled with an exponentiated power\nlaw, suggesting the existence of inference-time scaling laws. In domains like\ncoding and formal proofs, where answers can be automatically verified, these\nincreases in coverage directly translate into improved performance. When we\napply repeated sampling to SWE-bench Lite, the fraction of issues solved with\nDeepSeek-Coder-V2-Instruct increases from 15.9% with one sample to 56% with 250\nsamples, outperforming the single-sample state-of-the-art of 43%. In domains\nwithout automatic verifiers, we find that common methods for picking from a\nsample collection (majority voting and reward models) plateau beyond several\nhundred samples and fail to fully scale with the sample budget.",
  "url": "https://arxiv.org/abs/2407.21787",
  "issue_number": 513,
  "issue_url": "https://github.com/dmarx/papers-feed/issues/513",
  "created_at": "2025-01-04T14:49:12.234492",
  "state": "open",
  "labels": [
    "paper",
    "rating:novote"
  ],
  "total_reading_time_seconds": 17,
  "last_read": "2025-01-04T14:49:12.237648",
  "last_visited": "2024-12-29T20:31:06.783Z",
  "main_tex_file": null,
  "published_date": "2024-07-31T17:57:25Z",
  "arxiv_tags": [
    "cs.LG",
    "cs.AI"
  ]
}