- Decision to use a pure Transformer architecture for image classification
- Choice of image patch size for input to the Transformer
- Decision to use linear embeddings for image patches
- Use of a learnable classification token in the input sequence
- Implementation of position embeddings for retaining spatial information
- Choice of MLP architecture for the classification head
- Decision to pre-train on large datasets before fine-tuning
- Use of 2D interpolation for position embeddings when fine-tuning at higher resolutions
- Decision to evaluate model performance on multiple benchmark datasets
- Choice of datasets for pre-training and fine-tuning
- Decision to compare ViT with traditional CNN architectures
- Use of residual connections and layer normalization in the Transformer architecture
- Decision to explore hybrid architectures combining CNNs and Transformers
- Choice of activation function (GELU) in the MLP layers
- Decision to implement self-supervised learning experiments
- Choice of evaluation metrics for model performance assessment
- Decision to de-duplicate pre-training datasets with respect to downstream task test sets
- Use of specific data augmentation techniques during training
- Decision to analyze the impact of dataset size on model performance
- Choice of computational resources and hardware for training the models