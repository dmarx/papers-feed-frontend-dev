<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Characterising high-order interdependence via entropic conjugation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Fernando</forename><forename type="middle">E</forename><surname>Rosas</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution" key="instit1">Sussex AI</orgName>
								<orgName type="institution" key="instit2">Sussex Centre for Consciousness Science</orgName>
								<orgName type="institution" key="instit3">University of Sussex</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Centre for Complexity Science and Center for Psychedelic Research</orgName>
								<orgName type="department" key="dep2">Department of Brain Science</orgName>
								<orgName type="institution">Imperial College London</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Center for Eudaimonia and Human Flourishing</orgName>
								<orgName type="institution">University of Oxford</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Principles of Intelligent Behavior in Biological and Social Systems (PIBBSS)</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aaron</forename><surname>Gutknecht</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Campus Institute for Dynamics of Biological Networks</orgName>
								<orgName type="institution">Georg-August University</orgName>
								<address>
									<settlement>Göttingen</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pedro</forename><forename type="middle">A M</forename><surname>Mediano</surname></persName>
							<affiliation key="aff5">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
							</affiliation>
							<affiliation key="aff6">
								<orgName type="department">Division of Psychology and Language Sciences</orgName>
								<orgName type="institution">University College London</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Gastpar</surname></persName>
							<affiliation key="aff7">
								<orgName type="department">School of Computer and Communication Sciences</orgName>
								<orgName type="institution">École Polytechnique Fédérale de Lausanne</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Characterising high-order interdependence via entropic conjugation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">02232B49B3626ECD72716B7BD140F602</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-02-21T16:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>High-order phenomena play crucial roles in many systems of interest, but their analysis is often highly nontrivial. There is a rich literature providing a number of alternative information-theoretic quantities capturing high-order phenomena, but their interpretation and relationship with each other is not well understood. The lack of principles unifying these quantities obscures the choice of tools for enabling specific type of analyses. Here we show how an entropic conjugation provides a theoretically grounded principle to investigate the space of possible high-order quantities, clarifying the nature of the existent metrics while revealing gaps in the literature. This leads to identify novel notions of symmetry and skew-symmetry as key properties for guaranteeing a balanced account of high-order interdependencies and enabling broadly applicable analyses across physical systems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Physical and biological systems often exhibit relationships between their parts that cannot be reduced to dependencies in subsets of them <ref type="bibr" target="#b1">[1]</ref>. The study of these high-order interdependencies has lead to new insights in a wide range of physical systems <ref type="bibr" target="#b2">[2]</ref><ref type="bibr" target="#b3">[3]</ref><ref type="bibr" target="#b4">[4]</ref>, and also in studies involving genetics <ref type="bibr" target="#b5">[5,</ref><ref type="bibr" target="#b6">6]</ref> and neural systems (both biological <ref type="bibr" target="#b7">[7]</ref><ref type="bibr" target="#b8">[8]</ref><ref type="bibr" target="#b9">[9]</ref><ref type="bibr" target="#b10">[10]</ref><ref type="bibr" target="#b11">[11]</ref> and artificial <ref type="bibr" target="#b12">[12]</ref><ref type="bibr" target="#b13">[13]</ref><ref type="bibr" target="#b14">[14]</ref>), to name a few. Overall, qualitatively different types of interdependence have been found to play complementary roles balancing needs for robustness and flexibility <ref type="bibr" target="#b15">[15,</ref><ref type="bibr" target="#b16">16]</ref>.</p><p>There are different approaches to quantify high-order phenomena <ref type="bibr" target="#b17">[17]</ref>, among which we focus on informationtheoretic metrics based on Shannon entropy. While there is a rich literature offering such metrics, their interpretation is highly non-trivial -being unclear if these quantities are capturing the same effects or instead provide complementary perspectives. This lack of clarity makes it challenging for researchers to choose the right tools to carry out specific types of analyses, severely hindering the study of high-order phenomena.</p><p>Here we address this issue by introducing the notion of entropic conjugation, which establishes a theoretically grounded principle to explore the space of possible highorder quantities. Our results show that the existent highorder metrics have a closer relationship than previously thought, while revealing gaps in the literature for characterising interactions involving more than 5 variables. Moreover, the notions of symmetry and skew-symmetry with respect to conjugation emerge as key guarantees for providing a balanced account of high-order interdependence, enabling analyses that can illuminate the highorder profile of a wide range of physical systems. The proofs of our results can be found in the Appendix.</p><p>Measures of multivariate interdependence. Let's consider a system with a state is specified by the random vector X = (X 1 , . . . , X n ) following a joint distribution p X and marginal distributions p Xi . The literature presents various metrics to assess the dependencies between parts of X; here we focus on linear combinations of entropies of the form ϕ(X) = a⊆In λ a H(X a ), with I n = {1, . . . , n}, X a is a vector of variables whose indices are in a ⊆ I n , H is Shannon's entropy, and λ a are scalars. We require these metrics to satisfy two key properties:</p><p>(i) Labelling-symmetry: ϕ(X) is invariant to permutations among X 1 , . . . , X n .</p><p>(ii) Dependency: ϕ(X) = 0 if the variables are jointly independent (i.e. p X = n k=1 p X k ). Hence, property (i) guarantees that ϕ does not depend on how variables are named and (ii) that it only captures interactions effects between variables <ref type="bibr" target="#b18">[18]</ref>.</p><p>There are several well-known metrics that satisfy these properties. The oldest of these is the interaction information <ref type="bibr" target="#b19">[19]</ref>, which is defined as</p><formula xml:id="formula_0">II(X) := n k=1 (-1) k+1 |a|=k H(X a ).<label>(1)</label></formula><p>Other metrics of interdependence are the total correlation (TC) <ref type="bibr" target="#b20">[20]</ref> and the dual total correlation (DTC) <ref type="bibr" target="#b21">[21]</ref>, which are given by TC(X) := n j=1 H(X j ) -H(X) and ( <ref type="formula" target="#formula_36">2</ref>)</p><formula xml:id="formula_1">DTC(X) := H(X) - n j=1 H(X j |X -j ).<label>(3)</label></formula><p>arXiv:2410.10485v1 [cs.IT] 14 Oct 2024</p><p>Another such metric, well-known in computational neuroscience, is the Tononi-Sporns-Edelman (TSE) complexity <ref type="bibr" target="#b22">[22]</ref>, which is defined as</p><formula xml:id="formula_2">TSE(X) := ⌊n/2⌋ k=1 n k -1 |a|=k I(X a ; X -a ),<label>(4)</label></formula><p>where -a is the set of indices of X that are not in a.</p><p>Finally, we also consider the more recently introduced O-information and S-information <ref type="bibr" target="#b23">[23]</ref>:</p><formula xml:id="formula_3">Ω(X) := (n -2)H(X) + n j=1 H(X j ) -H(X -j ) ,<label>(5)</label></formula><formula xml:id="formula_4">Σ(X) := n j=1 I(X j ; X -j ).<label>(6)</label></formula><p>Of these, TC, DTC, TSE, and Σ are non-negative, while II and Ω can take positive and negative values. We will show these seemingly unrelated metrics can be parsimoniously unified under the concept of entropic conjugation.</p><p>Characterising high-order interdependencies. Let us introduce the following average quantities:</p><formula xml:id="formula_5">u k (X) := 1 n k+1 k+1 2 i,j∈In i&lt;j |a|=k-1 i,j / ∈a I(X i ; X j |X a ),<label>(7)</label></formula><p>with k = 1, . . . , n -1. These quantities satisfy labellingsymmetry and dependency, and capture the interdependencies between k variables -i.e. u j (X) = 0 for j &lt; k if and only if all subsets of k variables or less are statistically independent. Furthermore, it has been shown that all information-theoretic metrics ϕ satisfying labelling-symmetry and dependency can be expressed as</p><formula xml:id="formula_6">ϕ(X) = n-1 k=1 c k u k (X)</formula><p>, where c k ∈ R captures the relevance of (k + 1)-th order dependencies on ϕ <ref type="bibr" target="#b24">[24]</ref>. Moreover, this decomposition is unique in guaranteeing that ϕ is non-negative if and only if c k ≥ 0 for k = 1, . . . , n-1.</p><p>A complementary, more fine-grained way of investigating high-order interdependence is enabled by partial information decomposition (PID), which addresses how information about a variable Y provided by X may be decomposed into the contributions of its different components <ref type="bibr" target="#b25">[25]</ref><ref type="bibr" target="#b26">[26]</ref><ref type="bibr" target="#b27">[27]</ref>. PID reveals that while pairwise interdependence is quantified by its strength (measured e.g. by the mutual information), higher-order relationships can be of qualitatively different kinds -most notably redundant (multiple variables sharing the same information) or synergistic (a set of variables holding some information that cannot be seen from any subset). Moreover, PID recognises that synergy and redundancy can be mixed in non-trivial ways, and explores this thoroughly via an algebraic construction that leads to the decomposition</p><formula xml:id="formula_7">I(X; Y ) = α∈An I α ∂ (X; Y ),<label>(8)</label></formula><p>where A n is a collection of elements α that cover all possible combinations of redundancy and synergy (App. B). For example, if n = 2 then A 2 has four elements: α 1 = {{1}{2}} corresponding to the redundancy between X 1 and X 2 , α 2 = {{1, 2}} corresponding to the synergy between them, and α 3 = {{1}} and α 4 = {{2}} corresponding to unique information in one but not the other.</p><p>A conjugation of Shannon quantities. We are now ready to introduce the notion of entropy conjugation. Definition 1. The entropic conjugation is defined by</p><formula xml:id="formula_8">H(X a ) * :=H(X -a ) -H(X).<label>(9)</label></formula><p>The conjugation of a linear combination of entropies</p><formula xml:id="formula_9">ϕ(X) = a⊆In λ a H(X a ) is ϕ(X) * := a⊆In λ a H(X a ) * . (<label>10</label></formula><formula xml:id="formula_10">)</formula><p>It can be seen that * is a proper conjugation, as it is linear (by definition) and an involution, as ((H) * ) * = H. Also, a direct calculation shows that entropic conjugation acts on the mutual information as follows:</p><formula xml:id="formula_11">I(X a ; X b |X c ) * = I X a ; X b |X -(a∪b∪c) ,<label>(11)</label></formula><p>where a, b, c are disjoint subsets of indices. Furthermore, one can show that entropic conjugation exchanges highfor low-order interdependencies, which will be the basis of our analysis of high-order quantities in the next section.</p><formula xml:id="formula_12">Proposition 1. u k (X) * = u n-k (X).</formula><p>A deeper insight on the effect of conjugation can be attained by looking at it via the PID framework. Our next result shows that entropic conjugation is the unique operation that arises from applying the duality principle from order theory <ref type="bibr" target="#b28">[28]</ref> to PID, which results in a natural conjugation of atoms † that exchanges redundancies for synergies and vice-versa (for example, if α = {{1, 2}} then α † = {{1}, {2}}). Crucially, this holds for any operationalisation of synergy and redundancy that is consistent with the PID framework (see App. B).</p><p>Theorem 1. The natural conjugation of PID atoms † arising from order duality satisfies</p><formula xml:id="formula_13">I(X a ; Y |X b ) † = α∈A b a I α † ∂ (X; Y ) = I(X a ; Y |X b ) * , (<label>12</label></formula><formula xml:id="formula_14">)</formula><p>where A b a is a suitable collection of atoms (see Lemma 2). Let's illustrate this result with a simple example. Using the fact that the O-information is equal to redundancy minus synergy <ref type="bibr" target="#b23">[23]</ref>, Th. 1 implies that Ω(X 1 ; X 2 ; Y )</p><formula xml:id="formula_15">* = I {{1},{2}} † ∂ (X; Y ) -I {{1,2}} † ∂ (X; Y ) = I {{1,2}} ∂ (X; Y ) -I {{1},{2}} ∂ (X; Y ) = -Ω(X 1 ; X 2 ; Y ). (<label>13</label></formula><formula xml:id="formula_16">)</formula><p>Symmetric and skew-symmetric metrics. We now use the entropic conjugation to introduce the notions of symmetric and skew-symmetric interdepence quantities.</p><formula xml:id="formula_17">Definition 2. A linear combination of entropies ϕ is symmetric if (ϕ) * = ϕ and skew-symmetric if (ϕ) * = -ϕ.</formula><p>This definition, combined with Prop. 1 and Th. 1, implies that symmetric and skew-symmetric quantities provide balanced accounts of low-and high-order interdependencies (alternatively, redundancies and synergies): symmetric quantities weight these equally, while skewsymmetric weights them equally but with opposite signs. Thus, a practical way to recognise symmetric and skewsymmetric high-order metrics is via their weights in terms of the basis u k , as shown next.</p><formula xml:id="formula_18">Lemma 1. If ϕ(X) = k=1 c k u k (X), then • ϕ is symmetric ⇐⇒ c k = c n-k . • ϕ is skew-symmetric ⇐⇒ c k = -c n-k .</formula><p>With these tools at hand, we now study the existent high-order metrics under the lens of conjugation.</p><p>Proposition 2. The mentioned multivariate metrics can be decomposed as follows:</p><formula xml:id="formula_19">TC(X) = n-1 k=1 (n -k)u n k (X),<label>(14)</label></formula><formula xml:id="formula_20">DTC(X) = n-1 k=1 ku n k (X),<label>(15)</label></formula><formula xml:id="formula_21">TSE(X) = n-1 k=1 k(n -k) 2 u n k (X),<label>(16)</label></formula><formula xml:id="formula_22">Σ(X) = n n-1 k=1 u n k (X),<label>(17)</label></formula><formula xml:id="formula_23">Ω(X) = n-1 k=1 (n -2k)u n k (X),<label>(18)</label></formula><formula xml:id="formula_24">II(X) = n-1 k=1 (-1) k+1 n -2 k -1 u n k (X).<label>(19)</label></formula><p>Therefore, the following relationships hold:</p><formula xml:id="formula_25">TC(X) * = DTC(X),<label>(20)</label></formula><formula xml:id="formula_26">Σ(X) * = Σ(X),<label>(21)</label></formula><p>TSE(X) * = TSE(X), ( <ref type="formula">22</ref>)</p><formula xml:id="formula_27">Ω(X) * = -Ω(X),<label>(23)</label></formula><formula xml:id="formula_28">II(X) * = (-1) n II(X). (<label>24</label></formula><formula xml:id="formula_29">)</formula><p>These results show that the S-information and TSE complexity are balanced metrics of overall interdependence strength, while the O-information provides a balanced opposition between high-and low-order interdependencies. In contrast, the interaction information alternates between being symmetric or skew-symmetric in a way that will be better understood in the next subsection. Additionally, this result also shows that the TC and DTC are not balanced metrics, being duals to each other: the TC provides more weight to low-order effects while the DTC to high-order ones.</p><p>These results also reveal that this collection of metrics is not as arbitrary as it may seem: when seen from their coefficients c k , they cover the constant (S-information), linear (TC, DTC, and O-information), quadratic (TSE), and binomial (interaction information) cases.</p><p>Spanning the possible metrics. We now show that entropic conjugation induces a decomposition of high-order quantities into symmetric and skew-symmetric components -revealing that skew-symmetric quantities are akin to the imaginary part of complex numbers.</p><p>Theorem 2. Every information-theoretic metric of interdependence ϕ can be decomposed into unique symmetric and skew-symmetric components as follows:</p><formula xml:id="formula_30">ϕ = 1 2 ϕ + ϕ * symmetric + 1 2 ϕ -ϕ * skew-symmetric . (<label>25</label></formula><formula xml:id="formula_31">)</formula><p>Moreover, symmetric and skew-symmetric components are orthogonal under the inner product induced by</p><formula xml:id="formula_32">⟨u k , u j ⟩ = δ k j .</formula><p>This result provides a guide to investigate the geometry of the (n -1)-dimensional space of high-order metrics ϕ satisfying labelling-symmetry and dependency, which we denote by I n .</p><p>Corollary 1. If X has n variables, then the (n -1) dimensions of I (X) are divided in the following way:</p><formula xml:id="formula_33">dim I n = ⌊n/2⌋ symmetric + ⌊(n -1)/2⌋ skew-symmetric . (<label>26</label></formula><formula xml:id="formula_34">)</formula><p>These results have the following consequences:</p><p>-For n = 2 variables, Shannon's mutual information is the only symmetric functional (up to scaling), as there are no skew-symmetric functionals.</p><p>-For n = 3 variables, the S-information is the only symmetric functional and the O-information (equivalently, the interaction information) is the only skew-symmetric one (up to scaling). Therefore, if ϕ ∈ I 3 then ϕ(X) = αΣ(X) + βΩ(X).</p><p>-For n = 4 variables, the S-information and the interaction information span the subspace of symmetric metrics, while the O-information is the only skew-symmetric one (up to scaling). Therefore, if ϕ ∈ I 4 then ϕ(X) = αΣ(X) + α ′ II(X) + βΩ(X). The variability among u k is captured by two principal components: one of symmetric character which accounts for the overall strength of the interdependence (PC1), and one of skew-symmetric character that accounts for the balance between high-and low-order interdependence (PC2). c) The values of u k projected onto these PCs provide a simple characterisation of these three types of systems in terms of their overall interdependence strength (PC1) and the balance between high-and low-order effects (PC2).</p><p>-For n = 5 variables, the space of symmetric metrics is spanned by the S-information and the TSEcomplexity, and the space of skew-symmetric metrics is spanned by the O-information and the interaction information. Therefore, if ϕ ∈ I 5 then ϕ(X) = αΣ(X) + α ′ TSE(X) + βΩ(X) + β ′ II(X).</p><p>Larger systems can be analysed in a similar fashion, but the existing metrics do not cover all the dimensions.</p><p>Computational tractability. Most u k (and, therefore, most high-order metrics) require estimating a large number of information-theoretic terms, and hence their computation becomes unfeasible when n grows. Our next result characterises the space of possible computationallyefficient symmetric and skew-symmetric. Proposition 3. The S-information and O-information are the only symmetric and skew-symmetric interdependence metrics that can be computed using a linear number of entropy terms.</p><p>Note that the TC and DTC also require a linear number of terms, but they are neither symmetric or skewsymmetric -in fact, their decomposition via Th. 2 yields TC = (Σ + Ω)/2 and DTC = (Σ -Ω)/2. Empirical results. To illustrate the applicability of this framework, we investigated the interdependencies exhibited by small spin systems under weak, ferromagnetic (positive), and frustrated (negative) types of interactions (App. C). The latter condition makes it impossible to simultaneously satisfy the tendency of all spins to be different from their neighbours, which is known for inducing high-order interdependencies <ref type="bibr" target="#b17">[17]</ref>.</p><p>To investigate the interdependencies of these systems, we calculated the values of u k according to Eq. ( <ref type="formula" target="#formula_5">7</ref>) and identified the principal axes of variability by via principal component analysis (App. C). Results show that two components explain almost all the variability: a first component of symmetric character similar to the Sinformation, and a second component of skew-symmetric character similar to the O-information (Fig. <ref type="figure" target="#fig_0">1</ref>). In other words, an optimal information-theoretic analysis to characterise the high-order interdependence of these systems reduces to two keys aspects: (i) their strength, and (ii) the balance between high-and low-order components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion.</head><p>Here we investigated the space of possible metrics of high-order interdependence taking the form of linear combinations of Shannon entropies. We introduced the notion of entropic conjugation, the effect of which can be understood in two complementary ways: as exchanging how metrics account for high-and low-order interdependencies, or alternatively, how they account for redundancies and synergies. Crucially, while multiple operationalisation of synergy and redundancy exist <ref type="bibr" target="#b26">[26]</ref>, the properties of entropy conjugation hold for all approaches that are consistent with the PID formalism.</p><p>When studying high-oder quantities, non-negative metrics such as the S-information and TSE complexity were found to be invariant (i.e. symmetric) under entropic conjugation, confirming that they provide a balanced account of overall interdependence strength. Similarly, applying entropic conjugation to a signed metric such as the O-information results in a minus sing (i.e. skew-symmetric), guaranteeing that it provides a fair bal-ance of the relative strength of redundancies and synergies. The interaction information was found to be either symmetric or skew-symmetric depending on the number of variables, providing a principled explanation to the observation (first made in Ref. <ref type="bibr" target="#b25">[25]</ref>) that interpreting this quantity from a high-order perspective requires nuance.</p><p>This framework also let us prove that the well-known high-order metrics cover all possibilities when considering systems of up to n = 5 variables, while the space of possible metrics for capturing interactions involving more variables remains largely unexplored. Additionally, the S-information and O-information were found to be the symmetric and skew-symmetric quantities that are most computationally efficient, and numerical analyses showed their relevance when studying physical systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I α</head><p>∂ (X; Y ) quantifies the information about the target variable Y that is accessible via each collection of source variables α 1 , . . . , α l , while not being accessible via subsets of those collections or any other collections that not include them. For example, if n = 2 then I {{1,2}} ∂ (X; Y ) corresponds to the information accessible in (X 1 , X 2 ) but not accessible from either X 1 or X 2 by themselves.</p><p>The accessibility relations denoted by PID antichains can be made explicit by 're-representing' them in terms of Boolean functions f : P n → {0, 1}, where P n is the powerset of {1, . . . , n}, taking a set of source indices as an input and returning 0 or 1 depending on whether the associated atom I f ∂ (X; Y ) is or isn't accessible via the set of sources. For example, the atom α = {{1, 2}} corresponds to the Boolean function that gives f (∅) = f ({1}) = f ({2}) = 0 and f ({1, 2}) = 1. Crucially, it has been shown that there is a natural isomorphism between PID antichains and monotonic Boolean functions <ref type="bibr" target="#b29">[29,</ref><ref type="bibr" target="#b30">30]</ref>, which implies that PID can be re-defined as follows. Definition 3. A PID of the information provided by</p><formula xml:id="formula_35">X = (X 1 , . . . , X n ) about Y is a set of quantities I f ∂ (X; Y ) that satisfy for all a ⊆ {1, . . . , n} I(X a ; Y ) = f ∈Bn f (a)=1 I f ∂ (X; Y ),<label>(B1)</label></formula><p>where B n is the set of all non-constant monotonic Boolean functions f : P n → {0, 1}.</p><p>Note that Eq. (B1) is equivalent to Eq. ( <ref type="formula" target="#formula_7">8</ref>), with the only difference being the way in which PID atoms are labeled (either as antichains or Boolean functions). That said, viewing PID in terms of Boolean functions lets us conveniently handle various expressions, as shown below.</p><p>Lemma 2. Given two disjoint sets of source variables a and b, we have</p><formula xml:id="formula_36">I(X a ; Y |X b ) = f ∈B b a I f ∂ (X; Y ),<label>(B2)</label></formula><p>where</p><formula xml:id="formula_37">B b a = {f ∈ B n : f (a ∪ b) = 1, f (b) = 0}.</formula><p>Note that the set A b a used in Th. 1 corresponds to the same atoms in B b a but represented in antichain form instead of as Boolean functions.</p><p>Proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I(X</head><formula xml:id="formula_38">a ; Y |X b ) = I(X a , X b ; Y ) -I(X b ; Y ) = f ∈Bn f (a∪b)=1 I f ∂ (X; Y ) - f ∈Bn f (b)=1 I f ∂ (X; Y ), (B3)</formula><p>from which the desired result follows.</p><p>The information atoms have a natural order in terms of their accessibility: an atom I f ∂ (X; Y ) can be said to be 'more accessible' than an atom I g ∂ (X; Y ) if any set via which the latter is accessible is also a set via which the former is accessible. This property is elegantly captured by the Boolean function representation of atoms via the following partial ordering: f ⊑ g if and only if f (a) ≤ g(a) ∀a ∈ P n .</p><p>(B4)</p><p>Note that this partial ordering gives rise to a lattice of PID atoms denoted by (B n , ⊑), which is isomorphic to the original PID lattice of antichains <ref type="bibr" target="#b30">[30]</ref>.</p><p>Let us now introduce the notion of PID conjugation. For this, let us first note that, according to the ordertheoretic principle of duality <ref type="bibr" target="#b28">[28]</ref>, every lattice has a dual lattice in which all arrows are reverted. If we think of Boolean functions as bitstrings (with subsets ordered lexicographically), the dual of the PID lattice can be found by simply inverting the digits and reading the bitstring backwards, as shown by our next result. Proposition 4. The mapping f → f † , where f † is the Boolean function satisfying</p><formula xml:id="formula_39">∀a ⊆ {1 . . . , n} : f † (a) = 1 ⇔ f (a C ) = 0,<label>(B5)</label></formula><p>is an order-reversing involution on (B n , ⊑).</p><p>Proof.</p><formula xml:id="formula_40">Involution: f † † (a) = 1 if and only if f ((a C ) C ) = f (a) = 1. Hence, f † † = f . Order-reversing: Suppose first that f ⊑ g, meaning that g(a) = 1 → f (a) = 1.</formula><p>Then, if f † (a) = 1 we must have f (a c ) = 0 and so g(a c ) = 0 and hence g † (a) = 1. Therefore we have g</p><formula xml:id="formula_41">† ⊑ f † . Conversely, if g † ⊑ f † , then f † (a) = 1 → g † (a) = 1.</formula><p>Hence, if g(a) = 1 it follows that g † (a c ) = 0 and thus f † (a c ) = 0 and thus f (a) = 1. Therefore, f ⊑ g.</p><p>The effect of † on the PID lattice can be understood as follows. Following Ref. <ref type="bibr" target="#b31">[31]</ref>, each atom can be expressed as concatenations of meet and join operations corresponding to redundancies and synergies. For example, the atom α = {{1, 2}, {1, 3}} can be constructed as (1 ∨ 2) ∧ (2 ∨ 3), where the join operation (∨) can be thought of as denoting the union between sources (i.e., synergy), and the meet operation (∧) as the intersection between them (i.e., redundancy). Then, the involution introduced in Proposition 4 can be understood as switching meets for joins and vice-versa. For example</p><formula xml:id="formula_42">{{1, 2}, {1, 3}} † = ((1 ∨ 2) ∧ (2 ∨ 3)) † = (1 ∧ 2) ∨ (1 ∧ 3) (a) = 1 ∨ (2 ∧ 3) = {{1}, {2, 3}},</formula><p>where equality (a) uses the distributivity between meets and joins <ref type="bibr" target="#b31">[31]</ref>. This shows that the natural PID involution switches redundancy (i.e. easily accessible information, since it is contained in multiple sources) and synergy (i.e. difficult to access information, since one needs to observe multiple sources). Thus, the more easily an atom can be accessed, the more difficult it is to access its conjugate.</p><p>This PID involution leads to a natural conjugation between PID atoms, which we define next. Definition 4. The conjugate of a PID atom is given by</p><formula xml:id="formula_43">I f ∂ (X; Y ) † := I f † ∂ (X; Y ),<label>(B6)</label></formula><p>where f † is as defined in Prop. 4. Additionally, the conjugate of a linear combination of PID atoms ψ(X; Y ) =</p><formula xml:id="formula_44">f ∈Bn c f I f ∂ (X; Y ) is defined as ψ(X; Y ) † := f ∈Bn c f I f † ∂ (X; Y ).<label>(B7)</label></formula><p>We now prove Proposition 1, which states that applying PID conjugation on a conditional mutual information I(X a ; Y |X b ) leads to the same outcome as entropic conjugation does -namely, I(X a ; Y |X (a∪b) C ), where the complement is taken within the set of source variables. Please note that the proof uses no properties specific to particular instantiations of synergy or redundancy, and hence the result holds for any operationalisation of these quantities that are consistent with the PID framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof of</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix C: Analysis of spin systems</head><p>Our experiments considered systems of n spins X = (X 1 , . . . , X n ) ∈ {-1, 1} n following a Boltzmann distribution p X (x) = e -βH(x) /Z with a Hamiltonean of the form</p><formula xml:id="formula_45">H(x) = 2 n(n -1) n i=1 n j=i+1 x i x k J i,k ,<label>(C1)</label></formula><p>where the coupling coefficients J i,k are i.i.d. sampled from a Gaussian distribution with mean µ and variance σ 2 . The results reported in Fig. <ref type="figure" target="#fig_0">1</ref> corresponds to systems of n = 8 spins with β = 1, σ 2 = 2, and either µ = 5 (ferromagnetic), µ = 0 (weak), or µ = -5 (frustrated). Our analysis pipeline was structured as follows. We first computed the joint distribution of 10 systems of each type, and calculated the value of u k for each of them. The resulting values were then used to perform a principal component analysis. From this, we obtained the loadings of the two first principal components, denoted as ξ k and ν j , respectively. These loadings were then used to construct two high-order metrics, ϕ PC1 (X) := n-1 k=1 ξ k u k (X) and ϕ PC2 (X) := n-1 j=1 ν j u j (X), which corresponds to projecting the value of the u k 's onto the directions given by the principal components. Finally, these two resulting metrics were used to characterise the systems of interest.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FIG. 1 .</head><label>1</label><figDesc>FIG.1. Information-theoretic analysis of the interdependencies observed in systems of n = 8 spins subject to positive (ferromagnetic), negative (frustrated), and weak interactions between them. a) When calculating u k , each type of interactions exhibit distinct profiles of interdependence. b) The variability among u k is captured by two principal components: one of symmetric character which accounts for the overall strength of the interdependence (PC1), and one of skew-symmetric character that accounts for the balance between high-and low-order interdependence (PC2). c) The values of u k projected onto these PCs provide a simple characterisation of these three types of systems in terms of their overall interdependence strength (PC1) and the balance between high-and low-order effects (PC2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Th. 1 . 4 =f 2 =</head><label>142</label><figDesc>For a, b disjoint subsets of I n , thenI(X a ; Y |X b ) † lemma 2 = (a∪b)=1 &amp; f (b)=0 I f † ∂ (X; Y ) def. f † = f ((a∪b) C )=0 &amp; f (b C )=1 I f ∂ (X; Y ) = f (a∪(a∪b) C )=1 &amp; f ((a∪b) C )=0 I f ∂ (X; Y ) lemma I(X a ; Y |X (a∪b) C ),where the second to last equality follows because a ∪ (a ∪ b) C = b C if a and b are disjoint.</figDesc></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A: Short proofs</head><p>Here we present the proofs of our results. Some proofs use the quantities</p><p>H(X a ) for k = 0, 1, . . . , n, (A1) with r 0 (X) = 0. A direct calculation shows that</p><p>Moreover, we use the definition ∆ 2 r k := r k+1 +r k-1 -2r k and the fact that u k = -∆ 2 r k .</p><p>Proof of Prop. 1. Using the representation (A2), a direct calculation shows that</p><p>Proof of Lemma 1. The proof follows directly from Definitions 1 and 2.</p><p>Proof of Prop. 2. The expressions for each metric can be directly verified by leveraging the representation (A2) and using the definition of r k . The second part of the proposition follows then by using Lemma 1.</p><p>Proof of Th. 2. Let's denote as S = (ϕ + ϕ * )/2 and T = (ϕ -ϕ * )/2 the components proposed in the proposition, which can be directly shown to be symmetric and skew-symmetric and satisfying ϕ = S + T . Let's assume there is another decomposition ϕ = S ′ + T ′ where (S ′ ) * = S ′ and (T ′ ) * = -T * . However this would imply that ϕ + ϕ * = 2S ′ and ϕ -ϕ * = -2T ′ , which leads to S = S ′ and T = T ′ , showing that the decomposition is unique. The orthogonality of these subspaces follows directly from Lemma 1.</p><p>Using the representation (A2), one can re-write ϕ in terms of r k . Since every entropy term appears only in exactly one of the r k , there cannot be any term cancellations. Therefore, ϕ involves a linear number of (unconditional) entropy terms if and only if the resulting coefficients are non-zero only for r 1 , r n-1 , and r n .</p><p>Let us first consider the case in which c k = αk + β is linear on k. Then, one can show that</p><p>By using the fact that ∆ 2 r k = ∆r k+1 -∆r k where ∆r k := r k -r k-1 , one can use discrete calculus to find that</p><p>showing that ϕ only includes a linear number of entropies.</p><p>To prove the converse statement, let's consider a quantity ϕ = k c k u k , and let's denote its coefficients under r k and ∆r k as a k and b k respectively, so that ϕ = i a i r i = j b j ∆r j hold. As the r k are linearly independent, one can see that the above equations imply that the following conditions hold for all k = 1, . . . , n -2:</p><p>Now, note that a k = 0 with k ∈ {2, . . . , n -2} requires that b k = b k+1 , and hence the above condition forces b 1 = . . . = b n-1 . Then, applying the same reasoning shows that c k -c k+1 has to be constant, which proves that c k depends linearly on k.</p><p>The above shows that the space of metrics that can be computed with a linear number of terms is twodimensional, being spanned by DTC (α = 1, β = 0) and the S-information (α = 0, β = n). This space is also spanned by the S-information and the O-information, concluding the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B: PID conjugation</head><p>According to Eq. ( <ref type="formula">8</ref>), PID introduces a decomposition of the mutual information I(X; Y ) in terms of information atoms of the form I α ∂ (X; Y ), where α = {α 1 , . . . , α l } with α j ⊆ I n being sets of indices of the source variables X 1 , . . . , X n such that no α j contains another α k -making α an 'anti-chain' of sets of sources. Conceptually,</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>Rosas@sussex</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>ac.uk</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Battiston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Petri</surname></persName>
		</author>
		<title level="m">Higher-order systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">F</forename><surname>Battiston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cencetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Iacopini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Latora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Patania</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-G</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Petri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics reports</title>
		<imprint>
			<biblScope unit="volume">874</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">F</forename><surname>Battiston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Amico</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Barrat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bianconi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ferraz De Arruda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Franceschiello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Iacopini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kéfi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Latora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Moreno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Physics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">1093</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Battiston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Petri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Amico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Physics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">221</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Z</forename><surname>Cang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">2084</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Supek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lehner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">7051</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">M</forename><surname>Gatica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cofré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Mediano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Rosas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Orio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Diez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Swinnen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Cortes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain connectivity</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">734</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Luppi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Mediano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Rosas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Holland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Fryer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>O'brien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Rowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Stamatakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page">771</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">R</forename><surname>Herzog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Rosas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Whelan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fittipaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Santamaria-Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cruzat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Birba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moguilner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tagliazucchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurobiology of Disease</title>
		<imprint>
			<biblScope unit="volume">175</biblScope>
			<biblScope unit="page">105918</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Varley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Sporns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schaffelhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Scherberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page">2207677120</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Varley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Faskowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Sporns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications biology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">451</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Tax</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Mediano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shanahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Entropy</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">474</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Proca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Rosas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Luppi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Crosby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Mediano</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.02996</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Kaplanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mediano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Rosas</surname></persName>
		</author>
		<title level="m">NeurIPS 2023 workshop: Information-Theoretic Principles in Cognitive Systems</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Varley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bongard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chaos: An Interdisciplinary Journal of Nonlinear Science</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Luppi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Rosas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Mediano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Stamatakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Rosas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Mediano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Luppi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Varley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Lizier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Stramaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Marinazzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Physics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page">476</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">There are multiple &apos;directed&apos; high-order quantities that distinguish between predictor and target variables, which don&apos;t satisfy labelling-symmetry [32-34]. These quantities will be studied in a follow-up work using a formalism that extends the one presented here</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">W</forename><surname>Mcgill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the IRE Professional Group on Information Theory</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">93</biblScope>
			<date type="published" when="1954">1954</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">S</forename><surname>Watanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of research and development</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">66</biblScope>
			<date type="published" when="1960">1960</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">T</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Control</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page">337</biblScope>
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">G</forename><surname>Tononi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Sporns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Edelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page">5033</biblScope>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Rosas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Mediano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gastpar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page">32305</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Control</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page">133</biblScope>
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Beer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1004.2515</idno>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">M</forename><surname>Wibral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Priesemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Lizier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Phillips</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain and cognition</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page">25</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Mediano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Rosas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Luppi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Carhart-Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Seth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Barrett</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.13186</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Davey</surname></persName>
		</author>
		<title level="m">Introduction to Lattices and Order</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Gutknecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wibral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Makkeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Royal Society A</title>
		<imprint>
			<biblScope unit="volume">477</biblScope>
			<biblScope unit="page">20210110</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>Proceedings of the</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Gutknecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Makkeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wibral</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.00734</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">A</forename><surname>Jansma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Mediano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Rosas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2410.06224</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tononi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">1000091</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">N</forename><surname>Timme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Alford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Flecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Beggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computational neuroscience</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page">119</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Rosas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Mediano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gastpar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2404.07140</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
