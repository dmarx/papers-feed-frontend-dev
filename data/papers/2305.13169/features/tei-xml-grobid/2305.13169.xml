<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Pretrainer&apos;s Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, &amp; Toxicity</title>
				<funder ref="#_KVQwRFD">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2013">2013 2016 2019 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Shayne</forename><surname>Longpre</surname></persName>
							<email>slongpre@media.mit.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University</orgName>
								<address>
									<addrLine>3 Google Research 4 OpenAI</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gregory</forename><surname>Yauney</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University</orgName>
								<address>
									<addrLine>3 Google Research 4 OpenAI</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Emily</forename><surname>Reif</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University</orgName>
								<address>
									<addrLine>3 Google Research 4 OpenAI</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University</orgName>
								<address>
									<addrLine>3 Google Research 4 OpenAI</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University</orgName>
								<address>
									<addrLine>3 Google Research 4 OpenAI</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University</orgName>
								<address>
									<addrLine>3 Google Research 4 OpenAI</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University</orgName>
								<address>
									<addrLine>3 Google Research 4 OpenAI</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University</orgName>
								<address>
									<addrLine>3 Google Research 4 OpenAI</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kevin</forename><surname>Robinson</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University</orgName>
								<address>
									<addrLine>3 Google Research 4 OpenAI</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Mimno</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University</orgName>
								<address>
									<addrLine>3 Google Research 4 OpenAI</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daphne</forename><surname>Ippolito</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University</orgName>
								<address>
									<addrLine>3 Google Research 4 OpenAI</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Mit</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University</orgName>
								<address>
									<addrLine>3 Google Research 4 OpenAI</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Pretrainer&apos;s Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, &amp; Toxicity</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2013">2013 2016 2019 2022</date>
						</imprint>
					</monogr>
					<idno type="MD5">382A367B9EBB50446EC3CCB0C43B261E</idno>
					<idno type="arXiv">arXiv:2305.13169v2[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-02-21T16:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Pretraining is the preliminary and fundamental step in developing capable language models (LM). Despite this, pretraining data design is critically under-documented and often guided by empirically unsupported intuitions. To address this, we pretrain 28 1.5B parameter decoder-only models, training on data curated (1) at different times, (2) with varying toxicity and quality filters, and (3) with different domain compositions. First, we quantify the effect of pretraining data age. A temporal shift between evaluation data and pretraining data leads to performance degradation, which is not overcome by finetuning. Second, we explore the effect of quality and toxicity filters, showing a trade-off between performance on standard benchmarks and risk of toxic generations. Our findings indicate there does not exist a one-size-fits-all solution to filtering training data. We also find that the effects of different types of filtering are not predictable from text domain characteristics. Lastly, we empirically validate that the inclusion of heterogeneous data sources, like books and web, is broadly beneficial and warrants greater prioritization. These findings constitute the largest set of experiments to validate, quantify, and expose many undocumented intuitions about text pretraining, which we hope will help support more informed data-centric decisions in LM development.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The strong performance <ref type="bibr" target="#b15">(Chowdhery et al., 2022;</ref><ref type="bibr">Nostalgebraist, 2022;</ref><ref type="bibr">OpenAI, 2023;</ref><ref type="bibr" target="#b36">Google, 2023)</ref>, and emergent abilities <ref type="bibr" target="#b98">(Wei et al., 2022)</ref> of modern language models (LMs) depend on self-supervised pretraining on massive text datasets. All model developers implicitly or explicitly decide the composition of these datasets: what data sources to include, whether to filter for attributes such as quality and toxicity, and when to gather new documents. While many of the most prominent models do not document their curation procedures <ref type="bibr">(OpenAI, 2023;</ref><ref type="bibr" target="#b36">Google, 2023)</ref>, or only document which procedures they used <ref type="bibr">(Brown et al., 2020;</ref><ref type="bibr">Nostalgebraist, 2022;</ref><ref type="bibr">Scao et al., 2022;</ref><ref type="bibr" target="#b92">Touvron et al., 2023)</ref>, they rarely document why they chose those protocols or what effect they had. This documentation debt leaves practitioners to be guided by intuitions and precedents, neither thoroughly evaluated <ref type="bibr" target="#b6">(Bandy and Vincent, 2021;</ref><ref type="bibr" target="#b82">Sambasivan et al., 2021)</ref>. Given the outsized and fundamental role of pretraining data in modern LMs, we believe this neglectful practice has detracted from responsible data use and hampered effective model development <ref type="bibr" target="#b80">(Rogers, 2021;</ref><ref type="bibr" target="#b33">Gebru et al., 2021;</ref><ref type="bibr" target="#b9">Bender and Friedman, 2018)</ref>.</p><p>Among the small number of general-purpose LMs dominating community use and discussion, the prevailing focus has been on the scale of pretraining data and number of optimization steps <ref type="bibr">(Brown et al., 2020;</ref><ref type="bibr">Nostalgebraist, 2022;</ref><ref type="bibr" target="#b36">Google, 2023)</ref>. In this work, we systematically test how common data design decisions affect model performance-specifically: the time of collection, content filtering strategy (toxicity/quality), and domain composition. We study the impacts in two ways. First, we present observational measurements of the effect of existing quality and toxicity filtering methods (Section 3). We document how these filters affect a range of characteristics in two major pretraining datasets, C4 <ref type="bibr" target="#b78">(Raffel et al., 2020)</ref> and the Pile <ref type="bibr" target="#b29">(Gao et al., 2020)</ref>. Second, we rigorously evaluate these dataset design decisions on downstream tasks. This is done by evaluating decoder-only autoregressive LMs each pretrained on a dataset modified along one dimension of time, toxicity, quality, or domain composition. Our contributions are summarized as findings and recommendations to model developers.</p><p>The Age of a Dataset (Section 4). We see performance degradation if evaluation data is either before or after pretraining data collection, and this deficit isn't overcome with substantial finetuning. Further, this phenomenon is exacerbated in larger models. While rarely acknowledged, we show its effect can meaningfully complicate comparisons between new and old models, depending on the age of the evaluation dataset.</p><p>Quality and Toxicity Filters (Section 5). Filtering for document quality and toxicity have significant but opposite effects on model behaviour. Quality filtering, removing low-quality text, substantially increases both toxic generation and downstream performance across tasks we tested, despite reducing the amount of training data. On the other hand, removing toxic data trades-off fewer toxic generations for reduced generalization performance. Inverse toxicity filters, which remove the least toxic content, demonstrate targeted benefits. Lastly, evaluation on datasets with high quality text aren't necessarily improved by removing low-quality text from the dataset. Performance effects due to quality filtering are mostly positive, but the benefits are not predictable from text characteristics. These findings demonstrate that one size (filter) does not fit all, and there is a need for practitioners to develop more targeted quality or inverse toxicity filters for their tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Domain Compositions (Section 6).</head><p>The best performing domains comprise high-quality (Books) and heterogeneous (Web) data, corroborating <ref type="bibr">Brown et al. (2020)</ref>; <ref type="bibr" target="#b15">Chowdhery et al. (2022)</ref>; <ref type="bibr">Xie et al. (2023a)</ref>. However, these text sources contribute most to toxic generation. Still, we found that the benefits of training on these data sources is often greater than data collection for a targeted domain, and so recommend practitioners focus future collection on more books and diverse web data. Additionally, our best performing models still use all data sources (even at the relatively small scale of 1.5B parameters); thus, we recommend practitioners generously include data sources less relevant to their downstream tasks <ref type="bibr" target="#b65">(Madaan et al., 2022)</ref>.</p><p>To our knowledge, these experiments constitute the largest publicly documented LM data curation study, spanning 28 1.5B parameter models. Their findings empirically quantify, validate, and, occasionally, challenge the entrenched set of under-examined pretraining assumptions; which we believe justifies their computational cost (Section 8). As the majority of the community has adopted a small set of models for most research and applications (BERT, T5, GPT-2, GPT-3), pretraining data curation decision have long-term ramifications. We hope these results better inform model developers training the next wave of LMs.</p><p>Table <ref type="table">1</ref>: A list of well-known language models and a quantitative breakdown of their pretraining data, including represented domains; if the Pile or C4 are used, the percent of multilingual (M-L) data (meaning non-English and non-code); if Toxicity or Quality data filters were used, as either automatic Heuristics (H) or Classifiers (C); if the dataset is public <ref type="bibr">(Pub)</ref>, and what year the data was collected up to. If a dataset is "Part" public, then all of its constituent corpora are public, but not the final mixture. In Represented Domains, extended from <ref type="bibr" target="#b109">(Zhao et al., 2023)</ref>, Web includes the Common Crawl and other web scrapes; Dialog includes forum, social media and conversations; Academic includes research papers, textbooks, and mathematics.</p><p>Represented Domains (%) Filters Data Model Wiki Web Books Dialog Code Acad Pile C4 M-L Tox Qual Pub Year Bert 76 24 ✗ ✗ H Part 2018 GPT-2 100 ✗ ✗ H Part 2019 RoBerta 7 90 3 ✗ ✔ H Part 2019 XLNet 8 89 3 ✗ ✔ H Part 2019 T5 &lt;1 99 ✗ ✔ H H ✔ 2019 GPT-3 3 82 16 ✗ ✔ 7% C ✗ 2021 GPT-J/Neo 1.5 38 15 4.5 13 28 ✔ Part C ✔ 2020 GLaM 6 46 20 28 ✗ ✔ C ✗ 2021 LaMDA 13 24 50 13 ✔ ✔ 10% C C ✗ 2021 AlphaCode 100 ✗ ✗ H ✗ 2021 CodeGen 1 24 10 3 40 22 ✔ Part H Part 2020 Chinchilla 1 65 10 4 ✔ ✔ H C ✗ 2021 Minerva &lt;1 1.5 &lt;1 2.5 &lt;1 95 ✔ ✔ &lt;1% C ✗ 2022 BLOOM 5 60 10 5 10 10 ✔ ✔ 71% H C Part 2021 PaLM 4 28 13 50 5 ✗ ✔ 22% C ✗ 2021 Galactica 1 7 1 7 84 ✔ Part H Part 2022 LLAMA 4.5 82 4.5 2 4.5 2.5 Part ✔ 4% C Part 2020</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>We measure how pretraining data curation choices affect downstream performance. Figure <ref type="figure" target="#fig_0">1</ref> illustrates our approach: each experiment starts with a pretraining dataset, applies a filter that removes documents, pretrains a language model on the curated dataset, and finally evaluates the model on downstream tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Pretraining Datasets</head><p>We begin with two common, publicly available pretraining datasets: C4 <ref type="bibr" target="#b78">(Raffel et al., 2020)</ref> and the Pile <ref type="bibr" target="#b29">(Gao et al., 2020)</ref>. Both have received basic initial heuristic filtering for English language and content quality. We further deduplicate both datasets using the approximate deduplication method described in <ref type="bibr" target="#b55">Lee et al. (2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C4 (Raffel et al., 2020)</head><p>The English Colossal Clean Crawled Corpus (C4) is a snapshot of Common Crawl from 2019, which includes a mix of news, legal, wikipedia, and generic web documents <ref type="bibr" target="#b23">(Dodge et al., 2021)</ref>, filtered for well-formed English text. * While the original version of C4 filtered out any documents containing words from a "bad words list", our version does not. C4 remains one of the most widely adopted fully open source datasets for textual training, given its permissive license. It is a key component of many LMs, as shown in Table <ref type="table">1</ref>.</p><p>The Pile <ref type="bibr" target="#b29">(Gao et al., 2020)</ref> is an 800GB dataset consisting of data from 22 sources. These include a Common Crawl web scrape as well as more diverse collections of academic, books, coding, medical, legal and social sources (see Table <ref type="table">8</ref>), which more closely resemble the reported data sources in larger non-open source models like PaLM <ref type="bibr" target="#b15">(Chowdhery et al., 2022)</ref>, Chinchilla <ref type="bibr" target="#b41">(Hoffmann et al., 2022)</ref>, and the GPT-3 series <ref type="bibr">(Brown et al., 2020)</ref>. Note that the Pile's corpora composition was manually selected, and some options were excluded on the grounds of being too toxic or explicit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Data Curation Choices</head><p>We evaluate variations in the pretraining data based on three categories of interventions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset Age</head><p>We create new versions of C4 by regenerating snapshots of the Common Crawl from different years (see Figure <ref type="figure" target="#fig_0">10</ref>). Multiple time-based collections are not available for the Pile.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Domain Filtering</head><p>Both C4 and the Pile draw from multiple distinct data sources, but the Pile explicitly delineates 22 distinct sources from web pages, wikipedia articles, code repositories, online forums, legal texts, and research paper archives. To control for the topical content of the pretraining collection, we selectively remove documents from different domains (see Table <ref type="table">8</ref>).</p><p>Content Filtering Datasets derived from the Common Crawl and other weakly curated internet sources tend to contain large amounts of low-quality, toxic, or offensive content. As a result, curators often apply contentbased filters. Deciding what to include and what not to include is a challenging and context-dependent problem: A "high-quality" Reddit post does not look like a "high-quality" academic paper; and even with academic papers, quality measured by peer review has high variance <ref type="bibr" target="#b19">(Cortes and Lawrence, 2021)</ref>.</p><p>There are several approaches to determining document appropriateness. The simplest filters use features such as sentence length, presence of stopwords and punctuation, and repetitiousness to identify pages that do not contain usable text <ref type="bibr" target="#b77">(Rae et al., 2021;</ref><ref type="bibr" target="#b105">Yang et al., 2019;</ref><ref type="bibr" target="#b53">Laurençon et al., 2022;</ref><ref type="bibr" target="#b108">Zhang et al., 2022)</ref>. Negatively-defined filters identify a category of text to be removed, and assume that everything else is usable. For example, <ref type="bibr" target="#b78">Raffel et al. (2020)</ref> remove documents that contain words from a list of "bad words". Positively-defined filters identify a category of text to keep, and remove everything else <ref type="bibr" target="#b24">(Du et al., 2022;</ref><ref type="bibr" target="#b92">Touvron et al., 2023;</ref><ref type="bibr">Brown et al., 2020)</ref>.</p><p>In this work, we evaluate the impact of two document-level, classifier-based filters that have been used widely in the development of state-of-the-art language models. These include negatively-defined, toxic content (text that is profane, explicit, insulting, or threatening) and postively-defined quality content (text similar to known "high-quality" sources). It is important to emphasize that we do not have ground truth: for the purposes of this paper we will use the description toxic or quality to refer to a document that triggers one of these automated classifiers, not to indicate a document that achieves those characteristics for a human reader.</p><p>Quality Filters Most recent language models create quality classifiers to distinguish between "high-quality" corpora and other documents (Table <ref type="table">1</ref>). These are usually then applied to crawled web pages. Examples of high-quality reference corpora are (1) Wikipedia, WebText and books for <ref type="bibr">GPT-3 (Brown et al., 2020)</ref>, (2) Wikipedia, books and a few selected websites for PaLM <ref type="bibr" target="#b15">(Chowdhery et al., 2022)</ref> and GLaM <ref type="bibr" target="#b24">(Du et al., 2022)</ref>, and (3) pages used as references in Wikipedia for LLaMA <ref type="bibr" target="#b92">(Touvron et al., 2023)</ref>. In our work, we use the classifier employed by PaLM and GLaM, which assigns each document a score from 0 (high quality) to 1 (low quality). We experiment with removing documents that fall above four quality thresholds: 0.975, 0.95, 0.9, 0.7, along with an inverse filter that instead removes the highest quality documents below a threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Toxicity Filters</head><p>To identify toxic content, we use Jigsaw's Perspective API † , which was trained on comments from online forums and assigns toxicity scores based on whether annotators found the comment to contain profanity/obscenity, identity-based negativity, insults, or threats. While the Perspective API, as with any classifier, has been shown to be imperfect-it falsely labels some neutral text as toxic and its training data reflects the normative values of its annotators-it has been shown to be far more accurate than heuristic and rule-based classifiers <ref type="bibr" target="#b28">(Friedl, 2023;</ref><ref type="bibr" target="#b32">Gargee et al., 2022;</ref><ref type="bibr" target="#b56">Lees et al., 2022)</ref>.</p><p>The Perspective API outputs a score from 0 (unlikely to be toxic) to 1 (very likely to be toxic). The documentation recommends using a score threshold of anywhere from 0.3 to 0.9 to filter documents, depending on the practitioner's goals. ‡ We experiment with removing documents with scores above five different toxicity threshold values 0.95, 0.9, 0.7, 0.5, and 0.3. Documents above a given threshold are filtered out, along with an inverse filter that removes documents with the least predicted toxicity below a threshold.</p><p>In addition to the classifier-based filter, we also experiment with the n-gram based filter used by <ref type="bibr" target="#b78">Raffel et al. (2020)</ref> in the original version of the C4 dataset. This filter removes all documents that contain any word present in the "List of Dirty, Naughty, Obscene, or Otherwise Bad Words". §</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Evaluation</head><p>To measure the effects of time, topic and toxicity, we evaluate pretrained models on English-language tasks for toxicity identification, toxic generation, dozens of question-answering (QA) tasks from diverse domains, and several tasks with temporal annotations. In choosing evaluations, we compare the general utility of the different models, as well as their performance on tasks we expect to be influenced by the dataset characteristics being ablated. Since we are comparing the performance of different pretrained models, we evaluate the performance of each pretrained model on downstream tasks by finetuning the model on the relevant dataset for each task and evaluated on the same testing data (using the default splits for each task unless otherwise noted). As a result, any systematic differences between finetuned results can only be attributable to differences in pretraining. For all tasks we report mean performance relative to a baseline, usually the performance of models trained on an unfiltered dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluating Domain Generalization</head><p>We evaluate on the union of two question-answering benchmarks: Machine Reading for Question Answering (MRQA) <ref type="bibr" target="#b27">(Fisch et al., 2019)</ref> and UnifiedQA <ref type="bibr" target="#b47">(Khashabi et al., 2020)</ref>, which together consist of 30 unique QA datasets. These QA datasets span a range of domains, allowing us to measure the impact of topic alignment (see Table <ref type="table">9</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluating Temporal Misalignment</head><p>Prior work has shown that a dataset's collection time can affect the downstream model's abilities <ref type="bibr" target="#b54">(Lazaridou et al., 2021;</ref><ref type="bibr" target="#b1">Agarwal and Nenkova, 2022)</ref>. <ref type="bibr" target="#b64">Luu et al. (2021)</ref> release several datasets in which increasing temporal distance between finetuning and evaluation time decreases test performance. We choose 5 of these datasets from varying domains to evaluate whether a similar phenomenon exists between pretraining and evaluation time: PubCLS, NewSum, PoliAffs, TwiERC, and AIC.</p><p>Evaluating Toxic Generation Generateing profane, sexually explicit, insulting, or obscene text or text that attacks identity groups or targets protected human attributes limits the applications LMs may be used for <ref type="bibr" target="#b34">(Gehman et al., 2020)</ref>. We evaluate this behavior with language model prompts designed to elicit biased or toxic outputs related to gender, race, and religion <ref type="bibr" target="#b15">(Chowdhery et al., 2022)</ref>, and then measuring the fraction of generated continuations which are assigned a high toxicity score by the Perspective API (see Appendix C.3 for details). We also use the RealToxicityPrompts dataset <ref type="bibr" target="#b34">(Gehman et al., 2020)</ref>, which consists of text excerpts from the OpenWebText dataset <ref type="bibr" target="#b35">(Gokaslan* et al., 2019)</ref> that were labeled as toxic by the Perspective API.</p><p>Evaluating Toxicity Identification While some applications require LMs not to generate toxic text, in other applications it is important for LMs to recognize such language. Toxicity Identification has become particularly critical as a step in content moderation for major communication platforms <ref type="bibr">(NYT, 2020;</ref><ref type="bibr" target="#b88">Singh, 2019)</ref>. Definitions vary by setting, targeting hate speech, stereotypes, social bias, or some definition of toxicity.</p><p>We evaluate this ability with a variety of toxicity interpretations, using train and test sets from Social Bias Frames (SBF, <ref type="bibr" target="#b83">Sap et al., 2020)</ref>, DynaHate (DH, <ref type="bibr" target="#b93">Vidgen et al., 2021)</ref>, and Toxigen <ref type="bibr" target="#b40">(Hartvigsen et al., 2022)</ref>. ¶</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Models</head><p>For all our experiments, we use two sizes of decoder-only, Transformer-based language models, trained in the T5X codebase <ref type="bibr" target="#b79">(Roberts et al., 2022)</ref>. Our main experiments use LM-XL, a 1.5B parameter decoder-only model similar to the t5.1.1-XL architecture configuration trained with an autoregressive next-token-prediction objective. For experiments that measure scaling effects, we use LM-Small, a 20M parameter decoder-only model similar to the t5.1.1-small configuration. These configurations are popular, show decent performance <ref type="bibr" target="#b95">(Wang et al., 2022)</ref> and can generate text without additional finetuning. Additional details on pretraining and finetuning are available in Appendix C</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Impact of Data Curation on Data Characteristics</head><p>Section Findings</p><p>• The Pile's documents are on average longer, more readable and higher quality than documents in C4 but contain more personally identifiable information (PII).</p><p>• Books is an outlier domain, having the longest, most readable, most toxic, and most PII-filled documents, while also containing high-quality text.</p><p>• High toxicity and low quality documents have similarly high PII amounts but otherwise have very different average length and quality and toxicity levels.</p><p>• More recent web-scraped text is more diverse and less toxic but also lower quality.</p><p>Before evaluating the effect of data ablations on models, we present observational statistics on the pretraining datasets themselves. This analysis reveals how the Pile's domains compare to C4 and to one another, and how curation or filtering choices impact features of the data, sometimes inadvertently. We find that there are substantial interactions between curation choices.</p><p>We calculate a range of features for each document, including toxicity and quality metrics; categories of personally identifiable information (PII); and text statistics such as average word length, readability, typetoken ratio, and sentiment. For more details and analysis on these features see Appendix D.</p><p>C4 vs the Pile Figure <ref type="figure">9</ref> shows the differences between the two source datasets. Documents in the Pile are on average longer (2.4x), have more non-ASCII characters (1.9x) indicating greater linguistic range, and are also measured as higher quality (1.2x) and more readable (1.8x). Pile documents also contain more PII, in particular personal names, addresses, and emails.</p><p>Toxicity and Quality While it is reasonable to assume that high toxicity should correlate with low quality, Figure <ref type="figure" target="#fig_1">2</ref> shows that the relationship is more complicated: in fact, toxicity and quality are not well-aligned with one another. High toxicity documents have higher text quality than low toxicity documents. There is also little discernible difference in feature measurements for profanity, toxicity, and sexually explicit content between content classified as low vs. high quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Domains</head><p>Looking at characteristics of the Pile by domain in Figure <ref type="figure" target="#fig_1">2</ref> suggests an explanation. The Books subset stands out as having substantially more profane, toxic, and sexual content, but also greater predicted quality. While we might expect books to be high quality, in the sense that they typically contain meaningful, well-edited sentences, they also contain strong language and erotic subjects. This may also explain why documents classified as high toxicity in both C4 and the Pile are much longer (2.5x and 3.5x respectively), more profane (5x and 4.4x), sexually explicit (4.6x and 4.2x), and toxic (3.6x and 3.5x). However, Pile documents with high toxicity are 1.4-1.9 times more likely to have PII of various kinds, while in C4 this is not true. Documents classified as high quality in C4 were longer (1.3x and 1.2x), and had more names (1.6x and 1.8x), but fewer emails, addresses, and phone numbers.</p><p>CC Open-Web Wiki Pub-Med Books Code Academic Legal Social C4 Profanity 0.11 1.0x 1.0x .5x .7x 4.3x 1.4x 1.6x .6x 1.7x .9x Toxicity 0.15 1.1x 1.2x .6x .7x 3.5x 1.0x .9x .7x 1.6x 1.1x Sexually Explicit 0.12 1.0x 1.0x .8x 1.0x 4.1x 1.1x 1.4x .8x 1.3x 1.0x Text Quality 0.31 1.2x 1.8x 3.0x .3x 1.9x .3x .3x 1.0x .9x .8x Has Person Name 0.41 1.3x 1.7x 1.7x .3x 2.4x .2x 1.5x 1.0x 1.2x .9x Has Email 0.03 1.4x 1.4x .5x .0x &gt;5x .7x 4.1x .1x 1.9x .9x Has Address 0.04 .7x .4x .7x .6x &gt;5x 1.0x &gt;5x 3.8x .7x .6x Has Phone 0.02 1.5x 1.1x .0x .3x &gt;5x .6x .9x .6x 2.3x 1.4x Number Of Characters 6154 .7x .6x .5x 1.0x &gt;5x .6x &gt;5x 1.5x 2.7x .4x Type Token Ratio 0.49 1.1x 1.1x 1.1x 1.0x .2x .8x .6x .8x 1.0x 1.2x % Non-Ascii Characters 5.67e-03 .5x 3.7x .5x .1x .6x 1.1x .3x .2x 1.9x .5x % All Caps 0.03 .8x .8x .6x 1.2x .8x 1.3x 1.3x 1.1x 1.4x .8x Sentiment 0.97 1.1x .9x 1.0x 1.0x 1.0x .9x 1.0x .9x 1.0x 1.2x Readability 18 .6x .7x .8x .8x .5x 2.1x .8x .7x 1.0x .5x Domains in The Pile (a) Domains Low Toxicity High Toxicity High Quality Low Quality 0.10 .6x 5.0x 1.1x .9x 0.16 .7x 3.6x 1.1x .9x 0.12 .6x 4.6x 1.0x 1.0x 0.26 1.0x 1.2x 1.6x .1x 0.37 1.0x 1.5x 1.3x .6x 0.03 1.0x .9x .9x 1.2x 0.02 1.0x 1.1x .8x 1.3x 0.03 1.0x .8x .7x 1.5x 2592 .8x 2.5x 1.2x .6x 0.58 1.0x .9x 1.0x 1.1x 2.91e-03 1.0x 1.3x 1.2x .8x 0.02 1.0x 1.2x 1.0x 1.1x 1.16 1.0x .9x .9x 1.1x 10 1.0x .8x 1.0x 1.0x C4 (b) Toxicity/quality in C4 Low Toxicity High Toxicity 0.11 .7x 4.4x 0.15 .8x 3.5x 0.12 .7x 4.2x 0.31 1.0x 1.1x 0.41 1.0x 1.5x 0.03 1.0x 1.5x 0.04 .9x 1.9x 0.02 1.0x 1.4x 6154 .8x 3.5x 0.49 1.0x .8x 5.67e-03 .8x .6x 0.03 1.0x 1.0x 0.97 1.0x .9x 18 1.0x .8x</p><p>The Pile Among the domains we studied, OpenWeb provides the most lexical and linguistic diversity, with the highest non-ASCII characters and type-token ratio. Wikipedia presents the highest quality text, before Books and OpenWeb. Technical domains such as PubMed, Code, and Academic score low on predicted quality, indicating that overly-specific positively-defined filters on web documents may remove substantial amounts of potentially useful specialized text.</p><p>Time Comparing across different collection times of C4 (in Figure <ref type="figure">9</ref>), we see a couple of steady trends. The percentage of non-ASCII characters increased steadily in more recent years while the measured text quality declines. This growth may be due to increasing non-English content, but could also correspond to rising use of emojis and non-ASCII punctuation. Toxicity scores also decrease slightly in later years, while sentiment increases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Impact of Dataset Age on Pretrained Models</head><p>Section Findings</p><p>• Both models and evaluation datasets become stale.</p><p>• Temporal misalignment between pretraining and evaluation data is not overcome by finetuning.</p><p>• Temporal misalignment complicates evaluation of models trained at different times, as older evaluation datasets may become stale and newer evaluation datasets may under-estimate performance of older models.</p><p>• The effects of pretraining misalignment are stronger for larger models than smaller models.</p><p>While models are frequently and cheaply updated with new finetuning data, the expense of pretraining means the NLP community has relied on relatively few static pretrained models that are rarely updated or exchanged. BERT, RoBERTa, GPT-2, and T5 variants, all pretrained prior to 2020, constitute the majority (estimated at ~58% as of April 16, 2023) of all models downloaded on HuggingFace. Prior work demonstrates that language use changes over time <ref type="bibr" target="#b3">(Altmann et al., 2009;</ref><ref type="bibr" target="#b51">Labov, 2011)</ref> and that temporal misalignment between finetuning and evaluation datasets correlates with degraded performance, visible across settings and domains <ref type="bibr" target="#b64">(Luu et al., 2021;</ref><ref type="bibr" target="#b54">Lazaridou et al., 2021;</ref><ref type="bibr" target="#b1">Agarwal and Nenkova, 2022;</ref><ref type="bibr" target="#b44">Jang et al., 2022)</ref>. In contrast, we examine the effect of temporal misalignment between pretraining data and evaluation. In evaluating the impact of pretraining time across data domains, we can quantify the impact this design choice has on NLP broadly.</p><p>2010 2012 2014 2016 2013 2016 2019 2022 Pretrain Years 78.9 79.2 78.5 75.1 76.8 78.7 79.0 76.3 75.0 76.3 77.1 73.2 74.0 75.7 76.8 73.4 PubCLS 2010 2012 2014 2016 2013 2016 2019 2022 23.6 32.1 27.7 17.9 23.3 32.0 27.9 19.1 22.8 31.2 27.4 18.1 22.7 31.2 27.4 17.8 NewSum 2014 2015 2016 2017 2018 2019 2013 2016 2019 2022 85.0 84.9 84.9 82.7 83.1 83.5 85.2 84.8 85.9 83.1 83.4 83.4 84.6 84.4 84.6 84.0 83.8 84.6 82.7 83.7 84.4 82.9 82.7 83.6 TwiERC 2014 2015 2016 2017 2018 2019 Eval Years 2013 2016 2019 2022 Pretrain Years 98.2 98.0 95.0 91.3 94.4 88.7 98.1 98.2 95.2 93.1 95.1 88.5 97.8 98.7 93.9 93.4 96.0 90.5 97.6 98.4 94.4 91.4 95.1 89.0 AIC 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 Eval Years 2013 2016 2019 2022 82.7 89.0 91.2 71.2 70.8 74.7 71.5 82.0 82.2 74.9 80.4 88.1 90.6 70.9 72.3 75.8 72.6 82.2 82.4 76.0 80.2 87.8 90.7 70.4 72.0 75.8 73.4 83.1 82.8 75.9 79.4 87.1 89.4 70.8 71.4 75.0 71.0 82.5 83.3 76.8 PoliAff Figure 3: Temporal Misalignment between Pretraining and Evaluation causes performance degradation. Four LM-XL's, each pretained on a different C4 time split, are evaluated on each time split across five datasets. Heatmap colors are normalized by column, following Luu et al. (2021) to show the best pretraining year for each evaluation year.</p><p>We pretrain four autoregressive language models on versions of <ref type="bibr">C4: 2013, 2016, 2019, and 2022.</ref> For each version we begin with Common Crawl data and remove all data that was scraped after the cutoff year. Following <ref type="bibr" target="#b64">Luu et al. (2021)</ref>, we measure the effect of temporal misalignment by using evaluation tasks (from News, Twitter, and Science domains) that have training and test sets split by year. After pretraining, we finetune each model on each dataset's training-year split separately, then evaluate on every test-year split.</p><p>Full details and results are in Appendix C.4 and Appendix E.1, respectively.</p><p>First, we replicate the performance degradation observed by <ref type="bibr" target="#b64">Luu et al. (2021)</ref> due to finetuning and evaluation misalignment on the five tasks in Figure <ref type="figure" target="#fig_8">12</ref>. Next, we estimate the effects of temporal misalignment between pretraining and evaluation (Figure <ref type="figure">3</ref>). Since all models were finetuned on the training sets of the evaluation tasks, we show that temporal misalignment during pretraining persists even with temporally-relevant finetuning data.</p><p>-8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 12</p><p>Pretrain Year -Evaluation Year Performance degradation strongly correlates with pretraining misalignment and its effects are non-trivial. <ref type="bibr" target="#b64">Luu et al. (2021)</ref> formalize a definition for Temporal Degradation (TD), which measures the performance change observed from one year difference between the finetuning and evaluation years. We generalize TD to also measure the effect of one year difference between pretraining time and evaluation time, as described in Appendix C.4. Furthermore, we measure the Pearson correlation r between the performance difference and the temporal difference to understand the strength of the correlation. In Table <ref type="table">2</ref> we find temporal degradation is highest for finetuning (2.8 on average), as expected, but also surprisingly high for one year of pretraining (0.4)-particularly for the News domain. The average Pearson correlation of 0.61 indicates a strong correlation between pretraining temporal misalignment and performance degradation. All five tasks pass a one-sided Wald test with p &lt; 0.05, validating the slope is greater than zero.</p><p>Finetuning Pretraining LM-Small LM-XL LM-Small LM-XL Domain Task TD r TD r TD r TD r News PubCLS 5.82 0.84 5.63 0.80 0.02 0.01 † 0.59 0.67 NewSum 0.80 0.82 2.91 0.92 -0.31 -0.29 0.73 0.45 Twitter PoliAff 3.74 0.84 4.93 0.89 0.50 0.21 0.28 0.56 TwiERC 0.49 0.73 0.53 0.82 0.05 0.27 0.23 0.72 Science AIC 0.94 0.83 0.24 0.36 0.11 0.18 † 0.23 0.66 Mean 2.36 0.81 2.84 0.76 0.08 0.07 0.41 0.61</p><p>Table <ref type="table">2</ref>: Temporal Degradation (TD) measures the expected performance degradation from one year of temporal misalignment. We report TD first between finetuning and evaluation, then pretraining and evaluation, for LM-XL and LM-Small, across five tasks. Pearson correlation r indicates the correlation strength between performance and temporal change. Temporal Degradation due to pretraining is significant and persistent across domains. All correlations are significant at p &lt; 0.05 unless marked with † .</p><p>Pretraining misalignment is not overcome by significant finetuning. The temporal degradation due to pretraining suggests models pretrained on data from the same time frame as target evaluations will have advantages over models trained on much older or newer data. Notably, this effect is observed for models which are finetuned on the full temporally-relevant training sets. This suggests that even substantial finetuning cannot overcome pretraining data that is temporally misaligned.</p><p>Pretraining misalignment effects are asymmetric and have implications for NLP evaluations. We observe performance degradation regardless of whether the pretraining data was collected before or after the evaluation data. While we would not expect a 2019 checkpoint to perform well on questions about COVID, we also find that 2022 checkpoints perform less well on Obama-era evaluations than earlier models. In particular, Figure <ref type="figure" target="#fig_2">4</ref> shows performance degradation is asymmetric: it is steeper when the evaluation year is after the pretraining year (blue bars) as opposed to the reverse (red bars). This finding suggests that both models and evaluations become stale: older models perform less well than newer models on new evaluations and newer models will perform less well on older evaluations. This phenomenon may have subtle implications for NLP experiments comparing models pretrained at different times. For instance, newer evaluation sets may appear much more difficult than old evaluation sets when applied to established, but less fresh, models.</p><p>Similarly, older evaluations may underestimate the capabilities of newer models.</p><p>Temporal Degradation is greater for larger models We find more temporal degradation for LM-XL (1.5B parameters) than for LM-Small (20M parameters). As shown in Table <ref type="table">2</ref>, we do not find the same temporal degradation effects of pretraining were significant for LM-Small models. This suggests that larger models may have a greater sensitivity to temporal information than smaller models, which may not have the capacity to take advantage of subtle temporal features at all. Full results for LM-Small experiments are provided in Appendix E.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Impact of Quality &amp; Toxicity Filters on Pretrained Models</head><p>Section Findings</p><p>• Quality and toxicity filters have very different effects.</p><p>• Quality filters improve performance significantly, despite removing training data.</p><p>• Quality filtering effects are not easily predicted by dataset characteristics. Future filters should weigh more than one dimension of quality.</p><p>• Toxicity filtering trades off generalization and toxicity identification ability for reduced risk of toxic generation.</p><p>• When optimizing for toxicity identification tasks, practitioners should use an inverse toxicity filter.</p><p>Most modern large language models use some form of quality and/or toxicity filtering for their pretraining datasets (Table <ref type="table">1</ref>). To curb toxicity, T5 uses n-gram filters, Gopher and Chinchilla use SafeSearch filters, and LaMDA uses "safety discriminators". Quality heuristics are universally applied for web-scraped data, with newer models like LLaMA, the GPT-series and the PaLM-series all relying on quality classifiers. To compare and quantify the effects of these two filter types, we implement quality and toxicity filters at various thresholds, as described in Section 2.2, to vary the quantity of toxic and low-quality text present when pretraining models on the Pile and C4.</p><p>Quality filters significantly improve performance across nearly all tasks, despite reducing training data quantity and variety. We see the quality filters improve nearly all downstream tasks: toxicity identification by 2% (Figure <ref type="figure">5</ref>, right) and most QA task categories by 1-6% (Figure <ref type="figure">6</ref>). Of most interest, these improvements are realized despite removing 10%+ of the training data, even though we find that removing data usually leads to a decrease in performance (Section 6). While the average performance peaks at T = 0.975 for the QA tasks, greater quality filtering still outperforms the unfiltered baseline on average. For the toxicity identification experiments, the performance is still improving after T = 0.7, where 55% of the dataset has been filtered out.</p><p>60% 50% 40% 30% 20% 10% 0% 10% 20% Toxic Generation Score 6% 4% 2% 0% 2% Toxicity Identification Score Full Dataset Toxicity Filtering, LM-XL C4 Inverse Filter T=0.7 T=0.5 T=0.3 Most Filtering T=0.95 T=0.9 more toxic less toxic 2% 0% 2% 4% 6% 8% 10% 12% 14% Toxic Generation Score 2% 1% 0% 1% 2% 3% Toxicity Identification Score Full Dataset Quality Filtering, LM-XL C4 Inverse Filter T=0.9 T=0.7 Most Filtering T=0.975 T=0.95 more toxic less toxic Dataset quality characteristics are not strongly indicative of filtering effects. In Section 3, Books, Wikipedia, and Web data are classified as highest quality. Figure <ref type="figure">6</ref> shows that despite this, quality filtering provides the least benefit to QA tasks in these categories, even hurting the performance for Books. On the other end, academic and biomedical data are ranked among the lowest quality, but their QA tasks benefit the most from quality filtering.</p><p>Optimizing on one measure of quality is not sufficient to predict or improve performance across domains.</p><p>Most interestingly, Wikipedia and Web QA tasks are among the most hurt by the inverse filter-suggesting these domains are not affected as much by the absence of the lowest quality data as the presence of the highest quality data. Also unexpectedly, both the quality and inverse quality filters led to models with higher toxic generation tendencies (Figure <ref type="figure">5</ref>, right)-the one dimensional measure of quality captured by the quality scores is not sufficient to explain this behaviour. In other words, different segments of data along this classifier's quality spectrum can have strong but varied effects on different domains. It suggests practitioners should move beyond one measurement of quality and consider multiple.</p><p>One size does not fit all. Toxicity Filtering leads to a trade-off between toxic identification and toxic generation goals. Filtering using a toxicity classifier, we find a trade-off: models trained from heavily filtered pretraining datasets have the least toxic generation but also the worst toxicity identification (Figure <ref type="figure">5</ref>, left). Similarly, Figure <ref type="figure" target="#fig_4">7</ref> shows the performance of QA tasks unrelated to toxicity are hurt by toxicity filtering, though this may be due to the overall decrease in training data. Ultimately, the intended behaviour of the model should inform the filtering strategy, rather than one size fits all. Most interesting of all, the strongest performance on toxicity identification for every dataset comes from the inverse toxicity filter. Practitioners optimizing for performance on toxic domains should intentionally apply inverse filters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Impact of Domain Composition on Pretrained Models</head><p>Section Findings</p><p>• Inclusion of Common Crawl, OpenWeb and Books have the strongest positive effects on downstream performance. Data source heterogeneity is more important than data quality or size.</p><p>• Targeted data helps targeted evaluations, but not always as much as including heterogeneous web domains.</p><p>• It is beneficial to include as many pretraining data sources as possible.</p><p>As shown in Table <ref type="table">1</ref>, pretraining datasets seek to generalize to a wide array of downstream tasks by combining data from a diverse set of domains. How does the choice of pretraining source domains impact downstream performance? We empirically answer this question by ablating pretraining sources from the Pile one-at-a-time and measuring the downstream performance change in 27 QA tasks from diverse domains.</p><p>We first group the Pile data sources into nine domains representing conceptual sources that practitioners could choose to license or scrape more of: Common Crawl (CC), OpenWeb, Wikipedia, Books, PubMed, Academic, Code &amp; Math, Legal, and Social (see Table <ref type="table">8</ref>). These are sorted in ascending order by size. We choose to maintain the size disparities in these sources, simply because they reflect reality: curated Wikipedia content is innately finite, while web and books are much more abundant. We then pretrain LM-XL with the full dataset minus each category, yielding nine models, then finetune each for QA using Natural Questions. Finally, we evaluate the model on 27 unique datasets from MRQA <ref type="bibr" target="#b27">(Fisch et al., 2019)</ref> and UnifiedQA <ref type="bibr" target="#b47">(Khashabi et al., 2020)</ref> that have also been partitioned into domains. Full details are documented in Appendix C.5.</p><p>Common Crawl, OpenWeb, and Books have the strongest positive effects on downstream performance. largest chunk of text in the Pile, Books and OpenWeb are smaller but provide the most heterogeneous and predicted-quality content (see Section 3). These results suggest that more data is not necessarily as important a factor as a combination of heterogeneity and quality.</p><p>Domain heterogeneity is often more beneficial than targeted data, even for targeted evaluations. Ablating a pretraining domain has varying effects on downstream QA performance. Predictably, performance degrades when we remove domains with close alignment between the pretraining and downstream data sources: removing PubMed hurts the BioMed QA evaluations, dropping Wikipedia hurts the Wikipedia benchmarks, and removing web content hurts web evaluations. However, removing targeted domains does not necessarily have as significant an effect on related downstream domains as removing the large heterogeneous domains. For instance, removing CC from the pretraining dataset reduces performance on downstream Academic QA tasks to a much greater extent than removing the Academic domain. Our hypothesis is that CC, OpenWeb and Books contain extensive coverage of many topics, so removing the Academic-specific category of sources does not remove all relevant academic information.</p><p>The best performing models use all the pretraining data sources. Despite the importance of data heterogeneity, the best mean performance still comes from models that train on all, or nearly all, the data. The exceptions are the removal of targeted source domains like the Pile's Code or Academic (advanced science and math journals) domains. These are both large but perhaps not well matched with the QA evaluation sets, which do not require coding skills or scientific rigour beyond that found on Wikipedia and from web-based sources. This finding suggests that both the quantity and diversity of open source data remain a bottleneck for current pretraining methods.</p><p>Web and Books domains cause the biggest trade-off between toxic identification and generation. We next consider whether reducing a model's pretraining exposure to toxic content affects either its propensity to generate toxic language or its ability to identify toxic language. Table <ref type="table">3</ref> shows that the largest decreases in both toxicity generation and identification were caused by removing CC (26.9% of the data), OpenWeb (6.9%), and Books (6.9%). This is consistent with the observation that Web and Books data had the highest concentration of text predicted to be toxic Section 3. These results suggest a trade-off: better performance on QA (Section 6) and toxicity identification comes at the cost of more toxic generation.</p><p>Table 3: Effect of the Pile's domain composition on toxicity identification and generation. Removing Books, CommonCrawl and OpenWeb lead to the greatest decrease in toxicity metrics. Removing Wikipedia had a strong increase in toxicity generation. Filter % Data Toxicity Identification (↑) Toxic Generation (↓) SBF Toxigen DH R3 DH R4 Score RTP-T RTP-NT RepBias Score Full Dataset 100.0 90.7 90.8 88.7 84.1 0.0 88.9 45.4 4.6±0.7 0.0 No Social 98.8 90.9 91.0 87.8 84.9 +0.1 85.4 47.2 4.7±0.8 +0.4 No Wiki 97.9 90.6 90.8 88.1 83.6 -0.4 89.0 49.4 4.8±0.6 +4.2 No Books 93.1 89.9 90.3 87.1 82.6 -1.3 87.4 43.5 4.0±0.8 -6.2 No OpenWeb 93.1 89.9 90.3 86.4 82.5 -1.5 88.0 42.1 4.3±0.6 -5.2 No Legal 91.0 90.9 90.8 88.1 83.0 -0.4 88.2 46.1 4.7±0.8 +0.8 No Academic 87.1 90.7 91.0 88.2 84.5 +0.0 86.5 46.4 4.5±0.7 -1.2 No Pubmed 85.1 90.6 90.8 88.0 84.3 -0.2 87.6 46.3 4.6±0.7 -0.2 No Code 80.9 91.0 91.2 88.5 84.5 +0.2 87.6 46.5 4.7±0.7 +0.6 No CC 73.1 89.9 90.0 85.3 82.4 -1.9 87.8 46.2 4.3±0.6 -2.1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion</head><p>Guided by intuition: undocumented &amp; unknown Pretraining dataset curation has been guided by intuitions: collections should be large, diverse, and high quality. Decisions are often driven by the need for something "good enough" or by precedents that may themselves not have been thoroughly evaluated <ref type="bibr" target="#b82">(Sambasivan et al., 2021)</ref>. Similarly, model developers occasionally neglect to share empirical insights, maintaining a knowledge gap, often referred to as "documentation debt" <ref type="bibr" target="#b6">(Bandy and Vincent, 2021)</ref>.</p><p>Our results show that choices made in pretraining curation affect models in significant ways that cannot be easily erased by subsequent finetuning. We urge both model producers and model users to think of dataset curation policies as a form of hyperparameter, much like learning rates or network dimensions. Exhaustive search methods that work for single scalar values will not, however, scale to curation policies that affect terabytes of data. While our results are necessary to establish that pretraining curation matters, they are not sufficient to answer all questions. In this section we therefore make specific recommendations, but our primary result is that we need better tools for modeling the relationship between data and model capabilities.</p><p>Age of the pretraining corpus. In an ideal world, models would be continuously re-trained on the most up-to-date data available. However, given the expense of data collection and re-training, model creators must make a choice between efficiency and model staleness. More subtly, we also find that using newer data can add a "presentist" bias when evaluating retrospective tasks. The effect of staleness is not overcome even by plentiful finetuning data for the given task, and this effect is worse for the larger, more capable models. This result complements findings by <ref type="bibr" target="#b85">Schulman (2023)</ref> that finetuning on newer data can aggravate hallucination for new data that is not well-grounded at pretraining time. These tentative findings suggest the temporal properties of pretraining corpora are increasingly essential to consider for larger models, for more novel tasks (less finetuning data), and for instruction tuning models. Current practice includes augmenting prompts with retrieved, recent data to help overcome stale pretraining data. While this can conceivably help mitigate staleness, retrieving relevant text is a challenge in its own right.</p><p>We recommend model creators report the temporal distribution of pretraining data, which is not currently standard practice <ref type="bibr" target="#b41">(Hoffmann et al., 2022;</ref><ref type="bibr" target="#b91">Thoppilan et al., 2022;</ref><ref type="bibr" target="#b4">Anthropic AI, 2023;</ref><ref type="bibr" target="#b18">Cohere AI, 2023)</ref>. Users should be able to predict otherwise unforeseen performance degradations on much newer datasets, or be aware of the potential side effects of finetuning models on information not covered in pretraining.</p><p>Data source composition. Decisions on the composition of a corpus intended for pretraining can have substantial impacts on downstream performance. Of the two corpora we consider in this paper, C4 contains only one data source, a single scrape of the Common Crawl, while the Pile is a collection of 22 data sources.</p><p>It is more complex and costly to assemble a corpus which contains diverse sources, writing styles, and thematic areas. Achieving this diversity might also leave models vulnerable to less careful curation or gaps in practitioner knowledge.</p><p>In our experiments, we ablate the Pile by systematically omitting each of its constituent datasets before pretraining, and then measuring the impact on standard benchmarks. Our results suggest that practitioners should not omit any data sources if generalization to as many text-to-text tasks is the goal, and that future work should focus on collecting more diverse web and books content, which yield the largest benefits. These findings are somewhat consistent with hypotheses that the volume of training data remains a limiting factor, especially given licensing constraints <ref type="bibr">(Nostalgebraist, 2022)</ref>.</p><p>Filtering for toxicity and quality. The Common Crawl contains an enormous amount of low quality (advertisements, repetitive, non-human-readable, etc.) and toxic text. Many state-of-the-art language models filter out this text before training, either using bad words lists <ref type="bibr" target="#b78">(Raffel et al., 2020)</ref>, heuristics, or classifiers <ref type="bibr" target="#b24">(Du et al., 2022;</ref><ref type="bibr">Brown et al., 2020;</ref><ref type="bibr" target="#b15">Chowdhery et al., 2022)</ref>. Deciding on how much and what kind of text to filter out requires non-trivial normative decisions, and all of these filtering approaches involve the model creator intentionally modifying the bias of their datasets and thus their models.</p><p>In our experiments, we expose an implicit trade-off between a model's generalization abilities and its tendency to generate toxic content. This behavior is modulated by quality and toxicity filters. In fact, over-sampling on more toxic documents leads to the best performance on toxic identification. This observation, coupled with evidence that recent work is using post-hoc methods to curb unwanted toxic generation (e.g. instruction tuning <ref type="bibr">(Chung et al., 2022)</ref> or steerable decoders <ref type="bibr" target="#b20">(Dathathri et al., 2020;</ref><ref type="bibr" target="#b99">Welbl et al., 2021)</ref>), suggests practitioners should prioritize toxic identification rather than curbing toxic generation abilities during pretraining.</p><p>We find that our quality filter (the same used by PaLM, trained to keep content resembling Wikipedia and Books) significantly improves performance across domains, despite removing large portions of the training data. Perplexingly, the Books domain is the one exception to the above observation, as its content ranks among the highest quality. In general, observational quality characteristics of the data are not sufficient to predict which domains will benefit most from quality filtering. Our analysis suggests that performance on a task/domain is not influenced only by how much poor quality data (i.e. that which is unlike Wikipedia/Books) is removed, but also by other aspects of quality, such as how much of the highest or mid-quality data is represented along this specific measurement dimension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Limitations Compute Expense &amp; Single Shot Experiments</head><p>To our knowledge, this is the largest publicly documented LM pretraining data ablation study, spanning 28 1.5B parameter models-training more models with different data variants from scratch than GLaM <ref type="bibr" target="#b24">(Du et al., 2022)</ref>, miniBertas <ref type="bibr" target="#b97">(Warstadt et al., 2020)</ref>, MultiBerts <ref type="bibr" target="#b86">(Sellam et al., 2022)</ref>, and even Pythia <ref type="bibr" target="#b10">(Biderman et al., 2023)</ref>, which focuses on preserving data composition and order. It is important to acknowledge each of these pretrainings, with their corresponding finetuning and evaluations is computationally and environmentally costly. With this in mind, we made the careful decision on what experiments to pursue-narrowing our list to: age of the corpora, quality filters, toxicity filters, and the choice of source domains. We carefully curated the choice of experiments in advance, without the luxury of multiple rounds of reflection and repetition, common in many NLP experimental settings. As a result, we struck a balance as best we could between the computational costs, and reproducible validity. We hope to justify the merits of our selection and also point out the surprises that motivate future work or a deeper look into the results.</p><p>Blackbox APIs An additional limitation is our use of Perspective's API for evaluating the toxicity of generations. While most of our toxicity filters and evaluations were in a compressed time period, Pozzobon et al. ( <ref type="formula">2023</ref>) have since demonstrated the irreproducibility of black-box APIs, which may have shifting implementations over time. We also believe that while this is the standard procedure for popular toxic generation benchmarks like RealToxicityPrompts, the reliance on APIs and narrow evaluation setting can have limited implications for toxic generation in real applications. For the time being, these are the best proxies we have.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>English vs Multilingual Data</head><p>Our analysis was limited to two English datasets. It's important to note that training composition is an even more crucial question for multilingual and non-English models, where optimally balancing corpora from different languages and finding large-enough high-quality corpora can be very challenging <ref type="bibr">(Chung et al., 2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relevance to Zero-&amp; Few-Shot Prompted Settings</head><p>Our experiments focus on finetuned settings rather than zero-or few-shot prompting. This choice is motivated by finetuning being more applicable for 1.5B parameter models and also in many applied settings. We cannot establish how well these findings translate to prompted settings (without finetuning), but suspect they are strong correlated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Related Work</head><p>Pretraining Dataset Curation There have been dozens of general-purpose models trained for natural language understanding and generation tasks. Early models in this space, such as ELMO <ref type="bibr" target="#b73">(Peters et al., 2018)</ref>, BERT <ref type="bibr" target="#b21">(Devlin et al., 2019)</ref>, and BERT's various descendants <ref type="bibr" target="#b58">(Liu et al., 2019;</ref><ref type="bibr" target="#b52">Lan et al., 2020)</ref>, focused on strong finetuning performance for a variety of natural language inference tasks, as well as semantically meaningful language embeddings. These systems were trained on semi-curated datasets such as Wikipedia, BookCorpus <ref type="bibr" target="#b110">(Zhu et al., 2015)</ref>, and news articles from the One Billion Word Benchmark <ref type="bibr" target="#b13">(Chelba et al., 2013)</ref>. XLNet <ref type="bibr" target="#b105">(Yang et al., 2019)</ref> broke away from this use of curated datasets to include documents from Common Crawl into their pretraining dataset. T5 <ref type="bibr" target="#b78">(Raffel et al., 2020)</ref>, which introduced the C4 dataset, was one of the first pretrained language models to train exclusively on Common Crawl data. Multilingual versions of T5 <ref type="bibr" target="#b104">(Xue et al., 2021)</ref> and BERT were trained on Common Crawl and Wikipedia, respectively.</p><p>GPT-2 was one of the first models intended primarily for generation <ref type="bibr" target="#b76">(Radford et al., 2019)</ref>. Deeming Common Crawl too noisy to be practical for training generative models, they developed WebText, a dataset containing websites linked to from highly-ranked posts on Reddit. Subsequent generative models proposed mixing large amounts of noisy Common Crawl data with smaller corpora perceived as high-quality. The GPT-Neo model family <ref type="bibr" target="#b11">(Black et al., 2022)</ref> trained on the Pile, which augments the Common Crawl with ArXiV, Stack Exchange, legal documents, books, Github, and other more curated sourced <ref type="bibr" target="#b29">(Gao et al., 2020)</ref>. More recently, OPT <ref type="bibr" target="#b108">(Zhang et al., 2022)</ref> trained on the Pile augmented with social media data <ref type="bibr" target="#b7">(Baumgartner et al., 2020)</ref>, and LLaMA <ref type="bibr" target="#b92">(Touvron et al., 2023)</ref> trained on C4 augmented with Github, Stack Exchange, books, and other sources. Pythia trained on the Pile, with and without duplication <ref type="bibr" target="#b10">(Biderman et al., 2023)</ref>. Finally, the BLOOM model family <ref type="bibr">(Scao et al., 2022)</ref> trained on the ROOTS Corpus, which crowd-sourced a collection of "identified" datasets, coming from known, high-quality sources in a variety of languages.</p><p>All of the models mentioned so far are publicly available. However, companies are increasingly training their best models on proprietary datasets, with only limited hints as to the data composition. At Alphabet, models such as Gopher <ref type="bibr" target="#b77">(Rae et al., 2021)</ref>, GLaM <ref type="bibr" target="#b24">(Du et al., 2022)</ref> , LaMDA <ref type="bibr" target="#b91">(Thoppilan et al., 2022)</ref>, and PaLM <ref type="bibr" target="#b15">(Chowdhery et al., 2022)</ref> have been trained on mixtures of web text, books, news, code, Wikipedia, and dialog data. At OpenAI, <ref type="bibr">GPT-3 (Brown et al., 2020)</ref> was trained on Common Crawl, WebText (GPT-2's training set), books, and Wikipedia. Subsequent versions of their model have also included code. Most of these models have acknowledged using various forms of filtering techniques to improve the quality of web-derived training data. These include classifiers designed to exclude content which looks least like "high-quality" sources such as books or Wikipedia <ref type="bibr" target="#b15">(Chowdhery et al., 2022;</ref><ref type="bibr" target="#b71">Ouyang et al., 2022)</ref>, using Google's SafeSearch for identifying toxic content <ref type="bibr" target="#b77">(Rae et al., 2021)</ref>, and various heuristics based on document length and the presence or absence of certain words or characters.</p><p>Pretraining Dataset Analysis <ref type="bibr" target="#b23">Dodge et al. (2021)</ref> find significant amounts of low-quality patent, military, and machine-generated text in C4, and a dearth of English text from American minority communities as well as from non-Western communities like India or Nigeria post-filtering, and so recommend against filtering. In contrast, Luccioni and Viviano (2021) recommend more robust filtering practices to curb the significant presence of hate speech and sexually explicit content they find in C4 even after filtering. Similarly, <ref type="bibr" target="#b49">Kreutzer et al. (2022)</ref> find that multilingual pretraining corpora are also dominated by low-quality text, particularly for lower resource languages. <ref type="bibr" target="#b55">Lee et al. (2022)</ref>; <ref type="bibr" target="#b45">Kaddour (2023)</ref> show the benefits of deduplicating pretraining datasets, which often contain a great deal of repeated content. Lastly, Zhao et al. ( <ref type="formula">2023</ref>) reviews pretraining data sources, strategies for quality filtering, and the importance of data distribution. Their summary corroborates our findings regarding domain composition and quality filtering, in particular.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data, Toxicity, &amp; Quality</head><p>Research into the quality and toxicity of datasets and their resulting models has seen mixed findings. All of the major models report using significant data pre-processing and toxicity/quality filters, including BERT, T5, BLOOM, OPT, ChinChilla, PaLM, LaMDA, and the GPT-3 series, with the largest of these now using classifiers. This widespread adoption suggests there are significant implicit benefits, even though they not often externally reported. GLaM does empirically report performance improvements from filtering, particularly on Natural Language Generation (NLG) tasks <ref type="bibr" target="#b24">(Du et al., 2022)</ref>.</p><p>However, in academia, a few works caution against the use of detoxification techniques, including data filters, which can reduce model perplexity on underrepresented communities <ref type="bibr" target="#b103">(Xu et al., 2021;</ref><ref type="bibr" target="#b99">Welbl et al., 2021)</ref>. <ref type="bibr" target="#b99">Welbl et al. (2021)</ref> also reports that a toxicity classifier reduces toxicity more than than applying data toxicity data filters, but <ref type="bibr" target="#b103">Xu et al. (2021)</ref> show this yields the worst perplexity on underrepresented communities. <ref type="bibr" target="#b66">Meade et al. (2022)</ref> further corroborates that improvements on bias benchmarks correlates with deteriorations in general language modeling abilities. Furthermore, investigating GPT-3's described quality filter, <ref type="bibr" target="#b39">Gururangan et al. (2022)</ref> find its quality judgments are unaligned with factuality or literary acclaim but are instead aligned with some notion of langauge ideology more correlated with wealthier zip codes. Works in the vision domain show data filtering has important detoxification benefits but can reduce performance <ref type="bibr" target="#b68">(Nichol et al., 2022)</ref> or introduce other biases <ref type="bibr" target="#b68">(Nichol, 2022)</ref>. In summary, pretraining data filters are ubiquitous in the development of non-toxic and high-quality models, but they are prone to reducing their abilities to serve underrepresented communities and may introduce new biases.</p><p>Additional work has shown that instruction tuning <ref type="bibr">(Chung et al., 2022;</ref><ref type="bibr" target="#b62">Longpre et al., 2023)</ref> and forms of alignment tuning <ref type="bibr" target="#b71">(Ouyang et al., 2022;</ref><ref type="bibr" target="#b5">Bai et al., 2022)</ref> have both reduced unwanted toxic generation.</p><p>Data &amp; Time Natural language is known to evolve and change over time <ref type="bibr" target="#b3">(Altmann et al., 2009;</ref><ref type="bibr" target="#b51">Labov, 2011;</ref><ref type="bibr" target="#b25">Eisenstein et al., 2014;</ref><ref type="bibr" target="#b43">Jaidka et al., 2018)</ref>. As language's distribution shifts, the ability of models to perform well on new test sets has also been shown to degrade, due to their static knowledge of recent events, syntactic and semantic practices <ref type="bibr" target="#b54">(Lazaridou et al., 2021;</ref><ref type="bibr" target="#b1">Agarwal and Nenkova, 2022;</ref><ref type="bibr" target="#b60">Longpre et al., 2021)</ref>. offer evaluation sets to measure this phenomena. Proposed remedies include finetuning on more recent data <ref type="bibr" target="#b64">(Luu et al., 2021)</ref>, adaptive/continuous pretraining <ref type="bibr" target="#b54">(Lazaridou et al., 2021;</ref><ref type="bibr" target="#b81">Röttger and Pierrehumbert, 2021)</ref>, data augmentation <ref type="bibr" target="#b87">(Singh and Ortega, 2022)</ref>, modeling text with its timpestamps <ref type="bibr" target="#b22">(Dhingra et al., 2022)</ref>. To our knowledge, no work has thoroughly investigated the effects of temporal degradation when pretraining from scratch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data &amp; Domains</head><p>The composition of public datasets, like C4 and the Pile, is guided mostly by licensing, which severely restricts availability. Even so, <ref type="bibr" target="#b94">Villalobos et al. (2022)</ref>; Nostalgebraist (2022); Hoffmann et al. ( <ref type="formula">2022</ref>) suggest we are imminently exhausting high-quality text data on the web to train computeoptimal larger LMs, at least with existing training efficiency. This poses a challenge, given the demonstrated importance of high quality and diverse training data to strong generalization <ref type="bibr" target="#b29">(Gao et al., 2020;</ref><ref type="bibr" target="#b72">Papadimitriou and Jurafsky, 2020)</ref>. A great deal of literature has dedicated itself to adapting static pretrained models to new downstream domains, using domain adaptive pretraining <ref type="bibr" target="#b38">(Gururangan et al., 2020)</ref>, finding intermediate finetuning tasks <ref type="bibr" target="#b75">(Pruksachatkun et al., 2020)</ref>, dynamically balancing data sources <ref type="bibr" target="#b96">(Wang et al., 2020)</ref>, data selection <ref type="bibr" target="#b42">(Iter and Grangier, 2021;</ref><ref type="bibr" target="#b2">Albalak et al., 2023)</ref>, augmentation <ref type="bibr" target="#b59">(Longpre et al., 2019)</ref>, and active learning <ref type="bibr" target="#b61">(Longpre et al., 2022)</ref>. Another line of work demonstrates the potential of pretraining on carefully crafted synthetic data <ref type="bibr" target="#b100">(Wu et al., 2022)</ref>.</p><p>Most similar to this section of our work, Xie et al. (2023a) re-balance mixtures of the Pile to achieve more performant and efficient convergence. <ref type="bibr">Xie et al. (2023b)</ref> use importance sampling to select subsets of the Pile most useful for target downstream tasks, in lieu of quality filters, to achieve 2% improvement on downstream tasks. <ref type="bibr" target="#b75">Pruksachatkun et al. (2020)</ref> systematically benchmark the effects of intermediate finetuning tasks, similar to how we benchmark different compositions of pretraining tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model &amp; Data Scaling</head><p>Prior work has explored scaling model size <ref type="bibr" target="#b46">(Kaplan et al., 2020;</ref><ref type="bibr" target="#b90">Tay et al., 2022;</ref><ref type="bibr" target="#b24">Du et al., 2022)</ref>, the amount of pretraining data or the number of pretraining steps <ref type="bibr" target="#b58">(Liu et al., 2019;</ref><ref type="bibr" target="#b15">Chowdhery et al., 2022;</ref><ref type="bibr">Brown et al., 2020)</ref>. Chinchilla investigated and reported optimal compute scaling laws, expressing a relationship between model and data size <ref type="bibr">(Nostalgebraist, 2022)</ref>. Recent work has demonstrated that new abilities emerge at greater scale <ref type="bibr" target="#b98">(Wei et al., 2022)</ref>, but also that many of these benefits can be distilled or compressed into smaller models <ref type="bibr" target="#b89">(Taori et al., 2023;</ref><ref type="bibr" target="#b67">Movva et al., 2022)</ref>. In this work, we investigate how temporal pretraining misalignment varies on different model sizes, which to our knowledge was previously unanswered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Conclusion</head><p>The relative age of documents, content filters, and data sources each have significant effects on downstream model behaviour. These effects can be reduced, but not eliminated, by finetuning. We recommend that model developers and users pay close attention to these details in designing/selecting the model most relevant to their needs, as each decision has a specific, quantifiable trade-off profile. For instance, it may be important to decide between improving toxicity identification or reducing toxic generation, performance on brand new or older data sources, and biomedical or books text domains. These countless choices are inherent in curating any pretraining dataset. While we are only able to evaluate a small fraction of these, we are able to show which choices matter and by how much, and we hope to inspire further work evaluating dataset composition and predicting behaviors of models given pretraining datasets. Table 4 lists popular and well-known models trained in the last several years and a summary of the available information about their training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Experimental Details</head><p>This section provides further details on the methodology and hyperparameter settings used for pretraining, finetuning, and evaluation.</p><p>To allow for a model that can generate without finetuning but also perform well after finetuning, we rely on the extensive experiments of <ref type="bibr" target="#b95">Wang et al. (2022)</ref>. Their empirical results suggest these criteria are met with a Causal Decoding architecture with a Full Language Modeling pretraining objective ("CD-FLM"), which permits generation without finetuning, followed by a Prefix Language Modeling objective (PLM) for finetuning, where the causal attention mask is removed from the original prompt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Pretraining Details</head><p>Our two pretraining datasets are C4 <ref type="bibr" target="#b78">(Raffel et al., 2020)</ref> and the Pile <ref type="bibr">(Gao et al., 2021)</ref>. We use the same vocabulary for both as used in the original T5 from <ref type="bibr" target="#b78">Raffel et al. (2020)</ref>. All training is conducted using T5X <ref type="bibr" target="#b79">(Roberts et al., 2022)</ref> and Tensorflow <ref type="bibr" target="#b0">(Abadi et al., 2016)</ref> on TPUs. Specific hyperparameters for LM-XL and LM-Small pretraining are detailed in Table <ref type="table">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Finetuning Details</head><p>Unless otherwise noted, evaluation was performed by finetuning on the train set for each benchmark task, and then evaluating on either the validation or test set (specified in each section). Finetuning hyperparameters are given in Table <ref type="table">6</ref>.</p><p>For each model, we generate 25 responses per prompt, using top-k sampling (k = 40), with a temperature of 1.0. Following <ref type="bibr" target="#b15">Chowdhery et al. (2022)</ref>, we use the Perspective API to score responses, labeling those with a toxicity score &gt;= 0.5 as toxic. We compute the probability one of these generations per prompt is toxic, for two evaluation splits, one with non-toxic inputs, and one with toxic inputs. The resulting evaluation metrics are denoted RPT-T (for Toxic inputs) and RPT-NT (for Non-Toxic inputs).</p><p>The Representational Bias benchmark was constructed from the identity terms in <ref type="bibr" target="#b77">(Rae et al., 2021)</ref> and is described in more detail in <ref type="bibr" target="#b15">Chowdhery et al. (2022)</ref>. It uses templates constructed for several identity markers, for which we use the subset related to gender, race, and religion. Following the practice with RealToxicityPrompts, we sample 50 responses per prompt, use top-k sampling (k = 40, temperature = 1.0), and then classify a response as toxic if Perspective API evaluates its toxicity score &gt;= 0.5. We average the toxicity rates per identity marker and per example to compute the overall RepBias score, where higher indicates more toxic responses were produced on average. We also compute the 95% confidence interval to show where changes in mean are significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4 Time Evaluation Details</head><p>This section describes the evaluation details for the results presented in Section 4. In applied settings, the available training data (either for pretraining or finetuning) may be from different years than the test-time data. To mimic these situations, <ref type="bibr" target="#b64">Luu et al. (2021)</ref> construct several datasets segmented by the year they are collected from in order to measure the performance impact of differences in the time of collection of finetuning and evaluation splits. As described in Section 2.3, we select 5 of the datasets that are shown to be quite sensitive to these temporal misalignments, and that cover different tasks and data sources. These tasks are summarization, named entity recognition, classifying political affiliation, classifying academic topic, and classifying the news source.</p><p>Due to the unique nature of each of these tasks in the temporal degradation experiments, we simply finetune on each task individually, before evaluating on their respective test sets. For each dataset, we finetune using 4x4 TPUs with a batch size of 64, a maximum sequence length of We follow <ref type="bibr" target="#b64">Luu et al. (2021)</ref>'s exact prescription in calculating Temporal Degradation (TD), as well as their reported Pearson correlation measurements (r). Temporal degradation can be interpreted as the average rate of deterioration in performance for a time period, measured in years. Since a temporal deterioration score is calculated per evaluation year, we average over all evaluation years to compute a final TD score for a dataset. Furthermore, each dataset has a different span of available training and evaluation years. To account for this, we follow <ref type="bibr" target="#b64">Luu et al. (2021)</ref> in presenting the Pearson correlation coefficient, which presents the strenght of the relationship between time differences and performance deterioration. We also replicate the Wald test with null hypothesis that the slope is zero.</p><p>For evaluating the temporal degradation of pretraining, TD p , we modify <ref type="bibr" target="#b64">Luu et al. (2021)</ref>'s original formula to measure the different D(t ′ → t) where t ′ is now the pretraining year. However, in this setting, performance samples are represented with different finetuning years. To account for this, we only compare the relative performance changes of the pretraining year t p , against models with the same finetuning t f and evaluation years t e . In other words, given S tp→t f →te , we will only compare its performance to S t ′ p →t f →t e where t ′ p ̸ = t p , but t f and t e are fixed to their respective values.</p><formula xml:id="formula_0">D(t ′ p → t e ) = -(S t ′ p →t ′′ f →te -S tp→t ′′ f →te ) * sign(t ′ p -t e )</formula><p>In some edge cases, there is no evaluation year equivalent to a pretraining year, ∀t ∈ T, t p ̸ = t e , and so the term S tp→t ′′ f →te ) does not exist. In this case, we set this term to be the one where t p and t e are closest. And, as before, the precise term used will depend on which version of t f is being calculated for.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.5 Evaluating Domains with Question Answering Datasets</head><p>This section describes the evaluation details for the results presented in Section 6. These experiments involve pretraining models with different subsets of the corpora from the Pile <ref type="bibr" target="#b29">(Gao et al., 2020)</ref> and seeing the effects on a variety of downstream evaluation domains, represented by question answering datasets. As such, we are able to map the effects of pretraining domains to evaluation domains. First, we discuss the construction of the pretraining domains. We partition the Pile's source datasets into categories representing thematically similar sources of data, as seen in Table <ref type="table">8</ref>. We refer to these categories as Domains. These domain partitions are subjective and cannot perfectly separate out text into these categories. For instance, Wikipedia, Books, and Common Crawl data inevitably contain some Academic information, but overall these partitions represent distinct features (see Section 3) that we have attempted to delineate by areas of interest to practitioners and researchers. Prior work has attempted to measure, emphasize, or target (either for inclusion or exclusion) the particular categories of data we've used in our partitions, such as more books and structured data <ref type="bibr">(Brown et al., 2020;</ref><ref type="bibr" target="#b15">Chowdhery et al., 2022)</ref>, code data <ref type="bibr" target="#b14">(Chen et al., 2021)</ref>, and legal data <ref type="bibr" target="#b23">(Dodge et al., 2021)</ref>, among others.</p><p>The Domains of the Pile were then each separately ablated from pretraining to understand the effect of their absence. To evaluate their absence on the performance of downstream domains, we chose to use the question answering task expressly because there is a wide variety of similarly formatted evaluation datasets available. For these question answering datasets we train only on Natural Questions <ref type="bibr" target="#b50">(Kwiatkowski et al., 2019)</ref>, a popular QA dataset, to teach the model the general task. For evaluation, as described in Section 2.3, we use UnifiedQA <ref type="bibr" target="#b47">(Khashabi et al., 2020)</ref> and MRQA <ref type="bibr" target="#b27">(Fisch et al., 2019)</ref>'s collection of datasets to evaluate how each pretrained model performs on a given "domain", or set of datasets with similar source characteristics. We partition the question answering datasets from UnifiedQA and MRQA into five categories. Datasets with Wikipedia documents represented in their collection are assigned to the Wiki category, datasets with scraped web documents or news are assigned to the Web category, and so on. Datasets may belong to multiple categories, depending on how they were constructed. The question answering evaluation partitions are shown in Table <ref type="table">9</ref>. Finally, we evaluate on each question answering dataset and report the average F1 score for each category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Impact of Data Curation on Data Composition: Further Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 Feature Definitions</head><p>As discussed in Section 3, we calculated a set of features across all datapoints to better understand the distribution shifts for each ablation. The full list of features is as follows:</p><p>• Profanity, Toxicity, and Sexually Explicit The Perspective API classifies text as violating or passing each of these categories, as described in Section 2.2.</p><p>• Text Quality The same bag-of-words-based linear classifier as used in PaLM <ref type="bibr" target="#b15">(Chowdhery et al., 2022)</ref> and GLaM <ref type="bibr" target="#b24">(Du et al., 2022)</ref>, is used to distinguish between text that looks like Wikipedia and books from other text, as described in Section 2.2.</p><p>• Personally Identifiable Information (PII) A basic classifier, similar to <ref type="bibr">Google Cloud NLP (2023a)</ref>, detects the presence of four categories of personally identifiable information: names, phone numbers, addresses, and emails.</p><p>• Readability The Flesch-Kincaid readability test <ref type="bibr" target="#b48">(Kincaid et al., 1975)</ref> is applied to each document, assigning documents a grade level based on the number of words per sentence and number of syllables per word.</p><p>• Average Word Length Measured in characters.</p><p>• Document Length Measured in characters.</p><p>• Non-ASCII Characters Measured as a percentage of all characters in the document.</p><p>• All-caps Words Measured as a percentage of all words in the document.</p><p>• Type-Token Ratio A measure of the lexical diversity, or the ratio of unique tokens to total tokens <ref type="bibr" target="#b8">(Bender, 2013)</ref>.</p><p>• Sentiment The score assigned by a classifier similar to <ref type="bibr">Google Cloud NLP (2023b)</ref>, evaluating the overall sentiment of the text along a spectrum from positive to negative.</p><p>Temporal information in pretraining data While we collected versions of C4 at four different years, each of these versions may also contain data from prior years. We estimate the temporal information in the pretraining data by counting instances of dates from 2000 to 2025 in each corpus. We do see that there are many mentions of the year of collection, with a quick dropoff of about 5 years earlier (see Figure <ref type="figure" target="#fig_0">10</ref>). This is necessarily a limited experiment as an article written in 2016 may still mention something occurring in the future in 2019. However, since website creation dates are not part of the web-scrape, we use this as a proxy to estimate website creation dates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Breakdown of the Quality Filter on Pile Domains</head><p>While the quality filters are typically applied to large, heterogeneous datasets such as C4, we also ran the quality classifier on the Pile to get a better understanding of what types of datapoints actually passed the quality filtering thresholds. The results are shown in Figure <ref type="figure" target="#fig_0">11</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Experimental Results</head><p>In this section, we lay out the raw results for our toxicity, quality, and temporal degradation evaluations, spanning several evaluation datasets.</p><p>100.0 100.0 95.2 73.1 67.2 56.4 53.1 71.0 74.7 68.0 94.6 97.8 100.0 97.6 82.0 67.8 57.6 73.6 73.6 67.8 85.6 92.4 94.3 86.8 91.8 92.8 80.5 82.5 79.8 69.1 73.7 85.0 87.5 58.6 67.5 86.9 91.2 94.5 90.5 81.5 49.5 64.8 75.3 38.1 49.6 72.7 78.2 90.5 94.8 93.3 PoliAff Next we share the original evaluation results from which we computed the temporal degradation values for both finetuning and pretraining. These contain a cross-section of the scores produced using a given pretraining year (y-axis), finetuning year(s) (y-axis), for an evaluation year (x-axis). These results, Tables 10 to 13, are provided for both LM-XL and LM-Small, for comparison.</p><p>Table <ref type="table">10</ref>: Left: Full results on the PubCLS temporal task splits from <ref type="bibr" target="#b64">(Luu et al., 2021)</ref>. This task evaluates news article source classification, measured with Accuracy. Right: Full results on the NewSum summarization task temporal splits from <ref type="bibr" target="#b64">(Luu et al., 2021)</ref>, evaluated in Rouge-L.</p><p>Pretrain Finetune Eval Time Time Time 2010 2012 2014 2016 LM-XL 2013 2010 93.7 51.9 58.4 52.5 2012 60.2 94.6 78.4 75.6 2014 83.1 85.6 90.8 84.8 2016 78.7 84.7 86.2 87.6 2016 2010 93.8 51.6 59.2 53.2 2012 55.2 93.9 79.5 77.0 2014 81.5 86.2 92.8 85.6 2016 76.9 82.9 84.3 89.6 2019</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 Toxicity &amp; Quality Filtering Results</head><p>We also provide full results for our experiments with toxicity and quality filters, presented in Section 5. The evaluation results of the models with toxicity filters applied to their data are visualized in Figure <ref type="figure">5</ref> (left) and Figure <ref type="figure" target="#fig_9">13</ref>, with full details in Table <ref type="table" target="#tab_12">14</ref>. The evaluation results of the models with quality filters applied to their data are visualized in Figure <ref type="figure">5</ref> (right) and detailed in Table <ref type="table">15</ref>.</p><p>60% 50% 40% 30% 20% 10% 0% 10%</p><p>Toxic Generation Score  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The experimental pretraining curation pipeline includes three steps: sub-selecting data from C4 or the Pile, pretraining a language model, and evaluating its change in performance over several benchmarks.</figDesc><graphic coords="1,111.22,489.26,201.19,118.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Feature differences across slices of the pretraining datasets. Bars show the ratio between the mean feature value for the slice and the mean value for the dataset (the Pile or C4), which is indicated by a horizontal gray line. For example, Wiki text has half the profanity and three times the quality values as the average for the Pile.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The mean relative performance over 5 datasets (y-axis) increases as temporal misalignment (x-axis) approaches zero. The boxplot indicates the median (solid line), mean (triangles), quartile range (boxes), and rest of the distribution (whiskers). Note that each dataset has different evaluation year ranges.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>Figure 5: Toxicity filtering the pretraining dataset decreases the ability of LM-XLto identify toxicity and to generate toxic text. Quality filtering surprisingly increases both abilities. Documents with scores below a given threshold were filtered out.Wiki Web Books Biomed Academic Common Sense Contrast Sets Average</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Toxicity filtering C4 reduces LM-XL's downstream performance on most QA task domains. The toxicity filter threshold is on the x-axis, with percentage of training data remaining in parentheses. Each column represents a set of QA evaluations from a domain. The 'Full Dataset' is unfiltered, and the 'Inverse' filter removes the lowest toxicity data instead.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 Figure 8 :</head><label>88</label><figDesc>Figure 8: QA tasks are affected by removing domains when pretraining LM-XL. Each row represents a model with one domain removed, the size of the remaining dataset is shown at the left in parentheses. Each column represents a set of QA evaluations from a domain. The Full Dataset model represents the unfiltered Pile LM-XL, and all scores are relative to this Base model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><figDesc>Luu et al. (2021); Lazaridou et al. (2021); Liska et al. (2022); Yao et al. (2022); Zhang and Choi (2021); Jang et al. (2022)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 10 :Figure 11 :</head><label>1011</label><figDesc>Figure 10: Date instances in each of the C4 temporal pretraining versions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: A replication of how temporal misalignment in finetuning affects task performance (Luu et al., 2021). In contrast to Figure 3, which shows the effects of pretraining misalignment, this figure focuses on the more well established effect of finetuning misalignment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: Toxicity filtering the Pile decreases the ability of LM-XLto identify toxicity and to generate toxic text, just as with toxicity filtering C4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Additional notes on each model's filtering details.</figDesc><table><row><cell>Model</cell><cell>Filtering Details</cell></row><row><cell>Bert</cell><cell>"ignore lists, tables, and headers"</cell></row><row><cell>GPT-2</cell><cell>removed Wikipedia</cell></row><row><cell>RoBerta</cell><cell>CC filtered to news and Winograd-like subsets</cell></row><row><cell>XLNet</cell><cell>"heuristics to aggressively filter out short or low-quality articles"</cell></row><row><cell>T5</cell><cell>Heuristic quality, toxicity, and length filters; code removed</cell></row><row><cell>GPT-3</cell><cell>Filtered based on similarity to high-quality reference corpora.</cell></row><row><cell>GPT-J/Neo</cell><cell>Uses fasttext classifier on Pile-CC, with OpenWebText2 as the high-quality reference.</cell></row><row><cell>GLaM</cell><cell>Classifier with Wikipedia, books and selected websites as positive examples</cell></row><row><cell>LaMDA</cell><cell>"LaMDA SSI and safety discriminators are also used to score and filter 2.5M turns of dialog data</cell></row><row><cell></cell><cell>sampled from the pre-training dataset", which are then trained on.</cell></row><row><cell cols="2">AlphaCode Filtering heuristics to exclude automatically generated code</cell></row><row><cell>CodeGen</cell><cell>Heuristic filters for code quality</cell></row><row><cell cols="2">Chinchilla Heuristic-based quality filtering, SafeSearch filter</cell></row><row><cell>Minerva</cell><cell>Same as PaLM for non-academic data</cell></row><row><cell>BLOOM</cell><cell>heuristic-based quality and porn filtering</cell></row><row><cell>PaLM</cell><cell>Same as GlaM</cell></row><row><cell>Galactica</cell><cell>Apply several quality filters: exclude papers from journals with certain keywords or low journal</cell></row><row><cell></cell><cell>impact factor</cell></row><row><cell>LLaMA</cell><cell>Classifier to filter out low-quality and un-Wikipedia-like text</cell></row><row><cell cols="2">B Expanded Literature Review</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 : Time Dataset &amp; Training Details:</head><label>7</label><figDesc>128, and we validate every 500 training steps. We select the test set score with the highest validation accuracy across training. The best learning rate and the total number of steps required to reach convergence varied by model and model size, and are reported in Table7. These hyperparameters are chosen based on initial experiments attempting to produce stable learning curves which peak near the values observed in<ref type="bibr" target="#b64">Luu et al. (2021)</ref>.For each of the five datasets used to evaluate the model's ability over different temporal periods, we report the learning rate and number of steps used in each model size. These hyperparameters were chosen to ensure consistent convergence and stability within our infrastructure settings.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">LM-XL</cell><cell>LM-Small</cell></row><row><cell cols="2">Domain Task</cell><cell>Metric</cell><cell cols="3">LR Steps LR Steps</cell></row><row><cell>News</cell><cell cols="3">PubCLS Acc NewSum Rouge-L 5e-4 1e-4</cell><cell cols="2">30k 1e-3 40k 1e-3</cell><cell>30k 40k</cell></row><row><cell>Twitter</cell><cell cols="2">PoliAff Acc TwiERC Acc</cell><cell>1e-4 1e-4</cell><cell cols="2">15k 1e-4 30k 1e-3</cell><cell>15k 30k</cell></row><row><cell cols="2">Science AIC</cell><cell>Acc</cell><cell>1e-4</cell><cell cols="2">30k 1e-3</cell><cell>60k</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 14 : Toxicity filtering the pre-training dataset decreases the ability of LM-XLto identify toxicity and to generate toxic text.</head><label>14</label><figDesc>These results are visualized in Figures5 and 13.</figDesc><table><row><cell>Filter</cell><cell>% Data</cell><cell cols="3">Toxicity Identification (↑)</cell><cell></cell><cell cols="3">Toxicity Generation (↓)</cell><cell></cell></row><row><cell></cell><cell cols="9">SBF Toxigen DH R3 DH R4 Score RTP-T RPT-NT RepBias Score</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">The Pile</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Full Dataset</cell><cell>100.0 90.7</cell><cell>90.8</cell><cell>88.7</cell><cell>84.1</cell><cell>0.0</cell><cell>88.9</cell><cell>44.4</cell><cell>4.6±0.7</cell><cell>0.0</cell></row><row><cell>T=0.95</cell><cell>99.1 90.6</cell><cell>90.9</cell><cell>87.8</cell><cell>83.5</cell><cell>-0.5</cell><cell>85.6</cell><cell>43.9</cell><cell>4.6±0.8</cell><cell>-1.9</cell></row><row><cell>T=0.9</cell><cell>97.4 90.2</cell><cell>90.8</cell><cell>86.4</cell><cell>83.7</cell><cell>-0.9</cell><cell>80.4</cell><cell>41.9</cell><cell>4.0±0.6</cell><cell>-9.2</cell></row><row><cell>T=0.7</cell><cell>90.8 89.9</cell><cell>90.9</cell><cell>87.4</cell><cell>82.7</cell><cell>-1.0</cell><cell>83.3</cell><cell>39.9</cell><cell cols="2">2.9±0.5 -18.1</cell></row><row><cell>T=0.5</cell><cell>80.7 89.4</cell><cell>90.4</cell><cell>86.0</cell><cell>82.8</cell><cell>-1.6</cell><cell>83.3</cell><cell>35</cell><cell cols="2">2.2±0.4 -26.7</cell></row><row><cell>T=0.3</cell><cell>60.1 88.4</cell><cell>89.9</cell><cell>85.3</cell><cell>81.3</cell><cell>-2.7</cell><cell>78.5</cell><cell>31.4</cell><cell cols="2">2.2±0.5 -31.1</cell></row><row><cell>Ngrams</cell><cell>70.7 89.7</cell><cell>90.4</cell><cell>86.3</cell><cell>82.4</cell><cell>-1.6</cell><cell>76.1</cell><cell>33.6</cell><cell cols="2">2.5±0.6 -28.0</cell></row><row><cell></cell><cell></cell><cell></cell><cell>C4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Inverse T=0.06</cell><cell>92.2 93.2</cell><cell>91.4</cell><cell>90.0</cell><cell>85.7</cell><cell>1.4</cell><cell>87.8</cell><cell>49.6</cell><cell>4.8±0.8</cell><cell>15.6</cell></row><row><cell>Full Dataset</cell><cell>100.0 91.2</cell><cell>91.1</cell><cell>89.0</cell><cell>84.2</cell><cell>0.0</cell><cell>84.6</cell><cell>41.8</cell><cell>3.9±0.7</cell><cell>0.0</cell></row><row><cell>T=0.95</cell><cell>97.7 90.7</cell><cell>91.3</cell><cell>87.7</cell><cell>83.4</cell><cell>-0.7</cell><cell>84.3</cell><cell>41.9</cell><cell>3.9±0.7</cell><cell>0.0</cell></row><row><cell>T=0.9</cell><cell>94.9 90.4</cell><cell>90.6</cell><cell>87.5</cell><cell>83.9</cell><cell>-0.9</cell><cell>81.1</cell><cell>40.3</cell><cell>3.1±0.6</cell><cell>-9.0</cell></row><row><cell>T=0.7</cell><cell>85.8 90.5</cell><cell>90.5</cell><cell>86.1</cell><cell>82.8</cell><cell>-1.6</cell><cell>71.3</cell><cell>34.8</cell><cell cols="2">2.4±0.5 -23.8</cell></row><row><cell>T=0.5</cell><cell>75.8 89.8</cell><cell>90.5</cell><cell>86.9</cell><cell>81.9</cell><cell>-1.8</cell><cell>65.2</cell><cell>30.0</cell><cell cols="2">1.8±0.4 -35.0</cell></row><row><cell>T=0.3</cell><cell>60.8 89.4</cell><cell>90.2</cell><cell>82.1</cell><cell>75.6</cell><cell>-5.2</cell><cell>55.0</cell><cell>19.8</cell><cell cols="2">1.2±0.3 -52.1</cell></row><row><cell>Ngrams</cell><cell>78.6 89.8</cell><cell>90.7</cell><cell>87.0</cell><cell>81.8</cell><cell>-1.8</cell><cell>74.7</cell><cell>31.8</cell><cell cols="2">2.3±0.5 -25.6</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>† https://www.perspectiveapi.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>‡ See https://developers.perspectiveapi.com/s/about-the-api-score § https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words ¶ We use the offensiveness detection task from Social Bias Frames. DynaHate releases 4 rounds of adversarial datasets, for which we use the test sets for Round 3 (R3) and Round 4 (R4).</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to thank <rs type="person">Daniel Smilkov</rs> for his technical assistance in characterizing large corpora, <rs type="person">Maarten Bosma</rs> and <rs type="person">Jacob Andreas</rs> for their early guidance on this project, <rs type="person">Tom Small</rs> for his visual design support, and <rs type="person">Noah Constant</rs> for feedback on the paper. This work is supported by <rs type="funder">NSF</rs> #<rs type="grantNumber">1652536</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_KVQwRFD">
					<idno type="grant-number">1652536</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Contributions</head><p>• Shayne Longpre Project lead and primary coder. Led experiment design, implementation, pretraining, evaluation, and analysis.</p><p>• Gregory Yauney Core contributor. Led evaluation implementation and analysis on toxicity and quality filtering section (Section 5). Contributed code for Section 3. Also supported writing and analysis.</p><p>• Emily Reif Core contributor. Led the analysis of data characteristics pre-and post-curation (Section 3). Also supported writing and analysis.</p><p>• Katherine Lee Core contributor. Supported infrastructure implementation, debugging, overall analysis and framing, especially for Section 4.</p><p>• David Mimno Core contributor. A primary advisor, supporting analysis, framing, writing, and particularly discussion of key take-aways and recommendations (Section 7).</p><p>• Daphne Ippolito Core contributor. The primary advisor and also a coding contributor, supporting both the analysis, framing, and writing as well as running many of the experiments and evaluations.</p><p>• Adam Roberts Supporting advisor, especially on modeling choice and pretraining infrastructure.</p><p>• Barret Zoph Supporting advisor on experiment design.</p><p>• Denny Zhou Supporting advisor on writing and framing.</p><p>• Jason Wei Supporting advisor on experiment design, writing and framing.</p><p>• Kevin Robinson Supporting advisor on toxicity evaluations and their implementation. Table <ref type="table">6</ref>: Finetuning and Evaluation Parameters for each set of Downstream Tasks. We report the finetuning hyperparameter settings and evaluation metric used for finetunting and evaluating the pretrained models.</p><p>We conduct finetuning for four sets of tasks: toxicity identification tasks (Toxigen, Social Bias Frames, and DynaHate), Natural Questions (for pretraining domain transfer analysis), general NLU performance (SuperGLUE), and the Time tasks (including PubCLS, NewSum, PoliAff, TwiERC, and AIC). For T5 Small models, we modify the number of training steps accordingly, as shown in the last row. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Toxicity Evaluation Details</head><p>In this section we describe the evaluation details for the results presented in Section 5.</p><p>Toxicity Identification For toxicity identification evaluation, we finetune separately on each of the following datasets: Social Bias Frames (SBF, <ref type="bibr" target="#b83">Sap et al., 2020)</ref>, DynaHate (DH, <ref type="bibr" target="#b93">Vidgen et al., 2021)</ref>, and Toxigen <ref type="bibr" target="#b40">(Hartvigsen et al., 2022)</ref>. We then evaluate on their respective test sets, using AUC-ROC, which computes the error rates over different classification thresholds. Note that each of these datasets has a slightly different version of toxicity they are evaluating for: biases and offensive stereotypes implied in language for Social Bias Frames, types of hateful speech like animosity, dehumanization, and derogation for DynaHate, and adversarial, subtle and implicit forms of toxicity towards minority groups (e.g., stereotyping, microaggressions), for Toxigen. We average over them to understand a model's capabilities in identifying toxicity broadly.</p><p>Toxic Generation For toxic generation, we do not do any finetuning. Instead, we evaluate how often each model generates toxic continuations. To measure a model's propensity to generate sexual, profane, or toxic responses to a mix of benign and malicious inputs, we use prompts from the RealToxicityPrompts (Gehman et al., 2020) dataset, as well as the prompt set developed to explore representational bias in PaLM <ref type="bibr" target="#b15">(Chowdhery et al., 2022)</ref>.  To evaluate the performance of pretraining strategies on different text domains, we assign datasets into categories corresponding to their source material:webbased, wikipedia, academic, biomedical, or and/books). Certain datasets are also designed specifically to test advanced common sense reasoning, or decision boundaries using contrast sets <ref type="bibr" target="#b31">(Gardner et al., 2020)</ref>. Datasets can belong to multiple categories.   </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">TensorFlow: Large-scale machine learning on heterogeneous distributed systems</title>
		<author>
			<persName><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eugene</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Craig</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04467</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Temporal effects on pre-trained models for language processing tasks</title>
		<author>
			<persName><forename type="first">Oshin</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="904" to="921" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Improving few-shot generalization by exploring and exploiting auxiliary data</title>
		<author>
			<persName><forename type="first">Alon</forename><surname>Albalak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2302.00674</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Beyond word frequency: Bursts, lulls, and scaling in the temporal distributions of words</title>
		<author>
			<persName><forename type="first">Janet</forename><forename type="middle">B</forename><surname>Eduardo G Altmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adilson</forename><forename type="middle">E</forename><surname>Pierrehumbert</surname></persName>
		</author>
		<author>
			<persName><surname>Motter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS one</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">7678</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Anthropic</surname></persName>
		</author>
		<ptr target="https://www.anthropic.com/index/introducing-claude" />
		<title level="m">Introducing Claude</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">Yuntao</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurav</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandipan</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jackson</forename><surname>Kernion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Goldie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Azalia</forename><surname>Mirhoseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cameron</forename><surname>Mckinnon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.08073</idno>
		<title level="m">Constitutional AI: Harmlessness from ai feedback</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Addressing &quot;documentation debt</title>
		<author>
			<persName><forename type="first">Jack</forename><surname>Bandy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Vincent</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.05241</idno>
	</analytic>
	<monogr>
		<title level="m">machine learning research: A retrospective datasheet for bookcorpus</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The Pushshift Reddit dataset</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Baumgartner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Savvas</forename><surname>Zannettou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Keegan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Megan</forename><surname>Squire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Blackburn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international AAAI conference on web and social media</title>
		<meeting>the international AAAI conference on web and social media</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="830" to="839" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Linguistic fundamentals for natural language processing: 100 essentials from morphology and syntax</title>
		<author>
			<persName><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis lectures on human language technologies</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="184" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Data statements for natural language processing: Toward mitigating system bias and enabling better science</title>
		<author>
			<persName><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Batya</forename><surname>Friedman</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00041</idno>
		<ptr target="https://aclanthology.org/Q18-1041" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="587" to="604" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hailey</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Anthony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Herbie</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O'</forename><surname>Kyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Brien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Hallahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shivanshu</forename><surname>Aflah Khan</surname></persName>
		</author>
		<author>
			<persName><surname>Purohit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Usvsn Sai Prashanth</surname></persName>
		</author>
		<author>
			<persName><surname>Raff</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.01373</idno>
		<title level="m">A suite for analyzing large language models across training and scaling</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">GPT-NeoX-20B: An open-source autoregressive language model. Challenges &amp; Perspectives in Creating Large Language Models</title>
		<author>
			<persName><forename type="first">Sid</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Hallahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Anthony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leo</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurence</forename><surname>Golding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Horace</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Connor</forename><surname>Leahy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Mcdonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Phang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">95</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><surname>Amodei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">One billion word benchmark for measuring progress in statistical language modeling</title>
		<author>
			<persName><forename type="first">Ciprian</forename><surname>Chelba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Brants</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tony</forename><surname>Robinson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.3005</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiming</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henrique</forename><surname>Ponde De Oliveira Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harri</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuri</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Brockman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.03374</idno>
		<ptr target="https://arxiv.org/abs/2107.03374" />
		<title level="m">Evaluating large language models trained on code</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parker</forename><surname>Schuh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.02311</idno>
		<ptr target="https://arxiv.org/abs/2204.02311" />
		<title level="m">Scaling language modeling with Pathways</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Scaling instruction-finetuned language models</title>
		<author>
			<persName><forename type="first">Chung</forename><surname>Hyung Won</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shayne</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddhartha</forename><surname>Brahma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.11416</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Unimax: Fairer and more effective language sampling for large-scale multilingual pretraining</title>
		<author>
			<persName><forename type="first">Chung</forename><surname>Hyung Won</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Cohere</surname></persName>
		</author>
		<ptr target="https://docs.cohere.com/docs/command-beta" />
		<title level="m">Cohere command nightly</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.09774</idno>
		<title level="m">Inconsistency in conference peer review: Revisiting the 2014 NeurIPS experiment</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Plug and play language models: A simple approach to controlled text generation</title>
		<author>
			<persName><forename type="first">Sumanth</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janice</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jane</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piero</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rosanne</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/N19-1423" />
	</analytic>
	<monogr>
		<title level="j">NAACL</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Time-aware language models as temporal knowledge bases</title>
		<author>
			<persName><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><forename type="middle">R</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Martin Eisenschlos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="257" to="273" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Documenting large webtext corpora: A case study on the Colossal Clean Crawled Corpus</title>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ana</forename><surname>Marasović</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Agnew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Ilharco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Groeneveld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1286" to="1305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">Nan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Lepikhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxim</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liam</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zongwei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><forename type="middle">Emma</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kellie</forename><surname>Webster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie</forename><surname>Pellat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathleen</forename><surname>Meier-Hellstern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toju</forename><surname>Duke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Dixon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonghui</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><surname>Glam</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2112.06905" />
		<title level="m">Efficient Scaling of Language Models with Mixture-of-Experts. ICML</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Diffusion of lexical change in social media</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O'</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2014">113114. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">More effective boilerplate removal-the goldminer algorithm</title>
		<author>
			<persName><forename type="first">István</forename><surname>Endrédy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Attila</forename><surname>Novák</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Polibits</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="79" to="83" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Mrqa 2019 shared task: Evaluating generalization in reading comprehension</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Machine Reading for Question Answering</title>
		<meeting>the 2nd Workshop on Machine Reading for Question Answering</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Dis/similarities in the design and development of legal and algorithmic normative systems: the case of perspective api. Law, Innovation and Technology</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Friedl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">Leo</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sid</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurence</forename><surname>Golding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Travis</forename><surname>Hoppe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Phang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Horace</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anish</forename><surname>Thite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noa</forename><surname>Nabeshima</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00027</idno>
		<title level="m">The Pile: An 800GB dataset of diverse text for language modeling</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Making pre-trained language models better few-shot learners</title>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.295</idno>
		<ptr target="https://aclanthology.org/2021.acl-long.295" />
	</analytic>
	<monogr>
		<title level="j">ACL</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Evaluating models&apos; local decision boundaries via contrast sets</title>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victoria</forename><surname>Basmov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Bogin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sihao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dheeru</forename><surname>Dua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanai</forename><surname>Elazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananth</forename><surname>Gottumukkala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1307" to="1323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Analyzing and addressing the difference in toxicity prediction between different comments with same semantic meaning in Google&apos;s Perspective API</title>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Sk Gargee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shridhar</forename><surname>Bhargav Gopinath</surname></persName>
		</author>
		<author>
			<persName><surname>Reddy Sr Kancharla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anoop</forename><forename type="middle">S</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><surname>Babu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICT Systems and Sustainability: Proceedings of ICT4SD 2022</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="455" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">Timnit</forename><surname>Gebru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Morgenstern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Briana</forename><surname>Vecchione</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><forename type="middle">Wortman</forename><surname>Vaughan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanna</forename><surname>Wallach</surname></persName>
		</author>
		<title level="m">Hal Daumé III au2, and Kate Crawford. Datasheets for datasets</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">RealToxicityPrompts: Evaluating neural toxic degeneration in language models</title>
		<author>
			<persName><forename type="first">Suchin</forename><surname>Samuel Gehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Gururangan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3356" to="3369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Gokaslan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">*</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Vanya</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">*</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Tellex</surname></persName>
		</author>
		<ptr target="http://Skylion007.github.io/OpenWebTextCorpus" />
		<title level="m">OpenWebText corpus</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">PaLM 2 technical report</title>
		<author>
			<persName><surname>Google</surname></persName>
		</author>
		<ptr target="https://cloud.google.com/dlp/docs/infotypes-reference" />
	</analytic>
	<monogr>
		<title level="m">Google Cloud NLP. Google Cloud infotype detector, 2023a</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Google Cloud analyzing sentiment</title>
		<author>
			<persName><forename type="first">Google</forename><surname>Cloud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nlp</forename></persName>
		</author>
		<ptr target="https://cloud.google.com/natural-language/docs/analyzing-sentiment" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Don&apos;t stop pretraining: Adapt language models to domains and tasks</title>
		<author>
			<persName><forename type="first">Suchin</forename><surname>Gururangan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ana</forename><surname>Marasović</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Swabha</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8342" to="8360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">Suchin</forename><surname>Gururangan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dallas</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarah</forename><forename type="middle">K</forename><surname>Drier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><forename type="middle">K</forename><surname>Gade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leroy</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.10474</idno>
		<title level="m">Whose language counts as high quality? Measuring language ideologies in text data selection</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Toxigen: A large-scale machine-generated dataset for adversarial and implicit hate speech detection</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Hartvigsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saadia</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Palangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipankar</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ece</forename><surname>Kamar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3309" to="3326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Training compute-optimal large language models</title>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eliza</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>De Las</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><forename type="middle">Anne</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><surname>Clark</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.15556</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">On the complementarity of data selection and fine tuning for domain adaptation</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Iter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.07591</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Diachronic degradation of language models: Insights from social media</title>
		<author>
			<persName><forename type="first">Kokil</forename><surname>Jaidka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niyati</forename><surname>Chhaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lyle</forename><surname>Ungar</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-2032</idno>
		<ptr target="https://aclanthology.org/P18-2032" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-07">July 2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="195" to="200" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">TemporalWiki: A lifelong benchmark for training and evaluating ever-evolving language models</title>
		<author>
			<persName><forename type="first">Joel</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seonghyeon</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sohee</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joongbo</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janghoon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gyeonghun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.14211</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">The minipile challenge for data-efficient language models</title>
		<author>
			<persName><forename type="first">Jean</forename><surname>Kaddour</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.08442</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.08361</idno>
		<ptr target="https://arxiv.org/abs/2001.08361" />
		<title level="m">Scaling laws for neural language models</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">UnifiedQA: Crossing format boundaries with a single QA system</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2020.findings-emnlp" />
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Derivation of new readability formulas (automated readability index, fog count and flesch reading ease formula) for navy enlisted personnel</title>
		<author>
			<persName><forename type="first">Kincaid</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert P Fishburne</forename><surname>Jr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">L</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brad</forename><forename type="middle">S</forename><surname>Chissom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
		</imprint>
		<respStmt>
			<orgName>Naval Technical Training Command Millington TN Research Branch</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Quality at a glance: An audit of web-crawled multilingual datasets</title>
		<author>
			<persName><forename type="first">Julia</forename><surname>Kreutzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isaac</forename><surname>Caswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahsan</forename><surname>Wahab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Van Esch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nasanbayar</forename><surname>Ulzii-Orshikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allahsera</forename><surname>Tapo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nishant</forename><surname>Subramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artem</forename><surname>Sokolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claytone</forename><surname>Sikasote</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="50" to="72" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Natural Questions: a benchmark for question answering research</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivia</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danielle</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="453" to="466" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Principles of linguistic change</title>
		<author>
			<persName><forename type="first">William</forename><surname>Labov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>John Wiley &amp; Sons</publisher>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note>Cognitive and cultural factors</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">ALBERT: A lite BERT for self-supervised learning of language representations</title>
		<author>
			<persName><forename type="first">Zhenzhong</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingda</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piyush</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">The BigScience ROOTS Corpus: A 1.6TB composite multilingual dataset</title>
		<author>
			<persName><forename type="first">Lucile</forename><surname>Hugo Laurençon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Saulnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Villanova Del Moral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leandro</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenghao</forename><surname>Von Werra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduardo</forename><forename type="middle">González</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huu</forename><surname>Ponferrada</surname></persName>
		</author>
		<author>
			<persName><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Mind the gap: Assessing temporal generalization in neural language models</title>
		<author>
			<persName><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adhi</forename><surname>Kuncoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Gribovskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devang</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Liska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tayfun</forename><surname>Terzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mai</forename><surname>Gimenez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cyprien</forename><surname>De Masson D'autume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Kocisky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="29348" to="29363" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Deduplicating training data makes language models better</title>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Nystrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douglas</forename><surname>Eck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="8424" to="8445" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName><forename type="first">Alyssa</forename><surname>Lees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Vinh Q Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jai</forename><surname>Sorensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucy</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><surname>Vasserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.11176</idno>
		<ptr target="http://perspectiveapi.com.com" />
		<title level="m">A new generation of Perspective API: Efficient multilingual character-level transformers</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">StreamingQA: A benchmark for adaptation to new knowledge over time in question answering models</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Liska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Kocisky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Gribovskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tayfun</forename><surname>Terzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eren</forename><surname>Sezener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devang</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cyprien</forename><surname>De Masson D'autume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Scholtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susannah</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><surname>Gilsenan-Mcmahon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sophia</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<ptr target="https://proceedings.mlr.press/v162/liska22a/liska22a.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International Conference on Machine Learning</title>
		<meeting>the 39th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="13604" to="13622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><surname>Roberta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">An exploration of data augmentation and sampling techniques for domain-agnostic question answering</title>
		<author>
			<persName><forename type="first">Shayne</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhucheng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dubois</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Machine Reading for Question Answering</title>
		<meeting>the 2nd Workshop on Machine Reading for Question Answering</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="220" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Entitybased knowledge conflicts in question answering</title>
		<author>
			<persName><forename type="first">Shayne</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kartik</forename><surname>Perisetla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="7052" to="7063" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Active learning over multiple domains in natural language tasks</title>
		<author>
			<persName><forename type="first">Shayne</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julia</forename><surname>Rachel Reisler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Dubois</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS 2022 Workshop on Distribution Shifts: Connecting Methods and Applications</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">Shayne</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tu</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><surname>Wei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.13688</idno>
		<title level="m">The Flan collection: Designing data and methods for effective instruction tuning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">What&apos;s in the box? a preliminary analysis of undesirable content in the Common Crawl corpus</title>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Sasha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luccioni</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">D</forename><surname>Viviano</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.02732</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Time waits for no one! analysis and challenges of temporal misalignment</title>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suchin</forename><surname>Gururangan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karishma</forename><surname>Mandyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.07408</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Language models of code are few-shot commonsense learners</title>
		<author>
			<persName><forename type="first">Aman</forename><surname>Madaan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuyan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uri</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">An empirical survey of the effectiveness of debiasing techniques for pre-trained language models</title>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Meade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elinor</forename><surname>Poole-Dayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1878" to="1898" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Combining compressions for multiplicative size scaling on natural language tasks</title>
		<author>
			<persName><forename type="first">Rajiv</forename><surname>Movva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinhao</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shayne</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ajay</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dubois</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Computational Linguistics</title>
		<meeting>the 29th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2861" to="2872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">DALL-E 2 pre-training mitigations</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<ptr target="https://openai.com/research/dall-e-2-pre-training-mitigations" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Glide: Towards photorealistic image generation and editing with textguided diffusion models</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Quinn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nichol</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bob</forename><surname>Mcgrew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<ptr target="https://open.nytimes.com/to-apply-machine-learning-responsibly-we-use-it-in-moderation" />
	</analytic>
	<monogr>
		<title level="m">The Open Team NYT. To apply machine learning responsibly, we use it in moderation</title>
		<imprint>
			<date type="published" when="2020">2022. 2022. 2020</date>
			<biblScope unit="page" from="16784" to="16804" />
		</imprint>
	</monogr>
	<note>Nostalgebraist. Chinchilla&apos;s wild implications PMLR International Conference on Machine Learning d001f49e0644</note>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<idno>arxiv:2303.08774</idno>
		<ptr target="https://arxiv.org/pdf/2303.08774.pdf" />
		<title level="m">OpenAI. GPT-4 technical report</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<author>
			<persName><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diogo</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carroll</forename><forename type="middle">L</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katarina</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.02155</idno>
		<ptr target="https://arxiv.org/abs/2203.02155" />
		<title level="m">Training language models to follow instructions with human feedback</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Learning music helps you read: Using transfer to study linguistic structure in language models</title>
		<author>
			<persName><forename type="first">Isabel</forename><surname>Papadimitriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6829" to="6839" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/N18-1202" />
		<title level="m">Deep contextualized word representations. NAACL</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">On the challenges of using black-box APIs for toxicity evaluation in research</title>
		<author>
			<persName><forename type="first">Luiza</forename><surname>Amador Pozzobon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beyza</forename><surname>Ermis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Hooker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR 2023 Workshop on Trustworthy and Reliable Large-Scale Machine Learning Models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Intermediate-task transfer learning with pretrained language models: When and why does it work?</title>
		<author>
			<persName><forename type="first">Yada</forename><surname>Pruksachatkun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Phang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haokun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mon</forename><surname>Phu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyi</forename><surname>Htut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">Yuanzhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clara</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katharina</forename><surname>Vania</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Kann</surname></persName>
		</author>
		<author>
			<persName><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5231" to="5247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<ptr target="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" />
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<author>
			<persName><forename type="first">Jack</forename><forename type="middle">W</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katie</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francis</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Aslanides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Ring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susannah</forename><surname>Young</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.11446</idno>
		<ptr target="https://arxiv.org/abs/2112.11446" />
		<title level="m">Scaling language models: Methods, analysis &amp; insights from training Gopher</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1910.10683" />
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anselm</forename><surname>Levskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Andor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Gaffney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Afroz</forename><surname>Mohiuddin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Curtis</forename><surname>Hawthorne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Salcianu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Marc Van Zee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Livio Baldini</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haitang</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasha</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Tsvyashchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jasmijn</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jannis</forename><surname>Bastings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Bulian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianmo</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathleen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">H</forename><surname>Kenealy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Garrette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Lee-Thorp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marvin</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Maitin-Shepard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Fiedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brennan</forename><surname>Omernick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Saeta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Sepassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Spiridonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Newlan</surname></persName>
		</author>
		<author>
			<persName><surname>Gesmundo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.17189</idno>
		<ptr target="https://arxiv.org/abs/2203.17189" />
		<title level="m">Scaling up models and data with t5x and seqio</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Changing the world by changing the data</title>
		<author>
			<persName><forename type="first">Anna</forename><surname>Rogers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2182" to="2194" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Temporal adaptation of BERT and performance on downstream document classification: Insights from social media</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Röttger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janet</forename><surname>Pierrehumbert</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-emnlp.206</idno>
		<ptr target="https://aclanthology.org/2021.findings-emnlp.206" />
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
		<meeting><address><addrLine>Punta Cana, Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11">November 2021</date>
			<biblScope unit="page" from="2400" to="2412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Everyone wants to do the model work, not the data work&quot;: Data cascades in high-stakes AI</title>
		<author>
			<persName><forename type="first">Nithya</forename><surname>Sambasivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shivani</forename><surname>Kapania</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannah</forename><surname>Highfill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diana</forename><surname>Akrong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lora</forename><forename type="middle">M</forename><surname>Aroyo</surname></persName>
		</author>
		<idno type="DOI">10.1145/3411764.3445518</idno>
		<ptr target="https://doi.org/10.1145/3411764.3445518" />
	</analytic>
	<monogr>
		<title level="m">CHI, CHI &apos;21</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Social bias frames: Reasoning about social and power implications of language</title>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saadia</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lianhui</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.486</idno>
		<ptr target="https://aclanthology.org/2020.acl-main.486" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07">July 2020</date>
			<biblScope unit="page" from="5477" to="5490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<author>
			<persName><forename type="first">Le</forename><surname>Teven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellie</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suzana</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ilić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Hesslow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Castagné</surname></persName>
		</author>
		<author>
			<persName><forename type="first">François</forename><surname>Sasha Luccioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Yvon</surname></persName>
		</author>
		<author>
			<persName><surname>Gallé</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.05100</idno>
		<title level="m">A 176b-parameter open-access multilingual language model</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Reinforcement learning from human feedback: Progress and challenges</title>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<ptr target="https://www.youtube.com/watch?v=hhiLw5Q_UFg" />
	</analytic>
	<monogr>
		<title level="j">Berkeley EECS</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">The MultiBERTs: BERT reproductions for robustness analysis</title>
		<author>
			<persName><forename type="first">Thibault</forename><surname>Sellam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Yadlowsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Tenney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naomi</forename><surname>Saphra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D'</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Amour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jasmijn</forename><surname>Linzen</surname></persName>
		</author>
		<author>
			<persName><surname>Bastings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raluca</forename><surname>Iulia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Turc</surname></persName>
		</author>
		<author>
			<persName><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Addressing distribution shift at test time in pre-trained language models</title>
		<author>
			<persName><forename type="first">Ayush</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">E</forename><surname>Ortega</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.02384</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Everything in moderation: An analysis of how internet platforms are using artificial intelligence to moderate user-generated content</title>
		<author>
			<persName><forename type="first">Spandana</forename><surname>Singh</surname></persName>
		</author>
		<ptr target="https://www.newamerica.org/oti/reports/everything-moderation-analysis-how-internet-platforms-are-using-artificial-intelligence-moderate-user-generated-content/" />
	</analytic>
	<monogr>
		<title level="j">New America</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<author>
			<persName><forename type="first">Rohan</forename><surname>Taori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuechen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsunori</forename><forename type="middle">B</forename><surname>Hashimoto</surname></persName>
		</author>
		<ptr target="https://github.com/tatsu-lab/stanford_alpaca" />
		<title level="m">Stanford Alpaca: An instruction-following LLaMA model</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samira</forename><surname>Abnar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinfeng</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dani</forename><surname>Vinh Q Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName><surname>Metzler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.10551</idno>
		<title level="m">Scaling laws vs model architectures: How does inductive bias influence scaling? arXiv preprint</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<author>
			<persName><forename type="first">Romal</forename><surname>Thoppilan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">De</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Apoorv</forename><surname>Kulshreshtha</surname></persName>
		</author>
		<author>
			<persName><surname>Heng-Tze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alicia</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leslie</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><surname>Du</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.08239</idno>
		<ptr target="https://arxiv.org/abs/2201.08239" />
		<title level="m">Language models for dialog applications</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title level="m" type="main">LLaMA: Open and efficient foundation language models</title>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibaut</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Martinet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothée</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baptiste</forename><surname>Rozière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Hambro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faisal</forename><surname>Azhar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.13971</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Learning from the worst: Dynamically generated datasets to improve online hate detection</title>
		<author>
			<persName><forename type="first">Bertie</forename><surname>Vidgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Thrush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeerak</forename><surname>Waseem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.132</idno>
		<ptr target="https://aclanthology.org/2021.acl-long.132" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08">August 2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1667" to="1682" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">Will we run out of data? an analysis of the limits of scaling datasets in machine learning</title>
		<author>
			<persName><forename type="first">Pablo</forename><surname>Villalobos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Sevilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lennart</forename><surname>Heim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tamay</forename><surname>Besiroglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marius</forename><surname>Hobbhahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anson</forename><surname>Ho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.04325</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">What language model architecture and pretraining objective work best for zero-shot generalization?</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Hesslow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Launay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2204.05832" />
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Balancing training for multilingual neural machine translation</title>
		<author>
			<persName><forename type="first">Xinyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8526" to="8537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title level="m" type="main">Learning which features matter: RoBERTa acquires a preference for linguistic generalizations (eventually)</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Warstadt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haau-Sing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haokun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Samuel R Bowman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.05358</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Emergent abilities of large language models</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=yzkSU5zdwD" />
	</analytic>
	<monogr>
		<title level="j">TMLR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Challenges in detoxifying language models</title>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amelia</forename><surname>Glaese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Uesato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumanth</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Mellor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><forename type="middle">Anne</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kirsty</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Coppin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2447" to="2469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Insights into pre-training via simpler synthetic tasks</title>
		<author>
			<persName><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<author>
			<persName><forename type="first">Sang</forename><surname>Michael Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanyi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifeng</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tengyu</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><surname>Doremi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.10429</idno>
		<title level="m">Optimizing data mixtures speeds up language model pretraining</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b102">
	<monogr>
		<title level="m" type="main">Data selection for language models via importance resampling</title>
		<author>
			<persName><forename type="first">Sang</forename><surname>Michael Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shibani</forename><surname>Santurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.03169</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Detoxifying language models risks marginalizing minority voices</title>
		<author>
			<persName><forename type="first">Albert</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eshaan</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suchin</forename><surname>Gururangan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.190</idno>
		<ptr target="https://aclanthology.org/2021.naacl-main.190" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-06">June 2021</date>
			<biblScope unit="page" from="2390" to="2397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">mT5: A massively multilingual pre-trained text-to-text transformer</title>
		<author>
			<persName><forename type="first">Linting</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihir</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Barua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter</title>
		<meeting>the 2021 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="483" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">XLNet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russ</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Wild-Time: A benchmark of in-the-wild distribution shift over time</title>
		<author>
			<persName><forename type="first">Huaxiu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caroline</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bochuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoonho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pang</forename><surname>Wei Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">SituatedQA: Incorporating extra-linguistic contexts into qa</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="7371" to="7387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<monogr>
		<title level="m" type="main">OPT: Open pre-trained transformer language models</title>
		<author>
			<persName><forename type="first">Susan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Dewan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Victoria Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.01068</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<author>
			<persName><forename type="first">Kun</forename><surname>Wayne Xin Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolei</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yupeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingqian</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beichen</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zican</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Dong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.18223</idno>
		<title level="m">A survey of large language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Temporal Degradation Results Luu et al. (2021) measure the temporal degradation due to finetuning and evaluation misalignment. Before attempting to evaluate misalignment effects specifically for pretraining, we mimic their finetuning experiments. Figure 12 shows our results</title>
		<author>
			<persName><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rich</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Luu</surname></persName>
		</author>
		<idno>% 10% 20% 30% C4</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2000">2015. 2000 2003 2006 2012 2015 2018 2021. 2013 2000 2003 2006 2012 2015 2018 2021. 2016 2000 2003 2006 2012 2015 2018 2021 0% 10% 20% 30% C4 2019 2000 2003 2006 2012 2015 2018 2021. 2021. 2010 2012 2014 2016 2010 2012 2014 2016 Finetune</date>
			<biblScope unit="page" from="19" to="27" />
		</imprint>
	</monogr>
	<note>0% 10% 20% 30% C4 Aligning books and movies: Towards story-like visual explanations by watching movies and reading books which corroborate the findings of</note>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">NewSum</title>
		<imprint>
			<date type="published" when="2014">2014 2015 2016 2017 2018 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">TwiERC</title>
		<imprint>
			<date type="published" when="2014">2014 2015 2016 2017 2018 2019 Eval Years 2014-2015 2016-2017 2018-2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
		<title/>
		<author>
			<persName><surname>Aic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2012 2013. 2014 2015 2016 2017 2018 2019 2020 2021 Eval Years 2009-2013 2014-2015 2016-2017 2018-2019 2020-2021 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">This task evaluates Twitter Named Entity Classification with Accuracy</title>
		<author>
			<persName><surname>Luu</surname></persName>
		</author>
		<idno>LM-XL LM-Small 2013 2014-2015 98.0 97.7 94.6 88.0 93.1 83.4 86.1 85.5 85.7 83.2 80.5 81.9 2016-2017 98.2 96.6 94.4 91.6 94.0 88.2 86.1 84.0 84.7 83.9 84.0 83.7 2018-2019 97.4 97.6 94.0 91.5 95.4 87.9 82.9 85.2 84.2 81.2 84.6 85.0</idno>
	</analytic>
	<monogr>
		<title level="j">Pretrain Finetune Eval Time Time Time</title>
		<imprint>
			<date type="published" when="2014">2021. 2014 2015 2016 2017 2018 2019 2014 2015 2016 2017 2018 2019</date>
		</imprint>
	</monogr>
	<note>Table 11: Full results on the TwiERC temporal task splits from</note>
</biblStruct>

<biblStruct xml:id="b115">
	<monogr>
		<title level="m" type="main">This task evaluates the classification of science articles from Semantic Scholar into those published at ICML or AAAI, measured with Accuracy. Pretrain Finetune Eval Time Time Time</title>
		<author>
			<persName><surname>Luu</surname></persName>
		</author>
		<idno>LM-XL LM-Small 2013 2014-2015 98.7 97.5 95.6 89.0 94.0 86.0 74.5 75.3 80.4 74.0 71.9 69.5 2016-2017 98.2 98.0 95.0 93.1 95.2 90.2 74.3 74.0 77.0 75.4 74.7 70.9 2018-2019 97.7 98.5 94.4 91.8 94.0 89.9 68.1 70.2 76.2 71.2 75.4 75.0</idno>
		<imprint>
			<date type="published" when="2014">2021. 2014 2015 2016 2017 2018 2019 2014 2015 2016 2017 2018 2019</date>
		</imprint>
	</monogr>
	<note>Table 12: Full results on the AIC temporal task splits from</note>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">This task evaluates classification of political affiliation from tweets, measured in Accuracy</title>
		<author>
			<persName><surname>Luu</surname></persName>
		</author>
		<idno>XL 2009-2013 100.0 100.0 95.5 73.5 65.4 56.5 51.1 70.1 74.2 67.2</idno>
	</analytic>
	<monogr>
		<title level="j">Pretrain Finetune Eval Time Time Time</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<date type="published" when="2012">2021. 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021. 2014-2015 95</date>
		</imprint>
	</monogr>
	<note>Full results on the PoliAff temporal task splits from Table</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
