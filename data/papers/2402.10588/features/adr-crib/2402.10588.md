Here are detailed technical explanations and justifications for the researchers' decisions regarding the various aspects of their study on the Llama-2 family of transformer models:

### 1. Decision to Focus on the Llama-2 Family of Transformer Models
The Llama-2 family represents some of the largest and most widely used open-source language models available, making them a suitable choice for studying multilingual capabilities. Their architecture and training on a large, diverse corpus allow for a comprehensive analysis of how these models handle non-English prompts. Additionally, the availability of the models facilitates reproducibility and further research.

### 2. Choice of Using Non-English Prompts for Testing
Using non-English prompts is crucial for investigating whether the models implicitly use English as a pivot language. By employing prompts in various languages, the researchers can directly assess the model's behavior and performance in those languages, providing insights into how well the model generalizes beyond its dominant English training data.

### 3. Methodology for Tracking Intermediate Embeddings Through Layers
Tracking intermediate embeddings allows researchers to observe how the model processes information at different stages of its architecture. This methodology provides insights into the transformation of input embeddings as they progress through the layers, revealing how the model's understanding evolves and whether it aligns with the expected output in the target language.

### 4. Selection of Logit Lens Technique for Analyzing Model Behavior
The logit lens technique enables researchers to decode intermediate token representations by applying the language modeling head prematurely in earlier layers. This approach allows for the examination of how the model's internal states relate to the final output, providing a clearer picture of whether the model is operating in an English-centric manner or genuinely processing non-English inputs.

### 5. Assumption Regarding the Existence of an Internal Pivot Language
The assumption that an internal pivot language exists is grounded in the hypothesis that models trained predominantly on English data may rely on English representations when processing other languages. This assumption is critical for exploring potential biases and understanding the mechanisms behind the model's performance across languages.

### 6. Framework for Categorizing Phases of Embedding Transformation
The categorization into "input space," "concept space," and "output space" provides a structured way to analyze the model's processing stages. This framework helps clarify how embeddings transition from raw input representations to semantically meaningful outputs, highlighting the role of intermediate layers in shaping the final predictions.

### 7. Decision to Analyze Latent Embeddings as High-Dimensional Euclidean Points
Analyzing latent embeddings as high-dimensional Euclidean points allows for a geometric interpretation of the model's internal representations. This perspective facilitates the understanding of how different languages and concepts are represented in the model's latent space, revealing potential biases and relationships between languages.

### 8. Choice of Multilingual Corpus Dominated by English for Training
The decision to use a multilingual corpus that is predominantly English reflects the reality of most large language models, which are often trained on unbalanced datasets. This choice is essential for examining the implications of English bias and understanding how it affects the model's performance in other languages.

### 9. Decision to Utilize Specific Model Sizes (7B, 13B, 70B Parameters)
The selection of different model sizes allows for a comparative analysis of how model capacity influences performance across languages. By studying various sizes, researchers can assess whether larger models exhibit different behaviors regarding the use of English as a pivot language compared to smaller models.

### 10. Use of 8-Bit Quantization in Experiments
8-bit quantization is employed to reduce the memory footprint and computational requirements of the models during experiments. This choice enables researchers to run analyses more efficiently while maintaining a balance between performance and resource utilization.

### 11. Decision to Focus on the Implications of English Bias in Multilingual Models
Focusing on English bias is crucial for understanding the limitations and potential pitfalls of multilingual models. By investigating how this bias manifests, researchers can identify areas for improvement and develop strategies to mitigate its effects on model performance in non-English contexts.

### 12. Assumption About the Relationship Between Concept Space and Language-Specific Token Space
The assumption that concept space is distinct from language-specific token space allows researchers to explore how abstract representations of meaning are influenced by the model's training data. This distinction is vital for understanding how the model navigates between different languages and whether it relies on English-centric representations.

### 13. Choice of Evaluation Metrics for Determining Semantic Correctness of Decoded Tokens
Selecting appropriate evaluation metrics is essential for accurately assessing the model's performance in generating semantically correct outputs. By using metrics that align with the study's goals, researchers can ensure that their findings are robust and meaningful.

### 14. Decision to Make Code and Data Publicly Available for Reproducibility
Making code and data publicly available promotes transparency and reproducibility in research. This decision allows other researchers to validate findings, build upon the work, and contribute to the ongoing discourse surrounding multilingual language models.

### 15. Assumption Regarding the Impact of Training Data Composition on Model Performance Across Languages
The assumption that training data composition