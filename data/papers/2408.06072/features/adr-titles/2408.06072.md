- Decision to use a 3D Variational Autoencoder for video compression
- Choice of expert Transformer architecture for text-video alignment
- Implementation of progressive training techniques
- Adoption of Explicit Uniform Sampling for training stability
- Design of a video captioning pipeline for improved semantic understanding
- Use of multi-resolution frame packing during training
- Selection of mixed-duration training approach
- Decision to employ 3D full attention mechanism
- Implementation of Expert Adaptive Layernorm for modality alignment
- Choice of rotary positional embedding (3D-RoPE) for video data
- Strategy for context parallelism in 3D convolution
- Decision to incorporate GAN loss in training
- Choice of loss functions for training (L1, LPIPS, KL loss)
- Decision to release models publicly as open-source
- Strategy for handling varying video lengths and resolutions during training
- Decision to fine-tune on high-quality video subsets after initial training