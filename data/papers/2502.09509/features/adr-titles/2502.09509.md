- Decision to focus on equivariance in latent space for generative modeling
- Choice of EQ-VAE as a regularization method
- Selection of pre-trained autoencoders for fine-tuning
- Compatibility of EQ-VAE with both continuous and discrete autoencoders
- Decision to penalize discrepancies between transformed latent representations and corresponding transformations of input images
- Choice of training objectives for autoencoders (e.g., reconstruction loss, adversarial loss, regularization)
- Decision to evaluate performance improvements using FID scores
- Choice of generative models for testing EQ-VAE (e.g., DiT, SiT, REPA, MaskGIT)
- Decision to measure training speedup and convergence acceleration
- Assumption about the impact of equivariance on generative performance
- Decision to document empirical results and comparisons with state-of-the-art models
- Choice of architectural constraints versus regularization strategies
- Decision to explore the trade-off between reconstruction quality and latent space complexity
- Assumption regarding the limitations of existing autoencoder architectures
- Decision to leverage existing literature on equivariance in computer vision for methodological inspiration