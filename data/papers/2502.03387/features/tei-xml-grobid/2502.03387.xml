<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Generative AI Research LIMO: Less is More for Reasoning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-02-05">5 Feb 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yixin</forename><surname>Ye</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>AIME24 Kaoyan Grade School GPQA Gaokao CHMath Olympiad Bench Minerva AMC23 MATH500</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhen</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>AIME24 Kaoyan Grade School GPQA Gaokao CHMath Olympiad Bench Minerva AMC23 MATH500</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yang</forename><surname>Xiao</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>AIME24 Kaoyan Grade School GPQA Gaokao CHMath Olympiad Bench Minerva AMC23 MATH500</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ethan</forename><surname>Chern</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>AIME24 Kaoyan Grade School GPQA Gaokao CHMath Olympiad Bench Minerva AMC23 MATH500</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shijie</forename><surname>Xia</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>AIME24 Kaoyan Grade School GPQA Gaokao CHMath Olympiad Bench Minerva AMC23 MATH500</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>AIME24 Kaoyan Grade School GPQA Gaokao CHMath Olympiad Bench Minerva AMC23 MATH500</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>SII, GAIR</roleName><forename type="first">â€ </forename><surname>Sjtu</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>AIME24 Kaoyan Grade School GPQA Gaokao CHMath Olympiad Bench Minerva AMC23 MATH500</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Generative AI Research LIMO: Less is More for Reasoning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-02-05">5 Feb 2025</date>
						</imprint>
					</monogr>
					<idno type="MD5">57E06A2C8560A77A1702F9B05F3FCE9F</idno>
					<idno type="arXiv">arXiv:2502.03387v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-02-21T16:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a fundamental discovery that challenges our understanding of how complex reasoning emerges in large language models. While conventional wisdom suggests that sophisticated reasoning tasks demand extensive training data (often &gt; 100, 000 examples), we demonstrate a striking phenomenon: complex mathematical reasoning abilities can be effectively elicited with surprisingly few examples. This finding challenges not only the assumption of massive data requirements but also the common belief that supervised fine-tuning primarily leads to memorization rather than generalization. Through comprehensive experiments, our proposed model LIMO demonstrates unprecedented performance and efficiency in mathematical reasoning. With merely 817 curated training samples, LIMO achieves 57.1% accuracy on the highly challenging AIME benchmark and 94.8% on MATH, improving the performance of previous strong SFT-based models from 6.5% to 57.1% on AIME and from 59.2% to 94.8% on MATH, while only using 1% of the training data required by previous approaches. Most remarkably, LIMO demonstrates exceptional out-of-distribution generalization, achieving 40.5% absolute improvement across 10 diverse benchmarks, outperforming models trained on 100x more data, directly challenging the prevailing notion that SFT inherently leads to memorization rather than generalization. Synthesizing these pioneering results, we propose the Less-Is-More Reasoning Hypothesis (LIMO Hypothesis): In foundation models where domain knowledge has been comprehensively encoded during pre-training, sophisticated reasoning capabilities can emerge through minimal but precisely orchestrated demonstrations of cognitive processes. This hypothesis posits that the elicitation threshold for complex reasoning is not inherently bounded by the complexity of the target reasoning task, but fundamentally determined by two key factors: ( <ref type="formula">1</ref>) the completeness of the model's encoded knowledge foundation during pre-training, and (2) the effectiveness of post-training examples, which serve as "cognitive templates" that show the model how to effectively utilize its existing knowledge base to solve complex reasoning tasks. To facilitate reproducibility and future research in data-efficient reasoning, we release LIMO as a comprehensive open-source suite at <ref type="url" target="https://github.com/GAIR-NLP/LIMO">https://github.com/GAIR-NLP/LIMO</ref>.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1 Introduction</p><p>Complex reasoning has long been considered one of the most challenging capabilities to instill in large language models (LLMs). While recent work has shown that LLMs can be effectively aligned with user preferences through relatively small amounts of instruction data <ref type="bibr">(Zhou et al., 2024a)</ref>, teaching models to reason-particularly in mathematics and programming-is widely believed to require vastly more training examples <ref type="bibr" target="#b23">(Paster et al., 2023;</ref><ref type="bibr" target="#b41">Yue et al., 2024)</ref>. This conventional wisdom stems from the inherent complexity of reasoning tasks, which demand multi-step logical deduction, domain knowledge application, and structured solution paths. The resulting paradigm typically involves training on tens or hundreds of thousands of examples <ref type="bibr" target="#b39">(Yu et al., 2024;</ref><ref type="bibr">Li et al., 2024b)</ref>, based on two fundamental assumptions: first, that mastering such complex cognitive processes requires extensive supervised demonstrations, and second, that supervised fine-tuning leads primarily to memorization rather than true generalization <ref type="bibr" target="#b42">(Zhang et al., 2024;</ref><ref type="bibr" target="#b36">Xu et al., 2024;</ref><ref type="bibr" target="#b4">Chu et al., 2025)</ref>.</p><p>While this approach has shown success, it imposes substantial computational costs and data collection burdens. More importantly, we argue this data-intensive paradigm may no longer be necessary. Recent advances have fundamentally transformed how LLMs acquire, organize, and utilize reasoning knowledge, suggesting the possibility of a more efficient approach. Two key developments in particular have created the conditions for a fundamental reimagining of how we approach reasoning in LLMs:</p><p>1. Knowledge Foundation Revolution: Modern foundation models now incorporate unprecedented amounts of mathematical content during pre-training <ref type="bibr">(Qwen et al., 2025;</ref><ref type="bibr" target="#b37">Yang et al., 2024;</ref><ref type="bibr" target="#b33">Wang et al., 2024)</ref>. For example: Llama 2's total training data across all domains was 1.8T tokens <ref type="bibr">(Touvron et al., 2023)</ref>, while Llama 3 used 3.7T tokens just for mathematical reasoning <ref type="bibr">(Grattafiori et al., 2024)</ref>. This suggests that contemporary LLMs may already possess rich mathematical knowledge in their parameter space, transforming the challenge from knowledge acquisition to knowledge elicitation. 2. Inference-time Computation Scaling Revolution: The emergence of techniques scaling longer reasoning chains has revealed that effective reasoning requires substantial computational space during inference. Recent works (OpenAI et al., 2024; <ref type="bibr" target="#b24">Qin et al., 2024;</ref><ref type="bibr" target="#b11">Huang et al., 2024)</ref> have shown that allowing models to generate extended reasoning chains significantly improves their reasoning ability. In essence, inference-time computation provides the crucial cognitive workspace where models can systematically unpack and apply their pre-trained knowledge.</p><p>We hypothesize that successful reasoning emerges from the synergy of these two factors: rich pre-trained knowledge and sufficient computational resources at inference time. These developments collectively suggest a striking possibility: if models possess rich reasoning knowledge and are given adequate computational space, then activating their reasoning capabilities may require only a small number of high-quality training samples that encourage extended deliberation, rather than massive fine-tuning datasets. Building on this insight, we propose the Less-Is-More Reasoning (LIMO) Hypothesis. This hypothesis identifies two critical factors that determine the elicitation threshold for complex reasoning: <ref type="bibr" target="#b0">(1)</ref> the latent presence of prerequisite knowledge within the model's parameter space, and (2) the effectiveness of minimal exemplars in demonstrating systematic problem-solving processes that encourage extended deliberation. Critically, this suggests that the sample efficiency of eliciting advanced reasoning is not inherently bounded by the complexity of the target reasoning task, but rather by the completeness of the model's encoded knowledge foundation and its exposure to training samples that effectively utilize the inference-time computation space.</p><p>Through comprehensive experiments, we demonstrate that LIMO achieves 57.1% accuracy on the highly challenging AIME benchmark and 94.8% on MATH with merely 817 training samples, demolishing previous strong SFT-based models while using just 1% of their training data. Most remarkably, these benefits generalize across a diverse spectrum of previously unseen scenarios, with LIMO consistently outperforming models trained on 100x more data by 40.5% absolute improvement. This discovery has profound implications for artificial intelligence research: it suggests that even competition-level complex reasoning abilities can be effectively elicited through minimal but curated training samples. More fundamentally, it points to a promising technical pathway toward AGIany sophisticated reasoning capability, no matter how complex, could potentially be activated with minimal samples given two key conditions: (1) sufficient domain knowledge embedded during pre-training, and (2) optimal cognitive reasoning chains for activation. This represents not merely an argument for data efficiency, but a fundamental insight into how complex reasoning capabilities emerge in large language models.</p><p>The main contributions of this work are: <ref type="bibr" target="#b0">(1)</ref> We establish the LIMO hypothesis, demonstrating that complex reasoning capabilities can be elicited through surprisingly small datasets (hundreds of examples) by leveraging rich mathematical knowledge in pre-trained models and detailed reasoning chains. <ref type="bibr" target="#b1">(2)</ref> We provide systematic empirical evidence challenging current assumptions about scaling laws in reasoning tasks, showing that benefits generalize robustly to out-of-distribution problems and suggesting the acquisition of genuine reasoning capabilities rather -Optimal structure with adaptive step granularity -Strategic cognitive scaffolding for reasoning -Rigorous verification throughout solution than superficial pattern matching. (3) We identify critical factors for effective reasoning elicitation, particularly the synergy between pre-trained knowledge foundations and test-time computation scaling, providing insights into how these advances can be combined to achieve superior reasoning performance with minimal fine-tuning data. (4) We release a comprehensive open-source suite including our fine-tuned models, evaluation pipelines, training code, and carefully curated datasets with varying quality levels. This release enables systematic investigation of data efficiency in complex reasoning and facilitates reproducibility of our findings, while providing valuable resources for future research in this direction.</p><p>2 Phenomena Rethinking: Less-is-More and RL Scaling</p><p>The emergence of LIMO represents a paradigm shift in how we conceptualize and activate complex reasoning capabilities in large language models. This section examines two key comparisons that illuminate the fundamental nature of this advance: first, contrasting LIMO with LIMA to understand how Less-is-More principles extend from general alignment to complex reasoning; and second, comparing LIMO with reinforcement learning (RL) scaling approaches to highlight distinct philosophical perspectives on developing reasoning capabilities. Through these analyses, we aim to establish a deeper understanding of how complex cognitive abilities emerge in language models and the conditions that enable their efficient activation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">LIMO vs LIMA</head><p>The emergence of Less-is-More phenomena in LLMs represents a fundamental shift in our understanding of how complex capabilities can be elicited with minimal data. While LIMA <ref type="bibr">(Zhou et al., 2024a)</ref> first demonstrated this phenomenon in the context of general alignment, extending this principle to complex mathematical reasoning presents unique challenges and requirements. This section examines the critical developments that enable Less-is-More for reasoning, analyzing the essential differences between alignment and reasoning scenarios, and providing insights into the conditions necessary for efficient capability activation in large language models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Knowledge Foundation Revolution</head><p>The past two years have witnessed a transformation in how language models acquire and organize mathematical knowledge. While LIMA could rely on general text corpora for alignment, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Synergistic Convergence</head><p>The timing of LIMO's discovery reflects the necessary convergence of these two revolutions. The two-year gap between LIMA and LIMO represents not just the time needed for better pretrained models, but the essential wait for inference-time computation breakthroughs. This convergence enables a phenomenon we call the Reasoning Elicitation Threshold: when models possess both rich domain knowledge and sufficient computation space, complex reasoning capabilities can be activated with minimal but precise demonstrations.</p><p>Implications for Future Research This comparative analysis reveals Less-is-More not merely as an advocacy for using fewer data, but as a fundamental principle governing the efficient elicitation of model capabilities. The success of LIMO demonstrates that when essential prerequisites (knowledge foundation and computation framework) are met, complex capabilities can be elicited with remarkable data efficiency. This insight suggests a new research direction: systematically identifying the prerequisites and optimal activation conditions for different capabilities.</p><p>Future work should explore whether other advanced capabilities (e.g., planning, creative problem-solving) can achieve similar efficiency once their corresponding knowledge and computation foundations are established. The Less-is-More principle thus serves as both a theoretical framework for understanding capability emergence and a practical guide for pursuing data-efficient capability development across various domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">LIMO vs RL Scaling</head><p>The emergence of two distinct approaches to developing reasoning capabilities in large language models -RL Scaling and LIMO -represents a fundamental divergence in how we understand and enhance model intelligence. RL Scaling, exemplified by works like o1 (OpenAI, 2024), DeepSeek-R1 (Guo et al., 2025), approaches the challenge from an engineering optimization perspective. It assumes that reasoning capabilities need to be extensively trained into models through large-scale reinforcement learning. While effective, this approach essentially treats RL as a broad search mechanism to discover effective reasoning patterns through massive computational resources. In contrast, LIMO introduces a more foundational perspective: reasoning capabilities are already latent within pre-trained models, embedded during the pre-training phase. The key challenge shifts from "training" to "elicitation" -finding precise cognitive templates that can elicit these innate abilities. From this perspective, RL Scaling approaches like DeepSeek-R1 can be viewed as specific implementations of this principle, using reinforcement learning as a mechanism to search for such trajectories. While both approaches ultimately seek high-quality reasoning solutions, LIMO offers a more principled and direct path through explicit trajectory design, while RL Scaling discovers these trajectories through extensive computational exploration. This reframing suggests that various methods, including RL, expert design, or hybrid approaches, could all be understood and evaluated within LIMO's framework as different strategies for discovering optimal reasoning trajectories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">LIMO Dataset</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The LIMO Hypothesis</head><p>We formalize the Less-Is-More Reasoning (LIMO) Hypothesis as follows: In foundation models where domain knowledge has been comprehensively encoded during pre-training, sophisticated reasoning capabilities can emerge through minimal but precisely orchestrated demonstrations of cognitive processes. This hypothesis rests on two fundamental premises: (I) The latent presence of prerequisite knowledge within the model's parameter space (II) The quality of reasoning chains that precisely decompose complex problems into detailed, logical steps, making the cognitive process explicit and traceable. To validate this hypothesis, we propose a systematic approach to construct a high-quality, minimal dataset that can effectively elicit the model's inherent reasoning capabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Problem Definition</head><p>In this paper, we focus on the reasoning tasks with verifiable answer. Given a question q âˆˆ Q, where Q represents the space of reasoning problems, the goal is to generate an answer a âˆˆ A and a reasoning chain r âˆˆ R. We define a reasoning chain r as a sequence of intermediate steps {s 1 , s 2 , ..., s n }, where each step s i represents a logical deduction that bridges the gap between the question and the final answer.</p><p>Formally, we can represent the reasoning process as a function f :</p><formula xml:id="formula_0">f : Q â†’ R Ã— A<label>(1)</label></formula><p>Therefore, the quality of the resulting dataset D is determined by two fundamental yet multifaceted components: (1) the quality of questions q âˆˆ Q, which encompasses factors such as diversity in problem-solving approaches, appropriate difficulty levels to challenge model capabilities, and the breadth of knowledge domains covered, and (2) the quality of solutions (r, a) âˆˆ R Ã— A, which encompasses aspects including pedagogical value, logical coherence, and methodological rigor. Questions should be designed to encourage sophisticated reasoning patterns and knowledge integration, while solutions should demonstrate clear logical progression and serve as effective learning examples. These interrelated quality dimensions, among others, guide our systematic data curation process detailed in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">High-Quality Data Curation</head><p>Our data curation process focuses on constructing a high-quality dataset D = {(q i , r i , a i )} N i=1 where N is intentionally kept small to validate our LIMO hypothesis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Question Selection</head><p>We hypothesize that high-quality questions q âˆˆ Q should naturally elicit extended reasoning processes. Our selection criteria include the following:</p><p>â€¢ Level of difficulty We prioritize challenging problems that foster complex reasoning chains, diverse thought processes, and knowledge integration, enabling LLMs to effectively leverage pre-trained knowledge for highquality inference. â€¢ Generality Problems that deviate more from the model's training distribution can better challenge its fixed thinking patterns, encourage exploration of new reasoning approaches, thus expanding its inference search space. â€¢ Knowledge Diversity The selected problems should cover various mathematical domains and concepts, requiring the model to integrate and connect distant knowledge during problem-solving.</p><p>To implement these criteria effectively, we first assembled a comprehensive pool of candidate problems from various established datasets: NuminaMath-CoT, featuring meticulously annotated problems from high school to advanced competition levels; AIME historical examination problems, known for its extremely challenging and integrative problems spanning multiple mathematical domains; MATH <ref type="bibr" target="#b10">(Hendrycks et al., 2021)</ref>, encompassing various competitive mathematics problems from prestigious contests; and several other sources of mathematical problems.</p><p>From this rich initial collection, we employed a systematic multi-stage filtration process. Beginning with an initial pool of tens of millions of problems, we first applied a baseline difficulty filter using Qwen2.5-Math-7B-Instruct <ref type="bibr" target="#b37">(Yang et al., 2024)</ref>, eliminating problems that this model could solve correctly in a few attempts. This process helped establish a preliminary difficulty threshold. Subsequently, we subjected the remaining problems to a more rigorous evaluation using state-of-the-art reasoning models including R1, DeepSeek-R1-Distill-Qwen-32B (Guo et al., 2025), and models from <ref type="bibr" target="#b11">Huang et al. (2024)</ref>, retaining only problems where even these most capable models achieved success rates below certain threshold through multiple sampling iterations. Finally, to maintain corpus diversity, we employed strategic sampling techniques that balanced representation across mathematical domains and complexity levels while avoiding conceptual redundancy. This meticulous selection process ultimately yielded 817 carefully curated problems from an initial pool of tens of millions of candidates, with the selected problems collectively satisfying our stringent quality criteria while spanning a rich spectrum of mathematical reasoning challenges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Reasoning Chain Construction</head><p>Beyond high-quality questions, the quality of solutions plays a pivotal role in the training phase of large language models. To curate high-quality solutions, we adopted a comprehensive selection strategy. We began by gathering official solutions for problems where available, complemented by solutions authored by both human experts and AI specialists. Additionally, we leveraged state-of-the-art reasoning models, including DeepSeek R1, DeepSeek-R1-Distill-Qwen-32B (Guo et al., 2025), and Qwen2.5-32b-Instruct, to generate diverse solution approaches. Furthermore, following the methodology proposed in O1-Journey-Part2 (Huang et al., 2024), we utilized selfdistillation techniques based on Qwen2.5-32b-Instruct to create additional model variants, which were then used to generate supplementary problem responses. These responses were then filtered according to the correctness of the answers to establish a baseline collection of valid solutions. Subsequently, all the authors conducted a comprehensive analysis of these filtered solutions through collaborative examination. Through careful observation and systematic review, we identified several key characteristics that distinguish high-quality reasoning chains:</p><p>â€¢ Optimal Structural Organization: The solution exhibits clear and well-organized structural formatting, with adaptive granularity in step decomposition. Particularly, it allocates more tokens and detailed elaboration at crucial reasoning junctures while maintaining concise expressions for straightforward steps. This self-adaptive approach to step granularity ensures that complex transitions receive appropriate attention while avoiding unnecessary verbosity in simpler deductions. â€¢ Effective Cognitive Scaffolding: High-quality solutions provide strategic educational support by gradually building understanding through carefully structured explanations. This includes progressive concept introduction, clear articulation of key insights at critical points, and thoughtful bridging of conceptual gaps, making complex reasoning processes more accessible and learnable. â€¢ Rigorous Verification: High-quality solutions incorporate extremely frequent verification steps throughout the reasoning process. This includes validating intermediate results, cross-checking assumptions, and confirming the logical consistency of each deduction, thereby ensuring the reliability of the final answer.</p><p>Based on these identified characteristics, we developed a hybrid approach combining rule-based filtering and LLM-assisted curation to select high-quality solutions for each question identified in the previous section. This systematic process ensures that each selected solution adheres to our established quality criteria while maintaining consistency across the dataset. By focusing on a minimal yet meticulously curated set of reasoning chains, we embody the core principle of Less-Is-More: high-quality demonstrations, rather than sheer data volume, are key to unlocking complex reasoning capabilities. The resulting dataset D consists of carefully curated triples (q, r, a), where each reasoning chain r satisfies our quality criteria. By maintaining these stringent standards while limiting the dataset size |D|, we aim to demonstrate that high-quality demonstrations, rather than large quantities of training data, are crucial for unlocking complex reasoning capabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methodology</head><p>Based on the Less-Is-More principle, a model with substantial reasoning knowledge from pre-training and the ability to perform long-chain reasoning at test time can develop robust reasoning abilities. After training on only a few hundred instances of SFT data, the model learns to integrate meta-reasoning tasks into a cohesive reasoning chain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Training Protocol</head><p>We fine-tune Qwen2.5-32B-Instruct using supervised fine-tuning on our LIMO dataset. The training process employs full-parameter fine-tuning with DeepSpeed ZeRO-3 optimization (Rajbhandari et al., 2020) and FlashAttention-2 (Dao, 2023), with a sequence length limit of 16,384 tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation Framework</head><p>In-domain Evaluation To comprehensively assess the models' performance across various reasoning capabilities, we have established a diverse evaluation framework encompassing both traditional and novel benchmarks. Our primary evaluation suite includes several well-established mathematical competitions and benchmarks: the American Invitational Mathematics Examination (AIME24), MATH500 <ref type="bibr" target="#b10">(Hendrycks et al., 2021)</ref>, and the American Mathematics Competitions (AMC23).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Out-of-distribution Evaluation</head><p>To rigorously evaluate the models' performance on out-of-distribution (OOD) tasks, we carefully selected benchmarks that differ from our training data in various aspects. These benchmarks can be categorized into three distinct groups:</p><p>â€¢ Diverse Mathematical Competitions: We furthur selected OlympiadBench (He et al., 2024), which represents a distinct distribution of mathematical challenges to test models' OOD performance. â€¢ Novel Multilingual Benchmarks: To minimize data contamination, we constructed several benchmarks using the most recent examination problems: CHMath from the 2024 Chinese High School Mathematics League Competition, Gaokao from China's 2024 National College Entrance Examination, Kaoyan from Chinese Graduate School Entrance Examinations, and GradeSchool, our newly developed benchmark for elementary mathematical reasoning. Notably, all problems in these benchmarks are written in Chinese, while our training data contains no Chinese problems. This introduces an additional OOD dimension, assessing not only the model's ability to generalize across problem distributions but also its cross-lingual reasoning capabilities when confronted with unseen languages. â€¢ Multi-disciplinary Benchmarks: To assess broader generalization capabilities beyond mathematics (our training domain), we incorporated Miverva (Lewkowycz et al., 2022) (which includes undergraduate-level STEM problems) and GPQA (Rein et al., 2023). These benchmarks evaluate reasoning abilities across multiple disciplines and cognitive levels, providing insights into the model's capacity to transfer mathematical reasoning skills to broader contexts.</p><p>Performance metrics We evaluate performance using the pass@1 metric across our suite of benchmarks. All evaluations are conducted in a Zero-shot Chain-of-Thought (CoT) setting to better assess the model's reasoning capabilities. For benchmarks including MATH500, OlympiadBench, Gaokao, Kaoyan, GradeSchool, MinervaMath, and GPQA, we employ a straightforward approach using greedy decoding with a single sample to assess correctness. However, for the smaller benchmarks containing fewer than 50 problems each (specifically AIME24, AMC23, and CHMATH), we implement a more thorough evaluation protocol, generating 16 samples with a temperature setting of 0.7 and calculating the unbiased pass@1 metric as introduced in Chen et al. (2021). For problems where answers are well-structured numerical values, we directly apply rule-based evaluations to check for mathematical equivalence.</p><p>For more complex answer formats-such as expressions, equations, or structured solutions-we leverage an LLM-based evaluator, which we have validated for high reliability. Throughout all evaluations, we maintain a maximum output length of 32,768 tokens to minimize the potential for output truncation, ensuring our assessment captures complete problem-solving attempts. Additionally, when evaluating LIMO, we observed that inference-time scaling occasionally results in repetitive patterns at the end of lengthy outputs. In such cases, we extract the most likely final answer from the model's response for evaluation to ensure accurate assessment of its problem-solving capabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Baselines</head><p>We compare LIMO against a comprehensive set of baselines with the following prominent models:</p><p>â€¢ OpenAI-o1-preview (OpenAI, 2024), a large language model that has demonstrated advanced mathematical reasoning abilities across various complex tasks. â€¢ QwQ-32B-Preview (Team, 2024b), a model specifically designed for mathematical problem-solving with strong reasoning capabilities. â€¢ Qwen2.5-32B-Instruct, which serves as our base model for comparative analysis.</p><p>For evaluation, we use the OpenAI API to access OpenAI-o1-preview, while using VLLM <ref type="bibr" target="#b14">(Kwon et al., 2023)</ref> to deploy other open-weight models (e.g. QwQ-32B-Preview). To ensure fair comparison, all models follow the same evaluation protocol with identical inference hyper-parameters.</p><p>To investigate the impact of training data efficiency, we conduct comparative experiments using mainstream open-source reasoning datasets for supervised fine-tuning on our base model. For a fair comparison, all experiments use the same LLM backbone as LIMO, ensuring that performance differences are solely attributable to the training data characteristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Main Results</head><p>â€¢ OpenThoughts-114k:<ref type="foot" target="#foot_0">foot_0</ref> A synthetic reasoning dataset containing 114k examples covering mathematics, science, coding, and puzzles. The solutions follow a structured reasoning format generated by DeepSeek-R1. â€¢ NuminaMath-100k: A randomly selected 100k subset of NuminaMath-CoT, featuring mathematical problems ranging from Chinese high school exercises to international mathematics olympiad competitions. Each solution follows a Chain of Thought (CoT) format <ref type="bibr" target="#b34">(Wei et al., 2022)</ref>.</p><p>These datasets contain substantially more samples than LIMO's training set (817 examples), allowing us to examine the relationship between data quantity and model performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Main Results</head><p>Our experimental results demonstrate LIMO's superior performance across both in-domain and out-of-domain tasks, as shown in Table <ref type="table" target="#tab_4">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>In-domain</head><p>Performance On in-domain tasks, LIMO achieves the best results across all benchmarks. For AIME24, LIMO achieves 57.1% accuracy, outperforming QwQ-32B-Preview (50.0%) and OpenAI-o1-preview (44.6%) by significant margins. Most notably, on MATH500, LIMO achieves 94.8% accuracy, surpassing QwQ-32B-Preview (89.8%) and OpenAI-o1-preview (85.5%). The performance gap is even more pronounced on AMC23, where LIMO reaches 92.0% accuracy compared to QwQ-32B-Preview's 83.6%. Out-of-domain Generalization LIMO demonstrates strong generalization capabilities across diverse out-ofdomain tasks. On OlympiadBench, LIMO achieves 66.8% accuracy, significantly outperforming QwQ-32B-Preview (58.5%) and the base model (45.3%). Similar improvements are observed on other challenging benchmarks such as CHMath (75.4% vs 68.5%) and GradeSchool (76.2% vs 63.8%). Notably, LIMO maintains competitive performance even on GPQA, where it achieves 66.7% accuracy, close to OpenAI-o1-preview's leading score of 73.3%. Comparison with Larger Datasets Our experiments reveal that despite larger scale, both baseline datasets underperform compared to LIMO. NuminaMath-100k shows significant degradation (32.3% vs. base model's 49.9%) due to uncurated reasoning chains, while OpenThoughts-114k achieves suboptimal results (58.3%) probably due to unfocused problem selection. In contrast, LIMO's carefully curated 817 problems yield superior performance (72.8%), demonstrating that targeted selection and high-quality annotations are more crucial than data quantity for developing robust reasoning capabilities.</p><p>Overall Performance LIMO achieves the highest average performance of 72.1% across all benchmarks, substantially outperforming OpenAI-o1-preview (67.8%), QwQ-32B-Preview (66.4%), and other baselines. This comprehensive evaluation demonstrates that LIMO's carefully curated training approach with just 817 examples can outperform models trained on datasets that are orders of magnitude larger.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">RQ1: Impact of Reasoning Chain Quality</head><p>To gain a deeper understanding of why Less-Is-More achieves such remarkable results, we investigate the quality of reasoning chains (CoT). A fundamental question naturally arises: what characteristics define a high-quality reasoning chain that leads to superior model performance? To address this, we conducted a controlled comparative study examining how solutions of varying quality for the same problem statements affect the performance of models trained on them.</p><p>Setup To conduct this analysis, we selected 500 problems from the LIMO dataset. The selection was based on the intersection of problems for which the models used in rejection sampling exhibited performance differences and those with corresponding human-annotated solutions, ensuring consistency across comparisons. For these 500 problems, we collected and categorized solutions into five distinct quality levels based on our comprehensive evaluation framework. These solutions were sourced from various origins, including human experts, AI specialists, and model-generated responses, then classified strictly based on their reasoning quality rather than their source.</p><p>Quality Measure Following the principles outlined in Section 3.3.2, we took a holistic approach to categorize the reasoning chains into five quality levels (L1-L5, with L5 being the highest). Our assessment focused on several key aspects: how well the steps were organized and connected, whether important logical transitions were properly explained, and if the solution included self-verification steps to check the work. Using these general guidelines, we classified L5 solutions as those showing excellent organization with clear, well-explained steps and thorough self-verification. L4 solutions were also well-structured but perhaps with slightly less rigorous checking. L3 solutions showed decent organization but sometimes skipped over explaining crucial logical leaps. L2 solutions often provided abbreviated reasoning without much explanation, while L1 solutions typically just listed basic steps with minimal elaboration and rarely included any verification. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Our training results (Figure <ref type="figure" target="#fig_2">2</ref>) strongly correlate with the reasoning chain quality levels. Models trained on L5 quality reasoning chains achieved the highest performance on both AIME24 and MATH500, demonstrating the effectiveness of well-structured, detailed, and self-verified reasoning. Performance consistently decreased with each quality level, with L4 and L3 showing moderate success, while L2 and L1 resulted in notably lower performance. These results empirically validate our quality assessment framework and highlight the crucial role of high-quality reasoning chains in model performance. Specifically, we observed that the performance gap between L5 and L1 solutions was substantial -approximately 15 percentage points on AIME24 and 12 percentage points on MATH500. This significant difference suggests that the quality of reasoning chains plays a far more important role in model performance than previously assumed, reinforcing the importance of carefully curating training data to include well-structured, thorough solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">RQ2: Impact of Question Quality</head><p>We hypothesize that more challenging problems foster complex reasoning chains, diverse thought processes, and enhanced knowledge integration, enabling LLMs to better leverage pre-trained knowledge for high-quality inference. To validate this hypothesis, we investigate how question quality affects the reasoning capabilities of models fine-tuned on these questions and their corresponding solutions.</p><p>Setup We selected three sets of problems of similar size but increasing difficulty, constructing solutions in a consistent manner to form three training datasets. Our findings indicate that models trained on more challenging datasets exhibit superior reasoning performance. Specifically, we sampled three sets of problems, each containing 500 samples, from MATH and AIME:</p><p>â€¢ Simple-500: 500 simple problems randomly selected problems from MATH levels 1 and 2.</p><p>â€¢ Complex-500: 500 complex problems randomly selected problems from MATH levels 3, 4, and 5.</p><p>â€¢ Advanced-500: 500 advanced problems randomly selected problems from past AIME tests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Analysis</head><p>To rigorously establish the increasing difficulty of these sets, we evaluated various LLMs on them, observing a decline in accuracy and an increase in the average length of correctly generated reasoning chains.</p><p>We then used DeepSeek-R1 to generate solutions, which represent the highest-quality solutions available, for each problem set, forming the training data for fine-tuning Qwen2.5-32B-Instruct.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We evaluate all three fine-tuned models on the AIME2024 and MATH500 benchmarks to assess their reasoning performance. The results (Figure <ref type="figure" target="#fig_3">3</ref>) indicate that modifying the selection of problems alone leads to a 16% improvement in accuracy on the challenging AIME2024 benchmark, reaching 51.5%. Furthermore, despite the absence of in-domain training data, the model fine-tuned on Advanced-500 outperforms the other two models, achieving an accuracy of 91.2% on the MATH500 benchmark. This result suggests that the improvement in reasoning ability due to increased problem difficulty generalizes across datasets. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">RQ3: LLM Backbone</head><p>Building on our LIMO hypothesis, which emphasizes the importance of latent prerequisite knowledge within the model's parameter space, we examine how different pre-training data affect a model's capacity to leverage minimal exemplars for mathematical reasoning. This investigation allows us to assess the first key factor of our hypothesis: the role of pre-trained knowledge in enabling complex reasoning capabilities.</p><p>Setup To isolate the impact of pre-training while controlling for model architecture and fine-tuning procedures, we conduct experiments using two 32B-parameter variants of the Qwen model family: Qwen1.5-32B-Chat (Team, 2024a) and Qwen2.5-32B-Instruct (the base model of LIMO). Both models share the same architecture and parameter count, while Qwen2.5 demonstrates significant improvements in pre-training data quality, particularly in mathematical and code-related data, compared to its predecessor. We SFT both models using identical LIMO datasets and evaluation protocols, assessing their performance on the AIME2024 and MATH500 benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Our experiments reveal that the choice of pre-trained model dramatically impacts reasoning performance, as demonstrated in 4. LIMO, built on Qwen2.5-32B-Instruct, significantly outperforms its predecessor across both benchmarks. On the challenging AIME2024 test, LIMO achieves 57.1% accuracy, a remarkable 47.1 percentage point improvement over Qwen1.5-32B-Instruct's 10.0%. Similarly, on MATH500, LIMO demonstrates exceptional performance with 94.8% accuracy, surpassing Qwen1.5-32B-Instruct by 34.4 percentage points. These substantial improvements suggest that the enhanced pre-training in Qwen2.5 creates a stronger foundation for mathematical reasoning. The results align with our LIMO hypothesis, indicating that richer pre-trained knowledge within the model's parameter space enables more effective utilization of minimal exemplars during fine-tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.4">Case study</head><p>Qualitative Analysis Fig. <ref type="figure" target="#fig_5">5</ref> compares responses generated by Qwen2.5-32B-Instruct, DeepSeek-R1, and LIMO. LIMO achieves capabilities and behaviors comparable to DeepSeek-R1, despite using minimal data and compute resources (only 817 training samples). Notably, LIMO demonstrates strong self-reflection and long chain-of-thought generation capabilities. LIMO verifies its own statements ("Wait, 24 minutes is 0.4 hours? Wait, no. Wait, 60 minutes is 1 hour, so 24 minutes is 24/60, which is 0.4 hours") and validates its calculations ("But let me check again. Maybe I made a mistake in calculations."). Furthermore, it learns to allocate additional tokens (compute) for detailed complex equation-solving ("Now let's compute the left side, â€¢ â€¢ â€¢ , multiply both sides by 2) to prevent errors. In contrast, the base model Qwen2.5-32B-Instruct exhibits limitations in its reasoning process, being unable to correct inaccurate statements and failing to cross verify equation 2 in its solution. These results Okay, let's see. So Aya goes for a 9-km walk every morning and then stops at a coffee shop. The time she takes for the walk, including the time in the coffee shop, depends on her walking speed. [omitted for brevityâ€¦]. When she walks a bit faster, at s plus 2 kilometers per hour, the total time is 2 hours and 24 minutes, which is 2 hours and 24 minutes, so that's 2.4 hours? Wait, 24 minutes is 0.4 hours? Wait, no. Wait, 60 minutes is 1 hour, so 24 minutes is 24/60, which is 0.4 hours. So 2 hours and 24 minutes is 2.4 hours. [omitted for brevityâ€¦] So, let's set up equations. Let's denote the walking time as T1 when she walks at s km/h, and T2 when she walks at s+2 km/h. Then, T1 + t = 4 hours, and T2 + t = 2.4 hours. But t is in minutes, so we need to convert that to hours or convert the total time to minutes. Maybe it's better to keep everything in hours. So t minutes is t/60 hours. [omitted for brevityâ€¦] For the first case: walking time T1 = 9/s hours, then total time T1 + t/60 = 4 hours. For the second case: walking time T2 = 9/(s+2) hours, then total time T2 + t/60 = 2.4 hours. So now we have two equations: 1) 9/s + t/60 = 4, 2) 9/(s+2) + t/60 = 2.4 Let me write that as: 9*(1/s -1/(s+2)) = 1.6. So, 1/s -1/(s+2) = 1.6/9 Let me compute 1.6 divided by 9. Quantitative Analysis Table <ref type="table" target="#tab_5">4</ref> demonstrates the differences between models trained with varying sample quality. We observe a general trend where increasing post-training example quality leads to models that generate longer responses with more lines. Additionally, these higher-quality models employ more self-reflecting transitions (e.g., wait, perhaps, maybe, therefore) to allocate additional inference tokens (compute) for deeper thinking.</p><p>6 Background and Related Work ). These curated corpora can be composed of multiple sources, such as textbooks, scientific papers, and mathematical code, which capture diverse human cognitive patterns used to solve problems. In the post-training phase, a line of research focuses on curating large-scale instruction data to teach LLMs to reason <ref type="bibr" target="#b40">(Yue et al., 2023</ref><ref type="bibr" target="#b41">(Yue et al., , 2024;;</ref><ref type="bibr">Li et al., 2024a)</ref>. This includes scaling the number of questions and their corresponding solutions. The scaling approach is promising and has achieved significant performance gains. However, the reasoning ability gained through this method has been criticized for relying on the memorization of fixed patterns rather than achieving true generalization <ref type="bibr">(Mirzadeh et al., 2024;</ref><ref type="bibr" target="#b42">Zhang et al., 2024)</ref>. For example, <ref type="bibr">Mirzadeh et al. (2024)</ref> finds that LLMs exhibit noticeable variance when responding to different instantiations of the same question, and their performance declines when only the numerical values in the question are altered. This raises doubts about the generalization capability of SFT methods <ref type="bibr" target="#b4">(Chu et al., 2025)</ref> and whether LLMs can be true reasoners rather than mere knowledge retrievers (Kambhampati, 2024).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Test-time Scaling and Long Chain Reasoning</head><p>Instead of focusing on scaling model parameters and training data <ref type="bibr" target="#b13">(Kaplan et al., 2020)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Data Efficiency in Language Models</head><p>Zhou et al. (2024a) demonstrates that with just 1,000 carefully curated prompts and responses, models can learn to follow specific formats and generalize well to unseen tasks. The findings emphasize the importance of quality over quantity in the alignment process. However, whether this lesson can be applied to reasoning tasks remains uncertain, given the potential high computational complexity of such tasks <ref type="bibr" target="#b19">(Merrill and Sabharwal, 2024;</ref><ref type="bibr" target="#b35">Xiang et al., 2025)</ref>. While some work on reasoning highlights the importance of quality during the curation of training data <ref type="bibr">(Zhou et al., 2024b)</ref>, the quantity of such data is still much larger compared to that in LIMA. Our work extends the ideology of LIMA to reasoning tasks by investigating what constitutes high-quality questions and solutions, and demonstrates that the reasoning ability of LLMs can be enhanced in a highly data-efficient manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Future Work</head><p>While LIMO demonstrates remarkable success in mathematical reasoning with minimal data, several promising directions remain for future exploration.</p><p>Domain Generalization: First, extending the LIMO hypothesis to broader reasoning domains represents a critical next step. While our work focuses on mathematical reasoning, the principles of high-quality reasoning chains could potentially generalize to scientific reasoning, logical deduction, and causal inference. Understanding how these principles transfer across domains could reveal universal patterns in effective reasoning. This exploration would require adapting our quality metrics and developing domain-specific evaluation frameworks, ultimately contributing to a more comprehensive theory of machine reasoning.</p><p>Theoretical Foundations: A deeper theoretical understanding of LIMO's success is also essential. Future research should focus on formalizing the relationship between pre-training knowledge, inference-time computation, and reasoning capabilities. This includes investigating the minimum threshold of pre-trained knowledge required for effective reasoning and developing mathematical models to predict the optimal balance between reasoning chain quality and quantity. Such theoretical foundations could guide the development of more efficient training strategies and provide insights into the fundamental nature of machine reasoning.</p><p>Automated Assessment: The development of automated quality assessment tools represents another crucial direction. Current manual evaluation of reasoning chain quality, while effective, is time-consuming and difficult to scale. Future work should focus on creating automated systems that can evaluate and improve reasoning chain quality based on our proposed metrics. This could include developing algorithms that automatically enhance existing reasoning chains and generate high-quality ones with minimal human intervention, making the LIMO approach more accessible and scalable.</p><p>Multi-modal Integration: Cross-modal reasoning presents an exciting frontier for extending LIMO's principles.</p><p>As real-world reasoning often involves multiple modalities, investigating how visual information and structured data can enhance mathematical reasoning capabilities is crucial. This research direction would require developing new quality metrics for multi-modal reasoning chains and understanding how different types of information can be effectively integrated into the reasoning process.</p><p>Real-world Impact: The application of LIMO principles to real-world scenarios deserves significant attention. Future work should focus on adapting these approaches to practical problems in education, scientific research, and industrial applications. This includes developing specialized versions of LIMO for specific domains and creating tools that help human experts generate high-quality reasoning chains for complex real-world problems. Such applications could significantly impact how we approach problem-solving in various fields.</p><p>Cognitive Science Bridge: Finally, integrating insights from cognitive science could provide valuable directions for improvement. Understanding the parallels between LIMO's reasoning patterns and human cognitive processes could inform the development of more effective reasoning strategies. This includes studying how different reasoning approaches affect model performance and generalization, and incorporating cognitive science principles into the design of reasoning chains. Such research could not only improve AI systems but also provide insights into human reasoning processes. These future directions collectively aim to deepen our understanding of efficient reasoning in large language models while expanding their practical applications. By pursuing these paths, we can work toward more sophisticated, efficient, and widely applicable reasoning systems that better serve human needs across various domains.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: LIMO achieves substantial improvement over NuminaMath with fewer samples while excelling across diverse mathematical and multi-discipline benchmarks.</figDesc><graphic coords="1,137.85,517.50,132.99,123.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Comparison of models trained on reasoning chains of different quality levels.</figDesc><graphic coords="9,399.18,429.76,124.10,124.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Performance comparison on MATH and AIME benchmarks between models trained on different question quality: Simple-500, Complex-500, and Advanced-500.</figDesc><graphic coords="10,139.69,199.66,315.88,124.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Impact of Pre-trained Model Choice on Mathematical Reasoning Performance</figDesc><graphic coords="11,139.69,61.27,315.88,83.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Comparison between the responses generated by Qwen2.5-32B-Instruct, DeepSeek-R1, and LIMO</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>6. 1</head><label>1</label><figDesc>Evolution of Mathematical Reasoning in LLMsLarge-scale training data has been the driving force behind the development of reasoning abilities in LLMs. In the pretraining phase, the reasoning ability of LLMs can be enhanced by relevant corpora(Wang et  al., 2024; Azerbayev et al., 2024; Paster et al., 2023; Shao et al., 2024</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparative Analysis: Less-is-More Phenomena in Language Models</figDesc><table><row><cell>Aspect</cell><cell>General Alignment (LIMA)</cell><cell>Complex Reasoning (LIMO)</cell></row><row><cell cols="2">Core Capability Response format and style adaptation for general-</cell><cell>Multi-step logical inference and complex cogni-</cell></row><row><cell></cell><cell>purpose interaction</cell><cell>tive reasoning</cell></row><row><cell>Knowledge Foundation</cell><cell>â€¢ General text corpus sufficient â€¢ Social interaction patterns</cell><cell>â€¢ Diverse reasoning paradigms and problem-solving approaches</cell></row><row><cell></cell><cell>â€¢ Basic world knowledge</cell><cell>â€¢ Rich context for exploring alternative solutions</cell></row><row><cell></cell><cell></cell><cell>â€¢ Deep conceptual connections across domains</cell></row><row><cell>Computation Requirements</cell><cell>â€¢ Fixed-length generation sufficient â€¢ Single-pass processing adequate</cell><cell>â€¢ Scalable inference-time computation essential â€¢ Extended reasoning chain support required</cell></row><row><cell></cell><cell>â€¢ Limited context window acceptable</cell><cell>â€¢ Large cognitive workspace necessary</cell></row><row><cell>Historical</cell><cell>Emerged in 2023, requiring only:</cell><cell>Emerged in 2025, requiring convergence of:</cell></row><row><cell>Prerequisites</cell><cell>â€¢ Base models with general knowledge</cell><cell>â€¢ Advanced reasoning architectures</cell></row><row><cell></cell><cell>â€¢ Basic prompt engineering techniques</cell><cell>â€¢ Inference-time scaling revolution</cell></row><row><cell>Training Data Quality</cell><cell>â€¢ Question Design: -Common interaction scenarios</cell><cell>â€¢ Question Design: -High-difficulty problems fostering complex</cell></row><row><cell></cell><cell>-Standard task diversity</cell><cell>reasoning</cell></row><row><cell></cell><cell>-Basic instruction following</cell><cell>-Problems deviating from training distribution</cell></row><row><cell></cell><cell>â€¢ Solution Quality:</cell><cell>-Cross-domain knowledge integration chal-</cell></row><row><cell></cell><cell>-Clear communication style</cell><cell>lenges</cell></row><row><cell></cell><cell>-Format consistency</cell><cell>â€¢ Solution Quality:</cell></row><row><cell></cell><cell>-Appropriate tone</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Comparative Analysis of LIMO and RL Scaling Approaches</figDesc><table><row><cell>Aspect</cell><cell>RL Scaling (e.g., o1, R1)</cell><cell>LIMO</cell></row><row><cell></cell><cell>An implementation of the general principle:</cell><cell>The fundamental principle: reasoning</cell></row><row><cell>First Principle</cell><cell>searching for optimal reasoning trajectories</cell><cell>capabilities exist and need to be activated by</cell></row><row><cell></cell><cell>through RL</cell><cell>high-quality reasoning trajectories</cell></row><row><cell>Solution Nature</cell><cell>Discovers reasoning trajectories through extensive RL-based exploration</cell><cell>Directly constructs high-quality reasoning trajectories based on cognitive understanding</cell></row><row><cell>Core Challenge</cell><cell>How to efficiently search for effective reasoning trajectories in a large solution space</cell><cell>How to identify and construct optimal reasoning trajectories that activate existing capabilities</cell></row><row><cell>Methodology</cell><cell>Implicit trajectory discovery through large-scale RL optimization</cell><cell>Explicit trajectory design through cognitive templates</cell></row><row><cell>Search Strategy</cell><cell>Broad exploration of solution space using computational resources</cell><cell>Targeted exploration guided by cognitive principles</cell></row><row><cell>Resource Efficiency</cell><cell>Resource-intensive search process</cell><cell>Resource-efficient direct construction</cell></row><row><cell>Generalization</cell><cell>Through extensive sampling of trajectory space</cell><cell>Through understanding of fundamental reasoning patterns</cell></row><row><cell cols="3">LIMO's success builds upon the rich mathematical content now embedded in modern foundation models through</cell></row><row><cell cols="3">specialized pre-training (Wang et al., 2024). This specialized knowledge foundation serves as a prerequisite for</cell></row><row><cell cols="2">efficient reasoning capability activation.</cell><cell></cell></row><row><cell cols="3">Computation Capability Revolution A crucial distinction between LIMA and LIMO lies in their computational</cell></row><row><cell cols="3">requirements. While LIMA's alignment tasks could be accomplished with fixed-length generation and single-</cell></row><row><cell cols="3">pass processing, LIMO's reasoning tasks demand extensive computation space for multi-step deliberation. The</cell></row><row><cell cols="3">emergence of inference-time scaling techniques (OpenAI et al., 2024; Qin et al., 2024) provided the necessary</cell></row><row><cell cols="3">"cognitive workspace" where models can systematically unpack and apply their pre-trained knowledge.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Comparison of model performance (pass@1) across various mathematical reasoning benchmarks Models include state-of-the-art LLMs (OpenAI-o1-preview, QwQ-32B-Preview), our base model (Qwen2.5-32B-Instruct), and models fine-tuned on different datasets. Training data sizes are shown in parentheses. Best results for each benchmark are shown in bold. Our proposed LIMO model (highlighted in blue) achieves superior performance despite using significantly fewer training examples (817) compared to other fine-tuned models (more than 100k).</figDesc><table><row><cell>Datasets</cell><cell>OpenAI-o1 -preview</cell><cell>Qwen2.5-32B -Instruct</cell><cell>QwQ-32B-preview</cell><cell>OpenThoughts (114k)</cell><cell>NuminaMath (100k)</cell><cell>LIMO ours(817)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>In Domain</cell><cell></cell><cell></cell><cell></cell></row><row><cell>AIME24</cell><cell>44.6</cell><cell>16.5</cell><cell>50.0</cell><cell>50.2</cell><cell>6.5</cell><cell>57.1</cell></row><row><cell>MATH500</cell><cell>85.5</cell><cell>79.4</cell><cell>89.8</cell><cell>80.6</cell><cell>59.2</cell><cell>94.8</cell></row><row><cell>AMC23</cell><cell>81.8</cell><cell>64.0</cell><cell>83.6</cell><cell>80.5</cell><cell>40.6</cell><cell>92.0</cell></row><row><cell></cell><cell></cell><cell cols="2">Out of Domain</cell><cell></cell><cell></cell><cell></cell></row><row><cell>OlympiadBench</cell><cell>52.1</cell><cell>45.3</cell><cell>58.5</cell><cell>56.3</cell><cell>36.7</cell><cell>66.8</cell></row><row><cell>CHMath</cell><cell>50.0</cell><cell>27.3</cell><cell>68.5</cell><cell>74.1</cell><cell>11.2</cell><cell>75.4</cell></row><row><cell>Gaokao</cell><cell>62.1</cell><cell>72.1</cell><cell>80.1</cell><cell>63.2</cell><cell>49.4</cell><cell>81.0</cell></row><row><cell>Kaoyan</cell><cell>51.5</cell><cell>48.2</cell><cell>70.3</cell><cell>54.7</cell><cell>32.7</cell><cell>73.4</cell></row><row><cell>GradeSchool</cell><cell>62.8</cell><cell>56.7</cell><cell>63.8</cell><cell>39.0</cell><cell>36.2</cell><cell>76.2</cell></row><row><cell>Minerva</cell><cell>47.1</cell><cell>41.2</cell><cell>39.0</cell><cell>41.1</cell><cell>24.6</cell><cell>44.9</cell></row><row><cell>GPQA</cell><cell>73.3</cell><cell>48.0</cell><cell>65.1</cell><cell>42.9</cell><cell>25.8</cell><cell>66.7</cell></row><row><cell>AVG.</cell><cell>61.1</cell><cell>49.9</cell><cell>66.9</cell><cell>58.3</cell><cell>32.3</cell><cell>72.8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>, recent work has shifted to exploring test-time scaling<ref type="bibr" target="#b22">(OpenAI, 2024;</ref><ref type="bibr" target="#b29">Snell et al., 2024)</ref>, i.e., increasing the number of tokens to improve 6.3 Data Efficiency in Language Models Statistical analysis of models trained with examples of varying data quality. This table presents three key metrics: average token count per response, average line count per response, and frequently occurring keywords in model-generated responses. Keywords associated with reasoning transitions and uncertainty are highlighted in bold, with common stop words (e.g., "a", "the") excluded to focus on substantive language patterns. Notable differences in response length and keyword usage patterns suggest varying levels of reasoning complexity.</figDesc><table><row><cell>Data Quality Level</cell><cell>Avg. Tokens per</cell><cell>Avg. Lines per</cell><cell>Top 10 Frequently Occurring Keywords (in order)</cell></row><row><cell></cell><cell>response</cell><cell>response</cell><cell></cell></row><row><cell>Level 1</cell><cell>230</cell><cell>9.21</cell><cell>since, however, number, let, thus, which, get, two, triangle,</cell></row><row><cell></cell><cell></cell><cell></cell><cell>theta</cell></row><row><cell>Level 2</cell><cell>444.88</cell><cell>50.68</cell><cell>number, need, times, which, find, list, thus, since, triangle,</cell></row><row><cell></cell><cell></cell><cell></cell><cell>sum</cell></row><row><cell>Level 3</cell><cell>4956.11</cell><cell>375.60</cell><cell>perhaps, alternatively, consider, number, wait, which,</cell></row><row><cell></cell><cell></cell><cell></cell><cell>sides, need, equal, seems</cell></row><row><cell>Level 4</cell><cell>4726.97</cell><cell>354.87</cell><cell>wait, which, number, perhaps, therefore, let, since,</cell></row><row><cell></cell><cell></cell><cell></cell><cell>maybe, sides, two</cell></row><row><cell>Level 5</cell><cell>5290.26</cell><cell>239.29</cell><cell>wait, therefore, which, number, since, lets, two, sides, let,</cell></row><row><cell></cell><cell></cell><cell></cell><cell>maybe</cell></row></table><note><p>performance. This can be achieved by augmenting LLMs with methods such as parallel sampling(Brown et  </p><p>al., 2024; Wang et al., 2022; Li et al., 2022) or symbolic tree search (Hao et al., 2023; Chen et al., 2024; Yao et al., 2023) to enhance reasoning ability. Furthermore, OpenAI (2024); Guo et al. (2025</p><p>) explore training LLMs using reinforcement learning to generate long CoT, which often include self-reflection, verification, and backtracking-processes commonly employed by humans when solving complex problems. This approach not only innovates the training paradigm for LLMs but also provides a new form of training data to augment their reasoning ability. Our work demonstrates that this long CoT exhibits high-quality characteristics in eliciting the inherent reasoning abilities of LLMs.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://github.com/open-thoughts/open-thoughts</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="8">Acknowledgement</head><p>We would like to express our sincere gratitude to <rs type="person">Yixiu Liu</rs> and <rs type="person">Yiwei Qin</rs> for their valuable contributions to this research work. Their expertise, dedication, and collaborative spirit have significantly enhanced the quality of our study. Their insightful suggestions and technical assistance were instrumental in achieving our research objectives. We also wish to extend our appreciation to <rs type="person">Haoyang Zou</rs> and <rs type="person">Xuefeng Li</rs> for their valuable discussions during the early stages of this work. Their perspectives and insights helped shape the foundation of our research.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Hartshorn, Aobo Yang, Archi Mitra, Archie Sravankumar, Artem Korenev, Arthur Hinsvark, Arun Rao, Aston Zhang, Aurelien Rodriguez, Austen Gregerson, Ava Spataru, Baptiste Roziere, Bethany Biron, Binh Tang, Bobbie Chern, Charlotte Caucheteux, Chaya Nayak, Chloe Bi, Chris Marra, Chris McConnell, Christian Keller, Christophe Touret, Chunyang Wu, Corinne Wong, Cristian Canton Ferrer, Cyrus Nikolaidis, Damien Allonsius, Daniel Song, Danielle Pintz, Danny Livshits, Danny Wyatt, David Esiobu, Dhruv Choudhary, Dhruv Mahajan, Diego Garcia-Olano, Diego Perino, Dieuwke Hupkes, Egor Lakomkin, Ehab AlBadawy, Elina Lobanova, Emily Dinan, Eric Michael Smith, Filip Radenovic, Francisco GuzmÃ¡n, Frank Zhang, Gabriel Synnaeve, Gabrielle Lee, Georgia Lewis Anderson, Govind Thattai, Graeme Nail, Gregoire Mialon, Guan Pang, Guillem Cucurell, Hailey Nguyen, Hannah Korevaar, Hu Xu, Hugo Touvron, Iliyan Zarov, Imanol Arrieta Ibarra, Isabel Kloumann, Ishan Misra, Ivan Evtimov, Jack Zhang, Jade Copet, Jaewon Lee, Jan Geffert, Jana Vranes, Jason Park, Jay Mahadeokar, Jeet Shah, Jelmer van der Linde, Jennifer Billock, Jenny Hong, Jenya Lee, Jeremy Fu, Jianfeng Chi, Jianyu Huang, Jiawen Liu, Jie <ref type="bibr">Wang</ref> Collot, Suchin Gururangan, Sydney Borodinsky, Tamar Herman, Tara Fowler, Tarek Sheasha, Thomas Georgiou, Thomas Scialom, Tobias Speckbacher, Todor Mihaylov, Tong Xiao, Ujjwal Karn, Vedanuj Goswami, Vibhor Gupta, Vignesh Ramanathan, Viktor Kerkez, Vincent Gonguet, Virginie Do, Vish Vogeti, VÃ­tor Albiero, Vladan Petrovic, Weiwei Chu, Wenhan Xiong, Wenyin Fu, Whitney Meers, Xavier Martinet, Xiaodong Wang, Xiaofang Wang, Xiaoqing Ellen Tan, Xide Xia, Xinfeng Xie, Xuchao Jia, Xuewei Wang, Yaelle Goldschlag, Yashesh Gaur, Yasmine Babaei, Yi Wen, Yiwen Song, Yuchen Zhang, Yue Li, Yuning Mao, Zacharie Delpierre Coudert, Zheng Yan, Zhengxing Chen, Zoe Papakipos, Aaditya Singh, Aayushi Srivastava, Abha Jain, Adam Kelsey, Adam Shajnfeld, Adithya Gangidi, Adolfo Victoria, Ahuva Goldstand, Ajay Menon, Ajay Sharma, Alex Boesenberg, Alexei Baevski, Allie Feinstein, Amanda Kallet, Amit Sangani, Amos Teo, Anam Yunus, Andrei Lupu, Andres Alvarado, Andrew Caples, Andrew Gu, Andrew Ho, Andrew Poulton, Andrew Ryan, Ankit Ramchandani, Annie Dong, Annie Franco, Anuj Goyal, Aparajita Saraf, Arkabandhu Chowdhury, Ashley Gabriel, Ashwin Bharambe, Assaf Eisenman, Azadeh Yazdan, Beau James, Ben Maurer, Benjamin Leonhardi, Bernie Huang, Beth Loyd, Beto De Paola, Bhargavi Paranjape, Bing Liu, Bo Wu, Boyu Ni, Braden Hancock, Bram Wasti, Brandon Spence, Brani Stojkovic, Brian Gamido, Britt Montalvo, Carl Parker, Carly Burton, Catalina Mejia, Ce Liu, Changhan Wang, Changkyu Kim, Chao Zhou, Chester Hu, Ching-Hsiang Chu, Chris Cai, Chris Tindal, Christoph Feichtenhofer, Cynthia Gao, Damon Civin, Dana Beaty, Daniel Kreymer, Daniel Li, David Adkins, David Xu, Davide Testuggine, Delia David, Devi Parikh, Diana Liskovich, Didem Foss, Dingkang Wang, Duc Le, Dustin Holland, Edward Dowling, Eissa Jamil, Elaine Montgomery, Eleonora Presani, Emily Hahn, Emily Wood, Eric-Tuan Le, Erik Brinkman, Esteban Arcaute, Evan Dunbar, Evan Smothers, Fei Sun, Felix Kreuk, Feng Tian, Filippos Kokkinos, Firat Ozgenel, Francesco Caggioni, Frank Kanayet, Frank Seide, Gabriela Medina Florez, Gabriella Schwarz, Gada Badeer, Georgia Swee, Gil Halpern, Grant Herman, Grigory Sizov, Guangyi, Zhang, Guna Lakshminarayanan, Hakan Inan, Hamid Shojanazeri, Han Zou, Hannah Wang, Hanwen Zha, Haroun Habeeb, Harrison Rudolph, Helen Suk, Henry Aspegren, Hunter Goldman, Hongyuan Zhan, Ibrahim Damlaj, Igor Molybog, Igor Tufanov, Ilias Leontiadis, Irina-Elena Veliche, Itai Gat, Jake Weissman, James Geboski, James Kohli, Janice Lam, Japhet Asher, Jean-Baptiste Gaya, Jeff Marcus, Jeff Tang, Jennifer Chan, Jenny Zhen, Jeremy Reizenstein, Jeremy Teboul, Jessica Zhong, Jian Jin, Jingyi <ref type="bibr">Yang</ref> </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Zhangir</forename><surname>Azerbayev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hailey</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keiran</forename><surname>Paster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><forename type="middle">Dos</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Mcaleer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><forename type="middle">Q</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Welleck</surname></persName>
		</author>
		<title level="m">Llemma: An open language model for mathematics</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Large language monkeys: Scaling inference compute with repeated sampling</title>
		<author>
			<persName><forename type="first">Bradley</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Juravsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Ehrlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronald</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>RÃ©</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Azalia</forename><surname>Mirhoseini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Alphamath almost zero: process supervision without process</title>
		<author>
			<persName><forename type="first">Guoxin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minpeng</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengxi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Fan</surname></persName>
		</author>
		<idno>abs/2405.03553</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiming</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henrique</forename><surname>Ponde De Oliveira Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harri</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuri</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Brockman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.03374</idno>
		<title level="m">Evaluating large language models trained on code</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">Tianzhe</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuexiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jihan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengbang</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Ma</surname></persName>
		</author>
		<title level="m">Sft memorizes, rl generalizes: A comparative study of foundation model post-training</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Flashattention-2: Faster attention with better parallelism and work partitioning</title>
		<author>
			<persName><forename type="first">Tri</forename><surname>Dao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.08691</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Grattafiori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhimanyu</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Jauhri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Kadian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmad</forename><surname>Al-Dahle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aiesha</forename><surname>Letman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akhil</forename><surname>Mathur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Schelten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Vaughan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amy</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anirudh</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><forename type="middle">References</forename><surname>Ratanchandani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pritish</forename><surname>Yuvraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qian</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachad</forename><surname>Alao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafi</forename><surname>Ayub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raghotham</forename><surname>Murthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raghu</forename><surname>Nayani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rangaprabhu</forename><surname>Parthasarathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raymond</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rebekkah</forename><surname>Hogan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robin</forename><surname>Battey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rocky</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russ</forename><surname>Howes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruty</forename><surname>Rinott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sachin</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sachin</forename><surname>Siby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jayesh</forename><surname>Sai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samyak</forename><surname>Bondu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Chugh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sargun</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasha</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satadru</forename><surname>Sidorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seiji</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharadh</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaun</forename><surname>Ramaswamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaun</forename><surname>Lindsay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Lindsay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shenghao</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cindy</forename><surname>Shengxin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shishir</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiva</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuqiang</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sinong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sneha</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soji</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumith</forename><surname>Sajuyigbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Max</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Kehoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sudarshan</forename><surname>Satterfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Govindaprasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Summer</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungmin</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunny</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suraj</forename><surname>Virk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sy</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sydney</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Goldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tamar</forename><surname>Remez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tamara</forename><surname>Glaser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thilo</forename><surname>Best</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Koehler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianhe</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianjun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tzook</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varun</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victoria</forename><surname>Vontimitta</surname></persName>
		</author>
		<author>
			<persName><surname>Ajayi ; Xiaojian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xilun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaniv</forename><surname>Xinbo Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanjun</forename><surname>Kleinman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ye</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ye</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ye</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yenda</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yilin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yossi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youngjin</forename><surname>Adi</surname></persName>
		</author>
		<author>
			<persName><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuchen</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yundi</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunlu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuzi</forename><surname>He</surname></persName>
		</author>
		<editor>Victoria Montanez, Vijai Mohan, Vinay Satish Kumar, Vishal Mangla, Vlad Ionescu, Vlad Poenaru, Vlad Tiberiu Mihailescu, Vladimir Ivanov, Wei Li, Wenchen Wang, Wenwen Jiang, Wes Bouaziz, Will Constable, Xiaocheng Tang</editor>
		<imprint/>
	</monogr>
	<note>Zach Rait, Zachary DeVito, Zef Rosnbrick, Zhaoduo Wen, Zhenyu Yang, Zhiwei Zhao, and Zhiyu Ma. 2024. The llama 3 herd of models</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Dejian</forename><surname>Daya Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haowei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junxiao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruoyu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Runxin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qihao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shirong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peiyi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Bi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2501.12948</idno>
		<title level="m">Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Shibo</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haodi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">Jiahua</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daisy</forename><forename type="middle">Zhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiting</forename><surname>Hu</surname></persName>
		</author>
		<title level="m">Reasoning with language model is planning with world model</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Olympiadbench: A challenging benchmark for promoting agi with olympiad-level bilingual multimodal scientific problems</title>
		<author>
			<persName><forename type="first">Chaoqun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renjie</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuzhuo</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengding</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Leng Thai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junhao</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinyi</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiang</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.14008</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Collin</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurav</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akul</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.03874</idno>
		<title level="m">Measuring mathematical problem solving with the math dataset</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">O1 replication journey-part 2: Surpassing o1-preview through simple distillation</title>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoyang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuefeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixiu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Chern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shijie</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiwei</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhe</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2411.16489</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Can large language models reason and plan?</title>
		<author>
			<persName><forename type="first">Subbarao</forename><surname>Kambhampati</surname></persName>
		</author>
		<idno type="DOI">10.1111/nyas.15125</idno>
	</analytic>
	<monogr>
		<title level="j">Annals of the New York Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">1534</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="18" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Scaling laws for neural language models</title>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Efficient memory management for large language model serving with pagedattention</title>
		<author>
			<persName><forename type="first">Woosuk</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuohan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siyuan</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lianmin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cody</forename><forename type="middle">Hao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles</title>
		<meeting>the ACM SIGOPS 29th Symposium on Operating Systems Principles</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Solving quantitative reasoning problems with language models</title>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anders</forename><surname>Andreassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henryk</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinay</forename><surname>Ramasesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ambrose</forename><surname>Slone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cem</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Imanol</forename><surname>Schlag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theo</forename><surname>Gutman-Solo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="3843" to="3857" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">2024a. Common 7b language models already possess strong math capabilities</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingcheng</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixuan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nanning</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Houwen</forename><surname>Peng</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">2024b. Numinamath: The largest public dataset in ai4maths with 860k pairs of competition math problems and solutions</title>
		<author>
			<persName><forename type="first">Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Beeching</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lewis</forename><surname>Tunstall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Lipkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Soletskyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengyi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kashif</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Longhui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><forename type="middle">Q</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziju</forename><surname>Shen</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Hugging Face repository</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Competition-level code generation with alphacode</title>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">RÃ©mi</forename><surname>Leblond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Eccles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Keeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Gimeno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Agustin</forename><forename type="middle">Dal</forename><surname>Lago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Hubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cyprien</forename><surname>De Masson D'autume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Babuschkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sven</forename><surname>Gowal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Cherepanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Molloy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">J</forename><surname>Mankowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Esme</forename><surname>Sutherland Robson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Nando De Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><surname>Vinyals</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.abq1158</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">378</biblScope>
			<biblScope unit="issue">6624</biblScope>
			<biblScope unit="page" from="1092" to="1097" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The expressive power of transformers with chain of thought</title>
		<author>
			<persName><forename type="first">William</forename><surname>Merrill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">Iman</forename><surname>Mirzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keivan</forename><surname>Alizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hooman</forename><surname>Shahrokhi</surname></persName>
		</author>
		<title level="m">Oncel Tuzel, Samy Bengio, and Mehrdad Farajtabar. 2024. Gsm-symbolic: Understanding the limitations of mathematical reasoning in large language models. References</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">:</forename><surname>Openai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Jaech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Kalai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>El-Kishky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aiden</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Helyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Beutel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Carney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Iftimie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Karpenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Tachard Passos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Neitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Prokofiev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allison</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ally</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananya</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andre</forename><surname>Saraiva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Vallone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Duberstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Kondrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrey</forename><surname>Mishchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Applebaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashvin</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Behrooz</forename><surname>Ghorbani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Rossen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Sokolowsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boaz</forename><surname>Barak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bob</forename><surname>Mcgrew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Borys</forename><surname>Minaiev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Botao</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Houghton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Mckinzie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brydon</forename><surname>Eastman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Camillo</forename><surname>Lugaresi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cary</forename><surname>Bassin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cary</forename><surname>Hudson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Chak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>De Bourcy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Orsinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudia</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clive</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Kappler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Selsam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Farhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Mely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dragos</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eben</forename><surname>Oprica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eddie</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edmund</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enoch</forename><surname>Proehl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Mays</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felipe</forename><forename type="middle">Petroski</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filippo</forename><surname>Such</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florencia</forename><surname>Raso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Foivos</forename><surname>Leoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francis</forename><surname>Tsimpourlas</surname></persName>
		</author>
		<author>
			<persName><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Freddie</forename><surname>Fred Von Lohmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoff</forename><surname>Sulit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giambattista</forename><surname>Salmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gildas</forename><surname>Parascandolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grace</forename><surname>Chabot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Brockman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hadi</forename><surname>Leclerc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haiming</forename><surname>Salman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hart</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hessam</forename><surname>Andrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Bagherinezhad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hunter</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Lightman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><surname>Kivlichan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O'</forename><surname>Ian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Connell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ignasi</forename><surname>Osband</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilge</forename><surname>Clavera Gilaberte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Akkaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Kostrikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irina</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakub</forename><surname>Kofman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pachocki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Lennon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Harb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiacheng</forename><surname>Twore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiahui</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiayi</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jieqi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joaquin</forename><forename type="middle">QuiÃ±onero</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Candela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Palermo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Parish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Heidecke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Hallman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Rizzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Uesato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joost</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julie</forename><surname>Huizinga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karan</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karina</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katy</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kayla</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kendra</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keren</forename><surname>Rimbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Gu-Lemberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lama</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lauren</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leon</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leyton</forename><surname>Maksin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liam</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lilian</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linden</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lindsay</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lindsey</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lorenz</forename><surname>Held</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukas</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kondraciuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madelaine</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maja</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manas</forename><surname>Trebacz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Joglekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marko</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mason</forename><surname>Tintor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kaufer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meghan</forename><surname>Schwarzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehmet</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melody</forename><forename type="middle">Y</forename><surname>Yatbaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengyuan</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengyuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mia</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mianna</forename><surname>Glaese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Lampe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Malek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michelle</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Fradin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Mcclay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miles</forename><surname>Pavlov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mira</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Murati</surname></persName>
		</author>
		<editor>Mo Bavarian, Mostafa Rohaninejad, Nat McAleese, Neil Chowdhury, Neil Chowdhury, Nick Ryder, Nikolas Tezak, Noam Brown, Ofir Nachum, Oleg Boiko, Oleg Murk, Olivia Watkins, Patrick Chao, Paul Ashbourne, Pavel Izmailov, Peter Zhokhov, Rachel Dias, Rahul Arora, Randall Lin, Rapha Gontijo Lopes, Raz Gaon, Reah Miyara, Reimar Leike, Renny Hwang, Rhythm Garg, Robin Brown, Roshan James, Rui Shu, Ryan Cheu, Ryan Greene, Saachi Jain, Sam Altman, Sam Toizer, Sam Toyer, Samuel Miserendino, Sandhini Agarwal, Santiago Hernandez, Sasha Baker, Scott McKinney, Scottie Yan, Shengjia Zhao, Shengli Hu, Shibani Santurkar, Shraman Ray Chaudhuri, Shuyuan Zhang, Siyuan Fu, Spencer Papay, Steph Lin, Suchir Balaji, Suvansh Sanjeev, Szymon Sidor, Tal Broda, Aidan Clark, Tao Wang, Taylor Gordon, Ted Sanders, Tejal Patwardhan, Thibault Sottiaux, Thomas Degry, Thomas Dimson, Tianhao Zheng, Timur Garipov, Tom Stasi, Trapit Bansal, Trevor Creech, Troy Peterson, Tyna Eloundou, Valerie Qi</editor>
		<imprint/>
	</monogr>
	<note>Vineet Kosaraju, Vinnie Monaco, Vitchyr Pong, Vlad Fomenko, Weiyi Zheng, Wenda Zhou, Wes McCabe, Wojciech Zaremba, Yann Dubois, Yinghai Lu, Yining Chen, Young Cha, Yu Bai, Yuchen He, Yuchen Zhang, Yunyun Wang, Zheng Shao, and Zhuohan Li. 2024. Openai o1 system card</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Learning to reason with llms</title>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024-09">2024. september 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">Keiran</forename><surname>Paster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><forename type="middle">Dos</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhangir</forename><surname>Azerbayev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<title level="m">Openwebmath: An open dataset of high-quality mathematical web text</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">Yiwei</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuefeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoyang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixiu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shijie</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhe</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hector</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhi</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2410.18982</idno>
		<title level="m">O1 replication journey: A strategic progress report-part 1</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">:</forename><surname>Qwen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">An</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baosong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beichen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binyuan</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dayiheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoran</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianhong</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingren</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keming</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keqin</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kexin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingfeng</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Men</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Runji</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianhao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tingyu</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingzhang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuancheng</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuqiong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeyu</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenru</forename><surname>Zhang</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>and Zihan Qiu. 2025. Qwen2.5 technical report</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Zero: Memory optimizations toward training trillion parameter models</title>
		<author>
			<persName><forename type="first">Samyam</forename><surname>Rajbhandari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Rasley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olatunji</forename><surname>Ruwase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiong</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SC20: International Conference for High Performance Computing, Networking, Storage and Analysis</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">David</forename><surname>Rein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Betty</forename><forename type="middle">Li</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asa</forename><forename type="middle">Cooper</forename><surname>Stickland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jackson</forename><surname>Petty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">Yuanzhe</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Dirani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><surname>Samuel R Bowman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.12022</idno>
		<title level="m">Gpqa: A graduate-level google-proof q&amp;a benchmark</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Zhihong</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peiyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qihao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Runxin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junxiao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingchuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daya</forename><surname>Guo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.03300</idno>
		<title level="m">Deepseekmath: Pushing the limits of mathematical reasoning in open language models</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Scaling llm test-time compute optimally can be more effective than scaling model parameters</title>
		<author>
			<persName><forename type="first">Charlie</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaehoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aviral</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2408.03314</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Qwen</forename><surname>Team</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2024a. Introducing qwen1.5</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amjad</forename><surname>Almahairi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasmine</forename><surname>Babaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolay</forename><surname>Bashlykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumya</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prajjwal</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Bhosale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Bikel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukas</forename><surname>Blecher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristian Canton</forename><surname>Ferrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Esiobu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jude</forename><surname>Fernandes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenyin</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Fuller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vedanuj</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Hartshorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saghar</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hakan</forename><surname>Inan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Kardas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viktor</forename><surname>Kerkez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madian</forename><surname>Khabsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabel</forename><surname>Kloumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artem</forename><surname>Korenev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Punit</forename><surname>Singh Koura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibaut</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenya</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diana</forename><surname>Liskovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinghai</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuning</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Martinet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushkar</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Molybog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Poulton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Reizenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rashi</forename><surname>Rungta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalyan</forename><surname>Saladi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Schelten</surname></persName>
		</author>
		<editor>Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov</editor>
		<imprint/>
	</monogr>
	<note>and Thomas Scialom. 2023. Llama 2: Open foundation and fine-tuned chat models</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Self-consistency improves chain of thought reasoning in language models</title>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.11171</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Mathpile: A billion-token-scale pretraining corpus for math</title>
		<author>
			<persName><forename type="first">Zengzhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuefeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Chain-of-thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="24824" to="24837" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Towards system 2 reasoning in llms: Learning how to think with meta chain-of-thought</title>
		<author>
			<persName><forename type="first">Violet</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charlie</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kanishk</forename><surname>Gandhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alon</forename><surname>Albalak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anikait</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chase</forename><surname>Blagden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duy</forename><surname>Phung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafael</forename><surname>Rafailov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Lile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dakota</forename><surname>Mahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis</forename><surname>Castricato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan-Philipp</forename><surname>Franken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Haber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Benchmarking benchmark leakage in large language models</title>
		<author>
			<persName><forename type="first">Ruijie</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zengzhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Run-Ze</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">An</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beichen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binyuan</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bofei</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengpeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dayiheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianhong</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingren</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyang</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2409.12122</idno>
		<title level="m">Qwen2. 5-math technical report: Toward mathematical expert model via self-improvement</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Tree of thoughts: Deliberate problem solving with large language models</title>
		<author>
			<persName><forename type="first">Shunyu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Izhak</forename><surname>Shafran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">Longhui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weisen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jincheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengying</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Weller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiyang</forename><surname>Liu</surname></persName>
		</author>
		<title level="m">Metamath: Bootstrap your own mathematical questions for large language models</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Mammoth: Building math generalist models through hybrid instruction tuning</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingwei</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ge</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhu</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tuney</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ge</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhu</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">Mammoth2: Scaling instructions from the web</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">A careful examination of large language model performance on grade school arithmetic</title>
		<author>
			<persName><forename type="first">Hugh</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dean</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vaughn</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Will</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiffany</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Raja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charlotte</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dylan</forename><surname>Slack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qin</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Hendryx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russell</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Lunati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Summer</forename><surname>Yue</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">2024a. Lima: Less is more for alignment</title>
		<author>
			<persName><forename type="first">Chunting</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Puxin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srinivasan</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuning</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avia</forename><surname>Efrat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ping</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lili</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="page">36</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">2024b. Programming every example: Lifting pre-training data quality like experts at scale</title>
		<author>
			<persName><forename type="first">Fan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zengzhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junlong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
