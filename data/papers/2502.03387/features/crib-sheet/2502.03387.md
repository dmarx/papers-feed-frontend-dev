- **LIMO Hypothesis**: Complex reasoning capabilities can be elicited with minimal training samples by leveraging rich pre-trained knowledge and effective cognitive templates.
  
- **Key Metrics**: 
  - LIMO achieves 57.1% accuracy on AIME with 817 samples (previously 6.5%).
  - LIMO achieves 94.8% accuracy on MATH with 817 samples (previously 59.2%).
  - Out-of-distribution generalization: 40.5% absolute improvement across 10 benchmarks.

- **Two Critical Factors for Elicitation**:
  1. **Knowledge Foundation**: Completeness of the model's encoded knowledge during pre-training.
  2. **Effective Post-Training Examples**: Minimal exemplars that demonstrate systematic problem-solving processes.

- **Inference-Time Computation**: Extended reasoning chains improve reasoning ability; models require sufficient computational space during inference to unpack and apply pre-trained knowledge.

- **Data Efficiency**: LIMO uses only 1% of the training data required by previous models, demonstrating that complex reasoning can be activated with fewer, high-quality examples.

- **Comparative Analysis**:
  - **LIMO vs. LIMA**: LIMO extends the Less-is-More principle from general alignment to complex reasoning, emphasizing the need for rich domain knowledge and effective cognitive templates.
  - **LIMO vs. RL Scaling**: LIMO focuses on eliciting latent reasoning capabilities from pre-trained models, while RL Scaling relies on extensive training through reinforcement learning.

- **Future Research Directions**: Investigate other advanced capabilities (e.g., planning, creative problem-solving) for potential data-efficient development under the Less-is-More principle.

- **Open-Source Release**: LIMO includes fine-tuned models, evaluation pipelines, training code, and curated datasets to facilitate reproducibility and further research in data-efficient reasoning.

- **Implications for AGI**: Suggests that sophisticated reasoning capabilities could be activated with minimal samples if the model has sufficient domain knowledge and optimal cognitive reasoning chains.