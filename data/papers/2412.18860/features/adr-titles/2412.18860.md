- Decision to utilize a bootstrapping approach for training long-context language models
- Choice of agent workflow for data synthesis
- Selection of short-context language models for generating long-context instruction tuning data
- Implementation of a text retriever for document retrieval
- Use of query-focused summarization (QFS) agents for filtering and summarizing document chunks
- Decision to concatenate summaries for model input during training
- Adoption of instruction back-translation for generating long-output data
- Strategy for progressive training to handle long sequences
- Use of RingAttention for distributing long input sequences across multiple GPUs
- Decision to average loss over input and output tokens for long data samples
- Choice of training data mixture, including synthetic and open-source datasets
- Implementation of de-duplication for the Infinity-Instruct dataset
- Selection of RULER benchmark for evaluation of long-context performance
- Decision to utilize vLLM for efficient inference during evaluation
- Choice of hardware configuration for training and inference (H100 and A100 GPUs)
- Strategy for handling memory constraints during training (activation checkpointing, DeepSpeed ZeRO-3, etc.)