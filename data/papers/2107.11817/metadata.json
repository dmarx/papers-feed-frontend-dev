{
  "arxivId": "2107.11817",
  "title": "Go Wider Instead of Deeper",
  "authors": "Fuzhao Xue, Ziji Shi, Futao Wei, Yuxuan Lou, Yong Liu, Yang You",
  "abstract": "More transformer blocks with residual connections have recently achieved\nimpressive results on various tasks. To achieve better performance with fewer\ntrainable parameters, recent methods are proposed to go shallower by parameter\nsharing or model compressing along with the depth. However, weak modeling\ncapacity limits their performance. Contrastively, going wider by inducing more\ntrainable matrixes and parameters would produce a huge model requiring advanced\nparallelism to train and inference.\n  In this paper, we propose a parameter-efficient framework, going wider\ninstead of deeper. Specially, following existing works, we adapt parameter\nsharing to compress along depth. But, such deployment would limit the\nperformance. To maximize modeling capacity, we scale along model width by\nreplacing feed-forward network (FFN) with mixture-of-experts (MoE). Across\ntransformer blocks, instead of sharing normalization layers, we propose to use\nindividual layernorms to transform various semantic representations in a more\nparameter-efficient way. To evaluate our plug-and-run framework, we design\nWideNet and conduct comprehensive experiments on popular computer vision and\nnatural language processing benchmarks. On ImageNet-1K, our best model\noutperforms Vision Transformer (ViT) by $1.5\\%$ with $0.72 \\times$ trainable\nparameters. Using $0.46 \\times$ and $0.13 \\times$ parameters, our WideNet can\nstill surpass ViT and ViT-MoE by $0.8\\%$ and $2.1\\%$, respectively. On four\nnatural language processing datasets, WideNet outperforms ALBERT by $1.8\\%$ on\naverage and surpass BERT using factorized embedding parameterization by $0.8\\%$\nwith fewer parameters.",
  "url": "https://arxiv.org/abs/2107.11817",
  "issue_number": 802,
  "issue_url": "https://github.com/dmarx/papers-feed/issues/802",
  "created_at": "2025-01-05T18:40:55.338171",
  "state": "open",
  "labels": [
    "paper",
    "rating:novote"
  ],
  "total_reading_time_seconds": 13,
  "last_read": "2025-01-05T18:40:55.338983",
  "last_visited": "2025-01-05T18:44:31.871Z",
  "main_tex_file": null,
  "published_date": "2021-07-25T14:44:24Z",
  "arxiv_tags": [
    "cs.LG",
    "cs.AI",
    "cs.CV"
  ]
}