- **Key Concept**: The paper emphasizes the importance of optimizing both FLOPs and FLOPS to achieve lower latency in neural networks.
  
- **FLOPs vs. FLOPS**: 
  - **FLOPs**: Number of floating-point operations.
  - **FLOPS**: Floating-point operations per second, indicating effective computational speed.
  - Relationship: \( \text{Latency} = \frac{\text{FLOPs}}{\text{FLOPS}} \)

- **Depthwise Convolution (DWConv)**:
  - Commonly used in fast neural networks but suffers from low FLOPS due to high memory access.
  - Memory access for DWConv: 
    \[
    \text{Memory Access} \approx h \times w \times 2c' \quad (c' > c)
    \]

- **Partial Convolution (PConv)**:
  - Proposed as an alternative to DWConv, reducing both computational redundancy and memory access.
  - FLOPs of PConv:
    \[
    \text{FLOPs} = h \times w \times k^2 \times c^2_p \quad (c_p \text{ is the number of utilized channels})
    \]
  - Memory access for PConv:
    \[
    \text{Memory Access} \approx h \times w \times 2c_p
    \]

- **FasterNet**:
  - A new family of neural networks built on PConv, designed for high speed and efficiency across various devices.
  - Performance: FasterNet-T0 is 2.8×, 3.3×, and 2.4× faster than MobileViT-XXS on GPU, CPU, and ARM, respectively, with 2.9% higher accuracy on ImageNet-1k.
  - Larger model (FasterNet-L) achieves 83.5% top-1 accuracy, 36% higher throughput on GPU, and saves 37% compute time on CPU compared to Swin-B.

- **Design Considerations**:
  - PConv is designed to exploit redundancy in feature maps, applying convolution only to a subset of channels.
  - The combination of PConv and Pointwise Convolution (PWConv) creates a T-shaped receptive field, focusing on the center position of the input.

- **Experimental Validation**:
  - Extensive experiments demonstrate the effectiveness of PConv and FasterNet in various vision tasks, confirming their speed and accuracy advantages.

- **Code Availability**: Implementation can be found at [FasterNet GitHub Repository](https://github.com/JierunChen/FasterNet).