{
  "arxivId": "2406.09162",
  "title": "EMMA: Your Text-to-Image Diffusion Model Can Secretly Accept Multi-Modal\n  Prompts",
  "authors": "Yucheng Han, Rui Wang, Chi Zhang, Juntao Hu, Pei Cheng, Bin Fu, Hanwang Zhang",
  "abstract": "Recent advancements in image generation have enabled the creation of\nhigh-quality images from text conditions. However, when facing multi-modal\nconditions, such as text combined with reference appearances, existing methods\nstruggle to balance multiple conditions effectively, typically showing a\npreference for one modality over others. To address this challenge, we\nintroduce EMMA, a novel image generation model accepting multi-modal prompts\nbuilt upon the state-of-the-art text-to-image (T2I) diffusion model, ELLA. EMMA\nseamlessly incorporates additional modalities alongside text to guide image\ngeneration through an innovative Multi-modal Feature Connector design, which\neffectively integrates textual and supplementary modal information using a\nspecial attention mechanism. By freezing all parameters in the original T2I\ndiffusion model and only adjusting some additional layers, we reveal an\ninteresting finding that the pre-trained T2I diffusion model can secretly\naccept multi-modal prompts. This interesting property facilitates easy\nadaptation to different existing frameworks, making EMMA a flexible and\neffective tool for producing personalized and context-aware images and even\nvideos. Additionally, we introduce a strategy to assemble learned EMMA modules\nto produce images conditioned on multiple modalities simultaneously,\neliminating the need for additional training with mixed multi-modal prompts.\nExtensive experiments demonstrate the effectiveness of EMMA in maintaining high\nfidelity and detail in generated images, showcasing its potential as a robust\nsolution for advanced multi-modal conditional image generation tasks.",
  "url": "https://arxiv.org/abs/2406.09162",
  "issue_number": 410,
  "issue_url": "https://github.com/dmarx/papers-feed/issues/410",
  "created_at": "2025-01-04T14:49:45.263062",
  "state": "open",
  "labels": [
    "paper",
    "rating:novote"
  ],
  "total_reading_time_seconds": 24,
  "last_read": "2025-01-04T14:49:45.266317",
  "last_visited": "2024-12-28T08:40:07.461Z",
  "main_tex_file": null,
  "published_date": "2024-06-13T14:26:43Z",
  "arxiv_tags": [
    "cs.CV"
  ]
}