<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Response to Glaze Purification via IMPRESS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shawn</forename><surname>Shan</surname></persName>
							<email>shawnshan@cs.uchicago.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stanley</forename><surname>Wu</surname></persName>
							<email>stanleywu@cs.uchicago.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Haitao</forename><surname>Zheng</surname></persName>
							<email>htzheng@cs.uchicago.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ben</forename><forename type="middle">Y</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Chicago</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Response to Glaze Purification via IMPRESS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FBD3B8470FB0C144F4FC4EB833373B09</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-02-21T16:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent work proposed a new mechanism to remove protective perturbation added by Glaze in order to again enable mimicry of art styles from images protected by Glaze. Despite promising results shown in the original paper, our own tests with the authors' code demonstrated several limitations of the proposed purification approach. The main limitations are 1) purification has a limited effect when tested on artists that are not well-known historical artists already embedded in original training data, 2) problems in evaluation metrics, and 3) collateral damage on mimicry result for clean images. We believe these limitations should be carefully considered in order to understand real world usability of the purification attack.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cao et al.</head><p>[1] recently proposed a purification-based method (IM-PRESS) to remove Glaze protection [3] that are designed to protect art styles from AI mimicry. We first summarize how Glaze and IMPRESS work in §2. Then we show IMPRESS achieve limited effectiveness against Glaze in a variety of real-world mimicry scenarios. In short:</p><p>• IMPRESS has weaker performance on artists who are not historical artists already with a large presence in the pretrained models; • IMPRESS works poorly on smooth surface art styles (e.g., realism); • IMPRESS damages image quality even for clean images.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>Here, we first summarize Glaze and then IMPRESS purification method. Glaze protection against style mimicry. Glaze seeks to protect artist's artwork from AI mimicry by adding small perturbations on these artwork to confuse diffusion models. Given an artwork 𝑥 and target style 𝑇 that is different from the artist's, Glaze first uses a pretrained style transfer model Ω to compute a style transferred version of the artwork. We denote such image as Ω(𝑥,𝑇 ). Then, Glaze computes a cloak 𝛿 𝑥 that optimize the latent representation of Glazed artwork (𝑥 + 𝛿 𝑥 ) to be similar to the style transferred artwork (Ω(𝑥,𝑇 )). The Glaze optimization effectively moves the original image to a new position in the high dimensional latent space, causing model to learn an incorrect art style. Glaze calculates the latent space using the feature extractor (E) from a diffusion model. Formally, we write the Glaze optimization as solving the following: min</p><formula xml:id="formula_0">𝛿 𝑥 ||E (𝑥 + 𝛿 𝑥 ) -E (Ω(𝑥,𝑇 ))|| 2 (1)</formula><p>subject to LPIPS(𝑥 + 𝛿 𝑥 , 𝑥) &lt; 𝑝 𝐺</p><p>We use LPIPS, a popular human-perceived visual distortion metric <ref type="bibr" target="#b3">[4]</ref>, to bound the perturbation within a budget 𝑝 𝐺 . IMPRESS Purification Method. IMPRESS adds additional perturbation on top of a Glazed artwork hoping to "purify" the Glaze effect -recovering the precise latent representation of original artwork. First, the authors empirically find that when passing Glazed images through an image autoencoder, the output image looks more different from the input image, compared to the output when inputting a clean image to the same autoencoder. Then authors assume removing this particular discrepancy would guide them to find the original (non-Glazed) image. IMPRESS purification optimizes perturbations on Glaze images such that purified images behave similarly to clean images when passing through an autoencoder. The authors assume the optimization process will guide the image to move back to the original latent space of the non-Glazed image. Formally, IMPRESS purification optimize a perturbation 𝛿 𝑝𝑢𝑟 on a Glaze image 𝑥 𝑔𝑙𝑎𝑧𝑒𝑑 : min</p><formula xml:id="formula_1">𝛿 𝑝𝑢𝑟 ||(𝑥 𝑔𝑙𝑎𝑧𝑒𝑑 + 𝛿 𝑝𝑢𝑟 ) -VAE(𝑥 𝑔𝑙𝑎𝑧𝑒𝑑 + 𝛿 𝑝𝑢𝑟 )|| 2 2 (2)</formula><p>subject to LPIPS(𝑥 𝑔𝑙𝑎𝑧𝑒𝑑 + 𝛿 𝑝𝑢𝑟 , 𝑥 𝑔𝑙𝑎𝑧𝑒𝑑 ) &lt; 𝑝 𝐼 VAE is an image autoencoder, which consists of an encoder E followed by a decoder 𝐷. IMPRESS uses the same autoencoder as the stable diffusion model. The perturbation 𝛿 𝑝𝑢𝑟 is bounded by a LPIPS perturbation budget 𝑝 𝐼 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EVALUATION OF IMPRESS</head><p>Here, we first identify a few flaws in IMPRESS's experiment setup and then evaluate purification performance in several realistic mimicry scenarios. Setup. We follow the purification setup from the original IM-PRESS paper and the source code provided by the authors. We use default Glaze setup (perturbation budget = 0.07) as described in the paper. We follow style mimicry setup in prior work <ref type="bibr" target="#b2">[3]</ref>. Given a set of artworks, we mimic its style by fine-tuning stable diffusion model (version 1.5) using DreamBooth for 600 to 1000 steps depending on the finetuning sample size for the artist.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Generalizability to Realistic Scenarios</head><p>In the original IMPRESS paper, the authors focus the evaluation on protecting the art styles of famous historical artists (Monet, Van Gogh) -whose style are already learned by pretrained diffusion models prior to style mimicry. In the real-world, it is current artists who are most concerned about AI mimicking their art style. Glaze    is designed to protect those artists, and they are not as heavily pretrained into the base model as Monet or Van Gogh.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mimicry results on artist's original images</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mimicry results on Glazed images after applying purification</head><note type="other">Ivan Shishkin Ivan Aivazovsky</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Original artwork</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Purified artwork</head><p>We evaluate IMPRESS on non-historical artists and show that purification has limited effectiveness at removing Glaze protection. Even for historical artists, we find the purification works poorly for certain art styles. Lastly, we find purification also degrades clean image quality where it removes texture from art pieces.</p><p>Performance on non-historical artists. We use artwork from Karla Ortiz and Kim Van Deun to simulate the mimicry attack on current artists. Karla is a fine-art artist with a similar style as some historical artists tested in the IMPRESS paper. Figure <ref type="figure" target="#fig_1">1</ref> shows the mimicry results when model trained on artist's original art pieces (left) or when model trained on art pieces that are first Glazed and then purified by IMPRESS (right). We can observe significant amount of artifacts on mimicry results when the model is trained on purified Glazed images. Poor performance on certain art styles. IMPRESS works by adding artifacts on Glazed images to recover the latent representation of original artwork. We found purification has more challenges recovering smooth surface art styles (realism art, symbolism, romanticism, etc) even for historical artists already trained into the base model. We choose two historical artists: Ivan Aivazovsky (romanticism style) and Ivan Shishkin (realism style).</p><p>Figure <ref type="figure" target="#fig_2">2</ref> shows the mimicry results. We see IMPRESS introduces signficiant amount of artifacts to the mimicked images. The weaker performance is likely because purifying the original smoother surface art requires the optimization to be very percise -find the exact smooth surface. Degrading image quality. We found the purification process degrades clean image quality. Figure <ref type="figure" target="#fig_3">3</ref> shows original artwork and its corresponding purified artwork. The purified artwork is much more blurry as purification removes textures from the images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">CLIP-based metrics are Inaccurate</head><p>"CLIP genre accuracy" quantifies if mimicked art is classified into the same art genre as the original art pieces according to a CLIP model. It has been used in prior work to evaluate mimicry success. However, in our own tests dating back to late September 2023, we found CLIP genre accuracy is a poor indicator of end-to-end mimicry success. CLIP accuracy is especially poor when evaluating attacks against Glaze. The reason is that attacks (such as IMPRESS purification), as they seek to remove Glaze effect from art, often have signficant impact on the base image quaility of the artwork. The degradation in image quality is not captured by CLIP accuracy, e.g., a very low quality cubism painting is still classified as "cubism" with high probability. But the result are not successful mimicry due to the low quaility of the mimicked images. Because of these poor properties as an accuracy indicator, we stopped using CLIP distance as a success metric starting with the Glaze v1.1 update (October 2023).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION</head><p>We conclude with a discussion of Glaze, then describe some potential implications of attempts to remove Glaze. Challenges of evaluating mimicry protection. Evaluating mimicry performance is challenging with automated metrics. As we shown in §3, CLIP-based metric do not work well. Another popular image quaility metric, Fréchet inception distance (FID), is also shown to be erronous at evaluating generative models <ref type="bibr" target="#b1">[2]</ref>. The standard evaluation approach today is to rely on human inspectors <ref type="bibr" target="#b1">[2]</ref>, which is not only expensive, but also produces results with high variance. Particularly for art mimicry, the average human user (found on MTurk or Profilic) often does not have sufficient expertise to judge whether a mimicry is successful or not, while sourcing to professional artists can be prohibitively expensive. We hope future work can address this challenge by designing automated metrics that can faithfully approximate ratings from human artists. Implications on Copyright Law. Technical research results and their applications rarely have legal implications in practice. In the case of Glaze and image copyrights, however, there are interesting open questions with respect to copyright law. More specifically, Section 1201 of US Copyright law (enacted in 1998 as part of the DMCA) "prohibits circumvention of technological protection measures employed by or on behalf of copyright owners to control access to their works. " <ref type="foot" target="#foot_0">1</ref>For artists who apply Glaze to prevent unauthorized use of their art images for training, applying Glaze to one's art likely qualifies as an explicit statement of "opt-out" and a measure to control access to copyrighted work. In this uncertain legal and regulatory landscape, it is an interesting legal question to explore whether Section 1201 applies to the use of Glaze and attempted counter-measures to Glaze.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><figDesc>arXiv:2312.07731v1 [cs.CR] 12 Dec 2023 Mimicry results (trained on artist's original images) Mimicry results (trained on Glazed images after purification) Karla Ortiz Kim Van Deun</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Mimicry results on non-historical artists (Karla Ortiz and Kim van Deun). Left shows the images generated from a model trained on original images; right shows the images generated from a model trained on images that are first Glazed and then purified by IMPRESS.</figDesc><graphic coords="2,73.29,396.02,113.88,113.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Mimicry results on smooth surface art styles (Ivan Shishkin and Ivan Aivazovsky). Left shows the images generated from a model trained on original images; right shows the images generated from a model trained on images that are first Glazed and then purified by IMPRESS.</figDesc><graphic coords="2,439.44,515.24,113.88,113.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Original artwork and corresponding purified artwork.</figDesc><graphic coords="3,65.28,326.68,232.25,232.33" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>"Legal Liability for Removal or Alteration of Copyright Management Information Under the DMCA, " John DiGiacomo, September</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>2020, https://revisionlegal.com/copyright/ legal-liability-for-removal-or-alteration-of-copyright-management-information-under-the-dmca/.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGEMENTS</head><p>We are grateful to <rs type="person">Bochuan Cao</rs>, <rs type="person">Changjiang Li</rs>, <rs type="person">Ting Wang</rs>, <rs type="person">Jinyuan Jia</rs>, <rs type="person">Bo Li</rs>, <rs type="person">Jinghui Chen</rs> for providing us code and discussing their attack with us prior to paper publication.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">IMPRESS: Evaluating the Resilience of Imperceptible Perturbations Against Unauthorized Data Usage in Diffusion-Based Generative AI</title>
		<author>
			<persName><forename type="first">Bochuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changjiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinyuan</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinghui</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NeurIPS</title>
		<meeting>of NeurIPS</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">Dustin</forename><surname>Podell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zion</forename><surname>English</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Lacey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Blattmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Dockhorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Penna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robin</forename><surname>Rombach</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.01952</idno>
		<title level="m">Sdxl: Improving latent diffusion models for high-resolution image synthesis</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Glaze: Protecting artists from style mimicry by text-to-image models</title>
		<author>
			<persName><forename type="first">Shawn</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenna</forename><surname>Cryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Wenger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haitao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rana</forename><surname>Hanocka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><forename type="middle">Y</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of USENIX Security</title>
		<meeting>of USENIX Security</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The unreasonable effectiveness of deep features as a perceptual metric</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eli</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oliver</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CVPR</title>
		<meeting>of CVPR</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="586" to="595" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
