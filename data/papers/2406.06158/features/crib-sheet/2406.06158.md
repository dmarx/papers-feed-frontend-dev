- **Learning Regimes**: Distinguish between lazy and rich learning regimes in neural networks.
  - **Lazy Regime**: Characterized by minimal movement in parameter space, static hidden representations, and convergence to a deterministic NTK.
  - **Rich Regime**: Involves evolving NTK, non-convex dynamics, and sigmoidal learning curves.

- **Key Parameters**:
  - **Initialization Variances**: Layer-specific initialization variances influence learning dynamics.
  - **Learning Rates**: Layer-specific learning rates affect the transition between lazy and rich learning.

- **Conserved Quantities**: The learning regime is influenced by conserved quantities that modify the geometry of learning trajectories in parameter and function space.

- **Initialization Types**:
  - **Balanced Initialization**: All layers learn at similar speeds; leads to rich learning in linear networks.
  - **Unbalanced Initialization**: Can promote faster learning in earlier layers (upstream) or later layers (downstream) in nonlinear networks.

- **Neural Tangent Kernel (NTK)**:
  - Defined as \( \Theta(x, x'; \theta) = \sum_{p=1}^{m} \eta_{\theta_p} \frac{\partial f(x; \theta)}{\partial \theta_p} \frac{\partial f(x'; \theta)}{\partial \theta_p} \).
  - Kernel distance \( S(t_1, t_2) = 1 - \frac{\langle K_{t_1}, K_{t_2} \rangle}{\|K_{t_1}\|_F \|K_{t_2}\|_F} \) measures similarity between NTK at different times.

- **Learning Dynamics**:
  - **Gradient Flow**: \( \frac{d\theta}{dt} = -\eta_{\theta} \nabla_{\theta} L(\theta) \) for minimizing mean squared error \( L(\theta) \).
  - **Training Trajectories**: Upstream initializations lead to faster convergence and better alignment with teacher networks.

- **Experimental Evidence**:
  - Unbalanced initializations enhance feature learning in deep networks, improve interpretability in CNNs, and reduce sample complexity.

- **Applications**:
  - Insights from this work can be applied to enhance feature learning in various neural network architectures, particularly in hierarchical data and modular arithmetic contexts.