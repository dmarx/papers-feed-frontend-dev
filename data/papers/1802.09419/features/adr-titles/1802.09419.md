- Decision to use hypernetworks for hyperparameter optimization
- Choice of stochastic optimization methods for training
- Selection of loss functions for training the hypernetwork
- Decision to differentiate through the hypernetwork for hyperparameter optimization
- Choice of hyperparameter distribution p(Î») for sampling
- Decision to implement joint optimization of hypernetwork and hyperparameters
- Choice of model architecture for the hypernetwork
- Decision to use linear hypernetworks for efficiency
- Choice of training data distribution for hyperparameter tuning
- Decision to compare against standard hyperparameter optimization methods
- Assumptions about the convergence properties of the hypernetwork
- Decision to limit the scope of hyperparameter optimization to continuous parameters
- Choice of validation strategy for assessing hypernetwork performance
- Decision to incorporate uncertainty in hyperparameter exploration in future work
- Assumptions regarding the capacity of hypernetworks to approximate best-response functions
- Decision to use SGD for training the hypernetwork and hyperparameters