### Detailed Technical Explanations and Justifications

#### Choice of Unsupervised Learning Methods for Sentence Representations
The decision to utilize unsupervised learning methods for sentence representations stems from the need to leverage large amounts of unlabelled data, which is often more readily available than labelled datasets. Unsupervised methods allow for the extraction of semantic information from the natural structure of language without the constraints of predefined labels. This approach is particularly beneficial in scenarios where obtaining labelled data is expensive or impractical, enabling the model to learn from the inherent patterns and relationships present in the data.

#### Selection of Evaluation Metrics for Model Performance
The evaluation metrics were chosen to reflect the dual nature of the tasks: supervised and unsupervised evaluations. For supervised tasks, metrics such as accuracy or F1-score are appropriate as they measure the model's performance on specific tasks using labelled data. In contrast, unsupervised evaluations often rely on semantic similarity measures, such as cosine distance, which assess how well the learned representations capture the relationships between sentences without the need for labels. This dual approach ensures a comprehensive assessment of the models' capabilities across different applications.

#### Decision to Focus on Unlabelled Data for Training
Focusing on unlabelled data for training is justified by the abundance of such data compared to labelled datasets. Unlabelled data allows for the exploration of broader linguistic patterns and relationships, which can lead to more robust and generalizable sentence representations. This approach also aligns with the goal of developing models that can be applied across various domains and languages, as unlabelled data is often more universally available.

#### Comparison of Deep vs Shallow Models for Representation Learning
The comparison between deep and shallow models is rooted in the understanding that different architectures may excel in different contexts. Deep models, while computationally intensive, can capture complex relationships and nuances in data, making them suitable for supervised tasks where rich representations are beneficial. Conversely, shallow models, such as log-linear models, are computationally efficient and can perform well in unsupervised settings where the focus is on spatial relationships rather than intricate semantic structures.

#### Introduction of Sequential Denoising Autoencoders (SDAEs)
The introduction of SDAEs addresses the limitations of existing models, particularly the requirement for coherent inter-sentence narratives in models like SkipThought. SDAEs utilize a denoising approach, where the model learns to reconstruct original sentences from corrupted versions, allowing for greater flexibility in training on diverse datasets. This method enhances the model's ability to generalize across different domains, including those with less structured data, such as social media.

#### Development of FastSent Model
FastSent was developed to provide a computationally efficient alternative to more complex models like SkipThought. By leveraging a bag-of-words representation and focusing on predicting adjacent sentences, FastSent reduces training time while still capturing meaningful semantic relationships. This model exemplifies the trade-off between computational efficiency and representation richness, making it suitable for applications where speed is critical.

#### Use of Bag-of-Words vs Neural Network Architectures
The choice between bag-of-words (BOW) and neural network architectures is influenced by the specific requirements of the task. BOW models are simpler and faster to train, making them effective for certain unsupervised tasks where the focus is on word frequency and co-occurrence. In contrast, neural network architectures can capture more complex relationships and dependencies, which are essential for tasks requiring deeper semantic understanding. The decision to use one over the other depends on the balance between performance needs and computational resources.

#### Implementation of Noise Functions in SDAEs
The implementation of noise functions in SDAEs serves to enhance the model's robustness by introducing variability during training. By corrupting the input data through deletion and swapping of words, the model learns to focus on the most salient features of the sentences. This process not only improves the quality of the learned representations but also acts as a regularization technique, helping to prevent overfitting.

#### Trade-off Considerations Between Training Time and Performance
The trade-off between training time and performance is a critical consideration in model selection. While deeper models may yield better performance on complex tasks, they often require significantly more training time and computational resources. The research emphasizes the importance of finding a balance that meets the performance requirements of the application while remaining feasible in terms of training time and resource availability.

#### Domain Portability of Representation Learning Methods
The focus on unsupervised learning methods enhances the domain portability of representation learning techniques. By training on unlabelled data, models can generalize better across different domains and languages, making them more versatile. This characteristic is particularly valuable in real-world applications where the model may encounter diverse linguistic structures and contexts.

#### Choice of Datasets for Model Training and Evaluation
The selection of datasets for training and evaluation is crucial for ensuring that the models are tested on relevant and representative data. The Toronto Books Corpus, for instance, provides a rich source of coherent sentences, which is essential for training models like SkipThought and FastSent. The choice of datasets reflects the need for high-quality, diverse data that can effectively challenge the models and validate their performance