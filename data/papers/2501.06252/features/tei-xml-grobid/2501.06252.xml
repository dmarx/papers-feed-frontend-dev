<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">TRANSFORMER 2 : SELF-ADAPTIVE LLMS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-01-14">14 Jan 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Qi</forename><surname>Sun</surname></persName>
							<email>qisun@sakana.ai</email>
							<affiliation key="aff0">
								<orgName type="institution">Sakana AI</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Science</orgName>
								<address>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Edoardo</forename><surname>Cetin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Sakana AI</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yujin</forename><surname>Tang</surname></persName>
							<email>yujintang@sakana.ai</email>
							<affiliation key="aff0">
								<orgName type="institution">Sakana AI</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hidden</forename><surname>States</surname></persName>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Dispatch User Query</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">TRANSFORMER 2 : SELF-ADAPTIVE LLMS</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-01-14">14 Jan 2025</date>
						</imprint>
					</monogr>
					<idno type="MD5">1D41A61978784AE157D9C7D1F5D56014</idno>
					<idno type="arXiv">arXiv:2501.06252v2[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-02-21T16:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Self-adaptive large language models (LLMs) aim to solve the challenges posed by traditional fine-tuning methods, which are often computationally intensive and static in their ability to handle diverse tasks. We introduce Transformer 2 , a novel self-adaptation framework that adapts LLMs for unseen tasks in real-time by selectively adjusting only the singular components of their weight matrices. During inference, Transformer 2 employs a two-pass mechanism: first, a dispatch system identifies the task properties, and then task-specific "expert" vectors, trained using reinforcement learning, are dynamically mixed to obtain targeted behavior for the incoming prompt. Our method outperforms ubiquitous approaches such as LoRA, with fewer parameters and greater efficiency. Transformer 2 demonstrates versatility across different LLM architectures and modalities, including vision-language tasks. Transformer 2 represents a significant leap forward, offering a scalable, efficient solution for enhancing the adaptability and task-specific performance of LLMs, paving the way for truly dynamic, self-organizing AI systems. Our code is</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Figure <ref type="figure">1</ref>: Overview of Transformer 2 . In the training phase, we tune the scales of the singular values of the weight matrices to generate a set of "expert" vectors, each of which specializes in one type of tasks. In the inference phase, a two-pass process is adopted where the first applies the taskspecific expert and the second generates the answer.</p><p>Self-adaptive large language models (LLMs) would represent a significant advancement in artificial intelligence, providing a framework where models can adjust to varied tasks and dynamic contexts in real time. While compositionality and scalability are crucial for effective adaptation, current LLM training methodologies fall short of achieving both these properties simultaneously. Our research aims to present a pioneering solution to realize this vision and address these gaps.</p><p>Traditionally, LLM post-training has sought to optimize a model for a wide range of capabilities in a single, extensive training session. While this "one-shot" fine-tuning framework is ideal from a simplicity perspective, it is also difficult to achieve in practice. For instance, post-training is still highly resource-intensive, leading to significant computational costs and training times. Additionally, there tends to be notable performance trade-offs when introducing additional breadth to the data, making it challenging to overcome overfitting and task interference at the same time.</p><p>In contrast, self-adaptive models offer a more flexible and efficient approach. Rather than attempting to train an LLM for all tasks in one step, expert modules can be developed offline and augmented Preprint to the base LLM on-demand <ref type="bibr" target="#b15">(Kang et al., 2024)</ref>. This allows the model to dynamically modify its behavior based on the task at hand, without the need for constant re-tuning. In addition to the benefit of having independent components, this modularity also supports continual learning, enabling the model to add new skills over time without catastrophic forgetting. Moreover, self-adaptive LLMs mirror a well-established principle in neuroscience and computational biology, where the brain activates specific regions depending on the task at hand <ref type="bibr" target="#b22">(Loose et al., 2017)</ref> and dynamically reconfigures its functional networks in response to changing task demands <ref type="bibr" target="#b8">(Davison et al., 2015)</ref>.</p><p>In principle, the first step toward achieving self-adaptive LLMs can be realized through the development of specialized expert modules, each fine-tuned <ref type="bibr" target="#b16">(Kaplan et al., 2020)</ref> via techniques such as low-rank adaptation (LoRA) <ref type="bibr" target="#b13">(Hu et al., 2021)</ref>. These expert modules can then be dynamically composed at runtime based on the task demands, a process that can be efficiently managed through Mixture of Experts (MoE)-like systems <ref type="bibr">(Tianlong et al., 2024)</ref>. However, several challenges need to be addressed to make this approach both scalable and compositional. First, fine-tuning LLMs to create multiple expert modules significantly increases the number of parameters that need to be trained. In practice, even with parameter-efficient methods like LoRA, the cumulative size of these modules can quickly escalate, leading to increased storage and computational demands. Second, these expert modules are often prone to overfitting, a phenomenon especially prevalent when training on smaller datasets or narrow task domains. Third, the flexible composition of these expert modules also presents largely unresolved challenges currently posing as open research problems.</p><p>To overcome these limitations, we first propose Singular Value Fine-tuning (SVF), a novel parameter-efficient fine-tuning (PEFT) method to obtain effective building blocks for selfadaptation. SVF works by extracting and tuning only the singular values within the model's weight matrices. By focusing on this principled parameterization, our approach mitigates the risk of overfitting, drastically reduces computational demands, and allows for inherent compositionality. We show these properties enable us to cheaply obtain a set of effective domain-specific "expert" vectors by training on narrow datasets with RL, directly optimizing task performance on individual topics.</p><p>We then introduce our full Transformer 2 framework to empower LLMs through the underlying principles of self-adaptation. Given a prompt from an unknown task, Transformer 2 entails a two-pass inference mechanism which we illustrate in Figure <ref type="figure">1</ref>. During the first pass, Transformer 2 executes the model and observes its test-time behavior, gathering the relevant information to understand the necessary skills to tackle the current problem. During the second pass, our framework uses this information to combine the available expert vectors and provide a new modification to the base weights of the LLM specifically tailored to its test-time conditions. We design three different adaptation strategies that can be used within Transformer 2 , which we show provide monotonic performance benefits with increasing access to the test-time conditions.</p><p>We evaluate SVF and the full Transformer 2 framework through extensive experiments across a diverse range of LLMs and tasks. First, when trained on domain-specific datasets, we show that SVF consistently outperforms traditional strategies for efficient fine-tuning such as LoRA, and at the same time, with orders of magnitudes fewer parameters. Then we show that Transformer 2 is able to push performance far further, effectively adapting the weights of the base model even in entirely out-of-distribution applications such as visual question answering. Finally, we analyze the properties of our new framework, validating that it provides increasing benefits with additional access to its current test-time conditions and even allow for recycling pre-trained SVF experts across model architectures. In summary, our key technical contributions are the following:</p><p>• The development of Transformer 2 as a pivotal self-adaptation framework for LLMs, providing a universal blueprint to dynamically adapt the behavior of LLMs from a growing set of pre-trained skills.</p><p>• The introduction of SVF, a novel PEFT method trainable with RL on small datasets, producing compact expert vectors with inherent compositionality, all key properties necessary for our scalable self-adaptation framework.</p><p>• The implementation of three adaptation strategies within Transformer 2 , effectively dispatching SVF-trained experts with properties designed to cope with different requirements and deployment scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORKS</head><p>Self-adaptive LLMs We define self-adaptive LLMs as a group of LLMs or a standalone LLM that can evaluate and modify its behavior in response to changes in its operating environment or internal state, without external intervention. This adaptation can be explored from two perspectives: a macroview, where multiple LLMs collaborate and/or compete, and a microview, where internal adaptations allow a single LLM to specialize in different tasks.</p><p>Macroview: From this perspective, the system directs queries to LLMs with domain specific expertise, prioritizing outputs from expert models, thereby achieving higher accuracy and task-specific optimization. Such task-specific ensembles can be realized through various mechanisms: multiple LLMs playing distinct roles and coordinate toward a shared goal <ref type="bibr" target="#b37">(Zhuge et al., 2023)</ref>, engaging in mutual listening and debate <ref type="bibr" target="#b9">(Du et al., 2023)</ref>, or using meticulously crafted prompt constructions <ref type="bibr" target="#b34">(Zhang et al., 2024)</ref> to integrate knowledge library and skill planning. Naturally, the improvement in the specialization and adaptive capabilities of individual LLMs in the ensemble enhances the collective performance. Thus, in this paper, we focus on the microview of self-adaptive LLMs.</p><p>Microview: MoE in LLMs plays a critical role in this perspective <ref type="bibr">(Tianlong et al., 2024)</ref>. In MoE systems, inputs are dynamically routed to a subset of specialized modules or layers (e.g., MLPs) containing domain-specific knowledge <ref type="bibr" target="#b26">(Rajbhandari et al., 2022;</ref><ref type="bibr" target="#b10">Fedus et al., 2022)</ref>. To reduce inference time, researchers introduce sparsely activated MoE where only a subset of the experts are selected per token Jiang et al. (2024); Qwen <ref type="bibr" target="#b25">Team (2024)</ref>. While it is possible to view Transformer 2 loosely as a type of MoE, there are two major differences. In the aforementioned systems, selfadaptation is achieved through token-level routing, whereas Transformer 2 employs a sample-level module selection strategy. The second difference lies in the construction of expert modules. In traditional MoE systems, expert modules are either trained from scratch <ref type="bibr" target="#b10">(Fedus et al., 2022;</ref><ref type="bibr" target="#b14">Jiang et al., 2024)</ref> or dense models (e.g., upcycling) (Qwen <ref type="bibr" target="#b25">Team, 2024;</ref><ref type="bibr" target="#b36">Zhu et al., 2024)</ref>, without an auxiliary loss to ensure module specialization. In contrast, Transformer 2 specifically trains expert vectors with RL to acquire domain specific-knowledge, making them true experts.</p><p>Low-rank adaptation PEFT methods such as LoRA <ref type="bibr" target="#b13">(Hu et al., 2021)</ref> works by freezing the original model's parameters and introducing small trainable low-rank matrices for task-specific updates. It significantly lowers the computational and memory costs while providing performance comparable to full fine-tuning. Inspired by LoRA's design, various modifications have been proposed <ref type="bibr" target="#b35">(Zhang et al., 2023;</ref><ref type="bibr" target="#b18">Kopiczko et al., 2023;</ref><ref type="bibr" target="#b21">Liu et al., 2024;</ref><ref type="bibr" target="#b2">Bałazy et al., 2024;</ref><ref type="bibr" target="#b4">Cetoli, 2024)</ref>. Transformer 2 does not rely on low-rank matrices, and instead scales the singular vectors of the original parameter matrix that span the full rank space.</p><p>SVD for LLM Fine-tuning SVD is increasingly being used as an inductive bias for PEFT in LLMs. For example, <ref type="bibr" target="#b31">Wang et al. (2024)</ref> decompose a weight matrix and use the minor singular components, associated with noisy or long-tail information, to initialize low-rank matrices for LoRA fine-tuning. In a similar vein, SVD is employed to approximate an original weight matrix with the top r singular vectors, corresponding to the highest singular values. A small trainable matrix is then introduced on top of the truncated singular value matrix to adjust the magnitude and orientations within this top-r subspace <ref type="bibr" target="#b2">(Bałazy et al., 2024;</ref><ref type="bibr" target="#b4">Cetoli, 2024)</ref>. However, the drawback of this approach is that retaining only the top singular components can result in the loss of important information, particularly when the singular values distribution is less skewed. The work most similar to ours is a concurrent effort by <ref type="bibr" target="#b19">Lingam et al. (2024)</ref>, where they introduce various sparsification methods that utilize the SVD of the weights. However, it is not for self-adaptive LLMs and does not use RL to enhance learning efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">PRELIMINARIES</head><p>Singular value decomposition (SVD) offers a fundamental view of matrix multiplications. In the context of neural networks, each weight matrix W ∈ R n×m can be decomposed into three components W = U ΣV ⊺ , yielding semi-orthogonal matrices U ∈ R m×r and V ∈ R n×r together with an ordered vector of r singular values (in descending order) arranged in the diagonal matrix Σ ∈ R r×r . The linear operation defined by applying W onto x, can be then decomposed into a sum of indepen-Preprint dent terms, derived from mapping each column v i from V into the corresponding column u i from U as y = r i=1 σ i u i v ⊺ i x. Hence, each singular component represented by the rank-1 matrix u i v ⊺ i independently processes the input, providing an orthogonal contribution to the layer's outputs, with the singular values σ i modulating the degree of the contributions.</p><p>Cross-entropy method (CEM) is a Monte Carlo method for importance sampling and optimization <ref type="bibr" target="#b27">(Rubinstein &amp; Kroese, 2004)</ref>. The method is based on the concept of minimizing the KL divergence between two probability distributions D KL (P ∥Q), where P is the target distribution and Q is a maintained distribution. At its core, CEM repeatedly generates a set of samples from Q, evaluates these samples with a performance function, and then updates the distribution Q with the characteristics of the elite samples that have performed best. In the standard setup employed in most applications, Q is set to a diagonal multivariate Gaussian, reducing the problem to simply estimating the empirical mean and standard deviation of the latest elites until a stopping criterion is met. We illustrate a complete CEM step in the Python pseudocode below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">TRANSFORMER 2</head><p>The construction of Transformer 2 comprises two main steps, for which we provide an illustrative overview in Figure <ref type="figure" target="#fig_3">2</ref>. First, we introduce Singular Value Fine-tuning (SVF), a method to learn with RL compact and compositional expert vectors based on the SVD of the base model's weights. Then, we describe three different adaptation strategies within Transformer 2 , inspired by three orthogonal principles, which adaptively combine the SVF-trained expert vectors during inference. We motivate how the properties of SVF are highly complementary to our adaptation strategies, making Transformer 2 an effective and scalable framework for the design of new self-adaptive LLMs.</p><p>Layer Norm &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " h n f z L e U w 9 2</p><formula xml:id="formula_0">W J 9 y Y U k R k k / D J m o 2 g = " &gt; A A A B 8 n i c b Z D L S g M x F I Y z X m u 9 V V 2 6 C R b B V Z k R q e 4 s u H F Z w V 5 g O p Z M m m l D M 8 m Q n B H K 0 M d w Y R e K u P U F f A 1 3 v o 2 Z t g t t / S H w 8 f / n k H N O m A h u w H W / n Z X V t f W N z c J W c X t n d 2 + / d H D Y N C r V l D W o E k q 3 Q 2 K Y 4 J I 1 g I N g 7 U Q z E o e C t c L h T Z 6 3 H p k 2 X M l 7 G C U s i E l f 8 o h T A t b y m w 8 d L o F p S k S 3 V H Y r 7 l R 4 G b w 5 l K 8 / n 3 N N 6 t 3 S V 6 e n a B o z C V Q Q Y 3 z P T S D I i A Z O B R s X O 6 l h C a F D 0 m e + R U l i Z o J s O v I Y n 1 q n h y O l 7 Z O A p + 7 v j o z E x o z i 0 F b G B A Z m M c v N / z I / h e g q y L h M U m C S z j 6 K U o F B 4 X x / 3 O O a U R A j C 4 R q b m f F d E A 0 o f Y K p m i P 4 C 2 u v A z N 8 4 p X r V T v v H L t A s 1 U Q M f o B J 0 h D 1 2 i G r p F d d R A F C n 0 h F 7 Q q w P O</formula><p>x H l z 3 m e l K 8 6 8 5 w j 9 k f P x A 3 w 0 l d M = &lt; / l a t e x i t &gt;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V |</head><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " h n f z L e U w 9 2</p><formula xml:id="formula_1">W J 9 y Y U k R k k / D J m o 2 g = " &gt; A A A B 8 n i c b Z D L S g M x F I Y z X m u 9 V V 2 6 C R b B V Z k R q e 4 s u H F Z w V 5 g O p Z M m m l D M 8 m Q n B H K 0 M d w Y R e K u P U F f A 1 3 v o 2 Z t g t t / S H w 8 f / n k H N O m A h u w H W / n Z X V t f W N z c J W c X t n d 2 + / d H D Y N C r V l D W o E k q 3 Q 2 K Y 4 J I 1 g I N g 7 U Q z E o e C t c L h T Z 6 3 H p k 2 X M l 7 G C U s i E l f 8 o h T A t b y m w 8 d L o F p S k S 3 V H Y r 7 l R 4 G b w 5 l K 8 / n 3 N N 6 t 3 S V 6 e n a B o z C V Q Q Y 3 z P T S D I i A Z O B R s X O 6 l h C a F D 0 m e + R U l i Z o J s O v I Y n 1 q n h y O l 7 Z O A p + 7 v j o z E x o z i 0 F b G B A Z m M c v N / z I / h e g q y L h M U m C S z j 6 K U o F B 4 X x / 3 O O a U R A j C 4 R q b m f F d E A 0 o f Y K p m i P 4 C 2 u v A z N 8 4 p X r V T v v H L t A s 1 U Q M f o B J 0 h D 1 2 i G r p F d d R A F C n 0 h F 7 Q q w P O</formula><p>x H l z 3 m e l K 8 6 8 5 w j 9 k f P x A 3 w 0 l d M = &lt; / l a t e x i t &gt;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V |</head><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 j U L m K 0 J R D i G / w 9 c 6 w l V 1 j j 7 g u I</p><formula xml:id="formula_2">= " &gt; A A A B 7 X i c b Z C 7 S g N B F I b P x l u M t 6 i l I I N B S B V 2 L a K d A R v L B M 0 F k h B m J 7 P J m N m Z Z W Z W C E t K e x s L R W z t r P M c d j 6 D L + H k U m j i D w M f / 3 8 O c 8 7 x I 8 6 0 c d 0 v J 7 W y u r a + k d 7 M b G 3 v 7 O 5 l 9 w 9 q W s a K 0 C q R X K q G j z X l T N C q Y Y b T R q Q o D n 1 O 6 / 7 g a p L X 7 6 n S T I p b M 4 x o O 8 Q 9 w Q J G s L F W r X X D e i H u Z H N u w Z 0 K L Y M 3 h 9 z l x 7 j y / X A 8 L n e y n 6 2 u J H F I h S E c a 9 3 0 3 M i 0 E 6 w M I 5 y O M q 1 Y 0 w i T A e 7 R p k W B Q 6 r b y X T a E T q 1 T h c F U t k n D J q 6 v z s S H G o 9 D H 1 b G W L T 1 4 v Z x P w v a 8 Y m u G g n T E S x o Y L M P g p i j o x E k 9 V R l y l K D B 9 a w E Q x O y s i f a w w M f Z A G X s E b 3 H l Z a i d F b x i o V j x c q U 8 z J S G I z i B P H h w D i W 4 h j J U g c A d P M I z v D j S e X J e n b d Z a c q Z 9 x z C H z n v P x k H k y 0 = &lt; / l a t e x i t &gt; ⌃ &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 j U L m K 0 J R D i G / w 9 c 6 w l V 1 j j 7 g u I = " &gt; A A A B 7 X i c b Z C 7 S g N B F I b P x l u M t 6 i l I I N B S B V 2 L a K d A R v L B M 0 F k h B m J 7 P J m N m Z Z W Z W C E t K e x s L R W z t r P M c d j 6 D L + H k U m j i D w M f / 3 8 O c 8 7 x I 8 6 0 c d 0 v J 7 W y u r a + k d 7 M b G 3 v 7 O 5 l 9 w 9 q W s a K 0 C q R X K q G j z X l T N C q Y Y b T R q Q o D n 1 O 6 / 7 g a p L X 7 6 n S T I p b M 4 x o O 8 Q 9 w Q J G s L F W r X X D e i H u Z H N u w Z 0 K L Y M 3 h 9 z l x 7 j y / X A 8 L n e y n 6 2 u J H F I h S E c a 9 3 0 3 M i 0 E 6 w M I 5 y O M q 1 Y 0 w i T A e 7 R p k W B Q 6 r b y X T a E T q 1 T h c F U t k n D J q 6 v z s S H G o 9 D H 1 b G W L T 1 4 v Z x P w v a 8 Y m u G g n T E S x o Y L M P g p i j o x E k 9 V R l y l K D B 9 a w E Q x O y s i f a w w M f Z A G X s E b 3 H l Z a i d F b x i o V j x c q U 8 z J S G I z i B P H h w D i W 4 h j J U g c A d P M I z v D j S e X J e n b d Z a c q Z 9 x z C H z n v P x k H k y 0 = &lt; / l a t e x i t &gt; ⌃ &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " k a / W w x C 9 N k 0 i 9 9 a M s Q m 1 D v J g r g 0 = " &gt; A A A B 6 H i c b Z D P T s J A E M a n + A / x H + r R S y M x 8 U R a Y 9 C b J F 4 8 Q m K B B B q y X a a w s t 0 2 u 1 s T Q n g C L x 4 0 B o + + h a / h z b d x C x w U / J J N f v m + m e z M B A l n S j v O t 5 V b W 9 / Y 3 M p v F 3 Z 2 9 / Y P i o d H D R W n k q J H Y x 7 L V k A U c i b Q 0 0 x z b C U S S R R w b A b D 2 y x v P q J U L B b 3 e p S g H 5 G + Y C G j R B u r 7 n W L J a f s z G S v g r u A 0 s 3 n N N N 7 r V v 8 6 v R i m k Y o N O V E q b b r J N o f E 6 k Z 5 T g p d F K F C a F D 0 s e 2 Q U E i V P 5 4 N u j E P j N O z w 5 j a Z 7 Q 9 s z 9 3 T E m k V K j K D C V E d E D t Z x l 5 n 9 Z O 9 X h t T 9 m I k k 1 C j r / K E y 5 r W M 7 2 9 r u M Y l U 8 5 E B Q i U z s 9 p 0 Q C S h 2 t y m Y I 7 g L q + 8 C o 2 L s l s p V + p u q X o J c + X h B E 7 h H F y 4 g i r c Q Q 0 8 o I D w B C / w a j 1 Y z 9 a b N Z 2 X 5 q x F z z H 8 k f X x A 9 F 0 k W I = &lt; / l a t e x i t &gt; U &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " k a / W w x C 9 N k 0 i 9 9 a M s Q m 1 D v J g r g 0 = " &gt; A A A B 6 H i c b Z D P T s J A E M a n + A / x H + r R S y M x 8 U R a Y 9 C b J F 4 8 Q m K B B B q y X a a w s t 0 2 u 1 s T Q n g C L x 4 0 B o + + h a / h z b d x C x w U / J J N f v m + m e z M B A l n S j v O t 5 V b W 9 / Y 3 M p v F 3 Z 2 9 / Y P i o d H D R W n k q J H Y x 7 L V k A U c i b Q 0 0 x z b C U S S R R w b A b D 2 y x v P q J U L B b 3 e p S g H 5 G + Y C G j R B u r 7 n W L J a f s z G S v g r u A 0 s 3 n N N N 7 r V v 8 6 v R i m k Y o N O V E q b b r J N o f E 6 k Z 5 T g p d F K F C a F D 0 s e 2 Q U E i V P 5 4 N u j E P j N O z w 5 j a Z 7 Q 9 s z 9 3 T E m k V K j K D C V E d E D t Z x l 5 n 9 Z O 9 X h t T 9 m I k k 1 C j r / K E y 5 r W M 7 2 9 r u M Y l U 8 5 E B Q i U z s 9 p 0 Q C S h 2 t y m Y I 7 g L q + 8 C o 2 L s l s p V + p u q X o J c + X h B E 7 h H F y 4 g i r c Q Q 0 8 o I D w B C / w a j 1 Y z 9 a b N Z 2 X 5 q x F z z H 8 k f X x A 9 F 0 k W I = &lt; / l a t e x i t &gt; U Attention Layer Norm MLP &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " W P T q 7 o v T C C e l 7 T 1 4 7 D 5 3 / f 3 8 N R g = " &gt; A A A B 6 H i c b Z C 7 S g N B F I b P x l u M t 3 j p b A a D Y B V 2 L a K d A Q u t J A F z g W Q J s 5 O z y Z j Z C z O z Q l z y B D Y W i t j 6 A F Y + i Z 2 l b + L k U m j 0 h 4 G P / z + H O e d 4 s e B K 2 / a n l V l Y X F p e y a 7 m 1 t Y 3 N r f y 2 z t 1 F S W S Y Y 1 F I p J N j y o U P M S a 5 l p g M 5 Z I A 0 9 g w x u c j / P G L U r F o / B a D 2 N 0 A 9 o L u c 8 Z 1 c a q X n X y B b t o T 0 T + g j O D w t n 7 3 d f F 2 1 5 a 6 e Q / 2 t 2 I J Q G G m g m q V M u x Y + 2 m V G r O B I 5 y 7 U R h T N m A 9 r B l M K Q B K j e d D D o i h 8 b p E j + S 5 o W a T N y f H S k N l B o G n q k M q O 6 r + W x s / p e 1 E u 2 f u i k P 4 0 R j y K Y f + Y k g O i L j r U m X S 2 R a D A 1 Q J r m Z l b A + l Z R p c 5 u c O Y I z v / J f q B 8 X n V K x V H U K Z R u m y s I + H M A R O H A C Z b i E C t S A A c I 9 P M K T d W M 9 W M / W y 7 Q 0 Y 8 1 6 d u G X r N d v y O q Q m g = = &lt; / l a t e x i t &gt; N &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " W P T q 7 o v T C C e l 7 T 1 4 7 D 5 3 / f 3 8 N R g = " &gt; A A A B 6 H i c b Z C 7 S g N B F I b P x l u M t 3 j p b A a D Y B V 2 L a K d A Q u t J A F z g W Q J s 5 O z y Z j Z C z O z Q l z y B D Y W i t j 6 A F Y + i Z 2 l b + L k U m j 0 h 4 G P / z + H O e d 4 s e B K 2 / a n l V l Y X F p e y a 7 m 1 t Y 3 N r f y 2 z t 1 F S W S Y Y 1 F I p J N j y o U P M S a 5 l p g M 5 Z I A 0 9 g w x u c j / P G L U r F o / B a D 2 N 0 A 9 o L u c 8 Z 1 c a q X n X y B b t o T 0 T + g j O D w t n 7 3 d f F 2 1 5 a 6 e Q / 2 t 2 I J Q G G m g m q V M u x Y + 2 m V G r O B I 5 y 7 U R h T N m A 9 r B l M K Q B K j e d D D o i h 8 b p E j + S 5 o W a T N y f H S k N l B o G n q k M q O 6 r + W x s / p e 1 E u 2 f u i k P 4 0 R j y K Y f + Y k g O i L j r U m X S 2 R a D A 1 Q J r m Z l b A + l Z R p c 5 u c O Y I z v / J f q B 8 X n V K x V H U K Z R u m y s I + H M A R O H A C Z b i E C t S A A c I 9 P M K T d W M 9 W M / W y 7 Q 0 Y 8 1 6 d u G X r N d v y O q Q m g = = &lt; / l a t e x i t &gt; N layers &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " y C 9 X / v I c z v f 0 c N c 9 N a H z 4 5 L o 3 1 s = " &gt; A A A B 6 H i c b Z C 7 S g N B F I b P x l u M t 6 i l I I t B S B V 2 L a K d A R v L B M w F k x B m J 2 e T M b O z y 8 y s E J a U V j Y W i t j 6 A N Z 5 D j u f w Z d w c i k 0 8 Y e B j / 8 / h z n n e B F n S j v O l 5 V a W V 1 b 3 0 h v Z r a 2 d 3 b 3 s v s H N R X G k m K V h j y U D Y 8 o 5 E x g V T P N s R F J J I H H s e 4 N r i Z 5 / R 6 l Y q G 4 0 c M I 2 w H p C e Y z S r S x K r e d b M 4 p O F P Z y + D O I X f 5 M a 5 8 P x y P y 5 3 s Z 6 s b 0 j h A o S k n S j V d J 9 L t h E j N K M d R p h U r j A g d k B 4 2 D Q o S o G o n 0 0 F H 9 q l x u r Y f S v O E t q f u 7 4 6 E B E o N A 8 9 U B k T 3 1 W I 2 M f / L m r H 2 L 9 o J E 1 G s U d D Z R 3 7 M b R 3 a k 6 3 t L p N I N R 8 a I F Q y M 6 t N + 0 Q S q s 1 t M u Y I 7 u L K y 1 A 7 K 7 j F Q r H i 5 k p 5 m C k N R 3 A C e X D h H E p w D W W o A g W E R 3 i G F + v O e r J e r b d Z a c q a 9 x z C H 1 n v P 2 Z p k Q g = &lt; / l a t e x i t &gt; Z &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " y C 9 X / v I c z v f 0 c N c 9 N a H z 4 5 L o 3 1 s = " &gt; A A A B 6 H i c b Z C 7 S g N B F I b P x l u M t 6 i l I I t B S B V 2 L a K d A R v L B M w F k x B m J 2 e T M b O z y 8 y s E J a U V j Y W i t j 6 A N Z 5 D j u f w Z d w c i k 0 8 Y e B j / 8 / h z n n e B F n S j v O l 5 V a W V 1 b 3 0 h v Z r a 2 d 3 b 3 s v s H N R X G k m K V h j y U D Y 8 o 5 E x g V T P N s R F J J I H H s e 4 N r i Z 5 / R 6 l Y q G 4 0 c M I 2 w H p C e Y z S r S x K r e d b M 4 p O F P Z y + D O I X f 5 M a 5 8 P x y P y 5 3 s Z 6 s b 0 j h A o S k n S j V d J 9 L t h E j N K M d R p h U r j A g d k B 4 2 D Q o S o G o n 0 0 F H 9 q l x u r Y f S v O E t q f u 7 4 6 E B E o N A 8 9 U B k T 3 1 W I 2 M f / L m r H 2 L 9 o J E 1 G s U d D Z R 3 7 M b R 3 a k 6 3 t L p N I N R 8 a I F Q y M 6 t N + 0 Q S q s 1 t M u Y I 7 u L K y 1 A 7 K 7 j F Q r H i 5 k p 5 m C k N R 3 A C e X D h H E p w D W W o A g W E R 3 i G F + v O e r J e r b d Z a c q a 9 x z C H 1 n v P 2 Z p k Q g = &lt; / l a t e x i t &gt; Z</formula><p>Learnable parameters trained with RL</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Frozen parameters</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training Time Inference Time</head><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Z y 7 m R h e C x 4 9 r 7 k 9   … &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Z o B K u E 7 P 6 9 F e 4 F s t</p><formula xml:id="formula_3">l 9 p f Y k h W F 0 q k = " &gt; A A A B 6 H i c b Z C 7 S g N B F I b P x l u M t 3 j p b A a D Y B V 2 L a K d A Q t t h A T M B Z I l z E 7 O J m N m L 8 z M C n H J E 9 h Y K G L r A 1 j 5 J H a W v o m T S 6 H R H w Y + / v 8 c 5 p z j x Y I r b d u f V m Z h c W l 5 J b u a W 1 v f 2 N z K b + / U V Z R I h j U W i U g 2 P a p Q 8 B B r m m u B z V g i D T y B D W 9 w P s 4 b t y g V j 8 J r P Y z R D W g v 5 D 5 n V B u r e t X J F + y i P R H 5 C 8 4 M C m f v d 1 8 X b 3 t p p Z P / a H c j l g Q Y a i a o U i 3 H j r W b U q k 5 E z j K t R O F M W U D 2 s O W w Z A G q N x 0 M u i I H B q n S / x I m h d q M n F / d q Q 0 U G o Y e K Y y o L q v 5 r O x + V / W S r R / 6 q Y 8 j B O N I Z t + 5 C e C 6 I i M t y Z d L p F p M T R A m e R m V s L 6 V F K m z W 1 y 5 g j O / M p / o X 5 c d E r F U t U p l G 2 Y K g v 7 c A B H 4 M A J l O E S K l A D B g j 3 8 A h P 1 o 3 1 Y D 1 b L 9 P S j D X r 2 Y V f s l 6 / A c d m k J k = &lt; / l a t e x i t &gt; M &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Z y 7 m R h e C x 4 9 r 7 k 9 l 9 p f Y k h W F 0 q k = " &gt; A A A B 6 H i c b Z C 7 S g N B F I b P x l u M t 3 j p b A a D Y B V 2 L a K d A Q t t h A T M B Z I l z E 7 O J m N m L 8 z M C n H J E 9 h Y K G L r A 1 j 5 J H a W v o m T S 6 H R H w Y + / v 8 c 5 p z j x Y I r b d u f V m Z h c W l 5 J b u a W 1 v f 2 N z K b + / U V Z R I h j U W i U g 2 P a p Q 8 B B r m m u B z V g i D T y B D W 9 w P s 4 b t y g V j 8 J r P Y z R D W g v 5 D 5 n V B u r e t X J F + y i P R H 5 C 8 4 M C m f v d 1 8 X b 3 t p p Z P / a H c j l g Q Y a i a o U i 3 H j r W b U q k 5 E z j K t R O F M W U D 2 s O W w Z A G q N x 0 M u i I H B q n S / x I m h d q M n F / d q Q 0 U G o Y e K Y y o L q v 5 r O x + V / W S r R / 6 q Y 8 j B O N I Z t + 5 C e C 6 I i M t y Z d L p F p M T R A m e R m V s L 6 V F K m z W 1 y 5 g j O / M p / o X 5 c d E r F U t U p l G 2 Y K g v 7 c A B H 4 M A J l O E S K l A D B g j 3 8 A h P 1 o 3 1 Y D 1 b L 9 P S j D X r 2 Y V f s l 6 / A c d m k J k = &lt; / l a t e x i t &gt; M matrices &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " h n f z L e U w 9 2 W J 9 y Y U k R k k / D J m o 2 g = " &gt; A A A B 8 n i c b Z D L S g M x F I Y z X m u 9 V V 2 6 C R b B V Z k R q e 4 s u H F Z w V 5 g O p Z M m m l D M 8 m Q n B H K 0 M d w Y R e K u P U F f A 1 3 v o 2 Z t g t t / S H w 8 f / n k H N O m A h u w H W / n Z X V t f W N z c J W c X t n d 2 + / d H D Y N C r V l D W o E k q 3 Q 2 K Y 4 J I 1 g I N g 7 U Q z E o e C t c L h T Z 6 3 H p k 2 X M l 7 G C U s i E l f 8 o h T A t b y m w 8 d L o F p S k S 3 V H Y r 7 l R 4 G b w 5 l K 8 / n 3 N N 6 t 3 S V 6 e n a B o z C V Q Q Y 3 z P T S D I i A Z O B R s X O 6 l h C a F D 0 m e + R U l i Z o J s O v I Y n 1 q n h y O l 7 Z O A p + 7 v j o z E x o z i 0 F b G B A Z m M c v N / z I / h e g q y L h M U m C S z j 6 K U o F B 4 X x / 3 O O a U R A j C 4 R q b m f F d E A 0 o f Y K p m i P 4 C 2 u v A z N 8 4 p X r V T v v H L t A s 1 U Q M f o B J 0 h D 1 2 i G r p F d d R A F C n 0 h F 7 Q q w P O x H l z 3 m e l K 8 6 8 5 w j 9 k f P x A 3 w 0 l d M = &lt; / l a t e x i t &gt; V | &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " h n f z L e U w 9 2 W J 9 y Y U k R k k / D J m o 2 g = " &gt; A A A B 8 n i c b Z D L S g M x F I Y z X m u 9 V V 2 6 C R b B V Z k R q e 4 s u H F Z w V 5 g O p Z M m m l D M 8 m Q n B H K 0 M d w Y R e K u P U F f A 1 3 v o 2 Z t g t t / S H w 8 f / n k H N O m A h u w H W / n Z X V t f W N z c J W c X t n d 2 + / d H D Y N C r V l D W o E k q 3 Q 2 K Y 4 J I 1 g I N g 7 U Q z E o e C t c L h T Z 6 3 H p k 2 X M l 7 G C U s i E l f 8 o h T A t b y m w 8 d L o F p S k S 3 V H Y r 7 l R 4 G b w 5 l K 8 / n 3 N N 6 t 3 S V 6 e n a B o z C V Q Q Y 3 z P T S D I i A Z O B R s X O 6 l h C a F D 0 m e + R U l i Z o J s O v I Y n 1 q n h y O l 7 Z O A p + 7 v j o z E x o z i 0 F b G B A Z m M c v N / z I / h e g q y L h M U m C S z j 6 K U o F B 4 X x / 3 O O a U R A j C 4 R q b m f F d E A 0 o f Y K p m i P 4 C 2 u v A z N 8 4 p X r V T v v H L t A s 1 U Q M f o B J 0 h D 1 2 i G r p F d d R A F C n 0 h F 7 Q q w P O x H l z 3 m e l K 8 6 8 5 w j 9 k f P x A 3 w 0 l d M = &lt; / l a t e x i t &gt; V | &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 j U L m K 0 J R D i G / w 9 c 6 w l V 1 j j 7 g u I = " &gt; A A A B 7 X i c b Z C 7 S g N B F I b P x l u M t 6 i l I I N B S B V 2 L a K d A R v L B M 0 F k h B m J 7 P J m N m Z Z W Z W C E t K e x s L R W z t r P M c d j 6 D L + H k U m j i D w M f / 3 8 O c 8 7 x I 8 6 0 c d 0 v J 7 W y u r a + k d 7 M b G 3 v 7 O 5 l 9 w 9 q W s a K 0 C q R X K q G j z X l T N C q Y Y b T R q Q o D n 1 O 6 / 7 g a p L X 7 6 n S T I p b M 4 x o O 8 Q 9 w Q J G s L F W r X X D e i H u Z H N u w Z 0 K L Y M 3 h 9 z l x 7 j y / X A 8 L n e y n 6 2 u J H F I h S E c a 9 3 0 3 M i 0 E 6 w M I 5 y O M q 1 Y 0 w i T A e 7 R p k W B Q 6 r b y X T a E T q 1 T h c F U t k n D J q 6 v z s S H G o 9 D H 1 b G W L T 1 4 v Z x P w v a 8 Y m u G g n T E S x o Y L M P g p i j o x E k 9 V R l y l K D B 9 a w E Q x O y s i f a w w M f Z A G X s E b 3 H l Z a i d F b x i o V j x c q U 8 z J S G I z i B P H h w D i W 4 h j J U g c A d P M I z v D j S e X J e n b d Z a c q Z 9 x z C H z n v P x k H k y 0 = &lt; / l a t e x i t &gt; ⌃ &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 j U L m K 0 J R D i G / w 9 c 6 w l V 1 j j 7 g u I = " &gt; A A A B 7 X i c b Z C 7 S g N B F I b P x l u M t 6 i l I I N B S B V 2 L a K d A R v L B M 0 F k h B m J 7 P J m N m Z Z W Z W C E t K e x s L R W z t r P M c d j 6 D L + H k U m j i D w M f / 3 8 O c 8 7 x I 8 6 0 c d 0 v J 7 W y u r a + k d 7 M b G 3 v 7 O 5 l 9 w 9 q W s a K 0 C q R X K q G j z X l T N C q Y Y b T R q Q o D n 1 O 6 / 7 g a p L X 7 6 n S T I p b M 4 x o O 8 Q 9 w Q J G s L F W r X X D e i H u Z H N u w Z 0 K L Y M 3 h 9 z l x 7 j y / X A 8 L n e y n 6 2 u J H F I h S E c a 9 3 0 3 M i 0 E 6 w M I 5 y O M q 1 Y 0 w i T A e 7 R p k W B Q 6 r b y X T a E T q 1 T h c F U t k n D J q 6 v z s S H G o 9 D H 1 b G W L T 1 4 v Z x P w v a 8 Y m u G g n T E S x o Y L M P g p i j o x E k 9 V R l y l K D B 9 a w E Q x O y s i f a w w M f Z A G X s E b 3 H l Z a i d F b x i o V j x c q U 8 z J S G I z i B P H h w D i W 4 h j J U g c A d P M I z v D j S e X J e n b d Z a c q Z 9 x z C H z n v P x k H k y 0 = &lt; / l a t e x i t &gt; ⌃ &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " k a / W w x C 9 N k 0 i 9 9 a M s Q m 1 D v J g r g 0 = " &gt; A A A B 6 H i c b Z D P T s J A E M a n + A / x H + r R S y M x 8 U R a Y 9 C b J F 4 8 Q m K B B B q y X a a w s t 0 2 u 1 s T Q n g C L x 4 0 B o + + h a / h z b d x C x w U / J J N f v m + m e z M B A l n S j v O t 5 V b W 9 / Y 3 M p v F 3 Z 2 9 / Y P i o d H D R W n k q J H Y x 7 L V k A U c i b Q 0 0 x z b C U S S R R w b A b D 2 y x v P q J U L B b 3 e p S g H 5 G + Y C G j R B u r 7 n W L J a f s z G S v g r u A 0 s 3 n N N N 7 r V v 8 6 v R i m k Y o N O V E q b b r J N o f E 6 k Z 5 T g p d F K F C a F D 0 s e 2 Q U E i V P 5 4 N u j E P j N O z w 5 j a Z 7 Q 9 s z 9 3 T E m k V K j K D C V E d E D t Z x l 5 n 9 Z O 9 X h t T 9 m I k k 1 C j r / K E y 5 r W M 7 2 9 r u M Y l U 8 5 E B Q i U z s 9 p 0 Q C S h 2 t y m Y I 7 g L q + 8 C o 2 L s l s p V + p u q X o J c + X h B E 7 h H F y 4 g i r c Q Q 0 8 o I D w B C / w a j 1 Y z 9 a b N Z 2 X 5 q x F z z H 8 k f X x A 9 F 0 k W I = &lt; / l a t e x i t &gt; U &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " k a / W w x C 9 N k 0 i 9 9 a M s Q m 1 D v J g r g 0 = " &gt; A A A B 6 H i c b Z D P T s J A E M a n + A / x H + r R S y M x 8 U R a Y 9 C b J F 4 8 Q m K B B B q y X a a w s t 0 2 u 1 s T Q n g C L x 4 0 B o + + h a / h z b d x C x w U / J J N f v m + m e z M B A l n S j v O t 5 V b W 9 / Y 3 M p v F 3 Z 2 9 / Y P i o d H D R W n k q J H Y x 7 L V k A U c i b Q 0 0 x z b C U S S R R w b A b D 2 y x v P q J U L B b 3 e p S g H 5 G + Y C G j R B u r 7 n W L J a f s z G S v g r u A 0 s 3 n N N N 7 r V v 8 6 v R i m k Y o N O V E q b b r J N o f E 6 k Z 5 T g p d F K F C a F D 0 s e 2 Q U E i V P 5 4 N u j E P j N O z w 5 j a Z 7 Q 9 s z 9 3 T E m k V K j K D C V E d E D t Z x l 5 n 9 Z O 9 X h t T 9 m I k k 1 C j r / K E y 5 r W M 7 2 9 r u M Y l U 8 5 E B Q i U z s 9 p 0 Q C S h 2 t y m Y I 7 g L q + 8 C o 2 L s l s p V + p u q X o J c + X h B E 7 h H F y 4 g i r c Q Q 0 8 o I D w B C / w a j 1 Y z 9 a b N Z 2 X 5 q x F z z H 8 k f X x A 9 F 0 k W I = &lt; / l a t e x i t &gt; U &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " y C 9 X / v I c z v f 0 c N c 9 N a H z 4 5 L o 3 1 s = " &gt; A A A B 6 H i c b Z C 7 S g N B F I b P x l u M t 6 i l I I t B S B V 2 L a K d A R v L B M w F k x B m J 2 e T M b O z y 8 y s E J a U V j Y W i t j 6 A N Z 5 D j u f w Z d w c i k 0 8 Y e B j / 8 / h z n n e B F n S j v O l 5 V a W V 1 b 3 0 h v Z r a 2 d 3 b 3 s v s H N R X G k m K V h j y U D Y 8 o 5 E x g V T P N s R F J J I H H s e 4 N r i Z 5 / R 6 l Y q G 4 0 c M I 2 w H p C e Y z S</formula><formula xml:id="formula_4">j h A o S k n S j V d J 9 L t h E j N K M d R p h U r j A g d k B 4 2 D Q o S o G o n 0 0 F H 9 q l x u r Y f S v O E t q f u 7 4 6 E B E o N A 8 9 U B k T 3 1 W I 2 M f / L m r H 2 L 9 o J E 1 G s U d D Z R 3 7 M b R 3 a k 6 3 t L p N I N R 8 a I F Q y M 6 t N + 0 Q S q s 1 t M u Y I 7 u L K y 1 A 7 K 7 j F Q r H i 5 k p 5 m C k N R 3 A C e X D h H E p w D W W o A g W E R 3 i G F + v O e r J e r b d Z a c q a 9 x z C H 1 n v P 2 Z p k Q g = &lt; / l a t e x i t &gt; Z &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " y C 9 X / v I c z v f 0 c N c 9 N a H z 4 5 L o 3 1 s = " &gt; A A A B 6 H i c b Z C 7 S g N B F I b P x l u M t 6 i l I I t B S B V 2 L a K d A R v L B M w F k x B m J 2 e T M b O z y 8 y s E J a U V j Y W i t j 6 A N Z 5 D j u f w Z d w c i k 0 8 Y e B j / 8 / h z n n e B F n S j v O l 5 V a W V 1 b 3 0 h v Z r a 2 d 3 b 3 s v s H N R X G k m K V h j y U D Y 8 o 5 E x g V T P N s R F J J I H H s e 4 N r i Z 5 / R 6 l Y q G 4 0 c M I 2 w H p C e Y z S</formula><formula xml:id="formula_5">j h A o S k n S j V d J 9 L t h E j N K M d R p h U r j A g d k B 4 2 D Q o S o G o n 0 0 F H 9 q l x u r Y f S v O E t q f u 7 4 6 E B E o N A 8 9 U B k T 3 1 W I 2 M f / L m r H 2 L 9 o J E 1 G s U d D Z R 3 7 M b R 3 a k 6 3 t L p N I N R 8 a I F Q y M 6 t N + 0 Q S q s 1 t M u Y I 7 u L K y 1 A 7 K 7 j F Q r H i 5 k p 5 m C k N R 3 A C e X D h H E p w D W W o A g W E R 3 i G F + v O e r J e</formula><formula xml:id="formula_6">E B q O V I c w R L 0 = " &gt; A A A B + H i c b V D L S s N A F J 2 0 P m p 9 N C q u 3 A w W Q R B K 4 q K 6 L L h x W c E + o C l h M p 2 0 Q y e T M H M j 1 N A v c e N C E b f + g b / g Q n D l p + j 0 s d D W A x c O 5 9 z L v f c E i e A a H O f T y u V X V t f W C x v F z a 3 t n Z K 9 u 9 f U c a o o a 9 B Y x K o d E M 0 E l 6 w B H A R r J 4 q R K B C s F Q w v J 3 7 r l i n N Y 3 k D o 4 R 1 I 9 K X P O S U g J F 8 u 3 T q E Z E M i D / 0 g E d M + 3 b Z q T h T 4 G X i z k m 5 l v / 4 f j v 4 Y n X f f v d 6 M U 0 j J o E K o n X H d R L o Z k Q B p 4 K N i 1 6 q W U L o k P R Z x 1 B J z J J u N j 1 8 j I + N 0 s N h r E x J w F P 1 9 0 R G I q 1 H U W A 6 I w I D v e h N x P + 8 T g r h R T f j M k m B S T p b F K Y C Q 4 w n K e A e V 4 y C G B l C q O L m V k w H R B E K J q u i C c F d f H m Z N M 8 q b r V S v X b L N Q f N U E C H 6 A i d I B e d o x q 6 Q n X U Q B S l 6 B 4 9 o i f r z n q w n q 2 X W W v O m s / s o z + w X n 8 A T K C X P g = = &lt; / l a t e x i t &gt; +↵k⇥ &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Z o B K u E 7 P 6 9 F e 4 F s t E B q O V I c w R L 0 = " &gt; A A A B + H i c b V D L S s N A F J 2 0 P m p 9 N C q u 3 A w W Q R B K 4 q K 6 L L h x W c E + o C l h M p 2 0 Q y e T M H M j 1 N A v c e N C E b f + g b / g Q n D l p + j 0 s d D W A x c O 5 9 z L v f c E i e A a H O f T y u V X V t f W C x v F z a 3 t n Z K 9 u 9 f U c a o o a 9 B Y x K o d E M 0 E l 6 w B H A R r J 4 q R K B C s F Q w v J 3 7 r l i n N Y 3 k D o 4 R 1 I 9 K X P O S U g J F 8 u 3 T q E Z E M i D / 0 g E d M + 3 b Z q T h T 4 G X i z k m 5 l v / 4 f j v 4 Y n X f f v d 6 M U 0 j J o E K o n X H d R L o Z k Q B p 4 K N i 1 6 q W U L o k P R Z x 1 B J z J J u N j 1 8 j I + N 0 s N h r E x J w F P 1 9 0 R G I q 1 H U W A 6 I w I D v e h N x P + 8 T g r h R T f j M k m B S T p b F K Y C Q 4 w n K e A e V 4 y C G B l C q O L m V k w H R B E K J q u i C c F d f H m Z N M 8 q b r V S v X b L N Q f N U E C H 6 A i d I B e d o x q 6 Q n X U Q B S l 6 B 4 9 o i f r z n q w n q 2 X W W v O m s / s o z + w X n 8 A T K C X P g = = &lt; / l a t e x i t &gt; +↵k⇥ &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r v Y 7 U R D e t H J 3 u M U Q Z v 0 k 4 4 X F e l M = " &gt; A A A B + H i c b V D L S s N A F J 1 Y H 7 U + G h V X b g a L I A g l 6 a K 6 L L h x W c E + o C n h Z j p p h 0 4 m Y W Y i 1 N A v c e N C E b f + g b / g Q n D l p + j 0 s d D W A x c O 5 9 z L v f c E C W d K O 8 6 n t Z J b X V v f y G 8 W t r Z 3 d o v 2 3 n 5 T x a k k t E F i H s t 2 A I p y J m h D M 8 1 p O 5 E U o o D T V j C 8 n P i t W y o V i 8 W N H i W 0 G 0 F f s J A R 0 E b y 7 e K Z B z w Z g F / x N I u o 8 u 2 S U 3 a m w M v E n Z N S L f f x / X b 4 R e u + / e 7 1 Y p J G V G j C Q a m O 6 y S 6 m 4 H U j H A 6 L n i p o g m Q I f R p x 1 A B Z k k 3 m x 4 + x i d G 6 e E w l q a E x l P 1 9 0 Q G k V K j K D C d E e i B W v Q m 4 n 9 e J 9 X h R T d j I k k 1 F W S 2 K E w 5 1 j G e p I B 7 T F K i + c g Q I J K Z W z E Z g A S i T V Y F E 4 K 7 + P I y a V b K b r V c v X Z L N Q f N k E d H 6 B i d I h e d o x q 6 Q n X U Q A S l 6 B 4 9 o i f r z n q w n q 2 X W e u K N Z 8 5 Q H 9 g v f 4 A 9 N e X B Q = = &lt; / l a t e x i t &gt; +↵2⇥ &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r v Y 7 U R D e t H J 3 u M U Q Z v 0 k 4 4 X F e l M = " &gt; A A A B + H i c b V D L S s N A F J 1 Y H 7 U + G h V X b g a L I A g l 6 a K 6 L L h x W c E + o C n h Z j p p h 0 4 m Y W Y i 1 N A v c e N C E b f + g b / g Q n D l p + j 0 s d D W A x c O 5 9 z L v f c E C W d K O 8 6 n t Z J b X V v f y G 8 W t r Z 3 d o v 2 3 n 5 T x a k k t E F i H s t 2 A I p y J m h D M 8 1 p O 5 E U o o D T V j C 8 n P i t W y o V i 8 W N H i W 0 G 0 F f s J A R 0 E b y 7 e K Z B z w Z g F / x N I u o 8 u 2 S U 3 a m w M v E n Z N S L f f x / X b 4 R e u + / e 7 1 Y p J G V G j C Q a m O 6 y S 6 m 4 H U j H A 6 L n i p o g m Q I f R p x 1 A B Z k k 3 m x 4 + x i d G 6 e E w l q a E x l P 1 9 0 Q G k V K j K D C d E e i B W v Q m 4 n 9 e J 9 X h R T d j I k k 1 F W S 2 K E w 5 1 j G e p I B 7 T F K i + c g Q I J K Z W z E Z g A S i T V Y F E 4 K 7 + P I y a V b K b r V c v X Z L N Q f N k E d H 6 B i d I h e d o x q 6 Q n X U Q A S l 6 B 4 9 o i f r z n q w n q 2 X W e u K N Z 8 5 Q H 9 g v f 4 A 9 N e X B Q = = &lt; / l a t e x i t &gt; +↵2⇥ &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " / h I a t E S G x W 7 y 6 U S 6 A z 4 T Z b y H k 9 M = " &gt; A A A B 9 X i c b V D J S g N B E K 1 J X G L c o u L J S 2 M Q P I U Z D 9 F j w I v H C G a B z B h q O j 1 J k 5 6 F 7 h 4 l D P k P L x 4 U 8 e o 3 + A s e B E 9 + i n a W g 0 Y f F D z e q 6 K q n p 8 I r r R t f 1 i 5 / N L y y m p h r b i + s b m 1 X d r Z b a o 4 l Z Q 1 a C x i 2 f Z R M c E j 1 t B c C 9 Z O J M P Q F 6 z l D 8 8 n f u u G S c X j 6 E q P E u a F 2 I 9 4 w C l q I 1 2 7 K J I B d h 1 X 8 5 C p b q l s V + w p y F / i z E m 5 l n / / e t 3 / Z P V u 6 c 3 t x T Q N W a S p Q K U 6 j p 1 o L 0 O p O R V s X H R T x R K k Q + y z j q E R m i V e N r 1 6 T I 6 M 0 i N B L E 1 F m k z V n x M Z h k q N Q t 9 0 h q g H a t G b i P 9 5 n V Q H Z 1 7 G o y T V L K K z R U E q i I 7 J J A L S 4 5 J R L U a G I J X c 3 E r o A C V S b Y I q m h C c x Z f / k u Z J x a l W q p d O u W b D D A U 4 g E M 4 B g d O o Q Y X U I c G U J B w B w / w a N 1 a 9 9 a T 9 T x r z V n z m T 3 4 B e v l G x M U l p 4 = &lt; / l a t e x i t &gt; ↵1⇥ &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " / h I a t E S G x W 7 y 6 U S 6 A z 4 T Z b y H k 9 M = " &gt; A A A B 9 X i c b V D J S g N B E K 1 J X G L c o u L J S 2 M Q P I U Z D 9 F j w I v H C G a B z B h q O j 1 J k 5 6 F 7 h 4 l D P k P L x 4 U 8 e o 3 + A s e B E 9 + i n a W g 0 Y f F D z e q 6 K q n p 8 I r r R t f 1 i 5 / N L y y m p h r b i + s b m 1 X d r Z b a o 4 l Z Q 1 a C x i 2 f Z R M c E j 1 t B c C 9 Z O J M P Q F 6 z l D 8 8 n f u u G S c X j 6 E q P E u a F 2 I 9 4 w C l q I 1 2 7 K J I B d h 1 X 8 5 C p b q l s V + w p y F / i z E m 5 l n / / e t 3 / Z P V u 6 c 3 t x T Q N W a S p Q K U 6 j p 1 o L 0 O p O R V s X H R T x R K k Q + y z j q E R m i V e N r 1 6 T I 6 M 0 i N B L E 1 F m k z V n x M Z h k q N Q t 9 0 h q g H a t G b i P 9 5 n V Q H Z 1 7 G o y T V L K K z R U E q i I 7 J J A L S 4 5 J R L U a G I J X c 3 E r o A C V S b Y I q m h C c x Z f / k u Z J x a l W q p d O u W b D D A U 4 g E M 4 B g d O o Q Y X U I c G U J B w B w / w a N 1 a 9 9 a T 9 T x r z V n z m T 3 4 B e v l G x M U l p 4 = &lt; / l a t e x i t &gt;</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>↵1⇥</head><p>Replaced with a mixture of the learned vectors Singular value fine-tuning is a key building block in Transformer 2 . It offers an extremely efficient parameterization for fine-tuning and provides inherent compositionality for adaptation. Conventional fine-tuning techniques often aim to augment pre-trained models with new capabilities by modifying their weight matrices. However, in large-scale transformers, these weights are already rich repositories of abstracted knowledge, thanks to the breadth of the pre-training data and expansive architectural design. In fact, as evidenced in much of the prior literature, the requisite capabilities for solving many downstream tasks appear to already exist within these pre-trained models <ref type="bibr" target="#b28">(Sharma et al., 2023)</ref>. Therefore, instead of seeking to add new features, an efficient fine-tuning approach should focus on making these latent capabilities more expressible. Motivated by these considera-Preprint tions, for any weight matrix W , SVF learns a simple vector z ∈ R r that provides targeted modifications to each singular component of W independently, yielding a new weight matrix W ′ = U Σ ′ V ⊺ , where Σ ′ = Σ ⊗ diag(z). This essential parameterization enjoys several benefits:</p><p>Negligible parameters: Learning only a vector z for each weight matrix allows for very efficient fine-tuning with orders of magnitudes fewer optimized parameters even when compared to prior approaches specifically designed for efficiency. For example, the widely popular LoRA approach requires (m+n)×r ′ learnable parameters per weight matrix, where r ′ is a hyper-parameter that generally needs to be set large enough for expressivity. While recent extensions, such LoRA-XS <ref type="bibr" target="#b2">(Bałazy et al., 2024)</ref>, try to push efficiency even further, they often introduce limiting assumptions that curb applicability in several practical scenarios (see examples in Appendix C). In contrast, while SVF only needs r = min(m, n) parameters, we show it empirically does not display the same shortcomings thanks to working on a highly-meaning space provided by the latent expressiveness compressed in the weights of modern LLMs. SVF's scaling only the singular values may seem to lead to limited expressiveness, we wish to point out that the ability to affect the weight matrix in a full-rank manner technically provides more information than low-rank approaches.</p><p>High compositionality: Decomposing the weights in independent singular components makes the learned z vectors highly composable and interpretable, opening numerous possibilities for adaptation via algebraic manipulations. Instead, LoRA-based methods inherently lack these properties. For instance, even if two LoRAs learned on the same task were to learn exactly the same adjustments for each W , directly interpolating between their compressed A and B matrices is unlikely to preserve any of their original behavior, given the countless number of equivalent parameter permutations they might have converged to.</p><p>Principled regularization: Exclusively modifying the magnitude of pre-existing singular components provides a principled and effective form of regularization. In practice, this property enables us to fine-tune for arbitrary downstream tasks with only hundreds of data points without the risk of severe collapse or overfitting.</p><p>End-to-end optimization with RL. We train a set of SVF vectors θ z = {z 1 , • • • , z N ×M } to finetune an arbitrary language model π θ W parameterized by θ W with RL, optimizing directly for task performance. Here, θ W = {W 1 , • • • , W N ×M } is the set of weight matrices, where N is the number of layers and M is the number of weight matrices to fine-tune per layer. We use the seminal <ref type="bibr">RE-INFORCE algorithm (Williams, 1992)</ref> and label each generated answer y i (for the prompt x i ∈ D) with a unitary reward based on its correctness r ∈ {-1, 1}. Inspired by related applications of RL for optimizing LLMs <ref type="bibr" target="#b24">(Ouyang et al., 2022)</ref>, we regularize the REINFORCE objective by adding a KL penalty for deviating from the original model's behavior, weighted by a small coefficient λ ∈ R + . Thus, our final objective function can be written as:</p><formula xml:id="formula_7">J(θ z ) = E log π θ W ′ (ŷ i | x i ) r(ŷ i , y i ) -λD KL (π θ W ′ ∥π θ W ),<label>(1)</label></formula><p>where we use π θ W ′ to denote the resulting language model after substituting the original weight matrices W with W ′ . While RL is generally considered less stable than next-token prediction objectives, we find the regularization properties of SVF avoid many of the failure modes of prior lessconstrained parameterizations (see Section 4.3). Thus, combining these complementary components effectively enables us to avoid relying on expensive fine-tuning procedures with large hand-designed datasets as proxies, and directly maximize task performance end-to-end.</p><p>In general, SVF with RL puts lower requirement on the dataset it trains on. For example, LoRA fine-tuning requires "explaining texts" to perform next token predictions, which puts a higher requirement on the dataset (e.g., imagine LoRA fine-tuning on a GSM8K dataset where no reasoning text but only the final number is provided). This benefit allows SVF to be more general and effective. One possible caveat SVF can face is the sparse rewards caused by a weak base model, which we discuss this further in Section 5.</p><p>Self-adaptation is a critical mechanism in nature that has established itself as a core guiding principle in modern system design <ref type="bibr" target="#b17">(Klös et al., 2015)</ref>. Our initial efforts toward self-adaptive foundation models focus on the inference stage of LLMs, where we devise a simple two-pass adaptation strategy that combines K sets of base "expert" vectors z 1:K trained with SVF to provide different kinds of capabilities <ref type="bibr">(e.g., coding, math, etc)</ref>. The mapping between a capability and the dataset we train on can be acquired in the dataset's meta data. In the first inference pass, given a task or an individual input prompt, Transformer 2 executes the model and observes its test-time behavior to derive a new z ′ vector tailored to its test-time conditions. This adapted z ′ is then used in the second inference pass to provide an actual response with the newly adapted weights. The interaction between SVF-trained expert vectors and the adaptation strategies ensures seamless integration, where expert vectors provide modular capabilities, and the adaptation strategies dynamically determine and compose the most suitable combination to address the input task. In this first work, we propose three simple approaches to produce the vector z ′ during the first inference pass, implementing selfadaption with distinct methods and requirements. Below, we provide an outline of each method and refer to Appendix A for additional implementation details.</p><p>A) Prompt engineering: Our most basic approach involves constructing a new "adaptation" prompt which we use to directly ask the LLM to categorize the input prompt. Based on its response, we then extract one category out of the set of domain topics used to pre-train each SVF expert and, thus, we select the corresponding z ′ directly from z 1:K . In our adaptation prompt, we also explicitly provide the option for a generic "others" category, allowing the model to use its base weights in case no expert provides appropriate capabilities. We show the format used to construct the adaptation prompt in Figure <ref type="figure" target="#fig_4">3</ref>.</p><p>Analyze the given question and classify it into one of four categories: 'code', 'math', 'reasoning', or 'others'. Follow these guidelines:</p><p>1. Code: Questions asking for programming solutions... 2. Math: Questions involving mathematical calculations... 3. Reasoning: Questions requiring logical thinking.... 4. Others: Questions not clearly fit into above categories...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instructions:</head><p>-Consider the primary focus, skills, and knowledge required to answer the question.</p><p>-If a question spans multiple categories, choose the most dominant one.</p><p>-Provide your final classification within \\boxed{} notation. Example: \ \boxed{reasoning} Format your response as follows: Classification: \\boxed{category} B) Classification expert: A direct extension of the prompt engineering approach comes from using a specialized system to handle task identification. Following the principles of self-adaptation, we apply SVF to fine-tune the base LLM itself to handle this task. In particular, we collect a dataset</p><formula xml:id="formula_8">D = {(x 1,1 , 1), • • • , (x i,k , k), • • • } from the K SVF training tasks</formula><p>, where x i,k is the i-th example from the k-th expert task. Each tuple (x i,k , k) then forms an example to pre-train an additional job classification expert z c learned in the same fashion as the others. During the first inference pass, we simply load z c , intending to improve the inherent task classification capabilities of the base model to select a more appropriate z ′ to handle the input prompt.</p><p>C) Few-shot adaptation: Our third approach leverages additional task information by assuming extended access to its test-time conditions beyond individual prompts. Our approach is inspired by popular few-shot prompting techniques, which have been shown to provide consistent performance improvements and even allow LLMs to "in-context" learn tasks that were entirely unseen prior to inference <ref type="bibr" target="#b16">(Brown, 2020)</ref>. For each optimized W , our approach entails producing an entirely new z ′ = K k=1 α k z k by linearly interpolating between the K learned SVF vectors, each weighted by the coefficients α k . We employ CEM to search over the possible values of each α k based on the performance on a set of "few-shot prompts", which are specifically held out from the rest of the test prompts and used to evaluate CEM's population samples. In the case of multiple population samples obtaining the same score on these held-out prompts, we break ties by favoring the one with the highest average log-likelihood across its own generated correct answers. Crucially, we only need to perform this process once for each target task, avoiding the need to increase the length of each question prompt, a relevant downside of traditional few-shot prompting. We refer to Section A.4, for additional details and an extended discussion of this final approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>We extensively evaluate Transformer 2 on multiple tasks and models with the purpose of: (1) assessing the efficiency and effectiveness of SVF; (2) demonstrating self-adaptiveness through the three proposed adaptation strategies; (3) conducting in-depth analysis and ablation studies aimed at understanding and interpreting the properties of our new framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">EXPERIMENTAL SETUPS</head><p>To validate the generality of Transformer 2 we consider three pre-trained LLMs ranging across different model families and architecture sizes: LLAMA3-8B-INSTRUCT, MISTRAL-7B-INSTRUCT-V0.3, and LLAMA3-70B-INSTRUCT. For each model, we obtain three sets of SVF-trained z vectors to maximize performance for GSM8K <ref type="bibr" target="#b7">(Cobbe et al., 2021)</ref>, MBPP-pro <ref type="bibr" target="#b1">(Austin et al., 2021)</ref>, In our experiments, we update the parameters at the end of each epoch.</p><p>and ARC-Easy <ref type="bibr" target="#b6">(Clark et al., 2018)</ref>, respectively. Additionally, we also train a set of z vectors for LLAMA3-8B-INSTRUCT, when applied as the language backbone for TextVQA <ref type="bibr" target="#b29">(Singh et al., 2019)</ref>, in order to assess SVF's applicability to the vision-language modeling (VLM) domain. We provide SVF's main learning curves on each of these tasks in Figure <ref type="figure" target="#fig_5">4</ref>. Finally, we evaluate the full Transformer 2 adaptation framework on four unseen tasks: MATH <ref type="bibr" target="#b12">(Hendrycks et al., 2021)</ref>, Humaneval <ref type="bibr" target="#b5">(Chen et al., 2021)</ref>, ARC-Challenge <ref type="bibr" target="#b6">(Clark et al., 2018)</ref>, and OKVQA <ref type="bibr" target="#b23">(Marino et al., 2019)</ref>. In all our adaptation experiments, we only consider experts obtained in the pure-language settings, assessing its test-time applicability even for the distinctive vision domain. Please refer to the Appendix A for additional details and a summary of the hyper-parameters used in the experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">EXPERIMENTAL RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SVF performance</head><p>We provide results after training on each considered task with the LLAMA3-8B-INSTRUCT, MISTRAL-7B-INSTRUCT-V0.3, and LLAMA3-70B-INSTRUCT base models in Table 1. Remarkably, we find that SVF provides considerable and consistent performance gains across nearly all tasks and base models. Instead, LoRA experts yield smaller gains and even sporadic performance degradation. (These LoRA experts are trained with next token prediction. While we also have LoRA experts trained with RL in Table <ref type="table" target="#tab_3">4</ref>, RL seems work less well with LoRA than with SVF.) This observed trend extends also to the vision-language domain, as fine-tuning LLAMA3-LLAVA-NEXT-8B with SVF bolsters the base model's performance by over 39% (see Figure <ref type="figure">5</ref>). To ensure a fair comparison, we provide extensive ablations to both our model and the LoRA baseline considering different architecture and optimization objectives in Appendix 4.3). Due to its essential parameterization, we would like to note that training SVF requires considerably fewer resources, with less than 10% of the training parameters of our LoRA implementation.</p><p>Adaptation performance With the SVF trained z vectors, we assess the self-adaptation capability of Transformer 2 on unseen tasks. For a fair comparison with LoRA, we record the performance of this baseline using all checkpoints from the considered training tasks and report only its highest performance for each of the test tasks. As shown in ARC-Challenge task and still significantly deteriorate performance on both MATH and Humaneval. This discrepancy suggests that LoRA's parameterization and optimization might be particularly sensitive to overfitting, especially when trained with the smaller GSM8K and MBPP-Pro datasets, the tasks that provide information most related to MATH and Humaneval. In Figure <ref type="figure">5</ref>, we find a similar dichotomy in the OKVQA task, with the performance of the base LLAMA3-LLAVA-NEXT-8B VLM only improving after applying Transformer 2 . We note that also in this setting, Transformer 2 performs self-adaptation only from the expert vectors from GSM8K, MBPP-Pro, and ARC-Easy. Thus, this result further underscores the high flexibility of self-adaptation, transferring knowledge compressed for tasks entirely based on language even for unrelated vision-based problems.</p><p>Comparing the three proposed adaptation strategies, we highlight a clear monotonic trend -with more involved strategies and additional information about the test-time condition, self-adaptation appears to be increasingly effective. In particular, Transformer 2 with few-shot self-adaptation is almost always the highest-scoring method, providing notable improvements across all tested settings except for LLAMA3-70B-INSTRUCT @MATH, where we have only SVF-tuned half of the layers due to our limited GPU resources. This trend shows that providing additional or different kinds of information seems to be highly beneficial to our framework, suggesting that Transformer 2 could provide foundation models with new means to continually improve performance when deployed in lifelong settings. Table <ref type="table" target="#tab_2">3</ref> reports the inference time required by the prompt adaptation strategy of Transformer 2 , with the time spent on solving the entire problem set presented separately for the 1st and 2nd passes. Notice that the 2nd pass inference time is the time spent on solving the problems, and the 1st pass inference time is the time for self-adaptation, 1st to 2nd pass inference time ratios are in the parentheses. While the additional inference pass might appear to double the overall runtime, it is important to note that inference time primarily depends on the number of tokens generated. In our settings, it is O(n) where n is the length of the input. ARC-challenge's cost ratio is large because they are single choice problems and therefore the cost of the 2nd pass is also O(n). In general settings, we think it is reasonable to assume this ratio to be closer to those of MATH and Humaneval. For a detailed discussion on improving the efficiency of CEM few-shot adaptation methods, please see Appendix D</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">ANALYSIS</head><p>Lastly, we analyze and discuss the properties of our adaptation strategies for which we provide extensions and further discussion Appendix B.</p><p>Analysis 1: Job dispatching accuracy In Figure <ref type="figure">6</ref> we provide the confusion matrices of our classification-based adaptation strategies. These results validate the effectiveness of both our classification-based adaptation strategies to match each prompt with experts trained in similar domains, as evidenced by the high values along the diagonals. Furthermore, the results from LLAMA3-Figure <ref type="figure">6</ref>: Confusion matrices. These matrices display the classification percentages, where rows represent the task classes (ground truth) and columns indicate the predicted categories. Some samples are misclassified as "Others," which is reflected in rows where the totals do not sum to one. 8B-INSTRUCT and MISTRAL-7B-INSTRUCT-V0.3 also show that using the classification expert consistently provides higher classification accuracy than vanilla prompt engineering. While this difference could explain the higher performance of the relative self-adaptation strategy, we also note that domain similarity might not be the only metric relevant to identifying the best expert for each prompt or task. To this end, we believe many further unexplored extensions could be explored in future work, using heuristics such as past expert performance or token-level analysis to further push our framework's scalability.</p><p>Analysis 2: Training tasks adaptation contribution In Figure <ref type="figure" target="#fig_6">7</ref>, we show the normalized adaptive coefficients a k interpolating between our SVF vectors learned via CEM for LLAMA3-8B-INSTRUCT and MISTRAL-7B-INSTRUCT-V0.3 across all the unseen downstream tasks. Intuitively, we find that the expert vectors from the training tasks sharing similar topics to the unseen ones are often the highest contributors to the produced adaptive weights. However, we observe that the MATH task appears as an interesting exception, as the a k for the expert obtained from GSM8K training is actually the lowest out of the three in both models. We hypothesize this reflects the different nature of the mathematics competition problems from MATH as compared to the grade-school problems in GSM8K. In fact, not only is the difficulty of the MATH questions far beyond GSM8K, but a large portion of its problems also hinges mainly on logical reasoning, for which a task like ARC might actually be more aligned. Furthermore, we also note that the different z vectors appear to contribute more uniformly to adaptation in the Llama model. This difference might indicate that, due to its higher base performance, the Llama model does not need to rely on any particular set of skills as much as Mistral, and can harness more holistic benefits from self-adaptation. Note that applying a k uniformly is not a universal solution for leveraging expert vectors. This becomes evident when we look at different model and task combinations (e.g. applying a k uniformly on LLAMA3-8B-INSTRUCT for MATH tasks only achieves 24.47, while Transformer 2 (Few-shot) achieves 25.47).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis 3: Ablation studies</head><p>Module sensitivity: We first compare the performance of SVF when it is applied to different modules (see trials 1-3). Under consistent conditions, both individual MLP and attention updates improve performance, with MLP updates resulting in more pronounced gains. Simultaneous updates to both module types yield even more significant enhancements.</p><p>Objective function: We are interested in the performance impact from different objective functions, and we compare the RL objective with next-token prediction loss (see trials 2 and 4). For the latter, we use instruction fine-tuning with official GSM8K solutions as target tokens. Results show clear performance gains with RL, demonstrating its effectiveness in task-specific fine-tuning. Conversely, next-token prediction even hinders performance. This highlights RL's ability to handle cases lacking detailed solutions, suggesting its superiority in this context.</p><p>SVF vs LoRA: Finally, we also evaluate LoRA using the RL objective (see trials 2 and 5). A significant performance disparity is observed, primarily attributed to the severe instability of the LoRA training process. Despite exploring a wide range of learning rates, LoRA's performance consistently lagged behind. For further illustrations, see Figure <ref type="figure">9</ref> in the appendix.</p><p>Analysis 4: Cross-model compatibility Finally, we explore the potential for our self-adaptation framework to be applied across different LLMs. In particular, we evaluate whether the SVF expert vectors trained on LLAMA3-8B-INSTRUCT can benefit MISTRAL-7B-INSTRUCT-V0.3, and whether we can perform adaptation across the expert vectors of these two models. We present our main findings in Table <ref type="table" target="#tab_4">5</ref> and refer to Appendix B for additional detailed results. Surprisingly, we find that positive transfer occurs across the two models, with visible benefits in 2 out of 3 tasks. We   This operation leads to notable performance degradation across each task. Finally, by performing few-shot adaptation using the SVF vectors collected from both models, the performance of MISTRAL-7B-INSTRUCT-V0.3 further improves across the board. We observe that these gains even surpass the best score from adapting MISTRAL-7B-INSTRUCT-V0.3 with all the SVF vectors in the ARC-Challenge task reported in Table <ref type="table" target="#tab_1">2</ref>. While these results appear promising, we note that the surprising compatibility discovered through our naive transfer approach is potentially tied to the similarity between the architectures of the two considered LLMs. To this end, whether similar transfer can be replicated with models of different scales remains an open research question that could open the doors to disentangling and recycling task-specific skills for newer/larger models, with important implications for democratization and sustainability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this paper, we introduced Transformer 2 , providing a novel blueprint toward realizing self-adaptive LLMs. Within this framework, we first proposed SVF, offering superior performance than prior finetuning recipes, together with reduced costs, high compositionality, and overfitting regularizationall crucial properties to achieve scalable self-adaptation. Leveraging a set of SVF experts as building blocks, we developed three effective strategies for self-adaptation, each offering unique benefits and monotonic performance benefits with increasing access to the test-time conditions. While Transformer 2 demonstrates promising results, there remain exciting opportunities for future work. One limitation is that the capabilities of SVF experts are tied to the latent components of the base model. To address this, model merging offers a promising direction <ref type="bibr" target="#b33">(Yu et al., 2024;</ref><ref type="bibr" target="#b11">Goddard et al., 2024;</ref><ref type="bibr" target="#b0">Akiba et al., 2024)</ref>, enabling specialized models to be combined into a single, more capable model. Additionally, while our CEM-based adaptation effectively balances performance and efficiency, scaling to a large number of specialized domains may introduce increased one-time computational costs. However, this trade-off is offset by the benefits of improved performance and enhanced self-adaptation capabilities. Advances in model merging and efficient adaptation techniques have produced models dominating open leaderboards, making them strong candidates as base models for Transformer 2 and opening new possibilities for adaptive LLMs. 2 × 10 -4 , 5 × 10 -4 , 2 × 10 -5 , 5 × 10 -5 , 2 × 10 -6 . 5 × 10 -6 , Clip max norm 1 × 10 -3 , 1.0  We investigate the relationship between the number of samples available for fewshot adaptation and downstream performance. Our analysis focused on the test task where LLAMA3-8B-INSTRUCT demonstrates the highest baseline performance, to prevent the potential for a null signal in our CEM-based search.</p><p>As Table <ref type="table" target="#tab_7">8</ref> shows, substantial benefits of our few-shot strategy are evident with as few as 3 to 5 test samples. Moreover, performance appears to plateau beyond 10 samples, underscoring how our essential and inherently regularized SVF pa-</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><figDesc>r S x K r e d b M 4 p O F P Z y + D O I X f 5 M a 5 8 P x y P y 5 3 s Z 6 s b 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><figDesc>r S x K r e d b M 4 p O F P Z y + D O I X f 5 M a 5 8 P x y P y 5 3 s Z 6 s b 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><figDesc>r b d Z a c q a 9 x z C H 1 n v P 2 Z p k Q g = &lt; / l a t e x i t &gt;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Method overview. Left) At training time, we employ SVF and RL to learn the "expert" vectors z's that scale the singular values of the weight matrices. Right) At inference time, we propose three distinct methods to adaptively select/combine the learned expert vectors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Prompt based adaptation. Selfadaptation prompt used by Transformer 2 to classify the task prompt into pre-defined categories.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: SVF learning curves. The dashed lines indicate the performance of LLAMA3-8B-INSTRUCT on the test split of each task. SVF effectively fine-tunes to surpass the base performance. While we use the best validation score to select our checkpoint for evaluation (marked by red dots), we present the entire training curve without early stopping to demonstrate SVF's learning capabilities. Tasks with only hundreds of training samples like Coding and Reasoning were stopped early.In our experiments, we update the parameters at the end of each epoch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: α k learned weights.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Table2, all of our Transformer 2 adaptation strategies demonstrate improvements across all tasks for LLAMA3-8B-INSTRUCT base models, and in at least two out of three tasks for both MISTRAL-7B-INSTRUCT-V0.3 and LLAMA3-70B-INSTRUCT. In contrast, even the best training LoRAs only provide marginal improvements on the Fine-tuning results. LLM performance on the test splits of math, coding and reasoning. Normalized scores are in the parentheses.</figDesc><table><row><cell>Method</cell><cell>GSM8K</cell><cell>MBPP-Pro</cell><cell>ARC-Easy</cell><cell>50</cell><cell></cell><cell>Llama3-8B LoRA SVF/Transformer 2</cell></row><row><cell>LLAMA3-8B-INSTRUCT</cell><cell>75.89 (1.00)</cell><cell>64.65 (1.00)</cell><cell>88.59 (1.00)</cell><cell>45</cell><cell></cell></row><row><cell>+ LoRA</cell><cell>77.18 (1.02)</cell><cell>67.68 (1.05)</cell><cell>88.97 (1.00)</cell><cell></cell><cell></cell></row><row><cell>+ SVF (Ours)</cell><cell>79.15 (1.04)</cell><cell>66.67 (1.03)</cell><cell>89.56 (1.01)</cell><cell>40</cell><cell></cell></row><row><cell cols="2">MISTRAL-7B-INSTRUCT-V0.3 42.83 (1.00) + LoRA 44.66 (1.04)</cell><cell>49.50 (1.00) 51.52 (1.04)</cell><cell>81.65 (1.00) 81.19 (0.98)</cell><cell>35</cell><cell></cell></row><row><cell>+ SVF (Ours)</cell><cell>49.74 (1.16)</cell><cell>51.52 (1.04)</cell><cell>85.14 (1.04)</cell><cell></cell><cell></cell></row><row><cell>LLAMA3-70B-INSTRUCT</cell><cell cols="3">85.29 (1.00) 80.81 (1.00) 89.10 (1.00)</cell><cell>30</cell><cell>TextVQA</cell><cell>OKVQA</cell></row><row><cell>+ LoRA + SVF (Ours)</cell><cell cols="3">77.26 (0.91) 68.69 (0.85) 88.55 (0.99) 88.32 (1.04) 80.81 (1.00) 88.47 (0.99)</cell><cell cols="3">Figure 5: Results for the VLM domain.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Self-adaptation on unseen tasks. Normalized scores are in the parentheses.</figDesc><table><row><cell>Method</cell><cell>MATH</cell><cell>Humaneval</cell><cell>ARC-Challenge</cell></row><row><cell>LLAMA3-8B-INSTRUCT 3</cell><cell cols="3">24.54 (1.00) 60.98 (1.00) 80.63 (1.00)</cell></row><row><cell>+ LoRA</cell><cell cols="3">24.12 (0.98) 52.44 (0.86) 81.06 (1.01)</cell></row><row><cell>+ Transformer 2 (Prompt)</cell><cell cols="3">25.22 (1.03) 61.59 (1.01) 81.74 (1.01)</cell></row><row><cell>+ Transformer 2 (Cls-expert)</cell><cell cols="3">25.18 (1.03) 62.80 (1.03) 81.37 (1.01)</cell></row><row><cell>+ Transformer 2 (Few-shot)</cell><cell cols="3">25.47 (1.04) 62.99 (1.03) 82.61 (1.02)</cell></row><row><cell cols="4">MISTRAL-7B-INSTRUCT-V0.3 13.02 (1.00) 43.29 (1.00) 71.76 (1.00)</cell></row><row><cell>+ LoRA</cell><cell cols="3">13.16 (1.01) 37.80 (0.87) 75.77 (1.06)</cell></row><row><cell>+ Transformer 2 (Prompt)</cell><cell cols="3">11.86 (0.91) 43.90 (1.01) 72.35 (1.01)</cell></row><row><cell>+ Transformer 2 (Cls-expert)</cell><cell cols="3">11.60 (0.89) 43.90 (1.01) 74.83 (1.04)</cell></row><row><cell>+ Transformer 2 (Few-shot)</cell><cell cols="3">13.39 (1.03) 47.40 (1.09) 75.47 (1.05)</cell></row><row><cell>LLAMA3-70B-INSTRUCT</cell><cell cols="3">40.64 (1.00) 78.66 (1.00) 87.63 (1.00)</cell></row><row><cell>+ LoRA</cell><cell cols="3">25.40 (0.62) 73.78 (0.94) 83.70 (0.96)</cell></row><row><cell>+ Transformer 2 (Prompt)</cell><cell cols="3">40.44 (1.00) 79.88 (1.02) 88.48 (1.01)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Time</figDesc><table><row><cell></cell><cell cols="2">cost of 2-pass</cell></row><row><cell cols="3">inference in prompt adaptation strategy of Transformer 2 for the</cell></row><row><cell cols="3">entire problem set. 1st to 2nd pass</cell></row><row><cell cols="3">inference time ratios are shown in</cell></row><row><cell>parentheses.</cell><cell></cell><cell></cell></row><row><cell>Task</cell><cell cols="2">1st (s) 2nd (s)</cell></row><row><cell>MATH</cell><cell>42.64 (13%)</cell><cell>321.19</cell></row><row><cell>Humaneval</cell><cell>2.76 (19%)</cell><cell>14.28</cell></row><row><cell cols="2">ARC-Challenge 13.40 (47%)</cell><cell>28.51</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Ablation studies. We fine-tune LLAMA3-8B-INSTRUCT on the GSM8K training split with different settings and the results on the test split along with zero-shot transfer results on MATH.</figDesc><table><row><cell cols="3"># Method Objective Function Module</cell><cell cols="3">#Params (↓) GSM8K (↑) MATH (↑)</cell></row><row><cell>0</cell><cell cols="2">LLAMA-3-8B-INSTRUCT</cell><cell></cell><cell>75.89 (1.00)</cell><cell>24.54 (1.00)</cell></row><row><cell>1 SVF</cell><cell>Policy gradient</cell><cell>MLP</cell><cell>0.39M</cell><cell>78.62 (1.04)</cell><cell>24.20 (0.99)</cell></row><row><cell>2 SVF</cell><cell>Policy gradient</cell><cell>attention</cell><cell>0.16M</cell><cell>76.19 (1.00)</cell><cell>24.20 (0.99)</cell></row><row><cell>3 SVF</cell><cell>Policy gradient</cell><cell>MLP + attention</cell><cell>0.58M</cell><cell>79.23 (1.04)</cell><cell>25.04 (1.04)</cell></row><row><cell>4 SVF</cell><cell>Next token pred</cell><cell>attention</cell><cell>0.16M</cell><cell>60.50 (0.80)</cell><cell>18.52 (0.75)</cell></row><row><cell>5 LoRA</cell><cell>Policy gradient</cell><cell>attention</cell><cell>6.82M</cell><cell>57.92 (0.76)</cell><cell>15.72 (0.64)</cell></row><row><cell>6 LoRA</cell><cell>Next token pred</cell><cell>attention</cell><cell>6.82M</cell><cell>77.18 (0.98)</cell><cell>24.12 (0.96)</cell></row><row><cell>7 LoRA</cell><cell>Next token pred</cell><cell>MLP + attention</cell><cell>35.13M</cell><cell>75.66 (0.96)</cell><cell>22.12 (0.91)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Cross-model z vector transfer. Results from transferring the expert vectors trained on LLAMA3-8B-INSTRUCT to MISTRAL-7B-INSTRUCT-V0.3 with cross model few-shot adaptation. Llama SVF (ordered σ i ) 11.96 (0.92) 45.12 (1.04) 72.01 (1.00) + Llama SVF (shuffled σ i ) 10.52 (0.81) 40.24 (0.93) 70.82 (0.99) + Few-shot adaptation (cross-model) 12.65 (0.97) 46.75 (1.08) 75.64 (1.05)note these improvements are due to the inherent ordering of the SVF parameterization, as randomly shuffling each SVF vector before applying it to the Mistral model consistently degrades performance.</figDesc><table><row><cell>Method</cell><cell>MATH</cell><cell cols="5">Humaneval ARC-Challenge</cell></row><row><cell>SVF training task</cell><cell>GSM8K</cell><cell>MBPP-pro</cell><cell></cell><cell></cell><cell></cell><cell>ARC-Easy</cell></row><row><cell>MISTRAL-7B-INSTRUCT-V0.3</cell><cell cols="3">13.02 (1.00) 43.29 (1.00)</cell><cell></cell><cell></cell><cell>71.76 (1.00)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Llama3-8B</cell><cell>Mistral-7B</cell></row><row><cell></cell><cell></cell><cell>GSM8K</cell><cell cols="3">25.8%</cell><cell>GSM8K</cell><cell>31.1%</cell><cell>32.8%</cell><cell>Arc Easy</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>MATH</cell><cell>48.0%</cell><cell>Arc Easy</cell><cell>MATH</cell></row><row><cell></cell><cell></cell><cell>MBPP</cell><cell cols="3">26.2%</cell><cell>36.2%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>MBPP</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Arc Easy</cell><cell>Arc Easy</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">33.7%</cell><cell>GSM8K</cell><cell>33.3%</cell><cell>2.6%</cell></row><row><cell></cell><cell></cell><cell cols="3">GSM8K 31.2%</cell><cell>HumanEval</cell><cell>HumanEval</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>64.1%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>35.1%</cell><cell>MBPP</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">MBPP</cell></row><row><cell></cell><cell></cell><cell cols="2">GSM8K</cell><cell cols="2">19.3%</cell><cell>MBPP</cell><cell>GSM8K 5.4% 7.1%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Arc Challenge</cell><cell>50.7%</cell><cell>Arc Easy</cell><cell>Arc Challenge</cell></row><row><cell></cell><cell></cell><cell cols="3">30.0%</cell><cell></cell></row><row><cell></cell><cell></cell><cell>MBPP</cell><cell></cell><cell></cell><cell></cell><cell>87.5%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Arc Easy</cell></row></table><note><p>+</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Hyper-parameters used for SVF and LoRA training. We perform a sweep on certain sensitive hyper-parameters across methods for fair comparison.</figDesc><table><row><cell></cell><cell>SVF Hyperparameters</cell></row><row><cell>Initial mean value of z</cell><cell>0.1</cell></row><row><cell cols="2">Initial variance value of z 1 × 10 -3 Global batch size 256</cell></row><row><cell>Learning rate Clip max norm KL coefficient λ</cell><cell>2 × 10 -3 1 × 10 -3 0.0, 0.1, 0.2, 0.3</cell></row><row><cell></cell><cell>LoRA Hyperparameters</cell></row><row><cell>Rank</cell><cell>16</cell></row><row><cell>LoRA alpha</cell><cell>32</cell></row><row><cell>LoRA dropout</cell><cell>0.05</cell></row><row><cell>Global batch size</cell><cell>256</cell></row><row><cell>Learning rate</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Additional Comparison Experiment. Normalized scores are in the parentheses. (Cls-expert) 25.18 (1.03) 62.80 (1.03) 81.37 (1.01) + Transformer 2 (Few-shot) 25.47 (1.04) 62.99 (1.03) 82.61 (1.02) B ADDITIONAL RESULTS B.1 BASELINE COMPARISON TO MORE PEFT METHODS We conduct additional comparison studies against more parameter-efficient fine-tuning methods, including IA3Liu et al. (2022), DORA. Liu et al. (2024).As Table7shows, SVF still outperforms other methods and shows promising generalized performance.B.2 IMPACT FROM NUMBER OF FEW-SHOTS</figDesc><table><row><cell>Method</cell><cell>GSM8K</cell><cell>MBPP-Pro</cell><cell>ARC-Easy</cell></row><row><cell>LLAMA3-8B-INSTRUCT</cell><cell cols="3">75.89 (1.00) 64.65 (1.00) 88.59 (1.00)</cell></row><row><cell>+ IA3</cell><cell cols="3">78.01 (1.03) 67.68 (1.05) 89.10 (1.01)</cell></row><row><cell>+ DORA</cell><cell cols="3">78.09 (1.03) 64.65 (1.00) 89.14 (1.01)</cell></row><row><cell>+ SVF(Ours)</cell><cell cols="3">79.15 (1.04) 66.67 (1.03) 89.56 (1.01)</cell></row><row><cell>Method</cell><cell>MATH</cell><cell>Humaneval</cell><cell>ARC-Challenge</cell></row><row><cell>LLAMA3-8B-INSTRUCT</cell><cell cols="3">24.54 (1.00) 60.98 (1.00) 80.63 (1.00)</cell></row><row><cell>+ IA3</cell><cell cols="3">23.64 (0.96) 59.76 (0.98) 81.57 (1.01)</cell></row><row><cell>+ DORA</cell><cell cols="3">24.44 (0.99) 52.44 (0.86) 81.14 (1.01)</cell></row><row><cell>+ Transformer 2 (Prompt)</cell><cell cols="3">25.22 (1.03) 61.59 (1.01) 81.74 (1.01)</cell></row><row><cell>+ Transformer 2</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 :</head><label>8</label><figDesc>Few-shot adaptation scaling on the Arc-Challenge task. Performance varies with number of examples.</figDesc><table><row><cell>Method</cell><cell cols="3">Transformer 2 IA 3 100 steps IA 3 1000 steps</cell></row><row><cell>LLAMA3-8B-INSTRUCT</cell><cell>80.63 (1.00)</cell><cell>80.63 (1.00)</cell><cell>80.63 (1.00)</cell></row><row><cell>+ 3-shot adaptation</cell><cell>82.18 (1.02)</cell><cell>81.83 (1.01)</cell><cell>79.01 (0.98)</cell></row><row><cell>+ 5-shot adaptation</cell><cell>82.38 (1.02)</cell><cell>80.89 (1.00)</cell><cell>79.41 (0.98)</cell></row><row><cell>+ 10-shot adaptation</cell><cell>82.61 (1.02)</cell><cell>82.00 (1.02)</cell><cell>79.78 (0.99)</cell></row><row><cell>+ 20-shot adaptation</cell><cell>82.61 (1.02)</cell><cell>81.40 (1.01)</cell><cell>79.61 (0.99)</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6">AUTHOR CONTRIBUTIONS</head><p><rs type="person">Yujin Tang</rs> initiated the project. <rs type="person">Qi Sun</rs> proposed the prompted-based method, developed the evaluation framework, conducted the experiments, and provided contributions to writing. Edoardo Cetin designed the few-shot CEM adaptation strategy, performed the experiment, and made major contributions to manuscript writing. <rs type="person">Yujin Tang</rs> proposed the core algorithm, conducted initial experiments, made major contributions to the manuscript, and managed the project.</p></div>
			</div>
			<div type="funding">
<div><p>N 1 v d t u D D j / v 4 W 8 G h 3 E J B e D V K d H 4 = " &gt; A A A B 9 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X Y C t 4 K o l I 9 W b B i 8 c K 9 g P a W D b b a b t 0 s 4 m 7 m 0 I J / R 2 i e F D E q 3 f / h j f / j Z u 2 B 2 1 9 M P B 4 b 4 a Z e X 7 E m d K O 8 2 0 t L a + s r q 1 n N r K b W 9 s 7 u 7 m 9 / Z o K Y 0 m x S k M e y o Z P F H I m s K q Z 5 t i I J J L A 5 1 j 3 B 1 e p X x + i</p><p>K c i a o q 5 n m t B 1 L i k O f 0 5 Y / u s n y 1 i O V i k X i Q Y 9 j 6 o V 4 I F j A C N b G u i + 7 5 V 6 x Z F f s m d A q O A s o X X 9 O M 7 0 1 e s W v b j 8 i S U i F J h w r 1 X H s W H s p l p o R T i e F b q J o j M k I D 2 j H o M A h V V 4 6 G 3 W C z o z T R 0 E k z R M a z d z f H S k O l R q H v q k M s R 6 q 5 S w z / 8 s 6 i Q 6 u v <rs type="person">J S J O N F U k P l H Q c K R</rs> j l C 2 N + o z S Y n m <rs type="person">Y w O Y S G Z m R W S I J S</rs> b a X K d g j u A s r 7 w K z Y u K U</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A IMPLEMENTATION DETAILS AND HYPER-PARAMETERS A.1 SVF TRAINING</head><p>We obtain the expert vectors z as the base components in Transformer 2 by training the SVF finetunes with a consistent recipe across the considered training tasks and language models. We divide each dataset to produce equal-sized training and validation splits. We then apply our RL-based approach, optimizing θ z with AdamW using a learning rate of 2 × 10 -3 with cosine decay, a batch size of 256, and gradient clipping. We employ early stopping and select the best λ (the coefficient of the KL divergence term) based on validation performance. For the LLAMA3-70B-INSTRUCT and Vision tasks experiments, we apply the SVF on half of the layers to reduce memory usage while maintaining considerable performance improvement. During the training of LLAMA3-8B-INSTRUCT on the vision language tasks, we apply a small negative reward (-0.1) for training stability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 LORA TRAINING</head><p>Below is an instruction that describes a task. Write response that appropriately completes the request.</p><p>Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May? Natalia sold = &lt;&lt;48/2=24&gt;&gt;24 in May. Natalia sold 48+24 = &lt;&lt;48+24=72&gt;&gt;72 clips altogether in April and May. #### 72 We follow community best practices for LoRA fine-tuning, applying it to query and value projection layers with learning rates around 5 × 10 -5 . We set 200 total iterations with a 256 global batch size for sufficient training. For feasible LoRA instruction training, we collect solutions for all training tasks (GSM8K, MBPP, Arc-Easy, TextVQA) from official sources and append them to question prompts. Table <ref type="table">8</ref> shows a sample math problem used for LoRA fine-tuning. Despite extensive hyperparameter tuning, we often observe test performance decay as discussed, which can be attributed to the small number of training samples and potential model requirements for instruction fine-tuning data (specifically, the highly detailed thinking process).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 HYPER PARAMETERS</head><p>We present a summary of the hyperparameters used in our experiments in Table <ref type="table">6</ref>. To optimize performance, we conducted sweeps across several hyperparameters and selected the most effective combination based on validation results. For SVF, our primary focus was on adjusting the KL coefficient to enhance training stability. In the case of LoRA, we concentrated on sweeping the learning rate and maximum gradient clip norm to identify optimal settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 FEW-SHOT ADAPTATION</head><p>As described in the main text, our few-shot adaptation approach entails producing an entirely new z ′ = K k=1 α k z k for each W by linearly interpolating between the K learned SVF vectors, each weighted by the coefficients α ∈ R K . We employ CEM to search for α k 's based on the performance on the few-shot prompts, which are specifically held out from the rest of the test prompts and used to obtain the elite set at each iteration. In the case of multiple sample solutions obtaining the same score on these held-out samples, we break ties by choosing the sample solution with the highest average log-likelihood across the tokens of its generated correct answers.</p><p>In all of our main experiments, we reserve only 10 samples of data for self-adaptation and perform up to 100 CEM iterations. For each setting, we consider both per-layer and per-vector adaptation, where the latter strategy has the advantage of greatly simplifying search (as we only have 3 α coefficients). Moreover, we experiment with both normalizing across the α of different tasks (such that their sum would be fixed to 1) or keeping them unconstrained. Due to the lack of a validation set, we simply report the performance attained by our best sample from these test configurations at the end of optimization, on the remaining unseen samples for each task.</p><p>Preprint rameterization effectively complements self-adaptation. This efficiency enables optimal use of data to enhance understanding of the test task.</p><p>For completeness, we have also conducted experiments with identical settings on IA 3 <ref type="bibr" target="#b20">(Liu et al., 2022)</ref>, another method that leverages few-shot examples. All experiments were conducted with full batch size, a learning rate of 5 × 10 -5 , with 100 and 1000 training steps.</p><p>Our results indicate that the performance of IA 3 on the unseen test tasks is inferior to CEM-based adaptation for all numbers of few shots considered. We note that in our experiment, we have to considerably limit the number of optimization steps to avoid overfitting the 500,000 parameters of IA 3 on the few-shot samples. However, we believe overfitting might still be occurring to some degree even after only 100 steps, as also validated by the model's perfect training accuracy on this extremely small dataset. This limitation of fine-tuning-based adaptation highlights the superior generalization capability of our CEM-based adaptation approach in Transformer 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 CROSS-MODEL SVF TRANSFER ON THE TRAINING TASKS</head><p>We provide complementary results to Table <ref type="table">5</ref> in the main text, where we analyze the SVF crossmodel transfer performance from training on GSM8K, MBPP-pro, and ARC-Easy to our considered test tasks. In Table <ref type="table">9</ref>, we show the results in the same transfer setting this time evaluating MISTRAL-7B-INSTRUCT-V0.3 on the same training tasks where the LLAMA3-8B-INSTRUCT SVF vectors were obtained from. Overall, we recognize a similar trend, albeit with less consistent improvement from the original model (only in 1 out of 3 tasks), but still much higher performance than the randomly shuffled baseline. These results further confirm that the canonical ordering of the SVF parameterization is key for cross-model transfer, highlighting once more its inherent suitability to empower self-adaptation.  Here, σ's are the ordered (from largest to smallest) singular values on the weight matrix W . It is easy to see from the figures that when r = 256, less than 50% of the variance is captured by these top components on average. For the MLP layers, this fraction is even lower than 20%. On the other hand, the ranks adopted by LoRA-XS or similar methods are much less than 256, resulting in even more information loss and restrictions in their modeling power that relies mostly on these r components.  Our CEM-based adaptation method involves running inference on a small number of samples for each target task (up to 10 in our experiments). In a typical configuration, this process is relatively efficient: for example, our CEM-light approach (3-shot with 10 generations) completes the ARC-Challenge task in approximately 11 minutes. As shown in Table <ref type="table">10</ref>, this lighter setup reduces the total number of samples to just 3% of the original setting while still delivering substantial performance improvements over the base model. We acknowledge that CEM-based adaptation entails a trade-off between one-time overhead it spends on searching the optimal combination weights for the SVF-tune vectors and performance. Increasing the number of few-shot samples or the number of generations can yield higher performance, but this comes at the cost of additional computational overhead. However, it is important to note that this adaptation cost is a one-time overhead per task. The cost-per-prompt diminishes significantly when applied to tasks with a large number of prompts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D EFFICIENCY CONSIDERATIONS AND IMPROVEMENTS</head><p>Moreover, in practical scenarios, CEM-based adaptation offers better scalability than few-shot prompting methods, which require increasing the length of every prompt, leading to much worse scaling as task sizes grow. In contrast, our method focuses on determining optimal expert vector combinations efficiently and avoids repetitive inference-time costs. However, we note that the overhead might be significant for tasks with very few prompts. Thus, the other adaptations methods might be more appropriate for these particular settings.</p><p>We also highlight two immediate directions for improving efficiency:</p><p>1. Reducing the number of few-shot samples: As shown in our ablation study in Appendix B.2, substantial benefits can be seen even in the 3-shot setting, which requires only evaluation of only 30% of the number of prompts per generation.</p><p>2. Reducing the number of maximum generations: In the explored settings, the CEM parameters tend to converge early on, being very close to the final values after a much lower number of generations than 100.</p><p>Finally, in this work we only considered CEM due to its simplicity, there exist several different evolution algorithms empirically showing better efficiency and convergence properties that we hope will be explored in future research.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Takuya</forename><surname>Akiba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Makoto</forename><surname>Shing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujin</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Ha</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.13187</idno>
		<title level="m">Evolutionary optimization of model merging recipes</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Program synthesis with large language models</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henryk</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carrie</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Terry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.07732</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Lora-xs: Low-rank adaptation with extremely small number of parameters</title>
		<author>
			<persName><forename type="first">Klaudia</forename><surname>Bałazy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammadreza</forename><surname>Banaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><surname>Aberer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacek</forename><surname>Tabor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.17604</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tom</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.14165</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Fine-tuning llms with singular value decomposition. Hugging Face Blog</title>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Cetoli</surname></persName>
		</author>
		<ptr target="https://huggingface.co/blog/fractalego/svd-training.Ac-cessed" />
		<imprint>
			<date type="published" when="2024-06">June 2024</date>
			<biblScope unit="page" from="2024" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiming</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henrique</forename><surname>Ponde De Oliveira Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harri</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuri</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Brockman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.03374</idno>
		<title level="m">Evaluating large language models trained on code</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isaac</forename><surname>Cowhey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carissa</forename><surname>Schoenick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05457</idno>
		<title level="m">Think you have solved question answering? try arc, the ai2 reasoning challenge</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Training verifiers to solve math word problems</title>
		<author>
			<persName><forename type="first">Karl</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Plappert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reiichiro</forename><surname>Nakano</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.14168</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Brain network adaptability across task states</title>
		<author>
			<persName><forename type="first">Kimberly</forename><forename type="middle">J</forename><surname>Elizabeth N Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danielle</forename><forename type="middle">S</forename><surname>Schlesinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mary-Ellen</forename><surname>Bassett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">B</forename><surname>Lynall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><forename type="middle">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><forename type="middle">M</forename><surname>Grafton</surname></persName>
		</author>
		<author>
			<persName><surname>Carlson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1004029</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Improving factuality and reasoning in language models through multiagent debate</title>
		<author>
			<persName><forename type="first">Yilun</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Mordatch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14325</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity</title>
		<author>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">120</biblScope>
			<biblScope unit="page" from="1" to="39" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Arcee&apos;s mergekit: A toolkit for merging large language models</title>
		<author>
			<persName><forename type="first">Charles</forename><surname>Goddard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shamane</forename><surname>Siriwardhana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Malikeh</forename><surname>Ehghaghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Meyers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vlad</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Benedict</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Mcquade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Solawetz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.13257</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Measuring mathematical problem solving with the math dataset</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Collin</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurav</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akul</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.03874</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Edward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yelong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeyuan</forename><surname>Wallis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhi</forename><surname>Allen-Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shean</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Lora</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.09685</idno>
		<title level="m">Low-rank adaptation of large language models</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Albert Q Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Roux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Blanche</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Savary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devendra</forename><surname>Bamford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>Singh Chaplot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emma</forename><forename type="middle">Bou</forename><surname>De Las Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Hanna</surname></persName>
		</author>
		<author>
			<persName><surname>Bressand</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.04088</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">Mixtral of experts. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Self-moe: Towards compositional large language models with self-specialized experts</title>
		<author>
			<persName><forename type="first">Junmo</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonid</forename><surname>Karlinsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyin</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rameswar</forename><surname>Panda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rogerio</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.12034</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.08361</idno>
		<title level="m">Scaling laws for neural language models</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Adaptive knowledge bases in self-adaptive system design</title>
		<author>
			<persName><forename type="first">Verena</forename><surname>Klös</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Göthel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabine</forename><surname>Glesner</surname></persName>
		</author>
		<idno type="DOI">10.1109/SEAA.2015.48</idno>
	</analytic>
	<monogr>
		<title level="m">2015 41st Euromicro Conference on Software Engineering and Advanced Applications</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="472" to="478" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Jan</forename><surname>Dawid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tijmen</forename><surname>Kopiczko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuki</forename><forename type="middle">Markus</forename><surname>Blankevoort</surname></persName>
		</author>
		<author>
			<persName><surname>Asano</surname></persName>
		</author>
		<author>
			<persName><surname>Vera</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.11454</idno>
		<title level="m">Vector-based random matrix adaptation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Svft: Parameter-efficient fine-tuning with singular vectors</title>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Lingam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atula</forename><surname>Tejaswi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Vavre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aneesh</forename><surname>Shetty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishna</forename><surname>Gautham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joydeep</forename><surname>Gudur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunsol</forename><surname>Dimakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandar</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sujay</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName><surname>Sanghavi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.19597</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning</title>
		<author>
			<persName><forename type="first">Haokun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammed</forename><surname>Muqeeth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Mohta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tenghao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1950" to="1965" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">Shih-Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chien-Yi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxu</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pavlo</forename><surname>Molchanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu-Chiang Frank</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kwang-Ting</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min-Hung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Dora</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.09353</idno>
		<title level="m">Weight-decomposed low-rank adaptation</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Switch-independent task representations in frontal and parietal cortex</title>
		<author>
			<persName><forename type="first">David</forename><surname>Lasse S Loose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Wisniewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Rusconi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John-Dylan</forename><surname>Goschke</surname></persName>
		</author>
		<author>
			<persName><surname>Haynes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">33</biblScope>
			<biblScope unit="page" from="8033" to="8042" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Ok-vqa: A visual question answering benchmark requiring external knowledge</title>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Marino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Rastegari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roozbeh</forename><surname>Mottaghi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/cvf conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/cvf conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3195" to="3204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Training language models to follow instructions with human feedback</title>
		<author>
			<persName><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diogo</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carroll</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katarina</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="27730" to="27744" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Qwen1.5-moe: Matching 7b model performance with 1/3 activated parameters</title>
		<author>
			<persName><forename type="first">Qwen</forename><surname>Team</surname></persName>
		</author>
		<ptr target="https://qwenlm.github.io/blog/qwen-moe/.Blogpost" />
		<imprint>
			<date type="published" when="2024-03">March 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deepspeed-moe: Advancing mixture-of-experts inference and training to power next-generation ai scale</title>
		<author>
			<persName><forename type="first">Samyam</forename><surname>Rajbhandari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Conglong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhewei</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minjia</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reza</forename><surname>Yazdani Aminabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ammar</forename><surname>Ahmad Awan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Rasley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiong</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="18332" to="18346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">The cross-entropy method: a unified approach to combinatorial optimization, Monte-Carlo simulation, and machine learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Reuven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><forename type="middle">P</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName><surname>Kroese</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">133</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">The truth is in there: Improving reasoning in language models with layer-selective rank reduction</title>
		<author>
			<persName><forename type="first">Pratyusha</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><forename type="middle">T</forename><surname>Ash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipendra</forename><surname>Misra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.13558</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Towards vqa models that can read</title>
		<author>
			<persName><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vivek</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meet</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="8317" to="8326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Mixture-of-experts in the era of llms: A new odyssey</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Preprint</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Tianlong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhang</forename><surname>Beidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bansal</forename><surname>Minjia</surname></persName>
		</author>
		<author>
			<persName><surname>Mohit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML 2024 presentation slides, 2024. International Conference on Machine Learning (ICML)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Harnessing minor singular components for parameter-efficient llm finetuning</title>
		<author>
			<persName><forename type="first">Hanqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeguan</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guanhua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Milora</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.09044</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName><forename type="first">Williams</forename><surname>Ronald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Language models are super mario: Absorbing abilities from homologous models as a free lunch</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haiyang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongbin</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Forty-first International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Proagent: building proactive cooperative agents with large language models</title>
		<author>
			<persName><forename type="first">Ceyao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaijie</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siyi</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guanghe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yihang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaowei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anji</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="17591" to="17599" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">Qingru</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minshuo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Bukharin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikos</forename><surname>Karampatziakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tuo</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.10512</idno>
		<title level="m">Adalora: Adaptive budget allocation for parameterefficient fine-tuning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">Tong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoye</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daize</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiacheng</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingqi</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Conghui</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.16554</idno>
		<title level="m">Llama-moe: Building mixture-of-experts from llama with continual pre-training</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">Mingchen</forename><surname>Zhuge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haozhe</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Faccio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dylan</forename><forename type="middle">R</forename><surname>Ashley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Róbert</forename><surname>Csordás</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdullah</forename><surname>Hamdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abed</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kader</forename><surname>Al</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Hammoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kazuki</forename><surname>Herrmann</surname></persName>
		</author>
		<author>
			<persName><surname>Irie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.17066</idno>
		<title level="m">Mindstorms in natural language-based societies of mind</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
