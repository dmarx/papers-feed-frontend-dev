# Group Network Hawkes Process

## Abstract

## 

In this work, we study the event occurrences of individuals interacting in a network. To characterize the dynamic interactions among the individuals, we propose a group network Hawkes process (GNHP) model whose network structure is observed and fixed. In particular, we introduce a latent group structure among individuals to account for the heterogeneous user-specific characteristics. A maximum likelihood approach is proposed to simultaneously cluster individuals in the network and estimate model parameters. A fast EM algorithm is subsequently developed by utilizing the branching representation of the proposed GNHP model. Theoretical properties of the resulting estimators of group memberships and model parameters are investigated under both settings when the number of latent groups G is over-specified or correctly specified. A data-driven criterion that can consistently identify the true G under mild conditions is derived. Extensive simulation studies and an application to a data set collected from Sina Weibo are used to illustrate the effectiveness of the proposed methodology.

## INTRODUCTION

Point process models have gained increasing popularity for modeling activities observed on various networks, examples include posting activities in online social networks, corporation transactions in a financial network, and neuron spikes in a brain network. The main goal of this work is to develop a new modeling framework for random event times observed on a network consisting of heterogeneous nodes. While the proposed framework is applicable for the analysis of general event time data, we describe our model in the context of a motivating dataset collected from Sina Weibo (the largest Twitter type social media platform in mainland China).

The dataset contains posting times of 2,038 Sina Weibo users from January 1st to January 15th, 2014. Figure [1](#fig_0) shows that user posting patterns be highly heterogeneous and complex.

Firstly, the distribution of user post counts reveals great variability in users' activities levels: while most users had less than 200 posts during the study period, a small portion of users were much more active. Secondly, the averaged overall intensity of posting times aggregated over all users demonstrates the existence of apparent daily periodic patterns. Lastly, quantiles of gap times between a user's posting time and the closest posting time from his/her connected friends and randomly picked non-friends are drastically different. In particular, the quantiles of gap times among friends are consistently smaller than those among the non-friends, suggesting that a user's activities were heavily influenced by his/her friends. A popular model for event time data such as our motivating example is the multivariate Hawkes process [(Hawkes, 1971)](#b12), which has been widely used to model event times of multiple types in a variety of fields, such as criminology [(Linderman and Adams, 2014)](#b14), finance [(Bacry et al., 2013)](#b3), information diffusion [(Farajtabar et al., 2017)](#b7), and social studies [(Zhou et al., 2013;](#b30)[Fox et al., 2016)](#b9). In the network setting, the first line of existing research aims at recovering the unknown network structure using the observed event time data, see, e.g., [Zhou et al. (2013)](#b30); [Xu et al. (2016)](#b25); [Achab et al. (2018)](#b0); [Bacry et al. (2020)](#b2). In contrast, another line of research takes the network structure as given knowledge and incorporates it into the modeling of the event time data, examples include [Fox et al. (2016)](#b9); [Farajtabar et al. (2017)](#b7) and [Zarezade et al. (2018)](#b27). In the second framework, model parameters were assumed to be node-specific, and therefore the number of parameters grows at least linearly with the number of nodes. This may be problematic if many nodes in the network produce only scarce event times, which was observed in Figure [1](#fig_0). Section 2.4 gives a more detailed comparison between the proposed model and existing works.

In this work, we propose a group network Hawkes process (GNHP) to model the network heterogeneity by introducing a latent group structure among the network nodes. We assume that nodes in the same group share similar node-wise characteristics and that interaction patterns between any two connected nodes are determined by their group memberships. For each latent group, the background intensity varies over time and is nonparametrically approximated by spline basis functions. The proposed model is more parsimonious than existing models where all network nodes are considered as different (e.g., [Fox et al., 2016;](#b9)[Farajtabar et al., 2017;](#b7)[Zarezade et al., 2018)](#b27), but the latent group structure coupled with the observed network structure still allows us to build sufficiently flexible multivariate Hawkes process network models. Furthermore, the proposed GNHP model admits an equivalent branching process structure that enables us to develop easily interpretable numerical measures to quantify interactions within the network, see Section 2.3 for more details. The branching structure also allows us to develop a computationally efficient EM algorithm for model estimation, see Section 3.3. Lastly, the estimated group memberships cluster network nodes into several subgroups in a data-driven manner, offering further insights into the network activity dynamics. Therefore, the proposed GNHP model is an important addition to the existing toolbox for analyzing event time data observed on a network.

Our work also makes important theoretical contributions to the literature. The estimation of the (multivariate) Hawkes process is most commonly conducted through the maximum likelihood estimation [(Ogata, 1988;](#)[Mohler et al., 2011;](#b17)[Chen and Hall, 2013;](#b5)[Zhou et al., 2013)](#b30).

While [Ogata (1978)](#b18) and [Chen and Hall (2013)](#b5) studied the asymptotic property of the maximum likelihood estimator (MLE) for a univariate Hawkes process, to the best of our knowledge, however, little is known about the limiting behaviors of the MLE for a high-dimensional multivariate Hawkes process such as the proposed GNHP. In this work, we establish the consistency results for the MLE of the model parameters and the latent group memberships for the GNHP, with the number of groups being possibly over-specified. When the number of groups is correctly specified, we establish the asymptotic normality of the MLE. Finally, we show that a likelihood-based information criterion (LIC) can consistently select the number of groups. A similar theoretical framework has been considered in the panel data literature [(Su et al., 2016;](#b22)[Liu et al., 2020;](#b15)[Zhu et al., 2022)](#b34), although the treatments of point process data and panel data are very different. In this sense, our work also bridges a gap between the point process and the panel data literature.

The rest of the article is organized as follows. In Section 2, we introduce the GNHP model together with its branching structure representation and compare the proposed model to existing works. In Section 3, we detail our estimation procedure, including the computationally efficient EM algorithm. Theoretical properties of resulting estimators are investigated in Section 4. Simulation results under different network settings are presented in Section 5. In Section 6, we apply the proposed model to the Sina Weibo dataset. The article is concluded with a brief discussion in Section 7. Additional simulation resulats and all technical details are left to online supplementary material.

## GROUP NETWORK HAWKES PROCESS

## Background on Hawkes Process

Denote by 0 ≤ t 1 ≤ t 2 ≤ . . . ≤ t n ≤ T a realization of a temporal point process in [0, T ] and let N (t) = n k=1 I(t k < t) be the associated counting process, where I(•) is an indicator function.

Let H t = {t k : t k < t} be the process history up to time t, and the conditional intensity function of a point process is defined as

$λ(t|H t ) = lim ∆→0 ∆ -1 E [N (t + ∆) -N (t)|H t ].$The classical Hawkes process model [(Hawkes, 1971)](#b12) assumes that λ(t|H t ) takes the form

$λ(t|H t ) = µ + t k ∈Ht f (t -t k ),(1)$where µ > 0 is a background rate of events and f (•) is a non-negative triggering function. The Hawkes process is considered as "self-exciting" since the past events in H t contribute to the instantaneous intensity λ(t|H t ) at time t through f (•). The triggering function controls the dependence range and strength between the intensity at time t and the past events, and popular choices include the exponential kernel [(Hawkes, 1971](#b12)) and the power-law kernel [(Ogata, 1988)](#).

$Notations. For a vector v = (v 1 , • • • , v p ) ⊤ ∈ R p , let ∥v∥ 2 = ( p i=1 v 2 i ) 1/2 and ∥v∥ ∞ = max j |v j | denote the L 2 -norm and the infinity norm of v, respectively. For a function h(t) ∈ R 1 with t ∈ [0, T ], define ∥h(•)∥ T = {T -1 T 0 h(t) 2 dt} 1/2 and ∥h(•)∥ ∞ = sup t∈[0,T ] |h(t)|. For a matrix H = (h ij ) ∈ R m×n , define the row norm ∥H∥ ∞ = max i ( j |h ij |) and L 1 norm ∥H∥ 1 = i ( j |h ij |). For any set S, define S n = {v = (v 1 , • • • , v n ) ⊤ : v i ∈ S} as collection of vectors of length n, whose elements are in S. Finally, we denote [G] = {1, • • • , G} and 1 = (1, • • • , 1) ⊤ .$
## Network Hawkes Process with Latent Group Structures

In this section, we extend the classical Hawkes process to the network setting with a latent group structure. Consider a network with m nodes, where the relationships among the nodes are represented by an adjacency matrix A = (a ij ) ∈ R m×m , with a ij = 1 if the ith node follows the jth node and a ij = 0 if otherwise. By convention, we do not allow self-connected nodes, i.e., a ii = 0. To account for potential heterogeneity of network nodes, we assume that the nodes in the network belong to G latent groups where nodes within the same group share the same node-specific characteristics and interactions with nodes from other groups.

$Denote G = (g 1 , • • • , g m ) ⊤ ∈ R m$as the latent group membership vector of all nodes, where

$g i ∈ [G] for i = 1, • • • , m. For node i, let 0 ≤ t i1 ≤ t i2 ≤ • • • ≤ t in i ≤ T be the observed n i$event times and N i (t) = n i k=1 I(t ik ≤ t) be the associated counting process. Given the group membership vector G and event history

$H t = ∪ m i=1 H i,t with H i,t = {t ik : t ik < t; 1 ≤ k ≤ n i }, the$proposed GNHP model assumes that the conditional intensity for the ith node is of the form

$λ i (t|G , H t ) = µ g i (t) + β g i t ik ∈H i,t f b (t -t ik ; η g i ) + m j=1 ϕ g i g j a ij d i t jl ∈H j,t f b (t -t jl ; γ g i ),(2)$for 1 ≤ i ≤ m, where µ g (•) is the background intensity, f b (•; η) is a triggering function governed by parameter η, d i = m j=1 a ij is the out-degree of node i [(Zhu et al., 2017)](#b32), and {β g , γ g , η g , ϕ gg ′ } are unknown group-level parameters for g, g ′ ∈ [G]. Following [Chen et al. (2017)](#b6), we assume the

$support of f b (t; γ) is [0, b]. For example, f b (•; γ) can be the truncated exponential kernel f b (t; γ) = γ [1 -exp(-bγ)] -1 exp(-γt)I(t ≤ b), for any t ≥ 0. (3$$)$Our theoretical investigation allows the truncation range b → ∞ as m, T → ∞. For identifiability of parameters β g 's and ϕ gg ′ 's, we assume that ∞ 0 f b (t; γ)dt = 1 for any given γ. In addition, we

$assume that ∥∂ k f b (•; γ)/∂γ k ∥ ∞ < ∞ for 1 ≤ k ≤ 3.$The proposed conditional intensity in (2) can be decomposed into the following three parts.

• Background intensity µ g i (t). This describes the overall activity pattern of the node i.

$• Momentum intensity β g i t ik ∈H i,t f b (t -t ik ; η g i ).$It models "self-exciting" influence of its own past events on the occurrence of a new event at t at the node i.

$• Network intensity d -1 i m j=1 ϕ g i g j a ij t jl ∈H j,t f b (t -t jl ; γ g i ).$This models influences from past events of other nodes on the occurrence of a new event at t at node i.

The out-degree d i is used to prevent the inflation of the Network Intensity when d i → ∞, which is commonly done in literature [(Zhu et al., 2017](#b32)[(Zhu et al., , 2019))](#b33). The ϕ g i g j 's in the Network Intensity represent the average network influences from the connected nodes on the ith node. Finally, we remark that the triggering functions in the Momentum Intensity and the Network Intensity do not necessarily share the same form.

The network dependence of the proposed GNHP can be characterized by the transition matrix

$B = (b ij ) ∈ R m×m , where b ij = ϕ g i g j d -1 i a ij + β g i I(i = j), for i, j = 1, • • • , m.$Detailed properties of B will be further explored in the next subsection based on the following assumption.

$Assumption 1. Assume ∥B∥ ∞ ≤ c B < 1, where c B is a positive constant.$Assumption 1 is a sufficient condition for stability of a multivariate Hawkes process and has been widely used in the literature, see, e.g., [Hansen et al. (2015)](#b11); [Chen et al. (2017)](#b6). In the next subsection, we show that for the GNHP model, it is a sufficient condition to ensure that the expected number of offspring events triggered by a parent event at any network node is finite.  parent events (blue circle) and two generations of offspring events; Right: a two-node network where Node 1 follows Node 2. Parent events from both nodes (blue circles), event times triggered by their own past events (purple circles), event times in Node 1 triggered by past events from Node 2 (green circles).

## Branching Structure of the GNHP Model

Following [Rasmussen (2013)](#b20) and [Halpin et al. (2013)](#b10), a branching structure representation can be derived for the GNHP by treating the aggregated point process from all nodes, denoted by N pool , as a marked point process on [0, T ], with the mark for any t ∈ N pool being the node index where the event occurs. Specifically, event times in N pool can be categorized into two types: the parent and offspring events. Let M parent i be the set of parent events from node i and

$M f am ik = M of f ik ∪ {t ik },$where M of f ik is the set of offspring events generated from a parent event t ik ∈ M parent i . Note that M f am ik may contain event times from other nodes due to the network interactions. The branching structure is defined as follows and illustrated in Figure 2. 1. For any 1 ≤ i ≤ m, the parent events M parent i follows a Poisson process with an intensity µ g i (t), and all Poisson processes are independent. 2. Each parent event t ik ∈ M parent i generates a set of offspring events M of f ik , and all resulting M f am ik 's are independent. Event times in each M f am ik are generated recursively as follows. (a) Generation 0, denoted as M gen 0 ik , consists of only t ik , i.e., M gen 0 ik = {t ik }. (b) Having generated offspring event times up to n generations, M gen 0 ik , • • • , M genn ik , each event time in M genn ik generates a series of event times of the n + 1 generation. Specifically, suppose t jl ∈ M genn ik is an event time located in the jth node, then on the time interval [t jl , T ], it generates (i) a Poisson process with intensity β g j f b (t -t jl ; η g j ) on the node j; and (ii) a Poisson process with intensity ϕ g

$i ′ g j d -1 i ′ f b (t -t jl ; γ g i ′ )$on the node i ′ for any i ′ ̸ = j where a i ′ j = 1. All Poisson processes are independent.

(c) Obtain

$M f am ik = ∪ ∞ n=0 M genn ik .$Theorem 1. Denote by # i (S) the total number of events occurring at a subset of network nodes S ⊂ {1, • • • , m} that are offspring events of a parent event originated from the ith node on [0, ∞).

Then under Assumption 1, one has that

$E [# i (S)] = e ⊤ S (I -B) -1 e i , for any 1 ≤ i ≤ m,(4)$where e S is a vector with 1 for entries whose indexes are in S and 0 elsewhere, and e i = e {i} .

The proof is given in the online supplement. Theorem 1 provides a useful tool to quantify the network interactions. Examples include

• Node-to-node influence: the (j, i)th entry of (I -B) -1 gives the average number of events at node j that are triggered by a parent event at the ith node (set S = {j}).

• Node-to-network influence: by setting S = {1, • • • , m}, we obtain the sum of the ith column of (I -B) -1 as the average number of events in the entire network that are directly/indirectly triggered by a parent event at the ith node, i.e., E{# i (S)} = E{|M f am ik |}.

• Dynamic Group-to-Group influence: Let S g be the collection of node indexes in group g. Denote #(S g , S g ′ , [t 1 , t 2 ]) as the total number of events from group g ′ triggered by parent events from group g occurring within [t 1 , t 2 ], which reflects the influential power of group g on group g ′ . Based on Theorem 1, it can be verified that

$E #(S g , S g ′ , [t 1 , t 2 ]) = e ⊤ S g ′ (I -B) -1 e Sg t 2$t 1 µ g (t)dt. We can subsequently define the limiting case as follows

$GIF gg ′ (t) = lim ∆→0 ∆ -1 E #(S g , S g ′ , [t, t + ∆]) = e ⊤ S g ′ (I -B) -1 e Sg µ g (t), t ∈ [0, T ],(5)$which is more convenient for graphical illustrations.

## Comparisons with Existing Literature

There has been much work on multivariate Hawkes process (e.g., [Zhou et al., 2013;](#b30)[Bacry et al., 2013;](#b3)[Chen et al., 2017)](#b6), and models for the conditional intensity can be generally expressed as

$λ i (t|G , H t ) = µ i + m j=1 t jl ∈H j,t ζ ij (t -t jl ), i = 1, • • • , m,(6)$where µ i is the background rate at node i and ζ ij (•) is some transfer function between node j and node i. Key differences among existing multivariate Hawkes process models center around

$constructions of ζ ij (•)'s. A popular modeling strategy is to assume that ζ ij (•) = θ ij f (•; γ), i, j = 1, • • • , m, with some parametric f (•; γ). Such a model involves a total of O(m 2 ) parameters,$limiting its suitability to applications with a relatively small m (e.g., [Bacry et al., 2013)](#b3). When modeling a large network, one needs to impose some sparse structure on θ ij 's, in which case a nonzero θ ij implies that node i is directly influenced by node j, and estimated θ ij 's may help recover the latent network structure (e.g., [Xu et al., 2016;](#b25)[Bacry et al., 2020)](#b2). While most work in this line lack rigorous theory, there has been some recent theoretical studies of such models when m is diverging, see, e.g., [Hansen et al. (2015)](#b11), [Chen et al. (2017)](#b6) and [Cai et al. (2020)](#b4).

There is also a large body of literature on the identification of network node clusters (e.g., [Zhao et al., 2012;](#b29)[Amini et al., 2013)](#b1), which is commonly referred to as "community detection". We remark that the concept of "community" in the community detection literature is fundamentally different from the "groups" in the proposed GNHP model. In community detection, the network adjacent matrix A is assumed to be a random matrix consisting of Bernoulli random variables, and the identification of node communities c critically depends on the conditional probability P (A|c). However, the adjacent matrix A in the GNHP is considered deterministic and there is no probability associated with it. In contrast, the groups in the GNHP are formed by maximizing the likelihood of event times collected from all network nodes, and nodes in the same group are forced to share similar node-specific characteristics such as µ g i (•)'s and β g i 's. Although some recent works in community detection literature utilize nodal features to help identify communities [(Yan and Sarkar, 2021;](#b26)[Zhang et al., 2021;](#b28)[Weng and Feng, 2022)](#b24), the central piece of these models remains to be P (A|c). The difference is most manifested in the extreme case when all nodes are isolated from each other (i.e., A consists of all 0's), while the GNHP is still valid by manually setting ϕ g i g j 's as 0, the community detection can no longer be performed since there is no network anymore. We note another recent work [Matias et al. (2018)](#b16) also considers latent group structures when extending the stochastic block model for recurrent interaction events in continuous time.

The key difference between their work and ours lies in that they require that each observed event time is associated with a label indicating this event is an interaction between which two nodes.

However, such information is not available in event times modeled by the GNHP, which instead focuses on modeling events that occur on individual nodes but may have some correlations. In fact, as suggested by the branching structure in Section 2.3, identifying the triggering source of an event in the GNHP is the most challenging task. Similarly, in the extreme case when there are only self-activities on each node but no interaction between any pair of nodes, [Matias et al. (2018)](#b16) is not applicable but the GNHP model remains valid with ϕ g i g j 's set to 0.

The second line of research focuses on analyzing the network activities through parameterizations utilizing a known network structure, (e.g., [Fox et al., 2016;](#b9)[Farajtabar et al., 2017;](#b7)[Zarezade et al., 2018)](#b27). For instance, [Fox et al. (2016)](#b9) models email communications in a network by assuming

$ζ ij (t) = θ i a ij γ i exp(-γ i t)$, where θ i 's and γ i 's are unknown parameters. As a result, the total number of unknown parameters is reduced to O(m). Similar but more complex models were studied in [Farajtabar et al. (2017)](#b7) and [Zarezade et al. (2018)](#b27).

Our proposed GNHP model falls into the second line of research with four distinct features: the latent group structure imposed on network nodes not only accounts for commonly observed network heterogeneity in a natural way but also effectively reduces the number of parameters.

(d) the estimated group memberships for network nodes may provide further insights on the network activities using various influence measures discussed in Section 2.3.

## MODEL ESTIMATION

## Background Intensity Approximation

As illustrated in Figure [1](#fig_0), human activities such as social media posting often exhibit periodic patterns. We, therefore, assume that the background intensity of a given node takes a periodic form, for which there exists a finite ω > 0 such that µ g

$(t) = µ g (t + lω), t ∈ [0, T -lω], l = 0, 1, 2, • • • , for any g ∈ [G].$For our motivating example, it is natural to choose ω = 1 day (or 24 hours) to account for daily posting behaviors. Without assuming a restrictive parametric form for µ g (•)'s, we approximate µ g (•) using periodic splines. Let

$k n kt (•) = (k 1 (•), • • • , k n kt (•)) ⊤$be a collection of basis functions defined on [0, ω] and

$x n kt (t) = √ n kt k n kt (t -⌊t/ω⌋ω) for any t ∈ [0, T ],$where ⌊a⌋ is the largest integer less than or equal to a, then µ g (•) is approximated by

$µ g (t) = w ⊤ g x n kt (t), t ∈ [0, T ],(7)$where w g , g ∈ [G], are the coefficient vectors that need to be estimated. For our theoretical investigation, we require the following assumption for the spline basis functions.

Assumption 2. Assume that there exists a constant R > 0 such that k

$1 (•), • • • , k n kt (•) satisfy: (a) ∥k j (•)∥ ∞ ≤ R and ω 0 |k j (t)|dt = O(n -1 kt ); (b) ω 0 |k j (t)k j+l (t)|dt = O(n -1 kt ), and k j (t)k j+l (t) = 0 for l > J and any t ∈ [0, ω],$where J ≥ 0 is a finite integer. Denote by µ 0 g (•) the true background function of group g, and assume that for some constant ν > 0, it holds that

$max 1≤g≤G inf wg∈R n kt ,∥wg∥∞≤R/ √ n kt µ 0 g (•) -w ⊤ g x n kt (•) ∞ = O(n -ν kt ). (8$$)$Assumption 2 requires that the true background intensity functions can be approximated sufficiently well by a linear combination of spline basis functions, which is mild for many spline families. In our numerical examples, we choose

$k 1 (•), • • • , k n kt (•)$as the rth-order B-spline basis functions with equally spaced knots on [0, ω], which meet Assumption 2 [(Zhou et al., 1998)](#b31).

## Maximum Likelihood Estimation

For any g ̸ = g ′ , denote W ⊂ R n kt , Θ ⊂ R +3 and Φ ⊂ R + as the parameter spaces for parameters in w g , θ g = (β g , η g , γ g ) ⊤ , and ϕ gg ′ 's, respectively. Here

$R + denotes [0, ∞). Denote by G ≡ [G] m$as the parameter space for the membership vector

$G = (g 1 , • • • , g m ) ⊤ .$For our theoretical investigation, we impose the following assumption on the parameter spaces.

$Assumption 3. There exist R > 0, C > 0 such that (a) sup w∈W ∥w∥ ∞ ≤ R/ √ n kt and inf w∈W inf t∈[0,T ] w ⊤ x n kt (t) ≥ C; (b) sup θ∈Θ ∥θ∥ ∞ ≤ R; and (c) sup ϕ∈Φ |ϕ| ≤ R. Let N i = {j : a ij = 1} be the set of d i neighboring nodes of node i, G i = (g j 1 , • • • , g j d i ) ⊤$be the corresponding group membership vector of all nodes in N i , and the re-scaled interaction

$parameter φ g i ,G i = d -1/2 i (ϕ g i g j 1 , • • • , ϕ g i g j d i ) ⊤ , i = 1, • • • , m. The term d -1/2 i in φ g i ,G i is convenient$for our theoretical study but is of no practical importance. We can see that the conditional intensity (2) of node i only depends on w ⊤ g i x n kt (•), θ g i and φ g i ,G i , and hence can be rewritten as [9](#))

$λ i (t|w g i , θ g i , φ g i ,G i , H t ) = w ⊤ g i x n kt (t) + β g i t ik ∈H i,t f b (t -t ik ; η g i ) + m j=1 a ij ϕ g i g j d i t jl ∈H j,t f b (t -t jl ; γ g i ), ($$for i = 1, • • • , m. Denote the parameter vectors w = (w ⊤ 1 , • • • , w ⊤ G ) ⊤ ∈ W G , θ = (θ ⊤ 1 , • • • , θ ⊤ G ) ⊤ ∈ Θ G , and ϕ = (ϕ 11 , • • • , ϕ 1G , ϕ 21 , • • • , ϕ G,G ) ⊤ ∈ Φ G 2 .$Consequently, the scaled log-likelihood function (divided by mT ) of the proposed GNHP can be shown to have the form

$ℓ(w , θ , ϕ , G |H T ) = 1 m m i=1 ℓ i (w g i , θ g i , φ g i ,G i |H T ), where(10)$$ℓ i (w g i , θ g i , φ g i ,G i |H T ) = 1 T n i k=1 log λ i (t ik |w g i , θ g i , φ g i ,G i , H t ik ) - T 0 λ i (t|w g i , θ g i , φ g i ,G i , H t )dt .$For ease of presentation, from now on, we denote ψ = (w ⊤ , θ ⊤ , ϕ ⊤ , G ⊤ ) ⊤ and the MLE of the parameters are then obtained by

$ψ ≡ w ⊤ , θ ⊤ , ϕ ⊤ , G ⊤ ⊤ = argmax w ,θ ,ϕ ,G ℓ w , θ , ϕ , G |H T , where G = ( g 1 , . . . , g m ) ⊤ . (11$$)$
## An EM Algorithm

Direct maximization of ( [10](#formula_37)) is a non-concave problem with a large number of parameters, which can be computationally challenging. In this subsection, we propose a more efficient algorithm by taking advantage of the branching structure given in Section 2.3.

For the kth event of node i that occurs at time t ik , define Z ik = (j, l), where j = l = 0 indicates a parent event, and otherwise means the kth event is triggered by the lth event from node j at time t jl . Given

$Z i = (Z i1 , • • • , Z in i ) ⊤ ,$event times of node i can be categorized as:

1. Parent events with Z ik = (0, 0), which constitute a realization of a Poisson process on [0, T ] with an intensity µ g i (•). The log-likelihood can then be written as

$ℓ (1) br,i (w g i |H T , Z i ) = n i k=1 I [Z ik = (0, 0)] log w ⊤ g i x n kt (t ik ) - T 0 w ⊤ g i x n kt (t) dt.(12)$2. All t ik 's triggered by a past event of node i, i.e., Z ik = (i, l) for some 1 ≤ l < k, which form a realization of a Poisson process on [t il , T ] with an intensity

$β g i f b (t -t il ; η g i ) for any t ∈ [t il , T ].$The joint log-likelihood of all such events is of the form

$ℓ (2) br,i (β g i , η g i |H T , Z i ) = n i -1 l=1 n i k=l+1 I [Z ik = (i, l)] log [β g i f b (t ik -t il ; η g i )] -β g i T t il f b (t -t il ; η g i )dt .(13)$3. All t ik 's triggered by a past event of a node j ∈ N i , i.e., Z ik = (j, l) for some 1 ≤ l < n j and j ∈ N i , which form a realization of a Poisson process on [t jl , T ] with an intensity

$d -1 i ϕ g i g j f b (t -t jl ; γ g i ) for any t ∈ [t jl , T ].$The joint log-likelihood of all such events becomes

$ℓ (3) br,i γ g i , φ g i ,G i |H T , Z i = j∈N i n j l=1 n i k=1 I [Z ik = (j, l)] log ϕ g i g j d i f b (t ik -t jl ; γ g i ) - ϕ g i g j d i T t jl f b (t -t jl ; γ g i )dt .(14)$Consequently, when

$Z = (Z ⊤ 1 , • • • , Z ⊤ m )$⊤ is observed, by the branching structure given in Section 2.3, the complete log-likelihood for the proposed GNHP is then of the form

$ℓ br ψ |H T , Z = m i=1 ℓ (1) br,i (w g i |H T , Z i ) + ℓ (2) br,i (β g i , η g i |H T , Z i ) + ℓ (3) br,i γ g i , φ g i ,G i |H T , Z i . (15$$)$The MLE (11) can then be obtained by an EM algorithm using the complete likelihood ( [15](#formula_48)

## Selection of Number of Groups

Denote the true number of latent groups as G 0 . Theorems 2-4 in Section 4 suggest that under suitable conditions the MLE of model parameters are consistent for their theoretical counterparts and all node memberships can be correctly estimated as long as G ≥ G 0 . However, according to Theorem 5, the asymptotic normality of θ and ϕ depends on the assumption that G = G 0 .

Therefore, it is of practical interest to develop a data-driven criterion to determine G 0 .

With a slight abuse of notation, we denote w (G) , θ

$(G) , ϕ (G)$, G (G) as the MLE obtained in (11)

for a given G. We consider the following likelihood based criterion function,

$LIC(G) = ℓ w (G) , θ (G) , ϕ (G) , G (G) |H T -λ mT G,(16)$where ℓ(•|H T ) is as defined in (10) and λ mT > 0 is a tuning parameter depending on m and T . The optimal G is selected by G = arg max G LIC(G). If λ mT satisfies the rate condition in Theorem 3, then under suitable conditions, one can select G = G 0 with probability tending to 1.

## THEORETICAL PROPERTIES

We now investigate the asymptotic properties of the MLE (11). Denote µ 0 g (•) as the true background intensity of group g and µ

$* g (•) = w * ⊤ g x n kt (•) as the best spline approximation to µ 0 g (•) with w * g = argmin w∈W ∥w ⊤ x n kt (•) -µ 0 g (•)∥ ∞ , g ∈ [G]. By Assumption 2, one has that max 1≤g≤G ∥µ * g (•) -µ 0 g (•)∥ ∞ = O(n -ν kt ). (17$$) Denote β 0 g , γ 0 g , ϕ 0 gg ′ as the true values of β g , γ g , ϕ gg ′ respectively, for g ′ ̸ = g, g, g ′ ∈ [G]. Let G 0 = (g 0 1 , • • • , g 0 m )$⊤ be the true membership vector, where g 0 i ∈ [G 0 ]. Note that G and G 0 may be different in our theoretical framework. Correspondingly, θ 0 , ϕ 0 , G 0 i , and φ 0

$g 0 i ,G 0 i , i = 1, • • • , m,$are defined by replacing parameters with the true values in their definitions.

## Technical Assumptions

$Denote ψ = (w ⊤ , θ ⊤ , ϕ ⊤ , G ⊤ ) ⊤ and define the function ℓ(ψ ) = E[ℓ(ψ |H T )], which is of the form ℓ(ψ ) = 1 m m i=1 ℓ i (w g i , θ g i , φ g i ,G i ), and ℓ i (w g i , θ g i , φ g i ,G i ) = E ℓ i (w g i , θ g i , φ g i ,G i |H T ) . (18$$)$Denote by

$ψ i = (w ⊤ , θ ⊤ , φ ⊤ i ) ⊤ , ψ * i = w * ⊤ g 0 i , θ 0⊤ g 0 i , φ 0⊤ g 0 i ,G 0 i ⊤$, and a parameter space

$Ω i = {ψ i ∈ W × Θ × Φ i } with Φ i = {ϕ/ √ d i : ϕ ∈ Φ} d i .$To establish the parameter estimation consistency, we require the following assumptions.

Assumption 4. There exist a sequence τ m > 0 and a constant C 1 > 0 such that for sufficiently large T , it holds that inf

$ψ i ∈Ω i ℓ i (ψ * i ) -ℓ i (ψ i ) ≥ min{ ∥ψ * i -ψ i ∥ 2 τm , C 1 } for any i = 1, • • • , m.$Assumption 5. The functions ℓ i (w, θ, φ i )'s are Lipschitz continuous in the sense that there exist

$a constant M > 0 such that sup 1≤i≤m sup w,w ′ ∈W,θ,θ ′ ∈Θ,φ i ,φ ′ i ∈Φ i |ℓi(w,θ,φ i )-ℓ i (w ′ ,θ ′ ,φ ′ i )| ∥w-w ′ ∥ 2 +∥θ-θ ′ ∥ 2 +∥φ i -φ ′ i ∥ 2 ≤ M . Assumption 6. There exists a c 0 > 0 such that inf g̸ =g ′ ∈[G 0 ] w * g -w * g ′ + θ 0 g -θ 0 g ′ > c 0 . Assumption 7. Define π g,m = 1 m m i=1 I(g 0 i = g) and π gg ′ ,m = 1 m m i=1 1 d i j∈N i I(g 0 i = g, g 0 j = g ′ ), g, g ′ ∈ [G 0 ].$Assume that as m → ∞, π g,m → π g and π gg ′ ,m → π gg ′ and that there exists a con-

$stant c π > 0 such that min g,g ′ ∈[G 0 ] min{π g , π gg ′ } ≥ c π .$Assumption 4 is a condition to ensure the identifiability of model parameters, which essentially requires two things: (1) ψ * i is a global maximizer ℓ i (ψ i ), and ℓ i (ψ * i ) is at least C 1 greater than the function values at other local maximizers;

(2) ℓ i (ψ i ) is locally concave in a neighborhood of ψ * i , where it holds that λ min (-li (ψ i )) ≥ 2τ -1 m with li (•) being the negative hessian matrix of ℓ i (•). To see the second part, note that a second order Taylor expansion of ℓ i (ψ i ) around

$ψ i = ψ * i yields that ℓ i (ψ * i ) -ℓ i (ψ i ) ≈ -1 2 (ψ i -ψ * i ) ⊤ li (ψ ′ i ) (ψ i -ψ * i ) for some ψ ′ i in a neighborhood of ψ * i .$To further justify part (2), some straightforward calculation yields that

$-li (ψ * i ) ≈ H iT (ψ * i ) = E 1 T T 0 λi (t|ψ * i ,Ht) λ⊤ i (t|ψ * i ,Ht) λ i (t|ψ * i ,Ht) dt , where λi (•|ψ i , H t ) = ∂λ i (•|ψ i , H t )/∂ψ i .$By definition, H iT (ψ i ) is a positive semi-definite matrix of dimension n kt + d i + 3, whose upper left n kt × n kt submatrix is a banded matrix due to Assumption 2. Therefore, λ min (H iT (ψ i )) is mainly determined by d i , and may approach 0 when d i diverges. To account for the case that the network becomes denser (d i 's increase), we allow for τ m → ∞ at a slow rate as m, T increases in later theoretical discussions. In Section B.1 of the supplementary material, we provide some empirical evidence for Assumption 4 by simulation.

Assumption 5 imposes a smoothness condition on the expected node-wise log-likelihood, which is reasonable for the problem under consideration. Assumption 6 asserts that at least one of the background intensity or the node-specific parameter vector are well-separable between any two latent groups, which is a reasonable assumption for a wide range of applications such as the social network data studied in Section 6. Finally, Assumption 7 requires that there is a sufficient number of nodes in each latent group and that there is a sufficient number of connected nodes between any two different latent groups.

## Model Estimation Consistency When G ≥ G 0

The membership estimation accuracy when G ≥ G 0 is evaluated by the following measure

$ρ mT = 1 m G g=1 m i=1 I i ∈ C g , g 0 i ̸ = χ(g) ,(19)$where 

$χ(g) = arg max g ′ ∈[G 0 ] m i=1 I i ∈ C g , g 0 i = g ′$$b(n kt + d) log(mT )[log(max{b, n kt , log(mT )})] 3 ; (b). 1 m m i=1 ∥ µ g i (•) -µ 0 g 0 i (•)∥ T = O p e 1/6 mT + τ 1/2 m e 1/4 mT + n -ν kt , where g i is the estimated member- ship of node i, i = 1, • • • , m, and µ g (•) = w ⊤ g x n kt (•) for g ∈ [G]; (c). 1 m m i=1 θ g i -θ 0 g 0 i + 1 m ∥ B -B 0 ∥ 1 = O p e 1/6 mT + τ 1/2 m e 1/4$mT , where B and B 0 are the estimated/true B in Assumption 1, respectively.

The proof is given in the Supplementary Material.

Theorem 2 asserts that even if G is over-specified, both the clustering error ρ mT and the parameter estimation errors converge to 0, and the convergence rate is primarily determined by T rather than the number of nodes m. The convergence rates are also negatively impacted by large values of b and d, where the former is the triggering function range that controls the strength of serial dependence among offspring of the same parent, and the latter represents the level of connectivity among network nodes. Furthermore, the quantity τ m in Assumption 4 is also affected by d i 's and may also grow as the network becomes denser, leading to a slower convergence rate.

Particularly, it is of important practical interest to consistently estimate the transition matrix B 0 , since the estimator B can be used to study the network interactions following Section 2.3.

We remark that Theorem 2 is unlikely to hold when G < G 0 , in which case nodes from different groups are forced into the same group, resulting in biased parameter estimators.

## Selection Consistency of Number of Groups

In this subsection, we study the selection consistency of the LIC criterion proposed in (16). To this end, we show in the following Theorem that G selected by maximizing LIC estimates G 0 consistently when the penalty parameter λ mT is appropriately chosen. 

$b(n kt + d) log(mT )[log(max{b, n kt , log(mT )})] 3 = o(1), then P ( G = G 0 ) → 1.$The proof is given in the Supplementary Material.

Theorem 3 requires that λ mT converges to zero but not too fast. In our numerical examples, we set λ mT = (15T ) -1 (median 1≤i≤m n i ) 0.6 d0.25 and verify its finite sample performances in details in Section 5. Such a choice ensures that G does not depend on the unit of T .

## Convergence Rates and Asymptotic Normality When G = G 0

We now study the convergence rates and asymptotic normality of the model parameter estimators when G = G 0 , which requires some modifications of the MLE (11) as follows.

Membership refinements. The MLE (11) maximizes the overall log-likelihood function (10), but not necessarily each node-specific likelihood

$ℓ i w g , θ g , φ g,G i |H T , i = 1, • • • , m.$As a result, if ℓ i w g i , θ g i , φ g i , G i |H T is too low for some i, its membership estimate g i may be incorrect. To address this issue, we propose a membership refinement strategy. One way to check whether g i results in a too small ℓ i w g i , θ g i , φ g i , G i |H T is to compare it to the profile likelihood

$ℓ p i (g|H T ) = sup φ i ∈Φ i ℓ i w g , θ g , φ i |H T .$If for some g such that ℓ p i ( g|H T ) is much greater than

$ℓ i w g i , θ g i , φ g i , G i |H T ,$it may be a sign to relabel the node i to group g. Furthermore, instead of maximizing over all φ i ∈ Φ i , our theoretical investigation suggests that, for any given g, it suffices to define the profile likelihood function as ℓ p i (g|H T ) = ℓ i w g , θ g , φ p i (g)|H T , where

$φ p i (g) = argmax φ i ∈{ φ g ′ ,G i :g ′ ∈[G],G i ∈[G] d i } ℓ i w g , θ g , φ i |H T , for g ∈ [G].$Denote g † i = argmax 1≤g≤G ℓ p i (g|H T ). The refined membership of node i is then defined as

$g r i =    g i , if ℓ p i ( g † i |H T ) -ℓ i w g i , θ g i , φ g i , G i |H T ≤ 0, g † i , if ℓ p i ( g † i |H T ) -ℓ i w g i , θ g i , φ g i , G i |H T > 0.(20)$With this modification, we define the estimated groups C r g = {i : 1 ≤ i ≤ m, and g r i = g}, g ∈ [G], and the true groups C 0 g ′ = {i : 1 ≤ i ≤ m, and

$g 0 i = g ′ }, g ′ ∈ [G 0 ]. When G = G 0 , a$stronger version of Theorem 2 can be established as following.

Theorem 4. Assume G = G 0 , Assumptions 1-7, and that τ 2 m x mT = o(1) with x mT as defined in Theorem 2. Then, as m, T → ∞, it holds that (a). sup 1≤i≤m µ g r i (•) -µ 0

$g 0 i (•) T + θ g r i -θ 0 g 0 i = O p (x 1/3 mT + τ m x 1/2 mT + n -ν kt ) where g r i is the estimated membership of node i after refinement, i = 1, • • • , m; (b). if we further assume that τ 4 m x mT = o(1), then for each g ∈ [G], there exists g ′ ∈ [G 0 ] such that P ( C r g = C 0 g ′ ) → 1 as m, T → ∞.$The proof is given in the Supplementary Material.

Theorem 4 (a) states that when G = G 0 , the background intensity µ 0 g i (•) and the node-specific parameters θ 0 g 0 i can be consistently estimated for all network nodes. Theorem 4 (b) shows that, after some label permutation, all nodal memberships can be correctly identified with a probability tending to 1, which is crucial to establishing asymptotic normality of the parameter estimators.

Denote the refitted estimator

$w r⊤ , θ r⊤ , ϕ r⊤ ⊤ = argmax w ,θ ,ϕ ℓ(w , θ , ϕ , G r |H T ) with G r = ( g r 1 , g r 2 , • • • , g r m )$⊤ being the refined membership estimator. Due to Theorem 4 (b), for ease of presentation, we drop the notation G 0 whenever there is no ambiguity. In particular, the model parameters that need to be estimated become ψ = (w ⊤ , θ ⊤ , ϕ ⊤ ) ⊤ , whose true values are ψ * = (w * ⊤ , θ 0⊤ , ϕ 0⊤ ) ⊤ . For any given ψ , we view the conditional intensity function ( [9](#)) as a function of ψ and denote it as λ i (t|ψ , H t ) for any t ∈ [0, T ] and i = 1, • • • , m. Define the matrix

$H mT (ψ ) = 1 mT m i=1 T 0 E λi (t|ψ , H t ) λ⊤ i (t|ψ , H t ) λ i (t|ψ , H t ) dt,(21)$where λi (

$•|ψ , H t ) = ∂λ i (•|ψ , H t )/∂ψ , i = 1, • • • , m.$To establish the asymptotic normality result, we assume the following condition for H mT (ψ ).

Assumption 8. There exist positive constants ϵ, τ min , τ max such that for any ∥ψ -ψ * ∥ ≤ ϵ, one has that λ min H mT (ψ ) ≥ τ min and λ max H mT (ψ ) ≤ τ max for sufficiently large m, T .

Lemma D.7 in the Supplementary Material shows that, under suitable conditions, H mT (ψ ) is asymptotically equivalent to the negative Hessian matrix of ℓ(ψ ) in ( [18](#formula_55)). Therefore, Assumption 8 essentially assumes that ℓ(ψ ) is locally concave in a neighborhood of ψ * , which is a mild assumption similar to Assumption 4. In Section B.2 of the supplementary material, we provide more discussions on Assumption 8 through some simulation studies.

The following theorem establishes the convergence rates of the background intensity estimators and the asymptotic normality of the model parameters.

Theorem 5. Assume Assumptions 1-8 and and that τ 2 m x mT = o(1) with x mT as defined in Theorem 2. Then if G = G 0 , the following holds.

(a). If n kt / √ mT = o(1) and ν > 1/2, then as m, T → ∞, one has that

$max 1≤g≤G µ r g (•) -µ 0 g (•) T = O p n kt /mT + n -ν kt . (22$$) (b). Denote α r = ( θ r⊤ , ϕ r⊤ ) ⊤ , α 0 = (θ 0⊤ , ϕ 0⊤ ) ⊤ , and let Σ α = lim (m,T )→∞ I α H -1 mT (ψ * )I ⊤ α with I α = (0 (3G+G 2 )×n kt , I (3G+G 2 )×(3G+G 2 ) ). If it further holds that √ mT /n ν kt = o(1), then √ mT α r -α 0 d - → N (0, Σ α ) as m, T → ∞.$The proof is given in the Supplementary Material.

Theorem 5 part (a) gives an upper bound of the convergence rate of the nonparametric background intensity estimators that consists of two parts. The first part n kt /mT is due to the estimation variance, and the second part is introduced by the basis approximation error. Part (b) gives sufficient conditions under which the √ mT -convergence rate for α r and the asymptotic normality can be established. The result is proved by using a martingale central limit theorem [(Fleming and Harrington, 2011)](#b8). Particularly it requires that √ mT /n ν kt = o(1) so that the approximation bias is dominated by the estimation variance, a popular strategy used in the nonparametric inference literature. In a simple setting with max{b, τ m , d max } < ∞, Theorem 5 (b) requires n kt to satisfy (mT ) 1/(2ν) ≪ n kt ≪ (T /[log(mT ){log(log(mT ))} 3 ]) 1/(1+δ) for some δ > 0, where a mT ≪ b mT means a mT /b mT → 0 as m, T → ∞. As one can see, a larger ν, which suggests a smoother background intensity, will make the above condition more likely to hold. A plug-in estimator of the covariance matrix Σ α can be constructed straightforwardly using the definition of H mT (ψ * ) in ( [21](#formula_76)) for statistical inferences.

## Simulation Studies

In this section, we conduct simulation studies to evaluate the numerical performance of the proposed GNHP model. The following two types of network structures are considered:

Stochastic Block Model (SBM). This model is widely used in the community detection literature. The network consists of m nodes belonging to 3 blocks and each node is randomly assigned a block label with a probability of 1/3. An edge between two nodes is generated with a probability 0.3m -0.3 if they are in the same block, or with a probability of 0.3m -0.8 otherwise.

Power-law Network. Such a network resembles the commonly observed social network structure where most nodes have few followers while a small fraction of nodes have a large number of followers. For each node i, the number of randomly picked followers is 4f i , where f i follows the power-law distribution

$P (f i = f ) = cf -2 , 0 ≤ f ≤ m,$where c is the normalizing constant.

For each type of network, we random assign each node to G 0 = 3 latent groups with group proportions as π m = (π 1,m , π 2,m , π 3,m ) ⊤ = (0.3, 0.4, 0.3) ⊤ . To mimic typical daily activities of social network users, the background intensity of each latent group takes a periodic form

$µ g (t) = C g Hg h=1 b h,g exp{-(t -a h,g ) 2 /w h,g } g ∈ [G 0 ], t ∈ [0, ω].$Triggering functions of all groups are of the form f (t, γ) ∝ γ exp(-γt)1{t ≤ b} with b = 5 hours. Model parameters (except C g 's and b h,g 's) are listed in Table [1](#tab_1), and the true background intensities are illustrated in Figure [3](#fig_6), which have the same shapes of the estimated background intensities in our Sina Weibo data analysis (see Figure [7](#)), where the common period is set as ω = 24 hours and C g is chosen such that ω 0 µ g (t)dt is set at the targeted values in Table [1](#tab_1).

Background intensity Momentum Network  

$g ω 0 µ g (t)dt β g η g γ g (ϕ g1 , ϕ g2 , ϕ g3 ) 1 2.5 0.$${ µ (k) g (•), β (k) g , η (k) g , γ (k) g , ϕ (k)$gg ′ } and the group membership estimator as

$C (k) = { g (k) i : 1 ≤ i ≤ m}.$The group membership estimation accuracy rate is then computed by GAR= K -1 K k=1 GAR (k)   with GAR

$(k) = 1 -ρ (k)$mT , where ρ

$(k)$mT is obtained by applying (19) to C (k) .

## Estimation Accuracy When G = G 0

When G = G 0 , parameter estimation accuracy can be evaluated by the root mean squared error (RMSE) of estimates after some label switching. The estimation accuracy µ g (•) is evaluated by

$K -1 K k=1 | µ (k) g (t) -µ g (t)|dt.$For comparison, we also present the estimation accuracy of the "Oracle" estimator for which the true group memberships of all nodes are known and fixed when finding the MLE. All simulation results are summarized in Figure [4](#fig_8) and Tables [2](#)[3](#). From Figure [4](#fig_8), we observe that the estimated background intensities become closer to the true background intensities as either m or T increases, which supports our theoretical findings in Theorems 2 (b) and 5 (a). Results for the Power-law network are similar and given in Section ?? of the supplementary material. From Tables [2](#)[3](#), we can see that when both m and T are small, the group memberships of a proportion of network nodes may be incorrectly estimated in both network settings. However, in all case scenarios, the GARs of the GNHP model are much better than those of the intensity-based K-means algorithm, which is used to provide initial membership estimates for the GNHP estimation, see Section A.2.1 of the supplementary material for details. As m and/or T increases, the GARs of the GNHP gradually approach 1. This is consistent with our theoretical findings in Theorem 4. Consequently, as m or T increases, the estimation accuracy of the model parameters improves steadily and approaches that of the "Oracle" estimator. Overall, the simulation results support the estimation consistency of the proposed GNHP model when the group number G is correctly specified.

Table 2: Estimation Accuracy of GNHP for SBM network when

$G = G 0 . m = 100 µ (×10 -3 ) β(×10 -3 ) η (×10 -3 ) γ (×10 -3 ) ϕ (×10$-3 ) GAR (s.e.) GAR (s.e.) T GNHP (Oracle) GNHP (Oracle) GNHP (Oracle) GNHP (Oracle) GNHP (Oracle) (GNHP with (Intensity-based g/g ′ ----1 2 3 refinement) K-means) 5ω 1 340 (309) 16.3 (15.9) 199 (189) 212 (189) 29.1 (26) 45.3 (32.1) 29.6 (26.3) 95 (2.3) 53 (5.1) 2 271 (249) 24.7 (22.4) 228 (211) 357 (336) 40.3 (39.3) 55.4 (51.1) 52.8 (48.9) 3 192 (187) 26.5 (25.3) 431 (407) 183 (177) 21.7 (21.2) 34 (32.3) 29.1 (28.7) 10ω 1 229 (228) 10.7 (10.7) 129 (127) 133 (127) 18.3 (17.9) 24.6 (23.2) 19.5 (18.3) 99 (0.93) 59 (4.2) 2 184 (181) 15.4 (15.2) 148 (149) 237 (219) 28.2 (27.6) 35.7 (35.8) 34.4 (33.9) 3 132 (132) 18 (18.4) 283 (284) 110 (109) 14.4 (14.4) 21.4 (21.9) 18.7 (18.5) 20ω 1 165 (164) 7.31 (7.24) 92.7 (92.1) 93.5 (91) 13 (12.3) 15.4 (15.1) 12.3 (11.6) 100 (0.2) 64 (3.0) 2 131 (129) 11.2 (11.7) 95.3 (95.6) 161 (164) 19.1 (19.8) 24.5 (24.3) 24 (24.2) 3 95.8 (96.2) 12.5 (13.4) 207 (212) 78 (78.6) 10.3 (10.2) 15.8 (16) 13.6 (13.1) 40ω 1 126 (126) 5.19 (5.35) 65.6 (63.7) 69.1 (67.2) 9.06 (9.32) 11.1 (11.2) 9.47 (9.66) 100 (0) 66 (2.5) 2 93.8 (93.3) 7.77 (8.21) 66.5 (66.4) 110 (109) 13.3 (13.2) 16.7 (17.4) 15.8 (16.1) 3 69 (69) 8.71 (8.64) 140 (143) 55.1 (54.5) 7.05 (6.96) 11.2 (10.2) 9.49 (9.32) 5ω 1 272 (250) 12.2 (11.2) 148 (133) 218 (199) 36 (26) 29.9 (26.1) 25.3 (22.4) 94 (1.7) 49 (3.2) 2 205 (182) 16.3 (14.3) 141 (129) 257 (236) 27.8 (27.3) 35.4 (32.7) 37.1 (34.7) 3 152 (146) 18.2 (18.1) 307 (293) 144 (141) 18.3 (18) 28.4 (26.6) 20.5 (20) 10ω 1 181 (179) 8.58 (8.4) 99.7 (98.5) 138 (136) 19.2 (18.1) 17.8 (17.4) 17.7 (17.5) 99 (0.72) 55 (3.4) 2 136 (133) 10.5 (10.3) 95.3 (91.8) 167 (166) 19.6 (19.1) 23.9 (23.3) 24.7 (24.4) 3 106 (106) 13.1 (13.3) 196 (190) 98.1 (101) 12.2 (12) 19.3 (19.5) 14.1 (14.2) 20ω 1 133 (133) 5.65 (5.74) 69.5 (67.8) 98.5 (96.5) 12.7 (12.9) 12 (12.3) 11.3 (11.6) 100 (0.17) 64 (4.4) 2 98.7 (97.7) 6.91 (7) 66.2 (68) 115 (115) 12.8 (13.1) 17.2 (17.1) 17.2 (17.4) 3 77 (77.9) 8.81 (8.72) 144 (146) 64.6 (63.4) 8.98 (8.94) 13.7 (13.7) 10 (9.86) 40ω 1 103 (103) 3.99 (4.01) 50.5 (50.1) 69.5 (69.3) 9.17 (9.21) 8.49 (8.44) 8 (7.91) 100 (0) 71 (4.4) 2 72.3 (72.7) 5.01 (5.05) 47.4 (47.5) 82.2 (82.3) 9.37 (9.41) 12.2 (11.9) 12.2 (12.2) 3 56.8 (56.9) 6.33 (6.32) 102 (101) 45.2 (44.7) 6.26 (6.24) 9.47 (9.33) 6.85 (6.77)

Table 3: Estimation Accuracy of GNHP for Power Law network when G = G 0 . RMSE TABLE, PL setting.

$m = 100 µ (×10 -3 ) β(×10 -3 ) η (×10 -3 ) γ (×10 -3 ) ϕ (×10 -3 ) GAR ($s.e.) GAR (s.e.) T GNHP (Oracle) GNHP (Oracle) GNHP (Oracle) GNHP (Oracle) GNHP (Oracle) (GNHP with (Intensity-based g/g ′ ----1 2 3 refinement) K-means) 5ω 1 395 (349) 17.8 (15.5) 213 (193) 410 (362) 61 (50.4) 43.2 (38.8) 51.5 (46) 93 (2.8) 49 (4.3) 2 340 (290) 23.5 (20.2) 213 (191) 449 (405) 50.4 (46.6) 55.5 (48.4) 74.4 (67.4) 3 240 (231) 26.1 (25.4) 420 (388) 292 (283) 38 (37.8) 46.3 (42.4) 53.8 (51.8) 10ω 1 249 (246) 12.4 (11.8) 140 (135) 237 (225) 32.3 (31.2) 28.8 (25.8) 31.6 (31.5) 99 (1.3) 55 (4.5) 2 208 (202) 15 (14.3) 144 (137) 289 (272) 33.6 (32.7) 35.5 (33.8) 45.4 (45.3) 3 161 (163) 17.2 (17) 296 (279) 153 (159) 26.5 (26) 26.1 (27.3) 34.3 (35.6) 20ω 1 181 (179) 7.5 (8.13) 103 (96.9) 141 (151) 22.4 (22.4) 19.4 (19) 23.2 (22.6) 100 (0.31) 63 (5.6) 2 149 (147) (9.7) 92.2 (91.5) 208 (194) 22.9 (22.4) 22.5 (22.3) 34.7 (33.3) 3 115 (117) 12.5 (12.1) 201 (197) 108 (106) 17.5 (17.8) 18.8 (19.4) 23.7 (24.8) 40ω 1 133 (134) 5.71 (5.63) 70.5 (68.9) 119 (117) 16.2 (16.4) 13.5 (13.9) 16 (15) 100 (0.059) 74 (6.9) 2 107 (106) 6.84 (6.89) 69 (67.7) 137 (137) 16.4 (16.7) 16.5 (16.4) 23.4 (23.8) 3 83.1 (84.7) 9.29 (8.85) 143 (146) 72.9 (73) 12.6 (12.3) 14.2 (13.9) 17.3 (17.7) 5ω 1 296 (254) 12.3 (9.92) 136 (118) 216 (191) 35.2 (25.5) 43.2 (32.1) 32.4 (30.6) 94 (1.9) 51 (3.6) 2 281 (252) 17 (15) 164 (139) 331 (298) 32.1 (30.3) 45.7 (42.5) 56.2 (51) 3 195 (188) 17.7 (17.2) 299 (287) 186 (181) 23 (22.5) 37.5 (37.6) 35.7 (34.1) 10ω 1 191 (187) 7.25 (6.99) 85 (83.3) 137 (133) 20.5 (18.8) 26.2 (23.2) 21.3 (20.6) 99 (0.9) 59 (3.4) 2 186 (181) 10.5 (10.4) 103 (97.4) 212 (202) 21.1 (20.9) 29.5 (29.3) 38.8 (37.5) 3 139 (138) 12.9 (12.8) 214 (209) 117 (118) 16.1 (16.1) 24.8 (24.8) 23.9 (23.7) 20ω 1 138 (137) 4.87 (4.96) 60.1 (58.9) 98.8 (100) 12.2 (12.1) 15.5 (15.9) 14.2 (14.4) 100 (0.2) 67 (3.2) 2 128 (128) 7.43 (7.42) 68.5 (68.9) 146 (146) 14.4 (14.6) 21.7 (21.3) 26 (25.5) 3 99.4 (99.1) 8.7 (8.61) 139 (141) 75.6 (76.7) 11.4 (11.1) 17.7 (18) 16.4 (16.4) 40ω 1 110 (110) 3.23 (3.49) 39.4 (41.6) 82.8 (82.3) 9.34 (9.18) 11.2 (11.3) 10.4 (10.4) 100 (0.027) 75 (4.2) 2 97 (95.3) 5.1 (5.11) 51.3 (49.6) 117 (110) 10.4 (10.5) 15.1 (15) 17.2 (18) 3 72.6 (71.9) 6.09 (6.16) 91.5 (93.9) 52.5 (54) 7.56 (7.8) 11.7 (12.5) 12.2 (11.8)

## Coverage Probability When

$G = G 0$We next investigate the quality of statistical inference for the GNHP model by evaluating the coverage probabilities of the 95% confidence intervals for model parameters, derived through the limiting distribution given by Theorem 5 (b). For instance, the 95% confidence interval for β g is given by CI

$(k) βg = ( β (k) g -1.96 σ (k) βg , β (k) g +1.96 σ (k) βg ), where σ (k)$βg is the square root of the corresponding diagonal entry of the estimated covariance matrix Σ α . Empirical coverage probabilities based on 1000 simulation runs are summarized in Table [4](#tab_6).

Table [4](#tab_6) shows that the coverage probabilities have some departure from the nominal 95% when m = 100 and T = 5ω in both network settings, which is not surprising since on average only around 5% and 7% of group memberships are correctly estimated in these two settings. As m and T increase, the empirical coverage probabilities for almost all parameters approach the 

$T β g η g γ g ϕ gg ′ β g η g γ g ϕ gg ′ β g η g γ g ϕ gg ′ β g η g γ g ϕ gg ′ g/g ′ - - - 1 2 3 - - - 1 2 3 - - - 1 2 3 - - - 1 2$3 5ω 1 93.8 93.4 91.5 92.1 85.5 91.3 93.3 94.9 91.8 82.2 91.8 93.5 94.4 95.2 93.1 84.8 92.6 84.4 89.2 93.9 90.8 86.8 85.3 92.6 2 91.5 90.6 90.8 93.4 90.6 91.3 90.8 90 92.9 93.3 94.9 92.7 92.6 90.5 92.2 92.2 90.9 93.1 88.9 90.3 91.1 91.6 90.5 91.1 3 95 92.1 93.3 94 92.5 94.4 94.9 93.3 93.1 94.9 94.1 93.7 92.2 95.2 95.7 92.6 91.3 92.2 94.7 94.2 92.1 94.7 91.8 91.6 10ω 1 94.6 95.2 94.8 94.8 92.5 94.4 95.9 94.4 94.4 93 93.2 93.8 94.5 96.2 94.5 91.8 91.2 94 94.5 95.4 94.8 89 93.3 92 2 96 93.7 94.2 91.5 93.5 92.9 94 93.4 94.6 96.5 96.1 94.8 97.3 95.6 94 94 91.2 96.7 95.1 93.6 93.6 92.7 96.3 93.3 3 95.6 95.8 95.4 94.4 96.6 94.4 93.4 94.8 92.6 96.7 93.8 95.7 94 96.7 96.2 92.9 94 92.9 93.3 93.9 93.6 92.7 95.4 95.7 20ω 1 96.6 93.8 94.2 93.4 95.8 96 95.5 95.1 95.5 95.5 95.7 94.6 95 95.6 95 92.5 93.1 95.6 96.6 95.2 92.2 95.2 94.2 95.6 2 93.4 94.8 94.8 95.8 93.8 92.8 95.5 93.6 95.3 96.1 93.8 95.1 92.5 96.2 93.1 94.4 96.2 92.5 96.9 93.5 94.5 95.6 94.5 93.9 3 94.4 93.8 95 93.6 94 93.8 95.1 93.1 95.7 94.2 91.9 94.9 97.5 92.5 91.9 95 95.6 95 91.8 96.6 95.9 95.6 95.6 93.5 40ω 1 95 93.2 94.8 95.8 95.6 95 95.8 93.8 93.4 94 94.8 95.6 93.5 91.6 90.9 93.5 94.8 96.8 95.4 95.4 87.7 92.3 92.8 92.3 2 93.6 95.2 94.4 94 95.6 96 94.2 94.2 94 94.6 95.6 94 92.2 92.9 91.6 92.2 97.4 93.5 95.4 91.3 90.8 92.8 94.9 94.9 3 94.4 94.2 94.4 95.4 93 95.2 93.4 95.4 94 95.6 94.8 94.6 92.2 92.9 96.8 95.5 92.2 94.2 94.4 97.4 91.8 95.4 94.4 94.9

nominal level, which supports our theoretical findings in Theorem 5.

## Estimation Accuracy with a Mis-specified G

When G is mis-specified, we define PD To identify the true number of groups, we use λ mT = (15T ) -1 (median 1≤i≤m n i ) 0.6 d0.25 for the LIC in ( [16](#formula_51)), and report the selection error rate as SR(G) = K -1 K k=1 I( G (k) = G), where G (k)   maximizes the LIC in the kth simulation. To study the effect of the membership refinement algorithm in Section 4.4, we also compare the GARs with and without membership refinements.

$β = median 1≤k≤K 1 m m i=1 β 0 g 0 i -β(k) g (k) i$In the refinement step, we randomly sample 1, 000 ψ i 's to find the refined membership (20) if the candidate set size exceeds 1, 000.

Since the refinement step is rather time consuming, especially when G is large, we only provide summary statistics based on K = 200 simulation runs in Table [5](#tab_8), where we can see that even when G is over-specified, the consistency result still holds. For instance, PD β drops from approximately 42.2×10 -3 to 20.5×10 -3 as (m, T ) increases from (100, 5ω) to (200, 10ω) with G = 4, which corroborates with the result in Theorem 2. When G > 3, estimation errors are generally larger than those of the case with G = G 0 , which is reasonable due to the additional estimation variability introduced by an overly large G. Furthermore, the proposed LIC can correctly select the true number of groups with a probability tending to 1 as (m, T ) increases, which supports our conclusion of Theorem 3. Lastly, the GAR after the refinement tends to be slightly better than the GAR without the refinement, suggesting it is beneficial to perform membership refinement.

## Computation Times

We now study the computation times of the proposed EM algorithm outlined in Section 3.3. For each initial membership estimate, we perform 100 Stochastic EM iterations, 50 EM iterations with fixed memberships, and then 50 EM iterations. Fixing m = 100, computation times (in seconds)

of this algorithm on a cluster of Intel Xeon Gold 6126 CPUs with 2.6 Ghz are summarized in Figure [5](#). We can see that the CPU time grows approximately linearly as T and the total number of events increase. The CPU time grows slightly faster than linearly as G increases since the number of parameters is of the order Gn kt + 3G + G 2 . Results are similar for the Power-law Heuristically, T /ω can be roughly interpreted as the number of weakly dependent replicates over time and Gn kt T /ω can be viewed as the total number of knots placed over [0, T ] and G groups. Fixing G = 4, Figure [7](#) shows that the minimum BIC value is achieved with n kt = 6.

The estimated background intensities using n kt = 6 and G = 4 are illustrated in Figure [7](#) and the resulting parameter estimates are summarized in Table [6](#tab_9). Figure [7](#) shows that all estimated background intensities have two peaks around 10:00 am and 8:00 pm, suggesting that users are more active around these times. Based on the estimated GNHP model and users' information in the different groups, we summarize groups as following.

• Group 1 is largest group that includes 49.8% of users, who have the lowest background intensity throughout the day. Judging from ϕ g1 's, users from this group have relatively low impact on users from other groups. This group also has the largest η value, suggesting that the user's past posts have the shortest time impacts on his/her future posting behavior.

• Group 2 include many users that are playing leading roles in various communities such as entertainment, business, education, and social sciences, who typically do not post very frequently throughout the day. This group has the second smallest η value, indicating that users' past posts have a relatively long time effect. The estimated ϕ g2 's suggests that this group of users have the largest impacts on all groups except Group 3. Our subsequent analysis in Section 6.2 reveals that this group is the second most influential group.

• Group 3 mainly contains official accounts of some news outlets. Figure [7](#) shows that this group is the most active one on average, which is probably due to their mission to deliver information promptly. It has the smallest η, suggesting the longest temporal dependence on the posting histories. At the same time, it has an extremely large γ, which indicates that this group is very unlikely to be influenced by past posts from other groups. Although the estimated ϕ g3 's are not as large as those of Group 2, the largest background intensity of this group makes it the most influential group, as we shall demonstrate in Section 6.2.

• Group 4 consists of users who post quite frequently as suggested by Figure [7](#) but have rather limited impacts on other groups based on the estimated ϕ g4 's. It has a large ϕ 42 = 0.147, indicating that users in this group are heavily influenced by users in Group 2.

## Group Interaction and Influential User Analysis

In social network analysis, identifying influential users is an important task, as it may help improve the efficiency of news propagation, product release, and promotional campaign launches.

To identify the most influential users, we first define the influential power of the user i as the sum of the ith column of (I -B) -1 , which is the Node-to-network influence given by Theorem 1. The bar plots of users with top 20 and 100 influential powers are illustrated in Figure [8](#fig_10), which shows that top 20 influential users only consist of members from Groups 2 and 3, with the latter group being the most influential one. This observation is further confirmed in the barplot of the top 100 influential users, where the majority of users are from Groups 2 and 3.

To shed more light on interactions among different groups, Figure [8](#fig_10) gives impact curves of each group on the other groups as defined in (5). As expected, both Groups 1 and 4 have rather limited impacts on other groups throughout the day. It appears that the most influential Group 3 has the largest impact on the Group 2, suggesting that users in Group 2 may have the greatest need for timely information provided by users in Group 3. Group 4 is impacted more heavily than Group 1 by Group 3, probably because users in Group 4 are relatively more active and hence can react to information from Group 1 more quickly. Lastly, the impact of Group 3 on Groups 1 and 4 are rather similar, an interesting phenomenon that may require a deeper look. Overall, the influence power plots and impact curve plots reveal some interesting interactive patterns among social network users, suggesting potential usefulness of the proposed GNHP model.

Finally, in Section B.5 of the supplementary material, we show the differences between groups obtained from GNHP and some simple alternative algorithms. More importantly, we remark that GNHP provides numerical quantification of user influence powers while others cannot.

## DISCUSSION

We propose a group network Hawkes process (GNHP) that is suitable for analyzing the dynamic behavior patterns of heterogeneous users in a large network. The GNHP model extends the classical Hawkes model by utilizing the network structure and introduces a latent group structure to account for heterogeneity among network users. Theoretical properties are thoroughly investigated and a computationally efficient EM algorithm is proposed. The GNHP is highly interpretable, as we have demonstrated through an application to a Sina Weibo dataset.

The proposed model is suitable for abundant applications such as crime pattern analysis and financial risk management, as long as the network structure can be identified. Several research topics can be pursued for future studies. First, in many applications, the background intensities may be more complicated with multi-scale seasonalities such as daily, weekly, and annual seasonalities, in which case we can consider an additive background intensity µ(t) = J j=1 µ g,j (t -⌊t/ω j ⌋ω j ) with an increasing ω 1 < ω 2 < • • • < ω J and each µ g,j can be approximated by periodic splines. An alternative remedy is to introduce some time-dependent covariates such as "day of the week" or categorical variables such as "weekend or not?" and "holiday or not?". Our theory can be easily modified for both extensions. One can further introduce user-specific covariates such as "age", "gender" and "occupation" into the background

intensities, but such extensions require non-trivial modifications of the current theory. Second, it will also be interesting to find a data-driven method to detect the period parameter ω if it is unknown. Next, while we have only considered one type of user behavior, it would be interesting to incorporate multi-type user behaviors into the model for analyzing data collected from a social network with more complicated structures. Finally, the network structure in the current framework is assumed to be known and fixed. It is also of great interest to extend the current model to be suitable for networks whose topological structures are evolving over time.

![Figure 1: Left: histogram of users' post counts. Middle: estimated overall intensity function of all users' posting times. Right: QQ-plot of gap times among friends and among random picked non-friends.]()

![Hawkes and Oakes (1974) provides an equivalent branching structure representation for the classical Hawkes process (1), which classifies the observed events into two disjoint processes: a parent Poisson process with a rate µ, and offspring processes triggered by past events. The branching structure of the classical Hawkes process is illustrated in the left panel of Figure2.]()

![Figure 2: Branching structures of the classical Hawkes process (left) and the GNHP (right). Left:]()

![(a) the background intensities µ i (•)'s are allowed to be time-varying and nonparametrically approximated using spline basis functions, which provides greater modeling flexibility. (b) the Momentum Intensity in model (2) has a clear interpretation given the network structure. (c)]()

![), and similar approaches have been used inVeen and Schoenberg (2008);Halpin et al. (2013);Fox et al. (2016). Since the likelihood (10) is non-concave, the initial values of the group memberships and model parameters are of crucial importance. We propose to use a combination of the Kmeans algorithm and a stochastic EM algorithm to generate sensible initial values. The details are given in the Section A of the supplementary material.]()

![gives the true group label of the majority nodes in C g = {i : g i = g}, for g ∈ [G]. Note that 1 -ρ mT is referred to as the cluster "purity" in the machine learning literature(Schütze et al., 2008), and is well defined even when G > G 0 .The following theorem states the estimation consistency of the MLE (11) when G ≥ G 0 . Theorem 2. Assume Assumptions 1-7, G ≥ G 0 , and that τ m x mT = o(1) with x mT = 1 T b(n kt + d max ) log(mT )[log(max{b, n kt , log(mT )})] 3 , where d max = max 1≤i≤m d i and d = 1 m m i=1 d i are maximum and average out-degrees. Then it holds that as m, T → ∞, (a). ρ mT = O p e 1/2 mT + τ m e mT , with e mT = 1 T]()

![Assume Assumptions 1-7 and x mT τ m = o(1) with x mT as in Theorem 2. If λ mT τ m = o(1) and λ -1 mT 1 T]()

![Figure 3: True background intensities.]()

![Figure 4: The mean estimated background intensities with ±1.96 times sample standard errors.]()

![and PD η and PD γ are similarly defined. For the estimated background intensities, we define PD µ ∥ T , and for the network effects, we evaluate the estimation accuracy of the transition matrix B using PD B]()

![Figure 8: Barplot of top 20 and top 100 influential users.]()

![Parameter setting for G 0 = 3 groups.]()

![Empirical coverage probabilities (%) for the GNHP model parameters.]()

![Estimation accuracy and selection rate of G when G is miss-specified.]()

![Parameter estimates for Weibo data (p-values are given in the parentheses).]()

