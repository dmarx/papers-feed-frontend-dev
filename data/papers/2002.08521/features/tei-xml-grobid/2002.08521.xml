<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Group Network Hawkes Process</title>
				<funder ref="#_86576uz #_2B9S5fW #_3yrhHtm">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2023-08-30">30 Aug 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Guanhua</forename><surname>Fang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Fudan University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country>China;</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ganggang</forename><surname>Xu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Miami</orgName>
								<address>
									<country>USA;</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Haochen</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Fudan University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country>China;</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Xuening</forename><surname>Zhu</surname></persName>
							<email>xueningzhu@fudan.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Fudan University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country>China;</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yongtao</forename><surname>Guan</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country>China;</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Shenzhen Research Institute of Big Data</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Group Network Hawkes Process</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-08-30">30 Aug 2023</date>
						</imprint>
					</monogr>
					<idno type="MD5">BE314A859C9DFA88CB9568A29629E40F</idno>
					<idno type="arXiv">arXiv:2002.08521v3[stat.ME]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-02-21T16:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>EM algorithm</term>
					<term>Latent group structure</term>
					<term>Multivariate Hawkes process</term>
					<term>Network data analysis</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this work, we study the event occurrences of individuals interacting in a network. To characterize the dynamic interactions among the individuals, we propose a group network Hawkes process (GNHP) model whose network structure is observed and fixed. In particular, we introduce a latent group structure among individuals to account for the heterogeneous user-specific characteristics. A maximum likelihood approach is proposed to simultaneously cluster individuals in the network and estimate model parameters. A fast EM algorithm is subsequently developed by utilizing the branching representation of the proposed GNHP model. Theoretical properties of the resulting estimators of group memberships and model parameters are investigated under both settings when the number of latent groups G is over-specified or correctly specified. A data-driven criterion that can consistently identify the true G under mild conditions is derived. Extensive simulation studies and an application to a data set collected from Sina Weibo are used to illustrate the effectiveness of the proposed methodology.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Point process models have gained increasing popularity for modeling activities observed on various networks, examples include posting activities in online social networks, corporation transactions in a financial network, and neuron spikes in a brain network. The main goal of this work is to develop a new modeling framework for random event times observed on a network consisting of heterogeneous nodes. While the proposed framework is applicable for the analysis of general event time data, we describe our model in the context of a motivating dataset collected from Sina Weibo (the largest Twitter type social media platform in mainland China).</p><p>The dataset contains posting times of 2,038 Sina Weibo users from January 1st to January 15th, 2014. Figure <ref type="figure" target="#fig_0">1</ref> shows that user posting patterns be highly heterogeneous and complex.</p><p>Firstly, the distribution of user post counts reveals great variability in users' activities levels: while most users had less than 200 posts during the study period, a small portion of users were much more active. Secondly, the averaged overall intensity of posting times aggregated over all users demonstrates the existence of apparent daily periodic patterns. Lastly, quantiles of gap times between a user's posting time and the closest posting time from his/her connected friends and randomly picked non-friends are drastically different. In particular, the quantiles of gap times among friends are consistently smaller than those among the non-friends, suggesting that a user's activities were heavily influenced by his/her friends. A popular model for event time data such as our motivating example is the multivariate Hawkes process <ref type="bibr" target="#b12">(Hawkes, 1971)</ref>, which has been widely used to model event times of multiple types in a variety of fields, such as criminology <ref type="bibr" target="#b14">(Linderman and Adams, 2014)</ref>, finance <ref type="bibr" target="#b3">(Bacry et al., 2013)</ref>, information diffusion <ref type="bibr" target="#b7">(Farajtabar et al., 2017)</ref>, and social studies <ref type="bibr" target="#b30">(Zhou et al., 2013;</ref><ref type="bibr" target="#b9">Fox et al., 2016)</ref>. In the network setting, the first line of existing research aims at recovering the unknown network structure using the observed event time data, see, e.g., <ref type="bibr" target="#b30">Zhou et al. (2013)</ref>; <ref type="bibr" target="#b25">Xu et al. (2016)</ref>; <ref type="bibr" target="#b0">Achab et al. (2018)</ref>; <ref type="bibr" target="#b2">Bacry et al. (2020)</ref>. In contrast, another line of research takes the network structure as given knowledge and incorporates it into the modeling of the event time data, examples include <ref type="bibr" target="#b9">Fox et al. (2016)</ref>; <ref type="bibr" target="#b7">Farajtabar et al. (2017)</ref> and <ref type="bibr" target="#b27">Zarezade et al. (2018)</ref>. In the second framework, model parameters were assumed to be node-specific, and therefore the number of parameters grows at least linearly with the number of nodes. This may be problematic if many nodes in the network produce only scarce event times, which was observed in Figure <ref type="figure" target="#fig_0">1</ref>. Section 2.4 gives a more detailed comparison between the proposed model and existing works.</p><p>In this work, we propose a group network Hawkes process (GNHP) to model the network heterogeneity by introducing a latent group structure among the network nodes. We assume that nodes in the same group share similar node-wise characteristics and that interaction patterns between any two connected nodes are determined by their group memberships. For each latent group, the background intensity varies over time and is nonparametrically approximated by spline basis functions. The proposed model is more parsimonious than existing models where all network nodes are considered as different (e.g., <ref type="bibr" target="#b9">Fox et al., 2016;</ref><ref type="bibr" target="#b7">Farajtabar et al., 2017;</ref><ref type="bibr" target="#b27">Zarezade et al., 2018)</ref>, but the latent group structure coupled with the observed network structure still allows us to build sufficiently flexible multivariate Hawkes process network models. Furthermore, the proposed GNHP model admits an equivalent branching process structure that enables us to develop easily interpretable numerical measures to quantify interactions within the network, see Section 2.3 for more details. The branching structure also allows us to develop a computationally efficient EM algorithm for model estimation, see Section 3.3. Lastly, the estimated group memberships cluster network nodes into several subgroups in a data-driven manner, offering further insights into the network activity dynamics. Therefore, the proposed GNHP model is an important addition to the existing toolbox for analyzing event time data observed on a network.</p><p>Our work also makes important theoretical contributions to the literature. The estimation of the (multivariate) Hawkes process is most commonly conducted through the maximum likelihood estimation <ref type="bibr">(Ogata, 1988;</ref><ref type="bibr" target="#b17">Mohler et al., 2011;</ref><ref type="bibr" target="#b5">Chen and Hall, 2013;</ref><ref type="bibr" target="#b30">Zhou et al., 2013)</ref>.</p><p>While <ref type="bibr" target="#b18">Ogata (1978)</ref> and <ref type="bibr" target="#b5">Chen and Hall (2013)</ref> studied the asymptotic property of the maximum likelihood estimator (MLE) for a univariate Hawkes process, to the best of our knowledge, however, little is known about the limiting behaviors of the MLE for a high-dimensional multivariate Hawkes process such as the proposed GNHP. In this work, we establish the consistency results for the MLE of the model parameters and the latent group memberships for the GNHP, with the number of groups being possibly over-specified. When the number of groups is correctly specified, we establish the asymptotic normality of the MLE. Finally, we show that a likelihood-based information criterion (LIC) can consistently select the number of groups. A similar theoretical framework has been considered in the panel data literature <ref type="bibr" target="#b22">(Su et al., 2016;</ref><ref type="bibr" target="#b15">Liu et al., 2020;</ref><ref type="bibr" target="#b34">Zhu et al., 2022)</ref>, although the treatments of point process data and panel data are very different. In this sense, our work also bridges a gap between the point process and the panel data literature.</p><p>The rest of the article is organized as follows. In Section 2, we introduce the GNHP model together with its branching structure representation and compare the proposed model to existing works. In Section 3, we detail our estimation procedure, including the computationally efficient EM algorithm. Theoretical properties of resulting estimators are investigated in Section 4. Simulation results under different network settings are presented in Section 5. In Section 6, we apply the proposed model to the Sina Weibo dataset. The article is concluded with a brief discussion in Section 7. Additional simulation resulats and all technical details are left to online supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">GROUP NETWORK HAWKES PROCESS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Background on Hawkes Process</head><p>Denote by 0 ≤ t 1 ≤ t 2 ≤ . . . ≤ t n ≤ T a realization of a temporal point process in [0, T ] and let N (t) = n k=1 I(t k &lt; t) be the associated counting process, where I(•) is an indicator function.</p><p>Let H t = {t k : t k &lt; t} be the process history up to time t, and the conditional intensity function of a point process is defined as</p><formula xml:id="formula_0">λ(t|H t ) = lim ∆→0 ∆ -1 E [N (t + ∆) -N (t)|H t ].</formula><p>The classical Hawkes process model <ref type="bibr" target="#b12">(Hawkes, 1971)</ref> assumes that λ(t|H t ) takes the form</p><formula xml:id="formula_1">λ(t|H t ) = µ + t k ∈Ht f (t -t k ),<label>(1)</label></formula><p>where µ &gt; 0 is a background rate of events and f (•) is a non-negative triggering function. The Hawkes process is considered as "self-exciting" since the past events in H t contribute to the instantaneous intensity λ(t|H t ) at time t through f (•). The triggering function controls the dependence range and strength between the intensity at time t and the past events, and popular choices include the exponential kernel <ref type="bibr" target="#b12">(Hawkes, 1971</ref>) and the power-law kernel <ref type="bibr">(Ogata, 1988)</ref>.</p><formula xml:id="formula_2">Notations. For a vector v = (v 1 , • • • , v p ) ⊤ ∈ R p , let ∥v∥ 2 = ( p i=1 v 2 i ) 1/2 and ∥v∥ ∞ = max j |v j | denote the L 2 -norm and the infinity norm of v, respectively. For a function h(t) ∈ R 1 with t ∈ [0, T ], define ∥h(•)∥ T = {T -1 T 0 h(t) 2 dt} 1/2 and ∥h(•)∥ ∞ = sup t∈[0,T ] |h(t)|. For a matrix H = (h ij ) ∈ R m×n , define the row norm ∥H∥ ∞ = max i ( j |h ij |) and L 1 norm ∥H∥ 1 = i ( j |h ij |). For any set S, define S n = {v = (v 1 , • • • , v n ) ⊤ : v i ∈ S} as collection of vectors of length n, whose elements are in S. Finally, we denote [G] = {1, • • • , G} and 1 = (1, • • • , 1) ⊤ .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Network Hawkes Process with Latent Group Structures</head><p>In this section, we extend the classical Hawkes process to the network setting with a latent group structure. Consider a network with m nodes, where the relationships among the nodes are represented by an adjacency matrix A = (a ij ) ∈ R m×m , with a ij = 1 if the ith node follows the jth node and a ij = 0 if otherwise. By convention, we do not allow self-connected nodes, i.e., a ii = 0. To account for potential heterogeneity of network nodes, we assume that the nodes in the network belong to G latent groups where nodes within the same group share the same node-specific characteristics and interactions with nodes from other groups.</p><formula xml:id="formula_3">Denote G = (g 1 , • • • , g m ) ⊤ ∈ R m</formula><p>as the latent group membership vector of all nodes, where</p><formula xml:id="formula_4">g i ∈ [G] for i = 1, • • • , m. For node i, let 0 ≤ t i1 ≤ t i2 ≤ • • • ≤ t in i ≤ T be the observed n i</formula><p>event times and N i (t) = n i k=1 I(t ik ≤ t) be the associated counting process. Given the group membership vector G and event history</p><formula xml:id="formula_5">H t = ∪ m i=1 H i,t with H i,t = {t ik : t ik &lt; t; 1 ≤ k ≤ n i }, the</formula><p>proposed GNHP model assumes that the conditional intensity for the ith node is of the form</p><formula xml:id="formula_6">λ i (t|G , H t ) = µ g i (t) + β g i t ik ∈H i,t f b (t -t ik ; η g i ) + m j=1 ϕ g i g j a ij d i t jl ∈H j,t f b (t -t jl ; γ g i ),<label>(2)</label></formula><p>for 1 ≤ i ≤ m, where µ g (•) is the background intensity, f b (•; η) is a triggering function governed by parameter η, d i = m j=1 a ij is the out-degree of node i <ref type="bibr" target="#b32">(Zhu et al., 2017)</ref>, and {β g , γ g , η g , ϕ gg ′ } are unknown group-level parameters for g, g ′ ∈ [G]. Following <ref type="bibr" target="#b6">Chen et al. (2017)</ref>, we assume the</p><formula xml:id="formula_7">support of f b (t; γ) is [0, b]. For example, f b (•; γ) can be the truncated exponential kernel f b (t; γ) = γ [1 -exp(-bγ)] -1 exp(-γt)I(t ≤ b), for any t ≥ 0. (<label>3</label></formula><formula xml:id="formula_8">)</formula><p>Our theoretical investigation allows the truncation range b → ∞ as m, T → ∞. For identifiability of parameters β g 's and ϕ gg ′ 's, we assume that ∞ 0 f b (t; γ)dt = 1 for any given γ. In addition, we</p><formula xml:id="formula_9">assume that ∥∂ k f b (•; γ)/∂γ k ∥ ∞ &lt; ∞ for 1 ≤ k ≤ 3.</formula><p>The proposed conditional intensity in (2) can be decomposed into the following three parts.</p><p>• Background intensity µ g i (t). This describes the overall activity pattern of the node i.</p><formula xml:id="formula_10">• Momentum intensity β g i t ik ∈H i,t f b (t -t ik ; η g i ).</formula><p>It models "self-exciting" influence of its own past events on the occurrence of a new event at t at the node i.</p><formula xml:id="formula_11">• Network intensity d -1 i m j=1 ϕ g i g j a ij t jl ∈H j,t f b (t -t jl ; γ g i ).</formula><p>This models influences from past events of other nodes on the occurrence of a new event at t at node i.</p><p>The out-degree d i is used to prevent the inflation of the Network Intensity when d i → ∞, which is commonly done in literature <ref type="bibr" target="#b32">(Zhu et al., 2017</ref><ref type="bibr" target="#b33">(Zhu et al., , 2019))</ref>. The ϕ g i g j 's in the Network Intensity represent the average network influences from the connected nodes on the ith node. Finally, we remark that the triggering functions in the Momentum Intensity and the Network Intensity do not necessarily share the same form.</p><p>The network dependence of the proposed GNHP can be characterized by the transition matrix</p><formula xml:id="formula_12">B = (b ij ) ∈ R m×m , where b ij = ϕ g i g j d -1 i a ij + β g i I(i = j), for i, j = 1, • • • , m.</formula><p>Detailed properties of B will be further explored in the next subsection based on the following assumption.</p><formula xml:id="formula_13">Assumption 1. Assume ∥B∥ ∞ ≤ c B &lt; 1, where c B is a positive constant.</formula><p>Assumption 1 is a sufficient condition for stability of a multivariate Hawkes process and has been widely used in the literature, see, e.g., <ref type="bibr" target="#b11">Hansen et al. (2015)</ref>; <ref type="bibr" target="#b6">Chen et al. (2017)</ref>. In the next subsection, we show that for the GNHP model, it is a sufficient condition to ensure that the expected number of offspring events triggered by a parent event at any network node is finite.  parent events (blue circle) and two generations of offspring events; Right: a two-node network where Node 1 follows Node 2. Parent events from both nodes (blue circles), event times triggered by their own past events (purple circles), event times in Node 1 triggered by past events from Node 2 (green circles).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Branching Structure of the GNHP Model</head><p>Following <ref type="bibr" target="#b20">Rasmussen (2013)</ref> and <ref type="bibr" target="#b10">Halpin et al. (2013)</ref>, a branching structure representation can be derived for the GNHP by treating the aggregated point process from all nodes, denoted by N pool , as a marked point process on [0, T ], with the mark for any t ∈ N pool being the node index where the event occurs. Specifically, event times in N pool can be categorized into two types: the parent and offspring events. Let M parent i be the set of parent events from node i and</p><formula xml:id="formula_14">M f am ik = M of f ik ∪ {t ik },</formula><p>where M of f ik is the set of offspring events generated from a parent event t ik ∈ M parent i . Note that M f am ik may contain event times from other nodes due to the network interactions. The branching structure is defined as follows and illustrated in Figure 2. 1. For any 1 ≤ i ≤ m, the parent events M parent i follows a Poisson process with an intensity µ g i (t), and all Poisson processes are independent. 2. Each parent event t ik ∈ M parent i generates a set of offspring events M of f ik , and all resulting M f am ik 's are independent. Event times in each M f am ik are generated recursively as follows. (a) Generation 0, denoted as M gen 0 ik , consists of only t ik , i.e., M gen 0 ik = {t ik }. (b) Having generated offspring event times up to n generations, M gen 0 ik , • • • , M genn ik , each event time in M genn ik generates a series of event times of the n + 1 generation. Specifically, suppose t jl ∈ M genn ik is an event time located in the jth node, then on the time interval [t jl , T ], it generates (i) a Poisson process with intensity β g j f b (t -t jl ; η g j ) on the node j; and (ii) a Poisson process with intensity ϕ g</p><formula xml:id="formula_15">i ′ g j d -1 i ′ f b (t -t jl ; γ g i ′ )</formula><p>on the node i ′ for any i ′ ̸ = j where a i ′ j = 1. All Poisson processes are independent.</p><p>(c) Obtain</p><formula xml:id="formula_16">M f am ik = ∪ ∞ n=0 M genn ik .</formula><p>Theorem 1. Denote by # i (S) the total number of events occurring at a subset of network nodes S ⊂ {1, • • • , m} that are offspring events of a parent event originated from the ith node on [0, ∞).</p><p>Then under Assumption 1, one has that</p><formula xml:id="formula_17">E [# i (S)] = e ⊤ S (I -B) -1 e i , for any 1 ≤ i ≤ m,<label>(4)</label></formula><p>where e S is a vector with 1 for entries whose indexes are in S and 0 elsewhere, and e i = e {i} .</p><p>The proof is given in the online supplement. Theorem 1 provides a useful tool to quantify the network interactions. Examples include</p><p>• Node-to-node influence: the (j, i)th entry of (I -B) -1 gives the average number of events at node j that are triggered by a parent event at the ith node (set S = {j}).</p><p>• Node-to-network influence: by setting S = {1, • • • , m}, we obtain the sum of the ith column of (I -B) -1 as the average number of events in the entire network that are directly/indirectly triggered by a parent event at the ith node, i.e., E{# i (S)} = E{|M f am ik |}.</p><p>• Dynamic Group-to-Group influence: Let S g be the collection of node indexes in group g. Denote #(S g , S g ′ , [t 1 , t 2 ]) as the total number of events from group g ′ triggered by parent events from group g occurring within [t 1 , t 2 ], which reflects the influential power of group g on group g ′ . Based on Theorem 1, it can be verified that</p><formula xml:id="formula_18">E #(S g , S g ′ , [t 1 , t 2 ]) = e ⊤ S g ′ (I -B) -1 e Sg t 2</formula><p>t 1 µ g (t)dt. We can subsequently define the limiting case as follows</p><formula xml:id="formula_19">GIF gg ′ (t) = lim ∆→0 ∆ -1 E #(S g , S g ′ , [t, t + ∆]) = e ⊤ S g ′ (I -B) -1 e Sg µ g (t), t ∈ [0, T ],<label>(5)</label></formula><p>which is more convenient for graphical illustrations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Comparisons with Existing Literature</head><p>There has been much work on multivariate Hawkes process (e.g., <ref type="bibr" target="#b30">Zhou et al., 2013;</ref><ref type="bibr" target="#b3">Bacry et al., 2013;</ref><ref type="bibr" target="#b6">Chen et al., 2017)</ref>, and models for the conditional intensity can be generally expressed as</p><formula xml:id="formula_20">λ i (t|G , H t ) = µ i + m j=1 t jl ∈H j,t ζ ij (t -t jl ), i = 1, • • • , m,<label>(6)</label></formula><p>where µ i is the background rate at node i and ζ ij (•) is some transfer function between node j and node i. Key differences among existing multivariate Hawkes process models center around</p><formula xml:id="formula_21">constructions of ζ ij (•)'s. A popular modeling strategy is to assume that ζ ij (•) = θ ij f (•; γ), i, j = 1, • • • , m, with some parametric f (•; γ). Such a model involves a total of O(m 2 ) parameters,</formula><p>limiting its suitability to applications with a relatively small m (e.g., <ref type="bibr" target="#b3">Bacry et al., 2013)</ref>. When modeling a large network, one needs to impose some sparse structure on θ ij 's, in which case a nonzero θ ij implies that node i is directly influenced by node j, and estimated θ ij 's may help recover the latent network structure (e.g., <ref type="bibr" target="#b25">Xu et al., 2016;</ref><ref type="bibr" target="#b2">Bacry et al., 2020)</ref>. While most work in this line lack rigorous theory, there has been some recent theoretical studies of such models when m is diverging, see, e.g., <ref type="bibr" target="#b11">Hansen et al. (2015)</ref>, <ref type="bibr" target="#b6">Chen et al. (2017)</ref> and <ref type="bibr" target="#b4">Cai et al. (2020)</ref>.</p><p>There is also a large body of literature on the identification of network node clusters (e.g., <ref type="bibr" target="#b29">Zhao et al., 2012;</ref><ref type="bibr" target="#b1">Amini et al., 2013)</ref>, which is commonly referred to as "community detection". We remark that the concept of "community" in the community detection literature is fundamentally different from the "groups" in the proposed GNHP model. In community detection, the network adjacent matrix A is assumed to be a random matrix consisting of Bernoulli random variables, and the identification of node communities c critically depends on the conditional probability P (A|c). However, the adjacent matrix A in the GNHP is considered deterministic and there is no probability associated with it. In contrast, the groups in the GNHP are formed by maximizing the likelihood of event times collected from all network nodes, and nodes in the same group are forced to share similar node-specific characteristics such as µ g i (•)'s and β g i 's. Although some recent works in community detection literature utilize nodal features to help identify communities <ref type="bibr" target="#b26">(Yan and Sarkar, 2021;</ref><ref type="bibr" target="#b28">Zhang et al., 2021;</ref><ref type="bibr" target="#b24">Weng and Feng, 2022)</ref>, the central piece of these models remains to be P (A|c). The difference is most manifested in the extreme case when all nodes are isolated from each other (i.e., A consists of all 0's), while the GNHP is still valid by manually setting ϕ g i g j 's as 0, the community detection can no longer be performed since there is no network anymore. We note another recent work <ref type="bibr" target="#b16">Matias et al. (2018)</ref> also considers latent group structures when extending the stochastic block model for recurrent interaction events in continuous time.</p><p>The key difference between their work and ours lies in that they require that each observed event time is associated with a label indicating this event is an interaction between which two nodes.</p><p>However, such information is not available in event times modeled by the GNHP, which instead focuses on modeling events that occur on individual nodes but may have some correlations. In fact, as suggested by the branching structure in Section 2.3, identifying the triggering source of an event in the GNHP is the most challenging task. Similarly, in the extreme case when there are only self-activities on each node but no interaction between any pair of nodes, <ref type="bibr" target="#b16">Matias et al. (2018)</ref> is not applicable but the GNHP model remains valid with ϕ g i g j 's set to 0.</p><p>The second line of research focuses on analyzing the network activities through parameterizations utilizing a known network structure, (e.g., <ref type="bibr" target="#b9">Fox et al., 2016;</ref><ref type="bibr" target="#b7">Farajtabar et al., 2017;</ref><ref type="bibr" target="#b27">Zarezade et al., 2018)</ref>. For instance, <ref type="bibr" target="#b9">Fox et al. (2016)</ref> models email communications in a network by assuming</p><formula xml:id="formula_22">ζ ij (t) = θ i a ij γ i exp(-γ i t)</formula><p>, where θ i 's and γ i 's are unknown parameters. As a result, the total number of unknown parameters is reduced to O(m). Similar but more complex models were studied in <ref type="bibr" target="#b7">Farajtabar et al. (2017)</ref> and <ref type="bibr" target="#b27">Zarezade et al. (2018)</ref>.</p><p>Our proposed GNHP model falls into the second line of research with four distinct features: the latent group structure imposed on network nodes not only accounts for commonly observed network heterogeneity in a natural way but also effectively reduces the number of parameters.</p><p>(d) the estimated group memberships for network nodes may provide further insights on the network activities using various influence measures discussed in Section 2.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MODEL ESTIMATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Background Intensity Approximation</head><p>As illustrated in Figure <ref type="figure" target="#fig_0">1</ref>, human activities such as social media posting often exhibit periodic patterns. We, therefore, assume that the background intensity of a given node takes a periodic form, for which there exists a finite ω &gt; 0 such that µ g</p><formula xml:id="formula_23">(t) = µ g (t + lω), t ∈ [0, T -lω], l = 0, 1, 2, • • • , for any g ∈ [G].</formula><p>For our motivating example, it is natural to choose ω = 1 day (or 24 hours) to account for daily posting behaviors. Without assuming a restrictive parametric form for µ g (•)'s, we approximate µ g (•) using periodic splines. Let</p><formula xml:id="formula_24">k n kt (•) = (k 1 (•), • • • , k n kt (•)) ⊤</formula><p>be a collection of basis functions defined on [0, ω] and</p><formula xml:id="formula_25">x n kt (t) = √ n kt k n kt (t -⌊t/ω⌋ω) for any t ∈ [0, T ],</formula><p>where ⌊a⌋ is the largest integer less than or equal to a, then µ g (•) is approximated by</p><formula xml:id="formula_26">µ g (t) = w ⊤ g x n kt (t), t ∈ [0, T ],<label>(7)</label></formula><p>where w g , g ∈ [G], are the coefficient vectors that need to be estimated. For our theoretical investigation, we require the following assumption for the spline basis functions.</p><p>Assumption 2. Assume that there exists a constant R &gt; 0 such that k</p><formula xml:id="formula_27">1 (•), • • • , k n kt (•) satisfy: (a) ∥k j (•)∥ ∞ ≤ R and ω 0 |k j (t)|dt = O(n -1 kt ); (b) ω 0 |k j (t)k j+l (t)|dt = O(n -1 kt ), and k j (t)k j+l (t) = 0 for l &gt; J and any t ∈ [0, ω],</formula><p>where J ≥ 0 is a finite integer. Denote by µ 0 g (•) the true background function of group g, and assume that for some constant ν &gt; 0, it holds that</p><formula xml:id="formula_28">max 1≤g≤G inf wg∈R n kt ,∥wg∥∞≤R/ √ n kt µ 0 g (•) -w ⊤ g x n kt (•) ∞ = O(n -ν kt ). (<label>8</label></formula><formula xml:id="formula_29">)</formula><p>Assumption 2 requires that the true background intensity functions can be approximated sufficiently well by a linear combination of spline basis functions, which is mild for many spline families. In our numerical examples, we choose</p><formula xml:id="formula_30">k 1 (•), • • • , k n kt (•)</formula><p>as the rth-order B-spline basis functions with equally spaced knots on [0, ω], which meet Assumption 2 <ref type="bibr" target="#b31">(Zhou et al., 1998)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Maximum Likelihood Estimation</head><p>For any g ̸ = g ′ , denote W ⊂ R n kt , Θ ⊂ R +3 and Φ ⊂ R + as the parameter spaces for parameters in w g , θ g = (β g , η g , γ g ) ⊤ , and ϕ gg ′ 's, respectively. Here</p><formula xml:id="formula_31">R + denotes [0, ∞). Denote by G ≡ [G] m</formula><p>as the parameter space for the membership vector</p><formula xml:id="formula_32">G = (g 1 , • • • , g m ) ⊤ .</formula><p>For our theoretical investigation, we impose the following assumption on the parameter spaces.</p><formula xml:id="formula_33">Assumption 3. There exist R &gt; 0, C &gt; 0 such that (a) sup w∈W ∥w∥ ∞ ≤ R/ √ n kt and inf w∈W inf t∈[0,T ] w ⊤ x n kt (t) ≥ C; (b) sup θ∈Θ ∥θ∥ ∞ ≤ R; and (c) sup ϕ∈Φ |ϕ| ≤ R. Let N i = {j : a ij = 1} be the set of d i neighboring nodes of node i, G i = (g j 1 , • • • , g j d i ) ⊤</formula><p>be the corresponding group membership vector of all nodes in N i , and the re-scaled interaction</p><formula xml:id="formula_34">parameter φ g i ,G i = d -1/2 i (ϕ g i g j 1 , • • • , ϕ g i g j d i ) ⊤ , i = 1, • • • , m. The term d -1/2 i in φ g i ,G i is convenient</formula><p>for our theoretical study but is of no practical importance. We can see that the conditional intensity (2) of node i only depends on w ⊤ g i x n kt (•), θ g i and φ g i ,G i , and hence can be rewritten as <ref type="formula">9</ref>)</p><formula xml:id="formula_35">λ i (t|w g i , θ g i , φ g i ,G i , H t ) = w ⊤ g i x n kt (t) + β g i t ik ∈H i,t f b (t -t ik ; η g i ) + m j=1 a ij ϕ g i g j d i t jl ∈H j,t f b (t -t jl ; γ g i ), (</formula><formula xml:id="formula_36">for i = 1, • • • , m. Denote the parameter vectors w = (w ⊤ 1 , • • • , w ⊤ G ) ⊤ ∈ W G , θ = (θ ⊤ 1 , • • • , θ ⊤ G ) ⊤ ∈ Θ G , and ϕ = (ϕ 11 , • • • , ϕ 1G , ϕ 21 , • • • , ϕ G,G ) ⊤ ∈ Φ G 2 .</formula><p>Consequently, the scaled log-likelihood function (divided by mT ) of the proposed GNHP can be shown to have the form</p><formula xml:id="formula_37">ℓ(w , θ , ϕ , G |H T ) = 1 m m i=1 ℓ i (w g i , θ g i , φ g i ,G i |H T ), where<label>(10)</label></formula><formula xml:id="formula_38">ℓ i (w g i , θ g i , φ g i ,G i |H T ) = 1 T n i k=1 log λ i (t ik |w g i , θ g i , φ g i ,G i , H t ik ) - T 0 λ i (t|w g i , θ g i , φ g i ,G i , H t )dt .</formula><p>For ease of presentation, from now on, we denote ψ = (w ⊤ , θ ⊤ , ϕ ⊤ , G ⊤ ) ⊤ and the MLE of the parameters are then obtained by</p><formula xml:id="formula_39">ψ ≡ w ⊤ , θ ⊤ , ϕ ⊤ , G ⊤ ⊤ = argmax w ,θ ,ϕ ,G ℓ w , θ , ϕ , G |H T , where G = ( g 1 , . . . , g m ) ⊤ . (<label>11</label></formula><formula xml:id="formula_40">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">An EM Algorithm</head><p>Direct maximization of ( <ref type="formula" target="#formula_37">10</ref>) is a non-concave problem with a large number of parameters, which can be computationally challenging. In this subsection, we propose a more efficient algorithm by taking advantage of the branching structure given in Section 2.3.</p><p>For the kth event of node i that occurs at time t ik , define Z ik = (j, l), where j = l = 0 indicates a parent event, and otherwise means the kth event is triggered by the lth event from node j at time t jl . Given</p><formula xml:id="formula_41">Z i = (Z i1 , • • • , Z in i ) ⊤ ,</formula><p>event times of node i can be categorized as:</p><p>1. Parent events with Z ik = (0, 0), which constitute a realization of a Poisson process on [0, T ] with an intensity µ g i (•). The log-likelihood can then be written as</p><formula xml:id="formula_42">ℓ (1) br,i (w g i |H T , Z i ) = n i k=1 I [Z ik = (0, 0)] log w ⊤ g i x n kt (t ik ) - T 0 w ⊤ g i x n kt (t) dt.<label>(12)</label></formula><p>2. All t ik 's triggered by a past event of node i, i.e., Z ik = (i, l) for some 1 ≤ l &lt; k, which form a realization of a Poisson process on [t il , T ] with an intensity</p><formula xml:id="formula_43">β g i f b (t -t il ; η g i ) for any t ∈ [t il , T ].</formula><p>The joint log-likelihood of all such events is of the form</p><formula xml:id="formula_44">ℓ (2) br,i (β g i , η g i |H T , Z i ) = n i -1 l=1 n i k=l+1 I [Z ik = (i, l)] log [β g i f b (t ik -t il ; η g i )] -β g i T t il f b (t -t il ; η g i )dt .(13)</formula><p>3. All t ik 's triggered by a past event of a node j ∈ N i , i.e., Z ik = (j, l) for some 1 ≤ l &lt; n j and j ∈ N i , which form a realization of a Poisson process on [t jl , T ] with an intensity</p><formula xml:id="formula_45">d -1 i ϕ g i g j f b (t -t jl ; γ g i ) for any t ∈ [t jl , T ].</formula><p>The joint log-likelihood of all such events becomes</p><formula xml:id="formula_46">ℓ (3) br,i γ g i , φ g i ,G i |H T , Z i = j∈N i n j l=1 n i k=1 I [Z ik = (j, l)] log ϕ g i g j d i f b (t ik -t jl ; γ g i ) - ϕ g i g j d i T t jl f b (t -t jl ; γ g i )dt .<label>(14)</label></formula><p>Consequently, when</p><formula xml:id="formula_47">Z = (Z ⊤ 1 , • • • , Z ⊤ m )</formula><p>⊤ is observed, by the branching structure given in Section 2.3, the complete log-likelihood for the proposed GNHP is then of the form</p><formula xml:id="formula_48">ℓ br ψ |H T , Z = m i=1 ℓ (1) br,i (w g i |H T , Z i ) + ℓ (2) br,i (β g i , η g i |H T , Z i ) + ℓ (3) br,i γ g i , φ g i ,G i |H T , Z i . (<label>15</label></formula><formula xml:id="formula_49">)</formula><p>The MLE (11) can then be obtained by an EM algorithm using the complete likelihood ( <ref type="formula" target="#formula_48">15</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Selection of Number of Groups</head><p>Denote the true number of latent groups as G 0 . Theorems 2-4 in Section 4 suggest that under suitable conditions the MLE of model parameters are consistent for their theoretical counterparts and all node memberships can be correctly estimated as long as G ≥ G 0 . However, according to Theorem 5, the asymptotic normality of θ and ϕ depends on the assumption that G = G 0 .</p><p>Therefore, it is of practical interest to develop a data-driven criterion to determine G 0 .</p><p>With a slight abuse of notation, we denote w (G) , θ</p><formula xml:id="formula_50">(G) , ϕ (G)</formula><p>, G (G) as the MLE obtained in (11)</p><p>for a given G. We consider the following likelihood based criterion function,</p><formula xml:id="formula_51">LIC(G) = ℓ w (G) , θ (G) , ϕ (G) , G (G) |H T -λ mT G,<label>(16)</label></formula><p>where ℓ(•|H T ) is as defined in (10) and λ mT &gt; 0 is a tuning parameter depending on m and T . The optimal G is selected by G = arg max G LIC(G). If λ mT satisfies the rate condition in Theorem 3, then under suitable conditions, one can select G = G 0 with probability tending to 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">THEORETICAL PROPERTIES</head><p>We now investigate the asymptotic properties of the MLE (11). Denote µ 0 g (•) as the true background intensity of group g and µ</p><formula xml:id="formula_52">* g (•) = w * ⊤ g x n kt (•) as the best spline approximation to µ 0 g (•) with w * g = argmin w∈W ∥w ⊤ x n kt (•) -µ 0 g (•)∥ ∞ , g ∈ [G]. By Assumption 2, one has that max 1≤g≤G ∥µ * g (•) -µ 0 g (•)∥ ∞ = O(n -ν kt ). (<label>17</label></formula><formula xml:id="formula_53">) Denote β 0 g , γ 0 g , ϕ 0 gg ′ as the true values of β g , γ g , ϕ gg ′ respectively, for g ′ ̸ = g, g, g ′ ∈ [G]. Let G 0 = (g 0 1 , • • • , g 0 m )</formula><p>⊤ be the true membership vector, where g 0 i ∈ [G 0 ]. Note that G and G 0 may be different in our theoretical framework. Correspondingly, θ 0 , ϕ 0 , G 0 i , and φ 0</p><formula xml:id="formula_54">g 0 i ,G 0 i , i = 1, • • • , m,</formula><p>are defined by replacing parameters with the true values in their definitions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Technical Assumptions</head><formula xml:id="formula_55">Denote ψ = (w ⊤ , θ ⊤ , ϕ ⊤ , G ⊤ ) ⊤ and define the function ℓ(ψ ) = E[ℓ(ψ |H T )], which is of the form ℓ(ψ ) = 1 m m i=1 ℓ i (w g i , θ g i , φ g i ,G i ), and ℓ i (w g i , θ g i , φ g i ,G i ) = E ℓ i (w g i , θ g i , φ g i ,G i |H T ) . (<label>18</label></formula><formula xml:id="formula_56">)</formula><p>Denote by</p><formula xml:id="formula_57">ψ i = (w ⊤ , θ ⊤ , φ ⊤ i ) ⊤ , ψ * i = w * ⊤ g 0 i , θ 0⊤ g 0 i , φ 0⊤ g 0 i ,G 0 i ⊤</formula><p>, and a parameter space</p><formula xml:id="formula_58">Ω i = {ψ i ∈ W × Θ × Φ i } with Φ i = {ϕ/ √ d i : ϕ ∈ Φ} d i .</formula><p>To establish the parameter estimation consistency, we require the following assumptions.</p><p>Assumption 4. There exist a sequence τ m &gt; 0 and a constant C 1 &gt; 0 such that for sufficiently large T , it holds that inf</p><formula xml:id="formula_59">ψ i ∈Ω i ℓ i (ψ * i ) -ℓ i (ψ i ) ≥ min{ ∥ψ * i -ψ i ∥ 2 τm , C 1 } for any i = 1, • • • , m.</formula><p>Assumption 5. The functions ℓ i (w, θ, φ i )'s are Lipschitz continuous in the sense that there exist</p><formula xml:id="formula_60">a constant M &gt; 0 such that sup 1≤i≤m sup w,w ′ ∈W,θ,θ ′ ∈Θ,φ i ,φ ′ i ∈Φ i |ℓi(w,θ,φ i )-ℓ i (w ′ ,θ ′ ,φ ′ i )| ∥w-w ′ ∥ 2 +∥θ-θ ′ ∥ 2 +∥φ i -φ ′ i ∥ 2 ≤ M . Assumption 6. There exists a c 0 &gt; 0 such that inf g̸ =g ′ ∈[G 0 ] w * g -w * g ′ + θ 0 g -θ 0 g ′ &gt; c 0 . Assumption 7. Define π g,m = 1 m m i=1 I(g 0 i = g) and π gg ′ ,m = 1 m m i=1 1 d i j∈N i I(g 0 i = g, g 0 j = g ′ ), g, g ′ ∈ [G 0 ].</formula><p>Assume that as m → ∞, π g,m → π g and π gg ′ ,m → π gg ′ and that there exists a con-</p><formula xml:id="formula_61">stant c π &gt; 0 such that min g,g ′ ∈[G 0 ] min{π g , π gg ′ } ≥ c π .</formula><p>Assumption 4 is a condition to ensure the identifiability of model parameters, which essentially requires two things: (1) ψ * i is a global maximizer ℓ i (ψ i ), and ℓ i (ψ * i ) is at least C 1 greater than the function values at other local maximizers;</p><p>(2) ℓ i (ψ i ) is locally concave in a neighborhood of ψ * i , where it holds that λ min (-li (ψ i )) ≥ 2τ -1 m with li (•) being the negative hessian matrix of ℓ i (•). To see the second part, note that a second order Taylor expansion of ℓ i (ψ i ) around</p><formula xml:id="formula_62">ψ i = ψ * i yields that ℓ i (ψ * i ) -ℓ i (ψ i ) ≈ -1 2 (ψ i -ψ * i ) ⊤ li (ψ ′ i ) (ψ i -ψ * i ) for some ψ ′ i in a neighborhood of ψ * i .</formula><p>To further justify part (2), some straightforward calculation yields that</p><formula xml:id="formula_63">-li (ψ * i ) ≈ H iT (ψ * i ) = E 1 T T 0 λi (t|ψ * i ,Ht) λ⊤ i (t|ψ * i ,Ht) λ i (t|ψ * i ,Ht) dt , where λi (•|ψ i , H t ) = ∂λ i (•|ψ i , H t )/∂ψ i .</formula><p>By definition, H iT (ψ i ) is a positive semi-definite matrix of dimension n kt + d i + 3, whose upper left n kt × n kt submatrix is a banded matrix due to Assumption 2. Therefore, λ min (H iT (ψ i )) is mainly determined by d i , and may approach 0 when d i diverges. To account for the case that the network becomes denser (d i 's increase), we allow for τ m → ∞ at a slow rate as m, T increases in later theoretical discussions. In Section B.1 of the supplementary material, we provide some empirical evidence for Assumption 4 by simulation.</p><p>Assumption 5 imposes a smoothness condition on the expected node-wise log-likelihood, which is reasonable for the problem under consideration. Assumption 6 asserts that at least one of the background intensity or the node-specific parameter vector are well-separable between any two latent groups, which is a reasonable assumption for a wide range of applications such as the social network data studied in Section 6. Finally, Assumption 7 requires that there is a sufficient number of nodes in each latent group and that there is a sufficient number of connected nodes between any two different latent groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Model Estimation Consistency When G ≥ G 0</head><p>The membership estimation accuracy when G ≥ G 0 is evaluated by the following measure</p><formula xml:id="formula_64">ρ mT = 1 m G g=1 m i=1 I i ∈ C g , g 0 i ̸ = χ(g) ,<label>(19)</label></formula><p>where </p><formula xml:id="formula_65">χ(g) = arg max g ′ ∈[G 0 ] m i=1 I i ∈ C g , g 0 i = g ′</formula><formula xml:id="formula_66">b(n kt + d) log(mT )[log(max{b, n kt , log(mT )})] 3 ; (b). 1 m m i=1 ∥ µ g i (•) -µ 0 g 0 i (•)∥ T = O p e 1/6 mT + τ 1/2 m e 1/4 mT + n -ν kt , where g i is the estimated member- ship of node i, i = 1, • • • , m, and µ g (•) = w ⊤ g x n kt (•) for g ∈ [G]; (c). 1 m m i=1 θ g i -θ 0 g 0 i + 1 m ∥ B -B 0 ∥ 1 = O p e 1/6 mT + τ 1/2 m e 1/4</formula><p>mT , where B and B 0 are the estimated/true B in Assumption 1, respectively.</p><p>The proof is given in the Supplementary Material.</p><p>Theorem 2 asserts that even if G is over-specified, both the clustering error ρ mT and the parameter estimation errors converge to 0, and the convergence rate is primarily determined by T rather than the number of nodes m. The convergence rates are also negatively impacted by large values of b and d, where the former is the triggering function range that controls the strength of serial dependence among offspring of the same parent, and the latter represents the level of connectivity among network nodes. Furthermore, the quantity τ m in Assumption 4 is also affected by d i 's and may also grow as the network becomes denser, leading to a slower convergence rate.</p><p>Particularly, it is of important practical interest to consistently estimate the transition matrix B 0 , since the estimator B can be used to study the network interactions following Section 2.3.</p><p>We remark that Theorem 2 is unlikely to hold when G &lt; G 0 , in which case nodes from different groups are forced into the same group, resulting in biased parameter estimators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Selection Consistency of Number of Groups</head><p>In this subsection, we study the selection consistency of the LIC criterion proposed in (16). To this end, we show in the following Theorem that G selected by maximizing LIC estimates G 0 consistently when the penalty parameter λ mT is appropriately chosen. </p><formula xml:id="formula_67">b(n kt + d) log(mT )[log(max{b, n kt , log(mT )})] 3 = o(1), then P ( G = G 0 ) → 1.</formula><p>The proof is given in the Supplementary Material.</p><p>Theorem 3 requires that λ mT converges to zero but not too fast. In our numerical examples, we set λ mT = (15T ) -1 (median 1≤i≤m n i ) 0.6 d0.25 and verify its finite sample performances in details in Section 5. Such a choice ensures that G does not depend on the unit of T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Convergence Rates and Asymptotic Normality When G = G 0</head><p>We now study the convergence rates and asymptotic normality of the model parameter estimators when G = G 0 , which requires some modifications of the MLE (11) as follows.</p><p>Membership refinements. The MLE (11) maximizes the overall log-likelihood function (10), but not necessarily each node-specific likelihood</p><formula xml:id="formula_68">ℓ i w g , θ g , φ g,G i |H T , i = 1, • • • , m.</formula><p>As a result, if ℓ i w g i , θ g i , φ g i , G i |H T is too low for some i, its membership estimate g i may be incorrect. To address this issue, we propose a membership refinement strategy. One way to check whether g i results in a too small ℓ i w g i , θ g i , φ g i , G i |H T is to compare it to the profile likelihood</p><formula xml:id="formula_69">ℓ p i (g|H T ) = sup φ i ∈Φ i ℓ i w g , θ g , φ i |H T .</formula><p>If for some g such that ℓ p i ( g|H T ) is much greater than</p><formula xml:id="formula_70">ℓ i w g i , θ g i , φ g i , G i |H T ,</formula><p>it may be a sign to relabel the node i to group g. Furthermore, instead of maximizing over all φ i ∈ Φ i , our theoretical investigation suggests that, for any given g, it suffices to define the profile likelihood function as ℓ p i (g|H T ) = ℓ i w g , θ g , φ p i (g)|H T , where</p><formula xml:id="formula_71">φ p i (g) = argmax φ i ∈{ φ g ′ ,G i :g ′ ∈[G],G i ∈[G] d i } ℓ i w g , θ g , φ i |H T , for g ∈ [G].</formula><p>Denote g † i = argmax 1≤g≤G ℓ p i (g|H T ). The refined membership of node i is then defined as</p><formula xml:id="formula_72">g r i =    g i , if ℓ p i ( g † i |H T ) -ℓ i w g i , θ g i , φ g i , G i |H T ≤ 0, g † i , if ℓ p i ( g † i |H T ) -ℓ i w g i , θ g i , φ g i , G i |H T &gt; 0.<label>(20)</label></formula><p>With this modification, we define the estimated groups C r g = {i : 1 ≤ i ≤ m, and g r i = g}, g ∈ [G], and the true groups C 0 g ′ = {i : 1 ≤ i ≤ m, and</p><formula xml:id="formula_73">g 0 i = g ′ }, g ′ ∈ [G 0 ]. When G = G 0 , a</formula><p>stronger version of Theorem 2 can be established as following.</p><p>Theorem 4. Assume G = G 0 , Assumptions 1-7, and that τ 2 m x mT = o(1) with x mT as defined in Theorem 2. Then, as m, T → ∞, it holds that (a). sup 1≤i≤m µ g r i (•) -µ 0</p><formula xml:id="formula_74">g 0 i (•) T + θ g r i -θ 0 g 0 i = O p (x 1/3 mT + τ m x 1/2 mT + n -ν kt ) where g r i is the estimated membership of node i after refinement, i = 1, • • • , m; (b). if we further assume that τ 4 m x mT = o(1), then for each g ∈ [G], there exists g ′ ∈ [G 0 ] such that P ( C r g = C 0 g ′ ) → 1 as m, T → ∞.</formula><p>The proof is given in the Supplementary Material.</p><p>Theorem 4 (a) states that when G = G 0 , the background intensity µ 0 g i (•) and the node-specific parameters θ 0 g 0 i can be consistently estimated for all network nodes. Theorem 4 (b) shows that, after some label permutation, all nodal memberships can be correctly identified with a probability tending to 1, which is crucial to establishing asymptotic normality of the parameter estimators.</p><p>Denote the refitted estimator</p><formula xml:id="formula_75">w r⊤ , θ r⊤ , ϕ r⊤ ⊤ = argmax w ,θ ,ϕ ℓ(w , θ , ϕ , G r |H T ) with G r = ( g r 1 , g r 2 , • • • , g r m )</formula><p>⊤ being the refined membership estimator. Due to Theorem 4 (b), for ease of presentation, we drop the notation G 0 whenever there is no ambiguity. In particular, the model parameters that need to be estimated become ψ = (w ⊤ , θ ⊤ , ϕ ⊤ ) ⊤ , whose true values are ψ * = (w * ⊤ , θ 0⊤ , ϕ 0⊤ ) ⊤ . For any given ψ , we view the conditional intensity function ( <ref type="formula">9</ref>) as a function of ψ and denote it as λ i (t|ψ , H t ) for any t ∈ [0, T ] and i = 1, • • • , m. Define the matrix</p><formula xml:id="formula_76">H mT (ψ ) = 1 mT m i=1 T 0 E λi (t|ψ , H t ) λ⊤ i (t|ψ , H t ) λ i (t|ψ , H t ) dt,<label>(21)</label></formula><p>where λi (</p><formula xml:id="formula_77">•|ψ , H t ) = ∂λ i (•|ψ , H t )/∂ψ , i = 1, • • • , m.</formula><p>To establish the asymptotic normality result, we assume the following condition for H mT (ψ ).</p><p>Assumption 8. There exist positive constants ϵ, τ min , τ max such that for any ∥ψ -ψ * ∥ ≤ ϵ, one has that λ min H mT (ψ ) ≥ τ min and λ max H mT (ψ ) ≤ τ max for sufficiently large m, T .</p><p>Lemma D.7 in the Supplementary Material shows that, under suitable conditions, H mT (ψ ) is asymptotically equivalent to the negative Hessian matrix of ℓ(ψ ) in ( <ref type="formula" target="#formula_55">18</ref>). Therefore, Assumption 8 essentially assumes that ℓ(ψ ) is locally concave in a neighborhood of ψ * , which is a mild assumption similar to Assumption 4. In Section B.2 of the supplementary material, we provide more discussions on Assumption 8 through some simulation studies.</p><p>The following theorem establishes the convergence rates of the background intensity estimators and the asymptotic normality of the model parameters.</p><p>Theorem 5. Assume Assumptions 1-8 and and that τ 2 m x mT = o(1) with x mT as defined in Theorem 2. Then if G = G 0 , the following holds.</p><p>(a). If n kt / √ mT = o(1) and ν &gt; 1/2, then as m, T → ∞, one has that</p><formula xml:id="formula_78">max 1≤g≤G µ r g (•) -µ 0 g (•) T = O p n kt /mT + n -ν kt . (<label>22</label></formula><formula xml:id="formula_79">) (b). Denote α r = ( θ r⊤ , ϕ r⊤ ) ⊤ , α 0 = (θ 0⊤ , ϕ 0⊤ ) ⊤ , and let Σ α = lim (m,T )→∞ I α H -1 mT (ψ * )I ⊤ α with I α = (0 (3G+G 2 )×n kt , I (3G+G 2 )×(3G+G 2 ) ). If it further holds that √ mT /n ν kt = o(1), then √ mT α r -α 0 d - → N (0, Σ α ) as m, T → ∞.</formula><p>The proof is given in the Supplementary Material.</p><p>Theorem 5 part (a) gives an upper bound of the convergence rate of the nonparametric background intensity estimators that consists of two parts. The first part n kt /mT is due to the estimation variance, and the second part is introduced by the basis approximation error. Part (b) gives sufficient conditions under which the √ mT -convergence rate for α r and the asymptotic normality can be established. The result is proved by using a martingale central limit theorem <ref type="bibr" target="#b8">(Fleming and Harrington, 2011)</ref>. Particularly it requires that √ mT /n ν kt = o(1) so that the approximation bias is dominated by the estimation variance, a popular strategy used in the nonparametric inference literature. In a simple setting with max{b, τ m , d max } &lt; ∞, Theorem 5 (b) requires n kt to satisfy (mT ) 1/(2ν) ≪ n kt ≪ (T /[log(mT ){log(log(mT ))} 3 ]) 1/(1+δ) for some δ &gt; 0, where a mT ≪ b mT means a mT /b mT → 0 as m, T → ∞. As one can see, a larger ν, which suggests a smoother background intensity, will make the above condition more likely to hold. A plug-in estimator of the covariance matrix Σ α can be constructed straightforwardly using the definition of H mT (ψ * ) in ( <ref type="formula" target="#formula_76">21</ref>) for statistical inferences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Simulation Studies</head><p>In this section, we conduct simulation studies to evaluate the numerical performance of the proposed GNHP model. The following two types of network structures are considered:</p><p>Stochastic Block Model (SBM). This model is widely used in the community detection literature. The network consists of m nodes belonging to 3 blocks and each node is randomly assigned a block label with a probability of 1/3. An edge between two nodes is generated with a probability 0.3m -0.3 if they are in the same block, or with a probability of 0.3m -0.8 otherwise.</p><p>Power-law Network. Such a network resembles the commonly observed social network structure where most nodes have few followers while a small fraction of nodes have a large number of followers. For each node i, the number of randomly picked followers is 4f i , where f i follows the power-law distribution</p><formula xml:id="formula_80">P (f i = f ) = cf -2 , 0 ≤ f ≤ m,</formula><p>where c is the normalizing constant.</p><p>For each type of network, we random assign each node to G 0 = 3 latent groups with group proportions as π m = (π 1,m , π 2,m , π 3,m ) ⊤ = (0.3, 0.4, 0.3) ⊤ . To mimic typical daily activities of social network users, the background intensity of each latent group takes a periodic form</p><formula xml:id="formula_81">µ g (t) = C g Hg h=1 b h,g exp{-(t -a h,g ) 2 /w h,g } g ∈ [G 0 ], t ∈ [0, ω].</formula><p>Triggering functions of all groups are of the form f (t, γ) ∝ γ exp(-γt)1{t ≤ b} with b = 5 hours. Model parameters (except C g 's and b h,g 's) are listed in Table <ref type="table" target="#tab_1">1</ref>, and the true background intensities are illustrated in Figure <ref type="figure" target="#fig_6">3</ref>, which have the same shapes of the estimated background intensities in our Sina Weibo data analysis (see Figure <ref type="figure">7</ref>), where the common period is set as ω = 24 hours and C g is chosen such that ω 0 µ g (t)dt is set at the targeted values in Table <ref type="table" target="#tab_1">1</ref>.</p><p>Background intensity Momentum Network  </p><formula xml:id="formula_82">g ω 0 µ g (t)dt β g η g γ g (ϕ g1 , ϕ g2 , ϕ g3 ) 1 2.5 0.</formula><formula xml:id="formula_83">{ µ (k) g (•), β (k) g , η (k) g , γ (k) g , ϕ (k)</formula><p>gg ′ } and the group membership estimator as</p><formula xml:id="formula_84">C (k) = { g (k) i : 1 ≤ i ≤ m}.</formula><p>The group membership estimation accuracy rate is then computed by GAR= K -1 K k=1 GAR (k)   with GAR</p><formula xml:id="formula_85">(k) = 1 -ρ (k)</formula><p>mT , where ρ</p><formula xml:id="formula_86">(k)</formula><p>mT is obtained by applying (19) to C (k) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Estimation Accuracy When G = G 0</head><p>When G = G 0 , parameter estimation accuracy can be evaluated by the root mean squared error (RMSE) of estimates after some label switching. The estimation accuracy µ g (•) is evaluated by</p><formula xml:id="formula_87">K -1 K k=1 | µ (k) g (t) -µ g (t)|dt.</formula><p>For comparison, we also present the estimation accuracy of the "Oracle" estimator for which the true group memberships of all nodes are known and fixed when finding the MLE. All simulation results are summarized in Figure <ref type="figure" target="#fig_8">4</ref> and Tables <ref type="table">2</ref><ref type="table">3</ref>. From Figure <ref type="figure" target="#fig_8">4</ref>, we observe that the estimated background intensities become closer to the true background intensities as either m or T increases, which supports our theoretical findings in Theorems 2 (b) and 5 (a). Results for the Power-law network are similar and given in Section ?? of the supplementary material. From Tables <ref type="table">2</ref><ref type="table">3</ref>, we can see that when both m and T are small, the group memberships of a proportion of network nodes may be incorrectly estimated in both network settings. However, in all case scenarios, the GARs of the GNHP model are much better than those of the intensity-based K-means algorithm, which is used to provide initial membership estimates for the GNHP estimation, see Section A.2.1 of the supplementary material for details. As m and/or T increases, the GARs of the GNHP gradually approach 1. This is consistent with our theoretical findings in Theorem 4. Consequently, as m or T increases, the estimation accuracy of the model parameters improves steadily and approaches that of the "Oracle" estimator. Overall, the simulation results support the estimation consistency of the proposed GNHP model when the group number G is correctly specified.</p><p>Table 2: Estimation Accuracy of GNHP for SBM network when</p><formula xml:id="formula_88">G = G 0 . m = 100 µ (×10 -3 ) β(×10 -3 ) η (×10 -3 ) γ (×10 -3 ) ϕ (×10</formula><p>-3 ) GAR (s.e.) GAR (s.e.) T GNHP (Oracle) GNHP (Oracle) GNHP (Oracle) GNHP (Oracle) GNHP (Oracle) (GNHP with (Intensity-based g/g ′ ----1 2 3 refinement) K-means) 5ω 1 340 (309) 16.3 (15.9) 199 (189) 212 (189) 29.1 (26) 45.3 (32.1) 29.6 (26.3) 95 (2.3) 53 (5.1) 2 271 (249) 24.7 (22.4) 228 (211) 357 (336) 40.3 (39.3) 55.4 (51.1) 52.8 (48.9) 3 192 (187) 26.5 (25.3) 431 (407) 183 (177) 21.7 (21.2) 34 (32.3) 29.1 (28.7) 10ω 1 229 (228) 10.7 (10.7) 129 (127) 133 (127) 18.3 (17.9) 24.6 (23.2) 19.5 (18.3) 99 (0.93) 59 (4.2) 2 184 (181) 15.4 (15.2) 148 (149) 237 (219) 28.2 (27.6) 35.7 (35.8) 34.4 (33.9) 3 132 (132) 18 (18.4) 283 (284) 110 (109) 14.4 (14.4) 21.4 (21.9) 18.7 (18.5) 20ω 1 165 (164) 7.31 (7.24) 92.7 (92.1) 93.5 (91) 13 (12.3) 15.4 (15.1) 12.3 (11.6) 100 (0.2) 64 (3.0) 2 131 (129) 11.2 (11.7) 95.3 (95.6) 161 (164) 19.1 (19.8) 24.5 (24.3) 24 (24.2) 3 95.8 (96.2) 12.5 (13.4) 207 (212) 78 (78.6) 10.3 (10.2) 15.8 (16) 13.6 (13.1) 40ω 1 126 (126) 5.19 (5.35) 65.6 (63.7) 69.1 (67.2) 9.06 (9.32) 11.1 (11.2) 9.47 (9.66) 100 (0) 66 (2.5) 2 93.8 (93.3) 7.77 (8.21) 66.5 (66.4) 110 (109) 13.3 (13.2) 16.7 (17.4) 15.8 (16.1) 3 69 (69) 8.71 (8.64) 140 (143) 55.1 (54.5) 7.05 (6.96) 11.2 (10.2) 9.49 (9.32) 5ω 1 272 (250) 12.2 (11.2) 148 (133) 218 (199) 36 (26) 29.9 (26.1) 25.3 (22.4) 94 (1.7) 49 (3.2) 2 205 (182) 16.3 (14.3) 141 (129) 257 (236) 27.8 (27.3) 35.4 (32.7) 37.1 (34.7) 3 152 (146) 18.2 (18.1) 307 (293) 144 (141) 18.3 (18) 28.4 (26.6) 20.5 (20) 10ω 1 181 (179) 8.58 (8.4) 99.7 (98.5) 138 (136) 19.2 (18.1) 17.8 (17.4) 17.7 (17.5) 99 (0.72) 55 (3.4) 2 136 (133) 10.5 (10.3) 95.3 (91.8) 167 (166) 19.6 (19.1) 23.9 (23.3) 24.7 (24.4) 3 106 (106) 13.1 (13.3) 196 (190) 98.1 (101) 12.2 (12) 19.3 (19.5) 14.1 (14.2) 20ω 1 133 (133) 5.65 (5.74) 69.5 (67.8) 98.5 (96.5) 12.7 (12.9) 12 (12.3) 11.3 (11.6) 100 (0.17) 64 (4.4) 2 98.7 (97.7) 6.91 (7) 66.2 (68) 115 (115) 12.8 (13.1) 17.2 (17.1) 17.2 (17.4) 3 77 (77.9) 8.81 (8.72) 144 (146) 64.6 (63.4) 8.98 (8.94) 13.7 (13.7) 10 (9.86) 40ω 1 103 (103) 3.99 (4.01) 50.5 (50.1) 69.5 (69.3) 9.17 (9.21) 8.49 (8.44) 8 (7.91) 100 (0) 71 (4.4) 2 72.3 (72.7) 5.01 (5.05) 47.4 (47.5) 82.2 (82.3) 9.37 (9.41) 12.2 (11.9) 12.2 (12.2) 3 56.8 (56.9) 6.33 (6.32) 102 (101) 45.2 (44.7) 6.26 (6.24) 9.47 (9.33) 6.85 (6.77)</p><p>Table 3: Estimation Accuracy of GNHP for Power Law network when G = G 0 . RMSE TABLE, PL setting.</p><formula xml:id="formula_89">m = 100 µ (×10 -3 ) β(×10 -3 ) η (×10 -3 ) γ (×10 -3 ) ϕ (×10 -3 ) GAR (</formula><p>s.e.) GAR (s.e.) T GNHP (Oracle) GNHP (Oracle) GNHP (Oracle) GNHP (Oracle) GNHP (Oracle) (GNHP with (Intensity-based g/g ′ ----1 2 3 refinement) K-means) 5ω 1 395 (349) 17.8 (15.5) 213 (193) 410 (362) 61 (50.4) 43.2 (38.8) 51.5 (46) 93 (2.8) 49 (4.3) 2 340 (290) 23.5 (20.2) 213 (191) 449 (405) 50.4 (46.6) 55.5 (48.4) 74.4 (67.4) 3 240 (231) 26.1 (25.4) 420 (388) 292 (283) 38 (37.8) 46.3 (42.4) 53.8 (51.8) 10ω 1 249 (246) 12.4 (11.8) 140 (135) 237 (225) 32.3 (31.2) 28.8 (25.8) 31.6 (31.5) 99 (1.3) 55 (4.5) 2 208 (202) 15 (14.3) 144 (137) 289 (272) 33.6 (32.7) 35.5 (33.8) 45.4 (45.3) 3 161 (163) 17.2 (17) 296 (279) 153 (159) 26.5 (26) 26.1 (27.3) 34.3 (35.6) 20ω 1 181 (179) 7.5 (8.13) 103 (96.9) 141 (151) 22.4 (22.4) 19.4 (19) 23.2 (22.6) 100 (0.31) 63 (5.6) 2 149 (147) (9.7) 92.2 (91.5) 208 (194) 22.9 (22.4) 22.5 (22.3) 34.7 (33.3) 3 115 (117) 12.5 (12.1) 201 (197) 108 (106) 17.5 (17.8) 18.8 (19.4) 23.7 (24.8) 40ω 1 133 (134) 5.71 (5.63) 70.5 (68.9) 119 (117) 16.2 (16.4) 13.5 (13.9) 16 (15) 100 (0.059) 74 (6.9) 2 107 (106) 6.84 (6.89) 69 (67.7) 137 (137) 16.4 (16.7) 16.5 (16.4) 23.4 (23.8) 3 83.1 (84.7) 9.29 (8.85) 143 (146) 72.9 (73) 12.6 (12.3) 14.2 (13.9) 17.3 (17.7) 5ω 1 296 (254) 12.3 (9.92) 136 (118) 216 (191) 35.2 (25.5) 43.2 (32.1) 32.4 (30.6) 94 (1.9) 51 (3.6) 2 281 (252) 17 (15) 164 (139) 331 (298) 32.1 (30.3) 45.7 (42.5) 56.2 (51) 3 195 (188) 17.7 (17.2) 299 (287) 186 (181) 23 (22.5) 37.5 (37.6) 35.7 (34.1) 10ω 1 191 (187) 7.25 (6.99) 85 (83.3) 137 (133) 20.5 (18.8) 26.2 (23.2) 21.3 (20.6) 99 (0.9) 59 (3.4) 2 186 (181) 10.5 (10.4) 103 (97.4) 212 (202) 21.1 (20.9) 29.5 (29.3) 38.8 (37.5) 3 139 (138) 12.9 (12.8) 214 (209) 117 (118) 16.1 (16.1) 24.8 (24.8) 23.9 (23.7) 20ω 1 138 (137) 4.87 (4.96) 60.1 (58.9) 98.8 (100) 12.2 (12.1) 15.5 (15.9) 14.2 (14.4) 100 (0.2) 67 (3.2) 2 128 (128) 7.43 (7.42) 68.5 (68.9) 146 (146) 14.4 (14.6) 21.7 (21.3) 26 (25.5) 3 99.4 (99.1) 8.7 (8.61) 139 (141) 75.6 (76.7) 11.4 (11.1) 17.7 (18) 16.4 (16.4) 40ω 1 110 (110) 3.23 (3.49) 39.4 (41.6) 82.8 (82.3) 9.34 (9.18) 11.2 (11.3) 10.4 (10.4) 100 (0.027) 75 (4.2) 2 97 (95.3) 5.1 (5.11) 51.3 (49.6) 117 (110) 10.4 (10.5) 15.1 (15) 17.2 (18) 3 72.6 (71.9) 6.09 (6.16) 91.5 (93.9) 52.5 (54) 7.56 (7.8) 11.7 (12.5) 12.2 (11.8)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Coverage Probability When</head><formula xml:id="formula_90">G = G 0</formula><p>We next investigate the quality of statistical inference for the GNHP model by evaluating the coverage probabilities of the 95% confidence intervals for model parameters, derived through the limiting distribution given by Theorem 5 (b). For instance, the 95% confidence interval for β g is given by CI</p><formula xml:id="formula_91">(k) βg = ( β (k) g -1.96 σ (k) βg , β (k) g +1.96 σ (k) βg ), where σ (k)</formula><p>βg is the square root of the corresponding diagonal entry of the estimated covariance matrix Σ α . Empirical coverage probabilities based on 1000 simulation runs are summarized in Table <ref type="table" target="#tab_6">4</ref>.</p><p>Table <ref type="table" target="#tab_6">4</ref> shows that the coverage probabilities have some departure from the nominal 95% when m = 100 and T = 5ω in both network settings, which is not surprising since on average only around 5% and 7% of group memberships are correctly estimated in these two settings. As m and T increase, the empirical coverage probabilities for almost all parameters approach the </p><formula xml:id="formula_92">T β g η g γ g ϕ gg ′ β g η g γ g ϕ gg ′ β g η g γ g ϕ gg ′ β g η g γ g ϕ gg ′ g/g ′ - - - 1 2 3 - - - 1 2 3 - - - 1 2 3 - - - 1 2</formula><p>3 5ω 1 93.8 93.4 91.5 92.1 85.5 91.3 93.3 94.9 91.8 82.2 91.8 93.5 94.4 95.2 93.1 84.8 92.6 84.4 89.2 93.9 90.8 86.8 85.3 92.6 2 91.5 90.6 90.8 93.4 90.6 91.3 90.8 90 92.9 93.3 94.9 92.7 92.6 90.5 92.2 92.2 90.9 93.1 88.9 90.3 91.1 91.6 90.5 91.1 3 95 92.1 93.3 94 92.5 94.4 94.9 93.3 93.1 94.9 94.1 93.7 92.2 95.2 95.7 92.6 91.3 92.2 94.7 94.2 92.1 94.7 91.8 91.6 10ω 1 94.6 95.2 94.8 94.8 92.5 94.4 95.9 94.4 94.4 93 93.2 93.8 94.5 96.2 94.5 91.8 91.2 94 94.5 95.4 94.8 89 93.3 92 2 96 93.7 94.2 91.5 93.5 92.9 94 93.4 94.6 96.5 96.1 94.8 97.3 95.6 94 94 91.2 96.7 95.1 93.6 93.6 92.7 96.3 93.3 3 95.6 95.8 95.4 94.4 96.6 94.4 93.4 94.8 92.6 96.7 93.8 95.7 94 96.7 96.2 92.9 94 92.9 93.3 93.9 93.6 92.7 95.4 95.7 20ω 1 96.6 93.8 94.2 93.4 95.8 96 95.5 95.1 95.5 95.5 95.7 94.6 95 95.6 95 92.5 93.1 95.6 96.6 95.2 92.2 95.2 94.2 95.6 2 93.4 94.8 94.8 95.8 93.8 92.8 95.5 93.6 95.3 96.1 93.8 95.1 92.5 96.2 93.1 94.4 96.2 92.5 96.9 93.5 94.5 95.6 94.5 93.9 3 94.4 93.8 95 93.6 94 93.8 95.1 93.1 95.7 94.2 91.9 94.9 97.5 92.5 91.9 95 95.6 95 91.8 96.6 95.9 95.6 95.6 93.5 40ω 1 95 93.2 94.8 95.8 95.6 95 95.8 93.8 93.4 94 94.8 95.6 93.5 91.6 90.9 93.5 94.8 96.8 95.4 95.4 87.7 92.3 92.8 92.3 2 93.6 95.2 94.4 94 95.6 96 94.2 94.2 94 94.6 95.6 94 92.2 92.9 91.6 92.2 97.4 93.5 95.4 91.3 90.8 92.8 94.9 94.9 3 94.4 94.2 94.4 95.4 93 95.2 93.4 95.4 94 95.6 94.8 94.6 92.2 92.9 96.8 95.5 92.2 94.2 94.4 97.4 91.8 95.4 94.4 94.9</p><p>nominal level, which supports our theoretical findings in Theorem 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Estimation Accuracy with a Mis-specified G</head><p>When G is mis-specified, we define PD To identify the true number of groups, we use λ mT = (15T ) -1 (median 1≤i≤m n i ) 0.6 d0.25 for the LIC in ( <ref type="formula" target="#formula_51">16</ref>), and report the selection error rate as SR(G) = K -1 K k=1 I( G (k) = G), where G (k)   maximizes the LIC in the kth simulation. To study the effect of the membership refinement algorithm in Section 4.4, we also compare the GARs with and without membership refinements.</p><formula xml:id="formula_93">β = median 1≤k≤K 1 m m i=1 β 0 g 0 i -β<label>(k) g (k) i</label></formula><p>In the refinement step, we randomly sample 1, 000 ψ i 's to find the refined membership (20) if the candidate set size exceeds 1, 000.</p><p>Since the refinement step is rather time consuming, especially when G is large, we only provide summary statistics based on K = 200 simulation runs in Table <ref type="table" target="#tab_8">5</ref>, where we can see that even when G is over-specified, the consistency result still holds. For instance, PD β drops from approximately 42.2×10 -3 to 20.5×10 -3 as (m, T ) increases from (100, 5ω) to (200, 10ω) with G = 4, which corroborates with the result in Theorem 2. When G &gt; 3, estimation errors are generally larger than those of the case with G = G 0 , which is reasonable due to the additional estimation variability introduced by an overly large G. Furthermore, the proposed LIC can correctly select the true number of groups with a probability tending to 1 as (m, T ) increases, which supports our conclusion of Theorem 3. Lastly, the GAR after the refinement tends to be slightly better than the GAR without the refinement, suggesting it is beneficial to perform membership refinement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Computation Times</head><p>We now study the computation times of the proposed EM algorithm outlined in Section 3.3. For each initial membership estimate, we perform 100 Stochastic EM iterations, 50 EM iterations with fixed memberships, and then 50 EM iterations. Fixing m = 100, computation times (in seconds)</p><p>of this algorithm on a cluster of Intel Xeon Gold 6126 CPUs with 2.6 Ghz are summarized in Figure <ref type="figure">5</ref>. We can see that the CPU time grows approximately linearly as T and the total number of events increase. The CPU time grows slightly faster than linearly as G increases since the number of parameters is of the order Gn kt + 3G + G 2 . Results are similar for the Power-law Heuristically, T /ω can be roughly interpreted as the number of weakly dependent replicates over time and Gn kt T /ω can be viewed as the total number of knots placed over [0, T ] and G groups. Fixing G = 4, Figure <ref type="figure">7</ref> shows that the minimum BIC value is achieved with n kt = 6.</p><p>The estimated background intensities using n kt = 6 and G = 4 are illustrated in Figure <ref type="figure">7</ref> and the resulting parameter estimates are summarized in Table <ref type="table" target="#tab_9">6</ref>. Figure <ref type="figure">7</ref> shows that all estimated background intensities have two peaks around 10:00 am and 8:00 pm, suggesting that users are more active around these times. Based on the estimated GNHP model and users' information in the different groups, we summarize groups as following.</p><p>• Group 1 is largest group that includes 49.8% of users, who have the lowest background intensity throughout the day. Judging from ϕ g1 's, users from this group have relatively low impact on users from other groups. This group also has the largest η value, suggesting that the user's past posts have the shortest time impacts on his/her future posting behavior.</p><p>• Group 2 include many users that are playing leading roles in various communities such as entertainment, business, education, and social sciences, who typically do not post very frequently throughout the day. This group has the second smallest η value, indicating that users' past posts have a relatively long time effect. The estimated ϕ g2 's suggests that this group of users have the largest impacts on all groups except Group 3. Our subsequent analysis in Section 6.2 reveals that this group is the second most influential group.</p><p>• Group 3 mainly contains official accounts of some news outlets. Figure <ref type="figure">7</ref> shows that this group is the most active one on average, which is probably due to their mission to deliver information promptly. It has the smallest η, suggesting the longest temporal dependence on the posting histories. At the same time, it has an extremely large γ, which indicates that this group is very unlikely to be influenced by past posts from other groups. Although the estimated ϕ g3 's are not as large as those of Group 2, the largest background intensity of this group makes it the most influential group, as we shall demonstrate in Section 6.2.</p><p>• Group 4 consists of users who post quite frequently as suggested by Figure <ref type="figure">7</ref> but have rather limited impacts on other groups based on the estimated ϕ g4 's. It has a large ϕ 42 = 0.147, indicating that users in this group are heavily influenced by users in Group 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Group Interaction and Influential User Analysis</head><p>In social network analysis, identifying influential users is an important task, as it may help improve the efficiency of news propagation, product release, and promotional campaign launches.</p><p>To identify the most influential users, we first define the influential power of the user i as the sum of the ith column of (I -B) -1 , which is the Node-to-network influence given by Theorem 1. The bar plots of users with top 20 and 100 influential powers are illustrated in Figure <ref type="figure" target="#fig_10">8</ref>, which shows that top 20 influential users only consist of members from Groups 2 and 3, with the latter group being the most influential one. This observation is further confirmed in the barplot of the top 100 influential users, where the majority of users are from Groups 2 and 3.</p><p>To shed more light on interactions among different groups, Figure <ref type="figure" target="#fig_10">8</ref> gives impact curves of each group on the other groups as defined in (5). As expected, both Groups 1 and 4 have rather limited impacts on other groups throughout the day. It appears that the most influential Group 3 has the largest impact on the Group 2, suggesting that users in Group 2 may have the greatest need for timely information provided by users in Group 3. Group 4 is impacted more heavily than Group 1 by Group 3, probably because users in Group 4 are relatively more active and hence can react to information from Group 1 more quickly. Lastly, the impact of Group 3 on Groups 1 and 4 are rather similar, an interesting phenomenon that may require a deeper look. Overall, the influence power plots and impact curve plots reveal some interesting interactive patterns among social network users, suggesting potential usefulness of the proposed GNHP model.</p><p>Finally, in Section B.5 of the supplementary material, we show the differences between groups obtained from GNHP and some simple alternative algorithms. More importantly, we remark that GNHP provides numerical quantification of user influence powers while others cannot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">DISCUSSION</head><p>We propose a group network Hawkes process (GNHP) that is suitable for analyzing the dynamic behavior patterns of heterogeneous users in a large network. The GNHP model extends the classical Hawkes model by utilizing the network structure and introduces a latent group structure to account for heterogeneity among network users. Theoretical properties are thoroughly investigated and a computationally efficient EM algorithm is proposed. The GNHP is highly interpretable, as we have demonstrated through an application to a Sina Weibo dataset.</p><p>The proposed model is suitable for abundant applications such as crime pattern analysis and financial risk management, as long as the network structure can be identified. Several research topics can be pursued for future studies. First, in many applications, the background intensities may be more complicated with multi-scale seasonalities such as daily, weekly, and annual seasonalities, in which case we can consider an additive background intensity µ(t) = J j=1 µ g,j (t -⌊t/ω j ⌋ω j ) with an increasing ω 1 &lt; ω 2 &lt; • • • &lt; ω J and each µ g,j can be approximated by periodic splines. An alternative remedy is to introduce some time-dependent covariates such as "day of the week" or categorical variables such as "weekend or not?" and "holiday or not?". Our theory can be easily modified for both extensions. One can further introduce user-specific covariates such as "age", "gender" and "occupation" into the background</p><p>intensities, but such extensions require non-trivial modifications of the current theory. Second, it will also be interesting to find a data-driven method to detect the period parameter ω if it is unknown. Next, while we have only considered one type of user behavior, it would be interesting to incorporate multi-type user behaviors into the model for analyzing data collected from a social network with more complicated structures. Finally, the network structure in the current framework is assumed to be known and fixed. It is also of great interest to extend the current model to be suitable for networks whose topological structures are evolving over time.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Left: histogram of users' post counts. Middle: estimated overall intensity function of all users' posting times. Right: QQ-plot of gap times among friends and among random picked non-friends.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><figDesc><ref type="bibr" target="#b13">Hawkes and Oakes (1974)</ref> provides an equivalent branching structure representation for the classical Hawkes process (1), which classifies the observed events into two disjoint processes: a parent Poisson process with a rate µ, and offspring processes triggered by past events. The branching structure of the classical Hawkes process is illustrated in the left panel of Figure2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Branching structures of the classical Hawkes process (left) and the GNHP (right). Left:</figDesc><graphic coords="7,139.46,385.11,342.72,162.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><figDesc>(a) the background intensities µ i (•)'s are allowed to be time-varying and nonparametrically approximated using spline basis functions, which provides greater modeling flexibility. (b) the Momentum Intensity in model (2) has a clear interpretation given the network structure. (c)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><figDesc>), and similar approaches have been used in<ref type="bibr" target="#b23">Veen and Schoenberg (2008)</ref>;<ref type="bibr" target="#b10">Halpin et al. (2013);</ref><ref type="bibr" target="#b9">Fox et al. (2016)</ref>. Since the likelihood (10) is non-concave, the initial values of the group memberships and model parameters are of crucial importance. We propose to use a combination of the Kmeans algorithm and a stochastic EM algorithm to generate sensible initial values. The details are given in the Section A of the supplementary material.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><figDesc>gives the true group label of the majority nodes in C g = {i : g i = g}, for g ∈ [G]. Note that 1 -ρ mT is referred to as the cluster "purity" in the machine learning literature<ref type="bibr" target="#b21">(Schütze et al., 2008)</ref>, and is well defined even when G &gt; G 0 .The following theorem states the estimation consistency of the MLE (11) when G ≥ G 0 . Theorem 2. Assume Assumptions 1-7, G ≥ G 0 , and that τ m x mT = o(1) with x mT = 1 T b(n kt + d max ) log(mT )[log(max{b, n kt , log(mT )})] 3 , where d max = max 1≤i≤m d i and d = 1 m m i=1 d i are maximum and average out-degrees. Then it holds that as m, T → ∞, (a). ρ mT = O p e 1/2 mT + τ m e mT , with e mT = 1 T</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Theorem 3 .</head><label>3</label><figDesc>Assume Assumptions 1-7 and x mT τ m = o(1) with x mT as in Theorem 2. If λ mT τ m = o(1) and λ -1 mT 1 T</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: True background intensities.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The mean estimated background intensities with ±1.96 times sample standard errors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>,</head><figDesc>and PD η and PD γ are similarly defined. For the estimated background intensities, we define PD µ ∥ T , and for the network effects, we evaluate the estimation accuracy of the transition matrix B using PD B</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Barplot of top 20 and top 100 influential users.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Parameter setting for G 0 = 3 groups.</figDesc><table><row><cell></cell><cell></cell><cell>5</cell><cell>3</cell><cell>2 (0.4, 0.1, 0.1)</cell></row><row><cell>2</cell><cell>1</cell><cell>0.4</cell><cell>2</cell><cell>4 (0.6, 0.4, 0.5)</cell></row><row><cell>3</cell><cell>0.5</cell><cell>0.7</cell><cell>4</cell><cell>1 (0.15, 0.2, 0.1)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Empirical coverage probabilities (%) for the GNHP model parameters.</figDesc><table><row><cell>SBM network</cell><cell></cell><cell>Power Law network</cell><cell></cell></row><row><cell>m = 100</cell><cell>m = 200</cell><cell>m = 100</cell><cell>m = 200</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Estimation accuracy and selection rate of G when G is miss-specified.</figDesc><table><row><cell>SBM network</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Parameter estimates for Weibo data (p-values are given in the parentheses).</figDesc><table><row><cell></cell><cell></cell><cell cols="6">Group number selection</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">Knots selection</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Background intensities</cell><cell></cell></row><row><cell>Log Likelihood</cell><cell>-0.355 -0.340 -0.325</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>G</cell><cell>4</cell><cell>5</cell><cell>6 n kt =5 n kt =6 n kt =7 n kt =8 n kt =9</cell><cell>BIC</cell><cell>448000 452000 456000</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>n kt</cell><cell>7</cell><cell>8</cell><cell>9 10</cell><cell>Intensity</cell><cell>0.0 0.2 0.4 0.6</cell><cell>0</cell><cell>5</cell><cell>Hours 10 15</cell><cell>20</cell><cell>G1 G2 G3 G4</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Percent (%)</cell><cell></cell><cell>β g</cell><cell></cell><cell></cell><cell>η g</cell><cell></cell><cell></cell><cell cols="2">γ g</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ϕ gg ′</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">Group (g/g ′ )</cell><cell></cell><cell>-</cell><cell></cell><cell></cell><cell>-</cell><cell></cell><cell></cell><cell>-</cell><cell></cell><cell></cell><cell>-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell></cell><cell></cell><cell>2</cell><cell></cell><cell>3</cell><cell></cell><cell>4</cell></row><row><cell></cell><cell></cell><cell>1</cell><cell></cell><cell>49.8</cell><cell></cell><cell></cell><cell cols="19">0.346 (&lt; 0.001) 9.69 (&lt; 0.001) 2.73 (&lt; 0.001) 0.0213 (0.0018) 0.0589 (&lt; 0.001) 0.00461 (0.0044) 0.0189 (&lt; 0.001)</cell></row><row><cell></cell><cell></cell><cell>2</cell><cell></cell><cell>28.2</cell><cell></cell><cell></cell><cell cols="19">0.343 (&lt; 0.001) 1.35 (&lt; 0.001) 2.49 (&lt; 0.001) 0.0474 (&lt; 0.001) 0.144 (&lt; 0.001) 0.0568 (&lt; 0.001) 0.00796 (0.24)</cell></row><row><cell></cell><cell></cell><cell>3</cell><cell></cell><cell>12.2</cell><cell></cell><cell></cell><cell cols="17">0.585 (&lt; 0.001) 0.603 (&lt; 0.001) 100 (&lt; 0.001) 0.00592 (0.55) 0.0344 (&lt; 0.001) 0.18 (&lt; 0.001)</cell><cell cols="2">0.00512 (0.53)</cell></row><row><cell></cell><cell></cell><cell>4</cell><cell></cell><cell>9.9</cell><cell></cell><cell></cell><cell cols="2">0.64 (&lt; 0.001)</cell><cell cols="3">7 (&lt; 0.001)</cell><cell></cell><cell cols="4">2.31 (&lt; 0.001)</cell><cell cols="2">0.0532 (0.1)</cell><cell cols="7">0.147 (&lt; 0.001) 0.0682 (&lt; 0.001) 0.181 (&lt; 0.001)</cell></row></table><note><p>Figure 7: Left panel: maximized log-likelihood of various G's; Middle panel: LIC scores of various G's; Right panel: estimated background intensities.</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgment</head><p><rs type="person">Xuening Zhu</rs> is supported by the <rs type="funder">National Natural Science Foundation of China</rs> (nos. <rs type="grantNumber">72222009</rs>,   <rs type="grantNumber">71991472</rs>). <rs type="person">Guanhua Fang</rs> is partly supported by the <rs type="funder">National Natural Science Foundation of China</rs> (nos. <rs type="grantNumber">12301376</rs>) and he acknowledges the Terremoto high performance computing cluster service of <rs type="institution">Columbia University</rs>. The authors report there are no competing interests to declare.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_86576uz">
					<idno type="grant-number">72222009</idno>
				</org>
				<org type="funding" xml:id="_2B9S5fW">
					<idno type="grant-number">71991472</idno>
				</org>
				<org type="funding" xml:id="_3yrhHtm">
					<idno type="grant-number">12301376</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Network and are thus given in Section B.4 of the supplementary material. To increase the chance of finding the global optimal, for each simulation run, we use 50 initial membership estimates following the intensity-based K-means algorithm (using different starting values, supplement with random membership estimates if less than 50 distinct membership estimates are generate). Since the computations with different initial values can be easily paralleled, the overall computation times of the proposed EM algorithm appears to be reasonable for practical use. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EMPIRICAL STUDY: A SINA WEIBO DATASET</head><p>We apply the GNHP model to a dataset collected from Sina Weibo, the largest Twitter type social media in China, where we collect posting time stamps of m = 2, 038 users from January 1st to 15th, 2014, resulting in a T = 600 hours. Details of the data collection process is given in Section B.5 of the Supplementary Material. Figure <ref type="figure">6</ref> gives two sample Weibo posts by James</p><p>Cameron with posting times. The network adjacency matrix A is constructed using the followingfollowee relationships among users, which gives the network density i,j a ij /m(m -1) = 2.7%, suggesting a highly sparse network. Distributions of in-degrees and out-degrees of the network are given in Figure <ref type="figure">6</ref>, where we can see that the in-degrees tend to be more skewed than the out-degrees. This phenomenon is typical for a social network platform, where a few influential users may have a large number of followers but most users do not follow too many other users. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Model Estimation and Interpretation</head><p>We approximate the background intensities of the GNHP model by periodic B-spline basis with </p><p>where mT ℓ( ψ ) is the log-likelihood (10) evaluated at the MLE ψ given in (11).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Uncovering causality from multivariate Hawkes integrated cumulants</title>
		<author>
			<persName><forename type="first">M</forename><surname>Achab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bacry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gaiffas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mastromatteo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Muzy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Pseudo-likelihood methods for community detection in large sparse networks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Bickel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Levina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="2097" to="2122" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Sparse and low-rank multivariate Hawkes processes</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bacry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bompaire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gaïffas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Muzy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Modelling microstructure noise with mutually exciting point processes</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bacry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Delattre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Muzy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quantitative Finance</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="65" to="77" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Latent network structure learning from high dimensional multivariate point processes</title>
		<author>
			<persName><forename type="first">B</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">Working Paper</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Inference for a nonstationary self-exciting point process with an application in ultra-high frequency financial data modeling</title>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Probability</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="1006" to="1024" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The multivariate Hawkes process in high dimensions: Beyond mutual excitation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shojaie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shea-Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Witten</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.04928</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">COEVOLVE: A joint point process model for information diffusion and network evolution</title>
		<author>
			<persName><forename type="first">M</forename><surname>Farajtabar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gomez-Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1" to="49" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Fleming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Harrington</surname></persName>
		</author>
		<title level="m">Counting processes and survival analysis</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">169</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Modeling e-mail networks and inferring leadership using self-exciting point processes</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Short</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>Schoenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Coronges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Bertozzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="page" from="564" to="584" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Modelling dyadic interaction with Hawkes processes</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Halpin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Boeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="793" to="814" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Lasso and probabilistic inequalities for multivariate point processes</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Reynaud-Bouret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Rivoirard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bernoulli</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="83" to="143" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Spectra of some self-exciting and mutually exciting point processes</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Hawkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="83" to="90" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A cluster process representation of a self-exciting process</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Hawkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Oakes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Probability</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="493" to="503" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Discovering latent network structure in point process data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Linderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1413" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Identification and estimation in panel models with overspecified number of groups</title>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Econometrics</title>
		<imprint>
			<biblScope unit="volume">215</biblScope>
			<biblScope unit="page" from="574" to="590" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A semiparametric extension of the stochastic block model for longitudinal networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Matias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rebafka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Villers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="665" to="680" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Selfexciting point process modeling of crime</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">O</forename><surname>Mohler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Short</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Brantingham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>Schoenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Tita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="100" to="108" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The asymptotic behaviour of maximum likelihood estimators for stationary point processes</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ogata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of the Institute of Statistical Mathematics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="243" to="261" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Statistical models for earthquake occurrences and residual analysis for point processes</title>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical association</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="9" to="27" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Bayesian inference for Hawkes processes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Rasmussen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methodology and Computing in Applied Probability</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="623" to="642" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<title level="m">Introduction to information retrieval</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">39</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Identifying latent structures in panel data</title>
		<author>
			<persName><forename type="first">L</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Phillips</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="2215" to="2264" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Estimation of space-time branching process models in seismology using an EM-type algorithm</title>
		<author>
			<persName><forename type="first">A</forename><surname>Veen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>Schoenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="614" to="624" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Community detection with nodal information: likelihood and its variational approximation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat</title>
		<imprint>
			<biblScope unit="page">428</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning granger causality for hawkes processes</title>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Farajtabar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1717" to="1726" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Covariate regularized community detection in sparse graphs</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sarkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="734" to="745" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Steering social activity: a stochastic optimal control point of view</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zarezade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Upadhyay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Rabiee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gomez-Rodriguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Directed community detection with network embedding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Consistency of community detection in networks under degree-corrected stochastic block models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Levina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="2266" to="2292" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning social infectivity in sparse low-rank networks using multi-dimensional hawkes processes</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="641" to="649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Local asymptotics for regression splines and confidence regions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wolfe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1760" to="1782" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Network Vector Autoregression</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="1096" to="1123" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Network quantile autoregression</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Härdle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of econometrics</title>
		<imprint>
			<biblScope unit="volume">212</biblScope>
			<biblScope unit="page" from="345" to="358" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Simultaneous estimation and group identification for network vector autoregressive model with heterogeneous nodes</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2209.12229</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
