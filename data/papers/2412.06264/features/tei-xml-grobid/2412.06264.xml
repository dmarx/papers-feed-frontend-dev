<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Flow Matching Guide and Code</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-12-10">December 10, 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yaron</forename><surname>Lipman</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Weizmann Institute of Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marton</forename><surname>Havasi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Weizmann Institute of Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Peter</forename><surname>Holderrieth</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Weizmann Institute of Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Neta</forename><surname>Shaul</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Weizmann Institute of Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Matt</forename><surname>Le</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Weizmann Institute of Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Brian</forename><surname>Karrer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Weizmann Institute of Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ricky</forename><forename type="middle">T Q</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Weizmann Institute of Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Weizmann Institute of Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Heli</forename><surname>Ben-Hamu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Weizmann Institute of Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Itai</forename><surname>Gat</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Weizmann Institute of Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName><surname>Fair At Meta</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Weizmann Institute of Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mit</forename><surname>Csail</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Weizmann Institute of Science</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Flow Matching Guide and Code</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-12-10">December 10, 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">2CEE47D8CECDF2CCA0CE6741A15E5D6B</idno>
					<idno type="arXiv">arXiv:2412.06264v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-02-21T16:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Flow Matching (FM) is a recent framework for generative modeling that has achieved state-of-the-art performance across various domains, including image, video, audio, speech, and biological structures. This guide offers a comprehensive and self-contained review of FM, covering its mathematical foundations, design choices, and extensions. By also providing a PyTorch package featuring relevant examples (e.g., image and text generation), this work aims to serve as a resource for both novice and experienced researchers interested in understanding, applying and further developing FM.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Four time-continuous processes (Xt) 0≤t≤1 taking source sample X0 to a target sample X1. These are a flow in a continuous state space, a diffusion in continuous state space, a jump process in continuous state space (densities visualized with contours), and a jump process in discrete state space (states as disks, probabilities visualized with colors).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Flow matching (FM) <ref type="bibr" target="#b44">(Lipman et al., 2022;</ref><ref type="bibr" target="#b0">Albergo and Vanden-Eijnden, 2022;</ref><ref type="bibr" target="#b46">Liu et al., 2022</ref>) is a simple framework for generative modeling framework that has pushed the state-of-the-art in various fields and large-scale applications including generation of images <ref type="bibr" target="#b21">(Esser et al., 2024)</ref>, videos <ref type="bibr" target="#b63">(Polyak et al., 2024)</ref>, speech <ref type="bibr" target="#b43">(Le et al., 2024)</ref>, audio <ref type="bibr" target="#b84">(Vyas et al., 2023)</ref>, proteins <ref type="bibr" target="#b36">(Huguet et al., 2024)</ref>, and robotics <ref type="bibr" target="#b6">(Black et al., 2024)</ref>. This manuscript and its accompanying codebase have two primary objectives. First, to serve as a comprehensive and self-contained reference to Flow Matching, detailing its design choices and numerous extensions developed by the research community. Second, to enable newcomers to quickly adopt and build upon Flow Matching for their own applications.</p><p>The framework of Flow Matching is based on learning a velocity field (also called vector field). Each velocity field defines a flow ψ t by solving an ordinary differential equation (ODE) in a process called simulation. A flow is a determinstic, time-continuous bijective transformation of the d-dimensional Euclidean space, R d . The goal of Flow Matching is to build a flow that transforms a sample X 0 ∼ p drawn from a source distribution p into a target sample X 1 := ψ 1 (X 0 ) such that X 1 ∼ q has a desired distribution q, see figure <ref type="figure" target="#fig_7">1a</ref>. Flow models were introduced to the machine learning community by <ref type="bibr">(Chen et al., 2018;</ref><ref type="bibr" target="#b27">Grathwohl et al., 2018)</ref> as Continuous Normalizing Flows (CNFs). Originally, flows were trained by maximizing the likelihood p(X 1 )</p><p>of training examples X 1 , resulting in the need of simulation and its differentiation during training. Due to the resulting computational burdens, later works attempted to learn CNFs without simulation <ref type="bibr" target="#b68">(Rozen et al., 2021;</ref><ref type="bibr" target="#b4">Ben-Hamu et al., 2022)</ref>, evolving into modern-day Flow Matching algorithms <ref type="bibr" target="#b44">(Lipman et al., 2022;</ref><ref type="bibr" target="#b46">Liu et al., 2022;</ref><ref type="bibr" target="#b0">Albergo and Vanden-Eijnden, 2022;</ref><ref type="bibr" target="#b54">Neklyudov et al., 2023;</ref><ref type="bibr" target="#b30">Heitz et al., 2023;</ref><ref type="bibr" target="#b80">Tong et al., 2023)</ref>. The resulting framework is a recipe comprising two steps <ref type="bibr" target="#b44">(Lipman et al., 2022)</ref>, see figure <ref type="figure" target="#fig_2">2</ref>: First, choose a probability path p t interpolating between the source p and target q distributions. Second, train a velocity field (neural network) that defines the flow transformation ψ t implementing p t .</p><p>The principles of FM can be extended to state spaces S other than R d and even evolution processes that are not flows. Recently, Discrete Flow Matching <ref type="bibr" target="#b11">(Campbell et al., 2024;</ref><ref type="bibr" target="#b25">Gat et al., 2024)</ref> develops a Flow Matching algorithm for time-continuous Markov processes on discrete state spaces, also known as Continuous Time Markov Chains (CTMC), see figure <ref type="figure" target="#fig_7">1c</ref>. This advancement opens up the exciting possibility of using Flow Matching in discrete generative tasks such as language modeling. Riemannian Flow Matching (Chen and <ref type="bibr">Lipman, 2024)</ref> extends Flow Matching to flows on Riemannian manifolds S = M that now became the state-of-the-art models for a wide variety of applications of machine learning in chemistry such as protein folding <ref type="bibr" target="#b85">(Yim et al., 2023;</ref><ref type="bibr" target="#b8">Bose et al., 2023)</ref>. Even more generally, Generator Matching <ref type="bibr" target="#b33">(Holderrieth et al., 2024)</ref> shows that the Flow Matching framework works for any modality and for general Continuous Time Markov Processes (CTMPs) including, as illustrated in figure <ref type="figure" target="#fig_0">1</ref>, flows, diffusions, and jump processes in continuous spaces, in addition to CTMC in discrete spaces. Remarkably, for any such CTMP, the Flow Matching recipe remains the same, namely: First, choose a path p t interpolating source p and target q on the relevant state space S. Second, train a generator, which plays a similar role to velocities for flows, and defines a CTMP process implementing p t . This generalization of Flow Matching allows us to see many existing generative models in a unified light and develop new generative models for any modality with a generative Markov process of choice.</p><p>Chronologically, Diffusion Models were the first to develop simulation-free training of a CTMP process, namely a diffusion process, figure <ref type="figure" target="#fig_7">1b</ref>. Diffusion Models were originally introduced as discrete time Gaussian processes <ref type="bibr" target="#b77">(Sohl-Dickstein et al., 2015;</ref><ref type="bibr" target="#b32">Ho et al., 2020)</ref> and later formulated in terms of continuous time Stochastic Differential Equations (SDEs) <ref type="bibr">(Song et al., 2021)</ref>. In the lens of Flow Matching, Diffusion Models build the probability path p t interpolating source and target distributions in a particular way via forward noising processes modeled by particular SDEs. These SDEs are chosen to have closed form marginal probabilities that are in turn used to parametrize the generator of the diffusion process (i.e., drift and diffusion coefficient) via the score function <ref type="bibr" target="#b78">(Song and Ermon, 2019)</ref>. This parameterization is based on a reversal process to the forward noising process <ref type="bibr" target="#b3">(Anderson, 1982)</ref>. Consequently, Diffusion Models learn the score function of the marginal probabilities. Diffusion Models' literature suggested also other parametrizations of the generator besides the score, including noise prediction, denoisers <ref type="bibr" target="#b41">(Kingma et al., 2021)</ref>, or v-prediction <ref type="bibr" target="#b71">(Salimans and Ho, 2022)</ref>-where the latter coincides with velocity prediction for a particular choice of probability path p t .</p><p>Diffusion bridges <ref type="bibr" target="#b59">(Peluchetti, 2023)</ref> offers another approach to design p t and generators for diffusion process that extends diffusion models to arbitrary source-target couplings. In particular these constructions are build again on SDEs with marginals known in closed form, and again use the score to formulate the generator (using Doob's h-transform). <ref type="bibr" target="#b76">Shi et al. (2023)</ref>; <ref type="bibr" target="#b45">Liu et al. (2023)</ref> show that the linear version of Flow Matching can be seen as a certain limiting case of bridge matching.</p><p>The rest of this manuscript is organized as follows. Section 2 offers a self-contained "cheat-sheet" to understand and implement vanilla Flow Matching in PyTorch. Section 3 offers a rigorous treatment of flow models, arguably the simplest of all CTMPs, for continuous state spaces. In section 4 we introduce the Flow Matching framework in R d and its various design choices and extensions. We show that flows can be constructed by considering the significantly simpler conditional setting, offering great deal of flexibility in their design, e.g., by readily extending to Riemannian geometries, described in section 5. Section 6 provides an introduction to Continuous Time Markov Chains (CTMCs) and the usage as generative models on discrete state spaces. Then, section 7 discusses the extension of Flow Matching to CTMC processes. In section 8, we provide an introduction to using Continuous Time Markov Process (CTMPs) as generative models for arbitrary state spaces. In section 9, we describe Generator Matching (GM) -a generative modeling framework for arbitrary modalities that describes a scalable way of training CTMPs. GM also unifies all models in previous sections into a common framework. Finally, due to their wide-spread use, we discuss in section 10 denoising diffusion models as a specific instance of the FM family of models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Quick tour and key concepts</head><p>Given access to a training dataset of samples from some target distribution q over R d , our goal is to build a model capable of generating new samples from q. To address this task, Flow Matching (FM) builds a probability path (p t ) 0≤t≤1 , from a known source distribution p 0 = p to the data target distribution p 1 = q, where each p t is a distribution over R d . Specifically, FM is a simple regression objective to train the velocity field neural network describing the instantaneous velocities of samples-later used to convert the source distribution p 0 into the target distribution p 1 , along the probability path p t . After training, we generate a novel sample from the target distribution X 1 ∼ q by (i) drawing a novel sample from the source distribution X 0 ∼ p, and (ii) solving the Ordinary Differential Equation (ODE) determined by the velocity field.</p><p>More formally, an ODE is defined via a time-dependent vector field u : [0, 1] × R d → R d which, in our case, is the velocity field modeled in terms of a neural network. This velocity field determines a time-dependent flow ψ :</p><formula xml:id="formula_0">[0, 1] × R d → R d , defined as d dt ψ t (x) = u t (ψ t (x)),</formula><p>where ψ t := ψ(t, x) and ψ 0 (x) = x. The velocity field u t generates the probability path p t if its flow ψ t satisfies X t := ψ t (X 0 ) ∼ p t for X 0 ∼ p 0 .</p><p>(2.1)</p><p>According to the equation above, the velocity field u t is the only tool necessary to sample from p t by solving the ODE above. As illustrated in figure <ref type="figure" target="#fig_2">2d</ref>, solving the ODE until t = 1 provides us with samples X 1 = ψ 1 (X 0 ), resembling the target distribution q. Therefore, and in sum, the goal of Flow Matching is to learn a vector field u θ t such that its flow ψ t generates a probability path p t with p 0 = p and p 1 = q.  Using the notations above, the goal of Flow Matching is to learn the parameters θ of a velocity field u θ t implemented in terms of a neural network. As anticipated in the introduction, we do this in two steps: design a probability path p t interpolating between p and q (see figure <ref type="figure" target="#fig_2">2b</ref>), and train a velocity field u θ t generating p t by means of regression (see figure <ref type="figure" target="#fig_4">2c</ref>).</p><p>Therefore, let us proceed with the first step of the recipe: designing the probability path p t . In this example, let the source distribution p := p 0 = N (x|0, I), and construct the probability path p t as the aggregation of the conditional probability paths p t|1 (x|x 1 ), each conditioned on one of the data examples X 1 = x 1 comprising the training dataset. (One of such conditional paths is illustrated in figure <ref type="figure" target="#fig_6">3a</ref>.) The probability path p t therefore follows the expression: p t (x) = p t|1 (x|x 1 )q(x 1 )dx 1 , where p t|1 (x|x 1 ) = N (x|tx 1 , (1 -t) 2 I).</p><p>(</p><p>This path, also known as the conditional optimal-transport or linear path, enjoys some desirable properties that we will study later in this manuscript. Using this probability path, we may define the random variable X t ∼ p t by drawing X 0 ∼ p, drawing X 1 ∼ q, and taking their linear combination:</p><formula xml:id="formula_2">X t = tX 1 + (1 -t)X 0 ∼ p t .<label>(2.3)</label></formula><p>We now continue with the second step in the Flow Matching recipe: regressing our velocity field u θ t (usually implemented in terms of a neural network) to a target velocity field u t known to generate the desired probability path p t . To this end, the Flow Matching loss reads:</p><formula xml:id="formula_3">L FM (θ) = E t,Xt u θ t (X t ) -u t (X t ) 2</formula><p>, where t ∼ U[0, 1] and X t ∼ p t . <ref type="bibr">(2.4)</ref> In practice, one can rarely implement the objective above, because u t is a complicated object governing the joint transformation between two high-dimensional distributions. Fortunately, the objective simplifies drastically by conditioning the loss on a single target example X 1 = x 1 picked at random from the training set. To see how, borrowing equation <ref type="bibr">(2.3)</ref> to realize the conditional random variables</p><formula xml:id="formula_4">X t|1 = tx 1 + (1 -t)X 0 ∼ p t|1 (•|x 1 ) = N (• | tx 1 , (1 -t) 2 I).</formula><p>(2.5) Using these variables, solving d dt X t|1 = u t (X t|1 |x 1 ) leads to the conditional velocity field <ref type="bibr">.6)</ref> which generates the conditional probability path p t|1 (•|x 1 ). (For an illustration on these two conditional objects, see figure <ref type="figure" target="#fig_6">3c</ref>.) Equipped with the simple equation <ref type="bibr">(2.6)</ref> for the conditional velocity fields generating the designed conditional probability paths, we can formulate a tractable version of the Flow Matching loss in <ref type="bibr">(2.4)</ref>. This is the conditional Flow Matching loss:</p><formula xml:id="formula_5">u t (x|x 1 ) = x 1 -x 1 -t , (<label>2</label></formula><p>L CFM (θ) = E t,Xt,X1 ∥u θ t (X t ) -u t (X t |X 1 )∥ 2 , where t ∼ U [0, 1], X 0 ∼ p, X 1 ∼ q, (2.7)    and X t = (1 -t)X 0 + tX 1 . Remarkably, the objectives in <ref type="bibr">(2.4</ref>) and (2.7) provide the same gradients to learn u θ t , i.e., ∇ θ L FM (θ) = ∇ θ L CFM (θ).</p><p>(2.8)</p><p>Finally, by plugging u t (x|x 1 ) from (2.6) into equation (2.7), we get the simplest implementation of Flow Matching:</p><formula xml:id="formula_6">L OT,Gauss CFM (θ) = E t,X0,X1 ∥u θ t (X t ) -(X 1 -X 0 ) ∥ 2</formula><p>, where t ∼ U [0, 1], X 0 ∼ N (0, I), X 1 ∼ q.</p><p>(2.9)</p><p>A standalone implementation of this quick tour in pure PyTorch is provided in code 1. Later in the manuscript, we will cover more sophisticated variants and design choices, all of them implemented in the accompanying flow_matching library. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Flow models</head><p>This section introduces flows, the mathematical object powering the simplest forms of Flow Matching. Later parts in the manuscript will discuss Markov processes more general than flows, leading to more sophisticated generative learning paradigms introducing many more design choices to the Flow Matching framework.</p><p>The reason we start with flows is three-fold: First, flows are arguably the simplest of all CTMPs-being deterministic and having a compact parametrization via velocities-these models can transform any source distribution p into any target distribution q, as long as these two have densities. Second, flows can be sampled rather efficiently by approximating the solution of ODEs, compared, e.g., to the harder-to-simulate SDEs for diffusion processes. Third, the deterministic nature of flows allows an unbiased model likelihood estimation, while more general stochastic processes require working with lower bounds. To understand flows, we must first review some background notions in probability and differential equations theory, which we do next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Random vectors</head><p>Consider data in the d-dimensional Euclidean space x = (x 1 , . . . , x d ) ∈ R d with the standard Euclidean inner product ⟨x, y⟩ = d i=1 x i y i and norm ∥x∥ = ⟨x, x⟩. We will consider random variables (RVs) X ∈ R d with continuous probability density function (PDF), defined as a continuous function p X : R d → R ≥0 providing event A with probability</p><formula xml:id="formula_7">P(X ∈ A) = A p X (x)dx,<label>(3.1)</label></formula><p>where p X (x)dx = 1. By convention, we omit the integration interval when integrating over the whole space ( ≡ R d ). To keep notation concise, we will refer to the PDF p Xt of RV X t as simply p t . We will use the notation X ∼ p or X ∼ p(X) to indicate that X is distributed according to p. One common PDF in generative modeling is the d-dimensional isotropic Gaussian:</p><formula xml:id="formula_8">N (x|µ, σ 2 I) = (2πσ 2 ) -d 2 exp - ∥x -µ∥ 2 2 2σ 2 ,<label>(3.2)</label></formula><p>where µ ∈ R d and σ ∈ R &gt;0 stand for the mean and the standard deviation of the distribution, respectively.</p><p>The expectation of a RV is the constant vector closest to X in the least-squares sense:</p><formula xml:id="formula_9">E [X] = arg min z∈R d ∥x -z∥ 2 p X (x)dx = xp X (x)dx. (3.3)</formula><p>One useful tool to compute the expectation of functions of RVs is the Law of the Unconscious Statistician:</p><formula xml:id="formula_10">E [f (X)] = f (x)p X (x)dx. (3.4)</formula><p>When necessary, we will indicate the random variables under expectation as E X f (X). and similarly for the conditional PDF p Y |X . Bayes' rule expresses the conditional PDF p Y |X with p X|Y by p Y |X (y|x) = p X|Y (x|y)p Y (y) p X (x) , (3.7) for p X (x) &gt; 0. The conditional expectation E [X|Y ] is the best approximating function g ⋆ (Y ) to X in the least-squares sense: g ⋆ := arg min g:R d →R d E ∥X -g(Y )∥ 2 = arg min g:R d →R d ∥x -g(y)∥ 2 p X,Y (x, y)dxdy = arg min g:R d →R d ∥x -g(y)∥ 2 p X|Y (x|y)dx p Y (y)dy. (3.8) For y ∈ R d such that p Y (y) &gt; 0 the conditional expectation function is therefore</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Conditional densities and expectations</head><formula xml:id="formula_11">E [X|Y = y] := g ⋆ (y) = xp X|Y (x|y)dx,<label>(3.9)</label></formula><p>where the second equality follows from taking the minimizer of the inner brackets in equation <ref type="bibr">(3.8)</ref> for Y = y, similarly to equation <ref type="bibr">(3.3)</ref>. Composing g ⋆ with the random variable Y , we get</p><formula xml:id="formula_12">E [X|Y ] := g ⋆ (Y ),<label>(3.10)</label></formula><p>which is a random variable in R d . Rather confusingly, both E [X|Y = y] and E [X|Y ] are often called conditional expectation, but these are different objects. In particular,</p><formula xml:id="formula_13">E [X|Y = y] is a function R d → R d , while E [X|Y ] is a random variable assuming values in R d .</formula><p>To disambiguate these two terms, our discussions will employ the notations introduced here.</p><p>The tower property is an useful property that helps simplify derivations involving conditional expectations of two RVs X and Y :</p><formula xml:id="formula_14">E [E [X|Y ]] = E [X] (3.11)</formula><p>Because E [X|Y ] is a RV, itself a function of the RV Y , the outer expectation computes the expectation of E [X|Y ]. The tower property can be verified by using some of the definitions above:</p><formula xml:id="formula_15">E [E [X|Y ]] = xp X|Y (x|y)dx p Y (y)dy (3.6) = xp X,Y (x, y)dxdy (3.5) = xp X (x)dx = E [X] .</formula><p>Finally, consider a helpful property involving two RVs f (X, Y ) and Y , where X and Y are two arbitrary RVs. Then, by using the Law of the Unconscious Statistician with (3.9), we obtain the identity</p><formula xml:id="formula_16">E [f (X, Y )|Y = y] = f (x, y)p X|Y (x|y)dx.</formula><p>(3.12)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Diffeomorphisms and push-forward maps</head><p>We denote by C r (R m , R n ) the collection of functions f : R m → R n with continuous partial derivatives of order r: </p><formula xml:id="formula_17">∂ r f k ∂x i1 • • • ∂x ir , k ∈ [n], i j ∈ [m],<label>(3.13)</label></formula><formula xml:id="formula_18">∈ C r (R n , R n ) with ψ -1 ∈ C r (R n , R n ).</formula><p>Then, given a RV X ∼ p X with density p X , let us consider a RV Y = ψ(X), where ψ :</p><formula xml:id="formula_19">R d → R d is a C 1 diffeomorphism.</formula><p>The PDF of Y , denoted p Y , is also called the push-forward of p X . Then, the PDF p Y can be computed via a change of variables:</p><formula xml:id="formula_20">E [f (Y )] = E [f (ψ(X))] = f (ψ(x))p X (x)dx = f (y)p X (ψ -1 (y)) det ∂ y ψ -1 (y) dy,</formula><p>where the third equality is due the change of variables x = ψ -1 (y), ∂ y ϕ(y) denotes the Jacobian matrix (of first order partial derivatives), i.e.,</p><formula xml:id="formula_21">[∂ y ϕ(y)] i,j = ∂ϕ i ∂x j , i, j ∈ [d],</formula><p>and det A denotes the determinant of a square matrix A ∈ R d×d . Thus, we conclude that the PDF p Y is</p><formula xml:id="formula_22">p Y (y) = p X (ψ -1 (y)) det ∂ y ψ -1 (y) . (3.14)</formula><p>We will denote the push-forward operator with the symbol ♯, that is</p><formula xml:id="formula_23">[ψ ♯ p X ] (y) := p X (ψ -1 (y)) det ∂ y ψ -1 (y) .</formula><p>(3.15)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Flows as generative models</head><p>As mentioned in section 2, the goal of generative modeling is to transform samples X 0 = x 0 from a source distribution p into samples X 1 = x 1 from a target distribution q. In this section, we start building the tools necessary to address this problem by means of a flow mapping ψ t . More formally, a C r flow is a time-dependent mapping ψ :</p><formula xml:id="formula_24">[0, 1] × R d → R d implementing ψ : (t, x) → ψ t (x). Such flow is also a C r ([0, 1] × R d , R d ) function, such that the function ψ t (x) is a C r diffeomorphism in x for all t ∈ [0, 1]. A flow model is a continuous-time</formula><p>Markov process (X t ) 0≤t≤1 defined by applying a flow ψ t to the RV X 0 :</p><formula xml:id="formula_25">X t = ψ t (X 0 ), t ∈ [0, 1]</formula><p>, where X 0 ∼ p. <ref type="bibr">(3.16)</ref> See Figure <ref type="figure" target="#fig_9">5</ref> for an illustration of a flow model. To see why X t is Markov, note that, for any choice of 0 ≤ t &lt; s ≤ 1, we have <ref type="bibr">3.17)</ref> where the last equality follows from using equation <ref type="bibr">(3.16</ref>) to set X t = ψ t (X 0 ), and defining ψ s|t := ψ s • ψ -1 t , which is also a diffeomorphism. X s = ψ s|t (X t ) implies that states later than X t depend only on X t , so X t is Markov. In fact, for flow models, this dependence is deterministic. In summary, the goal generative flow modeling is to find a flow ψ t such that</p><formula xml:id="formula_26">X s = ψ s (X 0 ) = ψ s (ψ -1 t (ψ t (X 0 ))) = ψ s|t (X t ),<label>(</label></formula><formula xml:id="formula_27">X 1 = ψ 1 (X 0 ) ∼ q.</formula><p>(3.18)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Equivalence between flows and velocity fields</head><p>A C r flow ψ can be defined in terms of a</p><formula xml:id="formula_28">C r ([0, 1] × R d , R d ) velocity field u : [0, 1] × R d → R d implementing u : (t, x) → u t (x) via the following ODE: d dt ψ t (x) = u t (ψ t (x)) (flow ODE) (3.19a) ψ 0 (x) = x (flow initial conditions) (3.19b)</formula><p>See figure <ref type="figure" target="#fig_10">6</ref> for an illustration of a flow together with its velocity field.</p><p>A standard result regarding the existence and uniqueness of solutions ψ t (x) to equation <ref type="bibr">(3.19</ref>) is (see e.g., <ref type="bibr" target="#b60">Perko (2013)</ref>; Coddington et al. ( <ref type="formula">1956</ref>)):</p><p>Theorem 1 (Flow local existence and uniqueness).</p><formula xml:id="formula_29">If u is C r ([0, 1] × R d , R d ), r ≥ 1 (in particular, locally Lipschitz), then the ODE in (3.19) has a unique solution which is a C r (Ω, R d ) diffeomorphism ψ t (x) defined over an open set Ω which is super-set of {0} × R d .</formula><p>This theorem guarantees only the local existence and uniqueness of a C r flow moving each point x ∈ R d by ψ t (x) during a potentially limited amount of time t ∈ [0, t x ). To guarantee a solution until t = 1 for all x ∈ R d , one must place additional assumptions beyond local Lipschitzness. For instance, one could consider global Lipschitness, guaranteed by bounded first derivatives in the C 1 case. However, we will later rely on a different condition-namely, integrability-to guarantee the existence of the flow almost everywhere, and until time t = 1.</p><p>So far, we have shown that a velocity field uniquely defines a flow. Conversely, given a C 1 flow ψ t , one can extract its defining velocity field u t (x) for arbitrary x ∈ R d by considering the equation d dt ψ t (x ′ ) = u t (ψ t (x ′ )), and using the fact that ψ t is an invertible diffeomorphism for every t ∈ [0, 1] to let x ′ = ψ -1 t (x). Therefore, the unique velocity field u t determining the flow ψ t is <ref type="bibr">3.20)</ref> where ψt := d dt ψ t . In conclusion, we have shown the equivalence between C r flows ψ t and C r velocity fields u t .</p><formula xml:id="formula_30">u t (x) = ψt (ψ -1 t (x)),<label>(</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Computing target samples from source samples</head><p>Computing a target sample X 1 -or, in general, any sample X t -entails approximating the solution of the ODE in equation <ref type="bibr">(3.19</ref>) starting from some initial condition X 0 = x 0 . Numerical methods for ODEs is a classical and well researched topic in numerical analysis, and a myriad of powerful methods exist <ref type="bibr" target="#b37">(Iserles, 2009)</ref>. One of the simplest methods is the Euler method, implementing the update rule where h = n -1 &gt; 0 is a step size hyper-parameter with n ∈ N. To draw a sample X 1 from the target distribution, apply the Euler method starting at some X 0 ∼ p to produce the sequence X h , X 2h , . . . , X 1 . The Euler method coincides with first-order Taylor expansion of X t :</p><formula xml:id="formula_31">X t+h = X t + hu t (X t ) (3.21)</formula><formula xml:id="formula_32">X t+h = X t + h Ẋt + o(h) = X t + hu t (X t ) + o(h),</formula><p>where o(h) stands for a function growing slower than h, that is, o(h)/h → 0 as h → 0. Therefore, the Euler method accumulates o(h) error per step, and can be shown to accumulate o(1) error after n = 1/h steps. Therefore, the error of the Euler method vanishes as we consider smaller step sizes h → 0. The Euler method is just one example among many ODE solvers. Code 2 exemplifies another alternative, the second-order midpoint method, which often outperforms the Euler method in practice.</p><p>Code 2: Computing X 1 with Midpoint solver 1 from flow_matching.solver import ODESolver 2 from flow_matching.utils import ModelWrapper 3 4 class Flow(ModelWrapper): 5 def __init__(self, dim=2, h=64): 6 super().__init__() 7 self.net = torch.nn.Sequential( 8 torch.nn.Linear(dim + 1, h), torch.nn.ELU(), 9 torch.nn.Linear(h, dim)) 10 11 def forward(self, x, t): 12 t = t.view(-1, 1).expand(*x.shape[:-1], -1) 13 return self.net(torch.cat((t, x), -1)) 14 15 velocity_model = Flow() 16 17 ... # Optimize the model parameters s.t. model(x_t, t) = ut(Xt) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Probability paths and the Continuity Equation</head><p>We call a time-dependent probability (p t ) 0≤t≤1 a probability path. For our purposes, one important probability path is the marginal PDF of a flow model X t = ψ t (X 0 ) at time t:</p><formula xml:id="formula_33">X t ∼ p t . (3.22)</formula><p>For each time t ∈ [0, 1], these marginal PDFs are obtained via the push-forward formula in equation <ref type="bibr">(3.15)</ref>, that is,</p><formula xml:id="formula_34">p t (x) = [ψ t♯ p] (x). (3.23)</formula><p>Given some arbitrary probability path p t we define <ref type="bibr">.24)</ref> In this way, we establish a close relationship between velocity fields, their flows, and the generated probability paths, see Figure <ref type="figure" target="#fig_11">7</ref> for an illustration. Note that we use the time interval [0, <ref type="bibr" target="#b87">1)</ref>, open from the right, to allow dealing with target distributions q with compact support where the velocity is not defined precisely at t = 1.</p><formula xml:id="formula_35">u t generates p t if X t = ψ t (X 0 ) ∼ p t for all t ∈ [0, 1). (<label>3</label></formula><p>To verify that a velocity field u t generates a probability path p t , one can verify if the pair (u t , p t ) satisfies a partial differential equation (PDE) known as the Continuity Equation:</p><formula xml:id="formula_36">d dt p t (x) + div(p t u t )(x) = 0, (3.25) where div(v)(x) = d i=1 ∂ x i v i (x), and v(x) = (v 1 (x), . . . , v d (x)).</formula><p>The following theorem, a rephrased version of the Mass Conservation Formula <ref type="bibr">(Villani et al., 2009)</ref>, states that a solution u t to the Continuity Equation generates the probability path p t : Theorem 2 (Mass Conservation). Let p t be a probability path and u t a locally Lipchitz integrable vector field. Then, the following two statements are equivalent:</p><p>1. The Continuity Equation (3.25) holds for t ∈ [0, 1).</p><p>2. u t generates p t , in the sense of <ref type="bibr">(3.24)</ref>.</p><p>In the previous theorem, local Lipschitzness assumes that there exists a local neighbourhood over which u t (x) is Lipschitz, for all (t, x). Assuming that u is integrable means that:</p><formula xml:id="formula_37">1 0 ∥u t (x)∥ p t (x)dxdt &lt; ∞. (3.26)</formula><p>Specifically, integrating a solution to the flow ODE <ref type="bibr">(3.19a)</ref> across times [0, t] leads to the integral equation</p><formula xml:id="formula_38">ψ t (x) = x + t 0 u s (ψ s (x))ds. (3.27)</formula><p>Therefore, integrability implies</p><formula xml:id="formula_39">E ∥X t ∥ (3.16) = ∥ψ t (x)∥ p(x)dx = x + t 0 u s (ψ s (x))ds p(x)dx (i) ≤ E ∥X 0 ∥ + 1 0 ∥u s (x)∥ p t (x)dt (ii) &lt; ∞,</formula><p>where (i) follows from the triangle inequality, and (ii) assumes the integrability condition <ref type="bibr">(3.26</ref>) and E ∥X 0 ∥ &lt; ∞. In sum, integrability allows assuming that X t has bounded expected norm, if X 0 also does. (3.29) This equation expresses the rate of change of total probability mass in the volume D (left-hand side) as the negative probability flux leaving the domain (right-hand side). The probability flux, defined as j t (y) = p t (y)u t (y), is the probability mass flowing through the hyperplane orthogonal to n(y) per unit of time and per unit of (possibly high-dimensional) area. See figure <ref type="figure" target="#fig_13">8</ref> for an illustration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Instantaneous Change of Variables</head><p>One important benefit of using flows as generative models is that they allow the tractable computation of exact likelihoods log p 1 (x), for all x ∈ R d . This feature is a consequence of the Continuity Equation called the Instantaneous Change of Variables (Chen et al., 2018):</p><formula xml:id="formula_40">d dt log p t (ψ t (x)) = -div(u t )(ψ t (x)). (3.30)</formula><p>This is the ODE governing the change in log-likelihood, log p t (ψ t (x)), along a sampling trajectory ψ t (x) defined by the flow ODE <ref type="bibr">(3.19a</ref>). To derive <ref type="bibr">(3.30)</ref>, differentiate log p t (ψ t (x)) with respect to time, and apply both the Continuity Equation <ref type="bibr">(3.25)</ref> and the flow ODE <ref type="bibr">(3.19a)</ref>. Integrating (3.30) from t = 0 to t = 1 and rearranging, we obtain</p><formula xml:id="formula_41">log p 1 (ψ 1 (x)) = log p 0 (ψ 0 (x)) - 1 0 div(u t )(ψ t (x))dt. (3.31)</formula><p>In practice, computing div(u t ), which equals the trace of the Jacobian matrix ∂ x u t (x) ∈ R d×d , is increasingly challenge as the dimensionality d grows. Because of this reason, previous works employ unbiased estimators such as Hutchinson's trace estimator <ref type="bibr" target="#b27">(Grathwohl et al., 2018)</ref>:</p><formula xml:id="formula_42">div(u t )(x) = tr [∂ x u t (x)] = E Z tr Z T ∂ x u t (x)Z ,<label>(3.32)</label></formula><p>where Z ∈ R d×d is any random variable with E [Z] = 0 and Cov (Z, Z) = I, (for example, Z ∼ N (0, I)), and tr[Z] = d i=1 Z i,i . By plugging the equation above into <ref type="bibr">(3.31)</ref> and switching the order of integral and expectation, we obtain the following unbiased log-likelihood estimator: <ref type="bibr">.33)</ref> In contrast to div(u t )(ψ t (x)) in <ref type="bibr">(3.30)</ref>, computing tr Z T ∂ x u t (ψ t (x))Z for a fixed sample Z in the equation above can be done with a single backward pass via a vector-Jacobian product (JVP) <ref type="foot" target="#foot_0">1</ref> .</p><formula xml:id="formula_43">log p 1 (ψ 1 (x)) = log p 0 (ψ 0 (x)) -E Z 1 0 tr Z T ∂ x u t (ψ t (x))Z dt. (<label>3</label></formula><p>In summary, computing an unbiased estimate of log p 1 (x) entails simulating the ODE</p><formula xml:id="formula_44">d dt f (t) g(t) = u t (f (t)) -tr Z T ∂ x u t (f (t))Z , (3.34a) f (1) g(1) = x 0 ,<label>(3.34b)</label></formula><p>backwards in time, from t = 1 to t = 0, and setting:</p><formula xml:id="formula_45">log p 1 (x) = log p 0 (f (0)) -g(0). (3.35)</formula><p>See code 3 for an example on how to obtain log-likelihood estimates from a flow model using the flow_matching library.</p><p>Code 3: Computing the likelihood</p><p>1 from flow_matching.solver import ODESolver 2 from flow_matching.utils import ModelWrapper 3 from torch.distributions.normal import Normal 4 5 velocity_model: ModelWrapper = ... # Train the model parameters s.t. model(x_t, t) = ut(xt) 6 7 x_1 = torch.randn(batch_size, *data_dim) # Point X 1 where we wish to compute log p 1 (x) 8 9 # Define log p 0 (x) 10 gaussian_log_density = Normal(torch.zeros(size=data_dim), torch.ones(size=data_dim)).log_prob 11 12 solver = ODESolver(velocity_model=velocity_model) 13 num_steps = 100 14 x_0, log_p1 = solver.compute_likelihood( 15 x_1=x_1, 16 method='midpoint', 17 step_size=1.0 / num_steps, 18 log_p0=gaussian_log_density 19 )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Training flow models with simulation</head><p>The Instantaneous Change of Variables, and the resulting ODE system <ref type="bibr">(3.34)</ref>, allows training a flow model by maximizing the log-likelihood of training data <ref type="bibr">(Chen et al., 2018;</ref><ref type="bibr" target="#b27">Grathwohl et al., 2018)</ref>. Specifically, let u θ t be a velocity field with learnable parameters θ ∈ R p , and consider the problem of learning θ such that</p><formula xml:id="formula_46">p θ 1 ≈ q. (3.36)</formula><p>We can pursue this goal, for instance, by minimizing the KL-divergence of p θ 1 and q: <ref type="bibr">(3.37)</ref> where p θ 1 is the distribution of X 1 = ψ θ 1 (X 0 ), ψ θ t is defined by u θ t , and we can obtain an unbiased estimate of log p θ 1 (Y ) via the solution to the ODE system <ref type="bibr">(3.34)</ref>. However, computing this loss-as well as its gradientsrequires precise ODE simulations during training, where only errorless solutions constitute unbiased gradients. In contrast, Flow Matching, presented next, is a simulation-free framework to train flow generative models without the need of solving ODEs during training.</p><formula xml:id="formula_47">L(θ) = D KL (q, p θ 1 ) = -E Y ∼q log p θ 1 (Y ) + constant,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Flow Matching</head><p>Given a source distribution p and a target distribution q, Flow Matching (FM) <ref type="bibr" target="#b44">(Lipman et al., 2022;</ref><ref type="bibr" target="#b46">Liu et al., 2022;</ref><ref type="bibr" target="#b0">Albergo and Vanden-Eijnden, 2022</ref>) is a scalable approach for training a flow model, defined by a learnable velocity u θ t , and solving the Flow Matching Problem:</p><p>Find u θ t generating p t , with p 0 = p and p 1 = q. (4.1)</p><p>In the equation above, "generating" is in the sense of equation <ref type="bibr">(3.24)</ref>. Revisiting the Flow Matching blueprint from figure <ref type="figure" target="#fig_2">2</ref>, the FM framework (a) identifies a known source distribution p and an unknown data target distribution q, (b) prescribes a probability path p t interpolating from p 0 = p to p 1 = q, (c) learns a velocity field u θ t implemented in terms of a neural network and generating the path p t , and (d) samples from the learned model by solving an ODE with u θ t . To learn the velocity field u θ t in step (c), FM minimizes the regression loss:</p><formula xml:id="formula_48">L FM (θ) = E Xt∼pt D u t (X t ), u θ t (X t ) ,<label>(4.2)</label></formula><p>where D is a dissimilarity measure between vectors, such as the squared ℓ 2 -norm D(u, v) = ∥u -v∥ 2 . Intuitively, the FM loss encourages our learnable velocity field u θ t to match the ground truth velocity field u t known to generate the desired probability path p t . Figure <ref type="figure">9</ref> depicts the main objects in the Flow Matching framework and their dependencies. Let us start our exposition of Flow Matching by describing how to build p t and u t , as well as a practical implementation of the loss (4.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>To reiterate, let source samples be a RV X 0 ∼ p and target samples a RV X 1 ∼ q. Commonly, source samples follow a known distribution that is easy to sample, and target samples are given to us in terms of a dataset of finite size. Depending on the application, target samples may constitute images, videos, audio segments, or other types of high-dimensional, richly structured data. Source and target samples can be independent, or originate from a general joint distribution known as the coupling (X 0 , X 1 ) ∼ π 0,1 (X 0 , X 1 ), <ref type="bibr">(4.3)</ref> where, if no coupling is known, the source-target samples are following the independent coupling π 0,1 (X 0 , X 1 ) = p(X 0 )q(X 1 ). One common example of independent source-target distributions is to consider the generation of images X 1 from random Gaussian noise vectors X 0 ∼ N (0, I). As an example of a dependent coupling, consider the case of producing high-resolution images X 1 from their low resolution versions X 0 , or producing colorized videos X 1 from their gray-scale counterparts X 0 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Building probability paths</head><p>Flow Matching drastically simplifies the problem of designing a probability path p t -together with its corresponding velocity field u t -by adopting a conditional strategy. As a first example, consider conditioning the design of p t on a single target example X 1 = x 1 , yielding the conditional probability path p t|1 (x|x 1 ) illustrated in figure <ref type="figure" target="#fig_6">3a</ref>. Then, we may construct the overall, marginal probability path p t by aggregating such conditional probability paths p t|1 :</p><formula xml:id="formula_49">p t (x) = p t|1 (x|x 1 )q(x 1 )dx 1 ,<label>(4.4)</label></formula><p>as illustrated in figure 3b. To solve the Flow Matching Problem, we would like p t to satisfy the following boundary conditions:</p><formula xml:id="formula_50">p 0 = p, p 1 = q, (4.5)</formula><p>that is, the marginal probability path p t interpolates from the source distribution p at time t = 0 to the target distribution q at time t = 1. These boundary conditions can be enforced by requiring the conditional probability paths to satisfy</p><formula xml:id="formula_51">p 0|1 (x|x 1 ) = π 0|1 (x|x</formula><p>1 ), and p 1|1 (x|x 1 ) = δ x1 (x), (4.6) Flow ψ t (x) ψ t (x|x 1 )</p><formula xml:id="formula_52">tx 1 + (1 -t)x</formula><p>Velocity field</p><formula xml:id="formula_53">u t (x) u t (x|x 1 ) (x 1 -x)/(1 -t)</formula><p>Probability path p t (x)</p><formula xml:id="formula_54">p t (x|x 1 ) N (x|tx 1 , (1 -t) 2 I)</formula><p>Boundary conds.</p><formula xml:id="formula_55">p 0 = p p 1 = q p 0 = p p 1 = δ x1 p 0 = N (0, I) p 1 = δ x1 Loss Flow Matching (FM) (4.22) D u t (X t ), u θ t (X t ) Conditional FM (CFM) (4.23) D u t (X t |X 1 ), u θ t (X t )</formula><p>OT, Gauss CFM (2.9)</p><formula xml:id="formula_56">∥u θ t (X t ) -(X 1 -X 0 )∥</formula><p>2 differentiation solve ODE differentiation solve ODE Continuity (3.25) non-unique solution Continuity (3.25) non-unique solution cond. expectation ??? conditioning marginalization push-forward X0 push-forward X0 Figure 9 Main objects of the Flow Matching framework and their relationships. A Flow is represented with a Velocity field defining a random process generating a Probability path . The main idea of Flow Matching is to break down the construction of a complex flow satisfying the desired Boundary conditions (top row) to conditional flows (middle row) satisfying simpler Boundary conditions and consequently easier to solve. The arrows indicate dependencies between different objects; Blue arrows signify relationships employed by the Flow Matching framework. The Loss column lists the losses for learning the Velocity field , where the CFM loss (middle and bottom row) is what used in practice. The bottom row lists the simplest FM algorithm instantiation as described in section 2.</p><p>where the conditional coupling π 0|1 (x 0 |x 1 ) = π 0,1 (x 0 , x 1 )/q(x 1 ) and δ x1 is the delta measure centered at x 1 .</p><p>For the independent coupling π 0,1 (x 0 , x 1 ) = p(x 0 )q(x 1 ), the first constraint above reduces to p 0|1 (x|x 1 ) = p(x).</p><p>Because the delta measure does not have a density, the second constraint should be read as p t|1 (x|y)f (y)dy → f (x) as t → 1 for continuous functions f . Note that the boundary conditions (4.5) can be verified plugging (4.6) into <ref type="bibr">(4.4)</ref>.</p><p>A popular example of a conditional probability path satisfying the conditions in (4.6) was given in (2.2):</p><formula xml:id="formula_57">N (• | tx 1 , (1 -t) 2 I) → δ x1 (•) as t → 1.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Deriving generating velocity fields</head><p>Equipped with a marginal probability path p t , we now build a velocity field u t generating p t . The generating velocity field u t is an average of multiple conditional velocity fields u t (x|x 1 ), illustrated in figure <ref type="figure" target="#fig_6">3c</ref>, and satisfying:</p><formula xml:id="formula_58">u t (•|x 1 ) generates p t|1 (•|x 1 ). (4.7)</formula><p>Then, the marginal velocity field u t (x), generating the marginal path p t (x), illustrated in figure <ref type="figure" target="#fig_6">3d</ref>, is given by averaging the conditional velocity fields u t (x|x 1 ) across target examples:</p><formula xml:id="formula_59">u t (x) = u t (x|x 1 )p 1|t (x 1 |x)dx 1 . (4.8)</formula><p>To express the equation above using known terms, recall Bayes' rule</p><formula xml:id="formula_60">p 1|t (x 1 |x) = p t|1 (x|x 1 )q(x 1 ) p t (x) ,<label>(4.9)</label></formula><p>defined for all x with p t (x) &gt; 0. Equation (4.8) can be interpreted as the weighted average of the conditional velocities u t (x|x 1 ), with weights p 1|t (x 1 |x) representing the posterior probability of target samples x 1 given the current sample x. Another interpretation of (4.8) can be given with conditional expectations (see section 3.2). Namely, if X t is any RV such that X t ∼ p t|1 (•|X 1 ), or equivalently, the joint distribution of (X t , X 1 ) has density p t,1 (x, x 1 ) = p t|1 (x|x 1 )q(x 1 ) then using (3.12) to write (4.8) as a conditional expectation, we obtain</p><formula xml:id="formula_61">u t (x) = E [u t (X t |X 1 ) | X t = x] ,<label>(4.10)</label></formula><p>which yields the useful interpretation of u t (x) as the least-squares approximation to u t (X t |X 1 ) given X t = x, see section 3.2. Note, that the X t in (4.10) is in general a different RV that X t defined by the final flow model <ref type="bibr">(3.16)</ref>, although they share the same marginal probability p t (x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">General conditioning and the Marginalization Trick</head><p>To justify the constructions above, we need to show that the marginal velocity field u t from equations (4.8) and (4.10) generates the marginal probability path p t from equation (4.4) under mild assumptions. The mathematical tool to prove this is the Mass Conservation Theorem (theorem 2). To proceed, let us consider a slightly more general setting that will be useful later in the manuscript. In particular, there is nothing special about building conditional probability paths and velocity fields by conditioning on X 1 = x 1 . As noted in <ref type="bibr" target="#b80">Tong et al. (2023)</ref>, the analysis from the previous section carries through to conditioning on any arbitrary RV Z ∈ R m with PDF p Z . This yields the marginal probability path <ref type="bibr">(4.11)</ref> which in turn is generated by the marginal velocity field</p><formula xml:id="formula_62">p t (x) = p t|Z (x|z)p Z (z)dz,</formula><formula xml:id="formula_63">u t (x) = u t (x|z)p Z|t (z|x)dz = E [u t (X t |Z) | X t = x] ,<label>(4.12</label></formula><p>) where u t (•|z) generates p t|Z (•|z), p Z|t (z|x) = p t|Z (x|z)p Z (z) pt(x)</p><p>follows from Bayes' rule given p t (x) &gt; 0, and X t ∼ p t|Z (•|Z). Naturally, we can recover the constructions in previous sections by setting Z = X 1 . Before we prove the main result, we need some regularity assumptions, encapsulated as follows.</p><formula xml:id="formula_64">Assumption 1. p t|Z (x|z) is C 1 ([0, 1) × R d ) and u t (x|z) is C 1 ([0, 1) × R d , R d</formula><p>) as a function of (t, x). Furthermore, p Z has bounded support, that is, p Z (x) = 0 outside some bounded set in R m . Finally, p t (x) &gt; 0 for all x ∈ R d and t ∈ [0, 1).</p><p>These are mild assumptions. For example, one can show that p t (x) &gt; 0 by finding a condition z such that p Z (z) &gt; 0 and p t|Z (•|z) &gt; 0. In practice, one can satisfy this by considering (1 -(1 -t)ϵ)p t|Z + (1 -t)ϵN (0, I) for an arbitrarily small ϵ &gt; 0. One example of p t|Z (•|z) satisfying this assumption is the path in (2.2), where we let Z = X 1 . We are now ready to state the main result: Theorem 3 (Marginalization Trick). Under assumption 1, if u t (x|z) is conditionally integrable and generates the conditional probability path p t (•|z), then the marginal velocity field u t generates the marginal probability path p t , for all t ∈ [0, 1).</p><p>In the theorem above, conditionally integrable refers to a conditional version of the integrability condition from the Mass Conservation Theorem <ref type="bibr">(3.26)</ref>, namely:</p><formula xml:id="formula_65">1 0 ∥u t (x|z)∥ p t|Z (x|z)p Z (x)dzdxdt &lt; ∞. (<label>4</label></formula><p>.13) Proof. The result follows from verifying the two conditions of the Mass Conservation in theorem 2. First, let us check that the pair (u t , p t ) satisfies the Continuity Equation (3.25). Because u t (•|x 1 ) generates p t (•|x 1 ), we have that d dt p t (x) (i) = d dt p t|Z (x|z)p Z (x)dz (4.14) (ii) = -div x u t (x|z)p t|Z (x|z) p Z (z)dz (4.15) (i) = -div x u t (x|z)p t|Z (x|z)p Z (z)dz (4.16)</p><formula xml:id="formula_66">(iii) = -div x [u t (x)p t (x)] . (4.17)</formula><p>Equalities (i) follows from switching differentiation ( d dt and div x , respectively) and integration, as justified by Leibniz's rule, the fact that p t|Z (x|z) and u t (x|z) are C 1 in t, x, and the fact that p Z has bounded support (so all the integrands are integrable as continuous functions over bounded sets). Equality (ii) follows from the fact that u t (•|z) generates p t|Z (•|z) and theorem 2. Equality (iii) follows from multiplying and dividing by p t (x) (strictly positive by assumption) and using the formula (4.12) for u t .</p><p>To verify the second and last condition from theorem 2, we shall prove that u t is integrable and locally Lipschitz. Because C 1 functions are locally Lipschitz, it suffices to check that u t (x) is C 1 for all (t, x). This would follow from verifying that u t (x|z) and p t|Z (x|z) are C 1 and p t (x) &gt; 0, which hold by assumption. Furthermore, u t (x) is integrable because u t (x|z) is conditionally integrable:</p><formula xml:id="formula_67">1 0 ∥u t (x)∥ p t (x)dxdt ≤ 1 0 ∥u t (x|z)∥ p t|Z (x|z)p Z (z)dzdxdt &lt; ∞,<label>(4.18)</label></formula><p>where the first inequality follows from vector Jensen's inequality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Flow Matching loss</head><p>After having established that the target velocity field u t generates the prescribed probability path p t from p to q, the missing ingredient is a tractable loss function to learn a velocity field model u θ t as close as possible to the target u t . One major roadblock towards stating this loss function directly is that computing the target u t is infeasible, as it requires marginalizing over the entire training set (that is, integrating with respect to x 1 in equation <ref type="bibr">(4.8)</ref> or with respect to z in equation (4.12)). Fortunately, a family of loss functions known as Bregman divergences provides unbiased gradients to learn u θ t (x) in terms of conditional velocities u t (x|z) alone. Bregman divergences measure dissimilarity between two vectors u, v ∈ R d as</p><formula xml:id="formula_68">D(u, v) := Φ(u) -[Φ(v) + ⟨u -v, ∇Φ(v)⟩] ,<label>(4.19)</label></formula><p>where Φ : R d → R is a strictly convex function defined over some convex set Ω ⊂ R d . As illustrated in figure <ref type="figure" target="#fig_14">10</ref>, the Bregman divergence measures the difference between Φ(u) and the linear approximation to Φ developed around v and evaluated at u. Because linear approximations are global lower bounds for convex functions, it holds that D(u, v) ≥ 0. Further, as</p><formula xml:id="formula_69">Φ is strictly convex, it follows that D(u, v) = 0 if and only if u = v. The most basic Bregman divergence is the squared Euclidean distance D(u, v) = ∥u -v∥ 2 , esulting from choosing Φ(u) = ∥u∥ 2 .</formula><p>The key property that makes Bregman divergences useful for Flow Matching is that their gradient with respect to the second argument is affine invariant <ref type="bibr" target="#b33">(Holderrieth et al., 2024)</ref>:</p><formula xml:id="formula_70">∇ v D(au 1 + bu 2 , v) = a∇ v D(u 1 , v) + b∇ v D(u 2 , v), for any a + b = 1, (4.20)</formula><p>as it can be verified from equation <ref type="bibr">(4.19)</ref>. Affine invariance allows us to swap expected values with gradients as follows:</p><formula xml:id="formula_71">∇ v D(E[Y ], v) = E[∇ v D(Y, v)] for any RV Y ∈ R d . (4.21)</formula><p>The Flow Matching loss employs a Bregman divergence to regress our learnable velocity u θ t (x) onto the target velocity u t (x) along the probability path p t :</p><formula xml:id="formula_72">L FM (θ) = E t,Xt∼pt D(u t (X t ), u θ t (X t )),<label>(4.22)</label></formula><p>where time t ∼ U [0, 1]. As mentioned above, however, the target velocity u t is not tractable, so the loss above cannot be computed as is. Instead, we consider the simpler and tractable Conditional Flow Matching (CFM) loss:</p><formula xml:id="formula_73">L CFM (θ) = E t,Z,Xt∼p t|Z (•|Z) D(u t (X t |Z), u θ t (X t )). (4.23)</formula><p>The two losses are equivalent for learning purposes, since their gradients coincide <ref type="bibr" target="#b33">(Holderrieth et al., 2024)</ref>:</p><p>Theorem 4. The gradients of the Flow Matching loss and the Conditional Flow Matching loss coincide:</p><formula xml:id="formula_74">∇ θ L FM (θ) = ∇ θ L CFM (θ). (4.24)</formula><p>In particular, the minimizer of the Conditional Flow Matching loss is the marginal velocity u t (x).</p><p>Proof. The proof follows a direct computation:</p><formula xml:id="formula_75">∇ θ L FM (θ) = ∇ θ E t,Xt∼pt D(u t (X t ), u θ t (X t )) = E t,Xt∼pt ∇ θ D(u t (X t ), u θ t (X t )) (i) = E t,Xt∼pt ∇ v D(u t (X t ), u θ t (X t ))∇ θ u θ t (X t ) (4.12) = E t,Xt∼pt ∇ v D(E Z∼p Z|t (•|Xt) [u t (X t |Z)], u θ t (X t ))∇ θ u θ t (X t ) (ii) = E t,Xt∼pt E Z∼p Z|t (•|Xt) ∇ v D(u t (X t |Z), u θ t (X t ))∇ θ u θ t (X t ) (iii) = E t,Xt∼pt E Z∼p Z|t (•|Xt) [∇ θ D(u t (X t |Z), u θ t (X t ))] (iv) = ∇ θ E t,Z∼q,Xt∼p t|Z (•|Z) [D(u t (X t |Z), u θ t (X t ))] = ∇ θ L CFM (θ)</formula><p>where in (i),(iii) we used the chain rule; (ii) follows from equation ( <ref type="formula" target="#formula_48">4</ref>.21) applied conditionally on X t ; and in (iv) we use Bayes' rule.</p><p>Bregman divergences for learning conditional expectations. Theorem 4 is a particular instance of a more general result utilizing Bregman divergences for learning conditional expectations described next. It will be used throughout this manuscript and provide the basis for all scalable losses behind Flow Matching:</p><formula xml:id="formula_76">Proposition 1 (Bregman divergence for learning conditional expectations). Let X ∈ S X , Y ∈ S Y be RVs over state spaces S X , S Y and g : R p × S X → R n , (θ, x) → g θ (x), where θ ∈ R p denotes learnable parameters. Let D x (u, v), x ∈ S X be a Bregman divergence over a convex set Ω ⊂ R n that contains the image of f . Then, ∇ θ E X,Y D X Y , g θ (X) = ∇ θ E X D X E [Y | X], g θ (X) . (4.25)</formula><p>In particular, for all x with p X (x) &gt; 0, the global minimum of g θ (x) w.r.t. θ satisfies</p><formula xml:id="formula_77">g θ (x) = E [Y | X = x]. (4.26)</formula><p>Proof. We assume g θ is differentiable w.r.t. θ and that the distributions of X and Y , as well as D x , and g allow switching differentiation and integration, develop:</p><formula xml:id="formula_78">∇ θ E X,Y D X Y, g θ (X) (i) = E X E ∇ v D X Y, g θ (X) ∇ θ g θ (X) | X (ii) = E X ∇ v D X E [Y | X], g θ (X) ∇ θ g θ (X) (iii) = E X ∇ θ D X E [Y | X], g θ (X) = ∇ θ E X D X E [Y | X], g θ (X) ,</formula><p>where (i) follows from the chain rule and the tower property of expectations <ref type="bibr">(3.11)</ref>. Equality (ii) follows from <ref type="bibr">(4.21)</ref>. Equality (iii) uses the chain rule again. Lastly, for every x ∈ S X with p X (x) &gt; 0 we can choose</p><formula xml:id="formula_79">g θ (x) = E [Y |X = x], obtaining E X D X E [Y | X],</formula><p>g θ (X) = 0, which must be the global minimum with respect to θ.</p><p>Theorem 4 is readily shown from proposition 1 by making the choices</p><formula xml:id="formula_80">X = X t , Y = u t (X t |Z), g θ (x) = u θ t (x)</formula><p>, and taking the expectation with respect to t ∼ U [0, 1].</p><p>General time distributions One useful variation of the FM loss is to sample times t from a distribution other than Uniform. Specifically, consider t ∼ ω(t), where ω is a PDF over <ref type="bibr">[0,</ref><ref type="bibr" target="#b87">1]</ref>. This leads to the following weighted objective:</p><formula xml:id="formula_81">L CFM (θ) = E t∼ω,Z,Xt D(u t (X t |Z), u θ t (X t )) = E t∼U,Z,Xt ω(t)D(u t (X t |Z), u θ t (X t )). (4.27)</formula><p>Although mathematically equivalent, sampling t ∼ ω leads to better performance than using weights ω(t) in large scale image generation tasks <ref type="bibr" target="#b21">(Esser et al., 2024)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Solving conditional generation with conditional flows</head><p>So far, we have reduced the problem of training a flow model u θ t to: (i) Find conditional probability paths p t|Z (x|z) yielding a marginal probability path p t (x) satisfying the boundary conditions in (4.5). (ii) Find conditional velocity fields u t (x|z) generating the conditional probability path. (iii) Train using the Conditional Flow Matching loss (see equation <ref type="bibr">(4.23)</ref>). We now discuss a concrete options on how to do step (i) and (ii), i.e., design such conditional probability paths and velocity fields.</p><p>We will now propose a flexible method to design such conditional probability paths and velocity fields using a specific construction via conditional flows. The idea is as follows: Define a flow model X t|1 (similarly to <ref type="bibr">(3.16</ref>)) satisfying the boundary conditions (4.6), and extract the velocity field from X t|1 by differentiation <ref type="bibr">(3.20)</ref>. This process defines both p t|1 (x|x 1 ) and u t (x|x 1 ). In more detail, define the conditional flow model</p><formula xml:id="formula_82">X t|1 = ψ t (X 0 |x 1 ), where X 0 ∼ π 0|1 (• | x 1 ),<label>(4.28)</label></formula><p>where</p><formula xml:id="formula_83">ψ : [0, 1) × R d × R d → R d is a conditional flow defined by ψ t (x|x 1 ) = x t = 0 x 1 t = 1 ,<label>(4.29)</label></formula><p>smooth in (t, x), and a diffeomorphism in x. (Smooth here means that all derivatives of ψ t (x|x 1 ) with respect to t and x exist and are continuous:</p><formula xml:id="formula_84">C ∞ ([0, 1) × R d , R d ))</formula><p>. These conditions could be further relaxed to</p><formula xml:id="formula_85">C 2 ([0, 1) × R d , R d</formula><p>) at the expense of simplicity.) The push-forward formula (3.15) defines the probability density of X t|1 as</p><formula xml:id="formula_86">p t|1 (x|x 1 ) := ψ t (•|x 1 ) ♯ π 0|1 (•|x 1 ) (x),<label>(4.30)</label></formula><p>although we will not need this expression in practical optimization of the CFM loss it is used theoretically to show that p t|1 satisfies the two boundary conditions <ref type="bibr">(4.6)</ref>. First, and according to (4.29), ψ 0 (•|x 1 ) is the identity map, keeping π 0|1 (•|x 1 ) intact at time t = 0. Second, ψ 1 (•|x 1 ) = x 1 is the constant map, concentrating all probability mass at x 1 as t → 1. Furthermore, note that ψ t (•|x 1 ) is a smooth diffeomorphism for t ∈ [0, 1). Therefore, by the equivalence of flows and velocity fields (section 3.4.1), there exists a unique smooth conditional velocity field (see equation <ref type="bibr">(3.20</ref>)) taking form:</p><formula xml:id="formula_87">u t (x|x 1 ) = ψt (ψ -1 t (x|x 1 )|x 1 ). (4.31)</formula><p>To summarize: we have further reduced the task of finding the conditional path and a corresponding generating velocity to simply building a conditional flow ψ t (•|x 1 ) satisfying (4.29). In section 4.7 we will pick a particularly simple ψ t (x|x 1 ) with some desirable properties (conditional Optimal Transport flow) that leads to the standard Flow Matching algorithm as seen in section 1, and in section 4.8 we will discuss a particular and well-known family of conditional flows, namely affine flows that include some known examples from the diffusion models' literature. In section 5 we will use conditional flows to define Flow Matching on manifold which showcase the flexibility of this approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.1">The Conditional Flow Matching loss, revisited</head><p>Let us revisit the CFM loss (4.23) by setting Z = X 1 and using the conditional flows way of defining the conditional probability path and velocity,</p><formula xml:id="formula_88">L CFM (θ) = E t,X1,Xt∼pt(•|X1) D u t (X t |X 1 ), u θ t (X t ) (3.4) = E t,(X0,X1)∼π0,1 D ψt (X 0 |X 1 ), u θ t (X t ) (4.32)</formula><p>where in the second equality we used the Law of Unconscious Statistician with X t = ψ t (X 0 |X 1 ) and</p><formula xml:id="formula_89">u t (X t |X 1 ) (4.31) = ψt ψ -1 t ψ t (X 0 |X 1 ) X 1 X 1 = ψt (X 0 |X 1 ). (4.33)</formula><p>The minimizer of the loss (4.32) according to proposition 1 takes the form as in <ref type="bibr" target="#b46">(Liu et al., 2022)</ref>,</p><formula xml:id="formula_90">u t (x) = E ψt (X 0 |X 1 ) X t = x .<label>(4.34)</label></formula><p>In the flow_matching library the ProbPath object defines a probability path. This probability path can be sampled at (t, X 0 , X 1 ) to obtain X t and ψt (X 0 |X 1 ). Then, one can compute a Monte Carlo estimate of the CFM loss L CFM (θ). An example training loop with the CFM objective is shown in code 4.  </p><formula xml:id="formula_91">p t (x) = u t (x) = X1 conditioning ψ t (X 0 |x 1 ) ∼ p t|1 (•|x 1 ) p t|1 (x|x 1 )q(x 1 )dx 1 E [u t (X t |X 1 )|X t = x] = = X0 conditioning ψ t (X 1 |x 0 ) ∼ p t|0 (•|x 0 ) p t|0 (x|x 0 )p(x 0 )dx 1 E [u t (X t |X 0 )|X t = x] = = (X0,X1) conditioning ψ t (x 0 , x 1 ) ∼ p t|0,1 (•|x 0 , x 1 ) p t|0,1 (x|x 0 , x 1 )π 0,1 (x 0 , x 1 )dx 0 dx 1 E [u t (X t |X 0 , X 1 )|X t = x]</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.2">The Marginalization Trick for probability paths built from conditional flows</head><p>Next, we introduce a version of the Marginalization trick for probability paths that are built from conditional flows. To this end, note that if</p><formula xml:id="formula_92">π 0|1 (•|x 1 ) is C 1 , then p t (x|x 1 ) is also C 1 by construction; moreover, u t (x|x 1 ) is conditionally integrable if E t,(X0,X1)∼π0,1 ψt (X 0 |X 1 ) &lt; ∞.<label>(4.35)</label></formula><p>Therefore, by setting Z = X 1 , the following corollary to theorem 3 is obtained.</p><formula xml:id="formula_93">Corollary 1. Assume that q has bounded support, π 0|1 (•|x 1 ) is C 1 (R d</formula><p>) and strictly positive for some x 1 with q(x 1 ) &gt; 0, and ψ t (x|x 1 ) is a conditional flow satisfying equations (4.29) and (4.35). Then p t|1 (x|x 1 ) and u t (x|x 1 ), defined in (4.30) and (4.31), respectively, define a marginal velocity field u t (x) generating the marginal probability path p t (x) interpolating p and q.</p><p>Proof. <ref type="bibr">(4.30</ref>) and (3.15) for definitions). Furthermore, u t (x|x 1 ) (defined in (4.31)) is smooth and satisfies</p><formula xml:id="formula_94">If π 0|1 (•|x 1 ) &gt; 0 for some x 1 ∈ R d such that q(x 1 ) &gt; 0, it follows that p t|1 (x|x 1 ) &gt; 0 for all x ∈ R d and is C 1 ([0, 1) × R d ) (see</formula><formula xml:id="formula_95">1 0 ∥u t (x|x 1 )∥ p t|1 (x|x 1 )q(x 1 )dx 1 dxdt = E t,X1∼q,Xt∼p t|1 (•|X1) ∥u t (X t |X 1 )∥ (3.4) = E t,X1∼q,X0∼π 0|1 (•|X1) ∥u t (ψ t (X 0 |X 1 )|X 1 )∥ (4.33) = E t,(X0,X1)∼π0,1 ψt (X 0 |X 1 ) &lt; ∞.</formula><p>Therefore, u t (x|x 1 ) is conditionally integrable (see <ref type="bibr">(4.13))</ref>. By theorem 3, the marginal u t generates p t . Because p t|1 (x|x 1 ) as defined by (4.30) satisfies (4.6), it follows that p t interpolates p and q.</p><p>This theorem will be used as a tool to show that particular choices of conditional flows lead to marginal velocity u t (x) generating the marginal probability path p t (x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.3">Conditional flows with other conditions</head><p>Different conditioning choices Z exist but are essentially all equivalent. As illustrated in figure <ref type="figure" target="#fig_16">11</ref>, main options include fixing target samples Z = X 1 <ref type="bibr" target="#b44">(Lipman et al., 2022)</ref>, source samples Z = X 0 <ref type="bibr" target="#b21">(Esser et al., 2024)</ref>, or two-sided Z = (X 0 , X 1 ) (Albergo and Vanden-Eijnden, 2022; <ref type="bibr" target="#b46">Liu et al., 2022;</ref><ref type="bibr" target="#b64">Pooladian et al., 2023;</ref><ref type="bibr" target="#b80">Tong et al., 2023)</ref>.</p><p>Let us focus on the two-sided condition Z = (X 0 , X 1 ). Following the FM blueprint described above, we are now looking to build a conditional probability path p t|0,1 (x|x 0 , x 1 ) and a corresponding generating velocity u t (x|x 0 , x 1 ) such that p 0|0,1 (x|x 0 , x 1 ) = δ x0 (x), and p 1|0,1 (x|x 0 , x 1 ) = δ x1 (x). (4.36)</p><p>We will keep this discussion formal as it requires usage of delta functions δ and our existing derivations so far only deals with probability densities (and not general distributions). To build such a path we can consider an interpolant (Albergo and Vanden-Eijnden, 2022) defined by X t|0,1 = ψ t (x 0 , x 1 ) for a function</p><formula xml:id="formula_96">ψ : [0, 1] × R d × R d → R d satisfying conditions similar to (4.29), ψ t (x 0 , x 1 ) = x 0 t = 0 x 1 t = 1. (4.37) Therefore, ψ t (•, x 1 ) pushes δ x0 (x) to δ x1 (x)</formula><p>. We now, similarly to before, define the conditional probability path to be</p><formula xml:id="formula_97">p t|0,1 (•|x 0 , x 1 ) := ψ t (•, x 1 ) ♯ δ x0 (•) (4.38)</formula><p>which satisfies the boundary constraints in <ref type="bibr">(4.36)</ref>. Albergo and Vanden-Eijnden (2022)'s stochastic interpolant is defined by</p><formula xml:id="formula_98">X t = ψ t (X 0 , X 1 ) ∼ p t (•) = p t|0,1 (•|x 0 , x 1 )π 0,1 (x 0 , x 1 )dx 0 dx 1 . (4.39)</formula><p>Next, the conditional velocity along this path can also be computed with <ref type="bibr">(3.20)</ref> giving</p><formula xml:id="formula_99">u t (x|x 0 , x 1 ) = ψt (x 0 , x 1 ) (4.40)</formula><p>which is defined only for x = ψ t (x 0 , x 1 ). Ignoring for a second the extra conditions, Theorem 3 now presumably implies that the marginal velocity generating p t (x) is</p><formula xml:id="formula_100">u t (x) = E [u t (X t |X 0 , X 1 ) | X t = x] = E ψt (X 0 , X 1 ) | X t = x ,</formula><p>which leads to the same marginal formula as the X 1 -conditioned case (4.34), but with a seemingly more permissive conditional flow ψ t (x 0 , x 1 ) which is only required to be an interpolant now, weakening the more stringent diffeomorphism condition. However, A more careful look reveals that some extra conditions are still required to make u t (x) a generating velocity for p t (x) and simple interpolation (as defined in (4.37)) is not enough to guarantee this, not even with extra smoothness conditions, as required in Theorem 3. To see this, consider</p><formula xml:id="formula_101">ψ t (x 0 , x 1 ) = (1 -2t) τ + x 0 + (2t -1) τ + x 1 , where (s) + = ReLU(s), τ &gt; 2, a C 2 ([0, 1]</formula><p>) interpolant (in time) concentrating all probability mass at location 0 at time t = 0.5 for all x 0 , x 1 . That is P(X 1 2 = 0) = 1. Therefore, assuming u t (x) indeed generates p t (x) its marginal at t = 1 2 is δ 0 and since a flow is both Markovian (as shown in (3.17)) and deterministic its marginal has to be a delta function for all t &gt; 0.5 leading to a contradiction since X 1 = ψ 1 (X 0 , X 1 ) ∼ q, which is generally not a delta function. Albergo and Vanden-Eijnden (2022) and <ref type="bibr" target="#b46">Liu et al. (2022)</ref> provide some extra conditions that guarantee that u t (x) indeed geenrates p t (x) but these are somewhat harder to verify compared to the conditions of Theorem 3. Below we will show how to practically check the conditions of Theorem 3 to validate that particular paths of interest are guaranteed to be generated by the respective marginal velocities.</p><p>Nevertheless, when ψ t (x 0 , x 1 ) is in addition a diffeomorphism in x 0 for a fixed x 1 , and in x 1 for a fixed x 0 , the three constructions leads to the same marginal velocity, defined by (4.34), and same marginal probability path p t , defined by</p><formula xml:id="formula_102">X t = ψ t (X 0 , X 1 ) = ψ t (X 0 |X 1 ) = ψ t (X 1 |X 0 ), see Figure 11.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Optimal Transport and linear conditional flow</head><p>We now ask: how to find a useful conditional flow ψ t (x|x 1 )? One approach is to choose it as a minimizer of a natural cost functional, ideally with some desirable properties. One popular example of such cost functional is the dynamic Optimal Transport problem with quadratic cost <ref type="bibr">(Villani et al., 2009;</ref><ref type="bibr" target="#b81">Villani, 2021;</ref><ref type="bibr" target="#b61">Peyré et al., 2019)</ref>, formalized as</p><formula xml:id="formula_103">(p ⋆ t , u ⋆ t ) = arg min pt,ut 1 0 ∥u t (x)∥ 2 p t (x)dxdt (Kinetic Energy) (4.41a) s.t. p 0 = p, p 1 = q (interpolation) (4.41b) d dt p t + div(p t u t ) = 0. (continuity equation) (4.41c)</formula><p>The (p ⋆ t , u ⋆ t ) above defines a flow (via equation <ref type="bibr">(3.19</ref>)) with the form</p><formula xml:id="formula_104">ψ ⋆ t (x) = tϕ(x) + (1 -t)x,<label>(4.42)</label></formula><p>called the OT displacement interpolant <ref type="bibr" target="#b53">(McCann, 1997)</ref>, where ϕ : R d → R d is the Optimal Transport map.</p><p>The OT displacement interpolant also solves the Flow Matching Problem (4.1) by defining the random variable</p><formula xml:id="formula_105">X t = ψ ⋆ t (X 0 ) ∼ p ⋆ t when X 0 ∼ p. (4.43)</formula><p>The Optimal Transport formulation promotes straight sample trajectories</p><formula xml:id="formula_106">X t = ψ ⋆ t (X 0 ) = X 0 + t(ϕ(X 0 ) -X 0 ),</formula><p>with a constant velocity ϕ(X 0 ) -X 0 , which are in general easier to sample with ODE solvers-in particular, the target sample X 1 is here perfectly solvable with a single step of the Euler Method <ref type="bibr">(3.21)</ref>.</p><p>We can now try to plug our marginal velocity formula (equation (4.34)) into the Optimal Transport problem (4.41) and search for an optimal ψ t (x|x 1 ). While this seems like a challenge, we can instead find a bound for the Kinetic Energy for which such a minimizer is readily found <ref type="bibr" target="#b46">(Liu et al., 2022)</ref>:</p><formula xml:id="formula_107">1 0 E Xt∼pt ∥u t (X t )∥ 2 dt = 1 0 E Xt∼pt E ψt (X 0 |X 1 ) X t 2 dt (4.44) (i) ≤ 1 0 E Xt∼pt E ψt (X 0 |X 1 ) 2 X t dt (4.45) (ii) = E (X0,X1)∼π0,1 1 0 ψt (X 0 |X 1 ) 2 dt,<label>(4.46)</label></formula><p>where in the (i) we used Jensen's inequality, and in (ii) we used the tower property of conditional expectations (see equation <ref type="bibr">(3.11)</ref>) and switch integration of t and expectation. Now the integrand in (4.46) can be minimized individually for each (X 0 , X 1 ) -this leads to the following variational problem for γ t = ψ t (x|x 1 ):</p><formula xml:id="formula_108">min γ:[0,1]→R d 1 0 ∥ γt ∥ 2 dt (4.47a) s.t. γ 0 = x, γ 1 = x 1 . (4.47b)</formula><p>This problem can be solved using Euler-Lagrange equations <ref type="bibr" target="#b26">(Gelfand et al., 2000)</ref>, which in this case take the form d 2 dt 2 γ t = 0. By incorporating the boundary conditions, we obtain the minimizer:</p><formula xml:id="formula_109">ψ t (x|x 1 ) = tx 1 + (1 -t)x. (4.48)</formula><p>Note that although not constrained to be, this choice of ψ t (x|x 1 ) is a diffeomorphism in x for t ∈ [0, 1) and smooth in t, x, as required from conditional flows.</p><p>Several conclusions can be drawn:</p><p>1. The linear conditional flow minimizes a bound of the Kinetic Energy among all conditional flows.</p><p>2. In case the target q consists of a single data point q(x) = δ x1 (•) we have that the linear conditional flow in (4.48) is the Optimal Transport <ref type="bibr" target="#b44">(Lipman et al., 2022)</ref>. Indeed, in this case X t = ψ t (X 0 |x 1 ) ∼ p t and</p><formula xml:id="formula_110">X 0 = ψ -1 (X t |x 1 ) is a function of X t which makes E ψt (X 0 |x 1 ) X t = ψt (X 0 |x 1 )</formula><p>and therefore (ii) becomes an equality.</p><p>Theorem 5. If q = δ x1 , then the dynamic OT problem (4.41) has an analytic solution given by the OT displacement interpolant in (4.48).</p><p>3. Plugging the linear conditional flow in (4.46) we get</p><formula xml:id="formula_111">1 0 E Xt∼pt ∥u t (X t )∥ 2 dt ≤ E (X0,X1)∼π0,1 1 0 ∥X 1 -X 0 ∥ 2 dt (4.49)</formula><p>showing that the Kinetic Energy of the marginal velocity u t (x) is not bigger than that of the original coupling π 0,1 <ref type="bibr" target="#b46">(Liu et al., 2022)</ref>.</p><p>The conditional flow in (4.48) is in particular affine and consequently motivates investigating the family of affine conditional flows, discussed next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">Affine conditional flows</head><p>In the previous section we discovered the linear (Conditional-OT) flows as a minimizer to a bound of the Kinetic Energy among all conditional flows. The linear conditional flow is a particular instance the wider family of affine conditional flows, explored in this section.</p><formula xml:id="formula_112">ψ t (x|x 1 ) = α t x 1 + σ t x,<label>(4.50)</label></formula><p>where α t , σ t : [0, 1] → [0, 1] are smooth functions satisfying α 0 = 0 = σ 1 , α 1 = 1 = σ 0 , and αt , -σt &gt; 0 for t ∈ (0, 1). (4.51)</p><p>We call the pair (α t , σ t ) a scheduler. The derivative condition above ensures that α t is strictly monotonically increasing, while σ t is strictly monotonically decreasing. The conditional flow (4.50) is a simple affine map in x for each t ∈ [0, 1), which satisfies the conditions (4.29). The associated marginal velocity field (4.34) is</p><formula xml:id="formula_113">u t (x) = E [ αt X 1 + σt X 0 |X t = x] . (4.52)</formula><p>By virtue of corollary 1, we can prove that, if using the independent coupling and a smooth and strictly positive source density p with finite second moments-for instance, a Gaussian p = N (•|0, I)-then u t generates a probability path p t interpolating p and q. We formally state this result, significant for Flow Matching applications, as the following theorem.</p><p>Theorem 6. Assume that q has bounded support, p is C 1 (R d ) with strictly positive density with finite second moments, and these two relate by the independent coupling π 0,1 (x 0 , x 1 ) = p(x 0 )q(x 1 ). Let p t (x) = p t|1 (x|x 1 )q(x 1 )dx 1 be defined by equation (4.30), with ψ t defined by equation (4.50). Then, the marginal velocity (4.52) generates p t interpolating p and q.</p><p>Proof. We apply corollary 1. First, note that π 0|1 (•|x 1 ) = p(•) is C 1 and positive everywhere by assumption. Second, ψ t , defined in (4.50), satisfies <ref type="bibr">(4.29)</ref>. Third, we are left with checking (4.35):</p><formula xml:id="formula_114">E t,(X0,X1) ψ(X 0 |X 1 ) = E t,(X0,X1) ∥ αt X 1 + σt X 0 ∥ ≤ E t | αt | E X1 ∥X 1 ∥ + E t | σt | E X0 ∥X 0 ∥ = E X1 ∥X 1 ∥ + E X0 ∥X 0 ∥ &lt; ∞,</formula><p>where the last inequality follows from the fact that X 1 ∼ q has bounded support and X 0 ∼ p has bounded second moments.</p><p>In this affine case, the CFM loss (4.32) takes the form </p><formula xml:id="formula_115">L CFM (θ) = E t,(X0,X1)∼π0,1 D( αt X 1 + σt X 0 , u θ t (X t )) . (<label>4</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8.1">Velocity parameterizations</head><p>In the affine case, the marginal velocity field u t admits multiple parametrizations, each of them learnable using the Flow Matching losses introduced in section 4.5. To derive these parametrizations, use the equivalent formulations of the affine paths</p><formula xml:id="formula_116">X t = α t X 1 + σ t X 0 ⇔ X 1 = X t -σ t X 0 α t ⇔ X 0 = X t -α t X 1 σ t , (4.54)</formula><p>in the marginal velocity formula (4.52), obtaining</p><formula xml:id="formula_117">u t (x) = αt E [X 1 |X t = x] + σt E [X 0 |X t = x] (4.55) = σt σ t x + αt -α t σt σ t E [X 1 |X t = x] (4.56) = αt α t x + σt -σ t αt α t E [X 0 |X t = x],<label>(4.57)</label></formula><p>where we have used the fact that E [Z|Z = z] = z. Then, denote the deterministic functions:</p><formula xml:id="formula_118">x 1|t (x) = E [X 1 |X t = x] as the x 1 -prediction (target), (4.58) x 0|t (x) = E [X 0 |X t = x] as the x 0 -prediction (source). (4.59)</formula><p>These provides two more opportunities to parameterize u t : via the x 1 -prediction x 1|t (4.56) and via the x 0 -prediction x 0|t (4.57). Table <ref type="table">1</ref> offers conversion formulas between the parameterizations. These parameterizations can also be learned using a Conditional Matching loss, similar to (4.23). In particular, any function</p><formula xml:id="formula_119">g t (x) := E [f t (X 0 , X 1 )|X t = x] ,<label>(4.60)</label></formula><p>where f t (X 0 , X 1 ) is a RV defined as a time-dependent function of X 0 and X 1 , can be learned by minimizing a Matching loss of the form</p><formula xml:id="formula_120">L M (θ) = E t,Xt∼pt D g t (X t ), g θ t (X t ) . (4.61)</formula><p>This loss has the same gradients as the Conditional Matching loss</p><formula xml:id="formula_121">L CM (θ) = E t,(X0,X1)∼π0,1 D f t (X 0 , X 1 ), g θ t (X t ) . (4.62)</formula><p>To learn x 1|t , the Conditional Matching loss employs f t (x 0 , x 1 ) = x 1 , and similarly for x 0|t . This procedure is justified by theorem 7, which is an immediate result from proposition 1 when letting X = X t , Y = f t (X 0 , X 1 ), and integrating with respect to t ∼ U [0, 1].</p><p>Theorem 7. The gradients of the Matching loss and the Conditional Matching loss coincide for arbitrary functions f t (X 0 , X 1 ) of X 0 , X 1 :</p><formula xml:id="formula_122">∇ θ L M (θ) = ∇ θ L CM (θ). (4.63)</formula><p>In particular, the minimizer of the Conditional Matching loss is the conditional expectation</p><formula xml:id="formula_123">g θ t (x) = E [f t (X 0 , X 1 )|X t = x] . (4.64)</formula><p>Code 6 shows how to train with x 1 -prediction using the flow_matching library.  Singularities in the velocity parameterizations. Seemingly, the coefficients of (4.56) would blow up as t → 1, and similarly for (4.57</p><formula xml:id="formula_124">) as t → 0. If E [X 1 |X 0 = x] and E [X 0 |X 1 = x]</formula><p>exist, which is the case for p(x) &gt; 0 and q(x) &gt; 0, these are not essential singularities in theory, meaning that the singularities in x 1|t and x 0|t would cancel with the singularities of the coefficients of the parameterization. However, these singularities could be still problematic in practice when the learnable x θ 1|t and x θ 0|t are by construction continuous and therefore do not perfectly regress their targets x 1|t and x 0|t . To understand how to fix these potential issues, recall (4.55) and consider u 0</p><formula xml:id="formula_125">(x) = α0 E [X 1 |X 0 = x] + σ0 x as t → 0, and u 1 (x) = α1 x + σ1 E [X 0 |X 1 = x] as t → 1.</formula><p>These can be computed in many cases of interest. Returning to our example π 0,1 (x 0 , x 1 ) = N (x 0 |0, I)q(x 1 )</p><p>and assuming E X1 X 1 = 0, it follows that u 0 (x) = σ0 x and u 1 (x) = α1 x. These expressions can be used to fix singularities when converting from x 1|t and x 0|t to u t (x) as t → 1 or t → 0, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8.2">Post-training velocity scheduler change</head><p>Affine conditional flows admit a closed-form transformation from a marginal velocity field u t (x), based on a scheduler (α t , σ t ) and an arbitrary data coupling π 0,1 , to a marginal velocity field ūr (x), based on a different scheduler (ᾱ r , σr ) and the same data coupling π 0,1 . Such a transformation is useful to adapt a trained velocity field to a different scheduler, potentially improving sample efficiency and quality generation <ref type="bibr" target="#b40">(Karras et al., 2022;</ref><ref type="bibr">Shaul et al., 2023b;</ref><ref type="bibr" target="#b62">Pokle et al., 2023)</ref>. To proceed, define the scale-time (ST) transformation (s r , t r ) between the two conditional flows:</p><p>ψr (x 0 |x 1 ) = s r ψ tr (x 0 |x 1 ), <ref type="bibr">(4.65)</ref> where ψ t (x 0 |x 1 ) = α t x 1 + σ t x 0 , ψr (x 0 |x 1 ) = ᾱr x 1 + σr x 0 , and s, t</p><formula xml:id="formula_126">: [0, 1] → R ≥0 are time-scale reparametriza- tions. Solving (4.65) yields t r = ρ -1 (ρ(r)) s r = σr /σ tr ,<label>(4.66)</label></formula><p>where we define the signal-to-noise ratio by</p><formula xml:id="formula_127">ρ(t) = α t σ t ρ(t) = ᾱt σt ,<label>(4.67)</label></formula><p>assumed to be an invertible function. The marginal velocity ūr (x) for the new scheduler (ᾱ r , σr ) follows the expression</p><formula xml:id="formula_128">ūr (x) = E Ẋr Xr = x (4.65) = E ṡr X tr + s r Ẋtr ṫr s r X tr = x = ṡr E X tr X tr = x s r + s r ṫr E Ẋtr X tr = x s r = ṡr s r x + s r ṫr u tr x s r ,</formula><p>where as before Xr = ψr (X 0 |X 1 ) and X t = ψ t (X 0 |X 1 ). This last term can be used to change a schedular post-training. Code 7 shows how to change the scheduler of a velocity field trained with a variance preserving schedule to the conditional Optimal Transport schedule using the flow_matching library.</p><p>Equivalence of schedulers. One additional important consequence of the above formula is that all schedulers theoretically lead to the same sampling at time t = 1 <ref type="bibr">(Shaul et al., 2023a)</ref>. That is,</p><formula xml:id="formula_129">ψ1 (x 0 ) = ψ 1 (x 0 ), for all x 0 ∈ R d . (4.68)</formula><p>To see that, denote ψr (x) the flow defined by ūt (x), and differentiate ψr (x) := s r ψ tr (x) w.r.t. r and note that it also satisfies d dt ψr (x) = ūr ( ψr (x)). (4.69)</p><p>Therefore, from uniqueness of ODE solutions we have that ψr (x) = ψr (x) = s r ψ tr (x). Now, to avoid dealing with infinite signal-to-noise ratio assume the schedulers satisfy σ 1 = ϵ = σ1 for arbitrary ϵ &gt; 0 (in addition to (4.51)), then for r = 1 we have t 1 = 1 and s 1 = 1 and therefore equation (4.68) holds. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8.3">Gaussian paths</head><p>At the time of writing, the most popular class of affine probability paths is instantiated by the independent coupling π 0,1 (x 0 , x 1 ) = p(x 0 )q(x 1 ) and a Gaussian source distribution p(x) = N (x|0, σ 2 I). Because Gaussians are invariant to affine transformations, the resulting conditional probability paths take form</p><formula xml:id="formula_130">p t|1 (x|x 1 ) = N (x|α t x 1 , σ 2 t I). (4.70)</formula><p>This case subsumes probability paths generated by standard diffusion models (although in diffusion the generation is stochastic and follows an SDE, it has the same marginal probabilities). Two examples are the Variance Preserving (VP) and Variance Exploding (VE) paths <ref type="bibr">(Song et al., 2021)</ref>, defined by choosing the following schedulers:</p><formula xml:id="formula_131">α t ≡ 1, σ 0 ≫ 1, σ 1 = 0; (VP) α t = e -1 2 βt , σ t = 1 -e -βt , β 0 ≫ 1, β 1 = 0. (VE)</formula><p>In the previous equations, "≫ 1" requires a sufficiently large scalar such that p 0 (x) = p 0|1 (x|x 1 )q(x 1 )dx 1 is close to a known Gaussian distribution for t = 0-that is, the Gaussian N (•|0, σ 2 0 I) for VE, and N (•|0, I) for VP. Note that in both cases, p t (x) does not exactly reproduce p at t = 0, in contrast to the FM paths in (4.51).</p><p>One useful quantity admitting a simple form in the Gaussian case is the score, defined as the gradient of the log probability. Specifically, the score of the conditional path in (4.70) follows the expression</p><formula xml:id="formula_132">∇ log p t|1 (x|x 1 ) = - 1 σ 2 t (x -α t x 1 ) . (4.71) B A velocity x 1 -prediction x 0 -prediction score velocity 0, 1 σt σt , αtσt-σtαt σt αt αt , σtαt-αtσt αt αt αt , -σtσtαt-αtσ 2 t αt x 1 -prediction 0, 1 1 αt , -σt αt 1 αt , σ 2 t αt x 0 -prediction 0, 1 0, -σ t score 0, 1</formula><p>Table <ref type="table">1</ref> Conversion between different model parameterizations: (at, bt) corresponds to f B t (x) = atx + btf A t (x). The colors indicate the tranformation is relevant for all paths , Affine paths and Gaussian paths . The lower diagonal is computed from the upper diagonal using the inverse transformation:</p><formula xml:id="formula_133">f A t (x) = 1 b t -atx + f B t (x)</formula><p>which can be expressed as the paira t b t , 1 b t . Note some of these conversions have singularities, as discussed at the end of Section 4.8.1.</p><p>The score of the corresponding marginal probability path (4.4) is</p><formula xml:id="formula_134">∇ log p t (x) = ∇p t|1 (x|x 1 )q(x 1 ) p t (x) dx 1 (4.72) = ∇ log p t|1 (x|x 1 ) p t|1 (x|x 1 )q(x 1 ) p t (x) dx 1 (4.73) = E ∇ log p t|1 (X t |X 1 ) | X t = x (4.74) (4.71) = E - 1 σ 2 t (X t -α t X 1 ) | X t = x (4.75) (4.54) = E - 1 σ t X 0 X t = x (4.76) (4.59) = - 1 σ t x 0|t (x),<label>(4.77)</label></formula><p>where we borrow the notation x 0|t from (4.59). The literature on diffusion refers to x 0 -prediction (x 0|t ) as noise-prediction, or ϵ-prediction. The formula above shows that the score is proportional to the x 0 -prediction, and provides a conversion rule-for the Gaussian path case-from score to other parametrizations, as shown in table <ref type="table">1</ref>.</p><p>Kinetic optimality of marginal velocity. A consequence of the conversion formulas developed above (table <ref type="table">1</ref>) is that the marginal velocity for Gaussian paths can be written in the form</p><formula xml:id="formula_135">u t (x) = αt α t x - σt σ t α t -αt σ 2 t α t ∇ log p t (x) (4.78) = ∇ αt 2α t ∥x∥ 2 - σt σ t α t -</formula><p>αt σ 2 t α t log p t (x) (4.79) that shows u t (x) is a gradient and therefore Kinetic Optimal for the fixed marginalized Gaussian probability path p t (x) defined by p t|1 (x|x 1 ) = N (x|α t x 1 , σ 2 t I) (see e.g., Villani (2021) Section 8.1.2, or Neklyudov et al. (2023) Theorem 2.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.9">Data couplings</head><p>In developing the Flow Matching training algorithm, we have assumed we can draw samples (X 0 , X 1 ) ∼ π 0,1 (X 0 , X 1 ) from some coupling π 0,1 (x 0 , x 1 ) of the source p and target q distributions. For example, independent samples π 0,1 (x 0 , x 1 ) = p(x 0 )q(x 1 ), the simplest coupling preserving the marginal distributions p and q, or paired samples (X 0 , X 1 ) ∼ π 0,1 provided as part of the dataset. This section explores two examples of concrete couplings that can be used to train Flow Matching models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.9.1">Paired data</head><p>Dependent couplings arise naturally in learning tasks on paired data. Consider, for instance, the task of image in-painting, where q is a distribution of natural images, and p is the distribution of those same images with a square region masked-out. Rather than transforming noise into data, our goal here is to learn a mapping from masked-out images x 0 to their filled counterparts x 1 . As this is an ill-defined problem-many filled images x 1 are compatible with each masked-out image x 0 -solving this task can casted as learning to sample from the unknown, data-dependent coupling π 1|0 (x 1 |x 0 ).</p><p>Based on these insights, <ref type="bibr" target="#b45">Liu et al. (2023)</ref>; <ref type="bibr">Albergo et al. (2024)</ref> propose learning a bridge or flow model with data-dependent couplings, a simple modification enabling a new regime of applications. While the object of interest π 1|0 (x 1 |x 0 ) is unavailable to sample, it is often the case that one can sample from the reverse dependency, π 0|1 (x 0 |x 1 ). Returning to the example of image in-painting, it is easy to mask out a filled image X 1 ∼ q (target sample) to produce a source sample X 0 ∼ p. To this end, specify π 0,1 (x 0 , x 1 ) = π 0|1 (x 0 |x 1 )q(x 1 ).</p><p>(4.80)</p><p>Thus, we can obtain a pair (X 0 , X 1 ) by (i) drawing X 1 ∼ q, and (ii) applying a predefined randomized transformation to obtain X 0 from X 1 . To satisfy the conditions of corollary 1 (making sure the source is a density) and to encourage diversity, we add noise when sampling from π 0|1 (x 0 |x 1 ). <ref type="bibr" target="#b45">(Liu et al., 2023;</ref><ref type="bibr">Albergo et al., 2024)</ref> demonstrated the capability of this approach on various applications, such as image super-resolution, in-painting, and de-blurring, outperforming methods based on guided diffusion <ref type="bibr" target="#b70">(Saharia et al., 2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.9.2">Multisample couplings</head><p>As discussed in section 4.7, straight probability paths yield ODEs simulations with smaller errors. Therefore, it is natural ask: how could we change the training algorithm, so the learned velocity field induces straight(er) trajectories?</p><p>As hinted above, straight trajectories are related to the Optimal Transport (OT) problem. Specifically, consider a convex cost functional c : R d → R ≥0 and the conditional OT flow ψ t (x 0 |x 1 ) = tx 1 + (1 -t)x 0 .</p><p>Then, the transport cost of the coupling admits an upper bound on the marginal transport cost <ref type="bibr" target="#b46">(Liu et al., 2022;</ref><ref type="bibr" target="#b64">Pooladian et al., 2023)</ref>, that is:</p><formula xml:id="formula_136">E [c(ψ 1 (X 0 ) -X 0 )] ≤ E [c(X 1 -X 0 )] ,<label>(4.81)</label></formula><p>where the case of c(x) = ∥x∥ 2 can be understood from the bound in (4.49) after plugging the OT solution in the l.h.s. that satisfies u t (X t ) = u t (ψ t (x)) = ϕ(x) -x, where ϕ is the OT map. Therefore, one could construct low-cost marginal transport maps by reducing the coupling cost. To this end, <ref type="bibr" target="#b64">Pooladian et al. (2023)</ref> propose multisample couplings, a process to implicitly construct non-trivial joints π 0,1 (x 0 , x 1 ) introducing dependencies between source and target distributions:</p><formula xml:id="formula_137">1. Sample X (i) 0 ∼ p and X (i) 1 ∼ q, i ∈ [k] independently. 2. Construct π k ∈ B k by π k := arg min π∈B k E π c(X (i) 0 -X (j) 1 ) . 3. Sample a pair (X (i) 0 , X (j) 0 ) uniformly at random from (X (i) 0 , X (j) 1 ) for which π k (i, j) = 1.</formula><p>where B k is the polytope of k × k doubly stochastic matrices.</p><p>The process above implicitly defines a joint distribution π k 0,1 (x 0 , x 1 ) by means of sampling. This implicit joint preserves the marginals and obeys an optimality constraint (step 2) <ref type="bibr" target="#b64">(Pooladian et al., 2023)</ref>. For k = 1, the method reduces to independent couplings. For k &gt; 1, <ref type="bibr" target="#b64">Pooladian et al. (2023)</ref> show that the transport cost is reduced compared to independent couplings, that is,</p><formula xml:id="formula_138">E (x0,x1)∼π k 0,1 (x0,x1) [c(x 1 -x 0 )] ≤ E X0∼p,X1∼q [c(X 1 -X 0 )].</formula><p>Furthermore, for the quadratic cost function, multisample couplings approach the Optimal Transport cost and induces straight trajectories as k → ∞ <ref type="bibr" target="#b64">(Pooladian et al., 2023;</ref><ref type="bibr" target="#b80">Tong et al., 2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.10">Conditional generation and guidance</head><p>We now consider training a generative model under a guiding signal to further control the produced samples. This technique has proved valuable in numerous practical applications, such as image-to-image translation <ref type="bibr" target="#b70">(Saharia et al., 2022</ref>) and text-to-image generation <ref type="bibr" target="#b56">(Nichol et al., 2022;</ref><ref type="bibr" target="#b21">Esser et al., 2024)</ref>. In this subsection, we assume access to labeled target samples (x 1 , y), where y ∈ Y ⊆ R k is a label or guidance variable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.10.1">Conditional models</head><p>One natural way to train a generative model under guidance is to learn to sample from the conditional distribution q(x 1 |y), as demonstrated by both diffusion and FM models <ref type="bibr" target="#b86">(Zheng et al., 2023)</ref>. Following the FM blueprint in figure <ref type="figure" target="#fig_2">2</ref>, consider samples from the conditional target distribution q(x 1 |y) and prescribe a simple-typically but not necessarily Gaussian-source distribution p. Next, design a guided probability path as the aggregation of conditional probability paths:</p><formula xml:id="formula_139">p t|Y (x|y) = p t|1 (x|x 1 )q(x 1 |y)dx 1 . (4.82)</formula><p>where we assume p t,1|Y (x, x 1 |y) = p t|1 (x|x 1 )q(x 1 |y), meaning that the conditional path does not depend on Y . The resulting guided probability path is conditioned on the guidance variable Y ∼ p Y , and satisfies the marginal endpoints</p><formula xml:id="formula_140">p 0|Y (•|y) = p(•), p 1|Y (•|y) = q(•|y). (4.83)</formula><p>The guided velocity field takes form</p><formula xml:id="formula_141">u t (x|y) = u t (x|x 1 )p 1|t,Y (x 1 |x, y)dx 1 ,<label>(4.84)</label></formula><p>where, by Bayes' Rule, it follows</p><formula xml:id="formula_142">p 1|t,Y (x 1 |x, y) = p t|1 (x|x 1 )q(x 1 |y) p t|Y (x|y) . (<label>4</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.85)</head><p>To show that u t (x|y) generates p t|Y (x|y), plug (4.82) and (4.84) into (4.14), and realize that the FM/CFM losses remain unchanged for the guided case, and enable the same steps appearing in the proof of theorem 4.</p><p>In practice, we train a single neural network u θ t : R d × R k → R d to model the guided marginal velocity field for all values of y. Then, the guided version of the CFM loss (4.32) follows the expression</p><formula xml:id="formula_143">L CFM (θ) = E t,(X0,X1,Y )∼π 0,1,Y D ψt (X 0 |X 1 ), u θ t (X t |Y ) . (4.86)</formula><p>In practice, the literature in diffusion models shows that guidance is most effective in applications where a large amount of target samples X 1 share the same guiding signal Y , such as in class guidance (Nichol and Dhariwal, 2021). However, guiding is more challenging in settings where the guidance variable Y is non-repeating and complex, such as image captions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.10.2">Classifier guidance and classifier-free guidance</head><p>For flows trained with Gaussian paths, classifier guidance <ref type="bibr">(Song et al., 2021;</ref><ref type="bibr" target="#b55">Dhariwal and Nichol, 2021)</ref> and classifier-free guidance <ref type="bibr" target="#b31">(Ho and Salimans, 2021</ref>) can be applied utilizing the transformations between velocity fields and score functions for conditional distributions shown in table 1 <ref type="bibr" target="#b86">(Zheng et al., 2023)</ref>:</p><formula xml:id="formula_144">u t (x|y) = a t x + b t ∇</formula><p>log p t|Y (x|y). (4.87) Using Bayes' rule over the guided probability path yields p t|Y (x|y) = p Y |t (y|x)p t (x) p Y (y) . (4.88) Taking logarithms and gradients with respect to x, ∇ = ∇ x , we arrive at the fundamental relation between the scores of the probability path p t (x) and its guided counterpart p t|Y (x|y): conditional score ∇ log p t|Y (x|y) = ∇ classifier log p Y |t (y|x) + unconditional score ∇ log p t (x) . (4.89) Namely, the two are related by means of the score of a classifier model p Y |t (y|x) attempting to predict the guidance variable y given a sample x.</p><p>Based on this relation, <ref type="bibr">Song et al. (2021)</ref> propose classifier guidance, that is sampling from the conditional model q(x 1 |y) by guiding an unconditional model (parameterized with ∇ log p t (x)) with a time-dependent classifier (predicting the guiding variable y given x ∼ p t (x)). The corresponding velocity field then translates to:</p><formula xml:id="formula_145">ũθ,ϕ t (x|y) = a t x + b t ∇ log p ϕ Y |t (y|x) + ∇ log p θ t (x) = u θ t (x) + b t ∇ log p ϕ Y |t (y|x),<label>(4.90)</label></formula><p>where u θ t (x) is a velocity field trained on the unconditional target q(x), and log p ϕ Y |t (y|x) is a time-dependent classifier with parameters ϕ ∈ R m . <ref type="bibr" target="#b55">Dhariwal and Nichol (2021)</ref> show that this approach outperforms the conditional model from section 4.10.1 for both class-and text-conditioning <ref type="bibr" target="#b56">(Nichol et al., 2022)</ref>. In practice, because the classifier and the unconditional score are learned separately, it is often necessary to calibrate the classifier guidance as ũθ,ϕ</p><formula xml:id="formula_146">t (x|y) = u θ t (x) + b t w∇ log p ϕ Y |t (y|x),<label>(4.91)</label></formula><p>where w ∈ R is the classifier scale, typically chosen to be w &gt; 1 (Dhariwal and Nichol, 2021).</p><p>In a later work, <ref type="bibr" target="#b31">(Ho and Salimans, 2021)</ref> propose a pure generative approach called classifier-free guidance.</p><p>By simply re-arranging (4.89), we obtain</p><formula xml:id="formula_147">∇ classifier log p Y |t (y|x) = conditional score ∇ log p t|Y (x|y) - unconditional score ∇ log p t (x),<label>(4.92)</label></formula><p>revealing that the score of the classifier can be implicitly approximated by the difference between the scores of the vanilla and guided probability paths. Then, the authors propose to learn the conditional and unconditional scores simultaneously using the same model. In terms of velocities, <ref type="bibr" target="#b86">Zheng et al. (2023)</ref> show one can also plug 4.92 into 4.91 and use the conversion from scores to velocities as in table 1 to get:</p><formula xml:id="formula_148">ũθ t (x|y) = (1 -w)u θ t (x|∅) + wu θ t (x|y),<label>(4.93)</label></formula><p>where w is once again the guidance calibration scale. Now, only a single model is trained, u θ t (x|y), where y ∈ {Y, ∅}, ∅ is a place-holder value denoting the null-condition, and u θ t (x|∅) is the velocity field generating the unconditional probability path p t (x). The resulting loss reads:</p><formula xml:id="formula_149">L CFM (θ) = E t,ξ,(X0,X1,Y )∼π 0,1,Y D ψt (X 0 |X 1 ), u θ t (X t |(1 -ξ) • Y + ξ • ∅) ,<label>(4.94)</label></formula><p>where ξ ∼ Bernoulli(p uncond ), and p uncond is the probability of drawing the null condition ∅ during training.</p><p>The exact distribution which CFG samples from is unknown, with some works proposing different intuitive or theoretical justifications for CFG sampling <ref type="bibr" target="#b19">(Dieleman, 2022;</ref><ref type="bibr" target="#b28">Guo et al., 2024;</ref><ref type="bibr" target="#b14">Chidambaram et al., 2024;</ref><ref type="bibr" target="#b9">Bradley and Nakkiran, 2024)</ref>. Despite this, at the time of writing, CFG is the most popular approach to training a conditional model. <ref type="bibr" target="#b21">Esser et al. (2024)</ref>; <ref type="bibr" target="#b63">Polyak et al. (2024)</ref> show the application of classifier-free guidance to train large-scale guided FM models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Non-Euclidean Flow Matching</head><p>This section extends Flow Matching from Euclidean spaces R d to general Riemannian manifolds M. Informally, Riemannian manifolds are spaces behaving locally like Euclidean spaces, and are equipped with a generalized notion of distances and angles. Riemannian manifolds are useful to model various types of data. For example, probabilities of natural phenomena on Earth can be modeled on the sphere <ref type="bibr" target="#b51">Mathieu and Nickel (2020)</ref>, and protein backbones are often parameterized inn terms of matrix Lie groups <ref type="bibr" target="#b39">Jumper et al. (2021)</ref>. The extension of flows to Riemannian manifolds is due to <ref type="bibr" target="#b51">Mathieu and Nickel (2020)</ref>; <ref type="bibr" target="#b48">Lou et al. (2020)</ref>. However, their original training algorithms required expensive ODE simulations. Following Chen and Lipman (2024), the Flow Matching solutions in this section provide a scalable, simulation-free training algorithm to learn generative models on Riemannian manifolds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Riemannian manifolds</head><p>We consider complete connected, smooth Riemannian manifolds M with a metric g. The tangent space at point x ∈ M, a vector space containing all tangent vectors to M at x, is denoted with T x M. The Riemannian metric g defines an inner product over T x M denoted by ⟨u, v⟩ g , for u, v ∈ T x M. Let T M = ∪ x∈M {x} × T x M be the tangent bundle that collects all the tangent planes of the manifold. In the following, vector fields defined on tangent spaces are important objects to build flows on manifolds with velocity fields. We denote by U = {u t } the space of time-dependent smooth vector fields (VFs) u t : [0, 1] × M → T M, where u t (x) ∈ T x M for all x ∈ M. Also, div g (u t ) is the Riemannian divergence with respect to the spatial (x) argument. Finally, we denote by dvol x the volume element over M, and integration of a function f : M → R over M is denoted f (x)dvol x .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Probabilities, flows and velocities on manifolds</head><p>Probability density functions over a manifold M are continuous non-negative functions p : M → R ≥0 integrating to 1, namely M p(x)dvol x = 1. We define a probability path in time p t as a time-dependent curve in probability space P, namely p t : [0, 1] → P. A time-dependent flow, ψ : [0, 1] × M → M, similar to the Euclidean space, defines a global diffeomorphism on M for every t.</p><p>Remarkably, constructing flow-based models via velocity fields naturally applies to general Riemannian manifolds. Formally, and rephrasing Proposition 1 from Mathieu and Nickel (2020):</p><p>Theorem 8 (Flow local existence and uniqueness). Let M a smooth complete manifold and a velocity field</p><formula xml:id="formula_150">u t ∈ U. If u is C ∞ ([0, 1] × M, T M) (in particular, locally Lipschitz), then the ODE in (3.19) has a unique solution which is a C ∞ (Ω, M) diffeomorphism ψ t (x) defined over the open set Ω ⊃ {0} × M.</formula><p>Similar to theorem 1, flow ODEs generally only define a local diffeomorphism on the manifold, meaning that ψ t (x) may be defined on a maximal interval in time [0, t x ]) for different values of x ∈ M. Similar to the Euclidean case we will work with the semi-open time interval t ∈ [0, 1) to allow q to have compact support (for which u t is not everywhere defined). To ensure existence for the desired time interval, [0, 1), we add the integrability constraint (see theorem 2) and rely on the Mass Conservation theorem once again. For a Riemannian manifold with metric g, the Riemannian continuity equation reads</p><formula xml:id="formula_151">d dt p t (x) + div g (p t u t )(x) = 0, (5.1)</formula><p>and the corresponding Manifold Mass Conservation theorem <ref type="bibr">(Villani et al., 2009)</ref> is stated as follows.</p><p>Theorem 9 (Manifold Mass Conservation). Let p t be a probability path and u t ∈ U a locally Lipchitz integrable vector field over a Riemannian manifold M with metric g. Then the following are equivalent 1. The Continuity Equation (5.1) holds for t ∈ [0, 1).</p><p>2. u t generates p t in the sense of 3.24.</p><p>where, by Bayes' Rule for PDFs, we obtain</p><formula xml:id="formula_152">p 1|t (x 1 |x) = p t|1 (x|x 1 )q(x 1 ) p t (x) , (5.11)</formula><p>which is defined for all x ∈ M for which p t (x) &gt; 0.</p><p>The Marginalization Trick (theorem 3) for the Riemannian case requires adjusting assumption 1 as follows:</p><formula xml:id="formula_153">Assumption 2. p t|1 (x|x 1 ) is C ∞ ([0, 1) × M) and u t (x|x 1 ) is C ∞ ([0, 1) × M, M</formula><p>) as function of (t, x). Furthermore, we assume either q has bounded support, i.e., q(x 1 ) = 0 outside some bounded set or M is compact; and p t (x) &gt; 0 for all x ∈ M and t ∈ [0, 1).</p><p>We are now ready to state the Manifold Marginalization Trick theorem: Theorem 10 (Manifold Marginalization Trick). Under Assumption 2, if u t (x|x 1 ) is conditionally integrable and generates the conditional probability path p t (•|x 1 ) then the marginal velocity field u t (•) generates the marginal probability path p t (•).</p><p>By conditionally integrable, we mean a conditioned version of the integrability condition from the Mass Conservation Theorem (5.2):</p><formula xml:id="formula_154">1 0 M M ∥u t (x|x 1 )∥ g p t|1 (x|x 1 )q(x 1 )dvol x1 dvol x dt &lt; ∞ (5.12)</formula><p>The proof of theorem 10 is repeating the arguments of theorem 3 and is given in appendix A.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Riemannian Flow Matching loss</head><p>The Riemannian Conditional Flow Matching (RCFM) loss reads</p><formula xml:id="formula_155">L RCFM (θ) = E t,X1,Xt∼p t|1 (•|X1) D Xt u t (X t |X 1 ), u θ t (X t ) .</formula><p>(5.13)</p><p>Once again, we have the equivalence:</p><p>Theorem 11. The gradients of the Riemannian Flow Matching loss and the Riemannian Conditional Flow Matching loss coincide:</p><formula xml:id="formula_156">∇ θ L RFM (θ) = ∇ θ L RCFM (θ).</formula><p>(5.14)</p><p>The above theorem can be proved using proposition 1 with X = X t , Y = u t (X t |X 1 ), g θ (x) = u θ t (x), and integrating w.r.t. t ∈ [0, 1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Conditional flows through premetrics</head><p>Having established how to learn a flow model with the RCFM loss, we are left with specifying the conditional probability path and its generating velocity field. Similar to section 4.6, we begin by stating the requirements for the corresponding conditional flow ψ : [0, 1) × M × M → M, such that p t|1 (•|x 1 ) satisfies the boundary conditions (5.8). The conditional flow model is</p><formula xml:id="formula_157">X t|1 = ψ t (X 0 |x 1 ), where X 0 ∼ π 0|1 (•|x 1 ), (5.15)</formula><p>where the conditional flow is</p><formula xml:id="formula_158">ψ t (x|x 1 ) = x t = 0 x 1 t = 1</formula><p>, is smooth in t, x and diffeomorphism in x on M.</p><p>(5.16)</p><p>Our analysis in Euclidean space focused on affine conditional flows, as these served as a rich class of easily computable (simulation-free) conditional flows. Unfortunately, combinations α t x 1 + σ t x 0 for α t + σ t ̸ = 1 are not naturally defined on manifolds. The manifold analog for the case α t + σ t = 1 would be using geodesic interpolation. Indeed, Chen and Lipman (2024) proposed building conditional flows by moving along geodesic curves, in particular, generalizing the conditional OT paths moving along straight lines in Euclidean space (see theorem 5). Geodesics represent the shortest paths between two points on a manifold, reducing to straight lines in Euclidean spaces. For manifolds, we define the geodesic conditional flow as</p><formula xml:id="formula_159">ψ t (x 0 |x 1 ) = exp x0 (κ(t) log x0 (x 1 )), t ∈ [0, 1],</formula><p>(5.17)</p><p>where κ(t) : [0, 1] → [0, 1] is a monotonically increasing scheduler satisfying κ(0) = 0 and κ(1) = 1, making sure all x 0 are pushed to x 1 at t = 1. The exponential map, evaluated at x ∈ M, exp x : T x M → M, v → exp x (v), returns the endpoint at time t = 1 of the unique geodesic starting at x with initial speed v. The logarithmic map log x : M → T x M , y → log x (y), is the inverse of the exponential map. In Euclidean space, the exponential map is simply vector addition, and the logarithmic map is vector subtraction. Now, if we plug these in (5.17), we get ψ t (x 0 |x 1 ) = x 0 + κ(t)(x 1 -x 0 ), and by choosing κ(t) = t we recover the conditional OT flow.</p><p>For simple manifolds with closed-form exponential and logarithmic maps, this construction allows a simulationfree recipe for training flows on manifolds, an arguably clear advantage compared to diffusion models approaches built on manifolds <ref type="bibr">(De Bortoli et al., 2022;</ref><ref type="bibr">Huang et al., 2022b;</ref><ref type="bibr" target="#b49">Lou et al., 2023)</ref>. In particular, manifold diffusion models require in-training simulation to sample from p t , and have to resort to approximations of the score function on the manifold.</p><p>Nevertheless, while building geodesic conditional flows is a natural construction, geodesics may be hard to compute for general manifolds that do not have closed-form exponential and logarithmic maps and/or introduce undesired bias such as concentrating probability at boundary points. To overcome the difficulty in computing geodesics and/or inject a desired implicit bias, one may seek an alternative notion of smooth distance function, d(•, •) : M × M → R ≥0 , and require that the conditional flow satisfies</p><formula xml:id="formula_160">d(ψ t (x 0 |x 1 ), x 1 ) = κ(t)d(x 0 , x 1 ),<label>(5.18)</label></formula><p>where κ(t) = 1 -κ(t). This will assure that the conditional flow concentrates all the probability at x 1 at time t = 1 if the following conditions hold:</p><p>1. Non-negative: d(x, y) ≥ 0 for all x, y ∈ M.</p><p>2. Positive: d(x, y) = 0 if and only if x = y.</p><p>3. Non-degenerate: ∇d(x, y) ̸ = 0 if and only if x ̸ = y.</p><p>Chen and Lipman (2024) showed that the minimal norm conditional velocity field corresponding to a flow that satisfies (5.18) has the form:</p><formula xml:id="formula_161">u t (x|x 1 ) = d log κ(t) dt d(x, x 1 ) ∇d(x, x 1 ) ∥∇d(x, x 1 )∥ 2 g , (<label>5</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.19)</head><p>Figure <ref type="figure" target="#fig_7">12</ref> Conditional flows on the manifold M.</p><p>where the non-degeneracy requirement of the premetric ensures that the velocity field has no discontinuities, since u t (x|x 1 ) ∝ 1/∥∇d(x, x 1 )∥ g . In particular, note that the geodesic conditional flow in (5.17) satisfies (5.18) for the choice d = d g , where d g is the geodesic distance. An example of a choice of alternative premetrics is using spectral distances on general geometries (Chen and Lipman, 2024), where the conditional velocity offers a way to sample from p t (x|x 1 ) by simulation. Importantly, although conditional flows with premetrics require in-training simulation-like diffusion models on manifolds-the velocity field can still be accurately recovered compared to approximations of the score function.</p><p>Another issue, is that both conditional flows defined via geodesic interpolation and premetric can suffer from singularities, e.g., for compact manifolds. For example on the 2-sphere the geodesic function d(x, x 1 ) is not differentiable at the antipodal point x = -x 1 . Furthermore, any smooth function such as x → d(x, x 1 ) will showcase at-least two critical points (maximum and minimum) where the velocity in (5.19) is not-defined. However, the set of such problematic points is generally very small (in fact of zero volume usually). Therefore, this issue does not cause problems in practice, at-least in use cases we are aware of.</p><p>In any case, to deal with this issue, we can include an augmented scheduler in the geodesic conditional flow. That is, use κ(t, x, x 1 ), that depends also on x, x 1 to make (5.17) globally smooth. To deal with the zero gradient issue of the premetric conditional flow we can relax the non-degeneracy requirement as follows:</p><p>3. Non-degenerate (relaxed): The volume of the set A y = {x ∈ M | ∇d(x, y) = 0 and x ̸ = y} is 0 for all y ∈ M. This section presents the Continuous Time Markov Chains (CTMCs) as an alternative generative model to flow, with the use-case of generating discrete data, i.e., data residing in a discrete (and finite) state space. CTMC are Markov processes that form the building blocks behind the generative model paradigm of Discrete Flow Matching (DFM) Campbell et al. (2024); Gat et al. (2024), later discussed in section 7. Therefore, this section is analogous to section 3, where we presented flows as the building blocks behind the generative model paradigm of Flow Matching (FM). 6.1 Discrete state spaces and random variables Consider a finite version of R d as our state space S = T d , where T = [K] = {1, 2, . . . , K}, sometimes called vocabulary. Samples and states are denoted by x = (x 1 , . . . , x d ) ∈ S, where x i ∈ T is single coordinate or a token. We will similarly use states y, z ∈ S. Next, X denotes a random variable taking values in the state space S, with probabilities governed by the probability mass function (PMF) p X : S → R ≥0 , such that x∈S p X (x) = 1, and the probability of an event A ⊂ S being</p><formula xml:id="formula_162">P(X ∈ A) = x∈A p X (x). (6.1)</formula><p>The notations X ∼ p X or X ∼ p X (X) indicate that X has the PMF p X . The δ PMF in the discrete case is defined by</p><formula xml:id="formula_163">δ(x, z) = 1 x = z, 0 else. (6.2)</formula><p>where we sometimes also define δ PMFs on tokens, such as in δ(x i , y i ), for some x i , y i ∈ T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">The CTMC generative model</head><p>The CTMC model is an S-valued time-dependent family of random variables (X t ) 0≤t≤1 that a form a Markov chain characterized by the probability transition kernel p t+h|t defined via p t+h|t (y|x) := P(X t+h = y|X t = x) = δ(y, x) + hu t (y, x) + o(h), and P(X 0 = x) = p(x), (6.3)</p><p>Figure <ref type="figure" target="#fig_7">13</ref> The CTMC model is defined by prescribing rates (velocities) of probability between states.</p><p>where the PMF p indicates the initial distribution of the process at time t = 0, and o(h) is an arbitrary function satisfying o(h)/h → 0 as t → 0.</p><p>The values u t (y, x), called rates or velocities, indicate the speed at which the probability transitions between states as a function of time. By fully characterized, we mean that all the joints P(X t1 = x 1 , . . . , X tn = x n ), for arbitrary</p><formula xml:id="formula_164">0 ≤ t 1 &lt; • • • &lt; t n ≤ 1 and x i ∈ S, i ∈ [n],</formula><p>are defined this way.</p><p>To make sure the transition probabilities p t+h|t (y|x) are defined via (6.3), velocities needs to satisfy the following rate conditions: u t (y, x) ≥ 0 for all y ̸ = x, and y u t (y, x) = 0. (6.4)</p><p>If one of these conditions were to fail, then the transition probabilities p t+h|t (•|x) would become negative or sum to c ̸ = 1 for arbitrary small h &gt; 0. Equation (6.3) plays he same role as equation <ref type="bibr">(3.16</ref>) and equation <ref type="bibr">(3.19)</ref> when we were defining the flow generative modeling. The marginal probability of the process X t is denoted by the PMF p t (x) for time t ∈ [0, 1]. Then, similarly to equation <ref type="bibr">(3.24)</ref> for the case of flows, we say that u t generates p t if there exists p t+h|t satisfying (6.3) with marginals p t .</p><p>(6.5)</p><p>Simulating CTMC. To sample X t , sample X 0 ∼ p and take steps using the (naive) Euler method:</p><p>P(X t+h = y | X t ) = δ(y, X t ) + hu t (y, X t ). (6.6)</p><p>According to (6.3), these steps introduce o(h) errors to the update probabilities. In practice, this means that we would need a sufficiently small h &gt; 0 to ensure that the right-hand side in (6.6) remains a valid PMF. One possible remedy to assure that any choice of h &gt; 0 results in a valid PMF, and maintains the o(h) local error in probabilities is the following Euler method:</p><formula xml:id="formula_165">P(X t+h = y | X t ) = exp [hu t (X t , X t )] y = X t ut(y,Xt) |ut(Xt,Xt)| (1 -exp [hu t (X t , X t )]) y ̸ = X t . (<label>6</label></formula><p>.7) 6.3 Probability paths and Kolmogorov Equation Similarly to Continuity Equation in the continuous case, the marginal probabilities p t of the CTMC model (X t ) 0≤t≤1 are characterized by the Kolmogorov Equation d dt p t (y) = x u t (y, x)p t (x). (6.8)</p><p>The following classical theorem (see also Theorems 5. <ref type="bibr">1 and 5.2 in Coddington et al. (1956)</ref>) describes the existence of unique solutions for this linear homogeneous system of ODEs.</p><p>Theorem 12 (Linear ODE existence and uniqueness). If u t (y, x) are in C([0, 1)) (continuous with respect to time), then there exists a unique solution p t (x) to the Kolmogorov Equation (6.8), for t ∈ [0, 1) and satisfying p 0 (x) = p(x).</p><p>For the CTMC, the solution is guaranteed to exist for all times t ∈ [0, 1) and no extra conditions are required (unlike the non-linear case in theorem 1). The Kolmogorov Equation has an intimate connection with the Continuity Equation <ref type="bibr">(3.25)</ref>. Rearranging the right-hand side of (6.8) by means of the rate conditions yields where j t (y, x) := u t (y, x)p t (x) is the probability flux describing the probability of moving from state x to state y per unit of time. The excess of outgoing flux is defined as the divergence, giving the Kolmogorov Equation the same structure as the one described in section 3.5 for the Continuity Equation <ref type="bibr" target="#b25">(Gat et al., 2024)</ref>.</p><p>The following result is the main tool to build probability paths and velocities in the CTMC framework:</p><p>Theorem 13 (Discrete Mass Conservation). Let u t (y, x) be in C([0, 1)) and p t (x) a PMF in C 1 ([0, 1)) in time t. Then, the following are equivalent:</p><p>1. p t , u t satisfy the Kolmogorov Equation (6.8) for t ∈ [0, 1), and u t satisfies the rate conditions (6.4).</p><p>2. u t generates p t in the sense of 6.5 for t ∈ [0, 1).</p><p>The proof of theorem 13 is given in appendix A.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1">Probability preserving velocities</head><p>As a consequence of the Discrete Mass Conservation (theorem 13), if velocity u t (y, x) generates the probability path p t (x), then ũt (y, x) = u t (y, x) + v t (y, x) generates p t (x), (6.9) as long as v t (y, x) satisfies the rate conditions (6.4) and solves the divergence-free velocity equation x v t (y, x)p t (x) = 0. (6.10)</p><p>In fact, ũt (y, x) solves the Kolmogorov Equation <ref type="formula"></ref>x ũt (y, x)p t (x) =</p><p>x u t (y, x)p t (x) = ṗt (y),</p><p>showing that one may add divergence-free velocities during sampling without changing the marginal probability. This will be a useful fact when sampling from discrete Flow Matching models, described next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discrete Flow Matching</head><p>Remarkably, the Flow Matching blueprint in figure <ref type="figure" target="#fig_2">2</ref> carries out seamlessly from the continuous case to the discrete case, yielding the Discrete Flow Matching (DFM) framework <ref type="bibr" target="#b11">(Campbell et al., 2024;</ref><ref type="bibr" target="#b25">Gat et al., 2024)</ref>.</p><p>In analogy to the continuous case, start by defining a probability path p t interpolating between a source PMF p and a target PMF q. Second, we would like to find a CTMC model (X t ) 0≤t≤1 , defined by a learnable velocity u θ t , that generates the probability path p t . Finally, we train u θ t by minimizing a Bregman divergence that defines the Discrete Flow Matching loss. In sum, this is to solve the discrete version of the Flow Matching problem (4.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Data and coupling</head><p>Our goal is to transfer samples X 0 ∼ p from a source PMF p to samples X 1 ∈ q from a target PMF q, where X 0 , X 1 ∈ S are two RVs each taking values in the state space S. Source and target samples can be related by means of the independent coupling (X 0 , X 1 ) ∼ p(X 0 )q(X 1 ), or associate by means of a general PMF coupling π 0,1 (x 0 , x 1 ). For example, text translation data considers coupled data (x 0 , x 1 ) representing the same document written in two different languages. Another application, such as text generation, concerns independent pairing where p(x 0 ) is either the uniform probability over S giving all states equal probability, or adding a special token m to the vocabulary T , i.e., T ∪ {m}, and considering π 0,1 (x 0 , x 1 ) = δ(x 0 , m)q(x 1 ). Any RV X 0 ∼ δ(X 0 , m) is the constant RV X 0 = (m, . . . , m).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Discrete probability paths</head><p>The next step in the FM recipe is, as usual, to prescribe a probability path p t interpolating p and q. Following section 4.4, we condition these objects on a general conditioning RV Z ∼ p Z taking values in some arbitrary space Z. The marginal probability path takes form</p><formula xml:id="formula_166">p t (x) = z∈Z p t|Z (x|z)p Z (z), (7.1)</formula><p>where p t|Z (•|z) is a conditional PMF, and the marginal probability path satisfies the boundary constraints p 0 = p and p 1 = q.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">The Marginalization Trick</head><p>The Marginalization Trick (see section 4.4) transfers to the discrete case as-is <ref type="bibr" target="#b11">(Campbell et al., 2024;</ref><ref type="bibr" target="#b25">Gat et al., 2024)</ref>. Assuming that the conditional velocity field u t (•, •|z) generates p t (•|z) in the sense of (6.5), we obtain the marginal velocity field</p><formula xml:id="formula_167">u t (y, x) = z u t (y, x|z)p Z|t (z|x) = E [u t (y, X t |Z) | X t = x] , (7.2)</formula><p>defined for all x, y ∈ S where p t (x) &gt; 0, and RV X t ∼ p t|Z (•|Z). By using Bayes' rule, we get</p><formula xml:id="formula_168">p Z|t (z|x) = p t|Z (x|z)p Z (z) p t (x) . (7.3)</formula><p>To prove the discrete version of the Marginalization Trick Theorem (theorem 3), assume: <ref type="bibr">)</ref>), and p t (x) &gt; 0 for all x ∈ S and t ∈ [0, 1).</p><formula xml:id="formula_169">Assumption 3. p t|Z (x|z) ∈ C 1 ([0, 1)), u t (y, x|z) ∈ C([0,<label>1</label></formula><p>As it happened in the continuous case, the assumption p t &gt; 0 is in practice mild, because we can always use</p><formula xml:id="formula_170">(1 -(1 -t)ϵ) • p Z|t + (1 -t)ϵ • p uni</formula><p>, where p uni is the uniform distribution over S, and ϵ &gt; 0 is arbitrary small. We are no ready to state and prove the result.</p><p>Theorem 14 (Discrete Marginalization Trick). Under Assumption 3, if u t (y, x|z) generates p t|Z (x|z) then the marginal velocity u t (y, x) in (7.2) generates p t (x) in (7.1) for t ∈ [0, 1).</p><p>Proof. The proof is conceptually similar to the continuous case. Start by computing:</p><formula xml:id="formula_171">d dt p t (y) = z d dt p t|Z (y|z)p Z (z) (i) = z x u t (y, x|z)p t|Z (x|z) p Z (z) (ii) = x z u t (y, x|z) p t|Z (x|z)p Z (z) p t (x) p t (x) (Bayes) = x ut(y,x) z u t (y, x|z)p Z|t (z|x) p t (x),</formula><p>Equality (i) follows from theorem 13 and the fact that u t (y, x|z) generates p t|Z (y|z). Equality (ii) follows from multiplying and dividing by p t (x) which is assumed positive. Therefore, u t (y, x) satisfies the Kolmogorov Equation with p t . Also, u t (y, x) satisfies the rate conditions (6.4), because each u t (y, x|z) satisfies them. Lastly, u t (y, x) ∈ C([0, 1)) because both u t (y, x|z) and p Z|t (z|x) are in C([0, 1)). In particular, p Z|t (z|x) ∈ C([0, 1)) follows from assuming p t (x) &gt; 0 for t ∈ [0, 1). By theorem 13, and because u t (x, y) satisfies the Kolmogorov Equation with p t and the rate conditions, it generates p t in the sense of (6.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Discrete Flow Matching loss</head><p>To construct a CTMC generative model (X t ) 0≤t≤1 we parameterize a velocity field u θ t (y, x) with parameters θ, e.g., using a neural network. One would construct the neural network to satisfy the rate conditions equation (6.4). The Discrete Flow Matching loss to train the CTMC model is defined as:</p><formula xml:id="formula_172">L DFM (θ) = E t,Xt∼pt D Xt (u t (•, X t ), u θ t (•, X t )), (7.4)</formula><p>for t ∼ U [0, 1] and u t (•, x) ∈ R S satisfying the rate conditions. This means that u t (•, x) ∈ Ω x , where</p><formula xml:id="formula_173">Ω x =    v ∈ R S v(y) ≥ 0 ∀y ̸ = x, and v(x) = - y̸ =x v(y)    ⊂ R S , (7.5)</formula><p>is a convex set, and D x (u, v) is a Bregman divergence defined using a convex function Φ x : Ω x → R. The Conditional Discrete Flow Matching loss takes form</p><formula xml:id="formula_174">L CDFM (θ) = E t,Z,Xt∼p t|Z D Xt (u t (•, X t |Z), u θ t (•, X t )). (7.6)</formula><p>Once again, the two losses (7.4) and (7.6) both provide the same learning gradients.</p><p>Theorem 15. The gradients of the Discrete Flow Matching loss and the Conditional Discrete Flow Matching loss coincide:</p><formula xml:id="formula_175">∇ θ L DFM (θ) = ∇ θ L CDFM (θ). (7.7)</formula><p>In particular, the minimizer of the Conditional Discrete Matching loss is the marginal velocity</p><formula xml:id="formula_176">u θ t (y, x) = E [u t (y, X t |Z) | X t = x] . (7.8)</formula><p>The proof follows by applying proposition 1 when setting X = X t , Y = (X t , Z), defining f : S 2 → R S as (x, z) → u t (•, x|z) ∈ R S , and integrating with respect to t ∈ [0, 1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">Factorized paths and velocities</head><p>Figure <ref type="figure" target="#fig_15">14</ref> Factorized CTMC model allows non-zero rates (velocities) only between states that differ in at-most one coordinate (token).</p><p>If implementing DFM as presented, we would require a learnable model u θ t (y, x)-for instance, a neural network-that outputs a rate for all possible states y ∈ S = T d . This would result in a huge output dimension K d , infeasible for common sequence lengths d and vocabulary sizes K. One remedy to this issue is to consider factorized velocities <ref type="bibr" target="#b10">(Campbell et al., 2022)</ref>, <ref type="bibr">(7.9)</ref> where ī = (1, . . . , i -1, i + 1, . . . , d) denotes all indices excluding i. Therefore, the factorized velocity above connects state x to state y only if these differ in at most one single token. When using factorized velocities, we only require to model u i t (y i , x), as these fully define u t (y, x). In turn, each u i t (y i , x) is a learnable model accepting x ∈ S and returning a scalar</p><formula xml:id="formula_177">u t (y, x) = i δ(y ī, x ī)u i t (y i , x),</formula><formula xml:id="formula_178">u i t (y i , x) ∈ R, for all i ∈ [d] = {1, 2, .</formula><p>. . , d} and y i ∈ T . Therefore, the output of the model has a tractable dimension d • K. The rate conditions for factorized velocities u i t (y, x) are now required per dimension i ∈ [d]:</p><formula xml:id="formula_179">u i t (y i , x</formula><p>) ≥ 0 for all y i ̸ = x i , and</p><formula xml:id="formula_180">y i ∈T u i t (y i , x) = 0 for all x ∈ S.</formula><p>(7.10)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5.1">Simulating CTMC with factorized velocities</head><p>When using factorized velocities, we can sample CTMC models coordinate-wise <ref type="bibr" target="#b11">(Campbell et al., 2024)</ref>:</p><formula xml:id="formula_181">P(X t+h = y | X t = x) = δ(y, x) + h i δ(y ī, x ī)u i t (y i , x) + o(h) = i δ(y i , x i ) + hu i t (y i , x) + o(h) ,</formula><p>where the second equality follows from δ(y, x) = i δ(y i , x i ) and the identity</p><formula xml:id="formula_182">i a i + hb i = i a i + h i ( j̸ =i a j )b i + o(h).</formula><p>Therefore, and up to an o(h) order, the transition kernel factorizes to coordinate-wise independent transitions</p><formula xml:id="formula_183">P(X i t+h = y i | X t = x) = δ(y i , x i ) + hu i (y i , x) + o(h). (7.11)</formula><p>These can be sampled with the Euler method (6.7) per coordinate. Interestingly, continuous Flow Matching also enjoys a similar factorization u t (x) = [u 1 t (x), . . . , u d t (x)] ∈ R d , where Ẋi t (x) = u i t (X t ) determines the change for coordinate i, and can be sampled independently (the "samples" in continuous FM are just deterministic).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5.2">Building probability paths with factorized velocities</head><p>If we construct probability paths in a certain way, it turns out to have factorized velocities (equation (7.9)) by construction. We explain this construction next. For this, we define a factorized probability path as a probability path of the form: q t (x) = i q i t (x i ).</p><p>(7.12)</p><p>Then, the following result shows that these factorized probability paths have factorized velocities.</p><p>Proposition 2. Let q t (x) be a factorized probability path as in (7.12), where u i t (y i , x i ) ∈ C([0, 1)) generates q i t (x i ). Then q t has a factorized generating velocity of the form</p><formula xml:id="formula_184">u t (y, x) = i δ(y ī, x ī)u i t (y i , x i ). (7.13)</formula><p>To proceed with the proof, let us denote the marginal distributions of a PMF q(x) by</p><formula xml:id="formula_185">q i (x i ) := x ī q(x) q ī(x ī) := x i q(x) (7.14)</formula><p>Proof. Let q t be a factorized probability path (7.12). Let u i t (y i , x i ) be the generating velocity of q i t (x i ). Differentiating with respect to t yields</p><formula xml:id="formula_186">d dt q t (y) = i q ī t (y ī) d dt q i t (y i ) (i) = i   x ī δ(y ī, x ī)q ī t (x ī)   x i u i t (y i , x i )q i t (x i ) (ii) = x i δ(y ī, x ī)u i t (y i , x i ) q t (x),</formula><p>Equality (i) follows from q ī t (y ī) = x ī δ(y ī, x ī)q ī t (x ī) and the Kolmogorov Equation (6.8). Equality (ii) follows from changing the summation order and noting that, by the definition of q t , we have q ī t (x ī)q i t (x i ) = q t (x) and</p><p>x ī</p><p>x i = x .</p><p>We are now ready to show the main tool for constructing paths p t with factorized velocities that interpolate between arbitrary p and q <ref type="bibr" target="#b11">(Campbell et al., 2024;</ref><ref type="bibr" target="#b25">Gat et al., 2024)</ref>.</p><p>Theorem 16 (Discrete Factorized Marginalization Trick). Consider a marginal probability path constructed via <ref type="bibr">(7.15)</ref> i.e., where the conditional path factorizes in the sense of equation (7.12). Further, assume that <ref type="bibr">)</ref>), and p t (x) &gt; 0 for all x ∈ S and t ∈ [0, 1). Then, the marginal velocity is</p><formula xml:id="formula_187">p t (x) = z p t|Z (x|z)p Z (z), with p t|Z (x|z) = i p i t|Z (x i |z),</formula><formula xml:id="formula_188">u i t (y i , x i |z) is C([0, 1)) generates p i t|Z (x i |z) in C 1 ([0,<label>1</label></formula><formula xml:id="formula_189">u t (y, x) = i δ(y ī, x ī)u i t (y i , x) (7.16) with u i t (y i , x) = z u i t (y i , x i |z)p Z|t (z|x) = E u i t (y i , X i t |Z)|X t = x (7.17) generates p t (x).</formula><p>Proof. According to proposition 2, the factorized conditional paths p t|Z (x|z) have factorized generating velocities u t (y, x|z) = i δ(y ī, x ī)u i t (y i , x i |z). Therefore,</p><formula xml:id="formula_190">u t (y, x) (i) = z u t (y, x|z)p Z|t (z|x) (ii) = z i δ(y ī, x ī)u i t (y i , x i |z) p Z|t (x|z) (iii) = i δ(y ī, x ī) z u i t (y i , x i |z)p Z|t (z|x) .</formula><p>Equality (i) follows from (7.2). Equality (ii) follows from assuming that p t|Z has factorized velocity. Equality (iii) follows from changing summation order. Because <ref type="bibr">)</ref>). Therefore, theorem 14 implies that u t (y, x) generates p t (x), as required.</p><formula xml:id="formula_191">p i t|Z (x i |z) ∈ C 1 ([0, 1)) and p t (x) &gt; 0, it follows that p t|Z (x|z) ∈ C 1 ([0, 1)). Similarly, because u i t (y i , x i |z) ∈ C([0, 1)), it follows that u t (y, x|z) ∈ C([0,<label>1</label></formula><p>By using theorem 16, we can design a probability path p t with factorized velocities interpolating between a source PMF p and a target PMF q as follows.</p><p>1. Find factorized probability conditional paths p t|Z (x|z) = i p i t|Z (x i |z) such that the marginal p t (x) satisfies p 0 = p and p 1 = q.</p><p>2. Find generating velocities u i t (y i , x i |z) to p i t|Z (x i |z). This can be done by finding solution u i t (y i , x i |z) to the Kolmogorov Equation:</p><formula xml:id="formula_192">x i u i t (y i , x i |z)p i t|Z (x i |z) = d dt p i t|Z (y i |z),<label>(7.18)</label></formula><p>for all y i ∈ T , fixed values of i ∈ [d], z ∈ Z, and t ∈ [0, 1). As a remark, (7.18) is an under-determined linear system of equations with |T | unknowns (significantly less unknowns than the entire state space |S|).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5.3">Conditional Discrete Flow Matching loss for factorized velocities</head><p>Representing the marginal velocity u θ t in terms of factorized velocities u θ,i t enables the following Conditional Flow Matching loss</p><formula xml:id="formula_193">L CDFM (θ) = E t,Z,Xt∼p t|Z i D i Xt u i t (•, X t |Z), u θ,i t (•, X t ) ,<label>(7.19)</label></formula><p>where t ∼ U [0, 1], and u i t (•, x|z), u θ,i t (•, x) ∈ R T satisfy the rate conditions. This means that u i t (•, x|z), u θ,i t (•, x) ∈ Ω x i where, for α ∈ T , we define</p><formula xml:id="formula_194">Ω α =    v ∈ R T v(β) ≥ 0 ∀β ∈ T \ {α} , and v(α) = - β̸ =α v(β)    ⊂ R T . (7.20)</formula><p>This is a convex set, and</p><formula xml:id="formula_195">D i x (u, v) is a Bregman divergence defined by a convex function Φ i x : Ω x i → R.</formula><p>As before, we justify this loss using proposition 1 and setting</p><formula xml:id="formula_196">X = X t , Y = u i t (•, X t , Z) ∈ R T , letting D i x (u, v) be a Bregman divergence over Ω x i ⊂ R T ,</formula><p>and integrating with respect to t ∈ [0, 1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5.4">Mixture paths</head><p>It is time to implement section 7.5.2 to build practical probability paths and their corresponding conditional velocities. Following <ref type="bibr" target="#b25">Gat et al. (2024)</ref>, we condition on Z = (X 0 , X 1 ) to accommodate arbitrary data couplings (X 0 , X 1 ) ∼ π 0,1 (X 0 , X 1 ). Then, we build the factorized conditional paths</p><formula xml:id="formula_197">p t|0,1 (x|x 0 , x 1 ) = i p i t|0,1 (x i |x 0 , x 1 ) (7.21)</formula><p>as mixtures</p><formula xml:id="formula_198">p i t|0,1 (x i |x 0 , x 1 ) = κ t δ(x i , x i 1 ) + (1 -κ t )δ(x i , x i 0 ),<label>(7.22)</label></formula><p>where κ :</p><formula xml:id="formula_199">[0, 1] → [0, 1] is a C 1 ([0, 1]) scheduler. Note that a RV X i t ∼ p i t|0,1 (•|x 0 , x 1 ) follows X i t = x i 1 with prob κ t x i 0 with prob (1 -κ t ) ,<label>(7.23)</label></formula><p>i.e. it assumes either the source or the target states with a probability depending on the time t.</p><p>If κ 0 = 0 and κ 1 = 1, then the marginal p t (x) in (7.1) satisfies the boundary constraints. We also need generating velocities u i t (y i , x i |x 0 , x 1 ) for p i t|0,1 (x i |x 0 , x 1 ), which are solutions to (7.18). We derive these as follows:</p><formula xml:id="formula_200">d dt p i t|Z (y i |z) (7.22) = κt δ(y i , x i 1 ) -δ(y i , x i 0 ) (7.22) = κt δ(y i , x i 1 ) - p i t|Z (y i |z) -κ t δ(y i , x i 1 ) 1 -κ t = κt 1 -κ t δ(y i , x i 1 ) -p i t|Z (y i |z) = x i κt 1 -κ t δ(y i , x i 1 ) -δ(y i , x i ) p i t|Z (x i |z),</formula><p>where we have used z = (x 0 , x 1 ) and Z = (X 0 , X 1 ) interchangeably to keep notation concise. In conclusion, we have found a conditional velocity generating the path in (7.22), namely</p><formula xml:id="formula_201">u i t (y i , x i |x 0 , x 1 ) = κt 1 -κ t δ(y i , x i 1 ) -δ(y i , x i ) .<label>(7.24)</label></formula><p>Code 9 shows how mixture paths are defined in the library flow_matching library.  Velocity posterior parameterization. Similar to the continuous case (e.g., section 4.8.1), we can choose to parameterize our velocity u i t (y i , x) in different ways. The first approach is to parameterize it directly, akin to velocities in flows. Another way, which we take here, is motivated by the following computation of the mixture marginal velocity following (7.17):</p><formula xml:id="formula_202">) 14 sample.x_0 # X 0 is [0, 0] 15 sample.x_1 # X 1 is [1, 2]</formula><formula xml:id="formula_203">u i t (y i , x) = x0,x1 κt 1 -κ t δ(y i , x i 1 ) -δ(y i , x i ) p 0,1|t (x 0 , x 1 |x) = x i 1 κt 1 -κ t δ(y i , x i 1 ) -δ(y i , x i ) p i 1|t (x i 1 |x),<label>(7.25)</label></formula><p>where for the second equality we denote the marginal of the posterior p 0,1|t</p><formula xml:id="formula_204">p i 1|t (x i 1 |x) = x0,x ī 1 p 0,1|t (x 0 , x 1 |x) (7.26) = E δ(x i 1 , X i 1 ) | X t = x . (7.27)</formula><p>This derivation represents the marginal u i t (y i , x) using a learnable posterior p θ,i 1|t (x i 1 |x), which can be understood as a discrete version of x 1 -prediction (section 4.8.1). Next, we explore loss functions to learn this posterior.</p><p>CDFM losses for mixture paths We present two options for learning p θ,i 1|t (x i 1 |x), both justified by proposition 1. First, the marginal posterior (7.26) and (7.27) can be learned by the conditional matching loss</p><formula xml:id="formula_205">L CM (θ) = E t,X0,X1,Xt D Xt δ(•, X i 1 ), p θ,i 1|t (•|X t ) (7.28) Since δ(•, X i 1 ), p θ,i 1|t (•|X t )</formula><p>are PMFs. Therefore, we can set the Bregman divergence to be the KL-divergence D(p, q) = α∈T p(α) log p(α) q(α) comparing PMFs, obtaining</p><formula xml:id="formula_206">L CM (θ) = -E t,X0,X1,Xt log p θ,i 1|t (X i 1 |X t ) + const. (7.29)</formula><p>Alternatively, we may follow section 7.5.3 and use the factorized loss in (7.19) with u θ,i t parametrized by p θ,i 1|t . In this case, we can set the Bregman divergence to be the generalized KL comparing general (not necessarily probability) vectors u, v ∈ R m ≥0 : <ref type="bibr">(7.30)</ref> For this choice of D, we get</p><formula xml:id="formula_207">D(u, v) = j u j log u j v j - j u j + j v j .</formula><formula xml:id="formula_208">D u i t (•, x i |x 0 , x 1 ), u θ,i t (•, x) = κt 1 -κ t (δ(x i 1 , x i ) -1) log p θ,i 1|t (x i 1 |x) + δ(x i 1 , x i ) -p θ,i 1|t (x i |x) (7.31)</formula><p>which implements the loss (7.19) when conditioning on Z = (X 0 , X 1 ). The generalized KL loss (7.31) also provides an evidence lower bound (ELBO) on the likelihood of the target distribution <ref type="bibr" target="#b75">(Shaul et al., 2024)</ref>,</p><formula xml:id="formula_209">-log p θ 1 (x 1 ) ≤ E t,X0,Xt∼p t|0,1 i D u i t (•, X i t |X 0 , x 1 ), u θ,i t (•, X t ) ,<label>(7.32)</label></formula><p>where p θ 1 is the marginal generated by the model at time t = 1. Hence, in addition to training, the generalized KL loss is commonly used for evaluation.</p><p>Sampling mixture paths The parametrization based on the posterior p θ,i 1|t leads to the following sampling algorithm. As indicated in section 7.5.1 working with factorized velocities enables the coordinate-wise sampling (7.11). According to (7.17) and (7.25),</p><formula xml:id="formula_210">P(X i t+h = y i | X t = x) = δ(y i , x i ) + hu i (y i , x) + o(h) (7.33) = x i 1 δ(y i , x i ) + h κt 1 -κ t δ(y i , x i 1 ) -δ(y i , x i ) + o(h) p i 1|t (x i 1 |x). (7.34)</formula><p>Consequently, and given X t = x, we may perform one step of sampling by performing the next two steps</p><formula xml:id="formula_211">for each i ∈ [d]: (i) draw X i 1 ∼ p i 1|t (X i<label>1</label></formula><p>|x); and (ii) update X i t+h according to the Euler step in (6.7) with the velocity κt 1-κt δ(y i , X i 1 ) -δ(y i , x i ) . Intuitively, (ii) decides whether to set X i t+h = X i 1 or remain at</p><formula xml:id="formula_212">X i t+h = X i t .</formula><p>One-sided mixture paths and probability preserving velocities It is often useful to extend the design space of the sampling algorithm by adding some divergence-free component, as described in section 6.3.1. For factorized paths, the divergence-free velocity v i t needs to satisfy (7.18), namely,</p><formula xml:id="formula_213">x i v i t (y i , x i |z)p i t|Z (x i |z) = 0. (7.35)</formula><p>In general it could challenging to find such probability-preserving velocities without learning additional quantities, e.g., p i 0|t . However, one useful case where a probability preserving velocity can be found in closed form is when assuming iid source distribution i.e., p(x) = i p(x i ) and independent coupling π 0,1 (x 0 , x 1 ) = p(x 0 )q(x 1 ). In this case the marginal mixture path takes the form</p><formula xml:id="formula_214">p t (x) = x1 p t|1 (x|x 1 )q(x 1 ), where p t|1 (x|x 1 ) = i p i t|1 (x i |x 1 )</formula><p>,</p><formula xml:id="formula_215">where p i t|1 (x i |x 1 ) = κ t δ(x i , x i 1 ) + (1 -κ t )p(x i</formula><p>) . The conditional velocity in (7.24), i.e.,</p><formula xml:id="formula_216">u i t (y i , x i |x 1 ) = κt 1 -κ t δ(y i , x i 1 ) -δ(y i , x i ) (7.36)</formula><p>also generates p i t|1 (x i |x 1 ). To find a divergence-free velocity we can, for example, subtract from this velocity a backward-time velocity ũi t for p i t|1 (y i , x i |x 1 ) <ref type="bibr" target="#b25">(Gat et al., 2024)</ref>, in the sense that it satisfies the Kolmogorov equation with p i t|1 (y i , x i |x 1 ) and -ũ i t satisfies the rate conditions. Such a velocity can be found in a fashion to equation (7.24),</p><formula xml:id="formula_217">ũi t (y i , x i |x 1 ) = κt κ t δ(y i , x i ) -p(x i ) . (7.37)</formula><p>Therefore, a divergence-free velocity for p i t|1 (x i |x 1 ) conditional path can be defined via</p><formula xml:id="formula_218">v i t (y i , x i |x 1 ) = u i t (y i , x i |x 1 ) -ũi t (y i , x i |x 1 ). (7.38)</formula><p>According to section 6.3.1, if we add a divergence-free field v i t (y i , x i |x 1 ) to the velocity u i t (y i , x i |x 1 ), the latter still generates the same probability path p i t|1 (x i |x 1 ). Consequently, theorem 16 implies that the marginal velocity u i t (y i , x) defined by</p><formula xml:id="formula_219">u i t (y i , x) = x1 u i t (y i , x i |x 1 ) + c t v i t (y i , x i |x 1 ) p 1|t (x 1 |x) = x i 1 u i t (y i , x i |x i 1 ) + c t v i t (y i , x i |x i 1 ) p i 1|t (x i |x),</formula><p>still generates the same marginal path p t (x), where the second equality follows from u i t (y i , x i |x 1 ) = u i t (y i , x i |x i 1 ) for mixture paths, and similarly for v i t (y i , x i |x i 1 ). In conclusion, and given X t = x, a single step of the generalized sampling algorithm consists in (i) drawing X i 1 ∼ p i 1|t (X i 1 |x) and (ii) taking an Euler step (6.7) with the velocity</p><formula xml:id="formula_220">u i t (y i , x i |x 1 ) = κt 1 -κ t δ(y i , X i 1 ) -δ(y i , x i ) + c t κt 1 -κ t δ(y i , x i 1 ) -δ(y i , x i ) - κt κ t δ(y i , x i ) -p(x i ) ,</formula><p>where c t &gt; 0 is a time dependent constant.</p><p>Similar to the continuous flow matching example in code 1, we provide a standalone implementation of discrete flow matching in pure PyTorch in code 11. Code 10 illustrates how to train a discrete flow with arbitrary data coupling using the flow_matching library. In the previous sections, we have developed a flow model on R d and Riemannian manifolds (see section 3 and section 5) and a CTMC model for discrete data (see section 6). In this section, we want to unify and extend these models to a generative model that works for (1) general state spaces and ( <ref type="formula" target="#formula_1">2</ref>) general Markov processes. This generative model will allow us to extend the principles of Flow Matching to a wide variety of generative models for a variety of modalities in section 9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">General state spaces and random variables</head><p>Working with general modalities. Our explicit goal is not specify the modality we use. Hence, throughout this section, let S be a general state space. Important examples are S = R d (e.g., images, vectors), S discrete (e.g., language), S a Riemannian manifold (e.g., geometric data) or their products for generation of multiple data modalities jointly (multimodal models). For all modalities, we can define a metric (or distance function) d : S × S → R ≥0 , (x, y) → d(x, y) on S. For example, for S discrete, the metric is simply d(x, y) = 1 if y ̸ = x and d(x, x) = 0 for all x ∈ S. For S = R d , we use d(x, y) = ∥x -y∥. We need to make a technical assumption that (S, d) is a Polish metric space, i.e., it is complete (i.e., any Cauchy sequence converges) and separable (i.e., it has a countable dense subset). Any modality of interest for machine learning has that property.</p><p>Densities over general state spaces. So far, in this work we assumed that a probability distribution p over S is represented by a density p : S → R ≥0 . For general state spaces, we use a general reference measure ν and the density becomes the Radon-Nikodym derivative dp dν . In other words, probabilities can be expressed as integrals with respect to ν</p><formula xml:id="formula_221">P(A) = A p(x)ν(dx) for all measurable A ⊂ S</formula><p>For S discrete, ν was the counting measure (so the integrals are just sums) and p(x) is just the probability mass function (PMF). For S = R d , ν was the Lebesgue measure (so the integrals are just the "usual" integral) and p(x) is just the probability density function (PDF). The above generalizes that to arbitrary state spaces.</p><p>(Optional) Working with arbitrary distributions. It is important to note that not every probability distribution admits a density with respect to a reference measure. For the reader unfamiliar with general measure theory, it is safe ignore this possibility as a technical remark as long one works with distributions of interest that have a density p(x). However, note that these are not just pathological examples but there are real cases of interest for machine learning applications where this matters: A simple example is a probability path of the form p t = δ (1-t)x+ty on S = R d connecting two points x, y ∈ R d in a straight line -this cannot be represented by a density. Another example would be probability distributions over S = C([0, 1], R), e.g., for trajectory modeling, that often do not have a density with respect to a common reference measure. To mathematically handle such cases, we develop our framework for general probability measures p over S. For this, we use the notation p(dx) where "dx" is a symbolic expression denoting integration with respect to p in a variable x. For example, for a bounded measurable function f : S → R we write</p><formula xml:id="formula_222">E X∼p [f (X)] = f (x)p(dx)</formula><p>for the Lebesgue integral or the expected value of f under p. As before, we use (with a slight abuse of notation) the same notation p(x) to denote the density of the measure p(dx).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">The CTMP generative model</head><p>Similarly, our explicit goal is build a model that works for arbitrary evolution process -regardless of whether we use a flow, diffusion, a CTMC, a combination, or something else. Therefore, we define a evolution process in this section that is general but satisfies the necessary regularity assumptions to build a generative model. For t ∈ [0, 1], let X t ∈ S be a random variable. We call (X t ) 0≤t≤1 a Continuous-time Markov process (CTMP) if it fulfills the following condition:</p><p>Table <ref type="table">2</ref> Some examples of CTMP generative models and how they can be learnt with Generator Matching. This list is not exhaustive. Derivations are in section 8. For diffusion, we assume zero drift as this is covered by the "Flow" column. KFE is listed in its adjoint version, i.e., assumes jump kernel Qt(y, x) and density pt(x) exists with respect to reference measure ν. "p.s.d.": Positive semi-definite.</p><formula xml:id="formula_223">P[X tn+1 ∈ A|X t1 , X t2 , . . . , X tn ] = P[X tn+1 ∈ A|X tn ] (0 ≤ t 1 &lt; • • • &lt; t n+1 ≤ 1, A ⊆ S) (8.1)</formula><p>Informally, the above condition says that the process has no memory. If we know the present, knowing the past will not influence our prediction of the future. In table 2, we give an overview over important classes of Markov processes. For example, a flow on a manifold is a Markov process with deterministic transitions, a diffusion is a Markov process with transitions driven by Brownian motion, and CTMCs are Markov processes determined by rates (we will explain this in detail in section 8.2.2). Each Markov process has a transition kernel (p t+h|t ) 0≤t&lt;t+h≤1 that assigns every x ∈ S a probability distribution p t+h|t (•|x) such that</p><formula xml:id="formula_224">P[X t+h ∈ A|X t = x] = p t+h|t (A|x) for all t, h ≥ 0, A ⊂ S measurable (8.2)</formula><p>Due to the Markov assumption, a Markov process is uniquely determined by the transition kernel and the distribution of X 0 . Conversely, any transition kernel and initial distribution defines a Markov process. Therefore, there is a 1:1 correspondence.</p><p>Our next goal is to define a corresponding generalization of a velocity field for CTMPs. Informally, it would be the 1st-order derivative of the transition kernel in t:</p><formula xml:id="formula_225">L t := d dh h=0 p t+h|t (8.3)</formula><p>We call the 1st-order derivative L t the generator of p t+h|t <ref type="bibr" target="#b22">(Ethier and Kurtz, 2009;</ref><ref type="bibr" target="#b69">Rüschendorf et al., 2016)</ref>. Similar to derivatives, generators are first-order linear approximations and easier to parameterize than p t+h|t . As we will see, diffusion, flows, and other generative models can all be seen as algorithms to learn the generator of a Markov process (see table <ref type="table">2</ref>). This leads to the general form of the CTMP generative model given by CTMP model (informal): p t+h|t (•|x) := δ x + hL t (x) + o(h), and X 0 ∼ p. (8.4)</p><p>However, as a transition kernel p t+h|t is not a real function, equation 8. <ref type="bibr">3 and 8.4</ref> are only heuristic and not well-defined yet. Therefore the first goal of this section is to provide a formal definition of the generator and the CTMP generative model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.1">Formal definition of generator</head><p>The first problem in equation (8.3) is that derivatives are usually defined with respect to functions mapping to vector spaces but p t+h|t maps to a distribution. However, this can be alleviated by using test functions.</p><p>Test functions are a way to "probe" a probability distribution. They serve as a theoretical tool to handle distributions as if they were real-valued functions. Specifically, a set of test functions is a family T of bounded, measurable functions f : S → R that characterize probability distributions fully, i.e., for two probability distributions µ 1 , µ 2 on S it holds</p><formula xml:id="formula_226">µ 1 = µ 2 ⇔ E X∼µ1 [f (X)] = E X∼µ2 [f (X)] for all f ∈ T (8.5)</formula><p>Generally speaking, one chooses T to be as "nice" (or regular) as possible. For example, if S = R d , the space T = C ∞ c (R d ) of infinitely differentiable functions with compact support fulfills that property. For S discrete, T = R S simply consists of all functions (which are just vectors in this case). Let X t ∼ p t . We define the marginal action and transition action as</p><formula xml:id="formula_227">⟨p t , f ⟩ := f (x)p t (dx) = E X∼pt [f (X)] (8.6) p t+h|t , f (x) := p t+h|t (•|x), f = E [f (X t+h )|X t = x] (8.7)</formula><p>where the marginal action maps each test function f to a scalar ⟨p t , f ⟩ ∈ R, while the transition action maps a real-valued function x → f (x) to a another real-valued function x → p t+h|t , f (x). The tower property implies that p t , p t+h|t , f = ⟨p t+h , f ⟩. We note that the above is only a "symbolic" dot product but becomes a "proper" dot product if a density p t (x) exists, i.e., ⟨p t , f ⟩ = f (x)p t (x)ν(dx).</p><p>The second step to formally define a derivative as in equation ( <ref type="formula">8</ref>.3) is that we need to impose some notion of "smoothness" on a Markov process that we define now. Let C 0 (S) be the space of continuous functions f : S → R that vanish at infinity, i.e., for all ϵ &gt; 0 there exists a compact set K ⊂ S such that |f (x)| &lt; ϵ for all x ∈ S \ K. We use the supremum norm ∥ • ∥ ∞ on C 0 (S). A CTMP X t is called a Feller process if it fulfils the following two conditions <ref type="bibr" target="#b23">(Feller, 1955;</ref><ref type="bibr" target="#b69">Rüschendorf et al., 2016</ref>):</p><p>1. Strong continuity: The action of p t+h|t is continuous in time:</p><formula xml:id="formula_228">lim h ′ →h,t ′ →t ∥ p t ′ +h ′ |t ′ , f -p t+h|t , f ∥ ∞ = 0 for all h, t ≥ 0, f ∈ C 0 (S)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>No return from infinity: The action of p t+h|t preserves functions that vanish at infinity:</p><formula xml:id="formula_229">p t+h|t , f ∈ C 0 (S) for all h, t ≥ 0, f ∈ C 0 (S)</formula><p>Assumption 4. The CTMP (X t ) 0≤t≤1 is a Feller process. This is a reasonable assumption given that we want to use X t in a machine learning model: We define probability paths where the distribution of the generative process X t vary smoothly, and all our data usually lies in some bounded (compact) set.</p><p>Let us now revisit (8.3) and try define the derivative of p t+h|t . With the test function perspective in mind, we can take derivatives of p t+h|t , f (x) per x ∈ S and define</p><formula xml:id="formula_230">d dh h=0 p t+h|t , f (x) = lim h→0 p t+h|t , f (x) -f (x) h := [L t f ](x). (8.8)</formula><p>We call this action the generator L t and define it for all f for which the above limit exists uniformly, i.e., in the norm ∥ • ∥ ∞ . Intuitively, a generator is defined as an operator of test functions. In table 2, there are several examples of generators that we derive in section 8.2.2. There is a 1:1 correspondence between a generator and a Feller process <ref type="bibr" target="#b67">(Rogers and Williams, 2000;</ref><ref type="bibr" target="#b22">Ethier and Kurtz, 2009;</ref><ref type="bibr" target="#b58">Pazy, 2012)</ref> -in the same way as there is a correspondence between a flow and a vector field (see theorem 1). This will later allows us to parameterize a Feller process via a generator in a neural network.</p><p>With this definition, the CTMP model in (8.4) has the, now well-defined, form as</p><formula xml:id="formula_231">p t+h|t , f = f + hL t f + o(h) (for all f ∈ T ) and X 0 ∼ p (8.9)</formula><p>where o(h) describes an error terms E(h) ∈ C 0 (S) such that lim h→0 1 h ∥E(h)∥ ∞ = 0. Similarly to equation (3.24) for the case of flows and to equation (6.5) for the case of CTMCs, we say that L t generates p t if there exists a p t+h|t satisfying (8.9) with CTMP X t such that X t ∼ p t (8.10)</p><p>In other words, a generator L t generates the probability path p t if a Markov process that is (1) initialized with p = p 0 and ( <ref type="formula" target="#formula_1">2</ref>) simulated with L t has marginals p t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.2">Examples of CTMP models</head><p>We go through several examples to illustrate how to compute a generator of a Markov process. The results from this section are summarized in table <ref type="table">2</ref>.</p><formula xml:id="formula_232">Flows. Let S = R d and u : [0, 1] × R d → R d , (t, x) → u t (</formula><p>x) be a time-dependent velocity field defining a flow ψ t (see section 3). Let T = C ∞ c (R d ) be the space of infinitely differentiable and smooth functions with compact support. Then we can compute the generator via <ref type="bibr">(8.16)</ref> where (i) follows from a Euler approximation of the flow and (ii) follows from a first-order Taylor approximation of f around X t . Therefore, the flow generator is given by</p><formula xml:id="formula_233">[L t f ](x) = lim h→0 E [f (X t+h )|X t = x] -f (x) h (8.11) (i) = lim h→0 E [f (X t + hu t (X t ) + o(h))|X t = x] -f (x) h (8.12) (ii) = lim h→0 E f (X t ) + h∇f (X t ) T u t (X t ) + o(h)|X t = x -f (x) h (8.13) = lim h→0 f (x) + h∇f (x) T u t (x) + o(h) -f (x) h (8.14) (8.15) = ∇f (x) T u t (x),</formula><formula xml:id="formula_234">L t f (x) = ∇f (x) T u t (x).</formula><p>(8.17)</p><formula xml:id="formula_235">Diffusion. Let S = R d and σ t : [0, 1] × R d → R d×d , (t, x) → σ t (</formula><p>x) be a time-dependent function mapping to symmetric positive semi-definite matrices σ t in a continuous fashion. A diffusion process with diffusion coefficient σ t is defined via the SDE dX t = σ t (X t )dW t for a Wiener process W t <ref type="bibr">(Øksendal, 2003)</ref>. This process can be approximated via the infinitesimal sampling procedure:</p><formula xml:id="formula_236">X t+h = X t + √ hσ t (X t )ϵ t , ϵ t ∼ N (0, I) (8.18) Let again be T = C ∞ c (R d ).</formula><p>Then we can compute the generator via</p><formula xml:id="formula_237">[L t f ](x) = lim h→0 E f (X t + √ hσ t (X t )ϵ t + o(h))|X t = x -f (x) h (8.19) (i) = lim h→0 E ϵt [f (x) + ∇f (x) T √ hσ t (x)ϵ t + 1 2 h[σ t (x)ϵ t ] T ∇ 2 f (x)[σ t (x)ϵ t ] + o(h) -f (x)] h (8.20) = lim h→0 ∇f (x) T √ hσ t (x)E ϵt [ϵ t ] + E ϵt [ 1 2 h[σ t (x)ϵ t ] T ∇ 2 f (x)[σ t (x)ϵ t ]] h (8.21) = 1 2 E ϵt [ϵ T t [σ t (x)] T ∇ 2 f (x)[σ t (x)]ϵ t ]] (8.22) (ii) = 1 2 tr σ t (x) T ∇ 2 f (x)σ t (x) (8.23) (iii) = 1 2 tr(σ t (x)σ t (x) T ∇ 2 f (x)) (8.24) (iv) = 1 2 σ 2 t (x) • ∇ 2 f (x) (8.25)</formula><p>where in (i) we use a 2nd order Taylor approximation (2nd order because</p><formula xml:id="formula_238">E[∥ √ hϵ t ∥ 2 ] ∝ h), in (ii) the identity tr(A) = E ϵt [ϵ T t Aϵ t ] for A ∈ R d×d , in<label>(</label></formula><p>iii) the cyclic property of the trace, and in (iv) the symmetry of σ t . Further, we use A • B := tr(A T B) to denote the matrix inner product for matrices A, B ∈ R d×d . Therefore, the diffusion generator is given by</p><formula xml:id="formula_239">L t f (x) = 1 2 σ 2 t (x) • ∇ 2 f (x). (8.26)</formula><p>Jumps. Next, let S be arbitrary and let us consider a jump process. A jump process is defined by a time-dependent kernel Q t (dy, x), i.e., for every 0 ≤ t ≤ 1 and every x ∈ S, Q t (dy, x) is a positive measure over S \ {x}. The idea of a jump process is that the total volume assigned to S \ {x}</p><formula xml:id="formula_240">λ t (x) = Q t (dy, x) (8.27)</formula><p>gives the jump intensity, i.e., the infinitesimal likelihood of jumping. Further, if λ t (x) &gt; 0, we can assign a jump distribution by normalizing Q t to a probability kernel</p><formula xml:id="formula_241">J t (dy, x) = Q t (dy, x) λ t (x) .</formula><p>(8.28)</p><p>A jump process can be approximated via the infinitesimal sampling procedure as follows:</p><formula xml:id="formula_242">X t+h = X t with probability 1 -hλ t (X t ) + o(h) ∼ J t (dy, X t ) with probability hλ t (X t ) + o(h) (8.29)</formula><p>For a rigorous treatment of jump processes, see for example <ref type="bibr" target="#b17">(Davis, 1984)</ref>. The generator is then given by</p><formula xml:id="formula_243">L t f (x) = lim h→0 E[f (X t+h ) -f (X t )|X t = x] h (8.30) = lim h→0 E[f (X t+h ) -f (X t )|X t = x, Jump in [t, t + h)]P[Jump in [t, t + h)|X t = x] h (8.31) + lim h→0 E[f (X t+h ) -f (X t )|X t = x, No jump in [t, t + h)]P[No jump in [t, t + h)|X t = x] h =0 (8.32) = lim h→0 E Y ∼Jt(dy,x) [f (Y ) -f (x)] hλ t (x) h (8.33) = E Y ∼Jt(dy,x) [f (Y ) -f (x)] λ t (x) (8.34) = (f (y) -f (x))Q t (dy, x) (8.35)</formula><p>where we have used that if X t does not jump in [t, t + h], then X t+h = X t . Therefore, the jump generator is given by</p><formula xml:id="formula_244">L t f (x) = (f (y) -f (x))Q t (dy, x) = λ t (x)E Y ∼Jt(dy,x) [f (Y ) -f (x)]. (8.36)</formula><p>Continuous-time Markov chain (CTMC). Let us consider a continuous-time Markov chain X t on a discrete space S with |S| &lt; ∞. In fact, this is simply a jump process on a discrete state space with a specific parameterization. To see this, consider a vanilla jump kernel on a discrete state space S given by a matrix</p><formula xml:id="formula_245">Q t ∈ R S×S ≥0</formula><p>and using equation (8.36), the generator is given by</p><formula xml:id="formula_246">L t f (x) = y∈S [f (y) -f (x)]Q t (y, x) = y̸ =x [f (y) -f (x)]Q t (y, x) for all x ∈ S, f ∈ R S (8.37)</formula><p>i.e., the value of Q t (x, x) does not matter and is underdetermined. Therefore, a natural convention is to reparameterize the jump kernel on discrete state spaces by rates:</p><formula xml:id="formula_247">u t (y, x) =    Q t (y, x) if y ̸ = x - z̸ =x Q t (z; x) if y = x</formula><p>With this, we recover the rates u t (y, x) from section 6 fulfilling the rate conditions in 6.4 by construction. Therefore, this shows that a jump model on a discrete space coincides with the CTMC model (section 6). Applying this on equation (8.37), we get that the CTMC generator is given by</p><formula xml:id="formula_248">L t f (x) = y∈S f (y)u t (y, x) = f T u t (8.38)</formula><p>where we consider f = (f (x)) x∈S as a column vector and u t ∈ R S×S as a matrix. Therefore, the generator function is simply vector multiplication from the left.</p><p>Flows on manifolds. Next, we consider flows on Riemannian manifolds S = M as in section 5. A flow ψ : [0, 1] × M → M is defined via a vector field u : [0, 1] × M → T M via the ODE in <ref type="bibr">(3.19)</ref>. Let us denote the transition from time s to t via ψ t|s (x) = ψ t (ψ -1 s (x)) (as in (3.17)). Then, for a smooth function f : M → R we have that the Riemannian flow generator is given via</p><formula xml:id="formula_249">L t f (x) = lim h→0 f (ψ t+h|t (x)) -f (x) h = ∇f (x), d dh h=0 ψ t+h|t (x) g = ⟨∇f (x), u t (x)⟩ g (8.39)</formula><p>where ⟨•, •⟩ g describes the dot product defining the Riemannian metric g and ∇f describes the gradient of f with respect to g. In fact, the generator coincides with the Lie derivative of a function <ref type="bibr" target="#b38">(Jost, 2008)</ref>, a fundamental concept in differential geometry.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Probability paths and Kolmogorov Equation</head><p>For Flow Matching on S = R d , the Continuity Equation (see <ref type="bibr">3.25)</ref> is the central mathematical equation that allows us to construct velocity fields that generate a desired probability path (see section 3.5). In this section, we derive a corresponding -more general -equation for CTMPs. Let X t be a CTMP with generator L t and let X t ∼ p t , then we know that:</p><formula xml:id="formula_250">d dt ⟨p t , f ⟩ = d dh h=0 ⟨p t+h , f ⟩ = d dh h=0 p t , p t+h|t , f = p t , d dh h=0 p t+h|t , f = ⟨p t , L t f ⟩</formula><p>where we used that the ⟨p t , •⟩ operation is linear to swap the derivative, and that by the tower property p t , p t+h|t , f = ⟨p t+h , f ⟩. This shows that given a generator L t of a Markov process X t we can recover its marginal probabilities via their infinitesimal change, i.e., we arrive at the</p><p>Kolmogorov Forward Equation (KFE) d dt ⟨p t , f ⟩ = ⟨p t , L t f ⟩ for all f ∈ T (8.40) The version of the KFE in equation (8.40) determines the evolution of expectations of test functions f . This is necessary if we use probability distributions that do not have a density. If a density exists, a more familiar version of the KFE can be used that directly prescribes the change of the probability densities. To present it, we introduce the adjoint generator L * t , which acts on probability densities p t (x) with respect to a reference measure ν, namely L * t p t (x) is (implicitly) defined by the identity p t (x)L t f (x)ν(dx) = L * t p t (x)f (x)ν(dx) ∀f ∈ T (8.41) Further, we need to assume that p t is differentiable in t. Now, (8.41) applied to the KFE (8.40) we get d dt p t (x)f (x)ν(dx) = d dt p t (x)f (x)ν(dx) (8.42) = d dt ⟨p t , f ⟩ (8.43) = ⟨p t , L t f ⟩ (8.44) = p t (x)L t f (x)ν(dx) (8.45) = L * t p t (x)f (x)ν(dx) (8.46) As this holds for all test functions f , we can conclude using equation (8.5) that this is equivalent to the adjoint KFE d dt p t (x) = L * t p t (x) for all x ∈ S (8.47) As we will derive in the following examples, the adjoint KFE generalizes many famous equations used to develop generative models such as the Continuity Equation or the Fokker-Planck Equation (Song et al., 2021; Lipman et al., 2022) (see table 2). Whenever a probability density exists, we use the adjoint KFE -to avoid using test functions and work with probability densities directly. We summarize our findings in the following Theorem 17 (General Mass Conservation). Let L t be a generator of (X t ) 0≤t≤1 . Informally, the following conditions are equivalent: 1. p t , L t satisfies the KFE (8.40). 2. dpt dν (x), L t satisfy the adjoint KFE (8.47). 3. L t generates p t in the sense of equation (8.10).</p><p>Formally, ( <ref type="formula" target="#formula_169">1</ref>) and ( <ref type="formula" target="#formula_1">2</ref>) are equivalent whenever dpt dν exists and is continuously differentiable in t. Further, (3) implies ( <ref type="formula" target="#formula_169">1</ref>) for arbitrary state spaces. There are weak regularity assumptions that ensure that (1) implies (3) (see appendix A.3 for a list). In this work, we assume that these hold, i.e., we assume that <ref type="bibr" target="#b89">(3)</ref> implies <ref type="bibr" target="#b87">(1)</ref>.</p><p>To the best of our knowledge, there is no known result for abstract general state spaces that ensures that in theorem 17 condition (3) implies <ref type="bibr" target="#b87">(1)</ref>. This is why we simply assume it here. For the machine learning researcher, this assumption holds for any state space of interest and should therefore be of no concern (see appendix A.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3.1">Examples of KFEs</head><p>Adjoint KFE for Flows. Let us set S = R d and assume that p t has a density p t (x) with respect to the Lebesgue measure that is bounded and continuously differentiable. Then we can compute the adjoint generator</p><formula xml:id="formula_251">L * t via ⟨p t , L t f ⟩ =E x∼pt [L t f (x)] (8.48) = L t f (x)p t (x)dx (8.49) (i) = ∇f (x) T u t (x)p t (x)dx (8.50) (ii) = f (x) [-div(p t u t )(x)] =:L * t pt(x) dx (8.51) = f (x)L * t p t (</formula><p>x)dx (8.52) where (i) follows by equation (8.15) and (ii) by integration by parts. The above derivation shows that the adjoint generator is given by L * t p t = -div(p t u t )(x) (because it fulfils the condition in equation (8.41)). Using the adjoint KFE, we recover the Continuity Equation (see equation (3.25)) d dt p t (x) = -div(p t u t )(x), (8.53) an equation that we extensively studied in section 3.4. Adjoint for diffusion. Let's set S = R d and assume that p t has a density p t (x) with respect to the Lebesgue measure that is bounded and continuously differentiable. We can compute the adjoint generator L * t via ⟨p t , L t f ⟩ =E x∼pt [L t f (x)] (8.54) = L t f (x)p t (x)dx (8.55)</p><formula xml:id="formula_252">(i) = 1 2 σ 2 t (x) • ∇ 2 f (x)p t (x)dx (8.56) (ii) = f (x) 1 2 ∇ 2 • (p t σ 2 t )(x) =:L * t pt(x) dx (8.57) = f (x)L * t p t (</formula><p>x)dx (8.58) by (i) follows by equation (8.26) and (ii) follows by applying integration by parts twice. The above derivation shows that the adjoint generator is given by L * t p t = 1 2 ∇ 2 • (p t σ 2 t )(x) (because it fulfils the condition in equation (8.41)). The adjoint KFE then recovers the well-known Fokker-Planck equation d dt p t (x) = 1 2 ∇ 2 • (p t σ 2 t )(x) (8.59) Adjoint KFE for jumps. Let's assume that p t has a density p t (x) with respect to the Lebesgue measure that is bounded and continuously differentiable. Let's assume that the jump measures Q t (dy, x) is given via a kernel Q t</p><formula xml:id="formula_253">: S × S → R ≥0 , (y, x) → Q t (y, x) such that f (y)Q t (dy, x) = f (y)Q t (y, x)ν(dy) for all integrable f : S → R. (8.60)</formula><p>Then we can derive the adjoint generator as follows:</p><formula xml:id="formula_254">⟨p t , L t f ⟩ (x) = (f (y) -f (x))Q t (y, x)ν(dy)p t (x)ν(dx) (8.61) = f (y)Q t (y, x)p t (x)ν(dy)ν(dx) - f (x)Q t (y, x)p t (x)ν(dy)ν(dx) (8.62) (i) = f (x)Q t (x, y)p t (y)ν(dy)ν(dx) - f (x)Q t (y, x)p t (x)ν(dy)ν(dx) (8.63) = f (x) Q t (x, y)p t (y) -Q t (y, x)p t (x)ν(dy) =:L * t pt ν(dx) (8.64) = f (x)L * t p t (x)ν(dx) (8.65)</formula><p>where in (i) we simply swap the variables x and y. The above derivation shows that L * t as defined above fulfils the condition in equation (8.41) and indeed describes the adjoint generator for jumps. With this, the adjoint KFE becomes the Jump Continuity equation:</p><formula xml:id="formula_255">d dt p t (x) = [Q t (x, y)p t (y) -Q t (y, x)p t (x)] ν(dy) = λ t (y)J t (x, y)p t (y)ν(dy) -λ t (x)p t (x) (8.66)</formula><p>where we use the decomposition Q t (y, x) = λ t (x)J t (y, x) into a jump intensity λ t and a jump distribution J t (see equation (8.28)).</p><p>Adjoint KFE for CTMCs. For S discrete and generator given by f T u t as in equation ( <ref type="formula">8</ref>.38), we get that</p><formula xml:id="formula_256">⟨p t , L t f ⟩ = p t (x)L t f (x)ν(dx) = x∈S p t (x) y∈S u t (y, x)f (y) = y∈S [ x∈S p t (x)u t (y, x)] =:L * t pt(x) f (y) = L * t p t (y)f (y)ν(dy)</formula><p>where ν here just denotes the counting measure. Therefore, the adjoint is KFE simply given by</p><formula xml:id="formula_257">d dt p t (x) = y∈S u t (x, y)p t (y) (8.67)</formula><p>This recovers the KFE for CTMCs as derived in equation (6.8) (with x and y switched to keep consistency with the derivations in this section).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Generator Matching</head><p>In this section, we describe Generator Matching (GM) <ref type="bibr" target="#b33">(Holderrieth et al., 2024)</ref>, a generative modeling framework for (1) arbitrary data modalities and ( <ref type="formula" target="#formula_1">2</ref>) general Markov processes. GM unifies the vast majority of generative models developed in recent years, including diffusion models, "discrete diffusion" models, and the FM variants described in previous sections. To introduce GM, we defined the CTMP generative model in section 8 that is constructed via a generator of a Markov process. GM describes a scalable algorithm to train generators -giving the method its name. Beyond providing a unifying framework, GM gives rise to a variety of new models, allows us to combine models of different classes, as well as allows to build models for arbitrary modalities including models across multiple data modalities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1">Data and coupling</head><p>As before, our goal is to transfer samples X 0 ∼ p from a distribution p to samples X 1 ∼ q from a target distribution q, where X 0 , X 1 ∈ S are two RVs each taking values in the state space S. Source and target samples can be related by means of the independent coupling (X 0 , X 1 ) ∼ p ⊗ q (product distribution), or associated by means of a general PMF coupling π 0,1 , i.e., distribution over S × S with marginal π 0 = p and π 1 = q. The only difference to before is that S is a general state space and that p, q can be arbitrary probability measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2">General probability paths</head><p>The next step in the GM recipe is, as before, to prescribe a probability path p t interpolating p and q. Following section 4.4, we use a conditional probability path p t|Z (dx|z), i.e., a set of time-varying probability measures dependent on a latent state z ∈ Z. Given a distribution p Z over Z, we consider the corresponding marginal probability path p t (dx) defined via the hierarchical sampling procedure:</p><formula xml:id="formula_258">Z ∼ p Z , X t ∼ p t|Z (dx|z) ⇒ X t ∼ p t (dx)</formula><p>i.e., we obtain a sample from p t by first sampling Z from p Z and then sampling X t from p t|Z (dx|z). As before, the marginal probability path is constructed to satisfy the boundary constraints p 0 = p and p 1 = q.</p><p>We have seen already two common constructions for Z = S and p Z = q: First, affine conditional flows for S = R d (as used in continuous FM; section 4) defined via</p><formula xml:id="formula_259">Z ∼ q, X 0 ∼ p, X t = σ t X 0 + α t Z ⇒ X t ∼ p t (dx) (9.1)</formula><p>where α t , σ t ∈ R ≥0 are differentiable functions satisfying α 0 = σ 1 = 0 and α 1 = σ 0 = 1. Second, for arbitrary S, we can use mixtures as used in discrete FM for discrete state spaces (equation (7.22)):</p><formula xml:id="formula_260">Z ∼ q, X 0 ∼ p, X t ∼ Z with prob κ t X 0 with prob (1 -κ t ) ⇒ X t ∼ p t (dx) (9.2)</formula><p>where κ t ∈ R ≥0 is a differentiable functions satisfying κ 0 = 0 and κ 1 = 1 and 0 ≤ κ t ≤ 1. One can easily see that the affine conditional and mixture probability paths interpolate p and q, i.e., p 0 = p and p 1 = q.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.3">Parameterizing a generator via a neural network</head><p>Given a probability path p t , our goal is construct a CTMP model specified by a generator L t that generates this probability path (see equation (8.10)). To train a neural network for that, we first need to explain how to parameterize a generator L t with a neural network L θ t with parameters θ. We will do this in this section. Let T again be a family of test functions (see section 8.2.1). A linear parameterization of L t is defined as follows: for every x ∈ S there is (1) a convex closed set Ω x ⊂ V x that is a subset of a vector space V x with an inner product ⟨•, •⟩ x and (2) a linear operator K : T → C(S; V x ) such that every considered generator L t can be written as</p><formula xml:id="formula_261">L t f (x) = ⟨Kf (x), F t (x)⟩ x (9.3)</formula><p>for a function F t such that F t (x) ∈ Ω x for every x ∈ S. Crucially, the operator K cannot depend on L t , i.e., only F t has to be learned. This leads to the Parameterized generator: L θ t f (x) = Kf (x), F θ t (x) x with neural network F θ t and parameters θ, (9.4)</p><p>where again F θ t maps an element x ∈ S to F θ t (x) ∈ Ω x . We list several examples to make this definition more concrete.</p><p>Linear parameterization of flows. Let S = R d and Ω x = R d = V x . Let's consider all flows, i.e., the family of generators is given by (see equation (8.15)):</p><formula xml:id="formula_262">L t f = ∇f T u t , u t : R d → R d .</formula><p>(9.5)</p><p>Setting Kf = ∇f and F t = u t we recover the shape of equation ( <ref type="formula" target="#formula_272">9</ref>.3). This gives a natural linear parameterization of flow generators via their vector fields.</p><p>Linear parameterization of diffusion. Let S = R d and Ω</p><formula xml:id="formula_263">x = S ++ d ⊂ R d×d = V x , where S ++ d</formula><p>denotes the set of all positive semi-definite matrices. Then a diffusion generator is given by (see equation (8.26)):</p><formula xml:id="formula_264">L t f = ∇ 2 f • σ 2 t , σ t : R d → S ++ d (9.6)</formula><p>Setting Kf = ∇ 2 f and F t = σ 2 t we recover the shape of equation ( <ref type="formula" target="#formula_272">9</ref>.3). This gives a natural linear parameterization of diffusion generators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Linear parameterization of jumps. Let</head><formula xml:id="formula_265">Ω x = {a : S \ {x} → R ≥0 | a integrable} ⊂ L 2 (S \ {x}) = V x with dot product ⟨a, b⟩ x = S\{x} a(x)b(x)ν(dx).</formula><p>Then the jump generator is given by (see equation (8.36)):</p><formula xml:id="formula_266">L t f (x) = [f (y) -f (x)]Q t (y, x)ν(dy) = ⟨Kf (x), Q t (•; x)⟩ x (9.7)</formula><p>where we set Kf (x) as the function y → f (y) -f (x). Setting F t = Q t we recover the shape of equation (9.3)giving a linear parameterization of jump generators. We note that the above only parameterizes jumps with a jump kernel Q t (y, x), which does not necessarily include all jump measures.</p><p>Linear parameterization of CTMCs. Let S be discrete and u t ∈ R S×S be a rate matrix of a continuous-time Markov chain. As for discrete FM (see equation (7.5)), we define</p><formula xml:id="formula_267">Ω x =    v ∈ R S v(y) ≥ 0 ∀y ̸ = x, and v(x) = - y̸ =x v(y)    ⊂ V x = R S . (9.8)</formula><p>Then by equation (8.38), the generator is given for f ∈ R S by</p><formula xml:id="formula_268">L t f (x) = f T u t (•, x) = ⟨f, u t (•, x)⟩ x (9.9)</formula><p>where V x = R S and Kf = f and ⟨•, •⟩ x is the standard Euclidean dot product. With this, we recover the shape of equation (9.3). Therefore, this gives a natural linear parameterization of CTMCs via their rates u t .</p><p>Linear parameterization of flows on manifolds. Let S = M be a Riemannian manifold and as in section 5, let us consider flows on Riemannian manifolds. By equation (8.39), the generator is given by L t f (x) = ⟨∇f (x), u t (x)⟩ g (9.10) with u t being a time-dependent smooth vector field u t : [0, 1] × M → T M, and u t (x) ∈ T x M for all x ∈ M.</p><p>Setting Ω x = V x = T x M and K = ∇f the gradient operator, we recover the shape of equation (9.3). Therefore, this gives a natural linear parameterization of Riemannian flow generators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.4">Marginal and conditional generators</head><p>In this section, we show how to find generators for marginal probability paths. The recipe is as follows: We can find generators for conditional probability paths p t|Z (dx|z), often analytically, and use these to construct generators for the marginal path. Specifically, let us assume that for every z ∈ Z we found a (conditional) generator L z that generates p t|Z (dx|z), i.e., by theorem 17 this equivalent to the KFE (equation (8.40)):</p><formula xml:id="formula_269">d dt p t|Z (•|z), f = p t|Z (•|z), L z t f for all f ∈ T . (9.11)</formula><p>Further, let us assume that we found a linear parameterization (see equation (9.3)) as follows:</p><formula xml:id="formula_270">L z t f (x) = ⟨Kf (x), F t (x|z)⟩ x z ∈ Z (9.12) for functions F t (x|z) ∈ Ω x ⊂ V x .</formula><p>For example, F t (x|z) could be conditional velocity field in continuous FM (see section 4.3) or the conditional rates in discrete FM (see equation (7.2)). This allows us to find a formula for a generator that generates the marginal path: Theorem 19 (General Marginalization Trick). The marginal probability path (p t ) 0≤t≤1 is generated by a Markov process X t with generator</p><formula xml:id="formula_271">L t f (x) = E Z∼p Z|t (•|x) [L Z t f (x)] (9.13)</formula><p>where p Z|t (dz|x) is the posterior distribution (i.e., the conditional distribution of z given x). The generator L t has a linear parameterization given by</p><formula xml:id="formula_272">F t (x) = E Z∼p Z|t (•|x) [F t (x|Z)].<label>(9.14)</label></formula><p>The above theorem gives us our training target: to approximate L t in equation ( <ref type="formula" target="#formula_272">9</ref>.13) with a neural network.</p><p>The marginalization tricks seen in previous chapters (theorem 3, theorem 10, theorem 14) are special cases of this theorem. We give a proof here and then show a few examples of novel instantiations.</p><p>Proof. To prove that L t generates p t , we need to show by theorem 17 that the KFE is fulfilled. Let p t+h|t (•|x, z) be the transition kernel of L z t . Then:</p><formula xml:id="formula_273">d dt ⟨p t , f ⟩ = lim h→0 1 h (⟨p t+h , f ⟩ -⟨p t , f ⟩) = lim h→0 1 h (E Z∼p Z ,X ′ ∼p t+h|Z (•|Z) (f (X ′ )) -E Z∼p Z ,X∼p t|Z (•|z) (f (X))) = lim h→0 1 h (E Z∼p Z ,X∼p t|Z (•|Z),X ′ ∼p t+h|t (•|X,Z) (f (X ′ )) -E Z∼p Z ,X∼p t|Z (•|z) (f (X))) = lim h→0 1 h (E Z∼p Z ,X∼p t|Z (•|Z),X ′ ∼p t+h|t (•|X,Z) (f (X ′ ) -f (X))) = lim h→0 1 h E X∼pt E Z∼p t|Z (•|X) E( X ′ ∼p t+h|t (•|X,Z) (f (X ′ )) -f (X) = E X∼pt E Z∼p Z|t (•|X) lim h→0 1 h E X ′ ∼p t+h|t (•|X,Z) (f (X ′ )) -f (X) = E X∼pt (E Z∼p Z|t (•|X) (L z t f (X)) =:Ltf (X) ) = ⟨p t , L t f ⟩</formula><p>The proof for the form of F t follows then by</p><formula xml:id="formula_274">E Z∼p Z|t (•|X) (L z t f (x)) (9.12) = E Z∼p Z|t (•|X) (⟨Kf (x), F t (x|z)⟩ x ) = Kf (x), E Z∼p Z|t (•|X) (F t (x|z)) x = ⟨Kf (x), F t (x)⟩ x</formula><p>where we use the linearity of the dot product to swap it with the expected value. This shows that F t is a linear parameterization (see equation (9.3)) of the marginal generator.</p><p>Example -Jumps. Let S be arbitrary and Q t (y, x|z) be a conditional jump kernel on S for y, x ∈ S, z ∈ Z generating the conditional probability path p t|Z (dx|z). Using the linear parameterization of the jump kernel (see equation (9.7)), we get that the marginal jump kernel</p><formula xml:id="formula_275">Q t (y, x) = E Z∼p Z|t (•|x) [Q t (y, x|z)].</formula><p>generates the marginal probability p t (dx).</p><p>Example -Marginal diffusion coefficient. Let S = R d and σ 2 t (x|z) be a diffusion coefficient generating the conditional probability path p t|Z (dx|z). Using the linear parameterization of the diffusion coefficient (see equation (9.6)), we get that the marginal diffusion coefficient</p><formula xml:id="formula_276">σ 2 t (x) = E Z∼p Z|t (•|x) [σ 2 t (x|Z)]</formula><p>generates the marginal probability path p t (dx).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.5">Generator Matching loss</head><p>Our next goal is to develop a training objective for learning a CTMP model. Let us assume that we have a neural network F θ t that gives us a generator parameterization L θ t as in equation (9.4). As derived in theorem 19, our goal is to approximate the true marginal linear parameterization F t given by equation (9.14).</p><p>As before, let us assume that for every x ∈ S we have a Bregman divergence D</p><formula xml:id="formula_277">x : Ω x × Ω x → R defined via D x (a, b) = Φ x (a) -[Φ x (b) + ⟨a -b, ∇Φ x (b)⟩], a, b ∈ Ω x (9.15)</formula><p>for a strictly convex function Φ x : Ω x → R (see figure <ref type="figure" target="#fig_14">10</ref>). The Generator Matching loss to train the CTMP model is defined as</p><formula xml:id="formula_278">L GM (θ) = E t,Xt∼pt D Xt (F t (X t ), F θ t (X t )),<label>(9.16)</label></formula><p>for t ∼ U [0, 1]. Unfortunately, the above training objective is intractable as we do not know the marginal generator L t and also not the parameterization F t thereof (we only know the intractable formula in equation (9.14)). Hence, we introduce the Conditional Generator Matching loss as a tractable alternative that takes the form L CGM (θ) = E t,Z,Xt∼p t|Z D Xt (F t (X t |Z), F θ t (X t )).</p><p>(9.17)</p><p>This objective is tractable as we can derive F t (x|z) analytically in many cases (see section 9.6). As the next theorem shows, the two losses (9.16) and (9.17) both provide the same learning gradients.</p><p>Theorem 20. The gradients of the Generator Matching loss and the Conditional Generator Matching loss coincide: ∇ θ L GM (θ) = ∇ θ L CGM (θ).</p><p>(9.18)</p><p>In particular, the minimizer of the Conditional Generator Matching loss is the linear parameterization of the marginal generator (equation (9.14)):</p><formula xml:id="formula_279">F θ t (x) = E Z∼p Z|t (•|x) [F t (x|Z)]. (9.19)</formula><p>Furthermore, for these properties to hold, D x must necessarily be a Bregman divergence.</p><p>The above theorem generalizes theorem 4, theorem 11, and theorem 15 derived in previous sections to general CTMP models. It allows us to easily train any CTMP model parameterized by a neural network F θ t in a scalable fashion by minimizing the Conditional Generator Matching loss. In addition, it universally characterizes the space of loss functions. The proof of theorem 20 is identical as the proof of theorem 4 with u t replaced by F t . For the proof of the necessity of D being a Bregman divergence, we refer to <ref type="bibr" target="#b33">(Holderrieth et al., 2024)</ref>.</p><p>i.e., the jump intensity is given by λ t and once we decided to jump, we jump straight to z ∈ S. To show this, we show that the above jump process fulfils the KFE. We can derive:</p><formula xml:id="formula_280">E X∼p t|Z (•|z) λ t (X)E Y ∼Jt(•,X) [f (Y ) -f (X)] = κt 1 -κ t E X∼p t|Z (•|z) [f (z) -f (X)] = κt 1 -κ t [f (z) -E X∼p t|Z (•|z) [f (X)]] = κt 1 -κ t [f (z) -[κ t f (z) + (1 -κ t )E X∼p f (X)] = κt f (z) -κt E X∼p f (X) = d dt [κ t f (z) + (1 -κ t )E x∼p [f (x)]] = d dt E X∼p t|Z (•|z) [f (X)] = d dt p t|Z (•|z), f .</formula><p>Therefore, we see that the process fulfills the jump KFE (equation (9.26)). Therefore, we have established a jump model. We have seen a special example of that model for discrete state spaces in equation (7.24). Here, we have shown that one could also build a similar jump model for Euclidean space R d , for example.</p><p>Jump models for arbitrary paths with densities. Let us assume that we have a probability p t|Z (dx|z) that admits a density p t|Z (x|z) with respect to a reference measure ν on S and that is differentiable in t (note that the mixture path in equation (9.25) would not fulfill that for S = R d ). Further, we restrict ourselves to jump kernels J t (y, x) that admit a density.</p><p>With this, the adjoint KFE becomes the Jump Continuity Equation (equation (8.66)): d dt p t|Z (x|z) = λ t (y)J t (x, y)p t|Z (y|z)dy -p t|Z (x|z)λ t (x) (9.27) ⇔ p t|Z (x|z) d dt log p t|Z (x|z) + λ t (x) = λ t (y)J t (x, y)p t|Z (y|z)dy (9.28) Making J t (x, y) = J t (x) ("target-state-independent") and using ∂ t = d dt , we get that this equivalent to: p t|Z (x|z) ∂ t log p t|Z (x|z) + λ t (x) = J t (x) λ t (y)p t|Z (y|z)ν(dy) (9.29) ⇔ p t|Z (x|z) ∂ t log p t|Z (x|z) + λ t (x) λ t (y)p t|Z (y|z)ν(dy) = J t (x) (9.30)</p><p>In order to define a valid jump process, we require λ t , J t to satisfy λ t (x) ≥ 0, J t (x) ≥ 0. Therefore, we get:</p><formula xml:id="formula_281">λ t (x) ≥0, J t (x) ≥ 0 ⇔ λ t (</formula><p>x) ≥ [-∂ t log p t (x|z)] + (9.31) where [x] + = max(x, 0) describes the ReLU operation. Further, we require J t to define a valid jump distribution, i.e., integrate to 1. This can be seen to hold: 1 = J t (x)dx ⇔ λ t (x)p t|Z (x|z)ν(dx) = p t|Z (x|z) ∂ t log p t|Z (x|z) + λ t (x) ν(dx) ⇔ 0 = ∂ t p t|Z (x|z)ν(dx) ⇔ 0 = ∂ t p t|Z (x|z)ν(dx) ⇔ 0 = 0 i.e., J t indeed integrates to 1. Choosing the minimal λ t (x), we get that a jump model defined via λ t (x) = -∂ t log p t|Z (x|z) + , J t (x) = p t|Z (x|z)[∂ t log p t|Z (x|z)] + p t|Z (y|z)[∂ t log p t|Z (y|z)] + ν(dy) = [∂ t p t|Z (x|z)] + [∂ t p t|Z (y|z)] + ν(dy)</p><p>is a solution to the jump continuity equation and therefore generates the conditional probability path p t|Z (x|z). At first, it seems dissatisfying that jump distribution is independent of the location. However, if we extend this model to multiple dimensions, the jump distribution will depend on the location and leads to a powerful generation model <ref type="bibr" target="#b33">(Holderrieth et al., 2024)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.7">Combining Models</head><p>In this section, we explain how GM allows us to combine generative models for the same state space S in different ways. The underlying principle is simple: the generator is a linear operator and the KFE ∂ t ⟨p t , f ⟩ = ⟨p t , L t f ⟩ is a linear equation -so essentially, we can combine solutions for this equation like we do for matrix equations in linear algebra. Specifically, let L t , L ′ t be two generators of two Markov processes that solve the KFE for a probability path p t . Then for α 1 t , α</p><p>2 t ∈ R with α 1 t + α 2 t = 1 it holds that: p t , (α 1 t L t + α 2 t L ′ t )f (9.32) = α 1 t ⟨p t , L t f ⟩ + α 2 t ⟨p t , L ′ t f ⟩ (9.33) = α 1 t ∂ t ⟨p t , f ⟩ + α 2 t ∂ t ⟨p t , f ⟩ (9.34) = (α 1 t + α 2 t )∂ t ⟨p t , f ⟩ (9.35) = ∂ t ⟨p t , f ⟩ , (9.36) i.e., α 1 t L t + α 2 t L ′ t is again a solution of the KFE. A small but important detail is whether α 1 t , α 2 t are positive or negative and whether L t , L ′ t correspond to Markov processes in forward or backward time. This leads to the following Proposition 3 (Combining models). Let p t be a marginal probability path, then the following generators solve the KFE for p t and consequently define a generative model with p t as marginal: 1. Markov superposition: α 1 t L t + α 2 t L ′ t , where L t , L ′ t are two generators of Markov processes solving the KFE for p t , and α 1 t , α 2 t ≥ 0 satisfy α 1 t + α 2 t = 1. 2. Divergence-free components: L t + β t L div t , where L div t</p><p>is a generator such that p t , L div t f = 0 for all f ∈ T , and β t ≥ 0. We call such L div t divergence-free.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.</head><p>Predictor-corrector: α 1 t L t + α 2 t Lt , where L t is a generator solving the KFE for p t in forward-time and Lt is a generator solving the KFE in backward time, and α 1 t , α 2 t ≥ 0 with α 1 t -α 2 t = 1.</p><p>We give examples for a Markov superposition and a divergenc-free component here to illustrate proposition 3. An example of the power of a predictor-corrector scheme can be found in <ref type="bibr" target="#b25">(Gat et al., 2024)</ref>.</p><p>Markov superposition example -combining jump and flow. Markov superpositions can be used to combine generative models of different classes. These can be 2 networks trained separately or we can train two GM models in one network simultaneously <ref type="bibr" target="#b33">(Holderrieth et al., 2024)</ref>. We illustrate this here by combining a jump model and a flow model on S = R d . Let us assume that we have two models where each of them generates the probability path p t : (1) a flow model u t and (2) a jump model with jump intensity λ t and jump distribution J t . By proposition 3, for α 1 t , α 2 t ≥ 0 with α 1 t + α 2 t = 1, it holds that the following generator defines a valid GM model generating p t :</p><formula xml:id="formula_282">L t f (x) = α 1 t L jump t f (x) + α 2 t L flow t f (x) = (α 1 t λ t (x))E Y ∼Jt(•,x) [f (Y ) -f (x)] + ∇f T (x)(α 2 t u t (x))</formula><p>where we have used equation (8.17) and equation (8.36). In fact, the above generator describes a piecewisedeterministic Markov process, a combined ODE and jump model <ref type="bibr" target="#b17">(Davis, 1984)</ref>. As the equation above shows, we have to scale the jump intensity by α 1 t and the vector field by α 2 t . We can sample from the resulting GM model with the following sampling procedure: X 0 ∼ p 0 = p X t+h = ∼ J t (dy, X t ) with probability hα 1 t λ t (X t ) X t + hα 2 t u t (X t ) with probability 1 -hα 1 t λ t (X t )</p><p>In <ref type="bibr" target="#b33">(Holderrieth et al., 2024)</ref>, several examples of Markov superpositions of jump and flow are given and shown to lead to performance improvements.</p><p>Divergence-free example -MCMC algorithms. To find divergence-free components, one can use existing Markov-Chain Monte-Carlo (MCMC) algorithms -all of these algorithms describe a general recipe to find a divergence-free component. We illustrate this with 2 famous examples. Let us assume that we are given a general probability path p t with density p t (x). Then for a generator L div t to be divergence-free is equivalent to that its adjoint maps p t to zero: p t , L div t f = 0 for all f ∈ T ⇔ [L div t ] * p t (x) = 0 for all x ∈ S (9.37)</p><p>First, let us consider S = R d . Langevin dynamics correspond to an SDE with velocity field</p><p>1 2 β 2 t ∇ log p t (x) and diffusion coefficient β t , i.e., the dynamics are given via dX t = 1 2 β 2 t ∇ log p t (x)dt + β t dW t (9.38) The adjoint generator of this SDE is given by [L div t ] * p t (i) = -div(p t 1 2 β 2 t ∇ log p t )(x) + 1 2 β 2 t ∆p t (x) (ii) = -1 2 div(β 2 t ∇p t )(x) + 1 2 β 2 t ∆p t (x) (iii) = -1 2 β 2 t ∆p t (x) + 1 2 β 2 t ∆p t (x) = 0</p><p>where (i) holds by shape of flow and diffusion adjoint derived in section 8.3.1, (ii) holds because ∇ log p t = ∇p t /p t , and (iii) holds by the identity div∇ = ∆. The above shows that the generator of Langevin dynamics fulfils equation (9.37) and is therefore divergence-free in sense of proposition 3. This fact is widely applied in statistical physics and Markov chain Monte Carlo <ref type="bibr" target="#b66">(Roberts and Tweedie, 1996)</ref>. Proposition 3 shows that we can add these dynamics for arbitrary β t ≥ 0 to any generative model. In section 10, we use this to derive stochastic sampling for diffusion models.</p><p>Second, let S be a general state space again. The Metropolis-Hastings algorithm <ref type="bibr" target="#b29">(Hastings, 1970)</ref> wdescribes the construction of a jump process with jump kernel Q t (y, x) that satisfies the detailed balance condition:</p><p>Q t (y, x)p t (x) = Q t (x, y)p t (y) for all x, y ∈ S ⇒ [L div t ] * p t (x)</p><formula xml:id="formula_283">(i) = Q t (y, x)p t (x) -Q t (x, y)p t (y) = 0</formula><p>where in (i) we used equation (8.66). This shows that equation (9.37) is fulfilled and Q t is divergence-free.</p><p>Proposition 3 shows that one can arbitrarily add such a Metropolis-scheme to any GM model following the probability path p t . <ref type="bibr">et al., 2022)</ref>. This assumption allows us to express the conditional distribution of X r given X 0 = z ∈ R d as a Gaussian distribution <ref type="bibr" target="#b72">(Särkkä and Solin, 2019;</ref><ref type="bibr">Song et al., 2021;</ref><ref type="bibr" target="#b40">Karras et al., 2022)</ref>: Note that we have discussed such probability paths extensively in section 4.8.3 as affine Gaussian probability paths, i.e., they are constructed via the affine conditional flow (see section 4.8):</p><p>ψ t (x|x 1 ) = α t z + σ t x, z ∼ q, x ∼ N (α 0 , σ 2 0 I).</p><p>(10.9) Therefore, we can see that:</p><p>Forward processes with affine drift coefficients correspond to using Gaussian probability paths (see section 4.8.3) defined by equation (10.8).</p><p>Note that for diffusion models in the above time parameterization, there is no finite times r &lt; +∞ at which the marginal pr (x) is an exact Gaussian.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.3">Training a diffusion model</head><p>We now discuss how we can recover the training algorithm of diffusion models as a special case of FM training. In section 4.8, we discussed several options of how to parameterize and train a FM model with Gaussian probability paths (see theorem 7). One particular option was x 0 -prediction where the neural network x θ 0|t is trained to approximate</p><formula xml:id="formula_284">x θ 0|t ≈ E[X 0 |X t =</formula><p>x] via the following training algorithm L CM (θ) = E t,Z∼q,X0∼p ∥x θ 0|t (α t X 0 + σ t Z =Xt ) -X 0 ∥ 2 (i) = E t,Z∼q,Xt∼p t|1 (•|Z) σ 2 t ∥s θ t (X t ) -[-1 σ 2 t (X t -α t Z)]∥ 2 (ii) = E t,Z∼q,Xt∼p t|1 (•|Z) σ 2 t ∥s θ t (X t ) -∇ log p t|1 (X t |Z)∥ 2 ,</p><p>where in (i) we reparameterized the neural network via s θ t = -x θ 0|t /σ t and in (ii) we used equation (4.71). The above loss is also called the Denoising Score Matching <ref type="bibr" target="#b82">(Vincent, 2011)</ref> loss and is the fundamental loss function with which diffusion models are trained. By theorem 7, we get that the minimizer θ * fulfills that i.e., at minimal loss, s θ t equals the score function ∇ log p t (x) of the marginal probability path. Therefore, the network s θ t is also called the score network. We can therefore summarize:</p><formula xml:id="formula_285">s θ * t (x) = - 1 σ t E[X 0 |X t = x]</formula><p>The training algorithm for diffusion models is equivalent to training a specific FM model with x 0 -prediction. Specifically, in addition to reparameterizing time, it is the same as training a FM model with:</p><p>(1) Probability path: Using a Gaussian probability path with independent coupling constructed via an SDE with affine drift coefficients (α t , σ t defined via (10.7)).</p><p>(2) Score parameterization: Reparameterizing the marginal velocity field via the score function.</p><p>In table <ref type="table">1</ref>, we list how one can easily convert a score network to other velocity parameterizations. Therefore, different parameterizations are theoretically equivalent and one can even swap parameterizations post-training (see section <ref type="bibr">4.8.1)</ref>. Note however, that the score and x 0 prediction parameterizations introduce a singularity at time t = 0 (near noise).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.4">Sampling</head><p>Next, we discuss sampling from a diffusion model and how it relates to sampling from FM or GM model.</p><p>Deterministic sampling with ODE. If we consider the diffusion model a FM model, we would sample by sampling from the marginal vector field. In (4.78) we expressed the marginal vector field via the score function (for Gaussian paths): u t (x) = αt α t x -σt σ t -σ<ref type="foot" target="#foot_3">foot_3</ref> t αt α t ∇ log p t (x). (10.11) Using the specific form of equation (10.7) for α t , σ t , one derive the equivalent identity: u t (x) = k(t) a t x -g 2 t 2 ∇ log p t (x) . (10.12) Alternatively, one insert the above u t (x) into the Continuity Equation to validate this directly. The corresponding ODE to u t is also called the Probability Flow ODE (Song et al., 2021): dX t = k(t) a t X t -g 2 t 2 s θ t (X t ) dt, (10.13)</p><p>where we set s θ t (x) = ∇ log p t (x) as the learned score function. Note that we use here the notation for ODEs that is common for SDEs for a reason that becomes clear next. We also note that in equation ( <ref type="formula">10</ref>.11) we add the term k(t) compared to <ref type="bibr">(Song et al., 2021)</ref> because of the time reparameterization.</p><p>Stochastic sampling with SDE. In section 9.7, we have derived that we can add the Langevin dynamics</p><p>1 2 β 2 t ∇ log p t (x)dt + β t dW t (10.14) to any CTMP generative model and we will obtain a generative model following the same probability path. We can apply this to the Probability Flow ODE to get a whole family of SDEs that generate the probability path p t : dX t = k(t)α t X t + β 2 t -k(t)g 2 t 2 ∇ log p t (X t ) dt + β t dW t . (10.15)</p><p>The above results in stochastic sampling of a diffusion model. In theory, all models above lead to the same marginals for every β t ≥ 0. This is a mathematical fact about the ground truth underlying stochastic process.</p><p>In practice, we need to simulate the SDE</p><formula xml:id="formula_286">dX t = k(t)α t X t + β 2 t -k(t)</formula><p>g 2 t 2 s θ t (X t ) dt + β t dW t (10.16)</p><p>with a trained network s θ t . We have both estimation errors (i.e., imperfect training of s θ t ) as well as simulation errors (i.e., imperfect sampling of the underlying SDE). Therefore, there is an optimal unknown noise level β t (see e.g., <ref type="bibr">(Albergo and Vanden-Eijnden, 2022, equation (2.45)</ref>)) that can be determined empirically <ref type="bibr" target="#b40">(Karras et al., 2022)</ref> and theoretically <ref type="bibr" target="#b50">(Ma et al., 2024)</ref>. Therefore, we get:</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1</head><label>1</label><figDesc>Figure1Four time-continuous processes (Xt) 0≤t≤1 taking source sample X0 to a target sample X1. These are a flow in a continuous state space, a diffusion in continuous state space, a jump process in continuous state space (densities visualized with contours), and a jump process in discrete state space (states as disks, probabilities visualized with colors).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2</head><label>2</label><figDesc>Figure 2 The Flow Matching blueprint. (a) The goal is to find a flow mapping samples X0 from a known source or noise distribution q into samples X1 from an unknown target or data distribution q. (b) To do so, design a time-continuous probability path (pt) 0≤t≤1 interpolating between p := p0 and q := p1. (c) During training, use regression to estimate the velocity field ut known to generate pt. (d) To draw a novel target sample X1 ∼ q, integrate the estimated velocity field u θ t (Xt) from t = 0 to t = 1, where X0 ∼ p is a novel source sample.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>( c )</head><label>c</label><figDesc>Conditional velocity field ut(x|x1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3</head><label>3</label><figDesc>Figure 3 Path design in Flow Matching. Given a fixed target sample X = x1, its conditional velocity field ut(x|x1) generates the conditional probability path pt(x|x1). The (marginal) velocity field ut(x) results from the aggregation of all conditional velocity fields-and similarly for the probability path pt(x).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Code 1 :</head><label>1</label><figDesc>fig, axes = plt.subplots(1, n_steps + 1, figsize=(30, 4), sharex=True, sharey=True) time_steps = torch.linspace(0, 1.0, n_steps + 1)axes[0].scatter(x.detach()[:, 0], x.detach()[:, 1], s=10) axes[0].set_title(f't ={time_steps[0]:.2f}') axes[0].set_xlim(-3.0, 3.0) axes[0].set_ylim(-3.0, 3.0) for i in range(n_steps): x = flow.step(x, time_steps[i], time_steps[i + 1]) axes[i + 1].scatter(x.detach()[:, 0], x.detach()[:, 1], s=10) axes[i + 1].set_title(f't = {time_steps[i + 1]:.2f}') plt.tight_layout() plt.show()</figDesc><graphic coords="7,86.46,656.66,439.05,57.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 4</head><label>4</label><figDesc>Figure 4  Joint PDF pX,Y (in shades) and its marginals pX and pY (in black lines).</figDesc><graphic coords="8,423.57,567.50,117.56,116.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 5 A</head><label>5</label><figDesc>Figure5A flow model Xt = ψt(X0) is defined by a diffeomorphism ψt : R d → R d (visualized with a brown square grid) pushing samples from a source RV X0 (left, black points) toward some target distribution q (right). We show three different times t.</figDesc><graphic coords="10,82.42,63.78,141.08,105.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 6 A</head><label>6</label><figDesc>Figure 6 A flow ψt : R d → R d (square grid) is defined by a velocity field ut : R d → R d (visualized with blue arrows) that prescribes its instantaneous movements at all locations. We show three different times t.</figDesc><graphic coords="11,82.42,63.78,141.08,105.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 7 A</head><label>7</label><figDesc>Figure 7 A velocity field ut (in blue) generates a probability path pt (PDFs shown as contours) if the flow defined by ut (square grid) reshapes p (left) to pt at all times t ∈ [0, 1).</figDesc><graphic coords="12,82.42,63.78,141.08,105.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><figDesc>.sample(x_init=x_0, method='midpoint', step_size=1.0 / num_steps)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 8</head><label>8</label><figDesc>Figure 8 The continuity equation asserts that the local change in probability equals minus the net outgoing probability flux.</figDesc><graphic coords="14,418.86,181.48,117.57,116.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 10</head><label>10</label><figDesc>Figure 10 Bregman divergence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Code 4 :</head><label>4</label><figDesc>Training with the conditional flow matching (CFM) loss = ... # The flow_matching library implements the most common probability paths 6 velocity_model: torch.nn.Module = ... # Initialize the velocity model 7 optimizer = torch.optim.Adam(velocity_model.parameters()) 8 9 for x_0, x_1 in dataloader: # Samples from π 0,1 of shape [batch_size, *data_dim] 10 t = torch.rand(batch_size) # Randomize time t ∼ U [0, 1] 11 sample: PathSample = path.sample(t=t, x_0=x_0, x_1=x_1) 12 x_t = sample.x_t 13 dx_t = sample.dx_t # dX_t is ψt(X0|X1).14 # If D is the Euclidean distance, the CFM objective corresponds to the mean-squared error 15 cfm_loss = torch.pow(velocity_model(x_t, t) -dx_t, 2).mean()</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 11</head><label>11</label><figDesc>Figure 11 Different forms of conditioning in Flow Matching and path design with corresponding conditional flows. When the conditional flows are a diffeomorphism, all constructions are equivalent. When, they are not, extra conditions are required to validate that the marginal velocity generates the marginal path, see text for more details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>4 5# 9 #</head><label>49</label><figDesc>.53) Code 5: Examples of affine probability paths in the flow_matching library 1 from flow_matching.path import AffineProbPath, CondOTPath 2 from flow_matching.path.scheduler import ( 3 CondOTScheduler, PolynomialConvexScheduler, LinearVPScheduler, CosineScheduler) Conditional Optimal Transport schedule with αt = t, σt = 1 -t 6 path = AffineProbPath(scheduler=CondOTScheduler()) 7 path = CondOTPath() # Shorthand for the affine path with the CondOTScheduler above 8 Polynomial schedule with αt = t n , σt = 1 -t n 10 path = AffineProbPath(scheduler=PolynomialConvexScheduler(n=1.0)) 11 12 # Linear variance preserving schedule with αt = t, σt = √ 1 -t 2 13 path = AffineProbPath(scheduler=LinearVPScheduler()) 14 15 # Cosine schedule with αt = sin(0.5tπ), σt = cos(0.5tπ) 16 path = AffineProbPath(scheduler=CosineScheduler())</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Code 6 :</head><label>6</label><figDesc>Training an X 1 -prediction model using the Conditional Matching (CM) objective 1 import torch 2 from flow_matching.path import AffineProbPath 3 from flow_matching.solver import ODESolver 4 from flow_matching.utils import ModelWrapper 5 6 path: AffineProbPath = ...</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>7#</head><figDesc>denoiser_model: torch.nn.Module = ... # Initialize the denoiser 8 optimizer = torch.optim.Adam(velocity_model.parameters()) 9 10 for x_0, x_1 in dataloader: # Samples from π 0,1 of shape [batch_size, *data_dim] 11 t = torch.rand(batch_size) # Randomize time t ∼ U [0, 1] 12 sample = path.sample(t=t, x_0=x_0, x_1=x_1) # Sample the conditional path 13 cm_loss = torch.pow(model(sample.x_t, t) -sample.x_1, 2).mean() Convert from denoiser to velocity prediction 19 class VelocityModel(ModelWrapper): 20 def __init__(self, denoiser: nn.Module, path: AffineProbPath): 21 super().__init__(model=denoiser) 22 self.path=path 23 24 def forward(self, x: torch.Tensor, t: torch.Tensor, **extras) -&gt; torch.Tensor: 25 x_1_prediction = super().forward(x, t, **extras) 26 return self.path.target_to_velocity(x_1=x_1_prediction, x_t=x, t=t) .randn(batch_size, *data_dim) # Specify the initial condition 31 solver = ODESolver(velocity_model=velocity_model) 32 num_steps = 100 33 x_1 = solver.sample(x_init=x_0, method='midpoint', step_size=1.0 / num_steps)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>#</head><figDesc>Sample the transformed model with the conditional OT schedule20 solver = ODESolver(velocity_model=transformed_model) 21 x_0 = torch.randn(batch_size, *data_dim) # Specify the initial condition 22 solver = ODESolver(velocity_model=velocity_model) 23 num_steps = 100 24 x_1 = solver.sample(x_init=x_0, method='midpoint', step_size=1.0 / num_steps)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Code 8 :</head><label>8</label><figDesc>Training with geodesic flows on a Sphere using the CFM objective .. # Define a trainable velocity model 7 optimizer = torch.optim.Adam(model.parameters()) 8 loss_fn = torch.nn.MSELoss() # Any Bregman divergence x_1 in dataloader: # Samples from π 0,1 of shape [batch_size, *data_dim] 15 t = torch.rand(batch_size) # Randomize time t ∼ U [0, 1] 16 sample: PathSample = path.sample(t=t, x_0=x_0, x_1=x_1) # Sample the conditional path 17 18 model_output = model(sample.x_t, sample.t) 19 projected_model_output = manifold.proju(sample.x_t, model_output) # Project to tangent space</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><figDesc>(x, y) -j t (y, x)] ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><figDesc>= path.sample(t=t, x_0=x_0, x_1=x_1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Code 10 :</head><label>10</label><figDesc>Training and sampling DFM with mixture paths and arbitrary data coupling. .. # Define a trainable velocity model 11 optimizer = torch.optim.Adam(model.parameters()) x_1 in dataloader: # Samples from π 0,1 of shape [batch_size, *data_dim] 18 t = torch.rand(batch_size) * (1.0 -1e-3) # Randomize time t ∼ U [0, 1 -10 -3 ] 19 sample: DiscretePathSample = path.sample(t=t, x_0=x_0, x_1=x_1) # Sample the conditional path 20 model_output = model(sample.x_t, sample.t) 21 22 loss = loss_fn(logits=model_output, x_1=sample.x_1, x_t=sample.x_t, t=sample.t) # CDFM loss self, x: torch.Tensor, t: torch.Tensor, **extras) -&gt; torch.Tensor: 30 logits = self.model(x, t, **extras) 31 return torch.nn.functional.softmax(logits.float(), dim=-1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>⇒</head><figDesc>p t|1 (x|z) = N α t z, σ 2 t I α t = αk(t) , σ t = σk(t) (10.8)</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>E.g., see https://pytorch.org/docs/stable/generated/torch.autograd.functional.vjp.html.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>x_1 = solver.sample(x_init=x_0, step_size=step_size, time_grid=torch.tensor([0.0, 1.0-1e-3]))</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_2"><p>ODE sampling: For a Gaussian source, independent coupling, fixing α t , σ t according to (10.7), and score parameterization, sampling from a diffusion model with the Probability Flow ODE is the same as sampling from a FM model.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_3"><p>SDE sampling: Under the same conditions, sampling from a diffusion model with stochastic SDE sampling is equivalent to sampling from GM model defined via equation (10.15).</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the previous result, by integrable u we mean 1 0 M ∥u t (x)∥ p t (x)dvol x dt &lt; ∞.</p><p>(5.2)</p><p>Note that the assumptions of theorem 9 yield a global diffeomorphism on M, giving rise to the Riemannian instantaneous change of variables formula: d dt log p t (ψ t (x)) = -div g (u t )(ψ t (x)).</p><p>(5.3)</p><p>Finally, we say that u t generates p t from p if X t = ψ t (X 0 ) ∼ p t for X 0 ∼ p.</p><p>(5.4)</p><p>Having positioned flows as valid generative models on manifolds, it stands to reason that the FM principles can be transferred to this domain as well. In the Riemannian version of FM we aim to find a velocity field u θ t ∈ U generating a target probability path p t : [0, 1] → P with marginal constraints p 0 = p and p 1 = q, where p, q denote the source and target distributions over the manifold M. As the velocity field lies on the tangent spaces of the manifold, the Riemannian Flow Matching loss compares velocities using a Bregman divergence defined over the individual tangent planes of the manifold, L RFM (θ) = E t,Xt∼pt D Xt u t (X t ), u θ t (X t ) .</p><p>(5.5)</p><p>In the equation above, the expectation is now an integral over the manifold, that is E[f (X)] = M f (x)p X (x)dvol x , for a smooth function f : M → M and a random variable X ∼ p X . The Bregman divergences, D x , x ∈ M, are potentially defined with the Riemannian inner product and a strictly convex function assigned to each tangent space Φ x :</p><p>For example, choosing the Riemannian metric</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Probability paths on manifolds</head><p>Marginal probability paths are built as in the Euclidean case <ref type="bibr">(4.4)</ref>: <ref type="bibr">(5.6)</ref> where p t|1 (x|x 1 ) is the conditional probability path defined on the manifold. We also require the boundary constraints p 0 = p, p 1 = q.</p><p>(5.7)</p><p>For instance, these constraints can be implemented by requiring the conditional path p t|1 (x|x 1 ) to satisfy p 0|1 (x|x 1 ) = π 0|1 (x|x 1 ), and p 1|1 (x|x 1 ) = δ x1 (x), (5.8)</p><p>where π 0|1 is the conditional coupling, π 0|1 (x 0 |x 1 ) = π 0,1 (x 0 , x 1 )/q(x 1 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">The Marginalization Trick for manifolds</head><p>The Marginalization Trick for the marginal velocity field (theorem 3) readily applies to the Riemannian case. Consider the conditional velocity field u t (x|x 1 ) ∈ U such that</p><p>(5.9)</p><p>Then, the marginal velocity field u t (x) is given by the following averaging of the conditional velocities,</p><p>(5.10)  </p><p>Diffusion coefficient:</p><p>X t+h ∼ Qt(dy,x) Qt(dy,x) with prob. h Q t (dy, x)</p><p>Continuity Equation:</p><p>Fokker-Planck Equation:</p><p>Jump Continuity Equation:</p><p>Mass preservation:</p><p>-u t (y; X|Z) log u θ t (y; X))</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4">Universal representation theorem</head><p>Generators allow us to characterize the space of possible Markov processes. Specifically, the following result allows us to not only characterize a wide class of CTMP generative models but to characterize the design space exhaustively for S = R d or S discrete.</p><p>Theorem 18 (Universal characterization of generators). Under weak regularity assumptions, the generators of a Feller processes X t (0 ≤ t ≤ 1) take the form:</p><p>The generator is given by a rate transition matrix u t and the Markov process corresponds to a continuous-time Markov chain (CTMC). 2. Euclidean space S = R d : The generator has a representation as a sum of components described in <ref type="table">table 2,</ref>  i.e.,</p><p>where u :</p><p>denotes the positive semi-definite matrices), and Q t (dy; x) a jump measure; ∇ 2 f (x) describes the Hessian of f and ∇ 2 f (x) • σ 2 t (x) describes the Frobenius inner product. The proof adapts a known result in the mathematical literature <ref type="bibr">(Courrege, 1965;</ref><ref type="bibr" target="#b83">von Waldenfels, 1965)</ref> and can be found in <ref type="bibr" target="#b33">(Holderrieth et al., 2024)</ref>.</p><p>Example -Training a diffusion coefficient. We illustrate how theorem 20 allows us to train a diffusion coefficient of an SDE. Let S = R d and σ 2 t (x|z) be a diffusion coefficient generating the conditional probability path p t|Z (dx|z). We can parameterize the diffusion coefficient in a neural network (σ 2 t ) θ (x) ∈ R d×d . The Conditional Generator Matching loss then becomes</p><p>where we used the mean squared error as a Bregman divergence (many other options are possible). In <ref type="bibr" target="#b33">(Holderrieth et al., 2024)</ref>, examples are shown of models trained in this manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.6">Finding conditional generators as solutions to the KFE</head><p>To enable scalable training with the Conditional Generator Matching loss (see theorem 20), we need to be able to find a conditional generator L z t that solves the KFE</p><p>If p t|Z (dx|z) admits a density p t|Z (x|z) with respect to ν. In this case, we can equivalently solve the adjoint KFE</p><p>In general, equation (9.20) and equation (9.21) are challenging equations to solve analytically and there is no general formula to solve it for arbitrary generators. Therefore, we give 2 examples on how this can be done as illustration.</p><p>We illustrate it with jump models here, as these work for arbitrary state spaces. As explained in section 8.2.2, they are specified by a jump measure Q t that can be decomposed into Q t (dy, x) = λ t (x)J t (dy, x) for all x ∈ S (9.22) λ t (x) ≥ 0 for all x ∈ S (9.23) J t (dy, x) = 1 for all x ∈ S (9.24) where λ t (x) describes the jump intensity and J t describes a probability kernel specifying the jump distribution. Note that we drop the dependency on z ∈ Z to simplify notation (we keep it for p t|Z (dx|z) to avoid confusion with the marginal probability path).</p><p>Jump models for convex mixtures. Let us consider the mixture probability path given by (see equation (7.22)):</p><p>Using the form of the generator for jump processes (see equation (8.36)), the KFE becomes:</p><p>for λ t , J t satisfying the constraints in equation (9.23) and equation (9.24). We make the claim that this is satisfied for a jump model with</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.8">Multimodal models</head><p>We finally comment on how GM enables the construction of generative models over multiple data modalities jointly. For example, this could be a model that generates images and corresponding text descriptions at the same time. Two modalities are represented as two state spaces S 1 , S 2 (e.g., S 1 are images and S 2 is text) and a multimodal model would be a generative model over the product space S = S 1 × S 2 . As S is just another state space and GM works for arbitrary state spaces, we could simply go about it like constructing any other GM model. However, there is a specific construction of probability paths that allows us to reuse or "recycle" GM models built for individual modalities. For example, we could build a joint text-image model by combining a discrete and continuous FM model. This specific construction relies on factorized conditional probability paths. We have seen a simple case of this already in section 7.5.2 for discrete FM where factorized probability paths lead to factorized velocities. This holds more generally for arbitrary modalities. While the construction is rather simple and intuitive, it is rather technical to express in full generality. We refer to <ref type="bibr" target="#b33">(Holderrieth et al., 2024)</ref> for a rigorous treatment. A specific instantiation of this was also realized in <ref type="bibr" target="#b11">(Campbell et al., 2024)</ref> for multimodal protein generation. This highlights that GM enables the construction of multimodal models in a principled and rigorous manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Relation to Diffusion and other Denoising Models</head><p>In this section, we finally discuss the relation to denoising diffusion models (DDMs) and related models on non-Euclidean spaces. We mainly focus here on the construction of diffusion models by <ref type="bibr">(Song et al., 2021)</ref> via SDEs and explain how it can be placed with the FM/GM family of models. At the end of the section, we also discuss models in other modalities that took inspiration from DDMs ("denoising models") and how they can be framed as a GM model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.1">Time convention</head><p>The first simple difference between denoising diffusion models and flow matching is a difference how time is parameterized. This is just a convention but is important to avoid confusion. Different to FM, time is inverted in diffusion models and ranges from 0 to ∞. To differentiate the two time parameterizations, let us use r for the time convention of diffusion models and t for the time convention of FM. Then we have:</p><p>FM time t: Noise ≡ "t = 0", Data ≡ "t = 1" (10.1)</p><p>Diffusion time r: Noise ≡ "r = +∞", Data ≡ "r = 0" (10.2)</p><p>where k : (0, 1] → [0, +∞) is some strictly monotonically decreasing mapping with k(1) = 0 and lim t→0 k(t) = +∞.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.2">Forward process vs. probability paths</head><p>The underlying idea of denoising diffusion models is to construct a forward process that corrupts the data distribution. We will explain how this corresponds to a specific construction of a probability path as used in FM. The forward process X r is defined via the SDE dX r = a r (X r )dr + g r dW r , X 0 ∼ q (10.4)</p><p>where q is the data distribution, W r is a Brownian motion and a : R × R d → R d a velocity field, also called drift in the context of SDEs, and g : R → R ≥0 a diffusion coefficient (see section 8.2.2). Every such SDE defines a conditional probability path and marginal probability path as</p><p>where in the second line we reparameterized time into the FM time parameterization. We see that p t|1 (x|z) gives a conditional probability path. Further, the forward process is constructed such that for R ≫ 0, the distribution of X R is approximately a Gaussian. Therefore, we get that:</p><p>Every forward process in diffusion defines a "valid" conditional probability path as used in FM, i.e., the corresponding marginal path interpolates between a data distribution q and (roughly) a Gaussian p. Specifically:</p><p>(1) Deterministic initialization: The conditional probability path p t|1 (x|z) corresponds to the distribution of the forward process SDE when initialized with X 0 = z.</p><p>(2) Data initialization: The marginal probability path p t (x) corresponds to the distribution of the forward process when initialized with X 0 ∼ q where q is the data distribution.</p><p>An important requirement of diffusion models is that one can compute the conditional probability pr|0 (x|z) in closed form. This enforces working with SDEs that have analytic solution to their respective KFE (i.e., Fokker-Planck equation). Throughout most of the literature, the forward process is therefore assumed to have affine drift coefficients i.e., a r (x) = a r x for some continuous function a : R → R (Song et al., 2021; Karras</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.5">The role of time-reversal and the backward process</head><p>To finish our discussion of diffusion models, we discuss the role of time-reversal and the backward process in the context of diffusion models. Given how central the idea of time-reversal is for diffusion models, it might seem surprising to some readers that it is not needed for FM. We explain this, therefore, here in more detail. Specifically, to generate data, diffusion models frame training as learning a backward process Xr going from 0 to R &gt; 0 such that Xr d =X R-r for all r ∈ [0, R] (10.17) where d = denotes equality in distribution. Once we found such a process, we can initialize X0 d = X R with a Gaussian and simulate it to obtain XR d = X 0 ∼ q, i.e., a sample the data distribution q. If X r ∼ pr (i.e., it is the marginal probability path as in equation (10.5)), then equation ( <ref type="formula">10</ref>.17) is equivalent to:</p><p>In other words, we want the stochastic process Xr to generate the probability path pr . But this is exactly what we are trying to do in Generator Matching for general Markov processes (see equation (8.10)), and in particular in Flow Matching with flows. Therefore, we get:</p><p>The following problems are equivalent:</p><p>(1) Time-reverse marginals: Finding an SDE (resp. ODE) for the backward process that has the same marginals as the forward process -as done for diffusion models.</p><p>(2) Generate probability path: Finding an SDE (resp. ODE) that generates the probability path defined by the forward process.</p><p>(3) Solve KFE: Finding an SDE (resp. ODE) that solves the Fokker-Planck Equation (resp. Continuity Equation).</p><p>The original description of diffusion models included the "full" time-reversal of an SDE <ref type="bibr" target="#b3">(Anderson, 1982)</ref>. This is a notion that is stronger than the one we use, i.e., it requires that the joint distribution across time points are the same</p><p>(10.18) for all 0 ≤ r 1 , . . . , r n , and A 1 , . . . , A n ⊂ S measurable. (10.19)</p><p>As shown in <ref type="bibr" target="#b3">Anderson (1982)</ref>, one can obtain a time-reversal satisfying the above condition with a backward process for a specific choice of β t in equation (10.15) . However, for the purposes of generative modeling, we often only use the final point X 1 of the Markov process (e.g., as a generated image) and discard earlier time points. Therefore, whether a Markov process is a "true" time-reversal or only has the same marginals (as in equation (10.17)) does not matter for many applications. A famous example is the probability flow ODE. The probability flow ODE does not constitute a time-reversal of a diffusion process in the sense of <ref type="bibr" target="#b3">(Anderson, 1982)</ref> but it follows the same marginals. This illustrates that finding "true" time-reversals is a harder mathematical problem to solve but (often) not necessary for the purposes of generative modeling.</p><p>The probability flow ODE is the current state-of-the-art for sampling with a low number of neural network evaluations <ref type="bibr" target="#b40">(Karras et al., 2022)</ref>. This shows that the "true" time-reversal might even give suboptimal results compared to other solutions of the Fokker-Planck equation <ref type="bibr" target="#b50">(Ma et al., 2024)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.6">Relation to Other Denoising Model</head><p>Inspired by the success of diffusion models, there were significant advances in translating the methods from diffusion models to other state spaces <ref type="bibr" target="#b10">(Campbell et al., 2022</ref><ref type="bibr" target="#b11">(Campbell et al., , 2024;;</ref><ref type="bibr">De Bortoli et al., 2022;</ref><ref type="bibr">Huang et al., 2022a;</ref><ref type="bibr" target="#b5">Benton et al., 2022)</ref>. Similarly to diffusion models, they construct a forward Markov process that noises data and then time-reverse it (i.e., "de-noises" it). We therefore informally refer to such models as "denoising models". Naturally, one can ask how these models relate to GM (see section 9). In brief, the relation of these "denoising models" to GM models is the same as the relation between diffusion models and FM:</p><p>Generally speaking, denoising models are Generator Matching models with (1) Time convention: They use the diffusion time convention where time 0 corresponds to data.</p><p>(2) Probability path construction: Probability paths are constructed via a "forward" or "noising" process.</p><p>(3) Solving the KFE: A particular solution to the KFE is found via a time-reversal of the forward process.</p><p>We acknowledge that this an informal rule and that there might be exceptions to that rule. Therefore, we refer to an extended and detailed discussion of such related work (including a more complete list of references) to <ref type="bibr" target="#b33">(Holderrieth et al., 2024)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A Additional proofs A.1 Discrete Mass Conservation</head><p>Lemma 1 (PMF solutions to Kolmogoroc with rate conditions). Consider a solution f t (x) to Kolmogorov Equation (6.8) with initial condition f 0 (x) = p(x), where p is a PMF, u t (y, x) is C([0, 1]) in time t and satisfies the rate conditions (6.4). Then f t (x) is a probability mass function (PMF) for all t ∈ [0, 1].</p><p>Proof. Let f t (x), t ∈ [0, 1], be the solution to the Kolmogorov Equation, the existence and uniqueness of which is guarateed by theorem 12. Now, f t (x) is a PMF if and only if it satisfies f t (x) ≥ 0, and</p><p>The latter condition is shown to hold by summing both sides of the Kolmogorov Equation to get that the solution satisfies</p><p>where the second equality is due to y u t (y, x) = 0 in the rate conditions. Since x f 0 (x) = x p(x) = 1 we hae that x f t (x) ≡ 1 for all t ∈ [0, 1].</p><p>To prove that f t (x) ≥ 0 for all x ∈ S we will use a result on convex invariant sets of dynamical systems. In particular, Theorem 7. <ref type="bibr">3.4 in Prüss et al. (2010)</ref> asserts that as long as f 0 = p satisfies this condition (which it does) and whenever w(z) is on the boundary of this constraint, i.e., w is a PMF and w(z) = 0 for some z ∈ S, then a non-positive inner-product with the outer-normal to the constraint, i.e., x,y u t (y, x)w(x)δ(y, z) ≥ 0 implies that the solution f t (x) ≥ 0 for all t ∈ [0, 1] and x ∈ S. Let us check this condition:</p><p>x,y u t (y, x)w(x)δ(y, z) =</p><p>where in the second equality we use the fact that w(z) = 0 and in the last inequality we used the rate condition (6.4) that u t (z, x) ≥ 0 for z ̸ = x and w(y) ≥ 0 for all y.</p><p>Theorem 13 (Discrete Mass Conservation). Let u t (y, x) be in C([0, 1)) and p t (x) a PMF in C 1 ([0, 1)) in time t. Then, the following are equivalent:</p><p>1. p t , u t satisfy the Kolmogorov Equation (6.8) for t ∈ [0, 1), and u t satisfies the rate conditions (6.4).</p><p>2. u t generates p t in the sense of 6.5 for t ∈ [0, 1).</p><p>Proof. Let us start by assuming 2. In this case, the probability transition kernel p t+h|t (y|x) satisfies (6. where now o(1) = o(h)/h → 0 as h → 0, as per the definition of o(h). Taking the limit h → 0, we get that the pair (p t , u t ) satisfies the Kolmogorov Equation (6.8). Next, let us prove that u t satisfies the rate conditions (6.4). If u t (y, x) &lt; 0 for some y ̸ = x, it follows from (A.2) that p t+h|t (y|x) &lt; 0 for small h &gt; 0, and this contradicts p t+h|t being a probability kernel. If y u t (y, x) = c ̸ = 0, it follows from A.2 that 1 = x p t+h|t (y|x) = 1 + hc + o(h), leading to a contradiction for small h &gt; 0.</p><p>Conversely, assume now condition 1. That is, the pair (u t , p t ) satisfies the Kolmogorov Equation ( <ref type="formula">6</ref> = -div g [u t (x)p t (x)] , (A.9)</p><p>where in (i) we switched differentiation ( d dt and div g ) and integration justified by Leibniz rule, and the fact that p t|1 (x|x 1 ) and u t (x|x 1 ) are C 1 in t, x and q has bounded support or M is compact. In (ii), we used the fact that u t (•|x 1 ) generates p t|1 (•|x 1 ) and theorem 9. In (iii), we multiplied and divided by p t (x) (which is strictly positive by assumption) and used the formula for u t in (5.10). Lastly, u t is integrable and locally Lipschitz by employing the same arguments as in the proof of theorem 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Regularity assumptions for KFE</head><p>We note that assumption 5 is true under relatively weak assumptions and there is a diversity of mathematical literature on showing uniqueness of the solution of the KFE in p t for different settings. However, to the best of our knowledge, there is no known result that states regularity assumptions for general state spaces and Markov processes, which is why simply state it here as an assumption. For the machine learning practitioner, this assumption holds for any state space of interest. To illustrate this, we point the rich sources in the mathematical literature that show uniqueness that list the regularity assumptions for specific spaces and classes of Markov processes:</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Albergo</surname></persName>
		</author>
		<author>
			<persName><surname>Vanden-Eijnden</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.15571</idno>
		<title level="m">Building normalizing flows with stochastic interpolants</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Stochastic interpolants with data-dependent couplings</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Samuel Albergo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><forename type="middle">Matthew</forename><surname>Boffi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajesh</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Vanden-Eijnden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st International Conference on Machine Learning, ICML&apos;24</title>
		<meeting>the 41st International Conference on Machine Learning, ICML&apos;24</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Transport equation and cauchy problem forbvvector fields</title>
		<author>
			<persName><forename type="first">Luigi</forename><surname>Ambrosio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inventiones mathematicae</title>
		<imprint>
			<biblScope unit="volume">158</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Reverse-time diffusion equation models</title>
		<author>
			<persName><forename type="first">Brian Do</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Stochastic Processes and their Applications</title>
		<imprint>
			<date type="published" when="1982">1982</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="313" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Matching normalizing flows and probability paths on manifolds</title>
		<author>
			<persName><forename type="first">Heli</forename><surname>Ben-Hamu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joey</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Amos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maximillian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricky</forename><forename type="middle">T Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaron</forename><surname>Lipman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International Conference on Machine Learning</title>
		<meeting>the 39th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">162</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">Joe</forename><surname>Benton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuyang</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valentin</forename><forename type="middle">De</forename><surname>Bortoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Deligiannidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Doucet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.03595</idno>
		<title level="m">From denoising diffusions to denoising markov models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danny</forename><surname>Driess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adnan</forename><surname>Esmail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Equi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niccolo</forename><surname>Fusai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lachy</forename><surname>Groom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karol</forename><surname>Hausman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Ichter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Szymon</forename><surname>Jakubczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liyiming</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Li-Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohith</forename><surname>Mothukuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suraj</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><surname>Pertsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucy</forename><forename type="middle">Xiaoyang</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Tanner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quan</forename><surname>Vuong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Walling</surname></persName>
		</author>
		<ptr target="https://www.physicalintelligence.company/download/pi0.pdf" />
		<title level="m">Haohuan Wang, and Ury Zhilinsky. π0: Vision-language-action flow model for general robot control. arXiv</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName><surname>Vladimir I Bogachev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Nicolai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Krylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stanislav</forename><forename type="middle">V</forename><surname>Röckner</surname></persName>
		</author>
		<author>
			<persName><surname>Shaposhnikov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>American Mathematical Society</publisher>
			<biblScope unit="volume">207</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Fokker-Planck-Kolmogorov Equations</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Se(3)-stochastic flow matching for protein backbone generation</title>
		<author>
			<persName><forename type="first">Joey</forename><surname>Avishek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tara</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Akhound-Sadegh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><surname>Huguet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jarrid</forename><surname>Fatras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng-Hao</forename><surname>Rector-Brooks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrei</forename><forename type="middle">Cristian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maksym</forename><surname>Nica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Korablyov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName><surname>Tong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.02391</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Arwen</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preetum</forename><surname>Nakkiran</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2408.09000</idno>
		<title level="m">Classifier-free guidance is a predictor-corrector</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A continuous time framework for discrete denoising models</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Benton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valentin</forename><forename type="middle">De</forename><surname>Bortoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Rainforth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Deligiannidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Doucet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="28266" to="28279" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Generative flows on discrete state-spaces: Enabling multimodal flows with applications to protein co-design</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Rainforth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.04997</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Flow matching on general geometries</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Q</forename><surname>Ricky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaron</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Lipman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Twelfth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Neural ordinary differential equations</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Q</forename><surname>Ricky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulia</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Rubanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">K</forename><surname>Bettencourt</surname></persName>
		</author>
		<author>
			<persName><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="page">31</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">What does guidance do? a fine-grained analysis in a simple setting</title>
		<author>
			<persName><forename type="first">Muthu</forename><surname>Chidambaram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khashayar</forename><surname>Gatmiry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sitan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holden</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2409.13074</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Sur la forme intégro-différentielle des opérateurs de c</title>
		<author>
			<persName><forename type="first">Norman</forename><surname>Earl A Coddington</surname></persName>
		</author>
		<author>
			<persName><surname>Levinson</surname></persName>
		</author>
		<author>
			<persName><surname>Teichmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philippe Courrege</title>
		<imprint>
			<date type="published" when="1956">1956</date>
		</imprint>
	</monogr>
	<note>Theory of ordinary differential equations satisfaisant au principe du maximum</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Séminaire</forename><surname>Brelot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-Choquet-Deny</forename></persName>
		</author>
		<title level="m">Théorie du Potentiel</title>
		<imprint>
			<date type="published" when="1965">1965</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Piecewise-deterministic markov processes: A general class of non-diffusion stochastic models</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="353" to="376" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis</title>
		<author>
			<persName><forename type="first">Emile</forename><surname>Valentin De Bortoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Thornton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName><surname>Doucet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2021">2022. 2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="8780" to="8794" />
		</imprint>
	</monogr>
	<note>Riemannian score-based generative modelling Advances in Neural Information Processing Systems</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Guidance: a cheat code for diffusion models</title>
		<author>
			<persName><forename type="first">Sander</forename><surname>Dieleman</surname></persName>
		</author>
		<ptr target="https://benanne.github.io/2022/05/26/guidance.html" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Ordinary differential equations, transport theory and sobolev spaces</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre-Louis</forename><surname>Diperna</surname></persName>
		</author>
		<author>
			<persName><surname>Lions</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inventiones mathematicae</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="511" to="547" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Scaling rectified flow transformers for high-resolution image synthesis</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumith</forename><surname>Kulal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Blattmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahim</forename><surname>Entezari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harry</forename><surname>Saini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yam</forename><surname>Levi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Lorenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Axel</forename><surname>Sauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederic</forename><surname>Boesel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Forty-first International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Markov processes: characterization and convergence</title>
		<author>
			<persName><forename type="first">N</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">G</forename><surname>Ethier</surname></persName>
		</author>
		<author>
			<persName><surname>Kurtz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On second order differential operators</title>
		<author>
			<persName><forename type="first">William</forename><surname>Feller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Mathematics</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="90" to="105" />
			<date type="published" when="1955">1955</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Existence and uniqueness of martingale solutions for sdes with rough or degenerate coefficients</title>
		<author>
			<persName><forename type="first">Alessio</forename><surname>Figalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Functional Analysis</title>
		<imprint>
			<biblScope unit="volume">254</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="109" to="153" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">Itai</forename><surname>Gat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Remez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neta</forename><surname>Shaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Kreuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricky</forename><forename type="middle">T Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yossi</forename><surname>Adi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaron</forename><surname>Lipman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2407.15595</idno>
		<title level="m">Discrete flow matching</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Calculus of variations</title>
		<author>
			<persName><forename type="first">Izrail</forename><surname>Moiseevitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gelfand</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">A</forename><surname>Silverman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
		<respStmt>
			<orgName>Courier Corporation</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Will</forename><surname>Grathwohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricky</forename><forename type="middle">T Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Bettencourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.01367</idno>
		<title level="m">Ffjord: Free-form continuous dynamics for scalable reversible generative models</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Gradient guidance for diffusion models: An optimization perspective</title>
		<author>
			<persName><forename type="first">Yingqing</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yukang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minshuo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengdi</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2404.14743</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Monte carlo sampling methods using markov chains and their applications</title>
		<author>
			<persName><forename type="first">Hastings</forename><surname>Keith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Iterative α-(de) blending: A minimalist deterministic diffusion model</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Heitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Belcour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Chambon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH 2023 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Classifier-free diffusion guidance</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ajay</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6840" to="6851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Generator matching: Generative modeling with arbitrary markov processes</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Holderrieth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marton</forename><surname>Havasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neta</forename><surname>Shaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Itai</forename><surname>Gat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Karrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricky</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaron</forename><surname>Lipman</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2410.20587" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Riemannian diffusion models</title>
		<author>
			<persName><forename type="first">Chin-Wei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milad</forename><surname>Aghajohari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joey</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prakash</forename><surname>Panangaden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2750" to="2761" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Riemannian diffusion models</title>
		<author>
			<persName><forename type="first">Chin-Wei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milad</forename><surname>Aghajohari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joey</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prakash</forename><surname>Panangaden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Sequence-augmented se (3)-flow matching for conditional protein backbone generation</title>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Huguet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Vuckovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><surname>Fatras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Thibodeau-Laufer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pablo</forename><surname>Lemos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Riashat</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng-Hao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jarrid</forename><surname>Rector-Brooks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tara</forename><surname>Akhound-Sadegh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Bronstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.20313</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">A first course in the numerical analysis of differential equations</title>
		<author>
			<persName><forename type="first">Arieh</forename><surname>Iserles</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Riemannian geometry and geometric analysis</title>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Jost</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">42005</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Highly accurate protein structure prediction with alphafold</title>
		<author>
			<persName><forename type="first">John</forename><surname>Jumper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Figurnov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathryn</forename><surname>Tunyasuvunakool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russ</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Augustin</forename><surname>Žídek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Potapenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">596</biblScope>
			<biblScope unit="issue">7873</biblScope>
			<biblScope unit="page" from="583" to="589" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Elucidating the design space of diffusion-based generative models</title>
		<author>
			<persName><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miika</forename><surname>Aittala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="26565" to="26577" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Variational diffusion models</title>
		<author>
			<persName><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="21696" to="21707" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><surname>Kurtz</surname></persName>
		</author>
		<title level="m">Equivalence of stochastic equations and martingale problems. Stochastic analysis 2010</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="113" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Voicebox: Text-guided multilingual universal speech generation at scale. Advances in neural information processing systems</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Apoorv</forename><surname>Vyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Karrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leda</forename><surname>Sari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rashel</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mary</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vimal</forename><surname>Manohar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yossi</forename><surname>Adi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Mahadeokar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">36</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">Yaron</forename><surname>Lipman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricky</forename><forename type="middle">T Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heli</forename><surname>Ben-Hamu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.02747</idno>
		<title level="m">Maximilian Nickel, and Matt Le. Flow matching for generative modeling</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">I2sb: image-to-image schrödinger bridge</title>
		<author>
			<persName><forename type="first">Guan-Horng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arash</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De-An</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evangelos</forename><forename type="middle">A</forename><surname>Theodorou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weili</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anima</forename><surname>Anandkumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International Conference on Machine Learning, ICML&apos;23. JMLR.org</title>
		<meeting>the 40th International Conference on Machine Learning, ICML&apos;23. JMLR.org</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Flow straight and fast: Learning to generate and transfer data with rectified flow</title>
		<author>
			<persName><forename type="first">Xingchao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengyue</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.03003</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Advanced calculus</title>
		<author>
			<persName><forename type="first">Lynn</forename><surname>Harold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loomis</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Shlomo</forename><surname>Sternberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1968">1968</date>
			<publisher>World Scientific</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Neural manifold ordinary differential equations</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isay</forename><surname>Katsman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leo</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingxuan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ser-Nam</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">De</forename><surname>Sa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Neural Information Processing Systems</title>
		<meeting>the 34th International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Scaling riemannian diffusion models</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minkai</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Farris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="80291" to="80305" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Sit: Exploring flow and diffusion-based generative models with scalable interpolant transformers</title>
		<author>
			<persName><forename type="first">Nanye</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><forename type="middle">M</forename><surname>Michael S Albergo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Boffi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saining</forename><surname>Vanden-Eijnden</surname></persName>
		</author>
		<author>
			<persName><surname>Xie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.08740</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Riemannian continuous normalizing flows</title>
		<author>
			<persName><forename type="first">Emile</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">C</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><surname>Matthews</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
	<note>Vector calculus</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A convexity principle for interacting gases</title>
		<author>
			<persName><forename type="first">J</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><surname>Mccann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in mathematics</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="153" to="179" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Action matching: Learning stochastic dynamics from samples</title>
		<author>
			<persName><forename type="first">Kirill</forename><surname>Neklyudov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Brekelmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Severo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alireza</forename><surname>Makhzani</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="25858" to="25889" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Improved denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Quinn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nichol</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">Marina</forename><surname>Meila</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</editor>
		<meeting>the 38th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2021-07">Jul 2021</date>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="18" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">GLIDE: Towards photorealistic image generation and editing with text-guided diffusion models</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Quinn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nichol</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bob</forename><surname>Mcgrew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International Conference on Machine Learning</title>
		<meeting>the 39th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2022-07">Jul 2022</date>
			<biblScope unit="volume">162</biblScope>
			<biblScope unit="page" from="17" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName><forename type="first">Bernt</forename><surname>Øksendal</surname></persName>
		</author>
		<title level="m">Stochastic differential equations</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Semigroups of linear operators and applications to partial differential equations</title>
		<author>
			<persName><forename type="first">Amnon</forename><surname>Pazy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">44</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Peluchetti</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.14589</idno>
		<title level="m">Non-denoising forward-time diffusions</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Differential equations and dynamical systems</title>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Perko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Computational optimal transport: With applications to data science</title>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Peyré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Cuturi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends® in Machine Learning</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="355" to="607" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">Ashwini</forename><surname>Pokle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">J</forename><surname>Muckley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricky</forename><forename type="middle">T Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Karrer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.04432</idno>
		<title level="m">Training-free linear image inversion via flows</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Adam</forename><surname>Polyak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amit</forename><surname>Zohar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andros</forename><surname>Tjandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Animesh</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ann</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Apoorv</forename><surname>Vyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chih-Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ching-Yao</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhruv</forename><surname>Choudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dingkang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geet</forename><surname>Sethi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guan</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoyu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jialiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kiran</forename><surname>Jagadeesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunpeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luxin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mannat</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mary</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitesh</forename><forename type="middle">Kumar</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Vajda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Duval</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rohit</forename><surname>Girdhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roshan</forename><surname>Sumbaly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sai</forename><surname>Saketh Rambhatla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samaneh</forename><surname>Azadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samyak</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanyuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharadh</forename><surname>Ramaswamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shelly</forename><surname>Sheynin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simran</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tingbo</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Ning</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaniv</forename><surname>Taigman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaqiao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yen-Cheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi-Chiao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuval</forename><surname>Kirstain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zecheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zijian</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Pumarola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Thabet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artsiom</forename><surname>Sanakoyeu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arun</forename><surname>Mallya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baishan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Araya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Breena</forename><surname>Kerr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carleigh</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ce</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cen</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitry</forename><surname>Vengertsev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edgar</forename><surname>Schonfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elliot</forename><surname>Blanchard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Juefei-Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fraylie</forename><surname>Nord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Kohler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaolin</forename><surname>Fire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Sivakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Licheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luya</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markos</forename><surname>Georgopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rashel</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><forename type="middle">K</forename><surname>Sampson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shikai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simone</forename><surname>Parmeggiani</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2410.13720" />
		<imprint>
			<date type="published" when="2024">2024</date>
			<publisher>Vladan Petrovic</publisher>
			<pubPlace>Steve Fine, Tara Fowler</pubPlace>
		</imprint>
	</monogr>
	<note>and Yuming Du. Movie gen: A cast of media foundation models</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Multisample flow matching: Straightening flows with minibatch couplings</title>
		<author>
			<persName><forename type="first">Aram-Alexandre</forename><surname>Pooladian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heli</forename><surname>Ben-Hamu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carles</forename><surname>Domingo-Enrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Amos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaron</forename><surname>Lipman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricky</forename><forename type="middle">T Q</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Ordinary differential equations and dynamic systems</title>
		<author>
			<persName><forename type="first">Jan</forename><surname>Prüss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathias</forename><surname>Wilke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathias</forename><surname>Wilke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Exponential convergence of langevin distributions and their discrete approximations</title>
		<author>
			<persName><forename type="first">O</forename><surname>Gareth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">L</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><surname>Tweedie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bernoulli</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="341" to="363" />
			<date type="published" when="1996-12">December 1996. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><surname>Williams</surname></persName>
		</author>
		<title level="m">Diffusions, markov processes, and martingales</title>
		<imprint>
			<publisher>Cambridge university press</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Moser flow: Divergence-based generative modeling on manifolds</title>
		<author>
			<persName><forename type="first">Noam</forename><surname>Rozen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaron</forename><surname>Lipman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="17669" to="17680" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Comparison of time-inhomogeneous markov processes</title>
		<author>
			<persName><forename type="first">Ludger</forename><surname>Rüschendorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Schnurr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viktor</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Applied Probability</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1015" to="1044" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Palette: Image-to-image diffusion models</title>
		<author>
			<persName><forename type="first">Chitwan</forename><surname>Saharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huiwen</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH 2022 Conference Proceedings, SIGGRAPH &apos;22</title>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Progressive distillation for fast sampling of diffusion models</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.00512</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Applied stochastic differential equations</title>
		<author>
			<persName><forename type="first">Simo</forename><surname>Särkkä</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arno</forename><surname>Solin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="volume">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">On kinetic optimal probability paths for generative models</title>
		<author>
			<persName><forename type="first">Neta</forename><surname>Shaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricky</forename><forename type="middle">T Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaron</forename><surname>Lipman</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="30883" to="30907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<author>
			<persName><forename type="first">Neta</forename><surname>Shaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricky</forename><forename type="middle">T Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Thabet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Pumarola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaron</forename><surname>Lipman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.19075</idno>
		<title level="m">Bespoke solvers for generative flow models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Flow matching with general discrete paths: A kinetic-optimal perspective</title>
		<author>
			<persName><forename type="first">Neta</forename><surname>Shaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Itai</forename><surname>Gat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marton</forename><surname>Havasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Severo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anuroop</forename><surname>Sriram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Holderrieth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Karrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaron</forename><surname>Lipman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricky</forename><forename type="middle">T Q</forename><surname>Chen</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2412.03487" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Diffusion schrödinger bridge matching</title>
		<author>
			<persName><forename type="first">Yuyang</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valentin</forename><forename type="middle">De</forename><surname>Bortoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Doucet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-seventh Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Deep unsupervised learning using nonequilibrium thermodynamics</title>
		<author>
			<persName><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niru</forename><surname>Maheswaranathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Surya</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2256" to="2265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Generative modeling by estimating gradients of the data distribution</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="11895" to="11907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Scorebased generative modeling through stochastic differential equations</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Improving and generalizing flow-based generative models with minibatch optimal transport</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolay</forename><surname>Malkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Huguet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanlei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jarrid</forename><surname>Rector-Brooks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><surname>Fatras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.00482</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Cédric Villani et al. Optimal transport: old and new</title>
		<author>
			<persName><forename type="first">Cédric</forename><surname>Villani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Mathematical Soc</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<date type="published" when="2009">2021. 2009</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>Topics in optimal transportation</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">A connection between score matching and denoising autoencoders</title>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1661" to="1674" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<author>
			<persName><forename type="first">Waldenfels</forename><surname>Wilhelm Von</surname></persName>
		</author>
		<title level="m">Fast positive operatoren. Zeitschrift für Wahrscheinlichkeitstheorie und Verwandte Gebiete</title>
		<imprint>
			<date type="published" when="1965">1965</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="159" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Audiobox: Unified audio generation with natural language prompts</title>
		<author>
			<persName><forename type="first">Apoorv</forename><surname>Vyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andros</forename><surname>Tjandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi-Chiao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baishan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiemin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Adkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Ngan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.15821</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">Fast protein backbone generation with se (3) flow matching</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew Yk</forename><surname>Foong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Gastegger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">José</forename><surname>Jiménez-Luna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Garcia Satorras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bastiaan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Regina</forename><surname>Veeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tommi</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><surname>Jaakkola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.05297</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">Guided flows for generative modeling and decision making</title>
		<author>
			<persName><forename type="first">Qinqing</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neta</forename><surname>Shaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaron</forename><surname>Lipman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricky</forename><forename type="middle">T Q</forename><surname>Chen</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2311.13443" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Mass conservation formula</title>
		<author>
			<persName><surname>Villani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Flows in R d and manifolds</title>
		<imprint>
			<publisher>DiPerna and Lions</publisher>
			<date type="published" when="1989">2009. 1989. Ambrosio, 2004</date>
			<biblScope unit="volume">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Diffusion theorem</title>
		<author>
			<persName><surname>Villani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Diffusion in R d and manifolds</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<author>
			<persName><surname>Bogachev</surname></persName>
		</author>
		<title level="m">General Ito-SDEs in R d : (Figalli, 2008, Theorem 1.3 and 1.4)</title>
		<imprint>
			<date type="published" when="2011">(Kurtz, 2011, Corollary 1.3. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main">Discrete state spaces: Here, the KFE is a linear ODE</title>
		<imprint/>
	</monogr>
	<note>which has a unique solution under the assumption that the coefficients are continuous (see theorem 13</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
