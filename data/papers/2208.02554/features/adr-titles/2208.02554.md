- Decision to use vocabulary transfer for enhancing model performance in biomedical NLP
- Choice of Transformer architecture as the underlying model
- Selection of datasets for experimentation (OHSUMED and Kaggle Medical Texts Dataset)
- Implementation of a new tokenization strategy during fine-tuning
- Adoption of intermediary masked language modeling (MLM) step
- Heuristic token-matching procedure for transferring embeddings
- Use of matched vocabulary transfer and averaged transfer methods
- Decision to evaluate the impact of vocabulary size on classifier accuracy
- Consideration of inference time as a critical factor in the medical domain
- Strategy for splitting the downstream dataset into training, validation, and test sets
- Approach to measuring and reporting changes in model performance
- Decision to limit experiments to text classification tasks
- Acknowledgment of potential limitations and generalizability of findings
- Compliance with ethical standards in research and data handling