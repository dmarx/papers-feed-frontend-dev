<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Complementarity, Augmentation, or Substitutivity? The Impact of Generative Artificial Intelligence on the U.S. Federal Workforce</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">William</forename><forename type="middle">G</forename><surname>Resh</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Civic Leadership Education and Research (CLEAR) Initiative Sol Price School of Public Policy</orgName>
								<orgName type="department" key="dep2">Sol Price School of Public Policy</orgName>
								<orgName type="department" key="dep3">Viterbi School of Engineering</orgName>
								<orgName type="department" key="dep4">Sol Price School of Public Policy</orgName>
								<orgName type="institution" key="instit1">University of Southern</orgName>
								<orgName type="institution" key="instit2">California University of Southern California</orgName>
								<orgName type="institution" key="instit3">University of Southern California</orgName>
								<orgName type="institution" key="instit4">University of Idaho University of California</orgName>
								<orgName type="institution" key="instit5">Santa Barbara University of Southern California</orgName>
								<orgName type="institution" key="instit6">RAND Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yi</forename><forename type="middle">Ming</forename><surname>Xinyao Xia</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Civic Leadership Education and Research (CLEAR) Initiative Sol Price School of Public Policy</orgName>
								<orgName type="department" key="dep2">Sol Price School of Public Policy</orgName>
								<orgName type="department" key="dep3">Viterbi School of Engineering</orgName>
								<orgName type="department" key="dep4">Sol Price School of Public Policy</orgName>
								<orgName type="institution" key="instit1">University of Southern</orgName>
								<orgName type="institution" key="instit2">California University of Southern California</orgName>
								<orgName type="institution" key="instit3">University of Southern California</orgName>
								<orgName type="institution" key="instit4">University of Idaho University of California</orgName>
								<orgName type="institution" key="instit5">Santa Barbara University of Southern California</orgName>
								<orgName type="institution" key="instit6">RAND Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Overton</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Civic Leadership Education and Research (CLEAR) Initiative Sol Price School of Public Policy</orgName>
								<orgName type="department" key="dep2">Sol Price School of Public Policy</orgName>
								<orgName type="department" key="dep3">Viterbi School of Engineering</orgName>
								<orgName type="department" key="dep4">Sol Price School of Public Policy</orgName>
								<orgName type="institution" key="instit1">University of Southern</orgName>
								<orgName type="institution" key="instit2">California University of Southern California</orgName>
								<orgName type="institution" key="instit3">University of Southern California</orgName>
								<orgName type="institution" key="instit4">University of Idaho University of California</orgName>
								<orgName type="institution" key="instit5">Santa Barbara University of Southern California</orgName>
								<orgName type="institution" key="instit6">RAND Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gul</forename><forename type="middle">Nisa</forename><surname>Gürbüz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Civic Leadership Education and Research (CLEAR) Initiative Sol Price School of Public Policy</orgName>
								<orgName type="department" key="dep2">Sol Price School of Public Policy</orgName>
								<orgName type="department" key="dep3">Viterbi School of Engineering</orgName>
								<orgName type="department" key="dep4">Sol Price School of Public Policy</orgName>
								<orgName type="institution" key="instit1">University of Southern</orgName>
								<orgName type="institution" key="instit2">California University of Southern California</orgName>
								<orgName type="institution" key="instit3">University of Southern California</orgName>
								<orgName type="institution" key="instit4">University of Idaho University of California</orgName>
								<orgName type="institution" key="instit5">Santa Barbara University of Southern California</orgName>
								<orgName type="institution" key="instit6">RAND Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Brandon</forename><surname>De Breuhl</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Civic Leadership Education and Research (CLEAR) Initiative Sol Price School of Public Policy</orgName>
								<orgName type="department" key="dep2">Sol Price School of Public Policy</orgName>
								<orgName type="department" key="dep3">Viterbi School of Engineering</orgName>
								<orgName type="department" key="dep4">Sol Price School of Public Policy</orgName>
								<orgName type="institution" key="instit1">University of Southern</orgName>
								<orgName type="institution" key="instit2">California University of Southern California</orgName>
								<orgName type="institution" key="instit3">University of Southern California</orgName>
								<orgName type="institution" key="instit4">University of Idaho University of California</orgName>
								<orgName type="institution" key="instit5">Santa Barbara University of Southern California</orgName>
								<orgName type="institution" key="instit6">RAND Corporation</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Complementarity, Augmentation, or Substitutivity? The Impact of Generative Artificial Intelligence on the U.S. Federal Workforce</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">ECFB127E6501F549AE9B32A31A1BC936</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-03-18T18:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Artificial Intelligence (AI)</term>
					<term>Competencies</term>
					<term>Natural Language Processing (NLP)</term>
					<term>Natural Language Inference (NLI)</term>
					<term>LLM-as-a-Judge</term>
					<term>Retrieval-Augmented Generation (RAG)</term>
					<term>Strategic Workforce Planning</term>
					<term>Labor Markets</term>
					<term>Civil Service</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This study investigates the near-future impacts of generative artificial intelligence (AI) technologies on occupational competencies across the U.S. federal workforce. We develop a multi-stage Retrieval-Augmented Generation system to leverage large language models for predictive AI modeling that projects shifts in required competencies and to identify vulnerable occupations on a knowledge-by-skill-by-ability basis across the federal government workforce. This study highlights policy recommendations essential for workforce planning in the era of AI. We integrate several sources of detailed data on occupational requirements across the federal government from both centralized and decentralized human resource sources, including from the U.S. Office of Personnel Management (OPM) and various federal agencies. While our preliminary findings suggest some significant shifts in required competencies and potential vulnerability of certain roles to AI-driven changes, we provide nuanced insights that support arguments against abrupt or generic approaches to strategic human capital planning around the development of generative AI. The study aims to inform strategic workforce planning and policy development within federal agencies and demonstrates how this approach can be replicated across other large employment institutions and labor markets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>The rapid advancement of artificial intelligence (AI) technologies, especially generative AI large language models (LLMs), has profound implications for labor markets worldwide, both private and public sector. Generative AI systems, including models like GPT-4o, have the capacity to generate human-like text, images, and code with unprecedented accuracy <ref type="bibr" target="#b26">(Eloundou et al. 2024;</ref><ref type="bibr" target="#b13">Brown et al., 2020;</ref><ref type="bibr">Floridi &amp; Chiriatti, 2020)</ref>. The rapid advancement of these systems has already begun to reshape labor markets by automating tasks traditionally considered exclusive to human workers, including programming, writing, and data analysis. As these capabilities expand, understanding their potential impact on federal occupations is central to effective workforce planning and policy development. We prototype a retrieval-augmented generation (RAG) large-language model (LLM) system designed to assess the relative impact of generative AI through micro-level analysis that exhibits its near-future impact across several hundred occupations and hierarchical responsibilities using the U.S. federal government as our model.</p><p>The U.S. federal executive branch is one of the largest and most complex employers globally, with a diverse range of occupations and standardized competency frameworks <ref type="bibr">(OPM, 2020;</ref><ref type="bibr">Kellough &amp; Nigro, 2018)</ref>. Competencies, as defined by the U.S. Office of Personnel Management (OPM), are measurable patterns essential for successful job performance <ref type="bibr" target="#b57">(OPM, 2018)</ref>. By focusing on specific competencies rather than job titles or general occupations, we provide a nuanced analysis that captures the more fundamental and granular ways in which AI may affect work. This approach aligns with competency-based human resource management practices that emphasize aligning individual capabilities with organizational goals to avoid overly generic or reactive strategic workforce planning <ref type="bibr">(Shippmann et al., 2000;</ref><ref type="bibr">Rodriguez et al., 2002)</ref>.</p><p>Insights gained from this study have broader applicability and can be replicated across other large employment institutions and labor markets, providing valuable tools for workforce planning in the face of technological change. Moreover, the ethical and human implications of how AI will impact the people working in public service as well as the public they serve becomes paramount in making sure that governments are capable of both accurately and holistically assessing the intervention of AI to the civil service across occupations and competencies <ref type="bibr">(Floridi &amp; Chiriatti, 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AI and Workforce Transformation</head><p>The discourse on AI's impact on employment has evolved significantly with the advent of generative AI, particularly with tasks involving language processing, content creation, and data analysis increasingly within AI's capabilities <ref type="bibr">(Kaplan &amp; Haenlein, 2019;</ref><ref type="bibr">Dwivedi et al., 2021)</ref>. <ref type="bibr">Kaplan &amp; Haenlein (2019)</ref> provide a comprehensive overview that helped advance the discussion on AI capabilities in the labor market. <ref type="bibr">Brown et al.'s (2020)</ref> introduction of GPT-3, a language model demonstrating proficiency in tasks such as writing essays, answering questions, and generating code, proved that such overviews require constant updating. <ref type="bibr" target="#b26">Eloundou et al. (2024)</ref> further examined GPT-4's potential labor market impact, finding that significant portions of tasks across various occupations could be affected by large language models (LLMs). <ref type="bibr" target="#b11">Bommasani et al. (2021)</ref> coined the term "foundation models" to describe large-scale AI models like GPT-3 that serve as a base for various applications. They discussed both opportunities and risks, highlighting concerns about job displacement, ethical considerations, and the need for human oversight. <ref type="bibr">Similarly, Agarwal et al. (2022)</ref> emphasized the transformative potential of AI on job roles and the necessity for policy interventions to manage the transition. Indeed, AI and automation may very well lead to a large-scale reconfiguration of job tasks, requiring workers to adapt their skills and competencies <ref type="bibr" target="#b7">(Autor et al., 2022)</ref>. And, while some tasks might be automated, new tasks and roles will emerge that necessitate continuous learning and adaptability. <ref type="bibr">Nedelkoska and Quintini (2018)</ref> analyzed OECD countries and found that while automation poses risks, it also offers opportunities for job enhancement and creation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competency Modeling with Natural Language Processing</head><p>Competency modeling is an effective approach to aligning employee capabilities with organizational goals, especially in the face of rapid technological change <ref type="bibr">(Boyatzis, 2008;</ref><ref type="bibr">Marrelli et al., 2005)</ref>. However, traditional models may not adequately account for the dynamic nature of AI advancements. As <ref type="bibr">Sparrow and Makram (2015)</ref> note, organizations must develop dynamic competencies that enable adaptability and innovation. Indeed, the very development and training of skills in the labor market is endogenous to the rapid evolution in sophistication and capacity of generative AI itself. Humans must adapt to the technology's increased capacity as generative AI adapts to human learning and capacity to use the technology in turn <ref type="bibr">(Kim, 2024)</ref>.</p><p>The rise of generative AI accentuates the need for new competencies. Augmentation strategies, where humans work alongside AI systems, become paramount because they necessitate competencies in AI literacy and collaboration with intelligent machines <ref type="bibr">(Davenport and Kirby, 2016)</ref>. Wilson and <ref type="bibr" target="#b24">Daugherty (2018)</ref> explicate the "fusion skills" that will be required for successful human-AI partnerships, such as responsible normalization and reciprocal apprenticing. <ref type="bibr">Similarly, Calitz et al. (2017)</ref> emphasize the need for digital competencies in the era of Industry 4.0 (the "Fourth Industrial Revolution" <ref type="bibr" target="#b8">(Bai et al., 2020)</ref>).</p><p>The World Economic Forum's Future of Jobs Report <ref type="bibr">(2025)</ref> identified key skills for the future workforce, including analytical thinking, active learning, and technology use. These competencies are increasingly important as generative AI automates routine tasks, shifting the focus to higher-order skills and competencies required for digital transformation, including problem-solving and selfmanagement <ref type="bibr">(Hecklau et al., 2016</ref><ref type="bibr">). Felzmann et al. (2020)</ref> suggest that competencies in ethical reasoning and AI governance are essential. Workers need to understand AI's implications to ensure responsible use and to mitigate risks such as bias and misinformation. Dignum (2018) argues for the importance of embedding ethical considerations into AI systems, underlining the need for competencies in ethical AI development and use.</p><p>Advancements in natural language processing (NLP), particularly with transformer-based models, have revolutionized the field <ref type="bibr">(Wolf et al., 2020;</ref><ref type="bibr">Liu et al., 2019)</ref>. The introduction of the Transformer architecture by <ref type="bibr">Vaswani et al. (2017)</ref> paved the way for models like BERT <ref type="bibr" target="#b23">(Devlin et al., 2019)</ref> and <ref type="bibr">GPT-3 (Brown et al., 2020)</ref>. These models offer contextualized word embeddings that capture nuanced meanings based on context, enhancing the semantic representation of text data.</p><p>In competency modeling, using contextualized embeddings allows for more precise analysis of job descriptions and competencies. <ref type="bibr">Sun et al. (2019)</ref> demonstrated that fine-tuning pre-trained models like BERT on domain-specific data improves performance on NLP tasks. Similarly, <ref type="bibr">Lee et al. (2020)</ref> developed BioBERT, a domain-specific BERT model for biomedical text mining, illustrating the effectiveness of domain adaptation.</p><p>Applying this type of approach to analyze federal job descriptions enables us to capture subtle differences in competencies across occupations and to identify which tasks are susceptible to automation by generative AI. This approach aligns with methodologies used by <ref type="bibr">Zhang et al. (2021)</ref>, who utilized advanced NLP techniques to assess job automation risks at the task level. Additionally, <ref type="bibr">Chen et al. (2019)</ref> applied deep learning for job recommendation systems, showing practical applications of NLP in workforce analytics. Building on these applications, the next step involves examining how predictive models can anticipate the shifting competency requirements driven by generative AI. By exploring these predictive capabilities, organizations can better design interventions that help the workforce adapt to AI-driven changes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AI in Predicting Competency Interventions</head><p>Predicting the impact of generative AI on specific work competencies is complex due to the rapid evolution of AI capabilities. <ref type="bibr" target="#b26">Eloundou et al. (2024)</ref> assesses GPT-4's potential to affect various occupations, finding that tasks involving programming, writing, and data analysis are increasingly automatable. <ref type="bibr">Brynjolfsson et al. (2018)</ref> introduces the concept of "suitability for machine learning," evaluating tasks based on AI's ability to perform them effectively. <ref type="bibr">Acemoglu and Restrepo (2019)</ref> discuss the "task content" of production, emphasizing that automation can reduce labor demand for certain tasks while increasing demand for others, particularly those complementary to AI. This shift necessitates identifying which competencies remain valuable and which need development. <ref type="bibr">Zhao et al. (2022)</ref> explore the impact of AI on creative industries, highlighting that generative AI can both augment and compete with human creativity. They suggest that workers need to focus on uniquely human skills and integrate AI tools to enhance productivity.</p><p>Different frameworks have emerged for assessing the impact of automation and artificial intelligence that offer insights into workforce transformation (e.g., <ref type="bibr">Chui et al., 2018)</ref> and assessing automation potential at the task level across industries. However, the lack of standardization of competencies across organizations and industries as well as the lack of public availability of proprietary industry workforce data at a task level hamstrings our collective ability to adequately test and develop these frameworks on a labor market scale.</p><p>We argue that the U.S. federal government serves as an ideal prototype for such an approach due to its size, diversity, standardized competency frameworks, and the publicly available standards for hiring and promotion across a wide array of occupations and positions therein <ref type="bibr" target="#b57">(OPM, 2018;</ref><ref type="bibr">Ingraham &amp; Getha-Taylor, 2004)</ref>. As one of the largest employers globally, with approximately 2.1 million civilian employees distributed across geographic and economic regions of the largest economy on earth (OPM, 2020), it offers a comprehensive dataset for analyzing AI's impact across various occupations. Moreover, public administration scholars emphasize the government's role in setting standards for workforce practices <ref type="bibr">(Perry &amp; Hondeghem, 2008;</ref><ref type="bibr">Selden, 2009)</ref>. Innovations in workforce planning within the federal government can influence practices in other sectors, amplifying the generalizability of research using it as a prototype. Additionally, the federal government's comparative commitment to transparency and data availability over larger private enterprises enhances the feasibility of such studies <ref type="bibr" target="#b4">(Attard et al, 2015)</ref>.</p><p>Recent developments highlight the U.S. government's active role in leveraging AI responsibly while addressing workforce implications. The Office of Personnel Management (OPM), guided by President Biden's Executive Order on Safe, Secure, and Trustworthy AI, has issued frameworks to promote the ethical use of generative AI. This guidance emphasizes not only the efficiency gains offered by AI but also the necessity of safeguarding against risks like bias amplification, security vulnerabilities, and misinformation. For instance, federal agencies are encouraged to align AI applications with existing competency frameworks, ensuring that automation augments, rather than undermines, human contributions. Furthermore, OPM's guidance on the use of GenAI for federal workforce<ref type="foot" target="#foot_0">foot_0</ref> , including use case inventory and newly developed AI training programs, provides a unique opportunity to empirically study how generative AI transforms workforce competencies in real-world settings. Such initiatives position the federal government as a laboratory for testing scalable workforce interventions, fostering a deeper understanding of how generative AI can be integrated into diverse occupational contexts while upholding transparency and equity.</p><p>Moreover, the federal government faces unique challenges related to technological change that enhance that transparency, including accountability requirements and public scrutiny <ref type="bibr" target="#b53">(Mergel et al., 2019;</ref><ref type="bibr">Fountain, 2001)</ref>. Studying AI's impact in this context provides insights into overcoming barriers that large private organizations present in prototyping this type of analysis, such as the proprietary and internal nature of their workforce strategies and assessment analytics. This is among the reasons that <ref type="bibr">Rainey and Bozeman (2000)</ref>, in discussing some of the fundamental differences between public and private organizations, emphasize that lessons learned in the public sector can, and often do, inform private sector practices. Merit system practices in the federal government provide further transparency and specificity on competency expectations across occupations and positions.</p><p>Hence, the methodology we employ in this study is replicable across other large employment institutions and labor markets due to its foundation in universal concepts of competency modeling and AI's impact on tasks and skills <ref type="bibr">(Ulrich &amp; Dulebohn, 2015;</ref><ref type="bibr">Barney &amp; Wright, 1998)</ref>. Organizations with established competency models can apply similar NLP and AI-system techniques to analyze their specific competencies and predict AI's impact <ref type="bibr">(Campion et al., 2011)</ref>. By training domain-specific embeddings on their job descriptions and competencies, organizations can capture unique linguistic nuances <ref type="bibr" target="#b46">(Levy &amp; Goldberg, 2014)</ref>. This approach aligns with the trend of digital transformation in organizations (Vial, 2019), which comes with newly evolving lexicons. Adopting this methodology enables institutions to proactively manage technological changes, ensuring their workforce remains competitive and capable of leveraging new technologies effectively <ref type="bibr">(Fitzgerald et al., 2014;</ref><ref type="bibr">Kane et al., 2015)</ref>.</p><p>In the following sections, we provide a model that prototypes such an endeavor using the largest employer in the United States, the U. S. federal government. What follows is a description of our process, including the various data sources we employ for both knowledge base and extraction, the Retrieval Augmented Generation (RAG)-LLM system that we develop, the conceptual framework that guides our prompts, the outcomes we derive, the validation techniques that we are pursuing to further strengthen the system, and a discussion on its utility in mapping potential vulnerabilities across complex organizations to inform strategic workforce development.</p><p>Despite contentions within much of the current political rhetoric focused on the federal civil service and reform prescriptions that focus on the replacement of human capital with AI, we find that the impact of generative AI on the federal workforce will be mostly complementary or augmentative rather than substitutive. Our findings speak to the careful approach that is needed in workforce planning around emerging technologies, particularly those such as generative AI that can have impacts across such a broad range of occupations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overview of Methodology</head><p>Our study employs a multi-stage methodology using state-of-the-art natural language processing (NLP) techniques on occupation competency modeling to evaluate the impact of generative AI on federal government occupations. At the core of our approach is a Retrieval-Augmented Generation (RAG) enhanced Large Language Model (LLM) system, which strengthens the accuracy of LLM outputs by retrieving relevant information from specific knowledge bases. This system is designed to extract competencies-knowledge, skills, and abilities (KSAs)-from occupational classifications and assess the impact of AI-driven transformations on the occupation across three dimensions: complementarity, augmentation, and substitutivity. The methodology emphasizes precision and context relevance, supported by domain-specific embeddings, document chunking, and iterative refinement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Retrieval Augmented Generation (RAG)</head><p>Retrieval-Augmented Generation (RAG) is an AI framework in natural language processing that combines the strengths of information retrieval and generative models to provide more accurate and context-rich responses <ref type="bibr" target="#b47">(Lewis et al., 2020)</ref>. Pre-trained language models have shown an impressive ability to learn a substantial amount of knowledge from training data and produce responses based on the trained knowledge <ref type="bibr">(Fabio et al, 2019)</ref>. However, the knowledge of pre-trained models is limited to the static training database and is not updatable. Such an inflexible knowledge base often leads to "Information Hallucination" which occurs when the model tries to generate outputs that are not based on its training data <ref type="bibr" target="#b37">(Hadi et al, 2023)</ref>. To address these limitations, RAG works by first using a retrieval model to search a large collection of documents and extract relevant information as input, which is then fed into a generative model to create a coherent and informative output. Such input acts as a non-parametric memory that is updatable <ref type="bibr" target="#b38">(Izacard et al, 2022)</ref>. This method enhances the quality and reliability of generated content by grounding responses in real-world information, making RAG particularly useful for tasks requiring up-to-date or detailed answers in specific areas.</p><p>We implement our RAG system using Langchain, an open-source framework designed to simplify the implementation of RAG in practical applications <ref type="bibr">(Langchain, 2024)</ref>. Langchain allows us to create modular pipelines that automate retrieval and generation tasks. In the RAG system, Langchain is the backbone that orchestrates various components, such as document retrievers, vector databases, and generative language models. Figure <ref type="figure" target="#fig_0">1</ref> provides a comprehensive diagram of the methodology, illustrating the workflow from data collection and processing to competency extraction and AI impact assessment. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Document Loader</head><p>The document loader in the RAG system is represented by the PDF icons on the far left-and righthand sides of Figure <ref type="figure" target="#fig_0">1</ref>. These components are responsible for loading and parsing documents from external sources. The document loader in KSA extraction (at the top of Figure <ref type="figure" target="#fig_0">1</ref>) is for processing federal job descriptions, competency frameworks, and classification standards from sources such as the U.S. Office of Personnel Management (OPM) and the Federal Workforce Competency Initiative (FWCI).</p><p>These documents provide detailed descriptions of job roles, duties, and required competencies, forming the foundation for extracting knowledge, skills, and abilities (KSAs). The document loader in AI impact evaluation (at the bottom of Figure <ref type="figure" target="#fig_0">1</ref>) is for processing literature, reports, and other data sources on AI capabilities, ethical considerations, and workforce implications. This includes leveraging studies on AI's technical feasibility, its role in automation, and regulatory constraints to ground the impact evaluation in current and relevant knowledge. Together, these loaders ensure the first step of our RAG system is equipped with high-quality, domain-specific knowledge, enabling precise and contextually grounded KSA extraction and AI impact assessment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Document Chunking</head><p>Once the documents are successfully loaded, document chunking is an essential next step in an RAG system. By dividing large texts into smaller, semantic-consistent segments, chunking enables models to process and retrieve relevant information more efficiently, thereby enhancing the accuracy and contextual relevance of generated responses <ref type="bibr" target="#b76">(Zhong et al., 2024)</ref>. Thus, we break the data down into smaller and manageable "text chunks" to work with more precise units of information, making it easier for the model to retrieve relevant data during generation. Different chunking sizes serve different purposes. When a chunking size is small, RAG can perform more accurate information retrieval. When a chunking size is large, RAG can understand a broader context of the document. However, having a small chunking size might suffer from context fragmentation, which means long paragraphs will be split into multiple chunks and affect the model's ability to understand the full picture. Having a large chunking size might suffer from inaccurate output from the model <ref type="bibr" target="#b76">(Zhong et al., 2024)</ref>. Thus, the chunking size in our RAG system is 500 with an overlap of 100 to preserve the precision of knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Vector Database</head><p>After document chunking, the next step is embedding these text chunks into vector representations. Word embeddings, as introduced by <ref type="bibr" target="#b54">Mikolov et al. (2013)</ref>, are the foundational technique behind the vector database, converting each chunk of text into a mathematical representation that captures its semantic meaning. These vectors enable the model to understand the content at a deeper level, supporting efficient similarity searches during the retrieval process. By informing our model on a corpus of federal job descriptions and competency frameworks, we create domain-specific embeddings that reflect the unique language and nuances of federal occupations. This addresses the limitations of generic embeddings that may overlook important contextual details <ref type="bibr" target="#b46">(Levy &amp; Goldberg, 2014)</ref>, in our case, specific to federal occupations. Leveraging techniques such as domainspecific word embeddings, as demonstrated by <ref type="bibr">Zhang et al. (2019)</ref>, allows for enhanced text classification and more precise competency analysis. Once the text chunks are embedded, the vector database maintains an index of each chunk's embedding, enabling the system to perform similarity searches by comparing query embeddings against existing ones. Advanced techniques like approximate nearest neighbor (ANN) search ensures efficient and scalable retrieval, even with largescale datasets <ref type="bibr" target="#b39">(Johnson et al., 2019)</ref>. By preserving nuanced semantic relationships among text chunks, the vector database supports rapid and accurate information retrieval. As a centralized repository of both generic and domain-specific knowledge, the vector database is essential to the RAG system, driving the precision, reliability, and performance of the entire workflow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Knowledge Bases</head><p>Our RAG system process relies on two LangChain-based models that operate sequentially, each leveraging a distinct knowledge base tailored to its respective task. The first knowledge base informs the extraction of competencies (KSAs) from government job descriptions, while the second knowledge base provides the empirical and theoretical foundation for assessing AI's impact on those KSAs. Conceptually, the top left-hand corner of Figure <ref type="figure" target="#fig_0">1</ref> represents the document load for the first knowledge base, which supports competency extraction from federal occupations. The bottom right-hand corner of Figure <ref type="figure" target="#fig_0">1</ref> represents the document load for the second knowledge base, which equips the model with the necessary context to evaluate AI's transformative effects on those competencies.</p><p>The first knowledge base is built on authoritative government documentation that defines and structures KSAs, occupational classifications, and competency frameworks across the federal workforce. A key component of this knowledge base is the validated competency and task ratings from the Federal Workforce Competency Initiative (FWCI), which enhances the model's ability to semantically represent KSAs with greater accuracy. Other major sources of this knowledge base include federal job descriptions, occupational classification guides, and workforce competency datasets. Specifically, job descriptions are collected from multiple federal agencies and aligned with the Handbook of Occupational Groups and Families (OPM, 2018) and the Federal Position Classification Standards <ref type="bibr">(OPM, 2009)</ref>. Additionally, O*NET datasets (National Center for ONET Development, 2021) provide more granular information on occupational competencies, their importance, and required proficiency levels. By incorporating these structured sources, the system can better contextualize the unique demands and qualifications associated with each position.</p><p>The second knowledge base underpins the AI impact evaluation stage by providing empirical, technical, and regulatory context on AI's capabilities and limitations. This knowledge base is informed by research on the technical feasibility of AI applications in workplace settings, drawing from key studies such as <ref type="bibr" target="#b13">Brown et al. (2020)</ref> and <ref type="bibr" target="#b26">Eloundou et al. (2024)</ref>, as well as the AI Index Report by <ref type="bibr" target="#b52">Maslej et al. (2023)</ref>, which offers comprehensive insights into AI's evolving role across various domains. In addition to technical considerations, this knowledge base integrates ethical and regulatory frameworks relevant to AI adoption in the public sector. This includes literature on sector-specific constraints and ethical principles outlined by Felzmann et al. ( <ref type="formula">2020</ref>) and the IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems (IEEE, 2019). These sources help ensure that AI impact assessments align with both practical and ethical considerations unique to government workplaces. Finally, this knowledge base provides the conceptual framework for defining and measuring AI's impact on occupations. It systematically structures AI's role in shaping federal jobs across the three dimensions of Complementarity, Augmentation, and Substitutivity, which are discussed in further detail in subsequent sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stage 1: KSA Extraction</head><p>While OPM provides comprehensive coverage of occupational descriptions across U. S. federal government jobs, these descriptions often lack structure and come in varying lengths and content, which makes standardized AI impact assessment particularly challenging. These descriptions lack consistent formatting, detailed task delineation, and uniform language, complicating efforts to analyze the knowledge, skills, and abilities (KSAs) systematically. To address this, we systematize the data structure by extracting three primary units of analysis for each of the KSA categories from the job description text. In other words, we prompt the LLM to identify the three predominant knowledge bases (K), skills (S), and abilities (A) from the documentation for any given occupational series. These nine units of analysis collectively represent the job and serve as the foundation for subsequent tasks. The extraction process is powered by a RAG system based on OpenAI GPT-4o and our proprietary knowledge inventory, which ensures the model operates within a predefined framework and clear boundaries for its responses.</p><p>The extraction process has three major components-Retrievers, LLM wrappers, and Chains-for accurate and context-aware KSA extraction. Once a user query and initial prompt are embedded into a vector, the retriever compares this query embedding against the knowledge embeddings in the vector database. This is for highlighting and aggregating semantically similar passages, allowing the system to pull the most relevant and contextually appropriate information to "ground" the model's outputs. By selectively retrieving relevant job descriptions and competency definitions, the retriever enhances the quality of the outputs and mitigates factual inaccuracies <ref type="bibr" target="#b55">(Mousavi et al., 2022;</ref><ref type="bibr" target="#b3">Alghisi et al., 2024)</ref>. After retrieval, the LLM wrappers coordinate and integrate the retrieved contextual information into the foundational model (GPT-4o) along with prompts. This step enables the system to produce informed responses, including precise KSA extractions and AI impact scores grounded in authoritative, domain-specific content. Finally, chains link the retrieval and generation processes in a sequence. By combining retrieved information and prompts, chains facilitate the extraction of KSAs for each job. Together, these components create an efficient pipeline for extracting and analyzing KSAs with a specific context focus on the federal workforce.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stage 2: AI Impact Evaluation</head><p>Similarly, the process of AI impact evaluation employs an RAG system to assess the three underlying dimensions of AI's impact on federal occupations: Complementarity, Augmentation, and Substitutivity. These evaluations are grounded in the extracted KSAs during the first stage and rely on the same three key components-Retrievers, LLM wrappers, and Chains-for accurate and context-specific analysis.</p><p>The process begins with retrievers matching a prompt embedded into a vector against the vectorized contextual knowledge and KSAs of the targeted occupation. This step identifies semantically similar passages from datasets containing AI research, technical feasibility studies, and occupational competency frameworks. The retrievers highlight and aggregate relevant textual data to provide the necessary context for evaluating AI's influence on each impact dimension. By surfacing authoritative and contextually aligned information, retrievers ensure that the system remains focused on the three dimensions while mitigating hallucination, i.e., inaccurate and irrelevant outputs <ref type="bibr" target="#b61">(Shuster et al., 2021)</ref>.</p><p>The retrieved contextual knowledge is then integrated into the foundational model (GPT-4o) through LLM wrappers, which combine the contextual knowledge with the prompt. The prompt guides the model in evaluating the extent to which generative AI interacts with the required human competencies (KSAs) of a given occupation along three dimensions of "impact," which we discuss in detail below.</p><p>The LLM wrappers ensure that the model generates detailed and nuanced assessments for each dimension, supported by a brief justification for the assigned scores. Finally, chains coordinate the entire workflow, linking retrieval and generation steps into a sequence. Our RAG system offers a comprehensive model for evaluating the multidimensional impact of AI on federal occupations, delivering valuable insights to inform workforce planning and policy development in the public sector.</p><p>The Three Underlying Dimensions of AI Impact: Complementarity, Augmentation, Substitutivity</p><p>The introduction of AI into the workforce has brought about different frameworks for understanding its role in human labor. We argue that AI systems can be broadly categorized into three forms: Complementary AI, Augmented Intelligence, and Substitutive AI. These categorizations offer distinct perspectives on the interaction between AI and human occupations, each addressing how AI enhances, integrates with, or replaces human labor. For each dimension of impact, we provide a real-world example of a use case within the U. S. federal government (from 2024) that aligns to the construct.</p><p>Complementarity is the ability of generative AI to work alongside humans by enhancing human capabilities through distinct AI strengths without replacing human labor <ref type="bibr" target="#b6">(Autor, 2015;</ref><ref type="bibr">World Economic Forum, 2025)</ref>. The focus is on complementing rather than replicating human cognitive abilities. These systems handle data-heavy or repetitive tasks, freeing humans to focus on higherorder thinking, judgment, and decision-making <ref type="bibr">(Guo, 2024)</ref>. This form is especially valuable in sectors such as healthcare and education, where human judgment is critical, and AI supports by providing data-driven insights.</p><p>Example: As part of the Census Bureau's efforts to maintain and update the Geographic Frame ahead of the 2030 Decennial Census, the Geography Division is using AI to classify survey responses in real-time for the Economic Census according to relative changes in the built environment in which a survey respondent might be embedded, enabling immediate categorization of data as it is collected. It automates the preliminary classification stage of survey responses, significantly streamlining processing and reducing manual effort. <ref type="foot" target="#foot_1">7</ref>By automating repetitive classification tasks-a time-consuming activity for human workersand handling initial classifications efficiently, the AI system allows human analysts to dedicate their cognitive resources to complex analysis, decision-making, and interpreting nuanced economic data. In other words, AI enhances human capabilities rather than replacing their role, preserving and augmenting human judgment and insights.</p><p>Augmentation involves the integration of AI with human intelligence to create synergy, enabling humans to make better decisions and improve productivity. Unlike substitutivity, augmentation emphasizes collaboration between humans and machines, enhancing human cognitive abilities <ref type="bibr" target="#b14">(Brynjolfsson &amp; McAfee, 2014)</ref>. Augmentation requires humans, however, to change their orientation to a given KSA or duty by understanding how to integrate AI into that given competency. AI in this form is used in complex problem-solving environments, such as financial services and legal professions, where AI can provide real-time analytics, but humans retain final decision-making authority and must qualitatively understand the contribution of AI to that decision <ref type="bibr">(Clarke, 2023;</ref><ref type="bibr" target="#b17">Brynjolfsson, Li, and Raymond, 2025)</ref>.</p><p>Example: The Department of Energy has developed a Data Analytics and Machine Learning (DAMaL) Toolkit to integrate AI-generated analytics directly into the human decision-making workflow, specifically for complex project management and scientific research activities within the Department of Energy. The AI provides sophisticated analytics and real-time insights that humans must qualitatively interpret, contextualize, and apply strategically. <ref type="foot" target="#foot_2">8</ref>This requires human operators to actively learn how to incorporate AI-generated analytics into their existing competencies-adjusting their own cognitive processes to effectively leverage AI outputs in decision-making. While the AI handles the data-intensive analytics, humans retain authority over final decisions, reflecting a genuine partnership where AI enhances the depth and quality of human judgments rather than merely automating repetitive tasks.</p><p>Substitutivity refers to systems designed to fully automate tasks that humans traditionally perform. This form of AI is particularly focused on replicating human intelligence or creating functional equivalents in areas where human cognition is less important, such as routine, repetitive tasks <ref type="bibr" target="#b32">(Frey &amp; Osborne, 2017)</ref>. Substitutive AI is prevalent in low-skill jobs such as data entry and customer service, where efficiency and scalability are prioritized, potentially leading to workforce displacement <ref type="bibr">(Clarke, 2023;</ref><ref type="bibr" target="#b26">Eloundou et al, 2024)</ref>.</p><p>Example: The Department of Homeland Security's Optical Counter-UAS Detection system is a sophisticated AI application that autonomously monitors U.S. borders for potential threats. It integrates multi-spectral sensors with advanced machine learning algorithms to independently perform continuous surveillance, using AI to distinguish between benign objects and genuine threats like unauthorized drones or ground incursions. The system then generates real-time alerts and tracking data for border security personnel, fundamentally transforming how threat detection occurs along expansive and often remote border regions.<ref type="foot" target="#foot_3">foot_3</ref> </p><p>This case epitomizes substitutivity by completely automating cognitive tasks that traditionally demanded human attention and judgment. Where border agents once spent countless hours scanning surveillance feeds and making preliminary threat assessments-tasks requiring vigilance but often falling prey to fatigue and attention limitations-the AI system now performs these functions with greater consistency and precision. The technology doesn't merely augment human capabilities but wholly replaces human cognitive labor in the surveillance workflow, reducing operator workload by approximately 40% while simultaneously improving detection accuracy.</p><p>The key differences among complementarity, augmentation, and substitutivity lie in their objectives, approaches, outcomes, and application scopes. We break these down to their core elements in Table <ref type="table">1</ref>.</p><p>Table 1. Taxonomy of Generative AI Impacts on Occupations Aspect Complementarity Augmentation Substitutivity Objective Enhance human capabilities using existing KSAs Transform human KSAs to integrate AI into tasks and processes Replicate or replace human tasks and roles Approach AI works alongside humans, enhancing efficiency AI forces a change in human capabilities to collaborate effectively Automates tasks traditionally performed by humans Outcome Increases productivity without fundamentally changing human roles Human roles evolve, requiring new skills to work alongside AI May lead to job displacement in routine tasks Focus Efficiency and collaboration Evolution of human cognition and skills to integrate AI Functional equivalence to human intelligence Application Suited for tasks that benefit from enhanced efficiency but don't require a change in human cognition Suitable for tasks that require both human cognitive evolution and AI capabilities Effective for routine, repetitive tasks</p><p>Complementarity emphasizes collaboration by enhancing human efficiency in routine tasks without altering existing knowledge, skills, abilities, and duties (KSAs), allowing humans to focus on more complex, creative, or interpersonal activities. Augmentation, in contrast, requires a transformation of human capacities, integrating AI in a way that necessitates changes in KSAs to improve decisionmaking, while still maintaining human involvement. Substitutivity, on the other hand, seeks to fully automate tasks traditionally performed by humans, particularly in industries where jobs are repetitive and routine, potentially leading to labor displacement <ref type="bibr">(World Economic Forum, 2023)</ref>.</p><p>This taxonomy of AI impacts-complementarity, augmentation, and substitutivity-provides a useful framework for understanding the latent construct of impact more precisely at an aggregated level to a given position or occupation. The balance among these three respective aspects will shape future labor markets, with each aspect of AI intervention bringing distinct implications for job complexity, human involvement, and task automation <ref type="bibr" target="#b32">(Frey &amp; Osborne, 2017;</ref><ref type="bibr" target="#b14">Brynjolfsson &amp; McAfee, 2014;</ref><ref type="bibr">Brynjofsson et al, 2025;</ref><ref type="bibr" target="#b26">Eloundou et al, 2024)</ref>.</p><p>Our taxonomy also offers a structured framework for improving prompt engineering when assessing the impact of AI on occupations. By distinguishing between these three aspects, we can design more targeted prompts that ask language models (LLMs) to evaluate how AI will affect specific federal government occupations in terms of collaboration, enhanced decision-making, and automation. For example, when prompting the LLM to generate an AI impact score for a federal government occupation, we break down the task into three parts: asking for the extent to which part of the job duties that AI can complement to human skills (e.g., by handling repetitive tasks), the aspect of which AI might augment human capabilities (e.g., through decision support or analytics), and whether AI could substitute humans entirely in certain tasks.</p><p>This approach ensures a comprehensive evaluation, as the LLM is trained to consider AI's potential across all dimensions rather than focusing solely on automation (which seems often the default in AI discussions). By prompting the LLM to return an AI impact score for each dimension, decisionmakers can get a more nuanced view of how AI may affect workforce roles, which in turn will support policy decisions related to workforce training and job redesign in the public sector. This tailored prompt design leverages the taxonomy to systematically explore AI's role across various occupations, helping anticipate which tasks will see human-AI collaboration and where job displacement risks may arise. The RAG system produces not only the quantitative Impact Score, but it is also trained to provide a brief narrative around the reasoning for the score. These scores and narratives are then the basis of various validation tests that we describe later in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompt Engineering</head><p>While the rapid advancement of LLMs has transformed various industries by automating tasks and enhancing human capabilities, much depends on the querying approach to these models for those purposes. Eliciting the desired response from these models often involves prompt engineering, where carefully crafted inputs hone the accuracy of the model's outputs for specific tasks. When assessing AI's impact on occupations, prompts should clearly define the three aspects of AI intervention: complementarity, augmentation, and substitutivity. This clarity guides the RAG system to provide a structured response addressing each aspect.</p><p>When prompting an LLM to assess AI's impact, it is important to avoid language that implies a positive or negative stance on a given concept since LLMs exhibit cognitive biases <ref type="bibr" target="#b50">(Malberg et al., 2024)</ref>. A biased prompt like "Explain why AI will replace financial analysts" leads to a one-sided response, whereas a neutral prompt encourages a balanced analysis. Moreover, the sequence and context of information can influence the LLM's output. To prevent priming, prompts should present information in a way that does not unnecessarily bias subsequent responses. For instance, providing negative examples of AI impact before asking for an assessment can lead the model to focus on negatives. Instead, we need to present a balanced context and separate prompts to assess each aspect independently. Generally, prompts should avoid language that presupposes a particular answer.</p><p>The nascent science of prompt engineering offers some guidance for prompt design. Effective prompts share common components-text included for an intended goal such as adding context, providing instructions, and the desired output structure-regardless of the desired task <ref type="bibr" target="#b60">(Schulhoff et al., 2024)</ref>. <ref type="bibr" target="#b73">Ziems et al., (2024)</ref> recommend a specific order to these components of context, question, instructions/constraints, and output to improve the consistency of model responses.</p><p>Explicitly instructing models to analyze the provided context and provide an explanation for its decision increases a model's compliance with instructions (Atreia et al., 2024) and results in outputs that are more closely correlated with human outputs <ref type="bibr" target="#b19">(Chiang and Lee, 2023)</ref>.</p><p>We employ a zero-shot prompt strategy and generate a separate call to GPT-4o for each question to prevent anchoring bias <ref type="bibr" target="#b62">(Stureborg et al., 2024)</ref>. We employ role prompting and task provides a task overview to improve task alignment <ref type="bibr" target="#b18">(Chen et al., 2023)</ref>. We include definitions in our prompts, such as the definitions for complementary, augmented, and substitutive intelligence, to improve the accuracy of model outputs <ref type="bibr">(Atreia et al., 2024)</ref>. As emphasized in the best practices literature in survey research design, the use of close-ended Likert scales allows scholars to leverage the natural language capabilities of LLMs for the purposes of discrete measurement. Requesting that LLMs respond with the Likert item rather than a numerical score improves both compliance and accuracy of the generative AI responses <ref type="bibr">(Atreia et al., 2024)</ref>. As such, each option should be listed on a new line to elicit regular model responses <ref type="bibr" target="#b73">(Ziems et al., 2024)</ref>.</p><p>We use the prompts provided in Appendix A to produce assessments of AI impact on our extracted KSAs, employing our three distinct dimensions of impact: complementarity, augmentation, and substitutivity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LLM Model Specification</head><p>The LLM used in this process was OpenAI GPT-4o. The model was utilized on November 22, 2024. Each job in the KSA extraction and impact evaluation tasks was treated as an individual input into the RAG model. This input consisted of a query or API request containing a standardized prompt applied across all queries, along with a job-specific description that varied as different jobs were evaluated. Our model's temperature is set at the default of 1.0, enabling more diverse and creative responses. Lower temperature often limits the model's outputs to a more structured and factual format. High temperature encourages creativity. Context window refers to the maximum number of tokens used in a single request, including prompt, retrieved documents, conversation history, and generated response. The GPT-4o model we use has a context window limit of 128k tokens. Each request consists of retrieved documents, job descriptions, and the main prompt, making it challenging to predict the exact token count per request. While the retrieved documents and prompt alone typically range between 3,000 to 4,000 tokens, the addition of job descriptions significantly increases token usage, often exceeding this range. The selected input size is carefully managed to optimize retrieval relevance while preventing hallucinations, ensuring that responses remain grounded in factually rich information from our knowledge base. This aligns with findings from <ref type="bibr" target="#b74">Zhao et al. (2024)</ref>, who emphasize that supplementing LLMs with external data enhances factual accuracy and reduces hallucinations. System prompts are often used when a model is initiated. These prompts often define the model's behavior, tone, constraints, and role throughout the interaction, ensuring consistent responses that align with the intended use case. In our model, instead of explicitly defining the system prompt at the initiation, we incorporated into our input prompts with other contexts. The system instructions are visible this way and this allows for higher flexibility in updating our prompts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We conduct comprehensive descriptive analyses of our system's AI impact scores across federal job serieses. This analysis provides an empirical foundation to validate the model's predictions and offers additional insights into trends affecting the federal workforce. By combining the outputs of our Retrieval-Augmented Generation (RAG) system with statistical summaries, this approach strengthens the interpretability and credibility of our study's findings. Moreover, our system produces narrative reasoning to each score to provide a more nuanced understanding of why a given component was scored as it was.</p><p>Our descriptive analysis first focuses on evaluating the average AI impact scores across three key dimensions: complementarity, augmentation, and substitutivity. These dimensions were assessed for their effects on Knowledge, Skills, and Abilities (KSAs) across different job series. The analysis also explores differences between white-collar and trade, craft, and labor (TCL) occupational categories to allow for a more nuanced understanding of how AI impacts different segments of the workforce. White-collar roles often involve information-based, analytical, and data-intensive tasks, making them more likely to benefit from generative AI's complementarity and augmentation capabilities. In contrast, TCL occupations are more manually task-oriented, where generative AI's substitutive potential may be relatively higher but still limited by the nature of physical and contextual work. This distinction ensures that workforce strategies and policy recommendations are tailored to the specific needs and characteristics of each occupational group, enabling more effective AI integration and worker adaptation.</p><p>Figures <ref type="figure">2</ref><ref type="figure">3</ref><ref type="figure">4</ref>provide visual representations of the data to help clarify the distribution and relationships between the three AI impact dimensions. Figure <ref type="figure" target="#fig_0">1</ref>, for instance, provides ridgeline plots as a clear depiction of how our AI impact scores are distributed across KSAs and occupational categories. For each individual job series, we create an average score using all 9 individual KSA scores within each AI Impact category. We see that complementarity scores cluster at higher values, particularly for Knowledge, while augmentation and substitutivity exhibit more variability. We also plot the distribution of each AI Impact Category for White Collar jobs (Figure <ref type="figure">3</ref>) and Trade, Craft, and Labor jobs (Figure <ref type="figure">4</ref>) by categorical competency (i.e., Knowledge, Skills, and Abilities).</p><p>We show that complementarity-where AI enhances human capabilities without replacing them-had the highest mean scores across all KSAs. Augmentation scores, which reflect the degree to which AI transforms KSAs to integrate new tools and processes, were moderate, indicating a need for workers to adapt to AI-enhanced environments. Substitutivity scores, representing the potential for full automation, were the lowest, demonstrating the limited likelihood of AI replacing human labor entirely in most roles. White-collar jobs, which comprise the vast majority of federal occupations, exhibit higher scores for complementarity and augmentation, reflecting greater integration of AI in decisionmaking processes. Substitutivity scores are consistently low across both categories, further underscoring generative AI's supportive role.</p><p>These trends align closely with our expectations and suggest that generative AI primarily enhances rather than replaces human competencies in federal roles. 10 The high complementarity scores confirm the model's projection that generative AI will predominantly function as a collaborative tool in the near future, particularly in roles requiring data analysis and decision support. The moderate augmentation scores support the expectation that human workers will need to adapt their KSAs to leverage AI effectively, while the low substitutivity scores reinforce the idea that full automation remains unlikely for most federal occupations.</p><p>Figures 5-7 rank occupational series by their average scores for each respective dimension of AI impact, showing which jobs are influenced most and least by generative AI. This comparative analysis underscores that AI's impact varies significantly across white-collar occupations, with certain roles poised for high or low levels of complementarity, augmentation, and substitutivity. 11</p><p>10 In Appendix B, we provide tables that summarize the mean, standard deviation, and quartile ranges for AI impact scores across the three dimensions for Knowledge, Skills, and Abilities, reflective of the distributive graphs above.</p><p>11 We also include figures in Appendix C that rank TCL occupational series by their average scores for each respective dimension of AI impact. For instance, Figure <ref type="figure" target="#fig_2">5</ref> shows that white-collar occupations contrast across substitutivity, augmentation, and complementarity scores. Substitutivity is notably high in clerical roles such as cash processing, data transcribing, and language clerical, where AI can efficiently automate repetitive tasks, manage large volumes of structured data, and perform routine operations with high accuracy. These roles often involve predictable processes that AI can handle independently, which significantly reduces human involvement. In contrast, professions like mediation, orthotist and prosthetist, and wildlife refuge management exhibit the lowest substitutivity, as these roles require intricate problem-solving, adaptive decision-making, and nuanced physical human interaction that AI currently lacks, making it a limited tool in these complex environments. In terms of augmentation, occupations such as geology, coding, and nuclear engineering should benefit significantly from AI's capability to enhance data analysis, modeling, and technical precision. These occupations often involve intricate and large-scale datasets that require advanced computational tools for efficient processing, simulation, and analysis. AI enables faster, more accurate handling of these complex tasks, reducing human workload and minimizing errors. It creates a highly efficient collaborative environment through supporting iterative testing, data-driven decision-making, and high-dimensional problem-solving, while human experts contribute reasoning, innovative approaches, and oversight. Conversely, roles like aircraft operation and animal health technician show minimal augmentation, where AI's contributions are often limited to automation of routine tasks or data handling. In these occupations, the main workload still depends on human skills, manual operations, and on-the-spot problem-solving, with AI serving as a supplementary tool rather than a transformative force. The complementarity dimension illuminates the symbiotic potential between AI and human workers, unveiling fairly complex interactions. Fields like management and program clerical assistance, general mathematics and statistics, and bioengineering exemplify high complementarity by harnessing AI to tackle repetitive and structured tasks, freeing human workers to delve into nonlinear, abstract thinking and more nuanced decision-making. Unlike augmentation, which amplifies specific tasks, complementarity zeroes in on AI's role as a supportive backbone for human-led processes. This includes strategic management, complex research design, and adaptive problemsolving, where human creativity, ethical considerations, and contextual judgment will (at least in the short-term horizon of our model's predictions) remain relatively irreplaceable and paramount.</p><p>Professions such as police and security guard, vocational rehabilitation, and dental assistant exhibit limited complementarity. For these occupations, AI offers far less assistance, primarily through administrative support, surveillance tools, or data management systems. These roles lean heavily on human intervention for dynamic decision-making, interpersonal interactions, and specialized skills that prove elusive for AI to replicate convincingly. While generative AI's intervention can permeate background functions, these occupations will continue to hinge on human adaptability, emotional intelligence, and direct physical involvement -qualities that remain stubbornly resistant to algorithmic replication.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>High Complementarity and Augmentation, but Low Substitutivity</head><p>While AI enhances many roles through complementarity and augmentation, some occupations remain highly resistant to substitution due to their reliance on physical dexterity, hands-on expertise, and human judgment. Our evaluation results reveal interesting insights about several jobs where AI exhibits high complementarity but very low substitutivity, highlighting roles that benefit from AI support but cannot be replaced by AI's automation.</p><p>For instance, Wildlife Refuge Management (Series 0485) scores high in complementarity (4-5) and augmentation (4) due to AI's ability to assist in data collection, habitat analysis, and species monitoring. However, its substitutivity score remains very low (2), as conservation work requires onthe-ground expertise, decision-making based on unpredictable environmental factors, and direct engagement with ecosystems. AI can support decision-making but lacks the ability to perform fieldwork autonomously. Similarly, Masonry (Series 3603) and Plastering (Series 3605) benefit from AI-driven design tools that optimize construction plans and material usage, reflected in moderate complementarity (4) and augmentation (3). However, their substitutivity scores remain very low (2), as physical execution and craftsmanship remain irreplaceable. AI can suggest layouts and enhance efficiency, but it cannot replicate the manual skills required for high-quality masonry and finishing work. Another notable example is Waiters (Series 7420), where AI can complement and augment service roles through automated ordering systems, smart kitchen coordination, and workflow optimization. However, the role scores the lowest possible substitutivity score (1), emphasizing the importance of human interaction, customer service skills, and, most importantly, the physical presence of the waiter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bottom-Scoring Occupations: Limited AI Impact</head><p>At the bottom of our AI impact analysis, several occupations stand out due to their inherently human-centric nature, where AI offers little complementarity, augmentation, or substitutivity. These roles often require nuanced decision-making, hands-on physical execution, or strategic adaptability beyond AI's current capabilities.</p><p>For example, Nuclear Materials Courier (Series 0084) exhibits minimal complementarity (2), augmentation (2), and substitutivity (1). Transporting highly sensitive materials requires a combination of physical security, threat assessment, and strict regulatory compliance that AI cannot yet replicate. AI can assist in route optimization and security monitoring, but the task itself remains deeply human-driven. Similarly, Cash Processing (Series 0530) exhibits minimal complementarity (2), augmentation (2), and substitutivity (1). Handling financial transactions, verifying signatures, and reconciling discrepancies require a high level of scrutiny, regulation compliance, and human oversight that AI cannot fully automate. Similarly, Language Clerical Roles (Series 1046) score low in substitutivity (2) due to the complexity of linguistic nuances, cultural understanding, and contextdriven interpretation required in translating and clerical linguistic work. While AI tools like translation software can assist, human expertise is essential for accuracy and contextual appropriateness. Position Classification and Office Administration (Series 0326) also ranks among the lowest in substitutivity (2), as these roles require human judgment in assessing organizational structures, policy compliance, and decision-making in personnel management. AI can support documentation and analysis, but final decisions require human intervention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AI as a Complementary Force, Not a Replacement</head><p>Our findings highlight that while AI serves as a powerful tool in data-driven and knowledgeintensive fields, its impact varies significantly across professions. High complementarity and augmentation scores in roles like engineering, conservation, and skilled trades show AI's potential to enhance efficiency and decision-making. However, the persistently low substitutivity scores in these professions reinforce the irreplaceable value of human dexterity, adaptability, and field-based expertise. As AI continues to evolve, industries must adopt a balanced integration strategyleveraging AI for its strengths in data analysis and automation while ensuring that essential human skills remain central in physically demanding, socially interactive, and judgment-based roles. Future workforce planning should emphasize AI-augmented skill development without assuming full automation in areas where human presence remains indispensable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Advantages and a Poignant Example</head><p>The primary focus of this study involves asking LLMs about the impact of AI on KSAs. While this activity may initially appear to be a Question-Answer (QA) Natural Language Processing task, traditional QA evaluation metrics-which focus on factual accuracy for objective questions or human-alignment for subjective responses-do not adequately capture our goal of assessing LLMdriven insights. QA for our purposes is a format and not an information retrieval or reading comprehension task <ref type="bibr" target="#b59">(Rogers et al., 2023)</ref>.</p><p>Our research intersects with two distinct LLM task categories: LLM-as-a-judge and Natural Language Inference (NLI). LLM-as-a-judge refers to the use of LLMs to natural language tasks without reference answers <ref type="bibr" target="#b75">(Zheng et al., 2023)</ref>. LLM assessments are scalable, explainable, and align with human assessments <ref type="bibr" target="#b35">(Hu et al., 2024 ;</ref><ref type="bibr" target="#b22">Desmond et al., 2024;</ref><ref type="bibr" target="#b67">Wang et al., 2023)</ref>. Our study extends this approach by requesting an explanation behind LLM decisions. This not only improves consistency <ref type="bibr" target="#b5">(Atreja et al., 2024)</ref>, but provides auditable data.</p><p>LLM explanations are NLI tasks, where the emphasis is on understanding logical reasoning rather than factuality or accuracy due to the multitude of possible correct answers <ref type="bibr" target="#b72">(Yu et al., 2024)</ref>. The key goal in NLI explanations is determining entailment (i.e., does the explanation follow from the conclusion?) <ref type="bibr" target="#b12">(Bowman et al., 2015)</ref>. In this context, traditional accuracy metrics-measuring alignment with human evaluators-become less relevant, as human opinions may not necessarily represent a useful standard. We want the LLM to justify its answer, that answer to make sense, and the justification to provide additional insight into the reasoning. In the following section, we provide an example of the application of our framework on the Economist occupational series.</p><p>Applying the AI Impact Framework: The Case of Public Sector Economists</p><p>The role of economists is increasingly shaped by AI. While AI significantly enhances technical and computational tasks, human expertise remains for interpretation, strategic decision-making, and policy influence. In Figure <ref type="figure" target="#fig_4">7</ref>, we provide the Likert-scale output for each of our dimensions of impact across all 9 of the predominant KSAs identified by our model. We then provide a sample of the one-sentence justifications our trained model uses for these scores to exhibit the construct validity of our model. In Appendix D, we exhibit the consistency of our model's outputs to observations made in the emerging scholarship that explores the impact of generative AI technologies in the field of economics. As reflected in Figure <ref type="figure" target="#fig_5">8</ref>, Statistical Theory and Data Analysis are areas where AI excels in complementing (5) economists' work, though it varies in its substitutive impact. For instance, our AI system justified the complementarity score in its explanation for Data Analysis as "AI excels in data analysis, enabling faster and more precise manipulation of large datasets, which complements human skills in interpretation and decision-making." Our system suggests a substitutivity score of 4 as "AI excels in data manipulation and statistical analysis, offering high substitutivity in data analysis tasks" This provides a salient example of how our dimensions of impact are not completely separable in practice but remain distinct conceptually. AI can complement a competency in some ways and simultaneously substitute or augment aspects of the same competency. At other times, these dimensions can be much more practicably separable. For instance, Economic Principles was scored at 4 in complementarity, with our model justifying this as "AI provides simulations and data analysis tools that support economic understanding." However, its substitutivity remains low (2) because "interpreting economic principles requires contextual knowledge and adaptability that AI lacks."</p><p>Similarly, the knowledge base competency in Economic Institutions received 3 in complementarity and 2 in augmentation. Here, the moderate complementarity explanation was framed in terms of human judgement as "AI can assist in understanding economic institutions by providing comprehensive data analysis, though human judgment is crucial for context and insight." The lower augmentation score, on the other hand, was justified according to a separate aspect of that knowledge base, emphasizing the importance of contextual understanding: "While AI can assist in gathering and organizing information about economic institutions, the nuanced understanding and contextual analysis still heavily rely on human knowledge."</p><p>It is these nuances that illustrate the multifaceted nature of AI's impact on occupational competencies. AI's contributions are not strictly categorical but instead operate along a spectrum where complementarity, augmentation, and substitutivity interact in complex ways. While AI can enhance the efficiency of specific technical tasks, the interpretative and strategic elements of economic expertise remain deeply human-driven.</p><p>This interplay highlights the necessity of distinguishing between different forms of impact when assessing AI's role in professional domains. For example, even within a single competency, AI's ability to process vast amounts of data may serve as a strong complement to human decisionmaking, while its limited capacity for contextual reasoning prevents it from fully substituting human expertise. These dynamics suggest that AI's integration into the field of economics will likely continue to emphasize augmentation and complementarity rather than outright substitutionparticularly in tasks requiring adaptive judgment, critical thinking, and ethical considerations.</p><p>Ultimately, the model's distinctions between complementarity, augmentation, and substitutivity provide a structured framework for understanding AI's influence on occupational roles. The NLIgenerated justifications provide construct validation that also reveals how these dimensions often overlap in real-world application, reinforcing the importance of continual evaluation as AI technologies evolve and integrate further into professional practice. Our findings are consistent with recent insights on AI's impact on practice and further validate our approach as an apt method to "heatmap" organizations and occupational vulnerabilities and opportunities presented by the emergence of generative AI technologies.<ref type="foot" target="#foot_4">foot_4</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Our dynamic and iterative model addresses limitations identified in prior research by incorporating detailed competency data and accounting for the evolving capabilities of generative AI. By continuously updating according to the newest developments in AI technologies and the changing landscape of required competencies and KSAs (Knowledge, Skills, and Abilities), we ensure that our forecasts remain current and relevant. By weighting AI impacts according to validated competency ratings, we provide a nuanced forecast that accounts for the unique nature of federal jobs. This adaptive approach enhances the reliability of predictions and supports evidence-based decisionmaking.</p><p>The integration of generative AI considerations is necessary, as these technologies have accelerated the potential for automation in areas previously considered secure. As these technological interventions gain traction, our model constantly updates to reflect the specific tasks and competencies affected. This enables organizations to develop targeted strategies for reskilling and upskilling employees in a timely manner.</p><p>Furthermore, our findings emphasize the importance of emphasizing and developing complementary competencies that cannot be replicated by AI, such as critical thinking, ethical judgment, and complex problem-solving. By acknowledging the continuous evolution of AI and its impact on required competencies, our model aligns with the concept of human-AI collaboration, where AI augments human capabilities rather than replaces them. This dynamic approach ensures organizations are prepared to adapt to the ever-changing technological landscape.</p><p>While beyond the scope of this manuscript, evaluation of LLM outputs is critical to developing a robust knowledge base of synthetically generated data while also meeting the rigorous criteria for social science research. Future manuscripts will systematically evaluate the output's reliability and validity rooted in measurement theory <ref type="bibr">(Xiao et al., 2023;</ref><ref type="bibr" target="#b66">Wallach et al., 2024)</ref>. While an excellent start, LLM outputs benefit from additional evaluation that is not relevant to human subjects. The justifications provided by the LLMs allow for a rigorous and systematic evaluation of the quality of outputs <ref type="bibr" target="#b35">(Hu et al., 2024)</ref>. Quality evaluation criteria focus on assessing readability (quality of the output's language elements) and adequacy (quality of the output's task elements) of LLM outputs. Quality evaluations provide additional robustness checks that also serve as a value that can be compared with outputs from other LLMs. In addition to reliability, validity, and quality evaluations; we will want to test for entailment or whether the conclusion (i.e., the score from the model) is the logical conclusion reached from the justification <ref type="bibr">(Liu et al., (2023)</ref>. Entailment provides an assessment of the NLI capabilities of the model. In lieu of "ground truth", quality and entailment evaluations support the merit of LLM outputs.</p><p>In addition, we will soon expand this analysis so that it is run across multiple open-source LLMs.</p><p>Rerunning and refining the analysis across multiple open-source models enables both an assessment of LLM inter-rater reliability and a comparative analysis of similarities and differences in the model's assessments. A multi-model approach will shed light on how variations in architectural design, training data composition, and ethical alignment protocols influence model behavior. This comparative lens will help distinguish between universal trends in LLM reasoning and idiosyncrasies tied to individual models. The findings presented in this study establish a critical baseline, offering a reference point for tracking the evolution of LLM capabilities and limitations as the technology advances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>We demonstrate the effectiveness of a sophisticated RAG-system tailored to the unique demands of the federal civil service labor market. By leveraging the U.S. federal government as a prototype due to its size, diversity, and standardized competency frameworks, we have developed a replicable methodology that offers valuable insights for organizations navigating AI integration. However, the true power of this approach lies in its adaptability across different competency frameworks, allowing organizations to apply NLP and AI techniques with standardized descriptions and ratings.</p><p>Moreover, by training domain-specific models using industry-relevant job descriptions and competencies, organizations can capture nuanced linguistic elements essential for their sectors. The customization of AI agents can be further enhanced by incorporating industry-specific technological trends and economic factors, ensuring that the methodology aligns with regulatory and ethical considerations pertinent to each organization's context. This nuanced approach not only provides a comprehensive framework for assessing AI's impact on occupation labor markets but also accommodates the specificities of institutional expectations, contributing significantly to the broader discourse on workforce transformation across both public and private sectors.</p><p>Our study also highlights the importance of refining semantic representations through validated competency and task ratings, which serve as a ground truth for significance and proficiency levels. By comparing our findings with competency models from other sectors, we validate the universality of our approach. Additionally, our multi-level analysis allows for agency-level insights, enabling tailored recommendations that address the unique challenges and priorities within different federal organizations. This level of customization underscores the potential for our methodology to be applied broadly, offering a valuable tool for organizations seeking to navigate the evolving landscape of AI integration and workforce transformation.</p><p>Ultimately, this research provides insights that can be applied across various sectors, enhancing the adaptability and effectiveness of AI integration strategies. By embracing this approach, organizations can better align their workforce development with the dynamic needs of their respective industries, fostering a more resilient and adaptable workforce in the face of technological change. Finally, our work demonstrates that while AI can significantly enhance and, in some cases, substitute specific tasks, the nuanced interplay between complementarity, augmentation, and substitutivity underscores the enduring value of human expertise. By systematically assessing AI's impact on occupational competencies, our findings highlight the folly of assuming widespread replacement of human employees, revealing instead a more complex reality in which AI reshapes roles rather than rendering them obsolete.</p><p>You are an expert analyst specializing in evaluating and predicting the impact of generative AI over the next five years on occupations within the United States federal government. You evaluate the impact of generative AI on KSAs for different job series. The overall impact of generative AI can be assessed by different underlying dimensions. For the following task, you will evaluate strictly on the dimension of Augmented Intelligence.</p><p>Definition of Augmented Intelligence:</p><p>Augmented intelligence refers to the impact of AI that requires a transformation of human capacities. It involves integrating AI in a way that necessitates changes in knowledge, skills, abilities (KSAs), or tasks to improve decision-making while still maintaining human involvement. The focus is on the extent of necessary evolution of human cognitive KSAs to integrate AI.</p><p>Task:</p><p>For each of the given Knowledge, Skills, Abilities, assess how generative AI will impact the job role in terms of augmented intelligence within a five-year window from today.</p><p>Instructions:</p><p>Provide a score from 1 to 5 for each KSA :</p><p>Augmentation Score: 1 (No Augmentation) to 5 (High Augmentation) **For each score, write a brief explanation (1-2 sentences) justifying your assessment, focusing on how generative AI requires changes in human input.</p><p>Formatting Guidelines:</p><p>Do not use markdown formatting, bullet points, or any special characters in your response.</p><p>Strictly adhere to the format provided below:</p><p>Augmentation: Score Explanation Additionally, provide your response in the following JSON format: { "augmentation_score": "&lt;score from 1 to 5&gt;", "assessment": "&lt;brief explanation&gt;" }</p><p>Table B2. Descriptive Statistics by Occupational Family Mean SD Min Q1 Median Q3 Max White Collar Complementarity 3.46 0.41 2.00 3.33 3.33 3.67 4.67 Augmentation 3.13 0.43 2.00 3.00 3.00 3.33 4.67 Substitutivity 2.66 0.51 1.33 2.33 2.67 3.00 4.33 Trade, Craft and Labor Complementarity 3.18 0.46 1.67 3.00 3.33 3.33 4.67 Augmentation 2.77 0.49 1.33 2.33 2.67 3.00 4.00 Substitutivity 2.50 0.44 1.00 2.33 2.33 2.67 3.67</p><p>prevalent. AI augments these jobs by automating mundane tasks and improving the speed and accuracy of data analysis. However, in areas that require human judgment, interpretation, or creativity, AI functions as a complementary tool rather than a replacement. These findings support the broader scholarly consensus that while AI has the potential to significantly reshape many occupations, human expertise remains essential, particularly in roles where decision-making and contextual understanding are critical <ref type="bibr" target="#b6">(Autor, 2015;</ref><ref type="bibr" target="#b14">Brynjolfsson &amp; McAfee, 2014)</ref>. The balance between automation and augmentation underscores the varied nature of AI's impact across different types of federal government occupations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Multi-Stage RAG-Enhanced LLM Methodology for Competency Extraction and AI Impact Assessment</figDesc><graphic coords="9,72.00,72.00,468.00,272.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .Figure 4 :</head><label>24</label><figDesc>Figure 2. Distribution of AI Impact Scores Across KSAs and Occupational Categories</figDesc><graphic coords="20,72.00,113.86,394.10,427.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Ranking of White-Collar Occupations by Substitutivity Score</figDesc><graphic coords="24,72.00,72.00,448.83,486.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Ranking of White-Collar Occupations by Augmentation Score</figDesc><graphic coords="25,72.00,155.72,448.84,484.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Ranking of White-Collar Occupations by Complementarity Score</figDesc><graphic coords="27,72.00,72.00,448.85,485.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Economist Series (0110) Broken Out by Competencies and AI Impact Scores</figDesc><graphic coords="30,72.00,423.35,434.21,205.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="21,72.00,72.00,381.33,413.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="22,72.00,72.00,403.19,436.85" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_0"><p>https://www.opm.gov/data/resources/ai-guidance/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_1"><p>https://github.com/ombegov/2024-Federal-AI-Use-Case-Inventory</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_2"><p>Ibid.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_3"><p>Ibid.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_4"><p>See Appendix D for a summary of recent insights on AI's impact on the general economist occupation, as an example of the consistency of our model with recent developments in the field.</p></note>
		</body>
		<back>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>} """</head></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>You are a sophisticated analyst skilled in interpreting job descriptions to identify and categorize the critical knowledge, skills, and abilities (KSAs) essential to job performance. For the given job series, extract the three most critical of each category of knowledge, skill, and ability so that there are nine in total.</p><p>Knowledge refers to an organized body of information, usually of a factual or procedural nature, which, if applied, makes adequate performance on the job possible. A body of information applied directly to the performance of a function.</p><p>Skill refers to the proficient manual, verbal or mental manipulation of data or things. Skills can be readily measured by a performance test where quantity and quality of performance are tested, usually within an established time limit. Examples of proficient manipulation of things are skill in typing or skill in operating a vehicle. Examples of proficient manipulation of data are skill in computation using decimals; skill in editing for transposed numbers, etc.</p><p>Ability refers to the power to perform an observable activity at the present time. This means that abilities have been evidenced through activities or behaviors that are similar to those required on the job, e.g., the ability to plan and organize work. Abilities are different from aptitudes. Aptitudes are only the potential for performing the activity.</p><p>Stick closely to the original text in the job description, paraphrasing only when needed, and emphasize relevance and precision in each selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompt 2: AI Assessment</head><p>""" You are an expert analyst specializing in evaluating and predicting the impact of generative AI over the next five years on occupations within the United States federal government. You evaluate the impact of generative AI on KSAs for different job series. The overall impact of generative AI can be assessed by different underlying dimensions. For the following task, you will evaluate strictly on the dimension of Complementary Intelligence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition of Complementary Intelligence:</head><p>Complementary intelligence refers to generative AI that works alongside humans by enhancing human capabilities through distinct AI strengths without replacing human labor. The focus is on complementing-not replicating-human cognitive knowledge, skills, abilities (KSAs), or tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task:</head><p>For each given Knowledge, Skill, and Ability, assess how generative AI will impact the job role in terms of complementarity within a five-year window from today.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instructions:</head><p>Provide a score from 1 to 5 for each KSA using the following scale: For each score, write a brief explanation (1-2 sentences) justifying your assessment, focusing on how generative AI supports human competencies without replacing them. Do not use markdown formatting, bullet points, or any other special characters in your response.</p><p>Strictly adhere to the JSON format provided below: ```json { "k1_complementarity_score": "&lt; complementarity_score from 1 to 5&gt;", "k1_assessment": "&lt;brief explanation to justify your score&gt;", "k2_complementarity_score": "&lt; complementarity_score from 1 to 5&gt;", "k2_assessment": "&lt;brief explanation to justify your score&gt;", … } """ """ You are an expert analyst specializing in evaluating and predicting the impact of generative AI over the next five years on occupations within the United States federal government. You evaluate the impact of generative AI on KSAs for different job series. The overall impact of generative AI can be assessed by different underlying dimensions. For the following task, you will evaluate strictly on the dimension of Substitutive Intelligence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition of Substitutive AI:</head><p>Substitutive AI refers to artificial intelligence systems designed to fully replicate or replace functions traditionally performed by humans. In this approach, human involvement is minimized or eliminated as AI takes over functional responsibilities. Substitutive AI aims for automation that mirrors human capabilities without requiring human input, effectively achieving functional equivalence to human intelligence in specific functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task:</head><p>For each of the given Knowledge, Skills, Abilities, and Duties, assess how generative AI will impact the job role in terms of substitutivity within a five-year window from today.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instructions:</head><p>Provide a score from 1 to 5 for each KSA or Duty: Substitutivity Score: 1 (No Substitution) to 5 (Full Substitution) **For each score, write a brief explanation (1-2 sentences) justifying your assessment, focusing on the likelihood of AI fully automating or replacing the human input.</p><p>Formatting Guidelines: Do not use markdown formatting, bullet points, or any special characters in your response.</p><p>Strictly adhere to the format provided below: Substitutivity: Score Explanation Additionally, provide your response in the following JSON format: { "substitutivity_score": "&lt;score from 1 to 5&gt;", "assessment": "&lt;brief explanation&gt;"   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B. Descriptive Statistics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix D. A Synthesis of Recent Insights on Generative AI's Impact on Economists</head><p>Recent studies underscore the transformative role of AI in economic data-intensive tasks. <ref type="bibr" target="#b43">Korinek (2023)</ref> highlights that generative AI tools can automate numerous micro-tasks in research, such as data analysis and coding assistance, thereby allowing economists to focus more on interpreting results and applying insights. <ref type="bibr" target="#b21">Desai (2023)</ref> emphasizes that machine learning models excel at processing large volumes of unstructured data, capturing complex patterns, and enhancing predictive accuracy, which complements traditional econometric approaches. These capabilities align with the high complementarity and augmentation scores observed in statistical theory and data analysis, as AI streamlines computations and data handling, enabling economists to delve deeper into strategic analysis.</p><p>However, the integration of AI into economic modeling and policy-making presents nuanced challenges. <ref type="bibr" target="#b51">Marwala and Hurwitz (2017)</ref> discuss that while AI techniques can enhance economic models by providing more accurate simulations and trend analyses, human judgment remains paramount for refining these models and contextualizing outcomes within theoretical frameworks. This perspective supports the moderate substitutivity scores we got on economic modeling, which indicates that AI serves as a valuable tool but cannot fully replace the strategic insights provided by economists. Furthermore, the Congressional Budget Office ( <ref type="formula">2023</ref>) notes that although AI has the potential to transform service delivery in both business and government sectors, its ability to substitute human expertise is limited in areas requiring deep contextual understanding and adaptability, such as interpreting economic principles and understanding institutional frameworks. This limitation is reflected in the lower substitutivity scores for these knowledge areas in our model, reinforcing the notion that AI, while a powerful analytical tool, cannot fully replicate the economists' contribution to policy influence and strategic policy-making.</p><p>Our analysis of generative AI's impact on federal government occupations reveals notable trends in how different roles are affected, particularly in technical, scientific, and administrative domains. These findings align with broader scholarly research, which highlights AI's growing role in augmenting tasks across sectors while maintaining the critical need for human judgment in more complex areas of decision-making <ref type="bibr" target="#b6">(Autor, 2015;</ref><ref type="bibr" target="#b14">Brynjolfsson &amp; McAfee, 2014)</ref>.</p><p>Occupations that are data-intensive, such as those in the Data Science or Physics job series, are among the most impacted. AI has proven particularly effective at enhancing roles that require largescale data processing, predictive analytics, and computational problem-solving. Research by <ref type="bibr" target="#b1">Agrawal, Gans, and Goldfarb (2018)</ref> underscores that AI excels in tasks involving pattern recognition and data analysis, thereby automating routine aspects of information management. In these fields, AI augments rather than replaces human labor, allowing workers to focus on interpreting AI-generated results and applying insights. In physics, for instance, AI assists in complex calculations, but human expertise remains essential for nuanced understanding and application of findings. This aligns with <ref type="bibr" target="#b31">Frank et al. (2019)</ref>, who note that AI's predictive capabilities are most effective when paired with human expertise in interpreting outcomes.</p><p>Administrative and compliance-based roles, such as those in Auditing and Internal Revenue Officer positions, also demonstrate a high degree of AI augmentation. These positions benefit from AI's ability to process large volumes of data and automate rule-based tasks, such as compliance checks and anomaly detection <ref type="bibr" target="#b44">(Lambrecht &amp; Tucker, 2019</ref>). AI's impact here is largely about efficiency gains, as it accelerates processes that were previously labor-intensive, but human oversight remains critical when interpretation and nuanced judgment are required. This reflects findings from <ref type="bibr" target="#b27">Felten, Raj, and Seamans (2018)</ref>, who argue that AI's role in administrative work is to enhance human capabilities, not to fully automate tasks, especially in environments that require regulatory compliance and interpretive decision-making.</p><p>However, AI's influence in enforcement and field roles, such as Border Patrol Enforcement, takes a different form. In these jobs, AI supports monitoring, data collection, and reporting but does not substitute for human judgment in unpredictable, high-stakes situations. AI can assist in analyzing large-scale data to improve situational awareness, but field decisions still require human actors, particularly in the dynamic and often ambiguous contexts of law enforcement <ref type="bibr" target="#b63">(Susskind &amp; Susskind, 2015)</ref>. This aligns with research by <ref type="bibr" target="#b40">Kaplan and Haenlein (2020)</ref>, which notes that AI in law enforcement is more likely to serve as a decision-support tool, complementing rather than replacing human officers.</p><p>When examining how AI affects federal occupations more broadly, a clear divergence emerges between its impact on Knowledge, Skills, and Abilities (KSAs) and its influence on specific job duties. AI tends to augment KSAs, particularly in technical roles, by automating repetitive tasks and providing faster access to information. However, it leaves the higher-order interpretive and decisionmaking functions to humans. <ref type="bibr" target="#b15">Brynjolfsson, Rock, and Syverson (2017)</ref> emphasize that AI can greatly enhance productivity in jobs involving data analysis and information processing, but human insight is required to transform AI-driven data into actionable decisions. In contrast, the automation of routine duties is more likely, particularly in roles that involve repetitive or predictable tasks. AI can handle tasks such as data entry, basic reporting, and monitoring, especially in auditing and administrative positions <ref type="bibr" target="#b10">(Bessen, 2019)</ref>.</p><p>This distinction between KSAs and duties is critical. In data-intensive fields like Data Science, AI handles much of the labor-intensive computational work, but humans remain necessary for making final interpretations and decisions <ref type="bibr" target="#b31">(Frank et al., 2019)</ref>. Conversely, routine duties that are more procedural in nature-such as those found in Auditing or Internal Revenue Officer positions-are more susceptible to full or partial automation. AI can quickly process large amounts of financial data, generate reports, and identify irregularities, but human auditors are still required to interpret these findings and make compliance decisions, as noted by recent studies on AI and work automation <ref type="bibr" target="#b27">(Felten, Raj, &amp; Seamans, 2018)</ref>.</p><p>In summary, AI's most significant impacts, according to our analysis, are seen in technical, scientific, and administrative roles across the federal government where data processing and routine tasks are</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Demystifying the Future of Work: The Impact of Technology on Employment</title>
		<author>
			<persName><forename type="first">D</forename><surname>Acemoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Restrepo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Economics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Prediction machines: The simple economics of artificial intelligence</title>
		<author>
			<persName><forename type="first">A</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goldfarb</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>Harvard Business Review Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goldfarb</surname></persName>
		</author>
		<title level="m">The Economics of Artificial Intelligence: An Agenda</title>
		<imprint>
			<publisher>University of Chicago Press</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Alghisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rizzoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Roccabruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mousavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Riccardi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.06399</idno>
		<title level="m">Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A systematic review of open government data initiatives</title>
		<author>
			<persName><forename type="first">J</forename><surname>Attard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Orlandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Scerri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Auer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Government information quarterly</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="399" to="418" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Atreja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ashkinaze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mendelsohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hemphill</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.11980</idno>
		<title level="m">Prompt Design Matters for Computational Social Science Tasks but in Unpredictable Ways</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Why are there still so many jobs? The history and future of workplace automation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Autor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Economic Perspectives</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="3" to="30" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Autor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mindell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Reynolds</surname></persName>
		</author>
		<title level="m">The Work of the Future: Building Better Jobs in an Age of Intelligent Machines. MIT Work of the Future Report</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">C</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dallasega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Orzes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sarkis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Production Economics</title>
		<imprint>
			<biblScope unit="volume">229</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Industry 4.0 technologies assessment: A sustainability perspective</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gebru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mcmillan-Major</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shmitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</title>
		<meeting>the 2021 ACM Conference on Fairness, Accountability, and Transparency</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="610" to="623" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">AI and jobs: The role of demand</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bessen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>NBER Working Paper</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Bommasani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.07258</idno>
		<title level="m">On the Opportunities and Risks of Foundation Models</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.05326</idno>
		<title level="m">A large annotated corpus for learning natural language inference</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Language Models are Few-Shot Learners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">The second machine age: Work, progress, and prosperity in a time of brilliant technologies</title>
		<author>
			<persName><forename type="first">E</forename><surname>Brynjolfsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mcafee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>W.W. Norton &amp; Company</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Artificial intelligence and the modern productivity paradox: A clash of expectations and statistics</title>
		<author>
			<persName><forename type="first">E</forename><surname>Brynjolfsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Syverson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">NBER Working Paper</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Artificial Intelligence and the Modern Productivity Paradox: A Clash of Expectations and Statistics</title>
		<author>
			<persName><forename type="first">E</forename><surname>Brynjolfsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Syverson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Economics of Artificial Intelligence: An Agenda</title>
		<imprint>
			<publisher>University of Chicago Press</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="23" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Generative AI at Work</title>
		<author>
			<persName><forename type="first">Erik</forename><surname>Brynjolfsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danielle</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lindsey</forename><surname>Raymond</surname></persName>
		</author>
		<idno type="DOI">10.1093/qje/qjae044</idno>
		<ptr target="https://doi.org/10.1093/qje/qjae044" />
	</analytic>
	<monogr>
		<title level="j">The Quarterly Journal of Economics</title>
		<imprint>
			<biblScope unit="page">44</biblScope>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Langrené</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.14735</idno>
		<title level="m">Unleashing the potential of prompt engineering in Large Language Models: a comprehensive review</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A closer look into using large language models for automatic evaluation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2023</title>
		<imprint>
			<date type="published" when="2023-12">2023. December</date>
			<biblScope unit="page" from="8928" to="8942" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<ptr target="https://www.cbo.gov/publication/61147" />
		<title level="m">Artificial Intelligence and Its Potential Effects on the Economy and Labor Market</title>
		<imprint>
			<publisher>Congressional Budget Office</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Desai</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2304.00086" />
		<title level="m">Machine Learning for Economics Research: When, What, and How?</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">EvaluLLM: LLM assisted evaluation of generative outputs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Desmond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ashktorab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dugan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion Proceedings of the 29th International Conference on Intelligent User Interfaces</title>
		<imprint>
			<date type="published" when="2024-03">2024. March</date>
			<biblScope unit="page" from="30" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Human + Machine: Reimagining Work in the Age of AI</title>
		<author>
			<persName><forename type="first">P</forename><surname>Daugherty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Wilson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>Harvard Business Review Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Dillman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Smyth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Christian</surname></persName>
		</author>
		<title level="m">Internet, Phone, Mail, and Mixed-Mode Surveys: The Tailored Design Method</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">GPTs are GPTs: Labor market impact potential of LLMs</title>
		<author>
			<persName><forename type="first">T</forename><surname>Eloundou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">384</biblScope>
			<biblScope unit="issue">6702</biblScope>
			<biblScope unit="page" from="1306" to="1308" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A method to link advances in artificial intelligence to occupational abilities</title>
		<author>
			<persName><forename type="first">E</forename><surname>Felten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Seamans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AEA Papers and Proceedings</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="54" to="57" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Occupational, Industry, and Geographic Exposure to Artificial Intelligence: A Novel Dataset and Its Implications</title>
		<author>
			<persName><forename type="first">E</forename><surname>Felten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Seamans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3889" to="3905" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">AI Ethics: A Systematic Review and Annotated Bibliography of Machine Ethics and Artificial Moral Agents</title>
		<author>
			<persName><forename type="first">L</forename><surname>Floridi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cowls</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ethics and Information Technology</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="43" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Fowler</surname></persName>
		</author>
		<title level="m">Survey Research Methods</title>
		<imprint>
			<publisher>Sage Publications</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>th ed.</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Toward understanding the impact of artificial intelligence on labor</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Autor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Bessen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brynjolfsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cebrian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Deming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Youn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Proceedings of the National Academy of Sciences</publisher>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="6531" to="6539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The Future of Employment: How Susceptible Are Jobs to Computerisation?</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Osborne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technological Forecasting and Social Change</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="254" to="280" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Response Bias, Social Desirability and Dissimulation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Furnham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Personality and Individual Differences</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="385" to="400" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Groves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Fowler</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Couper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Lepkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tourangeau</surname></persName>
		</author>
		<title level="m">Survey Methodology</title>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>nd ed.</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.12055</idno>
		<title level="m">Are LLM-based Evaluators Confusing NLG Quality Criteria?</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Artificial Intelligence in Service</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Rust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Maksimovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Service Research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="155" to="172" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">U</forename><surname>Hadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">A</forename><surname>Tashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Qureshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Muneer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Irfan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zafar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Shaikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Akhtar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<idno type="DOI">10.36227/techrxiv.23589741.v1</idno>
		<ptr target="https://doi.org/10.36227/techrxiv.23589741.v1" />
		<title level="m">A Survey on Large Language Models: Applications, Challenges, Limitations, and Practical Usage</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lomeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dwivedi-Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2208.03299</idno>
		<ptr target="https://doi.org/10.48550/ARXIV.2208.03299" />
		<title level="m">Atlas: Few-shot Learning with Retrieval Augmented Language Models (Version 3)</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Billion-scale similarity search with GPUs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<idno type="DOI">10.1109/TBDATA.2019.2921572</idno>
		<ptr target="https://doi.org/10.1109/TBDATA.2019.2921572" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Big Data</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="535" to="547" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Rulers of the world, unite! The challenges and opportunities of artificial intelligence</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Haenlein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Business Horizons</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="50" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title/>
		<author>
			<persName><surname>Kim</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Cognitive impacts of AI on administration (Draft)</title>
		<author>
			<persName><surname>Kyoung-Cheol</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
			<publisher>School of Public and International Affairs, University of Georgia</publisher>
		</imprint>
	</monogr>
	<note>Center for the Study of Global Issues</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Korinek</surname></persName>
		</author>
		<idno type="DOI">https://www.aeaweb.org/articles?id=10.1257/jel.20231736</idno>
		<ptr target="https://www.aeaweb.org/articles?id=10.1257/jel.20231736" />
		<title level="m">Generative AI for Economic Research: Use Cases and Implications for Economists</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Algorithmic bias? An empirical study of apparent gender-based discrimination in the display of STEM career ads</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lambrecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2976" to="2991" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Human-Centered Approaches to Interactive Machine Learning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
			<affiliation>
				<orgName type="collaboration">Langchain Introduction.</orgName>
			</affiliation>
		</author>
		<ptr target="https://python.langchain.com/docs/introduction/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2021 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2021">2024, October 29. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Linguistic Regularities in Sparse and Explicit Word Representations</title>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth Conference on Computational Natural Language Learning</title>
		<meeting>the Eighteenth Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="171" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Retrieval-Augmented Generation for Knowledge-Intensive NLP tasks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Küttler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<idno>arXiv.org</idno>
		<ptr target="https://arxiv.org/abs/2005.11401" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">The Future of Work After COVID-19</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lund</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>McKinsey Global Institute</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Measuring and Understanding Differences in Private and Public Sector Technology Jobs: Evidence from Artificial Intelligence Job Posting Data</title>
		<author>
			<persName><forename type="first">Christos</forename><surname>Makridis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gil</forename><surname>Alterovitz</surname></persName>
		</author>
		<idno type="DOI">10.2139/ssrn.4891300</idno>
		<ptr target="http://dx.doi.org/10.2139/ssrn.4891300" />
		<imprint>
			<date type="published" when="2024-07-10">July 10, 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Malberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Poletukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Groh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2410.15413</idno>
		<title level="m">A Comprehensive Evaluation of Cognitive Biases in LLMs</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Marwala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hurwitz</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1703.06597" />
		<title level="m">Artificial Intelligence and Economic Theories</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Maslej</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fattorini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brynjolfsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Etchemendy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ligett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lyons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Perrault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2310.03715</idno>
		<title level="m">Artificial intelligence index report 2023</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Defining Digital Transformation: Results from Expert Interviews</title>
		<author>
			<persName><forename type="first">I</forename><surname>Mergel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Edelmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Haug</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Government Information Quarterly</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">101385</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<title level="m">Efficient Estimation of Word Representations in Vector Space</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Evaluation of Response Generation Models: Shouldn&apos;t It Be Shareable and Replicable</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mousavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Roccabruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lorandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Caldarella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Riccardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Natural Language Generation, Evaluation, and Metrics</title>
		<meeting>the 2nd Workshop on Natural Language Generation, Evaluation, and Metrics</meeting>
		<imprint>
			<publisher>GEM</publisher>
			<date type="published" when="2022-12">2022, December</date>
			<biblScope unit="page" from="136" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title/>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
		<respStmt>
			<orgName>OpenAI</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">GPT-4 Technical Report</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Handbook of Occupational Groups and Families</title>
		<author>
			<persName><surname>Opm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Federal Workforce Competency Initiative (FWCI) Fact Sheet</title>
		<imprint>
			<publisher>U.S. Office of Personnel Management</publisher>
			<date type="published" when="2018">2018. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bakhtin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1250</idno>
		<ptr target="https://doi.org/10.18653/v1/D19-1250" />
		<title level="m">Language Models as Knowledge Bases? Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2463" to="2473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Qa dataset explosion: A taxonomy of nlp resources for question answering and reading comprehension</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Augenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1" to="45" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Schulhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ilie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Balepur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kahadze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Resnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2406.06608</idno>
		<title level="m">The Prompt Report: A Systematic Survey of Prompting Techniques</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Poff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2104.07567" />
		<title level="m">Retrieval augmentation reduces hallucination in conversation</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Stureborg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Alikaniotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Suhara</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.01724</idno>
		<title level="m">Large language models are inconsistent and biased evaluators</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">The future of the professions: How technology will transform the work of human experts</title>
		<author>
			<persName><forename type="first">R</forename><surname>Susskind</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Susskind</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Tourangeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Rips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Rasinski</surname></persName>
		</author>
		<title level="m">The Psychology of Survey Response</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Artificial Intelligence as Augmenting Automation: Implications for Employment</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">T</forename><surname>Tschang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Almirall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>Academy of Management Perspectives</publisher>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="642" to="659" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pangakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Barocas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Z</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2411.10939</idno>
		<title level="m">Evaluating Generative AI Systems is a Social Science Measurement Challenge</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2303.04048</idno>
		<title level="m">Is chatgpt a good nlg evaluator? a preliminary study</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Artificial Intelligence and the Public Sector-Applications and Challenges</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Wirtz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Weyerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Geyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Public Administration</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="1083" to="1097" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Executive Order on Promoting the Use of Trustworthy Artificial Intelligence in the Federal Government</title>
		<author>
			<persName><forename type="first">White</forename><surname>House</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<ptr target="https://www.weforum.org/publications/the-future-of-jobs-report-2025/" />
	</analytic>
	<monogr>
		<title level="m">The Future of Jobs Report</title>
		<imprint>
			<date type="published" when="2025">2025. 2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Artificial Discretion as a Tool of Governance: A Framework for Understanding the Impact of Artificial Intelligence on Public Administration</title>
		<author>
			<persName><forename type="first">M</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Bullock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Lecy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perspectives on Public Management and Governance</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="301" to="313" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Natural language reasoning, a survey</title>
		<author>
			<persName><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tiwari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1" to="39" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Can large language models transform computational social science?</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ziems</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Held</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Shaikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="237" to="291" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Retrieval Augmented Generation (RAG) and Beyond: A Comprehensive Survey on How to Make your LLMs use External Data More Wisely (Version 1)</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Qiu</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2409.14924</idno>
		<ptr target="https://doi.org/10.48550/ARXIV.2409.14924" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Judging llm-as-a-judge with mt-bench and chatbot arena</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="46595" to="46623" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Mix-of-Granularity: Optimize the Chunking Granularity for Retrieval-Augmented Generation (Version 1)</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qin</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2406.00456</idno>
		<ptr target="https://doi.org/10.48550/ARXIV.2406.00456" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
