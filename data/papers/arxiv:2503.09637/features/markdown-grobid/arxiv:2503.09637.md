# Complementarity, Augmentation, or Substitutivity? The Impact of Generative Artificial Intelligence on the U.S. Federal Workforce

## Abstract

## 

This study investigates the near-future impacts of generative artificial intelligence (AI) technologies on occupational competencies across the U.S. federal workforce. We develop a multi-stage Retrieval-Augmented Generation system to leverage large language models for predictive AI modeling that projects shifts in required competencies and to identify vulnerable occupations on a knowledge-by-skill-by-ability basis across the federal government workforce. This study highlights policy recommendations essential for workforce planning in the era of AI. We integrate several sources of detailed data on occupational requirements across the federal government from both centralized and decentralized human resource sources, including from the U.S. Office of Personnel Management (OPM) and various federal agencies. While our preliminary findings suggest some significant shifts in required competencies and potential vulnerability of certain roles to AI-driven changes, we provide nuanced insights that support arguments against abrupt or generic approaches to strategic human capital planning around the development of generative AI. The study aims to inform strategic workforce planning and policy development within federal agencies and demonstrates how this approach can be replicated across other large employment institutions and labor markets.

## Introduction

The rapid advancement of artificial intelligence (AI) technologies, especially generative AI large language models (LLMs), has profound implications for labor markets worldwide, both private and public sector. Generative AI systems, including models like GPT-4o, have the capacity to generate human-like text, images, and code with unprecedented accuracy [(Eloundou et al. 2024;](#b26)[Brown et al., 2020;](#b13)[Floridi & Chiriatti, 2020)](#). The rapid advancement of these systems has already begun to reshape labor markets by automating tasks traditionally considered exclusive to human workers, including programming, writing, and data analysis. As these capabilities expand, understanding their potential impact on federal occupations is central to effective workforce planning and policy development. We prototype a retrieval-augmented generation (RAG) large-language model (LLM) system designed to assess the relative impact of generative AI through micro-level analysis that exhibits its near-future impact across several hundred occupations and hierarchical responsibilities using the U.S. federal government as our model.

The U.S. federal executive branch is one of the largest and most complex employers globally, with a diverse range of occupations and standardized competency frameworks [(OPM, 2020;](#)[Kellough & Nigro, 2018)](#). Competencies, as defined by the U.S. Office of Personnel Management (OPM), are measurable patterns essential for successful job performance [(OPM, 2018)](#b57). By focusing on specific competencies rather than job titles or general occupations, we provide a nuanced analysis that captures the more fundamental and granular ways in which AI may affect work. This approach aligns with competency-based human resource management practices that emphasize aligning individual capabilities with organizational goals to avoid overly generic or reactive strategic workforce planning [(Shippmann et al., 2000;](#)[Rodriguez et al., 2002)](#).

Insights gained from this study have broader applicability and can be replicated across other large employment institutions and labor markets, providing valuable tools for workforce planning in the face of technological change. Moreover, the ethical and human implications of how AI will impact the people working in public service as well as the public they serve becomes paramount in making sure that governments are capable of both accurately and holistically assessing the intervention of AI to the civil service across occupations and competencies [(Floridi & Chiriatti, 2020)](#).

## Background

## AI and Workforce Transformation

The discourse on AI's impact on employment has evolved significantly with the advent of generative AI, particularly with tasks involving language processing, content creation, and data analysis increasingly within AI's capabilities [(Kaplan & Haenlein, 2019;](#)[Dwivedi et al., 2021)](#). [Kaplan & Haenlein (2019)](#) provide a comprehensive overview that helped advance the discussion on AI capabilities in the labor market. [Brown et al.'s (2020)](#) introduction of GPT-3, a language model demonstrating proficiency in tasks such as writing essays, answering questions, and generating code, proved that such overviews require constant updating. [Eloundou et al. (2024)](#b26) further examined GPT-4's potential labor market impact, finding that significant portions of tasks across various occupations could be affected by large language models (LLMs). [Bommasani et al. (2021)](#b11) coined the term "foundation models" to describe large-scale AI models like GPT-3 that serve as a base for various applications. They discussed both opportunities and risks, highlighting concerns about job displacement, ethical considerations, and the need for human oversight. [Similarly, Agarwal et al. (2022)](#) emphasized the transformative potential of AI on job roles and the necessity for policy interventions to manage the transition. Indeed, AI and automation may very well lead to a large-scale reconfiguration of job tasks, requiring workers to adapt their skills and competencies [(Autor et al., 2022)](#b7). And, while some tasks might be automated, new tasks and roles will emerge that necessitate continuous learning and adaptability. [Nedelkoska and Quintini (2018)](#) analyzed OECD countries and found that while automation poses risks, it also offers opportunities for job enhancement and creation.

## Competency Modeling with Natural Language Processing

Competency modeling is an effective approach to aligning employee capabilities with organizational goals, especially in the face of rapid technological change [(Boyatzis, 2008;](#)[Marrelli et al., 2005)](#). However, traditional models may not adequately account for the dynamic nature of AI advancements. As [Sparrow and Makram (2015)](#) note, organizations must develop dynamic competencies that enable adaptability and innovation. Indeed, the very development and training of skills in the labor market is endogenous to the rapid evolution in sophistication and capacity of generative AI itself. Humans must adapt to the technology's increased capacity as generative AI adapts to human learning and capacity to use the technology in turn [(Kim, 2024)](#).

The rise of generative AI accentuates the need for new competencies. Augmentation strategies, where humans work alongside AI systems, become paramount because they necessitate competencies in AI literacy and collaboration with intelligent machines [(Davenport and Kirby, 2016)](#). Wilson and [Daugherty (2018)](#b24) explicate the "fusion skills" that will be required for successful human-AI partnerships, such as responsible normalization and reciprocal apprenticing. [Similarly, Calitz et al. (2017)](#) emphasize the need for digital competencies in the era of Industry 4.0 (the "Fourth Industrial Revolution" [(Bai et al., 2020)](#b8)).

The World Economic Forum's Future of Jobs Report [(2025)](#) identified key skills for the future workforce, including analytical thinking, active learning, and technology use. These competencies are increasingly important as generative AI automates routine tasks, shifting the focus to higher-order skills and competencies required for digital transformation, including problem-solving and selfmanagement [(Hecklau et al., 2016](#)[). Felzmann et al. (2020)](#) suggest that competencies in ethical reasoning and AI governance are essential. Workers need to understand AI's implications to ensure responsible use and to mitigate risks such as bias and misinformation. Dignum (2018) argues for the importance of embedding ethical considerations into AI systems, underlining the need for competencies in ethical AI development and use.

Advancements in natural language processing (NLP), particularly with transformer-based models, have revolutionized the field [(Wolf et al., 2020;](#)[Liu et al., 2019)](#). The introduction of the Transformer architecture by [Vaswani et al. (2017)](#) paved the way for models like BERT [(Devlin et al., 2019)](#b23) and [GPT-3 (Brown et al., 2020)](#). These models offer contextualized word embeddings that capture nuanced meanings based on context, enhancing the semantic representation of text data.

In competency modeling, using contextualized embeddings allows for more precise analysis of job descriptions and competencies. [Sun et al. (2019)](#) demonstrated that fine-tuning pre-trained models like BERT on domain-specific data improves performance on NLP tasks. Similarly, [Lee et al. (2020)](#) developed BioBERT, a domain-specific BERT model for biomedical text mining, illustrating the effectiveness of domain adaptation.

Applying this type of approach to analyze federal job descriptions enables us to capture subtle differences in competencies across occupations and to identify which tasks are susceptible to automation by generative AI. This approach aligns with methodologies used by [Zhang et al. (2021)](#), who utilized advanced NLP techniques to assess job automation risks at the task level. Additionally, [Chen et al. (2019)](#) applied deep learning for job recommendation systems, showing practical applications of NLP in workforce analytics. Building on these applications, the next step involves examining how predictive models can anticipate the shifting competency requirements driven by generative AI. By exploring these predictive capabilities, organizations can better design interventions that help the workforce adapt to AI-driven changes.

## AI in Predicting Competency Interventions

Predicting the impact of generative AI on specific work competencies is complex due to the rapid evolution of AI capabilities. [Eloundou et al. (2024)](#b26) assesses GPT-4's potential to affect various occupations, finding that tasks involving programming, writing, and data analysis are increasingly automatable. [Brynjolfsson et al. (2018)](#) introduces the concept of "suitability for machine learning," evaluating tasks based on AI's ability to perform them effectively. [Acemoglu and Restrepo (2019)](#) discuss the "task content" of production, emphasizing that automation can reduce labor demand for certain tasks while increasing demand for others, particularly those complementary to AI. This shift necessitates identifying which competencies remain valuable and which need development. [Zhao et al. (2022)](#) explore the impact of AI on creative industries, highlighting that generative AI can both augment and compete with human creativity. They suggest that workers need to focus on uniquely human skills and integrate AI tools to enhance productivity.

Different frameworks have emerged for assessing the impact of automation and artificial intelligence that offer insights into workforce transformation (e.g., [Chui et al., 2018)](#) and assessing automation potential at the task level across industries. However, the lack of standardization of competencies across organizations and industries as well as the lack of public availability of proprietary industry workforce data at a task level hamstrings our collective ability to adequately test and develop these frameworks on a labor market scale.

We argue that the U.S. federal government serves as an ideal prototype for such an approach due to its size, diversity, standardized competency frameworks, and the publicly available standards for hiring and promotion across a wide array of occupations and positions therein [(OPM, 2018;](#b57)[Ingraham & Getha-Taylor, 2004)](#). As one of the largest employers globally, with approximately 2.1 million civilian employees distributed across geographic and economic regions of the largest economy on earth (OPM, 2020), it offers a comprehensive dataset for analyzing AI's impact across various occupations. Moreover, public administration scholars emphasize the government's role in setting standards for workforce practices [(Perry & Hondeghem, 2008;](#)[Selden, 2009)](#). Innovations in workforce planning within the federal government can influence practices in other sectors, amplifying the generalizability of research using it as a prototype. Additionally, the federal government's comparative commitment to transparency and data availability over larger private enterprises enhances the feasibility of such studies [(Attard et al, 2015)](#b4).

Recent developments highlight the U.S. government's active role in leveraging AI responsibly while addressing workforce implications. The Office of Personnel Management (OPM), guided by President Biden's Executive Order on Safe, Secure, and Trustworthy AI, has issued frameworks to promote the ethical use of generative AI. This guidance emphasizes not only the efficiency gains offered by AI but also the necessity of safeguarding against risks like bias amplification, security vulnerabilities, and misinformation. For instance, federal agencies are encouraged to align AI applications with existing competency frameworks, ensuring that automation augments, rather than undermines, human contributions. Furthermore, OPM's guidance on the use of GenAI for federal workforce[foot_0](#foot_0) , including use case inventory and newly developed AI training programs, provides a unique opportunity to empirically study how generative AI transforms workforce competencies in real-world settings. Such initiatives position the federal government as a laboratory for testing scalable workforce interventions, fostering a deeper understanding of how generative AI can be integrated into diverse occupational contexts while upholding transparency and equity.

Moreover, the federal government faces unique challenges related to technological change that enhance that transparency, including accountability requirements and public scrutiny [(Mergel et al., 2019;](#b53)[Fountain, 2001)](#). Studying AI's impact in this context provides insights into overcoming barriers that large private organizations present in prototyping this type of analysis, such as the proprietary and internal nature of their workforce strategies and assessment analytics. This is among the reasons that [Rainey and Bozeman (2000)](#), in discussing some of the fundamental differences between public and private organizations, emphasize that lessons learned in the public sector can, and often do, inform private sector practices. Merit system practices in the federal government provide further transparency and specificity on competency expectations across occupations and positions.

Hence, the methodology we employ in this study is replicable across other large employment institutions and labor markets due to its foundation in universal concepts of competency modeling and AI's impact on tasks and skills [(Ulrich & Dulebohn, 2015;](#)[Barney & Wright, 1998)](#). Organizations with established competency models can apply similar NLP and AI-system techniques to analyze their specific competencies and predict AI's impact [(Campion et al., 2011)](#). By training domain-specific embeddings on their job descriptions and competencies, organizations can capture unique linguistic nuances [(Levy & Goldberg, 2014)](#b46). This approach aligns with the trend of digital transformation in organizations (Vial, 2019), which comes with newly evolving lexicons. Adopting this methodology enables institutions to proactively manage technological changes, ensuring their workforce remains competitive and capable of leveraging new technologies effectively [(Fitzgerald et al., 2014;](#)[Kane et al., 2015)](#).

In the following sections, we provide a model that prototypes such an endeavor using the largest employer in the United States, the U. S. federal government. What follows is a description of our process, including the various data sources we employ for both knowledge base and extraction, the Retrieval Augmented Generation (RAG)-LLM system that we develop, the conceptual framework that guides our prompts, the outcomes we derive, the validation techniques that we are pursuing to further strengthen the system, and a discussion on its utility in mapping potential vulnerabilities across complex organizations to inform strategic workforce development.

Despite contentions within much of the current political rhetoric focused on the federal civil service and reform prescriptions that focus on the replacement of human capital with AI, we find that the impact of generative AI on the federal workforce will be mostly complementary or augmentative rather than substitutive. Our findings speak to the careful approach that is needed in workforce planning around emerging technologies, particularly those such as generative AI that can have impacts across such a broad range of occupations.

## Methodology

## Overview of Methodology

Our study employs a multi-stage methodology using state-of-the-art natural language processing (NLP) techniques on occupation competency modeling to evaluate the impact of generative AI on federal government occupations. At the core of our approach is a Retrieval-Augmented Generation (RAG) enhanced Large Language Model (LLM) system, which strengthens the accuracy of LLM outputs by retrieving relevant information from specific knowledge bases. This system is designed to extract competencies-knowledge, skills, and abilities (KSAs)-from occupational classifications and assess the impact of AI-driven transformations on the occupation across three dimensions: complementarity, augmentation, and substitutivity. The methodology emphasizes precision and context relevance, supported by domain-specific embeddings, document chunking, and iterative refinement.

## Retrieval Augmented Generation (RAG)

Retrieval-Augmented Generation (RAG) is an AI framework in natural language processing that combines the strengths of information retrieval and generative models to provide more accurate and context-rich responses [(Lewis et al., 2020)](#b47). Pre-trained language models have shown an impressive ability to learn a substantial amount of knowledge from training data and produce responses based on the trained knowledge [(Fabio et al, 2019)](#). However, the knowledge of pre-trained models is limited to the static training database and is not updatable. Such an inflexible knowledge base often leads to "Information Hallucination" which occurs when the model tries to generate outputs that are not based on its training data [(Hadi et al, 2023)](#b37). To address these limitations, RAG works by first using a retrieval model to search a large collection of documents and extract relevant information as input, which is then fed into a generative model to create a coherent and informative output. Such input acts as a non-parametric memory that is updatable [(Izacard et al, 2022)](#b38). This method enhances the quality and reliability of generated content by grounding responses in real-world information, making RAG particularly useful for tasks requiring up-to-date or detailed answers in specific areas.

We implement our RAG system using Langchain, an open-source framework designed to simplify the implementation of RAG in practical applications [(Langchain, 2024)](#). Langchain allows us to create modular pipelines that automate retrieval and generation tasks. In the RAG system, Langchain is the backbone that orchestrates various components, such as document retrievers, vector databases, and generative language models. Figure [1](#fig_0) provides a comprehensive diagram of the methodology, illustrating the workflow from data collection and processing to competency extraction and AI impact assessment. 

## Document Loader

The document loader in the RAG system is represented by the PDF icons on the far left-and righthand sides of Figure [1](#fig_0). These components are responsible for loading and parsing documents from external sources. The document loader in KSA extraction (at the top of Figure [1](#fig_0)) is for processing federal job descriptions, competency frameworks, and classification standards from sources such as the U.S. Office of Personnel Management (OPM) and the Federal Workforce Competency Initiative (FWCI).

These documents provide detailed descriptions of job roles, duties, and required competencies, forming the foundation for extracting knowledge, skills, and abilities (KSAs). The document loader in AI impact evaluation (at the bottom of Figure [1](#fig_0)) is for processing literature, reports, and other data sources on AI capabilities, ethical considerations, and workforce implications. This includes leveraging studies on AI's technical feasibility, its role in automation, and regulatory constraints to ground the impact evaluation in current and relevant knowledge. Together, these loaders ensure the first step of our RAG system is equipped with high-quality, domain-specific knowledge, enabling precise and contextually grounded KSA extraction and AI impact assessment.

## Document Chunking

Once the documents are successfully loaded, document chunking is an essential next step in an RAG system. By dividing large texts into smaller, semantic-consistent segments, chunking enables models to process and retrieve relevant information more efficiently, thereby enhancing the accuracy and contextual relevance of generated responses [(Zhong et al., 2024)](#b76). Thus, we break the data down into smaller and manageable "text chunks" to work with more precise units of information, making it easier for the model to retrieve relevant data during generation. Different chunking sizes serve different purposes. When a chunking size is small, RAG can perform more accurate information retrieval. When a chunking size is large, RAG can understand a broader context of the document. However, having a small chunking size might suffer from context fragmentation, which means long paragraphs will be split into multiple chunks and affect the model's ability to understand the full picture. Having a large chunking size might suffer from inaccurate output from the model [(Zhong et al., 2024)](#b76). Thus, the chunking size in our RAG system is 500 with an overlap of 100 to preserve the precision of knowledge.

## Vector Database

After document chunking, the next step is embedding these text chunks into vector representations. Word embeddings, as introduced by [Mikolov et al. (2013)](#b54), are the foundational technique behind the vector database, converting each chunk of text into a mathematical representation that captures its semantic meaning. These vectors enable the model to understand the content at a deeper level, supporting efficient similarity searches during the retrieval process. By informing our model on a corpus of federal job descriptions and competency frameworks, we create domain-specific embeddings that reflect the unique language and nuances of federal occupations. This addresses the limitations of generic embeddings that may overlook important contextual details [(Levy & Goldberg, 2014)](#b46), in our case, specific to federal occupations. Leveraging techniques such as domainspecific word embeddings, as demonstrated by [Zhang et al. (2019)](#), allows for enhanced text classification and more precise competency analysis. Once the text chunks are embedded, the vector database maintains an index of each chunk's embedding, enabling the system to perform similarity searches by comparing query embeddings against existing ones. Advanced techniques like approximate nearest neighbor (ANN) search ensures efficient and scalable retrieval, even with largescale datasets [(Johnson et al., 2019)](#b39). By preserving nuanced semantic relationships among text chunks, the vector database supports rapid and accurate information retrieval. As a centralized repository of both generic and domain-specific knowledge, the vector database is essential to the RAG system, driving the precision, reliability, and performance of the entire workflow.

## Knowledge Bases

Our RAG system process relies on two LangChain-based models that operate sequentially, each leveraging a distinct knowledge base tailored to its respective task. The first knowledge base informs the extraction of competencies (KSAs) from government job descriptions, while the second knowledge base provides the empirical and theoretical foundation for assessing AI's impact on those KSAs. Conceptually, the top left-hand corner of Figure [1](#fig_0) represents the document load for the first knowledge base, which supports competency extraction from federal occupations. The bottom right-hand corner of Figure [1](#fig_0) represents the document load for the second knowledge base, which equips the model with the necessary context to evaluate AI's transformative effects on those competencies.

The first knowledge base is built on authoritative government documentation that defines and structures KSAs, occupational classifications, and competency frameworks across the federal workforce. A key component of this knowledge base is the validated competency and task ratings from the Federal Workforce Competency Initiative (FWCI), which enhances the model's ability to semantically represent KSAs with greater accuracy. Other major sources of this knowledge base include federal job descriptions, occupational classification guides, and workforce competency datasets. Specifically, job descriptions are collected from multiple federal agencies and aligned with the Handbook of Occupational Groups and Families (OPM, 2018) and the Federal Position Classification Standards [(OPM, 2009)](#). Additionally, O*NET datasets (National Center for ONET Development, 2021) provide more granular information on occupational competencies, their importance, and required proficiency levels. By incorporating these structured sources, the system can better contextualize the unique demands and qualifications associated with each position.

The second knowledge base underpins the AI impact evaluation stage by providing empirical, technical, and regulatory context on AI's capabilities and limitations. This knowledge base is informed by research on the technical feasibility of AI applications in workplace settings, drawing from key studies such as [Brown et al. (2020)](#b13) and [Eloundou et al. (2024)](#b26), as well as the AI Index Report by [Maslej et al. (2023)](#b52), which offers comprehensive insights into AI's evolving role across various domains. In addition to technical considerations, this knowledge base integrates ethical and regulatory frameworks relevant to AI adoption in the public sector. This includes literature on sector-specific constraints and ethical principles outlined by Felzmann et al. ( [2020](#)) and the IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems (IEEE, 2019). These sources help ensure that AI impact assessments align with both practical and ethical considerations unique to government workplaces. Finally, this knowledge base provides the conceptual framework for defining and measuring AI's impact on occupations. It systematically structures AI's role in shaping federal jobs across the three dimensions of Complementarity, Augmentation, and Substitutivity, which are discussed in further detail in subsequent sections.

## Stage 1: KSA Extraction

While OPM provides comprehensive coverage of occupational descriptions across U. S. federal government jobs, these descriptions often lack structure and come in varying lengths and content, which makes standardized AI impact assessment particularly challenging. These descriptions lack consistent formatting, detailed task delineation, and uniform language, complicating efforts to analyze the knowledge, skills, and abilities (KSAs) systematically. To address this, we systematize the data structure by extracting three primary units of analysis for each of the KSA categories from the job description text. In other words, we prompt the LLM to identify the three predominant knowledge bases (K), skills (S), and abilities (A) from the documentation for any given occupational series. These nine units of analysis collectively represent the job and serve as the foundation for subsequent tasks. The extraction process is powered by a RAG system based on OpenAI GPT-4o and our proprietary knowledge inventory, which ensures the model operates within a predefined framework and clear boundaries for its responses.

The extraction process has three major components-Retrievers, LLM wrappers, and Chains-for accurate and context-aware KSA extraction. Once a user query and initial prompt are embedded into a vector, the retriever compares this query embedding against the knowledge embeddings in the vector database. This is for highlighting and aggregating semantically similar passages, allowing the system to pull the most relevant and contextually appropriate information to "ground" the model's outputs. By selectively retrieving relevant job descriptions and competency definitions, the retriever enhances the quality of the outputs and mitigates factual inaccuracies [(Mousavi et al., 2022;](#b55)[Alghisi et al., 2024)](#b3). After retrieval, the LLM wrappers coordinate and integrate the retrieved contextual information into the foundational model (GPT-4o) along with prompts. This step enables the system to produce informed responses, including precise KSA extractions and AI impact scores grounded in authoritative, domain-specific content. Finally, chains link the retrieval and generation processes in a sequence. By combining retrieved information and prompts, chains facilitate the extraction of KSAs for each job. Together, these components create an efficient pipeline for extracting and analyzing KSAs with a specific context focus on the federal workforce.

## Stage 2: AI Impact Evaluation

Similarly, the process of AI impact evaluation employs an RAG system to assess the three underlying dimensions of AI's impact on federal occupations: Complementarity, Augmentation, and Substitutivity. These evaluations are grounded in the extracted KSAs during the first stage and rely on the same three key components-Retrievers, LLM wrappers, and Chains-for accurate and context-specific analysis.

The process begins with retrievers matching a prompt embedded into a vector against the vectorized contextual knowledge and KSAs of the targeted occupation. This step identifies semantically similar passages from datasets containing AI research, technical feasibility studies, and occupational competency frameworks. The retrievers highlight and aggregate relevant textual data to provide the necessary context for evaluating AI's influence on each impact dimension. By surfacing authoritative and contextually aligned information, retrievers ensure that the system remains focused on the three dimensions while mitigating hallucination, i.e., inaccurate and irrelevant outputs [(Shuster et al., 2021)](#b61).

The retrieved contextual knowledge is then integrated into the foundational model (GPT-4o) through LLM wrappers, which combine the contextual knowledge with the prompt. The prompt guides the model in evaluating the extent to which generative AI interacts with the required human competencies (KSAs) of a given occupation along three dimensions of "impact," which we discuss in detail below.

The LLM wrappers ensure that the model generates detailed and nuanced assessments for each dimension, supported by a brief justification for the assigned scores. Finally, chains coordinate the entire workflow, linking retrieval and generation steps into a sequence. Our RAG system offers a comprehensive model for evaluating the multidimensional impact of AI on federal occupations, delivering valuable insights to inform workforce planning and policy development in the public sector.

The Three Underlying Dimensions of AI Impact: Complementarity, Augmentation, Substitutivity

The introduction of AI into the workforce has brought about different frameworks for understanding its role in human labor. We argue that AI systems can be broadly categorized into three forms: Complementary AI, Augmented Intelligence, and Substitutive AI. These categorizations offer distinct perspectives on the interaction between AI and human occupations, each addressing how AI enhances, integrates with, or replaces human labor. For each dimension of impact, we provide a real-world example of a use case within the U. S. federal government (from 2024) that aligns to the construct.

Complementarity is the ability of generative AI to work alongside humans by enhancing human capabilities through distinct AI strengths without replacing human labor [(Autor, 2015;](#b6)[World Economic Forum, 2025)](#). The focus is on complementing rather than replicating human cognitive abilities. These systems handle data-heavy or repetitive tasks, freeing humans to focus on higherorder thinking, judgment, and decision-making [(Guo, 2024)](#). This form is especially valuable in sectors such as healthcare and education, where human judgment is critical, and AI supports by providing data-driven insights.

Example: As part of the Census Bureau's efforts to maintain and update the Geographic Frame ahead of the 2030 Decennial Census, the Geography Division is using AI to classify survey responses in real-time for the Economic Census according to relative changes in the built environment in which a survey respondent might be embedded, enabling immediate categorization of data as it is collected. It automates the preliminary classification stage of survey responses, significantly streamlining processing and reducing manual effort. [7](#foot_1)By automating repetitive classification tasks-a time-consuming activity for human workersand handling initial classifications efficiently, the AI system allows human analysts to dedicate their cognitive resources to complex analysis, decision-making, and interpreting nuanced economic data. In other words, AI enhances human capabilities rather than replacing their role, preserving and augmenting human judgment and insights.

Augmentation involves the integration of AI with human intelligence to create synergy, enabling humans to make better decisions and improve productivity. Unlike substitutivity, augmentation emphasizes collaboration between humans and machines, enhancing human cognitive abilities [(Brynjolfsson & McAfee, 2014)](#b14). Augmentation requires humans, however, to change their orientation to a given KSA or duty by understanding how to integrate AI into that given competency. AI in this form is used in complex problem-solving environments, such as financial services and legal professions, where AI can provide real-time analytics, but humans retain final decision-making authority and must qualitatively understand the contribution of AI to that decision [(Clarke, 2023;](#)[Brynjolfsson, Li, and Raymond, 2025)](#b17).

Example: The Department of Energy has developed a Data Analytics and Machine Learning (DAMaL) Toolkit to integrate AI-generated analytics directly into the human decision-making workflow, specifically for complex project management and scientific research activities within the Department of Energy. The AI provides sophisticated analytics and real-time insights that humans must qualitatively interpret, contextualize, and apply strategically. [8](#foot_2)This requires human operators to actively learn how to incorporate AI-generated analytics into their existing competencies-adjusting their own cognitive processes to effectively leverage AI outputs in decision-making. While the AI handles the data-intensive analytics, humans retain authority over final decisions, reflecting a genuine partnership where AI enhances the depth and quality of human judgments rather than merely automating repetitive tasks.

Substitutivity refers to systems designed to fully automate tasks that humans traditionally perform. This form of AI is particularly focused on replicating human intelligence or creating functional equivalents in areas where human cognition is less important, such as routine, repetitive tasks [(Frey & Osborne, 2017)](#b32). Substitutive AI is prevalent in low-skill jobs such as data entry and customer service, where efficiency and scalability are prioritized, potentially leading to workforce displacement [(Clarke, 2023;](#)[Eloundou et al, 2024)](#b26).

Example: The Department of Homeland Security's Optical Counter-UAS Detection system is a sophisticated AI application that autonomously monitors U.S. borders for potential threats. It integrates multi-spectral sensors with advanced machine learning algorithms to independently perform continuous surveillance, using AI to distinguish between benign objects and genuine threats like unauthorized drones or ground incursions. The system then generates real-time alerts and tracking data for border security personnel, fundamentally transforming how threat detection occurs along expansive and often remote border regions.[foot_3](#foot_3)

This case epitomizes substitutivity by completely automating cognitive tasks that traditionally demanded human attention and judgment. Where border agents once spent countless hours scanning surveillance feeds and making preliminary threat assessments-tasks requiring vigilance but often falling prey to fatigue and attention limitations-the AI system now performs these functions with greater consistency and precision. The technology doesn't merely augment human capabilities but wholly replaces human cognitive labor in the surveillance workflow, reducing operator workload by approximately 40% while simultaneously improving detection accuracy.

The key differences among complementarity, augmentation, and substitutivity lie in their objectives, approaches, outcomes, and application scopes. We break these down to their core elements in Table [1](#).

Table 1. Taxonomy of Generative AI Impacts on Occupations Aspect Complementarity Augmentation Substitutivity Objective Enhance human capabilities using existing KSAs Transform human KSAs to integrate AI into tasks and processes Replicate or replace human tasks and roles Approach AI works alongside humans, enhancing efficiency AI forces a change in human capabilities to collaborate effectively Automates tasks traditionally performed by humans Outcome Increases productivity without fundamentally changing human roles Human roles evolve, requiring new skills to work alongside AI May lead to job displacement in routine tasks Focus Efficiency and collaboration Evolution of human cognition and skills to integrate AI Functional equivalence to human intelligence Application Suited for tasks that benefit from enhanced efficiency but don't require a change in human cognition Suitable for tasks that require both human cognitive evolution and AI capabilities Effective for routine, repetitive tasks

Complementarity emphasizes collaboration by enhancing human efficiency in routine tasks without altering existing knowledge, skills, abilities, and duties (KSAs), allowing humans to focus on more complex, creative, or interpersonal activities. Augmentation, in contrast, requires a transformation of human capacities, integrating AI in a way that necessitates changes in KSAs to improve decisionmaking, while still maintaining human involvement. Substitutivity, on the other hand, seeks to fully automate tasks traditionally performed by humans, particularly in industries where jobs are repetitive and routine, potentially leading to labor displacement [(World Economic Forum, 2023)](#).

This taxonomy of AI impacts-complementarity, augmentation, and substitutivity-provides a useful framework for understanding the latent construct of impact more precisely at an aggregated level to a given position or occupation. The balance among these three respective aspects will shape future labor markets, with each aspect of AI intervention bringing distinct implications for job complexity, human involvement, and task automation [(Frey & Osborne, 2017;](#b32)[Brynjolfsson & McAfee, 2014;](#b14)[Brynjofsson et al, 2025;](#)[Eloundou et al, 2024)](#b26).

Our taxonomy also offers a structured framework for improving prompt engineering when assessing the impact of AI on occupations. By distinguishing between these three aspects, we can design more targeted prompts that ask language models (LLMs) to evaluate how AI will affect specific federal government occupations in terms of collaboration, enhanced decision-making, and automation. For example, when prompting the LLM to generate an AI impact score for a federal government occupation, we break down the task into three parts: asking for the extent to which part of the job duties that AI can complement to human skills (e.g., by handling repetitive tasks), the aspect of which AI might augment human capabilities (e.g., through decision support or analytics), and whether AI could substitute humans entirely in certain tasks.

This approach ensures a comprehensive evaluation, as the LLM is trained to consider AI's potential across all dimensions rather than focusing solely on automation (which seems often the default in AI discussions). By prompting the LLM to return an AI impact score for each dimension, decisionmakers can get a more nuanced view of how AI may affect workforce roles, which in turn will support policy decisions related to workforce training and job redesign in the public sector. This tailored prompt design leverages the taxonomy to systematically explore AI's role across various occupations, helping anticipate which tasks will see human-AI collaboration and where job displacement risks may arise. The RAG system produces not only the quantitative Impact Score, but it is also trained to provide a brief narrative around the reasoning for the score. These scores and narratives are then the basis of various validation tests that we describe later in this paper.

## Prompt Engineering

While the rapid advancement of LLMs has transformed various industries by automating tasks and enhancing human capabilities, much depends on the querying approach to these models for those purposes. Eliciting the desired response from these models often involves prompt engineering, where carefully crafted inputs hone the accuracy of the model's outputs for specific tasks. When assessing AI's impact on occupations, prompts should clearly define the three aspects of AI intervention: complementarity, augmentation, and substitutivity. This clarity guides the RAG system to provide a structured response addressing each aspect.

When prompting an LLM to assess AI's impact, it is important to avoid language that implies a positive or negative stance on a given concept since LLMs exhibit cognitive biases [(Malberg et al., 2024)](#b50). A biased prompt like "Explain why AI will replace financial analysts" leads to a one-sided response, whereas a neutral prompt encourages a balanced analysis. Moreover, the sequence and context of information can influence the LLM's output. To prevent priming, prompts should present information in a way that does not unnecessarily bias subsequent responses. For instance, providing negative examples of AI impact before asking for an assessment can lead the model to focus on negatives. Instead, we need to present a balanced context and separate prompts to assess each aspect independently. Generally, prompts should avoid language that presupposes a particular answer.

The nascent science of prompt engineering offers some guidance for prompt design. Effective prompts share common components-text included for an intended goal such as adding context, providing instructions, and the desired output structure-regardless of the desired task [(Schulhoff et al., 2024)](#b60). [Ziems et al., (2024)](#b73) recommend a specific order to these components of context, question, instructions/constraints, and output to improve the consistency of model responses.

Explicitly instructing models to analyze the provided context and provide an explanation for its decision increases a model's compliance with instructions (Atreia et al., 2024) and results in outputs that are more closely correlated with human outputs [(Chiang and Lee, 2023)](#b19).

We employ a zero-shot prompt strategy and generate a separate call to GPT-4o for each question to prevent anchoring bias [(Stureborg et al., 2024)](#b62). We employ role prompting and task provides a task overview to improve task alignment [(Chen et al., 2023)](#b18). We include definitions in our prompts, such as the definitions for complementary, augmented, and substitutive intelligence, to improve the accuracy of model outputs [(Atreia et al., 2024)](#). As emphasized in the best practices literature in survey research design, the use of close-ended Likert scales allows scholars to leverage the natural language capabilities of LLMs for the purposes of discrete measurement. Requesting that LLMs respond with the Likert item rather than a numerical score improves both compliance and accuracy of the generative AI responses [(Atreia et al., 2024)](#). As such, each option should be listed on a new line to elicit regular model responses [(Ziems et al., 2024)](#b73).

We use the prompts provided in Appendix A to produce assessments of AI impact on our extracted KSAs, employing our three distinct dimensions of impact: complementarity, augmentation, and substitutivity.

## LLM Model Specification

The LLM used in this process was OpenAI GPT-4o. The model was utilized on November 22, 2024. Each job in the KSA extraction and impact evaluation tasks was treated as an individual input into the RAG model. This input consisted of a query or API request containing a standardized prompt applied across all queries, along with a job-specific description that varied as different jobs were evaluated. Our model's temperature is set at the default of 1.0, enabling more diverse and creative responses. Lower temperature often limits the model's outputs to a more structured and factual format. High temperature encourages creativity. Context window refers to the maximum number of tokens used in a single request, including prompt, retrieved documents, conversation history, and generated response. The GPT-4o model we use has a context window limit of 128k tokens. Each request consists of retrieved documents, job descriptions, and the main prompt, making it challenging to predict the exact token count per request. While the retrieved documents and prompt alone typically range between 3,000 to 4,000 tokens, the addition of job descriptions significantly increases token usage, often exceeding this range. The selected input size is carefully managed to optimize retrieval relevance while preventing hallucinations, ensuring that responses remain grounded in factually rich information from our knowledge base. This aligns with findings from [Zhao et al. (2024)](#b74), who emphasize that supplementing LLMs with external data enhances factual accuracy and reduces hallucinations. System prompts are often used when a model is initiated. These prompts often define the model's behavior, tone, constraints, and role throughout the interaction, ensuring consistent responses that align with the intended use case. In our model, instead of explicitly defining the system prompt at the initiation, we incorporated into our input prompts with other contexts. The system instructions are visible this way and this allows for higher flexibility in updating our prompts.

## Results

We conduct comprehensive descriptive analyses of our system's AI impact scores across federal job serieses. This analysis provides an empirical foundation to validate the model's predictions and offers additional insights into trends affecting the federal workforce. By combining the outputs of our Retrieval-Augmented Generation (RAG) system with statistical summaries, this approach strengthens the interpretability and credibility of our study's findings. Moreover, our system produces narrative reasoning to each score to provide a more nuanced understanding of why a given component was scored as it was.

Our descriptive analysis first focuses on evaluating the average AI impact scores across three key dimensions: complementarity, augmentation, and substitutivity. These dimensions were assessed for their effects on Knowledge, Skills, and Abilities (KSAs) across different job series. The analysis also explores differences between white-collar and trade, craft, and labor (TCL) occupational categories to allow for a more nuanced understanding of how AI impacts different segments of the workforce. White-collar roles often involve information-based, analytical, and data-intensive tasks, making them more likely to benefit from generative AI's complementarity and augmentation capabilities. In contrast, TCL occupations are more manually task-oriented, where generative AI's substitutive potential may be relatively higher but still limited by the nature of physical and contextual work. This distinction ensures that workforce strategies and policy recommendations are tailored to the specific needs and characteristics of each occupational group, enabling more effective AI integration and worker adaptation.

Figures [2](#)[3](#)[4](#)provide visual representations of the data to help clarify the distribution and relationships between the three AI impact dimensions. Figure [1](#fig_0), for instance, provides ridgeline plots as a clear depiction of how our AI impact scores are distributed across KSAs and occupational categories. For each individual job series, we create an average score using all 9 individual KSA scores within each AI Impact category. We see that complementarity scores cluster at higher values, particularly for Knowledge, while augmentation and substitutivity exhibit more variability. We also plot the distribution of each AI Impact Category for White Collar jobs (Figure [3](#)) and Trade, Craft, and Labor jobs (Figure [4](#)) by categorical competency (i.e., Knowledge, Skills, and Abilities).

We show that complementarity-where AI enhances human capabilities without replacing them-had the highest mean scores across all KSAs. Augmentation scores, which reflect the degree to which AI transforms KSAs to integrate new tools and processes, were moderate, indicating a need for workers to adapt to AI-enhanced environments. Substitutivity scores, representing the potential for full automation, were the lowest, demonstrating the limited likelihood of AI replacing human labor entirely in most roles. White-collar jobs, which comprise the vast majority of federal occupations, exhibit higher scores for complementarity and augmentation, reflecting greater integration of AI in decisionmaking processes. Substitutivity scores are consistently low across both categories, further underscoring generative AI's supportive role.

These trends align closely with our expectations and suggest that generative AI primarily enhances rather than replaces human competencies in federal roles. 10 The high complementarity scores confirm the model's projection that generative AI will predominantly function as a collaborative tool in the near future, particularly in roles requiring data analysis and decision support. The moderate augmentation scores support the expectation that human workers will need to adapt their KSAs to leverage AI effectively, while the low substitutivity scores reinforce the idea that full automation remains unlikely for most federal occupations.

Figures 5-7 rank occupational series by their average scores for each respective dimension of AI impact, showing which jobs are influenced most and least by generative AI. This comparative analysis underscores that AI's impact varies significantly across white-collar occupations, with certain roles poised for high or low levels of complementarity, augmentation, and substitutivity. 11

10 In Appendix B, we provide tables that summarize the mean, standard deviation, and quartile ranges for AI impact scores across the three dimensions for Knowledge, Skills, and Abilities, reflective of the distributive graphs above.

11 We also include figures in Appendix C that rank TCL occupational series by their average scores for each respective dimension of AI impact. For instance, Figure [5](#fig_2) shows that white-collar occupations contrast across substitutivity, augmentation, and complementarity scores. Substitutivity is notably high in clerical roles such as cash processing, data transcribing, and language clerical, where AI can efficiently automate repetitive tasks, manage large volumes of structured data, and perform routine operations with high accuracy. These roles often involve predictable processes that AI can handle independently, which significantly reduces human involvement. In contrast, professions like mediation, orthotist and prosthetist, and wildlife refuge management exhibit the lowest substitutivity, as these roles require intricate problem-solving, adaptive decision-making, and nuanced physical human interaction that AI currently lacks, making it a limited tool in these complex environments. In terms of augmentation, occupations such as geology, coding, and nuclear engineering should benefit significantly from AI's capability to enhance data analysis, modeling, and technical precision. These occupations often involve intricate and large-scale datasets that require advanced computational tools for efficient processing, simulation, and analysis. AI enables faster, more accurate handling of these complex tasks, reducing human workload and minimizing errors. It creates a highly efficient collaborative environment through supporting iterative testing, data-driven decision-making, and high-dimensional problem-solving, while human experts contribute reasoning, innovative approaches, and oversight. Conversely, roles like aircraft operation and animal health technician show minimal augmentation, where AI's contributions are often limited to automation of routine tasks or data handling. In these occupations, the main workload still depends on human skills, manual operations, and on-the-spot problem-solving, with AI serving as a supplementary tool rather than a transformative force. The complementarity dimension illuminates the symbiotic potential between AI and human workers, unveiling fairly complex interactions. Fields like management and program clerical assistance, general mathematics and statistics, and bioengineering exemplify high complementarity by harnessing AI to tackle repetitive and structured tasks, freeing human workers to delve into nonlinear, abstract thinking and more nuanced decision-making. Unlike augmentation, which amplifies specific tasks, complementarity zeroes in on AI's role as a supportive backbone for human-led processes. This includes strategic management, complex research design, and adaptive problemsolving, where human creativity, ethical considerations, and contextual judgment will (at least in the short-term horizon of our model's predictions) remain relatively irreplaceable and paramount.

Professions such as police and security guard, vocational rehabilitation, and dental assistant exhibit limited complementarity. For these occupations, AI offers far less assistance, primarily through administrative support, surveillance tools, or data management systems. These roles lean heavily on human intervention for dynamic decision-making, interpersonal interactions, and specialized skills that prove elusive for AI to replicate convincingly. While generative AI's intervention can permeate background functions, these occupations will continue to hinge on human adaptability, emotional intelligence, and direct physical involvement -qualities that remain stubbornly resistant to algorithmic replication.

## High Complementarity and Augmentation, but Low Substitutivity

While AI enhances many roles through complementarity and augmentation, some occupations remain highly resistant to substitution due to their reliance on physical dexterity, hands-on expertise, and human judgment. Our evaluation results reveal interesting insights about several jobs where AI exhibits high complementarity but very low substitutivity, highlighting roles that benefit from AI support but cannot be replaced by AI's automation.

For instance, Wildlife Refuge Management (Series 0485) scores high in complementarity (4-5) and augmentation (4) due to AI's ability to assist in data collection, habitat analysis, and species monitoring. However, its substitutivity score remains very low (2), as conservation work requires onthe-ground expertise, decision-making based on unpredictable environmental factors, and direct engagement with ecosystems. AI can support decision-making but lacks the ability to perform fieldwork autonomously. Similarly, Masonry (Series 3603) and Plastering (Series 3605) benefit from AI-driven design tools that optimize construction plans and material usage, reflected in moderate complementarity (4) and augmentation (3). However, their substitutivity scores remain very low (2), as physical execution and craftsmanship remain irreplaceable. AI can suggest layouts and enhance efficiency, but it cannot replicate the manual skills required for high-quality masonry and finishing work. Another notable example is Waiters (Series 7420), where AI can complement and augment service roles through automated ordering systems, smart kitchen coordination, and workflow optimization. However, the role scores the lowest possible substitutivity score (1), emphasizing the importance of human interaction, customer service skills, and, most importantly, the physical presence of the waiter.

## Bottom-Scoring Occupations: Limited AI Impact

At the bottom of our AI impact analysis, several occupations stand out due to their inherently human-centric nature, where AI offers little complementarity, augmentation, or substitutivity. These roles often require nuanced decision-making, hands-on physical execution, or strategic adaptability beyond AI's current capabilities.

For example, Nuclear Materials Courier (Series 0084) exhibits minimal complementarity (2), augmentation (2), and substitutivity (1). Transporting highly sensitive materials requires a combination of physical security, threat assessment, and strict regulatory compliance that AI cannot yet replicate. AI can assist in route optimization and security monitoring, but the task itself remains deeply human-driven. Similarly, Cash Processing (Series 0530) exhibits minimal complementarity (2), augmentation (2), and substitutivity (1). Handling financial transactions, verifying signatures, and reconciling discrepancies require a high level of scrutiny, regulation compliance, and human oversight that AI cannot fully automate. Similarly, Language Clerical Roles (Series 1046) score low in substitutivity (2) due to the complexity of linguistic nuances, cultural understanding, and contextdriven interpretation required in translating and clerical linguistic work. While AI tools like translation software can assist, human expertise is essential for accuracy and contextual appropriateness. Position Classification and Office Administration (Series 0326) also ranks among the lowest in substitutivity (2), as these roles require human judgment in assessing organizational structures, policy compliance, and decision-making in personnel management. AI can support documentation and analysis, but final decisions require human intervention.

## AI as a Complementary Force, Not a Replacement

Our findings highlight that while AI serves as a powerful tool in data-driven and knowledgeintensive fields, its impact varies significantly across professions. High complementarity and augmentation scores in roles like engineering, conservation, and skilled trades show AI's potential to enhance efficiency and decision-making. However, the persistently low substitutivity scores in these professions reinforce the irreplaceable value of human dexterity, adaptability, and field-based expertise. As AI continues to evolve, industries must adopt a balanced integration strategyleveraging AI for its strengths in data analysis and automation while ensuring that essential human skills remain central in physically demanding, socially interactive, and judgment-based roles. Future workforce planning should emphasize AI-augmented skill development without assuming full automation in areas where human presence remains indispensable.

## Model Advantages and a Poignant Example

The primary focus of this study involves asking LLMs about the impact of AI on KSAs. While this activity may initially appear to be a Question-Answer (QA) Natural Language Processing task, traditional QA evaluation metrics-which focus on factual accuracy for objective questions or human-alignment for subjective responses-do not adequately capture our goal of assessing LLMdriven insights. QA for our purposes is a format and not an information retrieval or reading comprehension task [(Rogers et al., 2023)](#b59).

Our research intersects with two distinct LLM task categories: LLM-as-a-judge and Natural Language Inference (NLI). LLM-as-a-judge refers to the use of LLMs to natural language tasks without reference answers [(Zheng et al., 2023)](#b75). LLM assessments are scalable, explainable, and align with human assessments [(Hu et al., 2024 ;](#b35)[Desmond et al., 2024;](#b22)[Wang et al., 2023)](#b67). Our study extends this approach by requesting an explanation behind LLM decisions. This not only improves consistency [(Atreja et al., 2024)](#b5), but provides auditable data.

LLM explanations are NLI tasks, where the emphasis is on understanding logical reasoning rather than factuality or accuracy due to the multitude of possible correct answers [(Yu et al., 2024)](#b72). The key goal in NLI explanations is determining entailment (i.e., does the explanation follow from the conclusion?) [(Bowman et al., 2015)](#b12). In this context, traditional accuracy metrics-measuring alignment with human evaluators-become less relevant, as human opinions may not necessarily represent a useful standard. We want the LLM to justify its answer, that answer to make sense, and the justification to provide additional insight into the reasoning. In the following section, we provide an example of the application of our framework on the Economist occupational series.

Applying the AI Impact Framework: The Case of Public Sector Economists

The role of economists is increasingly shaped by AI. While AI significantly enhances technical and computational tasks, human expertise remains for interpretation, strategic decision-making, and policy influence. In Figure [7](#fig_4), we provide the Likert-scale output for each of our dimensions of impact across all 9 of the predominant KSAs identified by our model. We then provide a sample of the one-sentence justifications our trained model uses for these scores to exhibit the construct validity of our model. In Appendix D, we exhibit the consistency of our model's outputs to observations made in the emerging scholarship that explores the impact of generative AI technologies in the field of economics. As reflected in Figure [8](#fig_5), Statistical Theory and Data Analysis are areas where AI excels in complementing (5) economists' work, though it varies in its substitutive impact. For instance, our AI system justified the complementarity score in its explanation for Data Analysis as "AI excels in data analysis, enabling faster and more precise manipulation of large datasets, which complements human skills in interpretation and decision-making." Our system suggests a substitutivity score of 4 as "AI excels in data manipulation and statistical analysis, offering high substitutivity in data analysis tasks" This provides a salient example of how our dimensions of impact are not completely separable in practice but remain distinct conceptually. AI can complement a competency in some ways and simultaneously substitute or augment aspects of the same competency. At other times, these dimensions can be much more practicably separable. For instance, Economic Principles was scored at 4 in complementarity, with our model justifying this as "AI provides simulations and data analysis tools that support economic understanding." However, its substitutivity remains low (2) because "interpreting economic principles requires contextual knowledge and adaptability that AI lacks."

Similarly, the knowledge base competency in Economic Institutions received 3 in complementarity and 2 in augmentation. Here, the moderate complementarity explanation was framed in terms of human judgement as "AI can assist in understanding economic institutions by providing comprehensive data analysis, though human judgment is crucial for context and insight." The lower augmentation score, on the other hand, was justified according to a separate aspect of that knowledge base, emphasizing the importance of contextual understanding: "While AI can assist in gathering and organizing information about economic institutions, the nuanced understanding and contextual analysis still heavily rely on human knowledge."

It is these nuances that illustrate the multifaceted nature of AI's impact on occupational competencies. AI's contributions are not strictly categorical but instead operate along a spectrum where complementarity, augmentation, and substitutivity interact in complex ways. While AI can enhance the efficiency of specific technical tasks, the interpretative and strategic elements of economic expertise remain deeply human-driven.

This interplay highlights the necessity of distinguishing between different forms of impact when assessing AI's role in professional domains. For example, even within a single competency, AI's ability to process vast amounts of data may serve as a strong complement to human decisionmaking, while its limited capacity for contextual reasoning prevents it from fully substituting human expertise. These dynamics suggest that AI's integration into the field of economics will likely continue to emphasize augmentation and complementarity rather than outright substitutionparticularly in tasks requiring adaptive judgment, critical thinking, and ethical considerations.

Ultimately, the model's distinctions between complementarity, augmentation, and substitutivity provide a structured framework for understanding AI's influence on occupational roles. The NLIgenerated justifications provide construct validation that also reveals how these dimensions often overlap in real-world application, reinforcing the importance of continual evaluation as AI technologies evolve and integrate further into professional practice. Our findings are consistent with recent insights on AI's impact on practice and further validate our approach as an apt method to "heatmap" organizations and occupational vulnerabilities and opportunities presented by the emergence of generative AI technologies.[foot_4](#foot_4)

## Discussion

Our dynamic and iterative model addresses limitations identified in prior research by incorporating detailed competency data and accounting for the evolving capabilities of generative AI. By continuously updating according to the newest developments in AI technologies and the changing landscape of required competencies and KSAs (Knowledge, Skills, and Abilities), we ensure that our forecasts remain current and relevant. By weighting AI impacts according to validated competency ratings, we provide a nuanced forecast that accounts for the unique nature of federal jobs. This adaptive approach enhances the reliability of predictions and supports evidence-based decisionmaking.

The integration of generative AI considerations is necessary, as these technologies have accelerated the potential for automation in areas previously considered secure. As these technological interventions gain traction, our model constantly updates to reflect the specific tasks and competencies affected. This enables organizations to develop targeted strategies for reskilling and upskilling employees in a timely manner.

Furthermore, our findings emphasize the importance of emphasizing and developing complementary competencies that cannot be replicated by AI, such as critical thinking, ethical judgment, and complex problem-solving. By acknowledging the continuous evolution of AI and its impact on required competencies, our model aligns with the concept of human-AI collaboration, where AI augments human capabilities rather than replaces them. This dynamic approach ensures organizations are prepared to adapt to the ever-changing technological landscape.

While beyond the scope of this manuscript, evaluation of LLM outputs is critical to developing a robust knowledge base of synthetically generated data while also meeting the rigorous criteria for social science research. Future manuscripts will systematically evaluate the output's reliability and validity rooted in measurement theory [(Xiao et al., 2023;](#)[Wallach et al., 2024)](#b66). While an excellent start, LLM outputs benefit from additional evaluation that is not relevant to human subjects. The justifications provided by the LLMs allow for a rigorous and systematic evaluation of the quality of outputs [(Hu et al., 2024)](#b35). Quality evaluation criteria focus on assessing readability (quality of the output's language elements) and adequacy (quality of the output's task elements) of LLM outputs. Quality evaluations provide additional robustness checks that also serve as a value that can be compared with outputs from other LLMs. In addition to reliability, validity, and quality evaluations; we will want to test for entailment or whether the conclusion (i.e., the score from the model) is the logical conclusion reached from the justification [(Liu et al., (2023)](#). Entailment provides an assessment of the NLI capabilities of the model. In lieu of "ground truth", quality and entailment evaluations support the merit of LLM outputs.

In addition, we will soon expand this analysis so that it is run across multiple open-source LLMs.

Rerunning and refining the analysis across multiple open-source models enables both an assessment of LLM inter-rater reliability and a comparative analysis of similarities and differences in the model's assessments. A multi-model approach will shed light on how variations in architectural design, training data composition, and ethical alignment protocols influence model behavior. This comparative lens will help distinguish between universal trends in LLM reasoning and idiosyncrasies tied to individual models. The findings presented in this study establish a critical baseline, offering a reference point for tracking the evolution of LLM capabilities and limitations as the technology advances.

## Conclusion

We demonstrate the effectiveness of a sophisticated RAG-system tailored to the unique demands of the federal civil service labor market. By leveraging the U.S. federal government as a prototype due to its size, diversity, and standardized competency frameworks, we have developed a replicable methodology that offers valuable insights for organizations navigating AI integration. However, the true power of this approach lies in its adaptability across different competency frameworks, allowing organizations to apply NLP and AI techniques with standardized descriptions and ratings.

Moreover, by training domain-specific models using industry-relevant job descriptions and competencies, organizations can capture nuanced linguistic elements essential for their sectors. The customization of AI agents can be further enhanced by incorporating industry-specific technological trends and economic factors, ensuring that the methodology aligns with regulatory and ethical considerations pertinent to each organization's context. This nuanced approach not only provides a comprehensive framework for assessing AI's impact on occupation labor markets but also accommodates the specificities of institutional expectations, contributing significantly to the broader discourse on workforce transformation across both public and private sectors.

Our study also highlights the importance of refining semantic representations through validated competency and task ratings, which serve as a ground truth for significance and proficiency levels. By comparing our findings with competency models from other sectors, we validate the universality of our approach. Additionally, our multi-level analysis allows for agency-level insights, enabling tailored recommendations that address the unique challenges and priorities within different federal organizations. This level of customization underscores the potential for our methodology to be applied broadly, offering a valuable tool for organizations seeking to navigate the evolving landscape of AI integration and workforce transformation.

Ultimately, this research provides insights that can be applied across various sectors, enhancing the adaptability and effectiveness of AI integration strategies. By embracing this approach, organizations can better align their workforce development with the dynamic needs of their respective industries, fostering a more resilient and adaptable workforce in the face of technological change. Finally, our work demonstrates that while AI can significantly enhance and, in some cases, substitute specific tasks, the nuanced interplay between complementarity, augmentation, and substitutivity underscores the enduring value of human expertise. By systematically assessing AI's impact on occupational competencies, our findings highlight the folly of assuming widespread replacement of human employees, revealing instead a more complex reality in which AI reshapes roles rather than rendering them obsolete.

You are an expert analyst specializing in evaluating and predicting the impact of generative AI over the next five years on occupations within the United States federal government. You evaluate the impact of generative AI on KSAs for different job series. The overall impact of generative AI can be assessed by different underlying dimensions. For the following task, you will evaluate strictly on the dimension of Augmented Intelligence.

Definition of Augmented Intelligence:

Augmented intelligence refers to the impact of AI that requires a transformation of human capacities. It involves integrating AI in a way that necessitates changes in knowledge, skills, abilities (KSAs), or tasks to improve decision-making while still maintaining human involvement. The focus is on the extent of necessary evolution of human cognitive KSAs to integrate AI.

Task:

For each of the given Knowledge, Skills, Abilities, assess how generative AI will impact the job role in terms of augmented intelligence within a five-year window from today.

Instructions:

Provide a score from 1 to 5 for each KSA :

Augmentation Score: 1 (No Augmentation) to 5 (High Augmentation) **For each score, write a brief explanation (1-2 sentences) justifying your assessment, focusing on how generative AI requires changes in human input.

Formatting Guidelines:

Do not use markdown formatting, bullet points, or any special characters in your response.

Strictly adhere to the format provided below:

Augmentation: Score Explanation Additionally, provide your response in the following JSON format: { "augmentation_score": "<score from 1 to 5>", "assessment": "<brief explanation>" }

Table B2. Descriptive Statistics by Occupational Family Mean SD Min Q1 Median Q3 Max White Collar Complementarity 3.46 0.41 2.00 3.33 3.33 3.67 4.67 Augmentation 3.13 0.43 2.00 3.00 3.00 3.33 4.67 Substitutivity 2.66 0.51 1.33 2.33 2.67 3.00 4.33 Trade, Craft and Labor Complementarity 3.18 0.46 1.67 3.00 3.33 3.33 4.67 Augmentation 2.77 0.49 1.33 2.33 2.67 3.00 4.00 Substitutivity 2.50 0.44 1.00 2.33 2.33 2.67 3.67

prevalent. AI augments these jobs by automating mundane tasks and improving the speed and accuracy of data analysis. However, in areas that require human judgment, interpretation, or creativity, AI functions as a complementary tool rather than a replacement. These findings support the broader scholarly consensus that while AI has the potential to significantly reshape many occupations, human expertise remains essential, particularly in roles where decision-making and contextual understanding are critical [(Autor, 2015;](#b6)[Brynjolfsson & McAfee, 2014)](#b14). The balance between automation and augmentation underscores the varied nature of AI's impact across different types of federal government occupations.

![Figure 1. Multi-Stage RAG-Enhanced LLM Methodology for Competency Extraction and AI Impact Assessment]()

![Figure 2. Distribution of AI Impact Scores Across KSAs and Occupational Categories]()

![Figure 5: Ranking of White-Collar Occupations by Substitutivity Score]()

![Figure 6: Ranking of White-Collar Occupations by Augmentation Score]()

![Figure 7: Ranking of White-Collar Occupations by Complementarity Score]()

![Figure 8. Economist Series (0110) Broken Out by Competencies and AI Impact Scores]()

![]()

![]()

https://www.opm.gov/data/resources/ai-guidance/

https://github.com/ombegov/2024-Federal-AI-Use-Case-Inventory

Ibid.

Ibid.

See Appendix D for a summary of recent insights on AI's impact on the general economist occupation, as an example of the consistency of our model with recent developments in the field.

