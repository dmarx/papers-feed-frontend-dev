- Decision to define the problem as Zero-Shot Tokenizer Transfer (ZeTT)
- Choice of using a hypernetwork for embedding prediction
- Selection of tokenization granularity (subword tokenizers)
- Decision to focus on UnigramLM parametrization for experiments
- Choice of baseline heuristic (FOCUS) for comparison
- Decision to evaluate performance on cross-lingual and coding tasks
- Assumption about the generalizability of the hypernetwork across different tokenizers
- Decision to allow continued training on a small amount of tokens to close performance gaps
- Choice of models for empirical demonstration (e.g., XLM-R, Mistral-7B)
- Decision to make code and models publicly available
- Assumption regarding the efficiency of the hypernetwork approach compared to traditional methods
- Decision to explore the application of the hypernetwork to fine-tuned model variants
- Choice of evaluation metrics for performance assessment
- Decision to utilize a diverse distribution of tokenizers for hypernetwork training
- Assumption about the impact of tokenization on inference cost and performance
- Decision to investigate the effects of embedding initialization heuristics on ZeTT performance
- Choice of training methodology for the hypernetwork (e.g., training loop specifics)
- Decision to analyze the implications of tokenizer transfer on model ensembling and merging
- Assumption about the limitations of existing methods for n-shot tokenizer transfer
- Decision to document the findings and methodologies for future reference and reproducibility