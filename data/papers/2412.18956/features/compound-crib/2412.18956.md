The researchers' decisions regarding the core hypothesis and its supporting arguments are grounded in a comprehensive understanding of historical context, scalability challenges, and the evolving landscape of information seeking. Below is a detailed technical explanation and rationale for each aspect of their argument.

### Core Hypothesis
**Hypothesis**: The future of search should return to direct expert engagement, enhanced by large language models (LLMs) to overcome scalability challenges.

**Rationale**: The hypothesis posits that the most effective way to address information needs is through direct interaction with experts. This approach is rooted in historical practices where knowledge was transmitted orally. The integration of LLMs is proposed as a means to scale this interaction, allowing for a more personalized and dynamic exchange of information, akin to the direct conversations of preliterate societies.

### Historical Context
**Context**: Preliterate societies relied on direct conversations with experts for information seeking; writing emerged ~5000 years ago, enabling knowledge materialization.

**Rationale**: The historical perspective emphasizes that the foundational method of knowledge transfer was through direct human interaction. The advent of writing marked a significant shift, allowing knowledge to be documented and shared across time and space. This context is crucial for understanding the limitations of current search paradigms, which primarily rely on static content.

### Scalability Challenges
1. **Bandwidth Limitation**: Experts can only engage in a limited number of conversations daily due to other responsibilities.
   
   **Rationale**: This limitation highlights the inherent constraints of human interaction. Experts, regardless of their knowledge, have finite time and energy, which restricts their ability to engage with multiple information seekers simultaneously.

2. **Finding Experts**: As populations grow, identifying and accessing relevant experts becomes increasingly difficult (Dunbar's number).

   **Rationale**: Dunbar's number suggests a cognitive limit to the number of stable social relationships one can maintain, which directly impacts the ability to connect with experts. As societies expand, the challenge of locating and accessing the right expert becomes more pronounced, necessitating a scalable solution.

### Materialization of Knowledge
**Concept**: Writing allowed knowledge to be preserved and replicated, solving the bandwidth issue and enabling wider dissemination.

**Rationale**: The materialization of knowledge through writing addressed the limitations of oral transmission by allowing information to be stored and shared without the constraints of time and geography. This advancement facilitated the development of various technologies and systems for knowledge retrieval, ultimately leading to the modern search engine.

### Sub-optimal User Experience
**Observation**: Static content (books, articles) limits interaction; users cannot engage in follow-up discussions or clarifications.

**Rationale**: The static nature of written content creates a barrier to effective information seeking. Users often require clarification or deeper engagement, which static content cannot provide. This limitation underscores the need for a more interactive approach to information retrieval.

### Search Evolution
**Evolution**: Traditional search engines connect users to materialized proxies of knowledge (e.g., webpages), but do not facilitate direct expert interaction.

**Rationale**: Traditional search engines have evolved to surface relevant content but have not addressed the fundamental need for direct engagement with experts. This gap in the search experience highlights the potential for LLMs to fill this void by simulating expert interactions.

### LLMs as Expert Avatars
**Proposal**: Future interactions may involve conversing with LLMs representing experts, providing a more dynamic and personalized experience.

**Rationale**: LLMs can serve as avatars for experts, enabling users to engage in conversations that mimic direct expert interaction. This approach leverages the strengths of LLMs in natural language processing to create a more engaging and responsive information-seeking experience.

### Economic Viability of LLMs
**Observation**: The marginal cost of replicating LLMs is decreasing (estimated 10Ã— reduction per year), leading to a proliferation of specialized models.

**Rationale**: The decreasing costs associated with LLM deployment make it economically feasible to create and maintain a diverse array of specialized models. This proliferation can enhance the availability of expert knowledge across various domains, addressing the scalability challenges identified earlier.

### Reimagining Search
**Concept**: The search paradigm must evolve from finding documents to facilitating interactions with LLM experts capable of performing tasks.

**Rationale**: The shift from static content retrieval to dynamic interactions with LLMs represents a fundamental rethinking of the search process. This evolution aligns with the ultimate goal of information seeking, which often involves taking action based on the information obtained.

### Outcome of Information Seeking
**Goal**: The ultimate goal of information seeking is often action-oriented, where LLMs can assist directly in fulfilling user needs beyond mere information retrieval.

**Rationale**: Recognizing that users often seek information to inform actions emphasizes the need for a search paradigm that facilitates not just retrieval but also practical application. LLMs can bridge this gap by providing tailored assistance that goes beyond traditional search capabilities.

### Future Considerations
**Consideration**: The search paradigm must adapt to a landscape with millions of