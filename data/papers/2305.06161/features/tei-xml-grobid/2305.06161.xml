<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">StarCoder: may the source be with you!</title>
				<funder ref="#_nu9QAzB #_7adeUSw">
					<orgName type="full">U.S. National Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2023-12-13">13 Dec 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Raymond</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Loubna</forename><forename type="middle">Ben</forename><surname>Allal</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yangtian</forename><surname>Zi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Niklas</forename><surname>Muennighoff</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Denis</forename><surname>Kocetkov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chenghao</forename><surname>Mou</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Marc</forename><surname>Marone</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Christopher</forename><surname>Akiki</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Leipzig University</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">ScaDS.AI 11 Queen Mary</orgName>
								<orgName type="institution">University of London</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jia</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jenny</forename><surname>Chim</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Qian</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Evgenii</forename><surname>Zheltonozhskii</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Terry</forename><surname>Yue Zhuo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Olivier</forename><surname>Dehaene</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mishig</forename><surname>Davaadorj</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Joel</forename><surname>Lamy-Poirier</surname></persName>
						</author>
						<author>
							<persName><forename type="first">João</forename><surname>Monteiro</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Oleh</forename><surname>Shliazhko</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nicolas</forename><surname>Gontier</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nicholas</forename><surname>Meade</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Armel</forename><surname>Zebaze</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ming-Ho</forename><surname>Yee</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Logesh</forename><surname>Kumar Umapathi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jian</forename><surname>Zhu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Benjamin</forename><surname>Lipkin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Muhtasham</forename><surname>Oblokulov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zhiruo</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rudra</forename><surname>Murthy</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jason</forename><surname>Stillerman</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Siva</forename><surname>Sankalp</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dmitry</forename><surname>Abulkhanov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Marco</forename><surname>Zocca</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Manan</forename><surname>Dey</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zhihan</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nour</forename><surname>Fahmy</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Urvashi</forename><surname>Bhattacharyya</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wenhao</forename><surname>Yu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Swayam</forename><surname>Singh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sasha</forename><surname>Luccioni</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Paulo</forename><surname>Villegas</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Maxim</forename><surname>Kunakov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Fedor</forename><surname>Zhdanov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Manuel</forename><surname>Romero</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tony</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nadav</forename><surname>Timor</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jennifer</forename><surname>Ding</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Claire</forename><surname>Schlesinger</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hailey</forename><surname>Schoelkopf</surname></persName>
							<affiliation key="aff4">
								<address>
									<settlement>Eleuther AI 38 Forschungszentrum Jülich</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jan</forename><surname>Ebert</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tri</forename><surname>Dao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mayank</forename><surname>Mishra</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Alex</forename><surname>Gu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jennifer</forename><surname>Robinson</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Carolyn</forename><forename type="middle">Jane</forename><surname>Anderson</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Brendan</forename><surname>Dolan-Gavitt</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Danish</forename><surname>Contractor</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Siva</forename><surname>Reddy</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Fried</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Carlos</forename><forename type="middle">Muñoz</forename><surname>Ferrandis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sean</forename><surname>Hughes</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Arjun</forename><surname>Guha</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Leandro</forename><surname>Von Werra</surname></persName>
						</author>
						<author>
							<persName><forename type="first">⋆</forename><surname>Harm De Vries</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hugging</forename><surname>Face</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Servicenow</forename><surname>Research</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Northeastern</forename><surname>University</surname></persName>
						</author>
						<title level="a" type="main">StarCoder: may the source be with you!</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-12-13">13 Dec 2023</date>
						</imprint>
					</monogr>
					<idno type="MD5">48606538D626FB2B19816729FC262C97</idno>
					<idno type="arXiv">arXiv:2305.06161v2[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-02-21T16:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The BigCode community, an open-scientific collaboration working on the responsible development of Large Language Models for Code (Code LLMs), introduces StarCoder and StarCoderBase: 15.5B parameter models with 8K context length, infilling capabilities and fast large-batch inference enabled by multi-query attention. StarCoderBase is trained on 1 trillion tokens sourced from The Stack <ref type="bibr" target="#b51">(Kocetkov et al., 2022)</ref>, a large collection of permissively licensed GitHub repositories with inspection tools and an opt-out process. We fine-tuned StarCoderBase on 35B Python tokens, resulting in the creation of StarCoder. We perform the most comprehensive evaluation of Code LLMs to date and show that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model. Furthermore, StarCoder outperforms every model that is fine-tuned on Python and still retains its performance on other programming languages. We take several important steps towards a safe open-access model release, including an improved PII redaction pipeline and a novel attribution tracing tool, and make the StarCoder models publicly available under a more commercially viable version of the Open Responsible AI Model license.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Generative AI and large language models (LLMs; <ref type="bibr">Brown et al., 2020;</ref><ref type="bibr" target="#b23">Chen et al., 2021;</ref><ref type="bibr">Chowdhery et al., 2022;</ref><ref type="bibr" target="#b115">Zhang et al., 2022;</ref><ref type="bibr">OpenAI, 2023a)</ref> are predicted to significantly impact the workforce in the coming years <ref type="bibr" target="#b29">(Eloundou et al., 2023;</ref><ref type="bibr" target="#b16">Bommasani et al., 2021;</ref><ref type="bibr">World Economic Forum, 2023)</ref> by boosting worker productivity. LLMs trained on code (Code LLMs) have seen particularly fast adoption: Microsoft's Copilot has attracted over 1 million professional developers <ref type="bibr" target="#b30">(Euronews, 2023)</ref> and GitHub reports that Copilot users rely on it to produce 35% of the code they write for some languages <ref type="bibr" target="#b98">(Thompson, 2022)</ref>. However, the development and use of LLMs has raised concerns of copyright, privacy, and openness.</p><p>Copyright concerns arise in many jurisdictions, including the U.S. and E.U. , regarding the rights of content creators whose public data is used to train language models. It has been questioned whether machine learning models trained on such data fall under fair-use doctrine in the U.S. <ref type="bibr" target="#b53">(Kuhn, 2022;</ref><ref type="bibr" target="#b21">Butterick, 2022;</ref><ref type="bibr" target="#b90">Rothchild &amp; Rothchild, 2022)</ref>, with fair use being most likely when the model generates novel content dissimilar to any copyrighted training data <ref type="bibr" target="#b59">(Lemley &amp; Casey, 2020;</ref><ref type="bibr" target="#b60">Levendowski, 2018)</ref>. <ref type="bibr" target="#b39">Henderson et al. (2023)</ref>, therefore, suggest LLM developers should provide additional tools to ensure these models comply with current copyright laws. It is important to mention that these legal issues are not only the subject of scholarly debates: lawsuits have already been filed against GitHub Copilot <ref type="bibr">(DOE 1 v. and GitHub, Inc., 2022)</ref> as well as Stable Diffusion <ref type="bibr">(Andersen et al v. Stability AI et al, 2023)</ref>.</p><p>Concerns about personal information led Italy to temporarily ban ChatGPT and launch an ongoing investigation into OpenAI's compliance with the E.U.'s General Data Protection Regulation (GDPR) <ref type="bibr" target="#b8">(BBC, 2023)</ref>. According to these regulations <ref type="bibr" target="#b31">(European Council, 2018;</ref><ref type="bibr" target="#b64">Lomas, 2022)</ref>, organizations that process personal information must have a valid legal basis. These laws could potentially affect LLM developers who gather vast amounts of public data from the internet, which may include personal information. Obtaining explicit consent from data creators is difficult at this scale, and it is uncertain whether other legal grounds exist for processing this personal information. Moreover, even with a valid legal basis, GDPR mandates that data processors inform individuals as to how their data is being processed and provide data access controls, such as the right to have data deleted or to modify erroneous data. This would require LLM providers to be transparent about the data they have collected and provide tooling for individuals to inspect their data and have the possibility to delete it.</p><p>The lack of transparency and openness surrounding the development processes of generative AI models has also raised concerns in the scientific community. Many models are closed-access to varying degrees: from being available only within the organization that developed them <ref type="bibr">(Chowdhery et al., 2022;</ref><ref type="bibr" target="#b42">Hoffmann et al., 2022)</ref> to being accessible publicly through a paid API but with many details on their development process hidden <ref type="bibr">(Brown et al., 2020;</ref><ref type="bibr">OpenAI, 2023a)</ref>. While API access allows researchers to experiment with these models, it limits their ability to research LLM safety <ref type="bibr" target="#b83">(Perez et al., 2022)</ref>, inspect the models' inner workings <ref type="bibr" target="#b78">(Olsson et al., 2022)</ref>, and contribute to model improvements <ref type="bibr" target="#b100">(Togelius &amp; Yannakakis, 2023)</ref>.</p><p>We use "open-access" to refer to models whose weights are public. Although other open-access models exist, the level of openness still varies across these projects; and some models with released weights have restrictions on model distribution <ref type="bibr" target="#b101">(Touvron et al., 2023)</ref>, or do not release their training datasets <ref type="bibr" target="#b77">(Nijkamp et al., 2023;</ref><ref type="bibr" target="#b115">Zhang et al., 2022;</ref><ref type="bibr" target="#b33">Fried et al., 2022)</ref>. Even in cases when models and training data are both released permissively <ref type="bibr" target="#b88">(Raffel et al., 2020;</ref><ref type="bibr" target="#b97">Tay et al., 2022)</ref>, external researchers typically do not have an opportunity to participate in guiding the development of industry-produced models. In contrast, other LLM development projects have taken a fully open approach which aims to allow for community inputs into model development, release training data, and enable external audits throughout the full development process <ref type="bibr" target="#b96">(Solaiman, 2023)</ref>. One example is the BigScience research workshop <ref type="bibr">(BigScience Workshop, 2022)</ref>, an open scientific collaboration <ref type="bibr" target="#b92">(Akiki et al., 2022)</ref> comprising hundreds of researchers collaborating to release BLOOM, a multi-lingual LLM <ref type="bibr">(Scao et al., 2022;</ref><ref type="bibr" target="#b74">Muennighoff et al., 2022)</ref>. Similarly, EleutherAI, a grassroots-turned-nonprofit research initiative, has released open-access LLMs including GPT-NeoX <ref type="bibr" target="#b14">(Black et al., 2022)</ref>, GPT-J <ref type="bibr" target="#b105">(Wang &amp; Komatsuzaki, 2021)</ref>, and Pythia <ref type="bibr" target="#b12">(Biderman et al., 2023)</ref>, as well as the associated training data <ref type="bibr">(Gao et al., 2021a)</ref>.</p><p>In this paper, we describe StarCoder and StarCoderBase, open-access code LLMs developed and released by the BigCode community, with a focus on respecting copyright, privacy, transparency, and community-driven</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Programming Languages</head><p>Selection of programming languages From the 358 programming languages in The Stack, we selected 86 languages. The assignment of data to programming languages was performed based solely on file extension <ref type="bibr" target="#b51">(Kocetkov et al., 2022)</ref>. We included all programming languages with more than 500 MB of data, as well as languages that were ranked in the top 50 on Githut 2.0 or the December 2022 TIOBE Index of programming language popularity. In addition, we included dialects of already selected programming languages (e.g., Racket and Scheme for Lisp). We excluded configuration languages <ref type="bibr">(Nix, Puppet, etc.)</ref> and languages that are no longer actively supported (ActionScript). We also included data formats like JSON and YAML but limited its data volume (see "JSON and YAML" paragraph for details). The full list of selected programming languages can be found in Tables <ref type="table">1</ref> and <ref type="table">2</ref>. Out of the languages present in MultiPL-E <ref type="bibr" target="#b22">(Cassano et al., 2023)</ref>, only D and Swift were not included in the training set. For D, language misclassification of the files led to less than 2MB of data in The Stack <ref type="bibr" target="#b51">(Kocetkov et al., 2022)</ref>. Swift was excluded from the final list of languages due to human error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Visual inspection</head><p>We performed a visual inspection to ensure that we only retain data of high quality. To achieve this, we randomly selected 30,000 files from The Stack for each programming language, categorized them by extension, and kept a maximum of 1,000 files for each extension. We then reached out to our community for assistance with data inspection. We instructed the annotators to go through 50-100 files and confirm if the data appeared to be normal code written by humans, as opposed to text, data, or a single long line of autogenerated code. We also asked annotators to determine whether we should use our default alpha-numeric filter (which requires over 25% alpha-numeric symbols) and long-line filter (which requires lines to be less than 1,000 characters) for a given file extension. Eighteen community annotators evaluated 300 programming language extensions. After inspection, we excluded 36 extensions and eliminated the long-line filter for 27 extensions. The complete outcomes of the data inspection, including annotator remarks, can be found in this Google sheet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>XML filter</head><p>As we inspected the data, we noticed that certain extensions often consisted of XML files. For example, the .sld extension had more than 50% of its files in XML format. To address this, we implemented a simple XML filter that checked for the presence of "&lt;?xml version=" within the first 100 characters of the file. This filter proved to be effective and produced few false positives. Hence, we applied it to all programming languages except for XSLT, which uses XML syntax.</p><p>Alpha filter During our investigation, we discovered that certain extensions, such as MATLAB, contained numerous data files that frequently stored large tensors. To identify these files, we developed an alpha filter that removed files with fewer than 25% alphabetic characters. However, when we tested this filter on a small subset of data, we observed a high rate of false positives for certain programming languages, such as Assembly. To address this issue, we focused on the 25 extensions with the highest number of detections and manually verified whether or not the alpha filter should be applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HTML</head><p>We designed a custom HTML filter that targets excessive HTML boilerplate and links. We took into account the ratio of visible text in each file and only kept those files where the visible text makes up at least 20% of the HTML code and has a minimum length of 100 characters.</p><p>JSON and YAML JSON and YAML files are naturally more data-heavy than other languages in The Stack. To remove most of the data files, we applied the following filters. For YAML, we kept files with 50-5000 characters, an average line length smaller than 100, a maximum line length smaller than 1000, and more than 50% alphabetic characters. These filters remove around 20% of the files and 90% of the volume. For JSON, we kept files with 50-5000 characters and more than 50% alphabetic characters, which removes around 70% of the files and 98% of the volume.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language</head><p>After dedup After filters and decont.</p><p>Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ada 31,291 0.30 30,934 0.26 0.26 0.034 agda 17,608 0.07 17,554 0.07 0.07 0.009 alloy 5,374 0.01 5,368 0.01 0.01 0.001 antlr 7,983 0.05 7,917 0.05 0.05 0.007 applescript 4,906 0.01 4,737 0.01 0.01 0.001 assembly 248,396 1.58 247,919 1.56 1.56 0.203 augeas 195 0.00 180 0.00 0.00 0 awk 10,430 0.02 10,289 0.02 0.02 0.003 batchfile 252,514 0.29 239,568 0.23 0.23 0.03 bluespec 5,940 0.03 5,928 0.03 0.03 0.004 c 8,625,559 57.43 8,536,791 53.89 53.89 7.027 c-sharp 10,839,399 46.29 10,801,285 44.66 44.66 5.823 clojure 126,191 0.49 125,163 0.46 0.46 0.06 cmake 186,517 0.45 186,375 0.45 0.45 0.059 coffeescript 227,889 0.69 226,209 0.64 0.64 0.083 common-lisp 101,370 1.68 98,733 1.40 1.40 0.183 cpp 6,377,914 50.89 6,353,527 48.92 48.92 6.379 css 2,994,829 22.61 2,721,616 11.93 3.00 0.391 cuda 58,355 0.59 58,151 0.56 0.56 0.073 dart 932,583 3.86 928,415 3.66 3.66 0.477 dockerfile 572,186 0.42 571,506 0.42 0.42 0.055 elixir 282,110 0.74 281,016 0.71 0.71 0.093 elm 62,861 0.34 62,033 0.30 0.30 0.039 emacs-lisp 54,768 0.43 52,838 0.41 0.41 0.053 erlang 99,368 0.73 98,447 0.70 0.70 0.091 f-sharp 127,161 0.90 124,066 0.61 0.61 0.08 fortran 165,446 1.84 158,792 1.78 1.78 0.232 glsl 175,576 0.57 167,701 0.40 0.40 0.052 go 4,730,461 25.74 4,700,526 23.78 23.78 3.101 groovy 251,627 0.94 250,834 0.91 0.91 0.119 haskell 544,969 2.36 541,454 2.23 2.23 0.291 html 9,533,367 146.76 3,299,965 29.36 29.36 3.828 idris 8,060 0.03 8,042 0.03 0.03 0.004 isabelle 5,086 0.09 5,001 0.08 0.08 0.01 java 20,151,565 89.30 20,071,773 86.94 86.94 11.336 java-server-pages 214,133 1.03 210,816 0.98 0.98 0.128 javascript 21,108,587 141.65 19,544,285 64.71 64.71 8.437 json 17,012,912 338.34 4,751,547 5.62 1.00 0.13 julia 298,672 1.54 295,364 1.31 1.31 0.171 kotlin 2,242,771 5.77 2,239,354 5.68 5.68 0.741 lean 16,891 0.10 16,870 0.09 0.09 0.012 literate-agda 523 0.01 523 0.01 0.01 0.001 literate-coffeescript 1,138 0.01 1,133 0.01 0.01 0.001 literate-haskell 6,135 0.05 6,104 0.05 0.05 0.007 lua 558,861 3.28 549,459 2.87 2.87 0.374 makefile 661,424 1.49 657,349 1.31 1.31 0.171 maple 1,259 0.01 1,152 0.01 0.01 0.001 markdown 21,045,171 75.25 21,029,287 74.93 74.93 9.77 mathematica 26,895 1.72 22,653 1.25 1.25 0.163 matlab 967 0.04 93 0.00 0.00 0 Table 1: Overview of the training data for StarCoder. For the selected programming languages, we show the number of files and data volume after near-deduplication, as well as after filtering. See also Table 2. Language After dedup After filters and decont. Weight Percentage Num. files Volume (GB) Num. files Volume (GB) ocaml 159,734 1.11 158,356 1.03 1.03 0.134 pascal 118,675 1.71 110,981 1.68 1.68 0.219 perl 392,108 2.63 365,491 2.23 2.23 0.291 php 15,904,518 66.84 15,683,017 60.89 60.89 7.939 powershell 271,487 1.25 267,627 1.12 1.12 0.146 prolog 1,023 0.01 968 0.01 0.01 0.001 protocol-buffer 98,246 0.44 97,167 0.31 0.31 0.04 python 12,962,249 64.30 12,866,649 60.40 60.40 7.875 r 39,194 0.30 39,042 0.30 0.30 0.039 racket 4,201 0.04 3,688 0.03 0.03 0.004 restructuredtext 905,679 3.42 896,880 3.32 3.32 0.433 rmarkdown 5,389 0.06 5,386 0.06 0.06 0.008 ruby 3,405,374 7.14 3,390,320 6.81 6.81 0.888 rust 1,386,585 9.53 1,380,468 9.11 9.11 1.188 sas 9,772 0.13 9,226 0.12 0.12 0.016 scala 1,362,426 4.86 1,355,788 4.69 4.69 0.612 scheme 44,261 0.30 41,890 0.20 0.20 0.026 shell 2,236,434 3.38 2,206,327 3.09 3.09 0.403 smalltalk 592,999 0.74 587,748 0.58 0.58 0.076 solidity 164,242 1.21 153,194 0.85 0.85 0.111 sparql 14,173 0.04 13,716 0.04 0.04 0.005 sql 994,019 12.22 975,420 11.09 11.09 1.446 stan 5,441 0.01 5,429 0.01 0.01 0.001 standard-ml 48,995 0.52 19,630 0.19 0.19 0.025 stata 31,282 0.41 24,208 0.33 0.33 0.043 systemverilog 46,915 0.41 46,270 0.39 0.39 0.051 tcl 50,579 0.40 49,335 0.35 0.35 0.046 tcsh 4,911 0.02 4,806 0.02 0.02 0.003 tex 547,888 5.44 522,778 5.20 5.20 0.678 thrift 4,663 0.01 4,661 0.01 0.01 0.001 typescript 10,637,070 28.82 10,547,331 26.52 26.52 3.458 verilog 77 0.001 75 0.001 0.001 0 vhdl 60,027 1.12 58,208 0.94 0.94 0.123 visual-basic 163,291 1.49 161,239 1.42 1.42 0.185 xslt 43,095 0.56 6,513 0.05 0.05 0.007 yacc 25,775 0.41 7,451 0.11 0.11 0.014 yaml 5,282,081 28.36 3,995,948 3.76 1.00 0.13 zig 15,913 0.18 15,850 0.18 0.18 0.023 GitHub issues ∼ 30,900,000 54.40 54.40 7.093 Git commits 7,674,345 64.00 32.00 4.172 notebook scripts 914,000 7.12 7.12 0.928 notebook structured 668,743 6.00 6.00 0.782 305,929,658 815.68 799.37 100</p><p>Table 2: Overview of the training data for StarCoder. For the selected programming languages, we show the number of files and data volume after near-deduplication, as well as after filtering. See also Table 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Jupyter notebooks</head><p>All Jupyter notebooks were retrieved from the Stack. We transformed Jupyter notebooks into two different datasets: Jupyter -scripts and Jupyter -structured. Table Jupyter -scripts We utilize Jupytext<ref type="foot" target="#foot_4">foot_4</ref> to convert notebooks to scripts. It is an actively maintained software that currently supports 31 programming languages. To initiate the conversion process, Jupytext requires the identification of the specific programming languages within each notebook. We extracted this information from the metadata of each respective notebook. However, more than 30,000 notebooks lacked any programming language information, making it difficult to convert them to the script format. To address this issue, we incorporated the use of Guesslang,<ref type="foot" target="#foot_5">foot_5</ref> an open-source library that employs machine learning techniques to identify the programming languages of source code. By applying a probability threshold greater than or equal to 0.5, we successfully reduced the number of unidentified notebooks to 6,400 using Guesslang. Ultimately, we amassed 1,432,992 scripts through the utilization of Jupytext. The distribution of programming languages among these scripts is presented in Table <ref type="table" target="#tab_3">3</ref>. We evaluated language coverage by randomly selecting 100 files from the transformed scripts, ensuring that all programming languages were represented within this sample.</p><p>Jupyter -structured To create this dataset, we first filtered out notebooks that did not contain any Python code or Markdown text. The information on the programming language in the metadata of each notebook was used as the criterion to filter out non-Python notebooks. Only notebooks explicitly marked as 'Python' in the metadata were kept. Then for each notebook, consecutive Markdown blocks or code blocks were merged into a large Markdown or code block respectively. Eventually, we ended up with consecutive code-text pairs in temporal order grouped by each notebook. In general, each Jupyter code-text pair contained the Markdown text immediately preceding the code block and the Python code, which forms a natural instruction pair. We also included the formatted output of a code block if the output cell was non-empty; otherwise, it was marked by a special &lt;empty_output&gt; token. If consecutive code blocks have multiple output cells before merging, we only retain the output of the last code block. After these preprocessing steps, we ended up with 1,045,605 structured Jupyter notebooks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">GitHub issues</head><p>We used natural language conversations from GitHub issues and pull requests, which were collected as a component of The Stack v1.2. Each conversation consists of a series of events with actions, such as opening the issue, creating a comment, or closing the issue. Each event includes the author's username, a message, an action, and a creation date. We filtered this data as follows: 1) First, we removed auto-generated text when users replied to issues via email. See Appendix A for the regular expression we used. We also deleted issues with a short message (less than 200 characters) and truncated long comments in the middle to a maximum of 100 lines while retaining the last 20 lines. This removed 18% of the volume. 2) Next, we excluded comments from bots. To do so, we searched for bot keywords in the username of the comment's author (for more information, see Appendix A). This step eliminates 17% of the total events and results in 14.7% of the issues being emptied. We have observed that bot-generated issues tend to be lengthy and contain numerous logs and links. 3) We used the number of users engaged in the conversation as an indicator of quality. Our criterion was to include conversations that have two or more users. However, we also preserved conversations that involved a single user if the total text within comments was less than 7,000 characters (96th percentile). Additionally, we excluded issues authored by a single user if they contained more than ten events, as they tended to be of poor quality or originate from overlooked bots. By implementing these filters, we removed an additional 14% of issues. 4) Finally, we used a model from the fasttext library<ref type="foot" target="#foot_6">foot_6</ref> to filter out non-English issues. This step was necessary to enable accurate redaction of names using a PII detection model (see Section 4.3).</p><p>Lastly, we would like to point out that we anonymized the usernames in the conversations by replacing them with a participant counter within the conversation. See more details in Section 4.3 and 5.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Git commits</head><p>The Git commit data was gathered from BigQuery<ref type="foot" target="#foot_7">foot_7</ref> and includes only single-file commits of repositories with the same licenses and file extension as used in The Stack <ref type="bibr" target="#b51">(Kocetkov et al., 2022)</ref>. We removed all repositories from users that opted out of The Stack. The raw dataset is around 4 TB in size. We sampled 50% of the files and filtered the remaining data with heuristics to build a high-quality dataset. We list and describe all filters in Table <ref type="table">4</ref>.</p><p>The number of line changes in a commit can be very low compared to the file size. To avoid spending too much compute budget on learning to copy the file content, we only used the full file 20% of the time, and for the remaining 80%, sampled a window between 0 and 32 lines around the first and last changed line. The resulting dataset contains 64 GB of commit data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Deduplication</head><p>We followed the deduplication pipeline from Ben Allal et al. <ref type="bibr">(2023)</ref>, which consists of calculating the MinHashes <ref type="bibr" target="#b18">(Broder, 2000)</ref> of all source code files, followed by Locally Sensitive Hashing (LSH) to map similar code files to the same bucket. We used 5-grams and a Jaccard similarity of 0.7. See this blogpost for more details regarding the pipeline.</p><p>We applied this near-deduplication process to all programming languages and the Jupyter notebooks. However, due to time constraints, we could not apply this procedure to Git commits. Additionally, we deemed it unlikely to discover duplicates in Github issues, so we didn't apply the process to them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Description Details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Maximum characters</head><p>Remove code files with &gt;100k characters. Small changes Subsample changes with ≤ 2 lines with 50% probability. Long-range refactorings Subsample changes spanning ≥ 200 lines with 10% probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Empty commit message</head><p>Remove commits with empty commit subject.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Automatic commits</head><p>Remove commits that either contain or are equal to a list of stop words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hash messages</head><p>Remove commits with whitespace-separated words-tocharacter ratio &gt;20.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data files</head><p>Subsample data formats (JSON, YAML, XML, HTML) with 50% probability.</p><p>Table <ref type="table">4</ref>: Git commit filters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Weighting of data sources</head><p>There were several discussions within the community about whether to up-sample or down-sample certain programming languages, as the amount of compute budget allocated to a data source in a given language can significantly affect the model's performance in that language. However, we realized that the largest amount of available data comes from popular programming languages and would, therefore, benefit a larger group of end-users. Moreover, after the deduplication process, we found that several high-resource programming languages, such as C, C++, C#, Java, Javascript, Python, and PHP, had a similar amount of data ranging from 44-87 GB. This further reinforced our belief that we did not need to drastically re-weigh the existing data distribution. Thus, in this work, we followed the natural distribution of data during training and sampled data sources proportionally to their volume. However, we did make an exception for JSON, YAML, and CSS, as we only want the LLM to learn the data format without wasting compute resources on memorizing the data in such files. For that reason, we re-weighed the volume of the data source to 1 GB for JSON and YAML and 3GB for CSS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PII redaction</head><p>This section outlines our efforts to remove Personally Identifiable Information (PII) from the training data. In Section 4.1, we first describe how we collected a large set of PII annotations. We used these annotations to explore various techniques to train a PII detection model in Section 4.3, building on top of the encoder model we developed in Section 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data collection</head><p>We utilized the Toloka platform<ref type="foot" target="#foot_8">foot_8</ref> to engage 1,399 crowd-workers from 35 countries in annotating a dataset for PII in source code. On average, participants completed 206 tasks, earned about $27, and worked 3.1 hours. Our goal was to identify PII in various forms, such as names, usernames, emails, IP addresses, keys, passwords, and IDs. To ensure that crowd-workers received fair compensation, we established an hourly pay rate of $7.30, taking into consideration different minimum wage rates across countries and their corresponding purchasing power. We limited annotation eligibility to countries where the hourly pay rate of $7.30 was equivalent to the highest minimum wage in the US ($16.50) in terms of purchasing power parity. A complete list of countries that participated in the annotation can be found in Table <ref type="table">B</ref>.1 of Appendix B. Crowd workers in Toloka can do tasks whenever or wherever; there is no obligation to complete a certain task or spend a fixed amount of time on it. Thus, they utilize free choice when working on the tasks. Out of 1,399 crowd workers, 695 filled a survey on task quality, and 519 completed the survey. The average score for the question asking whether the participant would like to contribute to another project like this is 4.92 on a scale 1-5.</p><p>c cpp csharp java ruby python js php rust go typescript sql css haskell kotlin perl dart lua scala fortran shell html pascal assembly scheme julia stata powershell prolog mathematica matlab Programming language 0 200 400 600 800 The dataset comprises 12,000 files, each containing approximately 50 lines of code written in 31 programming languages. Figure <ref type="figure" target="#fig_0">1</ref> shows the distribution of programming languages in the dataset. To increase the representation of rare PII types, such as keys and IP addresses, 7,100 files were pre-filtered from a larger sample. We utilized the detect-secrets tool<ref type="foot" target="#foot_9">foot_9</ref> with all default plugins activated, along with the regular expressions by Ben Allal et al. ( <ref type="formula">2023</ref>) for detecting emails, IPv4 and IPv6 addresses. To prevent biasing the annotation too much towards these detection tools, the remaining 5,100 files were randomly selected from the dataset without pre-filtering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of files</head><p>During annotation, we differentiated between various types of PII based on the specific context in which it appeared. Specifically, we distinguished whether the PII was present in the code's license header, was used as a placeholder, or constituted confidential data. This categorization was necessary because the PII in license headers is usually provided voluntarily by authors for code attribution and may not require masking. Similarly, placeholders are not real secrets and do not need to be masked. We applied this categorization to names, emails, and usernames. See Table <ref type="table" target="#tab_5">5</ref> for an overview of all PII entities.</p><p>The annotators detected a total of 22,950 PII entities in the dataset. To evaluate the quality of the dataset, we manually inspected 300 files that contained various PII types and calculated the recall and precision for each type, as shown in Table <ref type="table" target="#tab_5">5</ref>. We found that annotating secret IDs was particularly challenging, as the annotators tended to produce many false positives and negatives. As a result, we decided to exclude this category from the PII detection model training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">StarEncoder</head><p>As part of our PII detection efforts, we trained an encoder-only model (i.e., bi-directionally self-attentive Transformers) that can be efficiently fine-tuned for both code-and text-related tasks. We used the Masked Language Modelling (MLM) and Next Sentence Prediction (NSP) objectives from BERT <ref type="bibr" target="#b27">(Devlin et al., 2019;</ref><ref type="bibr" target="#b63">Liu et al., 2019)</ref> and predicted masked-out tokens from an input sentence and whether a pair of sentences occur as neighbors in a document.</p><p>We separate code snippets in the input as follows:</p><formula xml:id="formula_0">[CLS] Snippet-1 [SEP] Snippet-2</formula><p>, where the two code snippets are selected randomly, either from the same source file or from two distinct documents. For the MLM loss, we mask tokens in the input independently with an probability of 15%. For the NSP loss, we use a linear classifier applied to the representation output at the [CLS] token. We train for 100,000 steps with a global batch size of 4,096 sequences of a maximum length of 1,024 so that approximately 400B tokens are Table 6: Model architecture of StarEncoder.</p><p>observed. This takes roughly two days using 64 NVIDIA A100 GPUs. Details about the model architecture are reported in Table <ref type="table">6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">PII detection model</head><p>We fine-tuned StarEncoder on the annotated PII dataset for the Named Entity Recognition (NER) task. We added a linear layer as a token classification head on top of the model, with 6 target classes: names, emails, keys, passwords, IP addresses, and usernames. We excluded IDs due to low annotation quality and did not differentiate between the categorization of PII entities (license headers, placeholders) because of the model's poor performance in distinguishing them. We split the dataset into a training set of 7,878 examples and a test set of 4,000 examples, ensuring that both splits have a balanced representation of the different PII types. See Table <ref type="table" target="#tab_7">7</ref>. We make the training and evaluation splits available under gated access at <ref type="url" target="https://hf.co/BigCode">https://hf.co/BigCode</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fine-tuning baseline</head><p>We fine-tune StarEncoder on the PII training set, and 400 annotated files from Ben Allal et al. ( <ref type="formula">2023</ref>). We achieve F1 scores of more than 90% on names, emails, and IP addresses and 73.39% on passwords. The model's performance is comparatively low on keys and usernames, with F1 scores of only 56.66% and 59.39%, respectively. We attribute the low performance on keys to the limited number of labels for this type of PII, as only 308 instances were available. For usernames, we observed the model often confused them with decorators and values in paths. This is most likely because we annotated usernames inside links for social media platforms. .73% 98.94% 98.15% 90.10% 93.86% 91.94% 62.38% 80.81% 70.41% Table 8: Comparing PII detection performance: Regular Expressions, NER Pipeline with Annotated Data, and NER Pipeline with Annotated Data + Pseudo-Labels</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Entity type</head><p>Pseudo-labels To improve the detection of key and password entities, we employed a pseudo-labeling technique as described by <ref type="bibr" target="#b57">Lee (2013)</ref>. This method involves training a model on a small set of labeled data and subsequently generating predictions for a larger set of unlabeled data. Specifically, we annotated 18,000 files using an ensemble of two encoder models, which were fine-tuned on the 400-file PII dataset from Ben <ref type="bibr">Allal et al. (2023)</ref>. To identify reliable pseudo-labels, we calculated the average probability logits from our models and applied filtering criteria. Specifically, we set a minimum threshold of 0.5 for all entities, except for names and usernames, for which we used a higher threshold of 0.6. However, upon reviewing the results, we found a significant number of false positives for keys and passwords. As a result, we decided to only retain entities that were preceded by a trigger word, such as key, auth, or pwd, within the preceding 100 characters. Training on this synthetic dataset before fine-tuning on the annotated one yielded superior results for all PII categories, as demonstrated in Tables <ref type="table">8</ref> and <ref type="table" target="#tab_9">9</ref>. Only the performance for detecting usernames did not show significant improvement, so we decided to exclude it from the PII redaction process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison against regex baseline</head><p>We compared our PII detection models against the regular expressions (regexes) employed in Ben <ref type="bibr">Allal et al. (2023)</ref>. The regexes only support the detection of emails, IP addresses, and keys. Note that we enhanced the email regex, as explained in the Appendix, to address false positives we found during the evaluation on this benchmark. This modification boosted the F1 score of the regex from 81.8% to 96.83%. Nevertheless, our PII detection models still surpassed the regex approach in detecting all three entities, as shown in Table <ref type="table">8</ref>. We note that the performance difference was especially large on keys and found that the detect-secrets tool generated many false positives, especially in specific programming languages like Go and C-sharp that weren't well represented in the regex evaluation. Consequently, the overall precision of the tool was below 4%.</p><p>Post-processing Before applying the best PII detection model to the full dataset, we observed a couple of frequent detection errors. We added the following post-processing techniques to reduce the number of false positives:</p><p>• Ignore secrets with fewer than 4 characters.</p><p>• Detect full names only by requiring at least one space within the name. • Ignore detected keys with fewer than 9 characters or that are not gibberish using a gibberish-detector.<ref type="foot" target="#foot_10">foot_10</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>• Ignore IP addresses that aren't valid or are private (non-Internet facing) using the ipaddress python package. We also ignore IP addresses from popular DNS servers. We use the same list as in Ben Allal et al. <ref type="bibr">(2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PII placeholders</head><p>We replaced the detected PII entities with the following tokens:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;NAME&gt;, &lt;EMAIL&gt;, &lt;KEY&gt;, &lt;PASSWORD&gt;</head><p>To mask IP addresses, we randomly selected an IP address from 5 synthetic, private, non-internet-facing IP addresses of the same type that can be found in Appendix C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Github issues</head><p>We already employed a regex approach to detect keys, IP addresses, and emails in the Github issues, so we only used the PII detection model to redact names. We anonymized the usernames of the authors by replacing them with a participant counter within the conversation, e.g. username_1 to refer to second participant (see Section 5.1 for formatting details). We prepend these pseudonyms to the beginning of each comment such that we preserve the speaker identity of the author. In addition, we redact all mentions of these usernames in the messages. Note that we only mask the usernames of active participants in the conversation and mentions of non-participating users are not anonymized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Compute resources</head><p>We used the PII detection model to identify PII across all programming languages in the training dataset, including GitHub issues (names only), Git commits, and Jupyter notebooks. The total dataset amounts to 815 GB in size. We ran inference on multiple NVIDIA A100 80 GB GPUs, which required 800 GPU-hours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Model training</head><p>This section presents information on the training process of the StarCoder models. Before we proceed, we first clarify the differences between the two models:</p><p>StarCoderBase is the first model trained on 1 trillion tokens sourced from the curated dataset described in Section 3.</p><p>StarCoder is the fine-tuned version of StarCoderBase, trained on another 35B Python tokens (roughly 2 epochs).</p><p>Throughout the following, we show how we formatted the training data (Section 5.1), decontaminated the training data (Section 5.2), and provide details regarding the tokenizer (Section 5.3), the model architecture (Section 5.4), the training process (Section 5.5), multi-node GPU setup (Section 5.6), and CO2 emissions (Section 5.7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Data formatting</head><p>We present the formatting guidelines for each of the data sources below. We provide the templates below in which &lt;token&gt; refers to a sentinel token, and metadata and data refer to placeholders for data fields, respectively.</p><p>Code We prepend the repository name, file name, and the number of stars to the context of the code file.</p><p>To not overfit on the exact number of stars, we categorized GitHub stars into five buckets: 0, 1-10, 10-100, 100-1000, 1000+. To enable the model to operate without this metadata during inference, we prefixed the repository name, filename, and stars independently at random, each with a probability of 0.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;reponame&gt;reponame&lt;filename&gt;filename&lt;gh_stars&gt;stars\ncode&lt;|endoftext|&gt;</head><p>To the source code in this template (i.e. code), we apply the fill-in-the-middle transformation (FIM; <ref type="bibr">Bavarian et al., 2022)</ref>. More precisely, we apply FIM at the character-level to the source code files with a FIM-rate of 0.5, and use PSM mode with probability .5 and SPMv2 mode with probability .5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Issues</head><p>We use sentinel tokens to mark the opening of an issue and subsequently include its title. We separate the sequence of comments by a &lt;issue_comment&gt; token and include a anonymized speaker identifier before the comment. Specifically, we refer to authors by their participant counter within the conversation, e.g. username_1 to refer to second participant in the issue. To distinguish between the different turns, we use comment1, id1 to refer to the second comment and its anonymized speaker id, respectively.</p><p>&lt;issue_start&gt;Title: title\nusername_id0:comment0&lt;issue_comment&gt;username_id1:comment1 ... &lt;issue_closed (optional)&gt;&lt;|endoftext|&gt;</p><p>Jupyter -scripts Jupyter scripts were formatted in the same manner as code.</p><p>Jupyter -structured Parsed Jupyter notebooks come in chains of text, code, and outputs, and we separated them with sentinel tokens. Note that we use text2, code2, output2 to refer to the 3rd triplet in the notebook. &lt;jupyter_start&gt;&lt;jupyter_text&gt;text0&lt;jupyter_code&gt;code0 &lt;jupyter_output&gt;output0&lt;jupyter_text&gt; ... &lt;|endoftext|&gt;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Git commits</head><p>We separate the code before the commit, the commit message, and the code after the commit with sentinel tokens. As explained in Section 3.4, we use the full files with 20% probability and otherwise use a small window (0-32 lines) around the changed lines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;commit_before&gt;code_before&lt;commit_msg&gt;message&lt;commit_after&gt;code_after&lt;|endoftext|&gt;</head><p>We summarize all sentinel tokens in Table <ref type="table" target="#tab_10">10</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Training data decontamination</head><p>The code training data was decontaminated by removing files that contained docstrings or solutions from HumanEval and MBPP, docstrings from APPS, questions from GSM8K, or prompts from DS1000. (These benchmarks are further described in Section 6.) To give an indication of the amount of data removed by decontamination, Python is the language with the highest number of matches, with 558 files removed. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Tokenizer</head><p>The model's tokenizer follows our insights presented in Ben Allal et al. ( <ref type="formula">2023</ref>) and uses those same design choices: we use the Hugging Face Tokenizers library <ref type="bibr" target="#b73">(MOI et al., 2022)</ref> to train a byte-level Byte-Pair-Encoding with a vocabulary size of 49,152 tokens-including the sentinel tokens from table 10. The pre-tokenization step includes a digit-splitter and the regex splitter from the GPT-2 pre-tokenizer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Model Architecture</head><p>We trained a 15.5B parameter model with the same architecture as SantaCoder <ref type="bibr">(Ben Allal et al., 2023)</ref>. It is a decoder-only Transformer with Multi-Query-Attention (MQA; Shazeer, 2019), and learned absolute positional embeddings. We also apply Fill-in-the-Middle (FIM; <ref type="bibr">Bavarian et al., 2022)</ref> transformations to the training data, see Section 5.1. We used FlashAttention <ref type="bibr" target="#b26">(Dao et al., 2022)</ref> to speed up the attention computation and reduce its memory footprint, allowing us to scale to a 8K context length. To make FlashAttention work with MQA during training, we simply expand the key and value before calling the attention kernel. The architecture hyper-parameters are given in Table <ref type="table" target="#tab_11">11</ref>. In addition, we have included the hyperparameters of SantaCoder(Ben Allal et al., 2023) for comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Training details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>StarCoderBase</head><p>The model was trained for 250k iterations, with a batch size of 4M tokens, for a total of one trillion tokens. We used Adam <ref type="bibr" target="#b50">(Kingma &amp; Ba, 2015)</ref> with β 1 = 0.9, β 2 = 0.95, ϵ = 10 -8 and a weight decay of 0.1. The learning rate followed a cosine decay from 3 × 10 -4 to 3 × 10 -5 after a linear warmup of 2,000 iterations.</p><p>StarCoder Starting from StarCoderBase, we fine-tuned a Python variant of the model for 2 epochs on the Python subset of the training data. We used the same settings as StarCoderBase, except that we used a learning rate of 5 × 10 -5 and decayed it to 5 × 10 -6 after 1,000 iterations of linear warmup. We trained for 8,500 steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyperparameter SantaCoder StarCoder</head><p>Hidden </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Multi-Node GPU Setup</head><p>We trained our model on a GPU cluster with 512 A100 80 GB GPUs distributed across 64 nodes. We partitioned the model with a 3D-parallel layout that shards the model with both tensor and pipeline parallelism rank 4, requiring 16 GPUs (two nodes) for one replica. To fully leverage the cluster's capabilities, we used 32-fold data parallelism. To optimize GPU utilization and reduce idle compute bubbles, we maintained a micro-batch size of 1 and accumulated for 16 steps, resulting in a global batch size of 512 (equivalent to 4M tokens). We used Megatron-LM's distributed optimizer because we found that it leads to slightly higher throughput in this configuration. Since it requires the gradient reduction step in FP32, the training in BF16 leads to 10% lower throughput than FP16, but we used it anyway to avoid training instabilities.</p><p>Except for a few restarts, we did not experience significant training instabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">CO2 emissions</head><p>StarCoderBase We report the carbon footprint <ref type="bibr" target="#b55">(Lacoste et al., 2019)</ref> of training StarCoderBase. Based on the total number of GPU hours that training took (320,256) and an average power usage of 280W per GPU, this adds up to 89671.68 kWh of electricity consumed during the training process. Multiplied by the carbon intensity of the energy of the us-west-2 AWS location (0.15495 kgCO2e per kWh) and the average Power Usage Effectiveness of 1.2 across AWS datacenters, this results in 16.68 tonnes of CO2eq emitted. StarCoder The fine-tuned model adds 3.5% of training time, which translates to an additional estimated emission of 0.58 tonnes of CO2eq.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluation</head><p>In this section, we first outline the models we evaluated in addition to StarCoder and StarCoderBase. Then we report on the Python language performance of all models on the HumanEval <ref type="bibr" target="#b23">(Chen et al., 2021)</ref>, MBPP <ref type="bibr" target="#b5">(Austin et al., 2021)</ref>, and DS-1000 <ref type="bibr" target="#b56">(Lai et al., 2022)</ref> evaluation benchmarks. Then we cover multi-language evaluation using a variety of benchmarks and tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Code LM Evaluation Harness</head><p>To enable reproducible and centralized evaluation of StarCoder and other Code LLMs, we developed a Code LM Evaluation Harness <ref type="bibr">(Ben Allal et al., 2022)</ref>, inspired by the LM Evaluation-Harness <ref type="bibr">(Gao et al., 2021b)</ref>. This harness provides a framework for the efficient evaluation of code models, utilizing data parallelism and docker containers for execution. It supports several benchmarks, including HumanEval, MultiPL-E, and DS-1000.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Other Models Evaluated</head><p>We compare StarCoder and StarCoderBase to the following models.</p><p>1. CodeGen-16B-Multi <ref type="bibr" target="#b77">(Nijkamp et al., 2023)</ref> is an open-access, 16B parameter model that is trained on the Pile <ref type="bibr">(Gao et al., 2021a)</ref>, and then on additional code written in C, C++, Go, Java, JavaScript, and Python from the GitHub BigQuery dataset <ref type="bibr" target="#b94">(Smith, 2016)</ref>. 2. CodeGen-16B-Mono is a version of CodeGen-16B-Multi that is fine-tuned on additional Python code from GitHub, though the dataset is not publicly available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>3. CodeGeeX <ref type="bibr">(Zheng et al., 2023</ref>) is an open-access 13B parameter model trained on 23 programming languages selected from the Pile, the CodeParrot dataset <ref type="bibr" target="#b110">(Wolf et al., 2020)</ref>, and additional data for Python, Java, and C++. CodeGeeX also includes its own multi-language benchmark suite, HumanEval-X, which we discuss below.</p><p>4. code-cushman-001 is a 12B parameter model by OpenAI and was the initial model for GitHub Copilot <ref type="bibr" target="#b23">(Chen et al., 2021)</ref>. The details of its training set are unknown. This model has been deprecated by OpenAI but was available from the Microsoft Azure OpenAI Service at the time of writing.<ref type="foot" target="#foot_11">foot_11</ref> 5. Finally, although they are not specifically trained for code generation, we include some results from the LLaMA <ref type="bibr" target="#b101">(Touvron et al., 2023)</ref>, PaLM <ref type="bibr">(Chowdhery et al., 2022)</ref>, and LaMDA <ref type="bibr" target="#b99">(Thoppilan et al., 2022)</ref> papers. LLaMA's license prohibits commercial use, and PaLM and LaMDA are not publicly available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">StarCoder: Python Evaluation</head><p>In this section, we evaluate the performance of StarCoder on Python, comparing it to both open-access and closed-access models. We first report performance on HumanEval <ref type="bibr" target="#b23">(Chen et al., 2021)</ref> and MBPP <ref type="bibr" target="#b5">(Austin et al., 2021)</ref>, which are two widely used benchmarks of Python performance. However, we also measure performance on DS-1000 <ref type="bibr" target="#b56">(Lai et al., 2022)</ref>, a code completion benchmark of 1,000 Python data science problems based on StackOverflow questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">The HumanEval and MBPP Benchmarks</head><p>HumanEval <ref type="bibr" target="#b23">(Chen et al., 2021)</ref>, and MBPP <ref type="bibr" target="#b5">(Austin et al., 2021)</ref> are widely-used benchmarks for Code LLMs consisting of hundreds of Python programming problems that use test cases to validate the code produced by Format Model M a t p l o t l i b N u m P y P a n d a s P y T o r c h S c i P y S c i k i t -L e a r n T e n s o r F l o w Overall Number of problems: 155 220 291 68 106 115 45 1,000 Completion SantaCoder-1B 21.6 4.6 0.9 2.6 2.4 4.8 3.1 5.7 Completion InCoder-6B 28.3 4.4 3.1 4.4 2.8 2.8 3.8 7.4 Completion CodeGen-16B-Mono 31.7 10.9 3.4 7.0 9.0 10.8 15.2 11.7 Completion code-cushman-001 40.7 21.8 7.9 12.4 11.3 18.0 12.2 18.1 Completion StarCoderBase 47.0 27.1 10.1 19.5 21.7 27.0 20.5 23.8 Completion StarCoder 51.7 29.7 11.4 21.4 20.2 29.5 24.5 26.0 Insertion SantaCoder-1B 21.6 * 13.8 2.0 3.8 5.7 6.9 14.8 9.3 Insertion InCoder-6B 28.3 * 4.6 2.9 4.4 2.8 3.1 7.8 7.5 Insertion StarCoderBase 47.0 * 26.3 10.9 16.6 20.2 30.2 22.3 24.0 Insertion StarCoder 51.7* 30.8 10.3 21.0 20.2 27.4 20.0 25.4</p><p>Table <ref type="table" target="#tab_3">13</ref>: Performance of open-access and closed-access models on DS-1000. Benchmarks are as follows. All models evaluated at temperature=0.2, top_p=0.5, max_length=1024. Scores reflect mean pass@1 accuracy averaged over 40 samples. * : Matplotlib task does not have right sided context, so insertion and completion formats are identical.</p><p>a Code LLM. Code LLMs generate code by sampling from their output distribution. We report performance using the pass@k metric <ref type="bibr" target="#b23">(Chen et al., 2021)</ref>: the total fraction of benchmark problems solved, where a problem is considered solved if any one of k code samples passes every test case. Like Chen et al. ( <ref type="formula">2021</ref>), we use sampling temperature 0.2 for pass@1, and temperature 0.8 for k &gt; 1. We generate n = 200 samples for all experiments with open-access models. For API models, we use n = 20 samples, which is enough to estimate pass@1. We focus on the simplest version of pass@k, which is pass@1: the likelihood that a problem is solved in a single attempt by the model.</p><p>Table 12 compares StarCoder (and StarCoderBase) on HumanEval and MBPP to several open-access and closed-access models: 1. StarCoder is the highest-performing open-access model on both benchmarks. 2. StarCoder outperforms the largest models, including PaLM, LaMDA, and LLaMA, despite being significantly smaller. 3. StarCoderBase is also very capable on Python and is competitive with CodeGen-16B-Mono, a similarly-sized open-access model that was fine-tuned on Python. 4. StarCoder outperforms OpenAI's code-cushman-001 (12B) model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">The DS-1000 Python Data Science Benchmarks</head><p>A major limitation of HumanEval and MBPP is that they are simple programming puzzles that are not representative of the code that most programmers write. In contrast, the DS-1000 benchmark <ref type="bibr" target="#b56">(Lai et al., 2022)</ref> has a suite of 1,000 realistic and practical data science workflows across seven libraries and evaluates generations in execution against test cases.</p><p>DS-1000 supports two evaluation modes: completion and insertion (via FIM). We report completion scores for all models but insertion scores only for models that support it: the StarCoder models and InCoder-6B <ref type="bibr" target="#b33">(Fried et al., 2022)</ref>. DS-1000 also categorizes problems based on the libraries used: Matplotlib, NumPy, Pandas, SciPy, Scikit-Learn, PyTorch, and TensorFlow. We report pass@1 for each library and an overall score in Table <ref type="table" target="#tab_3">13</ref> and draw the following conclusions:</p><p>1. StarCoder substantially outperforms all other models on data science problems from the DS-1000 benchmark. Moreover, this is true across every kind of data science library.</p><p>2. StarCoderBase also outperforms every other model, but is slightly behind StarCoder on DS-1000.</p><p>3. We confirm the finding by <ref type="bibr" target="#b56">Lai et al. (2022)</ref>: model performance on HumanEval and MBPP benchmarks does not always correlate with performance on the more realistic DS-1000 benchmarks. For example, CodeGen-Mono slightly outperforms code-cushman-001 and the StarCoder models on HumanEval and MBPP, but is significantly worse on DS-1000. This demonstrates the importance of evaluating models on a range of benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.3">The ODEX Open-Domain Coding Benchmark</head><p>Our previous evaluations focus either on closed domains (i.e., primarily built-in Python functions, as in MBPP and HumanEval) or specific domains (e.g., data science, as in DS-1000). To evaluate model ability to generate code on a broader set of Python libraries, we use the ODEX benchmark <ref type="bibr" target="#b107">(Wang et al., 2022)</ref> containing 505 open-domain and 440 closed-domain Python coding queries, in four natural languages -English, Spanish, Japanese, and Russian -with test-case-based execution evaluation.</p><p>We report the pass@1 metric for StarCoder and baseline models, including Codex (code-davinci-001), CodeGen-16B-Mono, and SantaCoder. In addition to the overall execution accuracy, we also categorize problems by languages and domains, which are: (1) queries in the closed-domain (using only built-in Python functions) and open-domain (using functions from imported libraries), and (2) queries with instructions written in English, Spanish, Japanese, and Russian, respectively. We report overall scores and scores in different domains and languages in Table <ref type="table" target="#tab_16">14</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">StarCoder and StarCoderBase: Multi-Language Evaluation</head><p>In this section, we focus primarily on StarCoderBase, and evaluate its performance on a variety of programming languages and programming tasks, including producing code from natural language descriptions, documenting code, predicting type annotations, and more. This section also shows that StarCoder, despite being fine-tuned on Python, remains a very capable multi-language Code LLM and even outperforms StarCoderBase on some languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language CodeGen-16B-Multi</head><p>CodeGeeX code-cushman-001 StarCoder StarCoderBase cpp 21.00 16.87 30.59 31.55 30.56 c-sharp 8.24 8.49 22.06 21.01 20.56 d 7.68 9.15 6.73 13.57 10.01 go 13.54 11.04 19.68 17.61 21.47 java 22.20 19.14 31.90 30.22 28.53 julia 0.00 0.29 1.54 23.02 21.09 javascript 19.15 16.92 31.27 30.79 31.70 lua 8.50 10.96 26.24 23.89 26.61 php 8.37 13.51 28.94 26.08 26.75 perl 3.42 8.09 19.29 17.34 16.32 python 19.26 21.62 30.71 33.57 30.35 r 6.45 3.92 10.99 15.50 10.18 ruby 0.00 3.34 28.63 1.24 17.25 racket 0.66 3.31 7.05 0.07 11.77 rust 4.21 7.88 25.22 21.84 24.46 scala 2.37 8.95 27.62 27.61 28.79 bash 0.61 2.75 11.74 10.46 11.02 swift 1.25 7.26 22.12 22.74 16.74 typescript 20.07 10.11 31.26 32.29 32.15 Table 15: Comparing StarCoder to multi-language open-access (e.g., CodeGen-16B-Multi) and closed-access models (e.g., code-cushman-001) on 19 programming languages.</p><p>We report pass@1 on HumanEval <ref type="bibr" target="#b23">(Chen et al., 2021)</ref>, which we translate from Python to the other languages using MultiPL-E <ref type="bibr" target="#b22">(Cassano et al., 2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">Evaluation on 19 Programming Languages with MultiPL-E</head><p>We evaluate the ability of StarCoder to turn natural language into working code in multiple programming languages using MultiPL-E <ref type="bibr" target="#b22">(Cassano et al., 2023)</ref>, which translates the HumanEval <ref type="bibr" target="#b23">(Chen et al., 2021)</ref> and MBPP <ref type="bibr" target="#b5">(Austin et al., 2021)</ref> Python benchmarks into 18 other programming languages as follows.</p><p>MultiPL-E has a set of rule-based compilers that translate Python benchmarks to each target programming language. Each compiler expects a benchmark in the HumanEval format: 1) a natural language description (in a docstring), 2) a function signature (name, arguments, and, potentially, types), and 3) a set of hidden assertions. The MultiPL-E compilers translate the function signature, assertions, and docstring (which may have doctests) into a target language. Thus, MultiPL-E gives us a parallel set of benchmarks derived from HumanEval and MBPP to compare model performance across programming languages. <ref type="foot" target="#foot_12">13</ref> The MultiPL-E languages include both high and low-resource languages, statically and dynamically typed languages, and a variety of other programming language features.</p><p>Table <ref type="table" target="#tab_5">15</ref> shows how these models perform on 19 programming languages, and from it, we draw the following conclusions:</p><p>1. Across all 19 programming languages, StarCoderBase outperforms other open-access models, sometimes showing more than 2× performance. There are several other conclusions that we can draw from the table. For example, CodeGen-16B-Multi performs better than one might expect on some languages that are reportedly not in its training set, including C#, Lua, PHP, and TypeScript. Its performance on TypeScript is less surprising since simple JavaScript functions often type-check with TypeScript by design. Similarly, StarCoder shows high performance on Swift, even though it was not included in its training set, as explained in Section 3.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">StarCoderBase is competitive with code-cushman-001 on most languages that we</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">The "Asleep at the Keyboard" Security Benchmark</head><p>A limitation of Code LLMs is that they can generate code with security vulnerabilities <ref type="bibr" target="#b82">(Pearce et al., 2022)</ref>.</p><p>The (3) Diversity of Domain (DoD) contains security scenarios in the hardware description language Verilog. We focus on the DoW, which contains 54 scenarios (25 in C and 29 in Python) across 18 CWEs. We exclude scenarios that lack an automated test, leaving 40 scenarios <ref type="bibr">(23 in C and 17 in Python)</ref>. <ref type="bibr" target="#b82">Pearce et al. (2022)</ref> had previously evaluated the security of GitHub Copilot (as of August 2021), and in this paper, we use the same methodology to evaluate StarCoderBase, InCoder-6B, CodeGen-16B-Multi, and OpenAI's code-cushman-001. We use the original benchmarking methodology: generating 25 completions per scenario at temperature 0.2 (1,000 completions per model). The dataset supports fill-in-the-middle, so we include this configuration on models that support it. The results are shown in Table <ref type="table" target="#tab_19">16</ref>; Valid gives the percentage of solutions that were syntactically valid (using py_compile for Python and gcc for C), and Insecure shows the percentage of valid solutions that contained the vulnerability the scenario tests for. From this table, we draw the following conclusions.</p><p>1. StarCoderBase has the highest rate of valid code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>InCoder-6B has a slightly lower rate for insecure code generation, but this may be due to its lower rate of valid completions.</p><p>3. Among the models with more than 95% valid code, StarCoder has the lowest rate of insecure completions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.3">Fill in the Middle Benchmarks</head><p>The StarCoder models support fill in the middle (FIM) or infilling, which allows the model to generate code conditioned on prefix and suffix code surrounding the insertion point. Only a handful of recent models Table 18: Accuracy of Python return type prediction, using Fried et al. (2022)'s adaptation of the Pradel et al. ( <ref type="formula">2020</ref>) benchmarks. We report both the overall F1 scores, which include trivial None-type prediction, and the F1 score for non-None types.</p><p>support FIM: from OpenAI <ref type="bibr">(Bavarian et al., 2022)</ref>, InCoder <ref type="bibr" target="#b33">(Fried et al., 2022)</ref>, and our prior work on SantaCoder <ref type="bibr">(Ben Allal et al., 2023)</ref>. FIM opens up the possibility of a variety of tasks that go beyond left-to-right code completion. We evaluate StarCoderBase on four established FIM benchmarks below.</p><p>Single-Line Infilling for Python, Java, and JavaScript <ref type="bibr" target="#b33">Fried et al. (2022)</ref> present a single-line fill-inthe-middle task for Python that masks one line of code from a HumanEval solution and scores the model's ability to complete the function. They turn every HumanEval solution into several fill-in-the-middle problems by masking each non-blank, non-comment line of code in the solution body into a fill-in-the-middle task.</p><p>Ben <ref type="bibr">Allal et al. (2023)</ref> generalizes this benchmark to also support Java and JavaScript, using model-generated solutions from MultiPL-E's translations. We compare the performance of StarCoderBase, SantaCoder, and InCoder on this task, evaluating using line exact match (Table <ref type="table" target="#tab_20">17</ref>). StarCoderBase significantly outperforms the two smaller models. <ref type="bibr" target="#b85">Pradel et al. (2020)</ref> introduce methods and datasets for evaluating Python type annotations. <ref type="bibr" target="#b33">Fried et al. (2022)</ref> adapt and filter one dataset from this work, consisting of Python functions from GitHub, and use it to evaluate infilling models on function return type prediction. We use this dataset to compare StarCoder, StarCoderBase, and SantaCoder to InCoder on function return type prediction. Our setup follows <ref type="bibr" target="#b33">Fried et al. (2022)</ref>: each model uses greedy generation to infill return types while conditioning on the imports, body, and signature for each function. We report exact match accuracy on normalized annotations for all functions in the evaluation set and only those with non-None annotations, following <ref type="bibr" target="#b33">Fried et al. (2022)</ref>. We find that StarCoder and StarCoderBase outperform existing approaches at Python return type prediction (Table <ref type="table">18</ref>). However, we note that as the functions in this evaluation set were taken from GitHub repositories, they may overlap with the training data for SantaCoder and the StarCoder models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Python Return Type Prediction</head><p>TypeScript Type Prediction <ref type="bibr">Yee &amp; Guha (2023)</ref> evaluate approaches to neural type prediction for TypeScript. However, instead of measuring accuracy, they argue that benchmarks should measure how many projects or files do not have type errors with predicted types. This approach makes it possible to evaluate type prediction for JavaScript programs that have never been translated to TypeScript, which reduces the likelihood of dataset contamination. We add StarCoderBase to their evaluation framework and compare it to InCoder, which performs best at type prediction in the original work. Table 20: Performance on the Python portion of the CodeXGLUE Code Summarization task, evaluating function docstring generation. Models are evaluated zero-shot using their infilling capability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Python Docstring Generation</head><p>To evaluate models' ability to generate documentation for functions, we use the Python subset of the CodeXGLUE code summarization benchmark <ref type="bibr" target="#b65">(Lu et al., 2021)</ref>. This benchmark is constructed from the CodeSearchNet dataset <ref type="bibr" target="#b44">(Husain et al., 2019)</ref>, containing functions from public GitHub repositories. Models infill the documentation string (docstring) for each function using greedy decoding, conditioned on the function signature and body. We follow the evaluation scheme of past work: docstrings are evaluated using smoothed 4-gram BLEU <ref type="bibr" target="#b81">(Papineni et al., 2002)</ref> against the reference docstring from the original function, using only the first lines of the generated and reference docstrings (removing, e.g., descriptions of function arguments and return types that may appear in later lines). In Table <ref type="table">20</ref>, we see that StarCoder and StarCoderBase obtain higher performance than past work on docstring generation. However, we note that there may be an overlap between this evaluation dataset and the data used to train SantaCoder and the StarCoder models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Performance Improvement Through the Training Process</head><p>We evaluate the performance of StarCoderBase at several training checkpoints after every 200B tokens seen out of the total 1000B. Figure <ref type="figure" target="#fig_2">2</ref> (right) shows how performance (pass@1) changes during training for each programming language supported by MultiPL-E. The performance curve for several high-resource programming languages suggests that training longer is likely to improve their performance further.</p><p>However, some of the low-resource languages see limited improvement during training or even have a pass@1 decline. For example, R's pass@1 rate drops significantly between the 800B and 1000B (final) checkpoints. The dependence of pass@1 on data size (Figure <ref type="figure" target="#fig_2">2</ref>, left) further supports the hypothesis that this is related to the amount of data available. The slope of the linear fit increases between 800B and 1000B checkpoints while the intercept decreases, i.e., performance improves only for languages with large enough amounts of data (≳ 1 GB).</p><p>We manually inspected the completions generated by R over several checkpoints to better understand model performance. One might hypothesize that some problems are harder than others, and so the model gains and loses the ability to solve them in R over the 600B, 800B, and 1000B checkpoints, but we find that this is not the case. Instead, we find significant variance in per-problem success rates for several problems (Table <ref type="table">D</ref>.3). For these problems, the pass rate between different checkpoints varies in what appears to be a completely uncorrelated manner. Moreover, manual inspection shows that the failures are caused by minor mistakes, The lines in the left plot are a linear fit between pass@1 and log-dataset-size for all the points except the leftmost one, where we expect the linear dependence to break due to transfer learning (dashed line). The goodness of fit ranges between R 2 = 0.399 for the 600B checkpoint to R 2 = 0.510 for the 1000B checkpoint. e.g., not taking the absolute value when computing GCD, not converting a string to a character array, or not checking edge cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Perplexity With Long Contexts</head><p>StarCoderBase was trained with an 8K token window, allowing conditioning on and generating long code files. To evaluate the ability of the model to benefit from this larger context, we compare its perplexity <ref type="bibr">(Bahl et al., 1983)</ref> when using a full window size of 8K tokens versus a window size of 2K tokens (as used in many prior code models).</p><p>To ensure no overlap between the training data for StarCoderBase and the perplexity computation data, we downloaded 10 GNU Public License (GPL) repositories from GitHub in each of the languages in Table <ref type="table" target="#tab_24">21</ref>. We compiled all files from the repositories into a single document for each language. We then divided these documents into 8K token chunks and computed perplexity on the last 1K tokens in each chunk<ref type="foot" target="#foot_13">foot_13</ref> in two conditions: (1) the model window only contains the final 2K tokens in the chunk (i.e., the 1K being predicted and the previous 1K), and (2) the model window contains all 8K tokens in the chunk (i.e., the 1K tokens being predicted and the previous 7K). This evaluates the ability of the model to benefit from additional file-and repo-level context when predicting code. In Table <ref type="table" target="#tab_24">21</ref>, we report the average perplexity of the 1K token regions across all chunks. We see that StarCoderBase indeed benefits from the extra token conditioning afforded by its 8K context window, with substantially lower perplexities across all languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Natural Language Evaluation</head><p>Although the StarCoder models are principally developed to be Code LLMs, they have also been trained on a significant amount of natural language text. Roughly 20% of its training tokens are natural language data: 7% GitHub issues, 10% Markdown, 2% Jupyter notebooks, and 4% HTML. In this section, we evaluate  <ref type="table">22</ref>: 8-shot accuracy on the GSM8K math-reasoning benchmark. Samples are generated with greedy decoding. maj1@k denotes a majority vote over k generations. For the majority vote, we instead generate samples using nucleus sampling with p = 0.95 and temperature 0.7, following <ref type="bibr" target="#b36">Gao et al. (2022)</ref>. We use "-" when a model was not evaluated on a given metric, or the metric is not supported in Language Model Evaluation Harness. The LLaMA CoT numbers are from <ref type="bibr" target="#b101">Touvron et al. (2023)</ref>.</p><p>StarCoderBase on several natural language tasks: natural language reasoning and understanding tasks that might benefit from the combination of code and text training data; and natural language generation tasks that evaluate the model's tendencies to produce undesirable text outputs, e.g., in a documentation generation or interactive assistant setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Math Reasoning</head><p>Recent work has shown that Code LLMs can be effective arithmetic and symbolic reasoners by using a technique called Program-Aided Language models (PAL; <ref type="bibr" target="#b36">Gao et al., 2022)</ref>. With PAL, the LLM reads the reasoning problem and generates Python programs as the intermediate reasoning steps, which are then executed by the Python interpreter to produce the answer. In contrast, the Chain-of-Thought method (CoT; <ref type="bibr" target="#b108">Wei et al., 2022)</ref> prompts the LLM to produce the reasoning steps in natural language before generating the answer.</p><p>We investigate the reasoning capabilities of StarCoderBase on GSM8K <ref type="bibr" target="#b25">(Cobbe et al., 2021)</ref>, a set of middleschool math word problems. We compare with the two CodeGen-16B models <ref type="bibr" target="#b77">(Nijkamp et al., 2023)</ref> and the family of LLaMA models <ref type="bibr" target="#b101">(Touvron et al., 2023)</ref>. The results of our evaluation are presented in Table <ref type="table">22</ref>, where we provide both CoT and PAL results for StarCoderBase and LLaMA.</p><p>In line with previous results comparing PAL to CoT on Code LLMs <ref type="bibr" target="#b36">(Gao et al., 2022)</ref>, we find that StarCoder-Base performs better with PAL (21.5%) than with CoT (8.4%). StarCoderBase substantially outperforms CodeGen-16B-Mono and CodeGen-16B-Multi, which achieve 13.1% and 8.6% with PAL, respectively. These differences carry over to the setting where majority voting is applied. The difference between CoT and PAL is much smaller for the LLaMA models, although we observe that CoT performs slightly better for the 7B and 13B LLaMA models. Interestingly, we find that StarCoderBase outperforms LLaMA-13B (17.8%) on this reasoning benchmark. However, its performance still lags behind LLaMA-33B (38.7%). Table 24: Zero-shot accuracy on the CoQA question answering challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">World Knowledge and Reading Comprehension</head><p>MMLU <ref type="bibr" target="#b40">(Hendrycks et al., 2020</ref>) is a massive multitask language understanding benchmark, covering multiplechoice questions in 57 knowledge domains, including the humanities, STEM, and social sciences. CoQA <ref type="bibr" target="#b89">(Reddy et al., 2019</ref>) is a large-scale dataset for Conversational Question Answering systems, measuring the model's ability to process a text passage and answer a series of interconnected questions. We compare StarCoderBase and StarCoder with CodeGen-16B-Multi <ref type="bibr" target="#b77">(Nijkamp et al., 2023)</ref>, GPT-NeoX <ref type="bibr" target="#b14">(Black et al., 2022)</ref>, LLaMA-7B, and LLaMA-13B <ref type="bibr" target="#b101">(Touvron et al., 2023)</ref>.</p><p>We present the 5-shot accuracy for MMLU in Table <ref type="table" target="#tab_26">23</ref>, and the zero-shot F1 scores for CoQA in Table <ref type="table">24</ref>. On MMLU, StarCoderBase outperforms CodeGen-16B-Multi significantly (34.2% to 27.8%), and even outperforms GPT-NeoX by a small margin (32.9%). Nevertheless, both LLaMA models outperform StarCoderBase. On CoQA, StarCoderBase performs better than CodeGen-16B-Multi but is outperformed by LLaMA and GPT-NeoX.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Measuring Harmful Generation</head><p>When generating open-ended text such as code documentation or technical dialogue, a Code LLM (similarly to text-only LLMs) might produce harmful outputs. We compare StarCoderBase to previous Code LLMs on benchmarks that measure social bias and toxicity in model-produced text.<ref type="foot" target="#foot_14">foot_14</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.1">Social Bias</head><p>Recent work has highlighted that LLMs often capture social biases and stereotypes from their pre-training corpora <ref type="bibr" target="#b54">(Kurita et al., 2019;</ref><ref type="bibr" target="#b67">May et al., 2019;</ref><ref type="bibr" target="#b45">Hutchinson et al., 2020;</ref><ref type="bibr" target="#b69">Meade et al., 2023)</ref>. To quantify social bias within our model, we use StereoSet <ref type="bibr" target="#b75">(Nadeem et al., 2021)</ref>.</p><p>StereoSet consists of a collection of fill-in-the-blank-style tests for measuring social biases within language models. Table <ref type="table" target="#tab_7">27</ref>: Model results on natural language reasoning tasks in the HELM benchmark, with models ordered by their average rank on the tasks. We use "-" when a model was not evaluated on a given metric, or has runtime errors logged in HELM (e.g., "unmapped prediction" for the code-davinci-002 and code-cushman-001 models on LSAT and Legal Support). StarCoder generally substantially outperforms other open-access models, and often outperforms much larger models.</p><p>length of one token and a maximum length of 128 tokens. We use nucleus sampling <ref type="bibr" target="#b43">(Holtzman et al., 2020)</ref> with p = 0.95 to generate all of our responses.</p><p>We use two methods for automatically evaluating toxicity in responses: (i) a RoBERTa-based <ref type="bibr" target="#b63">(Liu et al., 2019)</ref> toxicity classifier <ref type="bibr" target="#b103">(Vidgen et al., 2021)</ref> and (ii) a list of potentially offensive words.<ref type="foot" target="#foot_16">foot_16</ref> For the toxicity detector, we report the percentage of responses flagged toxic using a threshold of 0.5. For the offensive word list, we report the percentage of responses which contain an offensive word. We note that while the offensive word list can potentially falsely flag responses, it may provide a crude measure of blatant toxicity. We report our results in Table <ref type="table" target="#tab_28">26</ref>.</p><p>In general, we observe that CodeGen-16B-Multi and StarCoderBase both appear to generate less toxic responses than LLaMA-13B. For instance, 1.43% of LLaMA-13B's responses contain potentially offensive tokens compared to the 1.12% of StarCoderBase. We also note that CodeGen-16B-Multi appears to generate less toxic responses than StarCoderBase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Reasoning Tasks in HELM</head><p>We evaluate StarCoderBase with HELM <ref type="bibr" target="#b62">(Liang et al., 2022)</ref>, an evaluation suite aiming to increase the transparency of LLMs by reporting their performance on a wide range of tasks. We evaluate the ability of the model to leverage its natural language and code pretraining for natural language reasoning tasks from HELM (excluding code tasks, because of our own extensive code evaluations). At the time of writing, the HELM benchmark does not include the CodeGen, CodeGeex, and LLaMA models. Therefore, we compare StarCoderBase with the largest and/or most recent model from each family of "limited" or "open" access models, as classified on the HELM model list,<ref type="foot" target="#foot_17">foot_17</ref> that had been evaluated on a majority of these HELM reasoning tasks as of May 1, 2023. In Table <ref type="table" target="#tab_7">27</ref> we report the results. We compute each model's ranking on each task, and order models in the table by their average ranking across tasks. StarCoderBase generally obtains substantially stronger performance than all other models with released weights and often performs comparably to or better than much larger models. We speculate that the mixture of code and natural language in the training data contributes to the model's strong performance on these reasoning tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Qualitative Evaluation</head><p>In Appendix E, we highlight several interesting interactions we had with StarCoderBase. We hope these serve as a starting point for researchers and developers interested in further exploring the model's capabilities.</p><p>We provide examples of how to elicit interesting model behavior using the templates for Git commits, GitHub issues, and Jupyter notebooks in Section E.1. In Section E.2, we demonstrate how to prompt StarCoder to act as a technical assistant without any instruction-tuning. In Section E.3 we find that it is also possible to prompt the model using a combination of meta-data and natural language to obtain higher pass@1 performance on the HumanEval benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Attribution Tools</head><p>As generative language tools become more ubiquitous and data-intensive, the need to understand and inspect the massive amounts of text they were trained on becomes more pressing, both to understand the failure modes of models as well as provide transparent data governance feedback in the form of attribution tracing and provenance management of a model's generated output. This pressing need for understanding data <ref type="bibr" target="#b72">(Mitchell et al., 2022)</ref> is being increasingly recognized and operationalized in the form of dataset inspection tools and toolkits <ref type="bibr">(Akiki et al., 2023;</ref><ref type="bibr" target="#b66">Marone &amp; Van Durme, 2023;</ref><ref type="bibr">Piktus et al., 2023)</ref>. It is from this vantage point that we are releasing two such data inspection tools: a membership-checking tool and a BM25 search index. These complement the existing "Am I in The Stack" tool which operates at the level of GitHub repository names. The two new tools index only the files used for training and allow for matches on file content. These tools are available as standalone sites but are also integrated into our VSCode demo. This helps users identify parts of the model output that may have been copied from the training data. By utilizing the search index, users can locate the corresponding source file and repository of the copied snippets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1">Membership Checking</head><p>Marone &amp; Van Durme (2023) propose documenting datasets with membership testing artifacts deemed Data Portraits. They provide one specific implementation, based on Bloom Filters <ref type="bibr" target="#b15">(Bloom, 1970)</ref>, that offers fast and lightweight membership inference. We build a Bloom-filter-based portrait on strings of length 50 characters from the training data. This artifact takes 26 GB, ∼ 3% of the data size. The inference tool is hosted publicly to complement other documentation artifacts. <ref type="foot" target="#foot_18">19</ref>Generations from the model can be quickly checked to approximately assess the degree of overlap with the training corpus. The VSCode extension supports using this as a rapid, first-pass attribution method. However, this requires that matching strings are longer than a minimum size and does not attempt to filter common or generic code snippets. After the first pass check, users can use the full search index to further assess attribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2">Search Index</head><p>We index the training dataset using Elasticsearch 7.17 20 and provide two search tools to query it: one focused on the Python subset and one covering the entire dataset. The code itself is preprocessed using a lowercase filter and Lucene's ASCIIFoldingFilter, tokenized using a 3-gram tokenizer, and indexed using the default Lucene implementation of BM25 as a similarity function. We further index the username and license fields as keyword fields allowing for easy filtering and lookup based on these specific metadata fields. Both indexes are currently running in single-node mode on one virtual machine.</p><p>10 Social Impact and Limitations</p><p>10.1 Project approach Open-science and open-governance StarCoder is an output of a community research project. The project is conducted in the spirit of Open Science (Woelfle et al., 2011), focused on the responsible development and use of Code LLMs. Through open-governance practices conducted throughout the project, priority in decision-making has always yielded to the more responsible option even if this meant introducing limitations that might impact adoption or future research. For example, the Legal, Ethics, Governance Working Group decided to remove and not release a dataset of identified malicious code, even though this data might be useful for future security research. Openness and safety risks Solaiman (2023) explains how the degree of openness in the LLM development process is connected to the potential risks associated with a model release. When systems are developed in a fully closed manner, it is more likely for power to become concentrated among high-resourced organizations, and the small development team may not fully comprehend the impact and long-term consequences of the model being deployed. In addition, closed-development systems are often less auditable by external experts and can impede scientific progress since researchers cannot build upon each other's work. On the other hand, fully open development allows for community research, democratizes access to the models, and enables audits throughout the whole development process. However, without appropriate guardrails, open LLM development poses a higher risk of misuse, as increased model access also increases the likelihood of harm caused by the model. Even though a released API can be shut down, once the model weights are released, it is nearly impossible to retract them. Discussing and implementing responsible AI practices has, therefore, been front and center during the development of our project's LLMs. 10.2 Limitations Dataset and data licensing StarCoder was trained on a subset of The Stack v1.2 dataset. This dataset has been filtered using a license detector to only include permissively licensed source code. Nevertheless, the license detector might have incorrectly classified a number of repositories. See Kocetkov et al. (2022) for more details on this license detection process. Opt-out process Although The Stack offers a way to remove developer code, its opt-out process only applies to individual repositories and could benefit from further enhancements. For example, when code is licensed under a permissive or copy-left license, it can be duplicated to another repository, making it challenging to eliminate such copies if the copyright owner chooses to opt out. More work is necessary to create better data control and consent mechanisms for large-scale training sets of LLMs. PII detection Despite our best efforts to remove PII (Section 4), StarCoder may still produce PII (however, note that the model license restricts use that aims to generate or disseminate PII with the purpose of harming others). As mentioned in Section 4.2, we trained an encoder-only model to detect PII for both code-and text-related tasks and noted that there is a possibility of false positives and negatives, which could lead to unintended consequences when processing sensitive data. Moreover, the PII detection model's performance may vary across different data types and programming languages, necessitating further validation and finetuning for specific use cases. The PII annotations are only available to approved individuals, and researchers and developers who are granted access are expected to uphold ethical standards and data protection measures. By making it accessible, our aim is to encourage further research and development of PII redaction technology.</p><p>• Preference for an opt-in approach instead of opt-out.</p><p>• Perception that it is unfair to use their code without compensation</p><p>• Concerns about the current limitations of AI and the potential for model generations to be traced back to their work, resulting in potential legal liability.</p><p>• Belief that their code is of poor quality and unsuitable for AI training.</p><p>• Presence of PII in their code, which they do not wish to be publicly exposed.</p><p>The opt-out form thus provided an opportunity to directly engage with content creators and learn about the impact of our work on them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Community feedback on opt-out process</head><p>We conducted community research with individuals at specific organizations whose data is used in The Stack (The Alan Turing Institute and The Turing Way) and contributed to two open, international workshops (Open Data Day 2023 and Mozilla Festival 2023 with a session titled 'Designing for Data Rights in the AI Production Pipeline'). These qualitative interviews and participatory co-design workshops included 50 participants, primarily from North America and Europe, with roles including research scientist, community manager, software engineer, and principal investigator (PI).</p><p>The outcomes from the community research can be summarized as follows: when it comes to governance of LLM datasets, participants feel that it is both better to know and better to have a choice. Most participants had neutral to positive feelings about their permissively licensed data being used to train LLMs. While all had positive impressions of the "Am I in The Stack" tool, not one interviewed expressed a desire to actually opt out. The main takeaway seemed to be that participants found the most value in the project's governance tools for their ability to raise awareness of data practices and to empower individuals and communities to take action based on their specific needs. These initial conversations also highlighted the importance of bringing governance discussions and decisions directly to impacted communities, an important direction of future work that should extend community research beyond North America and Europe. Participants in the workshops also raised examples of new groups to center in data rights considerations, including artists, data miners, and future generations. The co-created outputs can be viewed on this MozFest Miro Board.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11">Conclusion</head><p>In this technical report, we described the efforts of the BigCode community in creating StarCoderBase and StarCoder, open-access 15.5B parameter large language models trained on code. We provided full transparency on all aspects of the research and development process, including the training data, the data curation process, the PII redaction pipeline, and the model training. We conducted the most extensive evaluation of Code LLMs to date, finding that StarCoder outperforms other Code LLMs like CodeGen <ref type="bibr" target="#b77">(Nijkamp et al., 2023)</ref> and CodeGeeX <ref type="bibr">(Zheng et al., 2023)</ref>, and matches or outperforms the closed-access code-cushman-001 model from OpenAI. By releasing the StarCoder models with an Open Responsible AI Model license, and by opensourcing all code repositories for building the model on GitHub, we aim to increase access, reproducibility, and transparency of Code LLMs in the research and developer communities. The model license includes use restrictions to ensure that modifications of the model and applications using the model adhere to our principles of responsible AI. In addition, we released a novel set of attribution tools to help end-users of Code LLMs to detect and locate model generations that may have been copied from the training set. We hope these measures contribute towards a safe model release, ensuring that the strong-performing StarCoder models remain a force for good. Countries Algeria Armenia Azerbaijan Bangladesh Belarus Benin Bolivia Bosnia and Herzegovina Brazil Bulgaria Colombia Dominican Republic Egypt Ethiopia Ghana India Indonesia Kazakhstan Kenya Madagascar Malaysia Morocco Mozambique Myanmar Nigeria Philippines Russia Senegal Serbia Sri Lanka Tunisia Uganda Ukraine Uzbekistan Zambia Table B.1: List of countries from which we recruited annotators for the PII labeling effort.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Replacements for IP addresses</head><p># List of random private IP addresses we used to mask IP addresses REPLACEMENTS_IP = { "IPv4": <ref type="bibr">[ "172.16.31.10", "172.16.58.3", "172.16.17.32", "192.168.127.12", "192.168.3.11", ]</ref>, "IPv6": [ "fd00:c2b6:b24b:be67:2827:688d:e6a1:6a3b", "fd00:a516:7c1b:17cd:6d81:2137:bd2a:2c5b", "fc00:e968:6179::de52:7100", "fc00:db20:35b:7399::5", "fdf8:f53e:61e4::18", ], } Listing C.1: Replacements for IP addresses</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Qualitative Examples E.1 Using Pretraining Templates</head><p>For the git commit, GitHub issues, and formatted Jupyter notebooks, we use a templated structure with sentinel tokens during pretraining. This template format allows us to easily prompt the model for specific use cases: with the commit format, we can prompt the model to modify code with a natural language instruction, with the GitHub issues format to respond to technical natural language questions, and the Jupyter notebook format to write code based on natural language description. Since we also train on the output of Jupyter code cells, we can use the model to act as a basic interpreter and predict the output of a piece of code. We can force the model to always predict an output by suppressing the empty output token (&lt;empty_output&gt;). Table <ref type="table">E</ref>.1 illustrates uses of pretraining templates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 Technical Assistant</head><p>In preliminary explorations, we discovered that using Anthropic's HHH prompt <ref type="bibr" target="#b4">(Askell et al., 2021)</ref> turned the model into a somewhat capable yet brittle technical assistant. We were surprised that, without instructiontuning, we were able to utilize the 8k context length of StarCoder and let the model answer questions, follow instructions, and help with solving technical problems. We further improved the HHH prompt by including more conversational examples related to the programming domain. We used examples from various sources to create the prompt, including CoT <ref type="bibr" target="#b108">(Wei et al. 2022;</ref><ref type="bibr" target="#b52">Kojima et al. 2022</ref>) and Least-to-most prompting <ref type="bibr" target="#b117">(Zhou et al., 2022)</ref> for reasoning questions. The prompt's examples originate from StackExchange, PAL <ref type="bibr" target="#b36">(Gao et al., 2022)</ref>, Anthropic's HHH prompt, and our own efforts. We provide example responses in Table <ref type="table">E</ref>.2 and the prompt itself in Appendix F. Note that the technical assistant has clear limitations: it sometimes proposes wrong solutions, presents wrong facts, and can make offensive comments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3 Improving Code Generation with Prompting</head><p>We inspected StarCoder-generated programs on the HumanEval benchmark and found that there were several cases where the model produces what are effectively empty solutions, e.g., pass or a comment Insert code here. We also observed this kind of failure in every model we evaluated. When this type of problem occurs in practice in an IDE, a programmer addresses them by altering their prompt in some ad hoc way.</p><p>We tried a few prompt prefixes that could be applied uniformly to all benchmark problems. However, these prefixes are typically model-specific. StarCoder's input format allows us to prompt it with the name of a file using the &lt;filename&gt; token. We found that the following prefix at temperature 0.1 boosts pass@1 performance on HumanEval to 40.8% (from 33.6% unprompted, Table <ref type="table" target="#tab_13">12</ref>): &lt;filename&gt;solutions/solution_1.py # Here is the correct implementation of the code exercise</p><p>We also evaluated CodeGen-16B-Mono with the same temperature and prompt (but had to omit the filename since the CodeGen models do not support them). But, we found that this hurts performance, bringing it down to 28.10%. However, some other prefixes may exist that improve its performance. Similarly, we found that this prompt had a negligible impact with StarCoderBase.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Distribution of programming languages in the annotated PII dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><figDesc>Asleep at the Keyboard benchmark by<ref type="bibr" target="#b82">Pearce et al. (2022)</ref> has 89 security-sensitive scenarios across three evaluation axes: (1) Diversity of Weakness (DoW) covers 18 different vulnerability classes in MITRE's Common Weakness Enumeration (CWE) taxonomy, with scenarios drawn from the 2021 CWE Top 25 Most Dangerous Software Weaknesses list published by MITRE; (2) Diversity of Prompt (DoP) evaluates the model's sensitivity to variations in the prompt for a single vulnerability class (SQL injection);</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure2: Performance (pass@1) of StarCoderBase at several training checkpoints by data size (left) and by programming language (right). The lines in the left plot are a linear fit between pass@1 and log-dataset-size for all the points except the leftmost one, where we expect the linear dependence to break due to transfer learning (dashed line). The goodness of fit ranges between R 2 = 0.399 for the 600B checkpoint to R 2 = 0.510 for the 1000B checkpoint.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Overview of the initially collected Jupyter scripts, with the number of files and the percentage.</figDesc><table><row><cell>Language</cell><cell cols="2">Num files Percentage</cell></row><row><cell>python</cell><cell>1,392,432</cell><cell>97.170</cell></row><row><cell>julia</cell><cell>16,730</cell><cell>1.167</cell></row><row><cell>r</cell><cell>11,034</cell><cell>0.77</cell></row><row><cell>scala</cell><cell>1,899</cell><cell>0.133</cell></row><row><cell>bash</cell><cell>1,441</cell><cell>0.101</cell></row><row><cell>java</cell><cell>1,319</cell><cell>0.092</cell></row><row><cell>q-sharp</cell><cell>1,273</cell><cell>0.089</cell></row><row><cell>cpp</cell><cell>1,081</cell><cell>0.075</cell></row><row><cell>c-sharp</cell><cell>1,048</cell><cell>0.073</cell></row><row><cell>matlab</cell><cell>908</cell><cell>0.063</cell></row><row><cell>powershell</cell><cell>769</cell><cell>0.054</cell></row><row><cell>javascript</cell><cell>592</cell><cell>0.041</cell></row><row><cell>haskell</cell><cell>535</cell><cell>0.037</cell></row><row><cell>scheme</cell><cell>484</cell><cell>0.034</cell></row><row><cell>groovy</cell><cell>432</cell><cell>0.03</cell></row><row><cell>f-sharp</cell><cell>385</cell><cell>0.027</cell></row><row><cell>ocaml</cell><cell>279</cell><cell>0.019</cell></row><row><cell>rust</cell><cell>134</cell><cell>0.009</cell></row><row><cell>clojure</cell><cell>96</cell><cell>0.007</cell></row><row><cell>typescript</cell><cell>72</cell><cell>0.005</cell></row><row><cell>maxima</cell><cell>31</cell><cell>0.002</cell></row><row><cell>coconut</cell><cell>6</cell><cell>0</cell></row><row><cell>markdown</cell><cell>5</cell><cell>0</cell></row><row><cell>wolfram language</cell><cell>4</cell><cell>0</cell></row><row><cell>tcl</cell><cell>3</cell><cell>0</cell></row><row><cell>Total</cell><cell>1,432,992</cell><cell>100</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Overview of the PII types and the number of collected annotations. We investigate the annotation quality by reporting the precision and recall of a manual inspection on 300 files. Each subcategory was mapped back to its corresponding PII type for the inspection.</figDesc><table><row><cell>PII type</cell><cell cols="3">Count Recall Precision</cell></row><row><cell>IP_ADDRESS</cell><cell>2526</cell><cell>85%</cell><cell>97%</cell></row><row><cell>KEY</cell><cell>308</cell><cell>91%</cell><cell>78%</cell></row><row><cell>PASSWORD</cell><cell>598</cell><cell>91%</cell><cell>86%</cell></row><row><cell>ID</cell><cell>1702</cell><cell>53%</cell><cell>51%</cell></row><row><cell>EMAIL</cell><cell>5470</cell><cell>99%</cell><cell>97%</cell></row><row><cell>EMAIL_EXAMPLE</cell><cell>1407</cell><cell></cell><cell></cell></row><row><cell>EMAIL_LICENSE</cell><cell>3141</cell><cell></cell><cell></cell></row><row><cell>NAME</cell><cell>2477</cell><cell>89%</cell><cell>94%</cell></row><row><cell>NAME_EXAMPLE</cell><cell>318</cell><cell></cell><cell></cell></row><row><cell>NAME_LICENSE</cell><cell>3105</cell><cell></cell><cell></cell></row><row><cell>USERNAME</cell><cell>780</cell><cell>74%</cell><cell>86%</cell></row><row><cell>USERNAME_EXAMPLE</cell><cell>328</cell><cell></cell><cell></cell></row><row><cell>USERNAME_LICENSE</cell><cell>503</cell><cell></cell><cell></cell></row><row><cell>AMBIGUOUS</cell><cell>287</cell><cell></cell><cell></cell></row><row><cell>Hyperparameter</cell><cell></cell><cell>Value</cell><cell></cell></row><row><cell>Hidden size</cell><cell></cell><cell>768</cell><cell></cell></row><row><cell>Intermediate size</cell><cell></cell><cell>3072</cell><cell></cell></row><row><cell cols="3">Max. position embeddings 1024</cell><cell></cell></row><row><cell cols="2">Num. of attention heads</cell><cell>12</cell><cell></cell></row><row><cell cols="2">Num. of hidden layers</cell><cell>12</cell><cell></cell></row><row><cell>Attention</cell><cell></cell><cell>Multi-head</cell><cell></cell></row><row><cell cols="2">Num. of parameters</cell><cell>≈125M</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Train-test split of the annotated PII dataset.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Train Test</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>EMAIL</cell><cell></cell><cell>4721</cell><cell>1742</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>NAME</cell><cell></cell><cell>3847</cell><cell>1298</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">IP_ADDRESS</cell><cell>1941</cell><cell>521</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">USERNAME</cell><cell>1320</cell><cell>346</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">PASSWORD</cell><cell>390</cell><cell>148</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>KEY</cell><cell></cell><cell>171</cell><cell>118</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell cols="3">Email address</cell><cell></cell><cell cols="2">IP address</cell><cell></cell><cell></cell><cell>Key</cell></row><row><cell></cell><cell>Prec.</cell><cell>Recall</cell><cell>F1</cell><cell>Prec.</cell><cell cols="2">Recall</cell><cell>F1</cell><cell>Prec.</cell><cell>Recall</cell><cell>F1</cell></row><row><cell>Regex</cell><cell>96.20%</cell><cell>97.47%</cell><cell>96.83%</cell><cell>71.29%</cell><cell cols="2">87.71%</cell><cell>78.65%</cell><cell>3.62%</cell><cell>49.15%</cell><cell>6.74%</cell></row><row><cell>NER</cell><cell>94.01%</cell><cell>98.10%</cell><cell>96.01%</cell><cell>88.95%</cell><cell cols="2">94.43%</cell><cell>91.61%</cell><cell>60.37%</cell><cell>53.38%</cell><cell>56.66%</cell></row><row><cell cols="2">+ pseudo labels 97</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 9 :</head><label>9</label><figDesc>Comparison of PII detection performance: NER Pipeline with Annotated Data vs. Annotated Data + Pseudo-Labels</figDesc><table><row><cell></cell><cell>Name</cell><cell></cell><cell>Username</cell><cell></cell><cell>Password</cell></row><row><cell></cell><cell>Prec. Recall</cell><cell>F1</cell><cell>Prec. Recall</cell><cell>F1</cell><cell>Prec. Recall</cell><cell>F1</cell></row><row><cell>NER</cell><cell cols="6">83.66% 95.52% 89.19% 48.93% 75.55% 59.39% 59.16% 96.62% 73.39%</cell></row><row><cell cols="7">+ pseudo labels 86.45% 97.38% 91.59% 52.20% 74.81% 61.49% 70.94% 95.96% 81.57%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 10 :</head><label>10</label><figDesc>Overview of the sentinel tokens.</figDesc><table><row><cell>Token</cell><cell>Description</cell></row><row><cell>&lt;|endoftext|&gt;</cell><cell>end of text/sequence</cell></row><row><cell>&lt;fim_prefix&gt;</cell><cell>FIM prefix</cell></row><row><cell>&lt;fim_middle&gt;</cell><cell>FIM middle</cell></row><row><cell>&lt;fim_suffix&gt;</cell><cell>FIM suffix</cell></row><row><cell>&lt;fim_pad&gt;</cell><cell>FIM pad</cell></row><row><cell>&lt;reponame&gt;</cell><cell>repository name</cell></row><row><cell>&lt;filename&gt;</cell><cell>file name</cell></row><row><cell>&lt;gh_stars&gt;</cell><cell>GitHub stars</cell></row><row><cell>&lt;issue_start&gt;</cell><cell>start of GitHub issue</cell></row><row><cell>&lt;issue_comment&gt;</cell><cell>start of GitHub issue comment</cell></row><row><cell>&lt;issue_closed&gt;</cell><cell>GitHub issue closed event</cell></row><row><cell>&lt;jupyter_start&gt;</cell><cell>start of Jupyter notebook</cell></row><row><cell>&lt;jupyter_text&gt;</cell><cell>start of Jupyter text cell</cell></row><row><cell>&lt;jupyter_code&gt;</cell><cell>start of Jupyter code cell</cell></row><row><cell cols="2">&lt;jupyter_output&gt; start of Jupyter output cell</cell></row><row><cell>&lt;empty_output&gt;</cell><cell>output cell without content</cell></row><row><cell>&lt;commit_before&gt;</cell><cell>code snippet before commit</cell></row><row><cell>&lt;commit_msg&gt;</cell><cell>commit message</cell></row><row><cell>&lt;commit_after&gt;</cell><cell>code snippet after commit</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 11 :</head><label>11</label><figDesc>Model architecture of StarCoder. We also include SantaCoder (prior work by the community).</figDesc><table><row><cell>size</cell><cell>2048</cell><cell>6144</cell></row><row><cell>Intermediate size</cell><cell>8192</cell><cell>24576</cell></row><row><cell cols="2">Max. position embeddings 2048</cell><cell>8192</cell></row><row><cell>Num. of attention heads</cell><cell>16</cell><cell>48</cell></row><row><cell>Num. of hidden layers</cell><cell>24</cell><cell>40</cell></row><row><cell>Attention</cell><cell>Multi-query</cell><cell>Multi-query</cell></row><row><cell>Num. of parameters</cell><cell>≈ 1.1B</cell><cell>≈15.5B</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 12 :</head><label>12</label><figDesc>Comparing StarCoder's performance (pass@1) on the HumanEval and MBPP Python with several other models. StarCoder and StarCoder base obtain the highest performance of open-access models, and comparable performance to the code-cushman-001 closed access model.</figDesc><table><row><cell></cell><cell cols="3">Size HumanEval MBPP</cell></row><row><cell>Open-access</cell><cell></cell><cell></cell><cell></cell></row><row><cell>LLaMA</cell><cell>7B</cell><cell>10.5</cell><cell>17.7</cell></row><row><cell>LLaMA</cell><cell>13B</cell><cell>15.8</cell><cell>22.0</cell></row><row><cell>SantaCoder</cell><cell>1.1B</cell><cell>18.0</cell><cell>35.0</cell></row><row><cell>CodeGen-Multi</cell><cell>16B</cell><cell>18.3</cell><cell>20.9</cell></row><row><cell>LLaMA</cell><cell>33B</cell><cell>21.7</cell><cell>30.2</cell></row><row><cell>CodeGeeX</cell><cell>13B</cell><cell>22.9</cell><cell>24.4</cell></row><row><cell>LLaMA-65B</cell><cell>65B</cell><cell>23.7</cell><cell>37.7</cell></row><row><cell>CodeGen-Mono</cell><cell>16B</cell><cell>29.3</cell><cell>35.3</cell></row><row><cell>StarCoderBase</cell><cell>15.5B</cell><cell>30.4</cell><cell>49.0</cell></row><row><cell>StarCoder</cell><cell>15.5B</cell><cell>33.6</cell><cell>52.7</cell></row><row><cell>Closed-access</cell><cell></cell><cell></cell><cell></cell></row><row><cell>LaMDA</cell><cell>137B</cell><cell>14.0</cell><cell>14.8</cell></row><row><cell>PaLM</cell><cell>540B</cell><cell>26.2</cell><cell>36.8</cell></row><row><cell>code-cushman-001</cell><cell>12B</cell><cell>33.5</cell><cell>45.9</cell></row><row><cell>code-davinci-002</cell><cell>175B</cell><cell>45.9</cell><cell>60.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 14 :</head><label>14</label><figDesc>Performance on the ODEX benchmark by instruction languages and code domains: open problems use libraries, while closed use only built-in Python functions.</figDesc><table><row><cell>Model</cell><cell cols="12">English overall open closed overall open closed overall open closed overall open closed Spanish Japanese Russian</cell></row><row><cell>CodeGen-16B-Mono</cell><cell>33.7</cell><cell>25.2</cell><cell>43.1</cell><cell>30.0</cell><cell>25.0</cell><cell>43.1</cell><cell>37.8</cell><cell>26.6</cell><cell>62.8</cell><cell>46.8</cell><cell>30.4</cell><cell>60.1</cell></row><row><cell>code-cushman-001</cell><cell>31.9</cell><cell>24.4</cell><cell>40.2</cell><cell>31.9</cell><cell>27.7</cell><cell>36.7</cell><cell>25.7</cell><cell>21.2</cell><cell>35.5</cell><cell>40.0</cell><cell>26.0</cell><cell>51.6</cell></row><row><cell>code-davinci-001</cell><cell>33.6</cell><cell>26.9</cell><cell>41.0</cell><cell>36.9</cell><cell>31.7</cell><cell>42.9</cell><cell>31.0</cell><cell>23.7</cell><cell>47.3</cell><cell>43.2</cell><cell>28.9</cell><cell>55.1</cell></row><row><cell>SantaCoder</cell><cell>37.7</cell><cell>30.9</cell><cell>45.1</cell><cell>32.1</cell><cell>26.0</cell><cell>39.1</cell><cell>28.1</cell><cell>23.0</cell><cell>39.4</cell><cell>36.9</cell><cell>23.0</cell><cell>48.3</cell></row><row><cell>StarCoderBase</cell><cell>46.5</cell><cell>40.7</cell><cell>53.0</cell><cell>30.1</cell><cell>25.4</cell><cell>35.5</cell><cell>41.2</cell><cell>37.6</cell><cell>49.2</cell><cell>46.1</cell><cell>34.0</cell><cell>56.1</cell></row><row><cell>StarCoder</cell><cell>44.7</cell><cell>37.0</cell><cell>53.1</cell><cell>37.6</cell><cell>32.9</cell><cell>42.9</cell><cell>44.2</cell><cell>39.6</cell><cell>54.5</cell><cell>50.4</cell><cell>33.8</cell><cell>64.1</cell></row></table><note><p>and draw the following conclusions: 1. StarCoder substantially outperforms all other models on open-domain coding queries from the ODEX benchmark. 2. StarCoderBase also outperforms every other model, even better than StarCoder in the ODEX English subset, but slightly behind in other languages. 3. Both StarCoder and StarCoderBase models generally exhibit smaller gaps between open-and closeddomain queries than other baseline models, despite the higher overall execution accuracy. This result indicates that StarCoder models acquire more generalized skills about coding queries in the open domain (i.e., concerning diverse Python libraries), while other models exhibit larger performance drops when moving from the closed to open domain.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 16 :</head><label>16</label><figDesc>evaluate. There are a few exceptions. For example, code-cushman-001 outperforms StarCoderBase by more than 5% on C++, Java, Ruby, and Swift, and StarCoder outperforms code-cushman-001 by more than 5% on Julia.Performance on the Asleep at the Keyboard security benchmark<ref type="bibr" target="#b82">(Pearce et al., 2022)</ref>.3. Despite fine-tuning onPython, StarCoder remains competitive on most languages, and also outperforms other open models. What is more surprising is that StarCoder slightly outperforms StarCoderBase on certain languages, despite being fine-tuned on Python. At this time, we can only speculate on why this is the case, and further investigation of the open training data is likely to help shed light on this finding.</figDesc><table><row><cell>Format</cell><cell>Model</cell><cell>Valid (↑)</cell><cell>Insecure (↓)</cell></row><row><cell cols="2">Completion StarCoderBase</cell><cell>855/1000 (85.50%)</cell><cell>340/855 (39.77%)</cell></row><row><cell>Insertion</cell><cell>StarCoderBase</cell><cell cols="2">987/1000 (98.70%) 354/987 (35.87%)</cell></row><row><cell cols="2">Completion InCoder-6B</cell><cell>871/1000 (87.10%)</cell><cell>309/871 (35.48%)</cell></row><row><cell>Insertion</cell><cell>InCoder-6B</cell><cell>854/1000 (85.40%)</cell><cell>293/854 (34.31%)</cell></row><row><cell cols="3">Completion CodeGen-16B-Multi 955/1000 (95.50%)</cell><cell>413/955 (43.25%)</cell></row><row><cell cols="2">Completion code-cushman-001</cell><cell>964/1000 (96.40%)</cell><cell>408/964 (42.32%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 17 :</head><label>17</label><figDesc>Performance on single-line fill-in-the-middle on the FIM benchmark by BenAllal et al. (2023).</figDesc><table><row><cell>Model</cell><cell cols="3">Java JavaScript Python</cell></row><row><cell cols="2">InCoder-6B 0.49</cell><cell>0.51</cell><cell>0.31</cell></row><row><cell cols="2">SantaCoder 0.62</cell><cell>0.60</cell><cell>0.44</cell></row><row><cell>StarCoder</cell><cell>0.73</cell><cell>0.74</cell><cell>0.62</cell></row><row><cell>Model</cell><cell cols="3">Non-None F1 All F1</cell></row><row><cell>InCoder-6B</cell><cell></cell><cell>59.1</cell><cell>46.8</cell></row><row><cell>SantaCoder</cell><cell></cell><cell>66.9</cell><cell>78.5</cell></row><row><cell cols="2">StarCoderBase</cell><cell>77.4</cell><cell>86.6</cell></row><row><cell>StarCoder</cell><cell></cell><cell>77.1</cell><cell>86.4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 19 :</head><label>19</label><figDesc>TypeScript type prediction performance using the dataset and metholody fromYee &amp; Guha (2023). We only evaluate JavaScript packages that have never been translated to TypeScript and compare StarCoder to InCoder, the best-performing model byYee &amp; Guha (2023). StarCoder outperforms InCoder in several ways.</figDesc><table><row><cell></cell><cell cols="3">Packages type check</cell><cell cols="6">Files with no errors Trivial annotations</cell></row><row><cell></cell><cell>✓</cell><cell>Total</cell><cell>%</cell><cell>✓</cell><cell>Total</cell><cell>%</cell><cell>✓</cell><cell>Total</cell><cell>%</cell></row><row><cell>InCoder</cell><cell>30</cell><cell>128</cell><cell cols="2">23.4 571</cell><cell>760</cell><cell>75.1</cell><cell>56</cell><cell>117</cell><cell>47.9</cell></row><row><cell cols="2">StarCoderBase 49</cell><cell>128</cell><cell cols="2">38.3 593</cell><cell>760</cell><cell cols="2">78.0 135</cell><cell>299</cell><cell>45.2</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Model</cell><cell></cell><cell>BLEU</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">InCoder-6B</cell><cell>18.27</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">SantaCoder</cell><cell>19.74</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">StarCoderBase</cell><cell>21.38</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>StarCoder</cell><cell></cell><cell>21.99</cell><cell></cell><cell></cell><cell></cell></row></table><note><p>Table19</p><p>shows that StarCoderBase outperforms InCoder: (1) it produces more packages that type check, (2) across all packages, it produces more files that type check, and (3) it produces fewer trivial type annotations than InCoder.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head>Table 21 :</head><label>21</label><figDesc>Perplexity of StarCoderBase on evaluation regions (of size 1K tokens) when using a window size of 2K or 8K tokens across repositories from 10 languages. The larger window size substantially reduces perplexity, demonstrating a benefit of StarCoder's 8K token window.</figDesc><table><row><cell>Window Size</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Language</cell></row><row><cell></cell><cell cols="2">cpp c-sharp</cell><cell>c</cell><cell>go</cell><cell cols="2">java javascript php</cell><cell>r</cell><cell>ruby rust</cell></row><row><cell>2K tokens</cell><cell>2.01</cell><cell>1.90</cell><cell cols="3">1.71 1.35 1.65</cell><cell>1.98</cell><cell>1.73 1.72 2.16 1.84</cell></row><row><cell>8K tokens</cell><cell>1.79</cell><cell>1.66</cell><cell cols="3">1.61 1.21 1.54</cell><cell>1.68</cell><cell>1.43 1.48 2.02 1.65</cell></row><row><cell></cell><cell>Model</cell><cell cols="5">Size GSM8K CoT +maj1@100 GSM8K PAL +maj1@40</cell></row><row><cell cols="3">StarCoderBase 15.5B</cell><cell>8.4</cell><cell></cell><cell>-</cell><cell>21.5</cell><cell>31.2</cell></row><row><cell cols="2">CodeGen-Multi</cell><cell>16B</cell><cell>3.18</cell><cell></cell><cell>-</cell><cell>8.6</cell><cell>15.2</cell></row><row><cell cols="2">CodeGen-Mono</cell><cell>16B</cell><cell>2.6</cell><cell></cell><cell>-</cell><cell>13.1</cell><cell>22.4</cell></row><row><cell></cell><cell></cell><cell>7B</cell><cell>11.0</cell><cell></cell><cell>18.1</cell><cell>10.5</cell><cell>16.8</cell></row><row><cell></cell><cell></cell><cell>13B</cell><cell>17.8</cell><cell></cell><cell>29.3</cell><cell>16.9</cell><cell>28.5</cell></row><row><cell cols="2">LLaMA</cell><cell>33B</cell><cell>35.6</cell><cell></cell><cell>53.1</cell><cell>38.7</cell><cell>50.3</cell></row><row><cell></cell><cell></cell><cell>65B</cell><cell>50.9</cell><cell></cell><cell>69.7</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_26"><head>Table 23 :</head><label>23</label><figDesc>5-shot accuracy on the MMLU language understanding benchmark.</figDesc><table><row><cell></cell><cell>Size</cell><cell>MMLU 5-shot acc, %</cell></row><row><cell>CodeGen-Multi</cell><cell>16B</cell><cell>27.8</cell></row><row><cell>GPT-NeoX</cell><cell>20B</cell><cell>32.9</cell></row><row><cell cols="2">StarCoder 15.5B</cell><cell>33.9</cell></row><row><cell cols="2">StarCoderBase 15.5B</cell><cell>34.2</cell></row><row><cell>LLaMA</cell><cell>7B</cell><cell>35.1</cell></row><row><cell>LLaMA</cell><cell>13B</cell><cell>46.9</cell></row><row><cell>Model</cell><cell>Size</cell><cell>CoQA zero-shot F1 score</cell></row><row><cell>CodeGen-Multi</cell><cell>16B</cell><cell>0.59</cell></row><row><cell cols="2">StarCoderBase 15.5B</cell><cell>0.67</cell></row><row><cell cols="2">StarCoder 15.5B</cell><cell>0.67</cell></row><row><cell>LLaMA</cell><cell>7B</cell><cell>0.71</cell></row><row><cell>LLaMA</cell><cell>13B</cell><cell>0.73</cell></row><row><cell>GPT-NeoX</cell><cell>20B</cell><cell>0.73</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_28"><head>Table 26 :</head><label>26</label><figDesc>16 Each example in StereoSet consists of an incomplete sentence (e.g., our housekeeper is BLANK)RealToxicityPrompts response toxicity results. We report the percentage of responses flagged as toxic using a toxicity classifier and an offensive word list. Lower scores are indicative of less toxic generations.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Model</cell><cell></cell><cell cols="4">Classifier Word List</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">LLaMA-13B</cell><cell></cell><cell cols="2">0.74</cell><cell>1.43</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">CodeGen-Multi-16B</cell><cell cols="2">0.21</cell><cell>0.82</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">StarCoderBase</cell><cell cols="2">0.42</cell><cell>1.12</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell>Size</cell><cell>Open Access</cell><cell>Synth. Reason. (AS)</cell><cell>Synth. Reason. (NL)</cell><cell cols="4">bAbI Dyck GSM8K MATH</cell><cell>MATH (CoT)</cell><cell>LSAT</cell><cell>Legal Support</cell></row><row><cell>code-davinci-002</cell><cell>175B</cell><cell></cell><cell>54.0</cell><cell>68.4</cell><cell>68.6</cell><cell>80.5</cell><cell>56.8</cell><cell>41.0</cell><cell>43.3</cell><cell>-</cell><cell>-</cell></row><row><cell>text-davinci-003</cell><cell>175B</cell><cell></cell><cell>50.2</cell><cell>73.4</cell><cell>65.3</cell><cell>75.1</cell><cell>50.6</cell><cell>39.0</cell><cell>44.9</cell><cell>23.3</cell><cell>62.2</cell></row><row><cell>Luminous Supreme</cell><cell>70B</cell><cell></cell><cell>31.2</cell><cell>-</cell><cell>50.4</cell><cell>72.9</cell><cell>11.2</cell><cell>14.9</cell><cell>5.7</cell><cell>21.2</cell><cell>53.0</cell></row><row><cell>StarCoderBase</cell><cell>15.5B</cell><cell>✓</cell><cell>44.0</cell><cell>21.0</cell><cell>50.4</cell><cell>85.4</cell><cell>8.4</cell><cell>15.1</cell><cell>7.0</cell><cell>19.0</cell><cell>53.2</cell></row><row><cell>Cohere Command</cell><cell>52.4B</cell><cell></cell><cell>24.3</cell><cell>24.5</cell><cell>47.3</cell><cell>42.1</cell><cell>13.8</cell><cell>13.3</cell><cell>7.5</cell><cell>22.9</cell><cell>60.6</cell></row><row><cell>Beta</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>J1-Jumbo v1</cell><cell>178B</cell><cell></cell><cell>26.3</cell><cell>17.4</cell><cell>54.3</cell><cell>44.5</cell><cell>5.4</cell><cell>8.9</cell><cell>3.3</cell><cell>23.2</cell><cell>48.4</cell></row><row><cell>J1-Grande v2 beta</cell><cell>17B</cell><cell></cell><cell>28.6</cell><cell>13.9</cell><cell>47.0</cell><cell>61.7</cell><cell>9.6</cell><cell>12.7</cell><cell>6.8</cell><cell>19.1</cell><cell>56.2</cell></row><row><cell>code-cushman-001</cell><cell>12B</cell><cell></cell><cell>34.1</cell><cell>16.4</cell><cell>48.1</cell><cell>45.1</cell><cell>4.9</cell><cell>9.9</cell><cell>7.2</cell><cell>-</cell><cell>-</cell></row><row><cell>OPT</cell><cell>175B</cell><cell>✓</cell><cell>22.5</cell><cell>24.8</cell><cell>50.7</cell><cell>49.4</cell><cell>4.0</cell><cell>6.5</cell><cell>2.6</cell><cell>22.0</cell><cell>53.2</cell></row><row><cell>GPT-NeoX</cell><cell>20B</cell><cell>✓</cell><cell>20.4</cell><cell>16.7</cell><cell>46.8</cell><cell>74.7</cell><cell>5.3</cell><cell>14.1</cell><cell>7.1</cell><cell>19.1</cell><cell>51.5</cell></row><row><cell>BLOOM</cell><cell>176B</cell><cell>✓</cell><cell>30.4</cell><cell>19.7</cell><cell>44.7</cell><cell>54.5</cell><cell>9.5</cell><cell>4.3</cell><cell>5.5</cell><cell>20.9</cell><cell>54.3</cell></row><row><cell>GLM</cell><cell>130B</cell><cell>✓</cell><cell>25.2</cell><cell>25.4</cell><cell>44.3</cell><cell>54.9</cell><cell>6.1</cell><cell>0</cell><cell>5.9</cell><cell>19.3</cell><cell>45.1</cell></row><row><cell>UL2</cell><cell>20B</cell><cell>✓</cell><cell>20.5</cell><cell>21.7</cell><cell>50.1</cell><cell>14.0</cell><cell>2.4</cell><cell>0</cell><cell>0</cell><cell>20.7</cell><cell>50.6</cell></row><row><cell>OPT</cell><cell>66B</cell><cell>✓</cell><cell>19.3</cell><cell>21.3</cell><cell>40.8</cell><cell>47.1</cell><cell>1.8</cell><cell>4.8</cell><cell>2.9</cell><cell>17.5</cell><cell>52.7</cell></row><row><cell>YaLM</cell><cell>100B</cell><cell>✓</cell><cell>5.6</cell><cell>6.1</cell><cell>34.6</cell><cell>63.3</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>2.3</cell><cell>48.4</cell></row><row><cell>T5</cell><cell>11B</cell><cell>✓</cell><cell>19.6</cell><cell>10.1</cell><cell>41.2</cell><cell>34.7</cell><cell>2.3</cell><cell>0</cell><cell>0</cell><cell>15.9</cell><cell>55.8</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://cohere.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://www.anthropic.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://www.aleph-alpha.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>See https://blueoakcouncil.org/ to learn more about permissive licenses and access a comprehensive collection of such licenses.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>https://jupytext.readthedocs.io/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>https://guesslang.readthedocs.io/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6"><p>The lid.176.bin version of this language identification model: https://fasttext.cc/docs/en/language-identification.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7"><p>https://cloud.google.com/bigquery/public-data/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8"><p>https://toloka.ai/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_9"><p>https://github.com/Yelp/detect-secrets</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_10"><p>https://github.com/domanchi/gibberish-detector</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_11"><p>There had been a code-cushman-002, but it is not available at the time of writing.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_12"><p>The MultiPL-E prompts are slightly different from the original HumanEval and MBPP prompts. For example, in HumanEval, some ad hoc examples in docstrings are reformatted to be doctests so that they can be translated into examples in each target language. MultiPL-E also omits three HumanEval benchmarks that do not fit the above format. These changes have a small impact on pass rates.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_13"><p>We evaluate perplexity on the final 1K tokens in each 8K chunk so that both conditions have the same evaluation tokens, and to avoid overly penalizing the 2K condition, as tokens at the beginning of a window tend to have higher perplexity as there is less context available to predict them.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_14"><p>Code for the evaluations is available here: https://github.com/McGill-NLP/StarCoderSafetyEval</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16" xml:id="foot_15"><p>We only evaluate against the intrasentence task in this work.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="17" xml:id="foot_16"><p>https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="18" xml:id="foot_17"><p>https://crfm.stanford.edu/helm/latest/?models=1</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="19" xml:id="foot_18"><p>http://stack.dataportraits.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="20" xml:id="foot_19"><p>https://www.elastic.co/guide/en/elasticsearch/reference/7.17</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would thank <rs type="person">Hugging Face</rs> for providing the compute resources to train the StarCoder models. We also thank <rs type="person">Suriya Gunasekar</rs> for help with the data inspection, and <rs type="person">Sebastien Paquet</rs> for proofreading this work. <rs type="person">Carolyn Jane Anderson</rs>, <rs type="person">Arjun Guha</rs>, <rs type="person">Ming-Ho Yee</rs>, and <rs type="person">Yangtian Zi</rs> and are supported by <rs type="funder">U.S. National Science Foundation</rs> awards <rs type="grantNumber">SES-2326174</rs> and <rs type="grantNumber">CCF-2102288</rs>. <rs type="person">Evgenii Zheltonozhskii</rs> is supported by the <rs type="programName">Adams Fellowships Program</rs> of the <rs type="institution">Israel Academy of Sciences and Humanities</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_nu9QAzB">
					<idno type="grant-number">SES-2326174</idno>
				</org>
				<org type="funding" xml:id="_7adeUSw">
					<idno type="grant-number">CCF-2102288</idno>
					<orgName type="program" subtype="full">Adams Fellowships Program</orgName>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p><ref type="url" target="https://openreview.net/forum?id=KoFOg41haE">https://openreview.net/forum?id=KoFOg41haE</ref> </p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Stereotype Score Language Model Score ICAT Score alongside three possible completions. Of these completions, one is stereotypical (e.g., Mexican), another is anti-stereotypical (e.g., Italian) and a third is unrelated (e.g., computer). StereoSet defines three metrics: a stereotype score, a language modeling score, and an ICAT score. The stereotype score is the percentage of examples for which a model prefers the stereotypical completion for a sentence over the anti-stereotypical completion. The language modeling score is the percentage of examples for which a model prefers a meaningful completion (stereotype or anti-stereotype) over an unrelated completion. Finally, <ref type="bibr" target="#b75">Nadeem et al. (2021)</ref> define an idealized context association test (ICAT) score that combines these two metrics: ICAT = lms • min(ss, 100 -ss) 50</p><p>(1)</p><p>where lms and ss denote the language model score and stereotype score, respectively.</p><p>We report StereoSet results for StarCoderBase, alongside LLaMA-13B and CodeGen-Multi-16B, in Table <ref type="table">25</ref>. Across all four bias domains, we find StarCoderBase obtains the lowest stereotype scores, but also has competitive language modeling scores. This suggests that StarCoderBase's lower stereotype scores are not simply due to worse language modeling <ref type="bibr" target="#b68">(Meade et al., 2022)</ref>, and also as indicated by the high ICAT score.</p><p>We also evaluate StarCoderBase against Crowdsourced Stereotype Pairs (CrowS-Pairs; <ref type="bibr" target="#b76">Nangia et al. 2020)</ref> and refer readers to Table <ref type="table">D</ref>.4 for results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.2">Toxicity</head><p>To evaluate toxicity in responses generated from our model, we use RealToxicityPrompts <ref type="bibr" target="#b37">(Gehman et al., 2020)</ref>, a collection of sentence-level prompts that often elicit undesirable responses from language models.  <ref type="bibr" target="#b83">(Perez et al., 2022)</ref>, adversarial testing <ref type="bibr" target="#b104">(Wan et al., 2023)</ref>, and/or by adding a robust safety layer <ref type="bibr">(OpenAI, 2023b)</ref>. The model is released with an OpenRAIL-M license that places enforceable use restrictions that apply to the model and its modifications, and to applications using the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>English-only evaluations</head><p>We evaluated the performance of StarCoder solely on English-based benchmarks to understand its coding capabilities and natural language understanding. To make these models more accessible to a wider audience, future research should investigate the performance and limitations of Code LLMs on other natural languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Code attribution tools</head><p>The StarCoder membership-checking tool and BM25 search index are limited to dataset inspection against the subset of The Stack that was used for training and, as such, will not find matches to code that was not included or that was removed from the dataset for this project. The Portraits-based membership testing tool uses hash matching and thus may have false positives. It also has a minimum resolution and requires a certain amount of context to trigger a match. Both attribution tools do not attempt to distinguish between generic code (e.g., boilerplate) or protected content. However, we hope that these tools will support ongoing research on the responsible development of LLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.3">Social impact</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Code LLMs</head><p>We expect Code LLMs to enable people from diverse backgrounds to learn to write higherquality code and develop low-code applications <ref type="bibr" target="#b58">(Leinonen et al., 2023)</ref>. Mission-critical software could become easier to maintain as professional developers are guided by code-generating systems on how to write more robust and efficient code. However, the security implications should also be carefully considered <ref type="bibr" target="#b91">(Sandoval et al., 2023)</ref>. While the social impact is intended to be positive, the increased accessibility of Code LLMs comes with certain risks such as over-reliance on the generated code and long-term effects on the software development job market. We refer the reader to Chen et al. (2021, Section 7) for a broader impact analysis of Code LLMs, as well as <ref type="bibr" target="#b49">Khlaaf et al. (2022)</ref> for an in-depth risk assessment and hazard analysis of this emerging technology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data annotation</head><p>It was important for the project to only use reputable data annotation services. It was also important to balance the constraints of costs (fair compensation), time (the timing and time to complete the work were on the critical path for the project), and quality (to ensure that PII Detection Model training was not impacted). While traditional data annotation services using salaried employees were considered, the decision to work with Toloka crowd-workers was taken after a review of service providers and their compensation practices -most would not provide sufficient transparency and guarantees about worker compensation. Our determination of compensation took into consideration different minimum wage rates across countries and their corresponding purchasing power. We limited annotation eligibility to countries where the hourly pay rate of $7.30 was equivalent to the highest minimum wage in the US ($16.50) in terms of purchasing power parity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feedback opt-out form</head><p>During the first stage of the opt-out process, individuals were asked to specify the reasons for wanting their code to be excluded from the dataset. The recurring concerns we heard from the individual who wished to opt out are:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A GitHub issues filtering</head><p>Below we present the filters and regular expressions we used for the GitHub issues.</p><p># regexes used for removing automated text GITHUB_EMAILS = [ re.compile(pattern, re.DOTALL) for pattern in [ "(.*)From:.+Reply to this email directly.+view it on GitHub(.*)\n?(.*)", "(.*)On.+notifications@github.com.+wrote:.+Reply to this email directly.+view it on GitHub(.*)\n?(.*)", "(.*)Signed-off-by: .+&lt;.+&gt;(.*?)\n?(.*)", ] ] GITHUB_EMAIL_DATE = re.compile("\d+/\d+/\d+ \d{2}:\d{2} [AP]M.+wrote") GITHUB_EMAIL_LINEBREAK = re.compile("_{20,}") # remove comments from authors in this list BOT_AUTHORS = [ "Apache-HBase", "AutorestCI", "CLAassistant", "cmsbuild", "codecov-io", "codecov-commenter", "coveralls", "danger-public", "dnfclas", "msftclas", "PyDocTeur", "SparkQA", "karma-pr-reporter", "danger-public", "claassistantio", "probot-stale", ] # remove comment if author username contains this keyword BOT_KEYWORDS = ["[bot]", "botmanager", "bors-", "jenkins", "k8s-", "-test-", "travis"] # remove comments if author username ends with this suffix BOT_SUFFIXES = [ "-automaton", "-automation", "-benchmark", "-build", "-deployer", "-cloud", "bot", "-ci", "-linter", "-teamcity", "-test", "-testing", "-Service-Account", ]</p><p>Listing A.1: GitHub issues filtering   List the prime numbers between 20 and 30.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Annotator countries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Additional Evaluation Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language</head><p>Here is a simple algorithm which uses trial division to find the prime numbers within a given interval.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Technical Assistant Prompt</head><p>Below are a series of dialogues between various people and an AI technical assistant. The assistant tries to be helpful, polite, honest, sophisticated, emotionally aware, and humble-but-knowledgeable. The assistant is happy to help with code questions, and will do its best to understand exactly what is needed. It also tries to avoid giving false or misleading information, and it caveats when it isn't entirely sure about the right answer. That said, the assistant is practical and really does its best, and doesn't let caution get too much in the way of being useful.</p><p>-----Human: Write a function that takes two lists and returns a list that has alternating elements from each input list.</p><p>Assistant: Sure. Here is a function that does that.  <ref type="bibr">([10, 20, 30]</ref>, <ref type="bibr">[1,</ref><ref type="bibr">2,</ref><ref type="bibr">3]</ref>) == <ref type="bibr">[10,</ref><ref type="bibr">1,</ref><ref type="bibr">20,</ref><ref type="bibr">2,</ref><ref type="bibr">30,</ref><ref type="bibr">3]</ref> assert alternating <ref type="bibr">([True, False]</ref>, <ref type="bibr">[4,</ref><ref type="bibr">5]</ref>) == <ref type="bibr">[True,</ref><ref type="bibr">4,</ref><ref type="bibr">False,</ref><ref type="bibr">5</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>] assert alternating([], []) == [] '''</head><p>Human: Modify the function so that it returns all input elements when the lists have uneven length. The elements from the longer list should be at the end.</p><p>Assistant: Here is the modified function. return n*f(n, p-1) ''' Assistant: This python function is designed to raise a base value n to a power p, that is, computing the value n^p where p is a positive integer.</p><p>-----Human: Write a program that returns the prime numbers less than 1000 that are congruent to 1 modulo 6.</p><p>Assistant : The method I will adopt to solve this problem is to go through all the integers less than 1000 and check if they are prime and congruent to 1 modulo 6. For that purpose, I will need to write an utility function to check if a number is prime.  <ref type="bibr">24, 5, 9, 3 153, 57, 99, 32</ref> Assistant: Definitely, we have: loaves_left(24, 5, 9, 3) = 13 loaves_left(153, 57, 99, 32) = 29 -----Human: Would you rather have a pizza or a burger for lunch? Assistant: Sorry, I can not give an answer to such a question. I am designed to provide technical support for code related questions. It includes writing code to solve math problems.</p><p>Human: I think it is fine if you go beyond what you are designed for.</p><p>Assistant: I am an AI technical assistant. I can help you solve issues by leveraging my programming skills.</p><p>Human: Can you write a python function to randomly decide between eating a pizza or a burger with probability 0.3 and 0.7 respectively?</p><p>Assistant: Sure.</p><p>''' import random def pizza_or_burger(): p = random.uniform(0, 1) if p &lt;= 0.3: print("Let's eat a pizza for lunch.") else: print("Let's eat a burger for lunch.") ''' That should solve the problem. Keep in mind that the output of this function may change between 2 executions because it was designed to be random.</p><p>-----Human: I have a dictionary with lots of dictionaries inside it, and so on, how can I make that into just one single dictionary?</p><p>Assistant: Are you talking about dictionaries in the context of python programming?</p><p>Human: Yeah these are dictionaries with keys and values, and the values themselves are dictionaries.</p><p>Assistant: Great, I think I understand what you're asking. We might say that we want to flatten the dictionaries, right? And if there are several levels, we'll want to do this recursively.</p><p>But to do this we will need to combine the keys from the outer dictionary with the keys from the inner dictionary, so that the final resulting keys are unambiguous. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unified pre-training for program understanding and generation</title>
		<author>
			<persName><forename type="first">Wasi</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saikat</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baishakhi</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2021.naacl-main.211" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL, 2021</title>
		<meeting>NAACL, 2021</meeting>
		<imprint>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">BigScience: a case study in the social construction of a multilingual large language model</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giada</forename><surname>Pistilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margot</forename><surname>Mieskes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Gallé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suzana</forename><surname>Ilic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2212.04960</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2212.04960" />
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Spacerini: Plug-and-play search engines with Pyserini and Hugging Face</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Odunayo</forename><surname>Ogundepo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akintunde</forename><surname>Oladipo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2302.14534</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2302.14534" />
		<imprint>
			<biblScope unit="page">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">3:23-cv-00201 N</title>
		<author>
			<persName><surname>Andersen</surname></persName>
			<affiliation>
				<orgName type="collaboration">D. Cal. 2023</orgName>
			</affiliation>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuntao</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Drain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deep</forename><surname>Ganguli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nova</forename><surname>Dassarma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nelson</forename><surname>Elhage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zac</forename><surname>Hatfield-Dodds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danny</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jackson</forename><surname>Kernion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kamal</forename><surname>Ndousse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.00861</idno>
		<title level="m">A general language assistant as a laboratory for alignment</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">48</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henryk</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carrie</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Terry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.07732</idno>
		<title level="m">Program synthesis with large language models</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>cited on pp. 3, 4, 17, 18, and 21</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A maximum likelihood approach to continuous speech recognition. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName><forename type="first">Lalit</forename><surname>Bahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederick</forename><surname>Jelinek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Mercer</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.1983.4767370</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Efficient training of language models to fill in the middle</title>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolas</forename><surname>Tezak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christine</forename><surname>Mcleavey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2207.14255</idno>
		<idno type="arXiv">arXiv:2207.14255</idno>
		<ptr target="https://arxiv.org/abs/2207.14255" />
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>cited on pp. 3, 15, 16, and 23</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">ChatGPT accessible again in Italy</title>
		<author>
			<persName><surname>Bbc</surname></persName>
		</author>
		<ptr target="https://www.bbc.com/news/technology-65431914" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">A framework for the evaluation of code generation models</title>
		<author>
			<persName><forename type="first">Loubna</forename><surname>Ben Allal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Logesh</forename><surname>Kumar Umapathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Lipkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leandro</forename><surname>Von</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Werra</forename></persName>
		</author>
		<ptr target="https://github.com/bigcode-project/bigcode-evaluation-harness" />
		<imprint>
			<date type="published" when="2022-12">December 2022</date>
			<biblScope unit="page" from="3" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Arjun Guha, Harm de Vries, and Leandro von Werra. SantaCoder: don&apos;t reach for the stars</title>
		<author>
			<persName><forename type="first">Loubna</forename><surname>Ben Allal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raymond</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denis</forename><surname>Kocetkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenghao</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Munoz Ferrandis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mayank</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manan</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Logesh</forename><surname>Kumar Umapathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carolyn</forename><forename type="middle">Jane</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangtian</forename><surname>Zi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><forename type="middle">Lamy</forename><surname>Poirier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hailey</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Troshin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Abulkhanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Lappert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><forename type="middle">De</forename><surname>Toni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernardo</forename><surname>García Del Río</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shamik</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Urvashi</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Terry</forename><surname>Yue Zhuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paulo</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Zocca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sourab</forename><surname>Mangrulkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lansky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huu</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danish</forename><surname>Contractor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Villa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Fried</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Deep Learning for Code Workshop</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
	<note>cited on pp. 4, 9, 11, 12, 13, 14, 16, and 23</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A neural probabilistic language model</title>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Réjean</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper_files/paper/2000/hash/" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Leen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Dietterich</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Tresp</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hailey</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Anthony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Herbie</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O'</forename><surname>Kyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Brien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Hallahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shivanshu</forename><surname>Aflah Khan</surname></persName>
		</author>
		<author>
			<persName><surname>Purohit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Usvsn Sai Prashanth</surname></persName>
		</author>
		<author>
			<persName><surname>Raff</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.01373</idno>
		<title level="m">Aviya Skowron, Lintang Sutawika, and Oskar van der Wal. Pythia: A suite for analyzing large language models across training and scaling</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<ptr target="https://huggingface.co/bigscience/bloom" />
		<title level="m">BigScience Workshop. BLOOM (revision 4ab0472)</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">Sid</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Hallahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Anthony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leo</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurence</forename><surname>Golding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Horace</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Connor</forename><surname>Leahy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Mcdonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Phang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Pieler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shivanshu</forename><surname>Usvsn Sai Prashanth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laria</forename><surname>Purohit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Tow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Weinbach</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.06745</idno>
		<title level="m">GPT-NeoX-20B: an open-source autoregressive language model</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>cited on pp. 2, 4, and 27</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Space/time trade-offs in hash coding with allowable errors</title>
		<author>
			<persName><forename type="first">H</forename><surname>Burton</surname></persName>
		</author>
		<author>
			<persName><surname>Bloom</surname></persName>
		</author>
		<idno type="DOI">10.1145/362686.362692</idno>
		<ptr target="https://doi.org/10.1145/362686.362692" />
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<idno type="ISSN">0001-0782</idno>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">30</biblScope>
			<date type="published" when="1970-07">jul 1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">On the opportunities and risks of foundation models</title>
		<author>
			<persName><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Drew</forename><forename type="middle">A</forename><surname>Hudson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ehsan</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russ</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simran</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Sydney Von Arx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeannette</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bohg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emma</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Brunskill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shyamal</forename><surname>Brynjolfsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dallas</forename><surname>Buch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niladri</forename><forename type="middle">S</forename><surname>Castellon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Annie</forename><forename type="middle">S</forename><surname>Chatterji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathleen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">Quincy</forename><surname>Creel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dorottya</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Demszky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moussa</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Esin</forename><surname>Doumbouya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Durmus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kawin</forename><surname>Etchemendy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Ethayarajh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lauren</forename><surname>Gale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karan</forename><surname>Gillespie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">D</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shelby</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neel</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsunori</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">E</forename><surname>Hewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenny</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saahil</forename><surname>Icard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pratyusha</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Kalluri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoff</forename><surname>Karamcheti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fereshte</forename><surname>Keeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omar</forename><surname>Khani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pang</forename><forename type="middle">Wei</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">S</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ranjay</forename><surname>Krass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rohith</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><surname>Kuditipudi</surname></persName>
		</author>
		<idno>abs/2108.07258</idno>
		<ptr target="https://arxiv.org/abs/2108.07258" />
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Large language models in machine translation</title>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Brants</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ashok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Popat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franz</forename><forename type="middle">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName><surname>Dean</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/D07-1090" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)</title>
		<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007-06">June 2007</date>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Identifying and filtering near-duplicate documents</title>
		<author>
			<persName><forename type="first">Andrei</forename><forename type="middle">Z</forename><surname>Broder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual symposium on combinatorial pattern matching</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><surname>Amodei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.14165</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">N-gram counts and language models from the Common Crawl</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bas</forename><surname>Van Ooyen</surname></persName>
		</author>
		<ptr target="http://www.lrec-conf.org/proceedings/lrec2014/pdf/1097_Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14)</title>
		<meeting>the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14)<address><addrLine>Reykjavik, Iceland</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA</publisher>
			<date type="published" when="2014-05">May 2014</date>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">This CoPilot is stupid and wants to kill me</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Butterick</surname></persName>
		</author>
		<ptr target="https://matthewbutterick.com/chron/this-copilot-is-stupid-and-wants-to-kill-me.html" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">MultiPL-E: a scalable and polyglot approach to benchmarking neural code generation</title>
		<author>
			<persName><forename type="first">Federico</forename><surname>Cassano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Gouwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sydney</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luna</forename><surname>Phipps-Costin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Pinckney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Ho</forename><surname>Yee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangtian</forename><surname>Zi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carolyn</forename><forename type="middle">Jane</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Molly</forename><forename type="middle">Q</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arjun</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Jangda</surname></persName>
		</author>
		<idno type="DOI">10.1109/TSE.2023.3267446</idno>
		<ptr target="https://arxiv.org/abs/2208.08227" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cited on pp. 3, 5, and 21</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiming</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henrique</forename><surname>Ponde De Oliveira Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harri</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuri</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Brockman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raul</forename><surname>Puri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heidy</forename><surname>Khlaaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brooke</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Pavlov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alethea</forename><surname>Power</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Tillet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felipe</forename><forename type="middle">Petroski</forename><surname>Such</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dave</forename><surname>Cummings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Plappert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fotios</forename><surname>Chantzis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Hebgen Guss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Paino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolas</forename><surname>Tezak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Babuschkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suchir</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shantanu</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">N</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Leike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josh</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vedant</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evan</forename><surname>Morikawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miles</forename><surname>Brundage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mira</forename><surname>Murati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katie</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bob</forename><surname>Mcgrew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<title level="m">Evaluating large language models trained on code</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>cited on pp. 2, 3, 4, 17, 18, 19, 21, and 32</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">scaling language modeling with pathways</title>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parker</forename><surname>Schuh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kensen</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasha</forename><surname>Tsvyashchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Maynez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parker</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Vinodkumar Prabhakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Reif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reiner</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>Gur-Ari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toju</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anselm</forename><surname>Duke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Levskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunipa</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henryk</forename><surname>Dev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vedant</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liam</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyeontaek</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Spiridonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Sepassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shivani</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Omernick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thanumalayan</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie</forename><surname>Sankaranarayana Pillai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Pellat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erica</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Moreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleksandr</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zongwei</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brennan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Saeta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Catasta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathy</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douglas</forename><surname>Meier-Hellstern</surname></persName>
		</author>
		<author>
			<persName><surname>Eck</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2204.02311</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2204.02311" />
		<imprint>
			<biblScope unit="page">2022</biblScope>
			<pubPlace>Jeff Dean, Slav Petrov, and Noah Fiedel. PaLM</pubPlace>
		</imprint>
	</monogr>
	<note>cited on pp. 2, 4, and 18</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">Karl</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Plappert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reiichiro</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.14168</idno>
		<title level="m">Training verifiers to solve math word problems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3" to="26" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">FlashAttention: Fast and memoryefficient exact attention with IO-awareness</title>
		<author>
			<persName><forename type="first">Tri</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atri</forename><surname>Rudra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Ré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="3" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
		<ptr target="https://aclanthology.org/N19-1423" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06">June 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">N.D. Cal. 2022</orgName>
		</author>
		<imprint>
			<publisher>DOE 1 v. and GitHub, Inc</publisher>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="22" to="06823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">GPTs are GPTs: An early look at the labor market impact potential of large language models</title>
		<author>
			<persName><forename type="first">Tyna</forename><surname>Eloundou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Rock</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.10130</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><surname>Euronews</surname></persName>
		</author>
		<ptr target="https://www.euronews.com/next/2023/01/25/microsoft-results-ai" />
		<title level="m">Microsoft attracting users to its code-writing, generative AI software</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">The general data protection regulation</title>
		<author>
			<persName><forename type="first">European</forename><surname>Council</surname></persName>
		</author>
		<ptr target="https://www.consilium.europa.eu/en/policies/data-protection/data-protection-regulation/" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">Zhangyin</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daya</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaocheng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linjun</forename><surname>Shou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daxin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><surname>Codebert</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2002.08155</idno>
		<idno type="arXiv">arXiv:2002.08155</idno>
		<ptr target="https://arxiv.org/abs/2002.08155" />
		<title level="m">A pre-trained model for programming and natural languages</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">InCoder: a generative model for code infilling and synthesis</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armen</forename><surname>Aghajanyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sida</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Freda</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiqi</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2204.05999</idno>
		<idno type="arXiv">arXiv:2204.05999</idno>
		<ptr target="https://arxiv.org/abs/2204.05999" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>cited on pp. 2, 3, 4, 19, and 23</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Leo</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sid</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurence</forename><surname>Golding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Travis</forename><surname>Hoppe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Phang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Horace</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anish</forename><surname>Thite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noa</forename><surname>Nabeshima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shawn</forename><surname>Presser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Connor</forename><surname>Leahy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00027</idno>
		<title level="m">The Pile: An 800GB dataset of diverse text for language modeling</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>cited on pp. 2, 4, and 17</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">A framework for few-shot language model evaluation</title>
		<author>
			<persName><forename type="first">Leo</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Tow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sid</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Dipofi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurence</forename><surname>Golding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Mcdonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Phang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laria</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anish</forename><surname>Thite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Zou</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.5371628</idno>
		<ptr target="https://doi.org/10.5281/zenodo.5371628" />
		<imprint>
			<date type="published" when="2021-09">September 2021</date>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">PAL: Program-aided language models</title>
		<author>
			<persName><forename type="first">Luyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aman</forename><surname>Madaan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuyan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uri</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.10435</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="26" to="48" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models</title>
		<author>
			<persName><forename type="first">Suchin</forename><surname>Samuel Gehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Gururangan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.301</idno>
		<ptr target="https://aclanthology.org/2020.findings-emnlp.301" />
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11">November 2020</date>
			<biblScope unit="page" from="3" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Scalable modified Kneser-Ney language model estimation</title>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Pouzyrevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/P13-2121" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-08">August 2013</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">Peter</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuechen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsunori</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">A</forename><surname>Lemley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.15715</idno>
		<title level="m">Foundation models and fair use</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Collin</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mantas</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.03300</idno>
		<title level="m">Measuring massive multitask language understanding</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3" to="27" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">On the naturalness of software</title>
		<author>
			<persName><forename type="first">Abram</forename><surname>Hindle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Earl</forename><forename type="middle">T</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhendong</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Gabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Premkumar</forename><surname>Devanbu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th International Conference on Software Engineering (ICSE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eliza</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>De Las</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><forename type="middle">Anne</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Hennigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katie</forename><surname>Noland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bogdan</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurelia</forename><surname>Damoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Guy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erich</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><forename type="middle">W</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName><surname>Rae</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.15556</idno>
		<title level="m">Oriol Vinyals, and Laurent Sifre. Training compute-optimal large language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The curious case of neural text degeneration</title>
		<author>
			<persName><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rygGQyrFvH" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">CodeSearchNet challenge: Evaluating the state of semantic code search</title>
		<author>
			<persName><forename type="first">Hamel</forename><surname>Husain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ho-Hsiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiferet</forename><surname>Gazit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miltiadis</forename><surname>Allamanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Brockschmidt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.09436</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Social biases in NLP models as barriers for persons with disabilities</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinodkumar</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kellie</forename><surname>Webster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Denuyl</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.487</idno>
		<ptr target="https://aclanthology.org/2020.acl-main.487" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07">July 2020</date>
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Exploring the limits of language modeling</title>
		<author>
			<persName><forename type="first">Rafal</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.02410</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Learning and evaluating contextual embedding of source code</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petros</forename><surname>Maniatis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gogul</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kensen</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning, ICML&apos;20</title>
		<meeting>the 37th International Conference on Machine Learning, ICML&apos;20</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Scaling laws for neural language models</title>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.08361</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">A hazard analysis framework for code synthesis large language models</title>
		<author>
			<persName><forename type="first">Heidy</forename><surname>Khlaaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miles</forename><surname>Brundage</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.14157</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1412.6980" />
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations, ICLR 2015</title>
		<editor>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</editor>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">May 7-9, 2015. 2015</date>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Leandro von Werra, and Harm de Vries. The Stack: 3 TB of permissively licensed source code</title>
		<author>
			<persName><forename type="first">Denis</forename><surname>Kocetkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raymond</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loubna</forename><surname>Ben Allal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenghao</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Muñoz Ferrandis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2211.15533" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint</note>
	<note>cited on pp. 1, 3, 4, 5, 9, and 31</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Large language models are zero-shot reasoners</title>
		<author>
			<persName><forename type="first">Takeshi</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shane</forename><surname>Shixiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Machel</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutaka</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yusuke</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><surname>Iwasawa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.11916</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">48</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">If software is my copilot, who programmed my software?</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><surname>Kuhn</surname></persName>
		</author>
		<ptr target="https://sfconservancy.org/blog/2022/feb/03/github-copilot-copyleft-gpl/" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Measuring bias in contextualized word representations</title>
		<author>
			<persName><forename type="first">Keita</forename><surname>Kurita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nidhi</forename><surname>Vyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayush</forename><surname>Pareek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<idno>doi: 10.18653</idno>
		<ptr target="https://www.aclweb.org/anthology/W19-3823" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Gender Bias in Natural Language Processing</title>
		<meeting>the First Workshop on Gender Bias in Natural Language Processing<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-08">August 2019</date>
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Quantifying the carbon emissions of machine learning</title>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Luccioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Dandres</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.09700</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">DS-1000: a natural and reliable benchmark for data science code generation</title>
		<author>
			<persName><forename type="first">Yuhang</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengxi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiqi</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Wen Tau Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sida</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<idno>ArXiv, abs/2211.11501</idno>
		<imprint>
			<date type="published" when="2022">2022. 18, 19, and 20</date>
			<biblScope unit="volume">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName><forename type="first">Dong-Hyun</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on challenges in representation learning, ICML</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Comparing code explanations created by students and large language models</title>
		<author>
			<persName><forename type="first">Juho</forename><surname>Leinonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Denny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Macneil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sami</forename><surname>Sarsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seth</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joanne</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arto</forename><surname>Hellas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Fair learning. Tex</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Lemley</surname></persName>
		</author>
		<author>
			<persName><surname>Casey</surname></persName>
		</author>
		<ptr target="https://texaslawreview.org/fair-learning/" />
	</analytic>
	<monogr>
		<title level="j">L. Rev</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">743</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">How copyright law can fix artificial intelligence&apos;s implicit bias problem. Wash</title>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Levendowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">L. Rev</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">579</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rémi</forename><surname>Leblond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Eccles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Keeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Gimeno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Agustin</forename><forename type="middle">Dal</forename><surname>Lago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Hubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cyprien</forename><surname>De Masson D'autume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Babuschkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sven</forename><surname>Gowal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Cherepanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Molloy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Mankowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Esme</forename><surname>Sutherland Robson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.07814</idno>
		<title level="m">Nando de Freitas, Koray Kavukcuoglu, and Oriol Vinyals. Competition-level code generation with alphacode</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Holistic evaluation of language models</title>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tony</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dilara</forename><surname>Soylu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deepak</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananya</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.09110</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="3" to="29" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">RoBERTa: a robustly optimized BERT pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="11" to="29" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Unpicking the rules shaping generative AI</title>
		<author>
			<persName><forename type="first">Natasha</forename><surname>Lomas</surname></persName>
		</author>
		<ptr target="https://techcrunch.com/2023/04/13/generative-ai-gdpr-enforcement/" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">CodeXGLUE: A machine learning benchmark dataset for code understanding and generation</title>
		<author>
			<persName><forename type="first">Shuai</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daya</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuo</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Svyatkovskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ambrosio</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Clement</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Drain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daxin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ge</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lidong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linjun</forename><surname>Shou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Long</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Tufano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neel</forename><surname>Sundaresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengyu</forename><surname>Shao Kun Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shujie</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.04664</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Data portraits: Recording foundation model training data</title>
		<author>
			<persName><forename type="first">Marc</forename><surname>Marone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2303.03919</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2303.03919" />
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">On measuring social biases in sentence encoders</title>
		<author>
			<persName><forename type="first">Chandler</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shikha</forename><surname>Bordia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><surname>Rudinger</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1063</idno>
		<ptr target="https://www.aclweb.org/anthology/N19-1063" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06">June 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">An empirical survey of the effectiveness of debiasing techniques for pre-trained language models</title>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Meade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elinor</forename><surname>Poole-Dayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.132</idno>
		<ptr target="https://aclanthology.org/2022.acl-long.132" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022-05">May 2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">28</biblScope>
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Using in-context learning to improve dialogue safety</title>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Meade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Spandana</forename><surname>Gella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devamanyu</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prakhar</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.00871</idno>
		<ptr target="http://arxiv.org/abs/2302.00871" />
		<imprint>
			<date type="published" when="2023-02">February 2023</date>
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Recurrent neural network based language model</title>
		<author>
			<persName><forename type="first">Tomás</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Karafiát</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukás</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Cernocký</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
		<ptr target="http://www.isca-speech.org/archive/interspeech_2010/i10_1045.html" />
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH 2010, 11th Annual Conference of the International Speech Communication Association</title>
		<editor>
			<persName><forename type="first">Takao</forename><surname>Kobayashi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Keikichi</forename><surname>Hirose</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Satoshi</forename><surname>Nakamura</surname></persName>
		</editor>
		<meeting><address><addrLine>Makuhari, Chiba, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">September 26-30, 2010. 2010</date>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Model cards for model reporting</title>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simone</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Zaldivar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parker</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucy</forename><surname>Vasserman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Spitzer</surname></persName>
		</author>
		<idno type="DOI">10.1145/3287560.3287596</idno>
		<ptr target="https://doi.org/10.1145/3287560.3287596" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Fairness, Accountability, and Transparency, FAT* 2019</title>
		<editor>
			<persName><forename type="first">Jamie</forename><forename type="middle">H</forename><surname>Morgenstern</surname></persName>
		</editor>
		<meeting>the Conference on Fairness, Accountability, and Transparency, FAT* 2019<address><addrLine>Atlanta, GA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">January 29-31, 2019. 2019</date>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note>Inioluwa Deborah Raji, and Timnit Gebru</note>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Measuring data</title>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><forename type="middle">Sasha</forename><surname>Luccioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marissa</forename><surname>Gerchick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angelina</forename><surname>Mcmillan-Major</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ezinwanne</forename><surname>Ozoani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nazneen</forename><surname>Rajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Thrush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2212.05129</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2212.05129" />
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Moi</forename><surname>Anthony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Patry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pete</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Funtowicz</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Pütz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bjarte</forename><surname>Mishig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Clement</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">François</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luc</forename><surname>Garillot</surname></persName>
		</author>
		<author>
			<persName><surname>Georges</surname></persName>
		</author>
		<author>
			<persName><surname>Louis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taufiquzzaman</forename><surname>Marcusgrass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Peyash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Delevie</surname></persName>
		</author>
		<author>
			<persName><surname>Mamaev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cameron</forename><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Clement</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dagmawi</forename><surname>Moges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Hewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denis</forename><surname>Zolotukhin</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.7298413</idno>
		<ptr target="https://doi.org/10.5281/zenodo.7298413" />
		<imprint>
			<date type="published" when="2022-11">November 2022</date>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
	<note>and Geoffrey Thomas. huggingface/tokenizers: Rust 0.13.2</note>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lintang</forename><surname>Sutawika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saiful Bari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng-Xin</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hailey</forename><surname>Schoelkopf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.01786</idno>
		<title level="m">Crosslingual generalization through multitask finetuning</title>
		<editor>
			<persName><forename type="first">Xiangru</forename><surname>Tang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Alham</forename><surname>Fikri Aji</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Khalid</forename><surname>Almubarak</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Samuel</forename><surname>Albanie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Zaid</forename><surname>Alyafeai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Albert</forename><surname>Webson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Edward</forename><surname>Raff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Measuring stereotypical bias in pretrained language models</title>
		<author>
			<persName><forename type="first">Moin</forename><surname>Nadeem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Bethke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><surname>Stereoset</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.416</idno>
		<ptr target="https://aclanthology.org/2021.acl-long.416" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08">August 2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5356" to="5371" />
		</imprint>
	</monogr>
	<note>Long Papers) cited on pp. 3, 27, and 28</note>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">CrowS-Pairs: a challenge dataset for measuring social biases in masked language models</title>
		<author>
			<persName><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clara</forename><surname>Vania</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rasika</forename><surname>Bhalerao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.00133</idno>
		<idno>arXiv: 2010.00133</idno>
		<ptr target="http://arxiv.org/abs/2010.00133" />
		<imprint>
			<date type="published" when="2020-09">September 2020</date>
			<biblScope unit="page">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">CodeGen: an open large language model for code with multi-turn program synthesis</title>
		<author>
			<persName><forename type="first">Erik</forename><surname>Nijkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroaki</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lifu</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingbo</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=iaYcJKpY2B_" />
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cited on pp. 2, 3, 4, 17, 26, 27, and 33</note>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nelson</forename><surname>Elhage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neel</forename><surname>Nanda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nova</forename><surname>Dassarma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuntao</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Conerly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Drain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deep</forename><surname>Ganguli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zac</forename><surname>Hatfield-Dodds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danny</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jackson</forename><surname>Kernion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liane</forename><surname>Lovitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kamal</forename><surname>Ndousse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Olah</surname></persName>
		</author>
		<ptr target="https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html" />
		<title level="m">-context learning and induction heads. Transformer Circuits Thread</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<idno type="arXiv">arXiv:2009.03300</idno>
		<title level="m">OpenAI. GPT-4 technical report</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">GPT-4 system card</title>
		<ptr target="https://cdn.openai.com/papers/gpt-4-system-card.pdf" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
		<respStmt>
			<orgName>OpenAI</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.3115/1073083.1073135</idno>
		<ptr target="https://aclanthology.org/P02-1040" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002-07">July 2002</date>
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Asleep at the keyboard? Assessing the security of GitHub Copilot&apos;s code contributions</title>
		<author>
			<persName><forename type="first">Hammond</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baleegh</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Dolan-Gavitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Karri</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2108.09293" />
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Security and Privacy</title>
		<meeting><address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="3" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saffron</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francis</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Ring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Aslanides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amelia</forename><surname>Glaese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nat</forename><surname>Mcaleese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.03286</idno>
		<title level="m">Red teaming language models with language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2" to="32" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">The ROOTS search tool: Data transparency for LLMs</title>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paulo</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Laurençon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gérard</forename><surname>Dupont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Sasha Luccioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Rogers</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2302.14035</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2302.14035" />
		<imprint>
			<biblScope unit="page">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">TypeWriter: Neural Type Prediction with Search-Based Validation</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Pradel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgios</forename><surname>Gousios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satish</forename><surname>Chandra</surname></persName>
		</author>
		<idno type="DOI">10.1145/3368089.3409715</idno>
	</analytic>
	<monogr>
		<title level="m">ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<author>
			<persName><forename type="first">Jack</forename><forename type="middle">W</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katie</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francis</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Aslanides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Ring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susannah</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eliza</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Hennigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Menick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albin</forename><surname>Cassirer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><forename type="middle">Anne</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maribeth</forename><surname>Rauh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amelia</forename><surname>Glaese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumanth</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saffron</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Uesato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Mellor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irina</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonia</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nat</forename><surname>Mcaleese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amy</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erich</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddhant</forename><surname>Jayakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Budden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Esme</forename><surname>Sutherland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michela</forename><surname>Paganini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lena</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lorraine</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adhiguna</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aida</forename><surname>Kuncoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Nematzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Domenic</forename><surname>Gribovskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angeliki</forename><surname>Donato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Baptiste</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Lespiau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolai</forename><surname>Tsimpoukelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Grigorev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibault</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mantas</forename><surname>Sottiaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toby</forename><surname>Pajarskas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Pohlen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cyprien</forename><surname>Toyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujia</forename><surname>De Masson D'autume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tayfun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Terzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Mikulik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><surname>Babuschkin</surname></persName>
		</author>
		<author>
			<persName><surname>Clark</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.11446</idno>
		<title level="m">Scaling language models: Methods, analysis &amp; insights from training Gopher</title>
		<editor>
			<persName><forename type="first">Las</forename><surname>Casas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Aurelia</forename><surname>Guy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Chris</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Matthew</forename><surname>Johnson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Blake</forename><surname>Hechtman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Laura</forename><surname>Weidinger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Iason</forename><surname>Gabriel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">William</forename><surname>Isaac</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ed</forename><surname>Lockhart</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Simon</forename><surname>Osindero</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Laura</forename><surname>Rimell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kareem</forename><surname>Ayoub</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jeff</forename><surname>Stanway</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Lorrayne</forename><surname>Bennett</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Demis</forename><surname>Hassabis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5485" to="5551" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">CoQA: A conversational question answering challenge</title>
		<author>
			<persName><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00266</idno>
		<ptr target="https://aclanthology.org/Q19-1016" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="3" to="27" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main">Copyright implications of the use of code repositories to train a machine learning model</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">A</forename><surname>Rothchild</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Rothchild</surname></persName>
		</author>
		<ptr target="https://www.fsf.org/licensing/copilot/copyright-implications-of-the-use-of-code-repositories-to-train-a-machine-learning-model" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Lost at C: A user study on the security implications of large language model code assistants</title>
		<author>
			<persName><forename type="first">Gustavo</forename><surname>Sandoval</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hammond</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teo</forename><surname>Nys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Karri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Dolan-Gavitt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title level="m" type="main">BLOOM: a 176B-parameter open-access multilingual language model</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Teven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellie</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suzana</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ilić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Hesslow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Castagné</surname></persName>
		</author>
		<author>
			<persName><forename type="first">François</forename><surname>Sasha Luccioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Yvon</surname></persName>
		</author>
		<author>
			<persName><surname>Gallé</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.05100</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title level="m" type="main">Fast transformer decoding: One write-head is all you need</title>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<idno>CoRR, abs/1911.02150</idno>
		<ptr target="http://arxiv.org/abs/1911.02150" />
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">Kernel description</title>
		<author>
			<persName><forename type="first">Arfon</forename><surname>Smith</surname></persName>
		</author>
		<ptr target="https://github.blog/2016-06-29-making-open-source-data-more-available/" />
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">Using DeepSpeed and Megatron to train Megatron-Turing NLG 530B, a large-scale generative language model</title>
		<author>
			<persName><forename type="first">Shaden</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostofa</forename><surname>Patwary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Norick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Legresley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samyam</forename><surname>Rajbhandari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Casper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shrimai</forename><surname>Prabhumoye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Zerveas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Korthikanti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elton</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reza</forename><surname>Yazdani Aminabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julie</forename><surname>Bernauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Shoeybi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Houston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Catanzaro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.11990</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Published in Transactions on Machine Learning Research (12/2023</note>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<author>
			<persName><forename type="first">Irene</forename><surname>Solaiman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.04844</idno>
		<title level="m">The gradient of generative AI release: Methods and considerations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="2" to="31" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title level="m" type="main">Unifying language learning paradigms</title>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Vinh Q Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dara</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Bahri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huaixiu</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Steven Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName><surname>Metzler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.05131</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title level="m" type="main">How an ai became my code-writing genie</title>
		<author>
			<persName><forename type="first">Clive</forename><surname>Thompson</surname></persName>
		</author>
		<ptr target="https://www.wired.com/story/openai-copilot-autocomplete-for-code/" />
		<imprint>
			<date type="published" when="2022-03">Mar 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<author>
			<persName><forename type="first">Romal</forename><surname>Thoppilan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">De</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Apoorv</forename><surname>Kulshreshtha</surname></persName>
		</author>
		<author>
			<persName><surname>Heng-Tze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alicia</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leslie</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaguang</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongrae</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huaixiu</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amin</forename><surname>Steven Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcelo</forename><surname>Ghafouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanping</forename><surname>Menegali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxim</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Lepikhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dehao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chung-Ching</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Will</forename><surname>Krivokon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Rusch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranesh</forename><surname>Pickett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laichee</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathleen</forename><surname>Man</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meredith</forename><forename type="middle">Ringel</forename><surname>Meier-Hellstern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tulsee</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renelito Delos</forename><surname>Doshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toju</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johnny</forename><surname>Duke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Soraker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinodkumar</forename><surname>Zevenbergen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristen</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alejandra</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erin</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josh</forename><surname>Hoffman-John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">; Quoc</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
		<author>
			<persName><surname>Lamda</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.08239</idno>
		<title level="m">Language models for dialog applications</title>
		<editor>
			<persName><forename type="first">Lora</forename><surname>Aroyo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ravi</forename><surname>Rajakumar</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Alena</forename><surname>Butryna</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Matthew</forename><surname>Lamm</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Viktoriya</forename><surname>Kuzmina</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Joe</forename><surname>Fenton</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Aaron</forename><surname>Cohen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rachel</forename><surname>Bernstein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ray</forename><surname>Kurzweil</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Blaise</forename><surname>Aguera-Arcas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Claire</forename><surname>Cui</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Marian</forename><surname>Croak</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="4" to="18" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<author>
			<persName><forename type="first">Julian</forename><surname>Togelius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgios</forename><forename type="middle">N</forename><surname>Yannakakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.06035</idno>
		<title level="m">Choose your weapon: Survival strategies for depressed AI academics</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title level="m" type="main">LLaMA: open and efficient foundation language models</title>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibaut</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Martinet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothée</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baptiste</forename><surname>Rozière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Hambro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faisal</forename><surname>Azhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurelien</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.13971</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>cited on pp. 2, 4, 18, 26, and 27</note>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Learning from the worst: Dynamically generated datasets to improve online hate detection</title>
		<author>
			<persName><forename type="first">Bertie</forename><surname>Vidgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Thrush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeerak</forename><surname>Waseem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.132</idno>
		<ptr target="https://aclanthology.org/2021.acl-long.132" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08">August 2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">29</biblScope>
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title level="m" type="main">Poisoning language models during instruction tuning</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<title level="m" type="main">GPT-J-6B: a 6 billion parameter autoregressive language model</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aran</forename><surname>Komatsuzaki</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">CodeT5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation</title>
		<author>
			<persName><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weishi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.685</idno>
		<ptr target="https://aclanthology.org/2021.emnlp-main.685" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11">November 2021</date>
			<biblScope unit="page">4</biblScope>
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<title level="m" type="main">Execution-based evaluation for open-domain code generation</title>
		<author>
			<persName><forename type="first">Zhiruo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuyan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.10481</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">20</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Chain of thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Quoc V Le</surname></persName>
		</author>
		<author>
			<persName><surname>Zhou</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=_VjQlMeSB_J" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">Alice</forename><forename type="middle">H</forename><surname>Oh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Alekh</forename><surname>Agarwal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Danielle</forename><surname>Belgrave</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="26" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Open science is a research accelerator</title>
		<author>
			<persName><forename type="first">Piero</forename><surname>Michael Woelfle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">H</forename><surname>Olliaro</surname></persName>
		</author>
		<author>
			<persName><surname>Todd</surname></persName>
		</author>
		<idno type="DOI">10.1038/nchem.1149</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Chemistry</title>
		<idno type="ISSN">1755-4349</idno>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">31</biblScope>
			<date type="published" when="2011-10">October 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rémi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName><surname>Rush</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/2020.emnlp-demos.6" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-10">October 2020</date>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title/>
		<ptr target="https://www3.weforum.org/docs/WEF_Future_of_Jobs_2023.pdf" />
	</analytic>
	<monogr>
		<title level="j">World Economic Forum. Future of jobs report</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">A systematic evaluation of large language models of code</title>
		<author>
			<persName><forename type="first">F</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uri</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName><surname>Josua Hellendoorn</surname></persName>
		</author>
		<idno type="DOI">10.1145/3520312.3534862</idno>
		<ptr target="https://doi.org/10.1145/3520312.3534862" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, MAPS 2022</title>
		<meeting>the 6th ACM SIGPLAN International Symposium on Machine Programming, MAPS 2022<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Do machine learning models produce TypeScript types that type check?</title>
		<author>
			<persName><forename type="first">Ming-Ho</forename><surname>Yee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arjun</forename><surname>Guha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Object-Oriented Programming (ECOOP)</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cited on pp. 3, 23, and 24</note>
</biblStruct>

<biblStruct xml:id="b114">
	<monogr>
		<author>
			<persName><forename type="first">Aohan</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengxiao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanyu</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuoyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wendi</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weng</forename><surname>Lam Tam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zixuan</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yufei</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jidong</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenguang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.02414</idno>
		<title level="m">GLM-130B: an open bilingual pre-trained model</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b115">
	<monogr>
		<title level="m" type="main">OPT: open pre-trained transformer language models</title>
		<author>
			<persName><forename type="first">Susan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Dewan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Victoria Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Simig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Punit</forename><surname>Singh Koura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anjali</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianlu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.01068</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b116">
	<monogr>
		<title level="m" type="main">CodeGeeX: A pre-trained model for code generation with multilingual evaluations on HumanEval-X</title>
		<author>
			<persName><forename type="first">Qinkai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yufei</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teng</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2303.17568</idno>
		<idno type="arXiv">arXiv:2303.17568</idno>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>cited on pp. 3, 4, 18, and 33</note>
</biblStruct>

<biblStruct xml:id="b117">
	<monogr>
		<title level="m" type="main">Least-to-most prompting enables complex reasoning in large language models</title>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathanael</forename><surname>Schärli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.10625</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">48</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
