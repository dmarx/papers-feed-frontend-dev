{
  "arxivId": "2412.06769",
  "title": "Training Large Language Models to Reason in a Continuous Latent Space",
  "authors": "Shibo Hao, Sainbayar Sukhbaatar, DiJia Su, Xian Li, Zhiting Hu, Jason Weston, Yuandong Tian",
  "abstract": "Large language models (LLMs) are restricted to reason in the \"language\nspace\", where they typically express the reasoning process with a\nchain-of-thought (CoT) to solve a complex reasoning problem. However, we argue\nthat language space may not always be optimal for reasoning. For example, most\nword tokens are primarily for textual coherence and not essential for\nreasoning, while some critical tokens require complex planning and pose huge\nchallenges to LLMs. To explore the potential of LLM reasoning in an\nunrestricted latent space instead of using natural language, we introduce a new\nparadigm Coconut (Chain of Continuous Thought). We utilize the last hidden\nstate of the LLM as a representation of the reasoning state (termed \"continuous\nthought\"). Rather than decoding this into a word token, we feed it back to the\nLLM as the subsequent input embedding directly in the continuous space.\nExperiments show that Coconut can effectively augment the LLM on several\nreasoning tasks. This novel latent reasoning paradigm leads to emergent\nadvanced reasoning patterns: the continuous thought can encode multiple\nalternative next reasoning steps, allowing the model to perform a breadth-first\nsearch (BFS) to solve the problem, rather than prematurely committing to a\nsingle deterministic path like CoT. Coconut outperforms CoT in certain logical\nreasoning tasks that require substantial backtracking during planning, with\nfewer thinking tokens during inference. These findings demonstrate the promise\nof latent reasoning and offer valuable insights for future research.",
  "url": "https://arxiv.org/abs/2412.06769",
  "issue_number": 752,
  "issue_url": "https://github.com/dmarx/papers-feed/issues/752",
  "created_at": "2025-01-04T06:52:12.616167",
  "state": "open",
  "labels": [
    "paper",
    "rating:novote"
  ],
  "total_reading_time_seconds": 32,
  "last_read": "2025-01-04T06:52:12.618753",
  "last_visited": "2025-01-02T19:39:10.844Z",
  "main_tex_file": null,
  "published_date": "2024-12-09T18:55:56Z",
  "arxiv_tags": [
    "cs.CL"
  ]
}