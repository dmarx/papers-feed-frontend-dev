- Decision to compare transcoders and sparse autoencoders (SAEs) for interpretability
- Choice of using skip connections in transcoder architecture
- Selection of training datasets (Pythia, Llama, Gemma)
- Adoption of the TopK activation function for enforcing sparsity
- Decision to evaluate interpretability using automated interpretability pipeline
- Choice of metrics for evaluating reconstruction loss and interpretability
- Decision to train on specific components of the model (e.g., feedforward layers)
- Choice of optimization algorithm (Adam) and training parameters (batch size, sequence length)
- Decision to analyze feature absorption behavior in different models
- Choice to focus on the tradeoff between reconstruction error and interpretability
- Decision to propose skip transcoders as an architectural improvement
- Choice of evaluation benchmarks (SAEBench) for sparse coders
- Decision to explore the implications of polysemanticity in neuron activations
- Choice to document contributions and roles of team members in the project
- Decision to suggest future work directions based on findings and limitations