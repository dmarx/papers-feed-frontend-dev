{
  "arxivId": "2412.10271",
  "title": "Benchmarking Linguistic Diversity of Large Language Models",
  "authors": "Yanzhu Guo, Guokan Shang, Chlo\u00e9 Clavel",
  "abstract": "The development and evaluation of Large Language Models (LLMs) has primarily\nfocused on their task-solving capabilities, with recent models even surpassing\nhuman performance in some areas. However, this focus often neglects whether\nmachine-generated language matches the human level of diversity, in terms of\nvocabulary choice, syntactic construction, and expression of meaning, raising\nquestions about whether the fundamentals of language generation have been fully\naddressed. This paper emphasizes the importance of examining the preservation\nof human linguistic richness by language models, given the concerning surge in\nonline content produced or aided by LLMs. We propose a comprehensive framework\nfor evaluating LLMs from various linguistic diversity perspectives including\nlexical, syntactic, and semantic dimensions. Using this framework, we benchmark\nseveral state-of-the-art LLMs across all diversity dimensions, and conduct an\nin-depth case study for syntactic diversity. Finally, we analyze how different\ndevelopment and deployment choices impact the linguistic diversity of LLM\noutputs.",
  "url": "https://arxiv.org/abs/2412.10271",
  "issue_number": 635,
  "issue_url": "https://github.com/dmarx/papers-feed/issues/635",
  "created_at": "2025-01-04T06:52:57.610109",
  "state": "open",
  "labels": [
    "paper",
    "rating:novote"
  ],
  "total_reading_time_seconds": 52,
  "last_read": "2025-01-04T06:53:18.652874",
  "last_visited": "2024-12-30T20:03:18.882Z",
  "main_tex_file": null,
  "published_date": "2024-12-13T16:46:03Z",
  "arxiv_tags": [
    "cs.CL"
  ]
}