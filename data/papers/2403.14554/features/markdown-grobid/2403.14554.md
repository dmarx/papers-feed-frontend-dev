# Gaussian Frosting: Editable Complex Radiance Fields with Real-Time Rendering

## Abstract

## 

[https://anttwo.github.io/frosting/](https://anttwo.github.io/frosting/) (a) Rendering three different scenes with Frosting: Bicycle, Buzz, and Kitten. (b) Composition: Buzz is riding a giant kitten jumping over a bench.

(c) Fuzzy details rendered with Frosting -occlusions are correctly rendered (d) Rendering with SuGaR [11] -the fur does not occlude the legs correctly

## 

Fig. [1](#): We propose to represent surfaces by a mesh covered with a "Frosting" layer of varying thickness and made of 3D Gaussians. This representation captures both complex volumetric effects created by fuzzy materials such as the cat's hair or grass as well as flat surfaces. Built from RGB images only, it can be rendered in real-time and animated using traditional animation tools. In the example above, we were able to animate both Buzz and the kitten, changing their original pose (a) while preserving high-quality rendering (b): Contrary to SuGaR, very fine and fuzzy details such as the kitten's hair can be seen covering Buzz's legs in a realistic way (c).  A thicker layer is shown with a brighter value. Our method automatically builds a thick Frosting layer for fuzzy areas such as the fur of the red panda plush, and a thin Frosting layer for flat surfaces such as the table or the floor. Adapting the thickness of the Frosting layer allows for allocating more Gaussians in areas where more volumetric rendering is necessary near the surface, resulting in an efficient distribution of Gaussians in the scene. As we demonstrate in the paper, using an adaptive thickness results in higher performance than using a predefined constant thickness, and reduces artifacts when animating the mesh.

1 Introduction 3D Gaussian Splatting (3DGS) [[17]](#b16) has recently conquered the field of 3D reconstruction and image-based rendering. By representing a scene with a large set of tiny Gaussians, 3DGS allows for fast reconstruction and rendering, while nicely capturing fine details and complex light effects. Compared to earlier neural rendering methods such as NeRFs [[23]](#b22), 3DGS is much more efficient for both the reconstruction and rendering stages by a large margin. However, like NeRFs, Vanilla 3DGS does not allow easy edition of the reconstructed scene. The Gaussians are unstructured, disconnected from each other, and it is not clear how a designer can manipulate them, for example to animate the scene. Very recently, SuGaR [[11]](#b10) showed how to extract a mesh from the output of 3DGS. Then, by constraining Gaussians to stay on the mesh, it is possible to edit the scene with traditional Computer Graphics tools for manipulating meshes. But by flattening the Gaussians onto the mesh, SuGaR loses the rendering quality possible with 3DGS for fuzzy materials and volumetric effects.

In this paper, we introduce Gaussian Frosting-or Frosting, for short-a hybrid representation of 3D scenes that is editable as a mesh while providing a rendering quality at least equal, sometimes superior to 3DGS. The key idea of Frosting is to augment a mesh with a layer containing Gaussians. The thickness of the Frosting layer adapts locally to the material of the scene: The layer should be thin for flat surfaces to avoid undesirable volumetric effects, and thicker around fuzzy materials for realistic rendering. As shown in Figure [2](#fig_1), using the Frosting representation, we can not only retrieve a highly accurate editable mesh but also render complex volumetric effects in real-time.

Frosting is reminiscent of the Adaptive Shells representation [[40]](#b39), which relies on two explicit triangle meshes extracted from a Signed Distance Function to control volumetric effects. Still, Frosting allies a rendering quality superior to the quality of Adaptive Shells to the speed efficiency of 3DGS for reconstruction and rendering, while being easily editable as it depends on a single mesh.

While the Frosting representation is simple, it is challenging to define the local thickness of its layer. To extract the mesh, we essentially rely on SuGaR, which we improved with a technique (described in the supplementary material) to automatically tune a critical hyperparameter. To estimate the Frosting thickness, we introduce a method to define an inner and outer bound for the Frosting layer at each vertex of this mesh based on the Gaussians initially retrieved by 3DGS around the mesh. Finally, we populate the Frosting layer with randomly sampled Gaussians and optimize these Gaussians constrained to stay within the layer. We also propose a simple method to automatically adjust in real-time the parameters of the Gaussians when animating the mesh.

In summary, we propose a simple yet powerful surface representation that captures complex volumetric effects, can be edited with traditional tools, and can be rendered in real-time. We also propose a method to build this representation from images, based on recent developments on Gaussian Splatting. We will release our code including a viewer usable in browser as an additional contribution. We also changed the pose of the characters by using the rigging tool in Blender (b).

Similarly to surface-based methods like SuGaR [[11]](#b10), Frosting can be used for editing and compositing scenes, but allows for better rendering of complex volumetric effects and fuzzy materials, such as hair or grass.

## Related Work

The goal of image-based rendering (IBR) is to create a representation of a scene from a given set of images in order to generate new images of the scene. Different types of scene representations have been proposed, ranging from explicit and editable ones like triangle meshes or point clouds, to implicit or non-editable ones like voxel grids, multiplane images, or neural implicit functions. Volumetric IBR methods. A recent breakthrough in IBR is Neural Radiance Fields (NeRF) [[23]](#b22), which uses a multilayer perceptron (MLP) to model a continuous volumetric function of density and color. NeRF can render novel views with high quality and view-dependent effects, by using volumetric ray tracing. However, NeRF is slow and memory hungry. Several works have tried to improve NeRF's efficiency and training speed by using discretized volumetric representations like voxel grids and hash tables to store learnable features that act as inputs for a much smaller MLP [[5,](#b4)[15,](#b14)[24,](#b23)[37,](#b36)[45]](#b44), or to improve rendering performance by using hierarchical sampling strategies [[2,](#b1)[13,](#b12)[29,](#b28)[46]](#b45). Other works have also proposed to modify NeRF's representation of radiance and include an explicit lighting model to increase the rendering quality for scenes with specular materials [[3,](#b2)[21,](#b20)[36,](#b35)[38,](#b37)[47]](#b46). However, most volumetric methods rely on implicit representations that are not suited to editing compared to triangle meshes, for which most standard graphics hardware and software are tailored. Surface-based IBR methods. Triangle meshes have been a popular 3D representation for generating novel views of scenes [[4,](#b3)[12,](#b11)[41]](#b40) after Structure-from-motion (SfM) [[35]](#b34) and multi-view stereo (MVS) [[10]](#b9) have enabled 3D reconstruction of surfaces. Deep-learning-based mesh representations [[30,](#b29)[31]](#b30) have also been used for improving view synthesis using explicit surface meshes; However, even though mesh-based methods allow for very efficient rendering, they have trouble capturing complex and very fine geometry as well as fuzzy materials.

Hybrid IBR methods. Some methods use a hybrid volumetric representation to recover surface meshes that are suitable for downstream graphics applications while efficiently modeling view-dependent appearance. Specifically, some works optimize a Neural Radiance Field in which the density is replaced by an implicit signed distance function (SDF), which provides a stronger regularization on the underlying geometry [[8,](#b7)[9,](#b8)[22,](#b21)[25,](#b24)[39,](#b38)[42]](#b41). However, most of these methods are not aimed at real-time rendering. To mitigate this issue, other approaches greatly accelerate rendering by "baking" the rendering computation into the extracted mesh after optimization with a dedicated view-dependent appearance model [[7,](#b6)[28,](#b27)[43]](#b42). Even though these surface-based methods encode the surface using a volumetric function represented by an MLP during optimization, they struggle in capturing fine details or fuzzy materials compared to volumetric methods.

Adaptive Shells [[40]](#b39) is a recent method that achieves a significant improvement in rendering quality by using a true hybrid surface-volumetric approach that restricts the volumetric rendering of NeRFs to a thin layer around the object. This layer is bounded by two explicit meshes, which are extracted after optimizing an SDF-based radiance field. The layer's variable thickness also improves the rendering quality compared to a single flat mesh. This method combines the high-quality rendering of a full volumetric approach with the editability of a surface-based approach by manipulating the two meshes that define the layer. However, Adaptive Shells depends on a neural SDF [[39]](#b38), which has some limitations in its ability to reconstruct precise surfaces, and requires more than 8 hours to optimize a single synthetic scene, which is much longer than the recent Gaussian Splatting methods.

Gaussian Splatting. Gaussian Splatting [[17]](#b16) is a new volumetric representation inspired by point cloud-based radiance fields [[20,](#b19)[32]](#b31) which is very fast to optimize and allows for real-time rendering with very good quality. One of its greatest strengths is its explicit 3D representation, which enables editing tasks as each Gaussian exists individually and can be easily adjusted in real-time. Some appearance editing and segmentation methods have been proposed [[6,](#b5)[14,](#b13)[18,](#b17)[44]](#b43), but the lack of structure in the point cloud makes it almost impossible for a 3D artist or an animator to easily modify, sculpt or animate the raw representation. The triangle mesh remains the standard 3D structure for these applications. A recent work, SuGaR [[11]](#b10), extends this framework by aligning the Gaussians with the surface and extracting a mesh from them. Gaussians are finally flattened and pinned on the surface of the mesh, which provides a hybrid representation combining the editability of a mesh with the high-quality rendering of Gaussian Splatting. However, SuGaR remains a surface-based representation with limited capacity in reconstructing and rendering fuzzy materials and volumetric effects, resulting in a decrease in performance compared to vanilla Gaussian Splatting.

## 3D Gaussian Splatting and Surface Reconstruction

Our method relies on the original 3D Gaussian Splatting (3DGS) method [[17]](#b16) for initialization and on SuGaR [[11]](#b10) to align Gaussians with the surface of the scene and facilitate the extraction of a mesh. We briefly describe 3DGS and SuGaR in this section before describing our method in the next section.

## 3D Gaussian Splatting

3DGS represents the scene as a large set of Gaussians. Each Gaussian g is equipped with a mean µ g ∈ R 3 and a positive-definite covariance matrix Σ g ∈ R 3×3 . The covariance matrix is parameterized by a scaling vector s g ∈ R 3 and a quaternion q g ∈ R 4 encoding the rotation of the Gaussian.

In addition, each Gaussian has a view-dependent radiance represented by an opacity α g ∈ [0, 1] and a set of spherical harmonics coordinates defining the colors emitted for all directions. To render an image from a given viewpoint, a rasterizer "splats" the 3D Gaussians into 2D Gaussians parallel to the image plane and blends the splats depending on their opacity and depth. This rendering is extremely fast, which is one of the advantages of 3DGS over volumetric rendering as in NeRFs for example [[2,](#b1)[23,](#b22)[24]](#b23).

Gaussian Splatting can be seen as an approximation of the traditional volumetric rendering of radiance fields with the following density function d, computed as the sum of the Gaussian values weighted by their alpha-blending coefficients at any 3D point p ∈ R 3 :

$d(p) = g α g exp - 1 2 (p -µ g ) T Σ -1 g (p -µ g ) .(1)$We initialize our Gaussian Frosting method using a vanilla 3DGS optimization: Gaussians are initialized using the point cloud produced by an SfM [[35]](#b34) algorithm like COLMAP [[33,](#b32)[34]](#b33), required to compute camera poses. The Gaussians' parameters (3D means, scaling vectors, quaternions, opacities, and spherical harmonics coordinates) are then optimized to make the renderings match the ground truth images of the scene, using a rendering loss that only consists in a combination of a pixel-wise L1 distance and a more structural D-SSIM term.

## SuGaR Mesh Extraction

Vanilla 3DGS does not have regularization explicitly encouraging Gaussians to align with the true surface of the scene. Our Gaussian Frosting representation relies on a mesh that approximates this surface, in order to be editable by traditional tools. To obtain this mesh, we rely on the method proposed in SuGaR [[11]](#b10), which we improve by automatically selecting a critical hyperparameter.

SuGaR proposes a regularization term encouraging the alignment of the 3D Gaussians with the true surface of the scene during the optimization of Gaussian Splatting, as well as a mesh extraction method. After enforcing the regularization, the optimization provides Gaussians that are mostly aligned with the We refer to these Gaussians as unconstrained. We then regularize these Gaussians to enforce their alignement with the surface, and extract a mesh that will serve as a basis for the Frosting. Next, we use the misalignment of surface-aligned Gaussians to identify areas where more volumetric rendering is needed, and we build search intervals Ji around the mesh's vertices vi. Finally, we use the density function of the unconstrained Gaussians to refine the intervals, resulting in a Frosting layer. We finally sample a novel, densified set of Gaussians inside the layer.

surface albeit not perfectly: We noticed that in practice, a large discrepancy between the regularized Gaussians and the extracted mesh indicates the presence of fuzzy materials or surfaces that require volumetric rendering. We thus exploit this discrepancy as a cue to evaluate where the Frosting should be thicker.

## Creating a Frosting Layer from Images

In this section, we describe our Gaussian Frosting creation method: First, we extract an editable surface with optimal resolution using SuGaR. We then detail how we use this surface-based model to go back to a volumetric but editable representation built around the mesh. This representation adapts to the complexity of the scene and its need for more volumetric effects. Finally, we describe how we parameterize and refine this representation. An overview is provided Figure [4](#fig_3).

## Forward Process: From Volume to Surface

We start by optimizing an unconstrained Gaussian Splatting representation for a short period of time to let Gaussians position themselves. We will refer to such Gaussians as unconstrained. We save these Gaussians aside, and apply the regularization term from SuGaR to enforce the alignment of the Gaussians with the real surface. We will refer to these Gaussians as regularized.

Once we obtain the regularized Gaussians, we extract a surface mesh from the Gaussian Splatting representation. This surface mesh serves as a basis for our representation. Like SuGaR [[11]](#b10), we then sample points on the visible level set of the Gaussian splatting density function, and apply Poisson reconstruction.

(a) Using the predefined, large parameter D as in SuGaR [[11]](#b10) (b) Using our automatically computed D that adapts to the complexity of the 3DGS Fig. [5](#): Comparison of meshes extracted by SuGaR from the Shelly dataset without and with our improvement that automatically tunes the octree depth D in Poisson reconstruction depending on the complexity of the scene. Our technique (bottom) drastically reduces surface artifacts for many scenes, such as the holes and the ellipsoidal bumps on the surface when using the default values from [[11]](#b10) (top).

In the supplementary material, we describe our technique to automatically estimate a good value for a critical hyperparameter used by Poisson reconstruction, namely the octree depth D. As we will show in the Experiments section, selecting the right value for D when applying Poisson reconstruction can drastically improve both the quality of the mesh and the rendering performance of our model. Figure [5](#) illustrates this point.

## Backward Process: From Surface to Volume

After extracting a base mesh, we build a Frosting layer with a variable thickness and containing Gaussians around this mesh. We want this layer to be thicker in areas where more volumetric rendering is necessary near the surface, such as fuzzy material like hair or grass for example. On the contrary, this layer should be very thin near the parts of the scene that corresponds to well-defined flat surfaces, such as wood or plastic for example.

As illustrated in Figure [6](#fig_4), to define this layer, we introduce two values δ in i and δ out i for each vertex v i of the extracted base mesh M. This gives two surfaces with vertices (v i + δ in i n i ) i and (v i + δ out i n i ) i respectively, where n i is the mesh normal at vertex v i . These two surfaces define the inner and outer bounds of the Frosting layer. Note that we do not have to build them explicitly as they directly depend on the base mesh and the δ in i 's and δ out i 's. To find good values for the δ in i 's and δ out i 's, we initially tried using directly the unconstrained Gaussians, i.e., the Gaussians obtained before applying the regularization term from SuGaR. Unfortunately, without regularization, Gaussian Splatting tends to retrieve a thick layer of Gaussians even for "non-fuzzy" surfaces, which would result in excessively large values for δ in i and δ out i . Moreover, the unconstrained Gaussians generally contain many transparent floaters and other outlier Gaussians. Such Gaussians could also bias the shifts toward unnecessarily large values. On the other hand, using only the regularized Gaussians to setup the δ in i 's and δ out i 's could miss fuzzy areas since these Gaussians are made flatter by the regularization.

Our solution is thus to consider both the unconstrained and the regularized Gaussians. More exactly, we estimate the Frosting thickness from the thickness of the unconstrained Gaussians by looking for their isosurfaces, BUT, to make sure we consider the isosurfaces close to the scene surface, we search for the isosurfaces close to the regularized Gaussians: Even under the influence of the regularization term from SuGaR, Gaussians do not align well with the geometry around surfaces with fuzzy details. As a consequence, the local thickness of the regularized Gaussians is a cue on how fuzzy the material is.

Figure [6](#fig_4) illustrates what we do to fix the δ in i 's and δ out i 's. To restrict the search, we define a first interval I i = [-3σ i , 3σ i ] for each vertex v i , where σ i is the standard deviation in the direction of n i of the regularized Gaussian the closest to v i . I i is the confidence interval for the 99.7 confidence level of the 1D Gaussian function of t along the normal. Fuzzy parts result in general in large I i . We could use the I i 's to restrict the search for the isosurfaces of the unconstrained Gaussians. A more reliable search interval J i is obtained by looking for the isosurfaces of the regularized Gaussians along n i within I i :

$ϵ in i = inf(T ) , ϵ out i = sup(T ) , with T = {t ∈ I i | d r (v i + tn i ) ≥ λ} ,(2)$where d r is the density function as defined in Eq. ( [1](#formula_0)) for the regularized Gaussians. In practice, we use an isosurface level λ = 0.01, i.e., close to zero. We use ϵ in i and ϵ out i to define interval J i :

$J i = ϵ mid i -kϵ half i , ϵ mid i + kϵ half i$, with ϵ mid i = (ϵ in + ϵ out )/2 and ϵ half i = (ϵ out -ϵ in )/2. We take k = 3 as it gives an interval large enough to include most of the unconstrained Gaussians while rejecting the outlier Gaussians. Finally, we can compute the inner and outer shifts δ in i and Fig. [7](#): Rendering complex scenes with Frosting. First row: Renderings, Second row: recovered normal maps, Third row: estimated Frosting thickness. Note that the Frosting is thick on fuzzy materials such as the hair and the grass, as expected, and very thin on flat surfaces such as the table on the fourth column.

δ out i as:

$δ in i = inf(V ) , δ out i = sup(V ) , with V = {t ∈ J i | d u (v i + tn i ) ≥ λ} .(3)$
## Frosting Optimization

Once we constructed the outer and inner bounds of the Frosting layer, we initialize a densified set of Gaussians inside this layer and optimize them using 3DGS rendering loss as the unconstrained Gaussians. To make sure the Gaussians stay inside the frosting layer during optimization, we introduce a new parameterization of the Gaussians. Moreover, this parameterization will make possible to easily adjust the Gaussians' parameters when editing the scene.

Parameterization. Let us consider a triangular face of the base mesh M, with vertices denoted by v 0 , v 1 , and v 2 and their corresponding normals n 0 , n 1 , and n 2 . After extracting inner and outer shifts from unconstrained Gaussians, we obtain six new vertices (v i + δ in i n i ) i=0,1,2 and (v i + δ out i n i ) i=0,1,2 that respectively belong to the inner and outer bounds of the frosting. Specifically, these six vertices delimit an irregular triangular prism. We will refer to such polyhedrons as "prismatic cells". We parameterize the 3D mean µ g ∈ R 3 of a Gaussian g ∈ G located inside a prismatic cell with a set of six barycentric coordinates split into two subsets (b

$(i) g ) i=0,1,2 and (β (i) g ) i=0,1,2 , such that µ g = 2 i=0 b (i) g v i + δ out i n i + β (i) g v i + δ in i n i ,(4)$with barycentric coordinates verifying 2 i=0 (b

$(i) g + β (i) g ) = 1.$Using barycentric coordinates enforces Gaussians to stay inside their corresponding prismatic cell, and guarantees the stability of our representation during optimization. In practice, we apply a softmax activation on the parameters to optimize to obtain barycentric coordinates that sum up to 1.

Initialization. For a given budget N of Gaussians provided by the user, we initialize N Gaussians in the scene by sampling N 3D centers µ g in the frosting layer. Specifically, for sampling a single Gaussian, we first randomly select a prismatic cell with a probability proportional to its volume. Then, we sample random coordinates that sum up to 1. This sampling allows for allocating more Gaussians in areas with fuzzy and complex geometry, where more volumetric rendering is needed. However, flat parts in the layer may also need a large number of Gaussians to recover texture details. Therefore, in practice, we instantiate N/2 Gaussians with uniform probabilities in the prismatic cells, and N/2 Gaussians with probabilities proportional to the volume of the cell.

We initialize the colors of the Gaussians with the color of the closest Gaussian in the unconstrained representation. However, we do not use the unconstrained Gaussians to initialize opacity, rotation, and scaling factors, as in practice, following the strategy from 3DGS [[17]](#b16) for these parameters provides better performance: We suppose the positions and configuration of the Gaussians inside the Frosting layer are already a good initialization, and resetting opacities, scaling factors and rotations helps Gaussians to take a fresh start, avoiding a potential local minimum encountered by previous unconstrained Gaussians.

Our representation allows for a much better control over the number of Gaussians than the original Gaussian Splatting densification process, as it is up to the user to decide on a number of Gaussians to instantiate in the frosting layer. These Gaussians will be spread in the entire frosting in a very efficient way, adapting to the need for volumetric rendering in the entire scene.

Optimizing the Gaussian Frosting. We reload the unconstrained Gaussians and apply our method for computing the inner and outer bounds of the Frosting. Then, for a given budget of N Gaussians, we initialize N Gaussians in the Frosting and optimize the representation while keeping the number of Gaussians constant. Note that compared to Vanilla 3DGS, this allows to control precisely the number of Gaussians.

Editing, Deforming, and Animating the Frosting. When deforming the base mesh, the positions of Gaussians automatically adjust in the frosting layer thanks to the use of the barycentric coordinates. To automatically adjust the rotation and scaling factors of the Gaussians, we propose a strategy different from the surface-based adjustment from SuGaR: In a given prismatic cell with center c and vertices v i for 0 ≤ i < 5, we first estimate the local transformation at each vertex v i by computing the rotation and rescaling of the vector (cv i ). Then, we use the barycentric coordinates of a Gaussian g to compute an average transformation at point µ g from the transformation of all 6 vertices, and we adjust the rotation and scaling factors of g by applying this average transformation. Please note that the spherical harmonics are also adjusted in practice, to ensure the consistency of the emitted radiance depending on the averaged rotation applied to the Gaussian. We provide more details about this automatic adjustment of Gaussian parameters in the supplementary material. 5 Experiments

## Implementation Details

We implemented our method with PyTorch [[26]](#b25) and optimized the representations on a single GPU Nvidia Tesla V100 SXM2 32 Go. Optimizing a full, editable Frosting model takes between 45 and 90 minutes on a single GPU, depending on the complexity of the scene. This optimization is much faster than the most similar approach to Frosting in the literature, namely Adaptive Shells [[40]](#b39), that requires 8 hours on a single GPU for a synthetic scene, and 1.7 times more iterations for a real scene.

Extracting the surface mesh. When reconstructing real scenes, we follow the approach from vanilla 3DGS [[17]](#b16) and first use COLMAP to estimate the camera poses and extract a point cloud for initialization. For synthetic scenes with known camera poses, we just use a random point cloud for initialization. Then, we optimize an unconstrained Gaussian Splatting representation for 7,000 iterations. We save these Gaussians aside and apply the regularization term from SuGaR until iteration 15,000. We finally compute an optimal depth parameter D with γ = 100 and extract a mesh from the regularized Gaussians by applying Poisson surface reconstruction as described in [[11]](#b10).

Optimizing the Gaussian Frosting. Given a budget of N Gaussians, we initialize N Gaussians in the Frosting layer and optimize them for 15,000 additional iterations, which gives a total of 30,000 iterations, similarly to 3DGS [[17]](#b16). Vanilla 3DGS optimization generally produces between 1 and 5 million Gaussians. In practice, we use N =5 million for real scenes and N =2 million for synthetic scenes.

## Real-Time Rendering in Complex Scenes

To evaluate the quality of Frosting's rendering, we compute the standard metrics PSNR, SSIM and LPIPS [[48]](#b47) and compare to several baselines, some of them focusing only on Novel View Synthesis [[1,](#b0)[2,](#b1)[17,](#b16)[23,](#b22)[24,](#b23)[39,](#b38)[45]](#b44) and others relying on an editable representation [[7,](#b6)[11,](#b10)[27,](#b26)[28,](#b27)[40,](#b39)[43]](#b42), just like Frosting. We compute metrics on several challenging datasets containing synthetic and real scenes.

Shelly. We first compare Frosting to state-of-the-art methods on the dataset Shelly introduced in Adaptive Shells [[40]](#b39). Shelly includes six synthetic scenes with challenging fuzzy materials that surface-based approaches struggle to reconstruct accurately. As we show in Table [1](#) and Figure [8](#fig_5), Frosting outperforms every other methods for all three metrics. Frosting even outperforms with a wide margin vanilla Gaussian Splatting, which is free from any surface constraints and only focuses on optimizing the rendering quality. Indeed, the sampling of Gaussians inside the Frosting layer provides a much more efficient densification of Gaussians than the strategy proposed in 3DGS [[17]](#b16), targeting the challenging fuzzy areas close to the surface and allocating more Gaussians where volumetric rendering is needed.

NeRFSynthetic. Table [1](#) provides a comparison on the NeRFSynthetic dataset [[23]](#b22), which consists in eight synthetic scenes. Frosting performs the best among the editable methods, surpassing SuGaR [[11]](#b10), and achieves results on par with vanilla 3DGS and other radiance field methods.

Table [1](#): Quantitative evaluation of rendering quality on the synthetic datasets Shelly [[40]](#b39) and NeRFSynthetic [[23]](#b22). Frosting is the best among all methods, outperforming even non-editable models that only focus on rendering. Contrary to an unconstrained 3D Gaussian Splatting [[17]](#b16), our representation allows for densifying Gaussians more efficiently by targeting challenging and fuzzy areas.

$Shelly NeRFSynthetic PSNR ↑ SSIM ↑ LPIPS ↓ PSNR ↑ SSIM ↑ LPIPS ↓ NeRF [$23] 31.27 0.893 0.157 31.01 0.947 0.081 NeuS [39] 29.98 0.893 0.158 ---Mip-NeRF [1] 32.59 0.899 0.148 33.09 0.961 0.043 I-NGP [24] 33.22 0.922 0.125 33.18 --3DGS [17] 37.66 0.958 0.066 33.32 0.970 0.030 MobileNeRF [7] 31.62 0.911 0.129 30.90 0.947 0.062 Adaptive Shells [40] 36.02 0.954 0.079 31.84 0.957 0.056 SuGaR [11] 36.33 0.954 0.059 32.40 0.964 0.033 Frosting (Ours) 39.84 0.977 0.033 33.03 0.967 0.029

Mip-NeRF 360. We also compare Frosting to state-of-the-art approaches on the real scenes from the Mip-NeRF 360 dataset [[2]](#b1). This dataset contains images from seven challenging real scenes, but was captured with ideal lighting condition and provides really good camera calibration data and initial SfM points.

Results are available in Table [2](#tab_1) and Figure [7](#). Frosting reaches the best performance among all editable methods, and obtains worse but competitive results compared to vanilla Gaussian Splatting. When Gaussian Splatting is given a very good initialization with a large amount of SfM points, the benefits from the Gaussian Frosting densification are not as effective, and optimizing Gaussians without additional constraints as in 3DGS slightly improves performance.

Additional real scenes. We finally compare Frosting to the baselines with captures of real scenes that present variations in exposure or white balance.

To this end, we follow the approach from 3DGS [[17]](#b16) and select the same two subsets of two scenes from Tanks&Temples (Truck and Train) and Deep Blending (Playroom and Dr. Johnson). We also evaluate a few methods on a custom dataset that consists of four casual captures made with a smartphone (we call these scenes SleepyCat, Buzz, RedPanda, and Knight), illustrated in Figures [2](#fig_1) and [7](#). Results are available in Table [3](#tab_2). In these more realistic scenarios, Frosting achieves once again similar or better performance than unconstrained Gaussian Splatting even though it is an editable representation that relies on a single, animatable mesh.   We were able to animate the sculpture in the left image using the rigging tool in Blender.

## Editing, Compositing, and Animating Gaussian Frosting

As shown in Figure [1](#), Figure [3](#fig_2) and Figure [9](#fig_6), our Frosting representation automatically adapts when editing, rescaling, deforming, combining or animating base meshes. Frosting offers editing, composition and animation capabilities similar to surface-based approaches like SuGaR [[11]](#b10), but achieves much better performance thanks to its frosting layer with variable thickness that adapts to the volumetric effects and fuzzy materials in the scene.

## Ablation Study: Octree Depth

To demonstrate how our technique for automatically computing the optimal octree depth D for Poisson reconstruction improves the performance of Frosting, we provide in Table [4](#) a comparison in rendering performance between our full model, and a version of Frosting that uses the same predefined depth parameter as SuGaR. This technique results in equivalent or better rendering performance with much fewer triangles.

Table [4](#): Ablation for two different depth computation methods used for the octree in Poisson surface reconstruction. We compare the rendering performance between using a predefined depth with a high value as in [[11]](#b10) and our automatically computed depth. Our technique systematically selects an optimal depth depending on the complexity of the scene, avoiding artifacts in the mesh, and resulting in equivalent or better rendering performance with a much smaller average number of triangles.

NeRFSynthetic Shelly We compare the rendering performance (PSNR ↑) in synthetic and real scenes depending on how we compute and refine the thickness of the Frosting layer. Specifically, we first show that using an adaptive thickness improves performance over a constant thickness. Even though using a large constant thickness improves performance in scenes with very fuzzy materials like Shelly [[40]](#b39), this lowers performance in scenes with flat surfaces and generates artifacts when editing the scene, as shown in Figure [10](#). By contrast, our method adapts automatically to the type of surfaces.

$PSNR ↑ SSIM ↑ LPIPS ↓ Ntri ↓ ↑ SSIM ↑ LPIPS ↓ Ntri ↓ Predefined depth D =$We also demonstrate that refining the thickness using the unconstrained Gaussians is necessary to achieve top performance.

Shelly Mip-NeRF 360 Average Indoor Outdoor Average Constant thickness (Small) 39.03 30.36 25.50 28.28 Constant thickness (Medium) 39.67 30.19 25.54 28.20 Constant thickness (Large) 40.00 30.06 25.48 28.10 Using Regularized Gaussians only (δ in/out = ϵ in/out ) 39.34 30.42 25.57 28.34 Using Regularized and Unconstrained Gaussians (Full method) 39.84 30.49 25.57 28.38

## Ablation Study: Thickness of the Frosting Layer

We also provide in Table [5](#tab_3) an ablation study comparing different strategies for computing the thickness of the Frosting layer. Specifically, we first evaluate the rendering performance of a Frosting layer with constant thickness. We repeat the experiment for small, medium and large thickness values, using different quantiles of our inner and outer shifts δ in and δ out for computing the constant thickness. We show that using an adaptive thickness improves performance over a constant thickness, as (a) some fuzzy materials need a thicker frosting to be accurately rendered, and (b) some flat surfaces are better rendered with a very thin frosting. As a consequence, even though using a large constant thickness improves performance in scenes with very fuzzy materials like Shelly [[40]](#b39), it lowers performance in scenes with flat surfaces. Moreover, using an adaptive thickness rather than a constant thickness with a large value helps to greatly reduce artifacts, as we demonstrate in Figure [10](#).

We also show that using unconstrained Gaussians to refine the thickness of the Frosting is necessary to achieve top performance. To this end, we skip the Fig. [10](#): Comparison with a constant thickness. Our strategy to compute an adaptive thickness for Frosting is essential to maintain optimal performance while avoiding artifacts when editing the scene. As shown in the right image, using a constant thickness may produce artifacts when animating a character: When using a constant, large thickness in this scene, Gaussians located near the right knee of the knight participate in reconstructing the right hand, which produces artifacts when moving the hand.

refinement process and evaluate the rendering performance of a Frosting layer with δ in = ϵ in and δ out = ϵ out . This results in lower performance, as shown in Table [5](#tab_3).

## Conclusion

We proposed a simple yet powerful surface representation with many advantages over current representations together with a method to extract it from images. One limitation of our implementation is the simple deformation model as it is piecewise linear. It should be however simple to replace it with a more sophisticated, physics-based deformation model. Another limitation is that our models are larger than vanilla Gaussian Splatting models since we have to include the barycentric coordinates and the mesh vertices. Recent works about compressing 3DGS could help. We believe that the Frosting representation can be useful beyond image-based rendering. It could for example be used in more general Computer Graphics applications to render complex materials in real-time. a large but very detailed shape can be reconstructed using Gaussians with large size, if these Gaussians are close to each other. On the contrary, whatever their size, if the centers of the Gaussian are too far from each other, then the rendered geometry will look rough.

Consequently, to first evaluate the geometrical complexity of a scene, we propose to compute, for each Gaussian g in the scene, the distance between g and its nearest neighbor Gaussian. We use these distances to define the following geometrical complexity score CS:

$CS = Q 0.1 min g ′ ̸ =g ∥µ g -µ g ′ ∥ 2 L g∈G ,(5)$where G is the set of all 3D Gaussians in the scene, L is the length of the longest edge of the bounding box of the point cloud to use in Poisson reconstruction, and Q 0.1 is the function that returns the 0.1-quantile of a list. We use the 0.1-quantile rather than the average because Gaussians that have a neighbor close to them generally encode details in the scene, which provide a much more reliable and less noisy criterion than using the overall average. We also use a quantile rather than a minimum to be robust to extreme values. In short, this complexity score CS is a canonical distance between the closest Gaussians in the scene, i.e., the distance between neighbor Gaussians that reconstruct details in the scene. Since the normalized length of a cell in the octree is 2 -D and this score represents a canonical normalized distance between Gaussians representing details in the scene, we can compute a natural optimal depth D for the Poisson reconstruction algorithm:

$D = ⌊-log 2 (γ × CS)⌋ ,(6)$where γ > 0 is a hyperparameter that does not depend on the scene and its geometrical complexity. This formula guarantees that the size of the cells is as close as possible but greater than γ × CS. Decreasing the value of γ increases the resolution of the reconstruction. But for a given γ, whatever the dataset or the complexity of the scene, this formula enforces the scene to be reconstructed with a similar level of smoothness. Choosing γ is therefore much easier than having to tune D as it is not dependent on the scene. In practice, we use γ = 100 for all the scenes. Our experiments validates that this method to fix D results in greater rendering performance.

8 Initializing the frosting layer 8.1 Sampling Gaussians in the frosting layer Sampling more Gaussians in thicker parts of the frosting. For a given budget N of Gaussians provided by the user, we initialize N Gaussians in the scene by sampling N 3D centers µ g in the frosting layer. Specifically, for sampling a single Gaussian, we first randomly select a prismatic cell with a probability proportional to its volume. Then, we sample random coordinates that sum up to 1. This sampling allows for allocating more Gaussians in areas with fuzzy and complex geometry, where more volumetric rendering is needed. However, flat parts in the layer may also need a large number of Gaussians to recover texture details. Therefore, in practice, we instantiate N/2 Gaussians with uniform probabilities in the prismatic cells, and N/2 Gaussians with probabilities proportional to the volume of the cell.

Contracting volumes in unbounded scenes. In real unbounded scenes, 3D Gaussians located far away from the center of the scene can have a significantly large volume despite their limited participation in the final rendering. This can lead to an unnecessarily large number of Gaussians being sampled in the frosting layer far away from the training camera poses. To address this issue, we propose distributing distant Gaussians proportionally to disparity (inverse distance) rather than distance.

When sampling Gaussians in practice, we start by contracting the volumes of the prismatic cells. We achieve this by applying a continuous transformation f : R 3 → R 3 to the vertices of the outer and inner bounds of the frosting layer. Then, we compute the volumes of the resulting "contracted" prismatic cells and use these adjusted volumes for sampling Gaussians within the frosting layer, as previously described. The transformation function f aims to contract the volume of prismatic cells located far away from the center of the scene. We define f using a formula similar to the contraction transformation introduced in Mip-NeRF 360 [[2]](#b1):

$f (x) = x if ∥x -c∥ ≤ l c + l × 2 -l ∥x-c∥ x-c ∥x-c∥ if ∥x -c∥ > l ,(7)$where c ∈ R 3 is the center of the bounding box containing all training camera positions, and l ∈ R + is equal to half the length of the diagional of the same bounding box. We choose the bounding box of the camera positions as our reference scale because both 3D Gaussian Splatting [[17]](#b16) and SuGaR [[11]](#b10) use this same reference for scaling learning rates and distinguishing foreground from background in unbounded scenes.

## Avoiding self-intersections in the frosting layer

In the main paper, we define the inner and outer bounds of the frosting layer by adding inner and outer shifts δ in i and δ out i to the vertices v i of the base mesh. This results in two bounding surfaces with vertices v i +δ in i and v i +δ out i . In practice, we wish to minimize self-intersections within the frosting layer, specifically avoiding prismatic cells intersecting with each other.

While self-intersections do not directly impact rendering quality, they can lead to artifacts during scene editing or animation. Consider the scenario where different cells intersect. In such cases, moving a specific triangle of the base mesh may not affect all Gaussians intersecting the surrounding cell: Some Gaussians may belong to prismatic cells associated with different triangles, resulting in artifacts due to their failure to follow local motion or scene edits.

To mitigate self-intersections, we adopt an indirect approach for initializing the shifts δ in and δ out . Instead of using the final computed values directly, we start with shifts equal to zero and progressively increase them until reaching their final values. As soon as an inner vertex (or outer vertex) of a prismatic cell is detected to intersect another cell, we stop further increases in its inner shift (or outer shift). This straightforward process significantly reduces self-intersections in the frosting layer while maintaining rendering performance.

By following this approach, we ensure that the frosting layer remains free from unwanted artifacts while preserving efficient rendering capabilities.

## Adjusting Gaussians' parameters for edition

When editing or animating the scene, we automatically adjust Gaussians' parameters. Specifically, in a given prismatic cell with center c and six vertices v i for 0 ≤ i < 6, we first estimate the local transformation at each vertex v i by computing the rotation and rescaling of the vector (c -v i ).

To compute the local rotations at vertex v i , we use an axis-angle representation where the axis angle is the normalized cross-product between the previous and the current values of the vector (c -v i ). The local rescaling transformation at vertex v i is computed as the transformation that scales along axis (c -v i ) with the appropriate factor but leaves other axes unchanged.

To update the scaling factors and rotation of a Gaussian g, we first apply each of these six transformations on the three main axes of the Gaussian. We then average the resulting axes using the barycentric coordinates of the center µ g of the Gaussian. We finally orthonormalize the three resulting axes.

![arXiv:2403.14554v1 [cs.CV] 21 Mar 2024]()

![Fig. 2: Visualization of the thickness of the Frosting layer on an example.A thicker layer is shown with a brighter value. Our method automatically builds a thick Frosting layer for fuzzy areas such as the fur of the red panda plush, and a thin Frosting layer for flat surfaces such as the table or the floor. Adapting the thickness of the Frosting layer allows for allocating more Gaussians in areas where more volumetric rendering is necessary near the surface, resulting in an efficient distribution of Gaussians in the scene. As we demonstrate in the paper, using an adaptive thickness results in higher performance than using a predefined constant thickness, and reduces artifacts when animating the mesh.]()

![Fig.3: Scene composition. Using mesh editing tools in Blender, we were able to combine various elements from multiple scenes (a) to build a whole new scene (c). We also changed the pose of the characters by using the rigging tool in Blender (b). Similarly to surface-based methods like SuGaR[11], Frosting can be used for editing and compositing scenes, but allows for better rendering of complex volumetric effects and fuzzy materials, such as hair or grass.]()

![Fig.4: Creating a Layer of Gaussian Frosting. To build our proposed Frosting representation, we start by optimizing a Gaussian Splatting representation using a rendering loss without any additional constraint, to let Gaussians position themselves. We refer to these Gaussians as unconstrained. We then regularize these Gaussians to enforce their alignement with the surface, and extract a mesh that will serve as a basis for the Frosting. Next, we use the misalignment of surface-aligned Gaussians to identify areas where more volumetric rendering is needed, and we build search intervals Ji around the mesh's vertices vi. Finally, we use the density function of the unconstrained Gaussians to refine the intervals, resulting in a Frosting layer. We finally sample a novel, densified set of Gaussians inside the layer.]()

![Fig. 6: How we define the inner and outer bounds of the Frosting layer. See text in Section 4.2.]()

![Fig. 8: Close-up views of fuzzy materials from the Shelly dataset [40] reconstructed with vanilla Gaussian Splatting [17] (center) and Frosting (right).]()

![Fig.9: Examples of animation with Frosting. We were able to animate the sculpture in the left image using the rigging tool in Blender.]()

![Original pose(b) Adaptive thickness (ours) (c) Constant thickness (baseline)]()

![Quantitative evaluation of rendering quality on the Mip-NeRF 360 dataset[2]. Frosting is best among the methods that recover an editable Radiance Field with explicit meshes, and achieves performance comparable to NeRF methods and vanilla 3D Gaussian Splatting.]()

![Quantitative evaluation of rendering quality on real scenes from Tanks&Temples[19], Deep Blending[12] and our custom dataset. Our representation performs the best among the surface-based methods, and achieves similar or better performance than unconstrained 3DGS and other non-editable methods.]()

![Comparing different strategies for computing the thickness of the Frosting layer.]()

