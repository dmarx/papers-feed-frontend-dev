- Decision to use coherence scores for training conditional diffusion models
- Choice of datasets for training and evaluation (e.g., COCO, ImageNet, ADE-20K)
- Method for integrating coherence scores into the training process
- Approach to handling noisy data in training sets
- Design of the flexible inference scheme for varying coherence levels
- Modification of Classifier-Free Guidance (CFG) to incorporate coherence
- Selection of evaluation metrics (e.g., CLIP score, FID)
- Strategy for data preprocessing and cleaning
- Decision on model architecture (e.g., U-Net vs. alternative architectures)
- Choice of loss function for training the diffusion model
- Assumptions regarding the relationship between coherence and image quality
- Approach to handling different types of conditioning (text, class labels, semantic maps)
- Decision to retain low-coherence samples for training
- Method for estimating coherence scores during inference
- Strategy for user control over the generation process through coherence manipulation
- Evaluation of model performance across different tasks and datasets