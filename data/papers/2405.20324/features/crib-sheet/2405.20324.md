- **Conditional Diffusion Models**: Learn to denoise images at various noise levels, using a noise scheduler \( \gamma(t) \) to corrupt images with Gaussian noise. The objective is to minimize the loss:
  \[
  L_{\text{simple}} = E_{(X,y) \sim p_{\text{data}}, t \sim U[0,1]} \left[ \| \epsilon - \epsilon_\theta(X_t, y, t) \| \right]
  \]

- **Coherence Score**: A measure \( c \in [0, 1] \) indicating the alignment of the condition \( y \) with the image \( X \). A score of 1 indicates perfect alignment, while 0 indicates poor alignment.

- **Coherence-Aware Diffusion (CAD)**: Introduces coherence scores into the training process, allowing the model to learn from both high and low coherence samples. The modified loss function is:
  \[
  L_{\text{simple}} = E_{(X,y,c) \sim p_{\text{data}}, t \sim U[0,1]} \left[ \| \epsilon - \epsilon_\theta(X_t, y, c, t) \| \right]
  \]

- **Classifier-Free Guidance (CFG)**: Enhanced by incorporating coherence scores, allowing for better control over the influence of conditions during image generation.

- **Training with Noisy Data**: Instead of discarding low-coherence samples, CAD allows the model to learn from them, improving robustness against noisy labels.

- **Evaluation Tasks**: CAD evaluated on three tasks:
  - Text-to-image generation using CLIP score for coherence.
  - Class-conditional generation using confidence estimators.
  - Semantic map generation with pixel-level coherence scores.

- **Results**: CAD improves image quality and coherence with prompts, demonstrating versatility across different conditioning types.

- **Applications**: CAD applicable in various domains such as design, art, and marketing, enhancing user control over generated content.

- **Key Figures**: 
  - Figure 1: Visual quality and aesthetics of images generated by CAD.
  - Coherence score impact on CLIPScore and FID metrics.

- **Future Work**: Explore further refinements in coherence scoring and its implications on model training and inference.