- **SSMBA Overview**: Self-Supervised Manifold Based Data Augmentation (SSMBA) generates synthetic training examples by using corruption and reconstruction functions to navigate the data manifold.
  
- **Key Functions**:
  - **Corruption Function (q)**: Perturbs an example \( x \) off the data manifold.
  - **Reconstruction Function (r)**: Projects the perturbed example back onto the manifold.

- **Manifold Assumption**: High-dimensional data concentrates around a low-dimensional manifold, allowing for effective data augmentation by generating examples within the manifold neighborhood.

- **Denoising Autoencoder (DAE)**: Trained to reconstruct clean input \( x \) from a corrupted version \( x \sim q(x | x) \). The sampling process follows:
  \[
  x_t \sim q(x | x_{t-1}), \quad x_t \sim P_\theta(x | x_t)
  \]

- **Masked Language Models (MLM)**: Utilized as DAEs in SSMBA, where a percentage of input tokens are randomly corrupted, and the model reconstructs the original tokens based on context.

- **Augmentation Process**:
  1. For each input-output pair \( (x_i, y_i) \):
     - Sample a perturbed \( x_i \sim q(x | x_i) \).
     - Sample a reconstructed \( x_{ij} \sim r(x | x_i) \).
     - Generate corresponding output \( \hat{y}_{ij} \) using either \( y_i \) or a teacher model.
  2. Repeat to create multiple augmented examples.

- **Experimental Results**: SSMBA outperforms existing methods on various tasks:
  - **OOD Amazon Reviews**: +0.8% accuracy
  - **OOD MNLI**: +1.8% accuracy
  - **IWSLT14 German-English**: +1.4 BLEU score

- **Datasets Used**:
  - **Sentiment Analysis**: Amazon Reviews, SST2, Yelp Reviews.
  - **Natural Language Inference**: MNLI, ANLI.
  - **Machine Translation**: IWSLT14 (de→en), OPUS (OOD), Allegra corpus (de→rm).

- **Model Types**:
  - **Sentiment Analysis**: LSTMs, CNNs.
  - **NLI**: Fine-tuned RoBERTa BASE models.
  - **MT**: Transformers.

- **SSMBA Settings**:
  - **Corruption Percentage**: Total percentage of tokens corrupted is tuned; specific operations are fixed (80% masked, 10% random, 10% unmasked).
  - **Augmented Example Generation**: 5 examples per input using unrestricted sampling.

- **Baselines for Comparison**: 
  - Easy Data Augmentation (EDA)
  - Conditional Bert Contextual Augmentation (CBERT)

- **Code Availability**: Implementation can be found at [GitHub Repository](https://github.com/nng555/ssmba).