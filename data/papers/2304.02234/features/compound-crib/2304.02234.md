The research you provided highlights significant challenges in using imperceptible perturbations to protect images from malicious editing by AI models, particularly in the context of JPEG compression. Below is a detailed technical explanation and rationale for the researchers' decisions regarding the key concerns and methodologies discussed in the study.

### Key Concerns

1. **JPEG Compression and Perturbation Fragility**:
   - JPEG compression is a lossy compression technique that reduces file size by discarding some image data, particularly high-frequency components. This characteristic makes JPEG compression particularly effective at diminishing the effectiveness of imperceptible perturbations designed to protect images. The researchers found that when images protected by perturbations (like those generated by photoguard) are JPEG compressed, the perturbations are often significantly reduced or eliminated, allowing adversaries to edit the images while maintaining the original subjects.
   - The study emphasizes that the robustness of perturbations is critical, especially since JPEG is a widely used format for image storage and sharing. The commonality of JPEG compression means that any protection mechanism must account for this transformation to be effective in real-world scenarios.

2. **Diffusion Models and Malicious Use**:
   - Text-to-image diffusion models, such as the Stable Diffusion Model (SDM), can generate or edit images based on textual prompts. This capability raises concerns about malicious applications, such as creating deepfakes or altering images in deceptive ways. The researchers highlight the ease with which these models can be used for harmful purposes, necessitating effective protective measures for images.

3. **Imperceptible Perturbations**:
   - The researchers discuss the use of imperceptible perturbations as a defense mechanism against AI editing. These perturbations are designed to be undetectable to human observers while disrupting the ability of diffusion models to generate realistic edits. However, the study reveals that these perturbations are fragile against JPEG compression, which undermines their effectiveness.

### Methodologies

1. **Encoder and Diffusion Attacks**:
   - The study introduces two types of attacks: the encoder attack and the diffusion attack. Both aim to find perturbations that, when added to an image, result in a protected image that either confuses the image encoder or the diffusion model itself.
   - The encoder attack formulates the problem as minimizing the difference between the encoded representation of the perturbed image and a target latent representation. The diffusion attack similarly seeks to minimize the difference between the output of the diffusion model applied to the perturbed image and a target image.
   - These formulations highlight the adversarial nature of the problem, where the goal is to create perturbations that effectively disrupt the model's ability to generate realistic outputs.

2. **JPEG Compression Impact**:
   - The researchers conducted experiments to assess how different levels of JPEG compression affect the ability of adversaries to edit protected images. They found that compression levels between 85% and 75% significantly reduced the effectiveness of the perturbations, allowing adversaries to generate more realistic edits.
   - This finding underscores the need for protective mechanisms to be robust against common image transformations, particularly those that are likely to occur in practice.

3. **Robustness of Perturbations**:
   - The study emphasizes the necessity for perturbations to be robust against a wider range of transformations, including JPEG compression. The researchers argue that current methods are inadequate for protecting images against adversarial editing, especially when JPEG compression is applied.
   - They suggest that future research should focus on developing more resilient perturbation techniques that can withstand various transformations without losing their protective qualities.

4. **Alternative Transformations**:
   - The researchers explored other transformations, such as Gaussian blur and rotations, to determine their effectiveness in restoring adversary editing capabilities. However, they found that these transformations were largely ineffective compared to JPEG compression, indicating that JPEG's unique characteristics make it particularly challenging for perturbation-based defenses.

### Conclusion

The research concludes that while imperceptible perturbations represent a novel approach to protecting images from AI editing, they are currently insufficient due to their fragility against JPEG compression. The findings highlight the ongoing challenge of developing robust image protection mechanisms in the face of evolving AI capabilities and common image processing practices. The researchers call for further exploration of alternative methods that can provide stronger defenses against adversarial editing, particularly in high-stakes scenarios where image integrity is critical.