- **Key Concern**: JPEG compression undermines the effectiveness of imperceptible perturbations designed to protect images from AI editing.
  
- **Diffusion Models**: Text-to-image diffusion models (e.g., Stable Diffusion Model (SDM)) can easily edit or create images based on user-defined prompts, raising concerns about malicious use.

- **Imperceptible Perturbations**: Proposed methods (e.g., photoguard) add imperceptible noise to images to prevent realistic edits by diffusion models. However, these perturbations are fragile against JPEG compression.

- **Encoder Attack**: 
  - Objective: Find perturbation \( \delta_{\text{encoder}} \) such that:
    \[
    \delta_{\text{encoder}} = \arg \min_{\delta} \| E(x + \delta) - z_{\text{target}} \|_2^2
    \]
  - \( E \): Image encoder, \( x \): original image, \( z_{\text{target}} \): target latent representation.

- **Diffusion Attack**: 
  - Objective: Find perturbation \( \delta_{\text{diffusion}} \) such that:
    \[
    \delta_{\text{diffusion}} = \arg \min_{\delta} \| f(x + \delta) - x_{\text{target}} \|_2^2
    \]
  - \( f \): SDM, \( x_{\text{target}} \): target image to be generated.

- **JPEG Compression Impact**: JPEG compression can significantly reduce the effectiveness of perturbations, allowing adversaries to edit images while maintaining original subjects. Compression quality between 85% and 75% is particularly effective.

- **Robustness of Perturbations**: The study emphasizes the need for perturbations to be robust against a wider range of transformations, including JPEG compression, to effectively protect images.

- **Alternative Transformations**: Other transformations (e.g., Gaussian blur, rotations, flips) were found ineffective in restoring adversary editing capabilities compared to JPEG compression.

- **Conclusion**: Current methods using imperceptible perturbations are inadequate for protecting images against adversarial editing, especially when JPEG compression is applied. The challenge remains to develop more robust protection mechanisms.