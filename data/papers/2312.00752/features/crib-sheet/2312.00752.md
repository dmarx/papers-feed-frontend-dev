- **Foundation Models (FMs)**: Large models pretrained on massive datasets, primarily using Transformer architecture for sequence modeling across various domains (language, images, audio, etc.).

- **Key Limitations of Transformers**: Quadratic scaling with sequence length and inability to model beyond finite context windows.

- **Structured State Space Models (SSMs)**: A class of sequence models combining RNNs and CNNs, offering linear or near-linear scaling in sequence length and effective long-range dependency modeling.

- **Selective State Space Models**: Introduces input-dependent parameterization to enhance content-based reasoning, allowing selective information propagation and retention.

- **Mamba Architecture**: A simplified end-to-end neural network architecture integrating selective SSMs, designed for high throughput (5× faster than Transformers) and linear scaling in sequence length.

- **Performance Metrics**:
  - **Language Modeling**: Mamba-3B outperforms Transformers of the same size and matches those twice its size in pretraining and downstream tasks.
  - **Audio and Genomics**: Achieves state-of-the-art performance, significantly improving metrics like FID in speech generation.

- **Hardware-aware Algorithm**: Implements a recurrent computation with a scan to avoid inefficient IO access, enhancing performance on modern GPUs (up to 3× faster on A100).

- **Key Equations**:
  - State transformation: 
    - \( h'(t) = A h(t) + B x(t) \)
    - \( y(t) = C h(t) \)
  - Discretization rules for parameters \( A \) and \( B \):
    - \( A = f_A(\Delta, A) \)
    - \( B = f_B(\Delta, A, B) \)

- **Linear Time Invariance (LTI)**: SSMs maintain constant dynamics over time, allowing efficient computation through recurrence or convolution.

- **Empirical Validation**: Mamba demonstrates superior performance on synthetic tasks, audio, and genomics, with scalability up to 1 million tokens.

- **Open-source Availability**: Model code and pre-trained checkpoints are accessible at [GitHub - Mamba](https://github.com/state-spaces/mamba).