# Time-series attribution maps with regularized contrastive learning

## Abstract

## 

Gradient-based attribution methods aim to explain decisions of deep learning models but so far lack identifiability guarantees. Here, we propose a method to generate attribution maps with identifiability guarantees by developing a regularized contrastive learning algorithm trained on time-series data plus a new attribution method called Inverted Neuron Gradient (collectively named x CEBRA). We show theoretically that x CEBRA has favorable properties for identifying the Jacobian matrix of the data generating process. Empirically, we demonstrate robust approximation of zero vs. non-zero entries in the ground-truth attribution map on synthetic datasets, and significant improvements across previous attribution methods based on feature ablation, Shapley values, and other gradient-based methods. Our work constitutes a first example of identifiable inference of time-series attribution maps and opens avenues to a better understanding of timeseries data, such as for neural dynamics and decision-processes within neural networks.

## Introduction

The distillation of knowledge from data is a core tenet of science. In neuroscience, where high-dimensional and large-scale data are becoming increasingly available, a better understanding of how the input data is shaping the distilled knowledge is a key challenge. Modern approaches for extracting information for neural time-series data are leveraging deep learning models to extract latent dynamics. Yet, the nature of how individual neurons can be mapped to these populationlevel latents is unknown. Similarly to computer vision, where pixels are attributed to classification decisions, our aim is to understand how individual neurons contribute to the neural code over time.

In machine learning, especially in computer vision, many algorithms exist for explaining the decisions of trained (non-linear) neural networks, often on staticimage classification tasks [(Samek et al., 2019;](#b0)[Ancona et al., 2017;](#b1)[Shrikumar et al., 2016;](#)[Sundararajan et al., 2017;](#b3)[Montavon et al., 2015;](#b4)[Simonyan et al., 2013;](#b5)[Lundberg and Lee, 2017)](#b6). In particular, gradient-based attribution methods have shown empirical success, but can be computationally costly and/or lack theoretical grounding [(Simonyan et al., 2013;](#b5)[Lundberg and Lee, 2017)](#b6), which ultimately limits their utility and scope in scientific applications that benefit from theoretical guarantees.

We consider the problem of estimating time-series attribution maps for the purpose of scientific, neural data analysis. Concretely, in neuroscience, various populations of neurons are recorded over time, and one aims to understand how these neurons relate to observable behaviors or internal states (Figure [1](#)). For interpretability, linear methods (such as PCA or linear regression) are often used, even though the underlying data did not necessarily arise from linear processes. However, non-linear methods are difficult to interpret [(Breen et al., 2018;](#b7)[Samek et al., 2019)](#b0). Emerging approaches leverage latent variable models, which are particularly well suited to extract the underlying dynamics, but how these abstract latent factors map onto neurons remains an open challenge.

Here, we build on recent advances using time contrastive learning with auxiliary variables, as it showed considerable promise in its performance for recovering latent spaces with identifiability guarantees, both theoretically and empirically [(Hyvarinen and Morioka, 2016;](#b8)[Hyvarinen et al., 2019;](#b9)[Schneider et al., 2023;](#b10)[Zimmermann et al., 2021)](#b11). arXiv:2502.12977v1 [stat.ML] 17 Feb 2025

x CEBRA for explainable attribution maps in time-series data Our work connects recent advances in identifiable representation learning with the estimation of attribution maps for scientific data analysis. Specifically, 1. We formalize properties of time-series attribution maps based on the causal connectivity between latents and input data in Section 2. Moving towards such a formalism will help align goals of future estimation algorithms, as the derivated theoretical properties are necessary for successful application of attribution methods in scientific inference. 2. We propose a regularized contrastive learning algorithm in Section 3, and theoretically show that this algorithm recovers the essential graph structure of these ground truth attribution maps in Section 4. 3. We verify our algorithm on multiple synthetic datasets in Section 6 and show applicability to neural data in Section 7. Critically, we show that our unsupervised regularized contrastive learning and Inverted Neuron Gradient ( x CEBRA) method can outperform supervised baselines.

Related Works. Interpretable machine learning stems from either ante hoc designing interpretable models, i.e., linear models or de-correlated design matrices, or post hoc using attribution methods such as perturbations or gradient methods. In the presence of non-linear relationships in the data, the first approach is often not feasible. Thus, the field of Explainable AI aims to design algorithms for understanding "blackbox models", which facilitates comprehension and refinement of complex models and/or data.

Depending on the type of explanation one aims to obtain, there are different post hoc interpretability methods [(Samek et al., 2019)](#b0). We can differentiate between local and global explanations. Global explanations provide an interpretable description of the behavior of the model as a whole. Local explanations provide a description of the model behavior in a specific neighborhood/for an individual prediction.

Local explanations, which we consider most critical for time-series, assign a weight to each feature in the input space that indicates its importance or effect.

Perturbation-based methods compute a relevance score by removing, masking, or altering the input, running a forward pass on the new input, and measuring the difference with the original input. Methods include LIME or the highly popular Shapley values [(Ribeiro et al., 2016;](#b12)[Lundberg and Lee, 2017)](#b6). Gradient-based methods locally evaluate the gradient ∂f /∂x i or variations of it (e.g., the absolute value of the gradient). Methods include Integrated Gradients, SmoothGrad, or Grad-CAM [(Sundararajan et al., 2017;](#b3)[Smilkov et al., 2017;](#b13)[Selvaraju et al., 2017)](#b14).

## Identifiable attribution maps

A critical application of attribution methods is to investigate properties of a trained neural network, e.g., a computer vision model classifying images. In many scientific domains, data comes in the form of timeseries [(videos, neural recordings, etc.)](#). Therefore, in this setting, we are interested in a notion of attribution grounded in the ground truth connectivity -"ground truth map' -between the recorded time-series data and the underlying data-generating process, i.e., latent factors, at each time step. Such a view on attribution methods allows us to connect the attribution map to the causal structure of the data generating process, which we outline in the following:

Definition 1 (Data generating process). We assume that data is generated from a set of latent factors

$z 1 ∈ R d1 , . . . , z G ∈ R d G .$For brevity, the vector z ∈ R d denotes the concatenation of all factors, and d = i d i . Their distribution for the timestep t factorizes to

$p(z (t) |z (t-1) ) = G i=1 p(z (t) i |z (t-1) i ),(1)$i.e., factors are conditionally independent given their value at the previous time step z (t-1) . The support of the resulting marginal distributions p(z i ) is assumed to be a convex body or the hypersphere embedded in R di . The conditional distribution is assumed to take the form

$∀i ∈ [G] : p(z (t) i |z (t-1) i ) ∝ exp (-δ(z (t) i , z (t-1) i )) (2)$for each latent factor, based on the negative dotproduct or a semi-metric δ :

$Z × Z → R. An injective mixing function g : Z → X with X ⊆ R D maps latent factors to observations, ∀i ∈ [D] : x i = g i ([z j ] j∈Pi ). (3$$)$P i is an index set, and j ∈ P i implies that factor z j ∈ R dj is used to generate the output x i .

Some factors are connected to auxiliary variables c i through bijective maps

$γ i : R di → R di s.t. z i = γ i (c i ), as exemplified in Figures 1 & 2.$We proceed with a rigorous definition of identifiability for time-series attribution maps. Identifiability in the context of deep learning models is commonly studied in terms of indeterminacies in the inferred latent space [(Khemakhem et al., 2020;](#b15)[Roeder et al., 2021)](#b16). Under the data-generating framework defined above, consider a feature encoder f : X → Z which maps observable data to an embedding space. The feature encoder is Figure [1](#): Identifiable attribution maps for time-series data. Using time-series data (such as neural data recorded during navigation, as depicted), our inference framework estimates the ground-truth Jacobian matrix J g (i.e., x is the observed neural data linked to latents z and c, where c is the explicit [auxiliary] behavioral variable that would be linked to grid cells) by identifying the inverse data generation process up to a linear indeterminacy L. Then, we estimate the Jacobian J f of the encoder model (f ) by minimizing a generalized InfoNCE objective. Inverting this Jacobian J + f , which approximates J g , allows us to construct the attributions.

part of a probabilistic model with density 1 p f . We define:

Definition 2 (Subspace Identifiability). Feature encoders f ′ , f * : X → Z are identifiable up to subspaces if matching distributions p f ′ = p f * imply that the following equivalence relation holds (the label "B" denotes "blockwise"):

$f ′ B ∼ f * ⇐⇒ f ′ (x) = Bf * (x),(4)$for the block-diagonal matrix B ∈ R d×d with blocks of sizes

$d 1 × d 1 , . . . , d G × d G .$Next, we extend the concept of identifiability to attribution maps. An attribution map A ∈ A ⊆ R D×d contains scores A ij . If the i-th latent is connected to the j-th output, we expect a high score, otherwise a low score -our definitions below are invariant to scaling and shifting of the scores. For two attribution methods generating attribution maps A ′ , A * ∈ A, we define the following equivalence relation on A:

Definition 3 (Identifiability of connectivity in attribution maps). Let A ′ , A * ∈ A be attribution maps for the feature encoders f ′ , f * . Let ∼ C be a pairwise relation on A defined as:

$A ′ C ∼ A * ⇐⇒ ∀i, j : (A ′ ij ̸ = 0 ⇔ A * ij ̸ = 0) (5)$An attribution method is identifiable if the following relation holds (the label "C" denotes "connectivity"):

$f ′ B ∼ f * =⇒ A ′ C ∼ A * . (6$$)$1 The definition of this density depends on the model type and would e.g., vary between an iVAE [(Khemakhem et al., 2020)](#b15) and a contrastive learning model. The following definitions are independent of this model choice.

The relation describes how to match the locations of the "zero entries" in A ′ and A * . For scientific discovery, obtaining this relation is already of high value: It addresses the question of how inferred latent factors are related (i.e.,"connected") to parts of the observable data. It also avoids conflicts with other definitions of attribution values discussed in the current literature [(Sundararajan et al., 2017;](#b3)[Afchar et al., 2021)](#b17).

We now have all the necessary definitions to establish a ground-truth attribution map for the mixing function g. Specifically, we are interested in how the factors z are connected to the generated data x by means of any non-linear mapping. The connectivity defined in Eq. 3 can be read out by considering the Jacobian matrix of g, which lets us define the ground truth attribution map as follows:

Definition 4 (Ground truth attribution map of the mixing function). The ground-truth attribution map A g ∈ A of the mixing function g is defined via the following relationship to the Jacobian matrix J g :

$∀z ∈ Z : A g C ∼ J g (z). (7$$)$Intuitively, zero-valued derivatives of the observable data with respect to a latent defines non-connectivity.

This definition of the "ground-truth map" is intentionally quite flexible. It does not conflict with existing approaches (for example, see [Sundararajan et al., 2017)](#b3), and does not imply a particular form of the groundtruth map A g besides the locations of zeros.

We now propose a new estimation algorithm for timeseries attribution maps under the data generating process in Def. 1, and later show that it satisfies the notion of identifiability in Def. 3. We introduce a new variant of contrastive learning for estimation of time-series attribution maps, which we call x CEBRA (e x plainable). Specifically, we build on our previous work [CEBRA Schneider et al. (2023)](#). As we show in our theoretical results, this extended algorithm identifies latent factors underlying the dataset, and then attributes them to the input data conditioned on observable, auxiliary variables.

In the following, we call p(•|•) the positive and q(•|•) the negative sample distribution. We call (x, x + ) a positive pair, and all (x, x - i ) for i ∈ [N ] negative pairs. The auxiliary variables shape the positive distribution, and hence the positive pairs. x is the input time-series data, for example neural activity recorded from the brain (Figure [1](#)).

We define a feature encoder f := [f 1 ; . . . ; f G ], with f i : X → R di that maps samples into an embedding space partitioned into G groups. In practice, we parameterize f as a single neural network and only split the last layer into G different parts. For training, we apply similarity metrics ϕ i : R di × R di → R to the different parts of this feature encoder, abbreviated as ψ i (x, y) := ϕ i (f (x), f (y)). We then leverage the generalized InfoNCE loss [(Schneider et al., 2023)](#b10),

$L N [ψ] = E x∼p(x), x + ∼pi(x + |x), x - 1 ...x - N ∼q(x -|x) ℓ(x, x + , {x - j } N j=1 ) ,(8)$using the loss function

$ℓ(x, x + , S) = -ψ(x, x + ) + log x -∈S e ψ(x,x -) ,(9)$where S denotes a set of negative examples. In addition, we regularize the Jacobian matrix of the feature encoder by minimizing its Frobenius norm [(Hoffman et al., 2019)](#b18). With these constraints, we propose our modified objective function, which we call Regularized Contrastive Learning, for all parts of the representation:

$L N [ψ; λ] = E x∼p(x), x + i ∼pi(x + |x) ∀i∈[G] x - 1 ,...,x - N ∼q(x -|x) G i=1 ℓ(x, x + i , {x - i } N i=1 ) + λ∥J f (x)∥ 2 F ,(10$) where J f (x) is the Jacobian of the feature encoder f optimized as part of ψ, ∥ • ∥ F denotes the Frobenius norm and λ is a hyperparameter tuned based on the learning dynamics. λ is set to the highest value possible that still allows the InfoNCE component of the loss to stay at its minimum.

In this work, we use this method in two ways: "supervised contrastive" and "hybrid contrastive" both with (λ > 0) or without regularization (λ = 0). Supervised means the auxiliary information is used for all latent dimensions. Hybrid means some latent dimensions are specifically reserved for unaccounted for latent factors (i.e., unsupervised "time-only'; factors that we do not explicitly test with auxiliary data but want to account for) and others tied to auxiliary variables [(Schneider et al., 2023)](#b10).

Model fitting. To optimize Eq. 10, we need to sample from suitable positive distributions p 1 , . . . , p G for each group and a negative distribution q. If a latent factor z is connected to an observable c, we use a variant of supervised contrastive learning with continuous labels [(Schneider et al., 2023)](#b10): We uniformly sample a timestep t (and hence, a sample x (t) ) from the dataset. This timestep is associated to the label c (t) . We consider the changes of c across the dataset, ∆ t = c (t+1) -c (t) . We sample a timestep τ uniformly, and then find the timestep t ′ for which ∥c (t ′ ) -c (t) -∆ τ ∥ is minimized. This yields a positive pair (x (t) , x (t ′ ) ) to feed to the model.

If a latent factor is not connected to an observable, we leverage the time structure only [(Hyvarinen and Morioka, 2017;](#b19)[Hyvarinen et al., 2019)](#b9) and use adjacent timesteps as positive pairs: (x (t) , x (t+1) ). More details about sampling are provided in the Appendix.

Obtaining attribution maps. Our attribution map A is a D × d-dimensional matrix and its entry A ij denotes if the latent at dimension j is related to input dimension i. We can compute such a map for every timepoint in the dataset or aggregate multiple timepoints into a global map.

After training f using our regularized contrastive learning method, we obtain attribution maps by computing the Jacobian matrix J f (x). We then consider its pseudo-inverse J + f (x) at every timestep, which we name the "inverted neuron gradient". The estimation coincides with the "neuron gradient" attribution method [(Simonyan et al., 2013)](#b5), however this has not been paired with identifiable regularized contrastive learning as proposed here.

Similar to [Afchar et al. (2021)](#b17), our work focuses on the problem of clearly delineating the binary relationship between latents and input data. For this, we threshold the attribution map with a variable decision threshold ϵ, Â(x) := 1{|J + f (x)| > ϵ} for inverted neuron gradi-ent, and analogously for our baseline methods.

To obtain a global attribution map from local attribution maps, we additionally improve the signal-tonoise ratio by averaging multiple maps. In practice, we found that the operation

$Â = 1{ x |J + f (x)| > ϵ}(11)$yields even better performance, which we used for all experiments and baselines. An alternative, which we considered but did not further explore due to seeing considerably worse performance, is to leverage a max operation instead of the sum. Taking the median is possible, and performs roughly on par with the mean.

4 Identifiability of x CEBRA

We now derive two new results relevant for the application to the generation of attribution maps. Firstly, we want to ensure a goodness of fit criterion for distinguishing meaningful fits of the model, both in the time contrastive and supervised contrastive case (Theorem 1). Secondly, we extend identifiability of the latent space to identifiability of the Jacobian (Theorem 2).

Theorem 1. Assume ψ * is a minimizer of the generalized InfoNCE loss (Eq. 8) under the non-linear ICA problem in Def. 1 for N → ∞. Assume that the model is trained on auxiliary variables c which are independent of z. Then, ψ * = const. is the trivial solution with lim N →∞ L N [ψ * ] = log N and the embedding collapses.

Proof. The full proof is given in Appendix A.3.

This result ensures that if an auxiliary variable c is not related to the data but still used during training, the loss remains at change level log N . Hence, we can rule out auxiliary variables not useful for subspace identification, and sort them out for model fitting.

We proceed with studying the attribution map. The loss in Eq. 10 intuitively solves G non-linear demixing problems using the single feature encoder f . By applying time contrastive and supervised contrastive learning to structure the embedding space, we can show:

Theorem 2. Assume

• A mixing function g with ground truth map A g maps latent factors z to a signal space such that x = g(z) according to Def. 1.

• The differentiable feature encoder f minimizes the regularized contrastive loss (Eq. 10) on the support of p(z).

Then, in the limit of infinite samples N → ∞,

• the model identifies the latent subspaces of the ground truth process, i.e., g(f (x)) = Bx with a block diagonal matrix B.

• we identify zero-entries of the ground truth attribution map A g (Def. 4) through the pseudoinverse J + f (x),

$J + f (x) C ∼ A g . (12$$)$Proof Sketch. The individual parts of the loss function result in ψ(x,

$x ′ ) = log p i (z ′ i |z i )/q(z ′ i ) from which a linear indeterminacy follows, f i (g(z)) = L i z.$We can express the result as f (g(z)) = Lz where L is a blockdiagonal matrix with zeros in its lower block triangular part. Hence, L -1 will have the same property. It then follows that J f (x)J g (z) = L and since J f has minimum norm everywhere, J + f (x) is the Moore-Penrose pseudoinverse of J g (z)L -1 . Multiplication with L -1 does not alter the location of zero entries in J g (z), and hence thresholding J + f (x) across samples x in the dataset is an estimator of the ground-truth attribution map. The full proof is given in Appendix A.4.

Theorem 1 justifies the use of the InfoNCE loss as a "goodness of fit". We leverage this property during model training of our regularized contrastive learning model, where we set λ = 0 for the first steps to determine the value of L N (ψ * ; 0). If this value converges to a minimum that is meaningfully below chance level (log N ), we proceed by raising λ, while ensuring that the InfoNCE loss stays constant. Once the second component of the loss also converges, Theorem 2 guarantees identifiability of zero/non-zero entries in the attribution map. Note, while both Theorems are stated in the limit of infinite data, [Wang and Isola (2020)](#b20) show that the deviation of the contrastive loss and its asympotic limit decays with O(N -1/2 ). The empirical verification below also confirms that our identifiability guarantee holds up well in practice, with limited N .

## Experimental Methods

Synthetic finite time-series data design. To verify our theory, we generated a synthetic dataset following Def. 1. An essential aspect of our synthetic design lies in the definition of the mixing function g which, consequently, defines the ground truth attribution map. We split z into the factors z 1 and z 2 (Appendix Figure [5](#)). Figure [2](#) illustrates the two experimental synthetic data-generation configurations employed in this work, and Appendix Figure [8](#) shows the learned embedding.

Table [1](#): Verification of the theory. auROC comparison of attribution methods (rows), and combinations of training/regularization schemes (columns). Our proposed method is regularized contrastive learning, with the Jacobian (Neuron gradient) or pseudo-inverse Jacobian (Inverted Neuron Gradient). Numbers average across different total latent dimensions (d = 4 to d = 9), for 10 different datasets. Sub-and superscript values denote the 95% confidence interval obtained through bootstrapping (n=1,000).

supervised supervised contrastive hybrid contrastive none regularized none regularized none regularized attribution method (Ours) (Ours) Feature Ablation 83.1 84.8 81.3 88.5 90.0 87.0 84.0 85.6 82.1 84.7 86.5 82.8 82.9 84.5 81.3 85.2 86.9 83.4 Shapley, shuffled 82.0 83.7 80.3 89.2 90.8 87.6 83.3 84.9 81.4 84.6 86.6 82.6 81.6 83.2 80.1 85.1 87.1 83.0 Shapley, zeros 81.0 82.8 79.3 84.9 86.8 83.1 82.0 83.7 80.2 82.4 84.3 80.4 81.6 83.4 79.9 83.2 85.0 81.2 Integrated Gradients 81.0 82.7 79.2 84.9 86.6 83.1 81.9 83.7 80.2 82.3 84.3 80.5 83.9 85.6 82.1 86.9 88.8 84.9 Neuron Gradient 79.2 81.0 77.4 93.0 94.5 91.5 80.6 82.4 78.8 86.7 89.0 84.6 79.2 81.0 77.5 88.0 90.1 85.8

Inverted Neuron Gradient (Ours) 76.9 78.7 74.9

92.9 94.5 91.5

77.5 79.4   75.5

86.1 88.3   83.8

87.9 89.5 86.3

98.2 98.9

97.4

$z 1 z 2 c 2 x 1 x 2 z 1 z 2 c 1 x 1 x 2 (a)(b)$Figure [2](#): Left: Graphical model for the data generating process where z 2 is observed through c 2 . The attribution map needs to be computed with respect to z 2 , which is inferred with supervised (contrastive) learning. Note, practically, this means x 2 is behaviorally linked to c 2 (denoted by dashed line). Related to Table [1](#). Right: Graphical model for the data generating process where z 1 is observed through c 1 . Since z 2 is not observed, the attribution map can only be estimated through the time-contrastive component in

x CEBRA. Related to Table [2](#tab_1).

In both settings, z 1 is connected both to x 1 and x 2 whereas z 2 is only connected to x 2 . The main difference is that in the first setting z 2 = γ 2 (c 2 ) whereas in the second setting z 1 = γ 1 (c 1 ). We sample 10 different datasets with 100,000 samples, each with a different mixing function g. All latents of the dataset are chosen to lie within the box [-1, 1] D . The following timesteps are generated by Brownian motion.

Model fitting. The feature encoder f is an MLP with three layers followed by GELU activations [(Hendrycks and Gimpel, 2016)](#b21), and one layer followed by a scaled tanh to decode the latents [Schneider et al. (2023)](#b10). We train on batches with 5,000 samples each.

The first 2,500 training steps minimize the InfoNCE or supervised loss with λ = 0; we ramp up λ to its maximum value over the following 2,500 steps, and train until 20,000 total steps. We compute the R 2 for predicting the auxiliary variable c from the feature space after a linear regression and ensure that this metric is close to 100% for both our baseline and contrastive learning models to remove performance as a potential confounder. Hyperparameters are identical between training setups, the regularizer λ, and number of training steps are informed by the training dynamics.

Baselines. To compare to previous works, we vary the training method (hybrid contrastive, supervised contrastive, standard supervised) and consider baseline methods for estimating the attribution maps (Neuron gradients, [Simonyan et al., 2013;](#b5)[Integrated gradients, Shrikumar et al., 2018;](#)[Sundararajan et al., 2017;](#b3)[Shapley values, Shapley, 1953;](#)[Lundberg and Lee, 2017;](#b6)[and Feature ablation, Molnar, 2022)](#), which are commonly used algorithms in scientific applications [(Samek et al., 2019;](#b0)[Molnar, 2022)](#b24). To compute these attribution maps, we leveraged the open source library Captum [(Kokhlikyan et al., 2020)](#b25). We also compare regularized and non-regularized training.

Evaluation. We evaluate the identification of the attribution map at different decision thresholds ϵ similar to a binary classification problem: namely, for each decision threshold, we binarize the inferred map, and compute the binary accuracy to the ground truth map.

We compute the ROC curve as we vary the threshold for each method, and use area under ROC (auROC) as our main metric. In practice where a single threshold needs to be picked, we found z-scoring of the attribution score an effective way to set ϵ corresponding to a z-score of 0.

Synthetic (RatInABox) neural data. As an application to a neuroscientific use case, we generate syn-thetic neural data during navigation using RatInABox (George et al., 2024), a toolbox that simulates spatial trajectories and neural firing patterns of an agent in an enclosed environment. We generate firing rates of place, two modules of grid, head direction, and speed cells (n=100 neurons each, 400 neurons in total) for 20,000 time steps. To calculate the grid scores we used the method described by [Sargolini et al. (2006)](#b27).

With these cell types, at least three properties (position, speed, and head direction) are encoded by these neurons, and represented in the ground truth latents. Speed information is incorporated only in speed cells, head direction information only in head direction cells, and position information is coded by both position and grid cells, by design. We design the attribution map accordingly (Appendix Figure [9](#)) -for models trained with position information, we would expect to discover grid and place cells, but not the other types. Further details are outlined in Appendix B.2.

## Simulations

Regularized, hybrid contrastive learning identifies the ground truth attribution map. We begin by experimentally testing our theory that regularized hybrid contrastive learning allows for causal discovery of time-series attribution maps. To quantify this, we first consider an average auROC score across time for recovering the ground truth graph structure (as shown in Figure [2](#)(a)).

Concretely, Table [1](#) shows the auROC for recovering A using combinations of training schemes. We investigate the effect of the different model properties with an ordinary least squares (OLS) ANOVA (F = 17.0, p < 10 -5 ) followed by a Tukey HSD posthoc test, see Appendix D for statistical methods and full results. Both the combination of regularized training followed by estimating the pseudo-inverse (p < 0.01), and combining regularized training with hybrid contrastive learning (p < 0.001) significantly outperform all considered baselines, validating the claims made in Theorem 2 empirically.

Contrastive learning is critical for large numbers of latent factors. The importance of using hybrid contrastive learning (which can identify the latent factors) becomes most apparent with an increasing number of latent factors, as we would expect in a realistic dataset. Figure [3](#fig_2) shows the variation in performance as we keep the dimension of observable factors fixed at 2 and vary the latent dimension from 4 to 9. Performance scales with the number of available training samples, and we observed that increasing dataset size beyond 100,000 samples allows the use of   even higher numbers of latents.

Hybrid contrastive learning allows attribution computation with latent factors. In contrast to supervised algorithms, hybrid contrastive learning allows us to estimate the attribution map with respect to latent factors, i.e., we treat z 1 as the observable, and z 2 as the latent factor. With hybrid contrastive learning, we can continue to estimate the attribution map at auROC=99.2% (Table [2](#tab_1)).

Estimation of the correct dimensionality. It is interesting to consider the case where the dimensionality of the underlying latent space, and the dimensionality of the feature encoder do not match. In these cases, the correct dimensionality can be inferred by starting at a low embedding dimension, and increasing the dimension until the empirical identifiability between pairs of models peaks. The aforementioned results also hold if the true latent dimensionality is unknown (see Appendix).

## Application to neural data analysis

We next tested the combinations of supervised (baseline), supervised-contrastive, and hybrid contrasting learning with or without regularization using the attribution method we propose (and compare to the described baselines) on synthetic neural data for benchmarking using RatInABox (Figure [4a](#fig_3); see Experimental Methods). On this data, multiple combinations of methods reach the maximum possible performance (100% auROC), but importantly this means that our

x CEBRA method still performs very well under more realistic (time and neuron number) settings (Appendix Table [3](#tab_3), Figure [4b](#fig_3)).

We then examined the position attribution scores for each cell type. Specifically, we measured whether place and grid cells had a higher attribution to speed or head direction (as would be desired from the ground truth graph (see Appendix Figure [9](#)). x CEBRA could indeed nicely segment neurons into different types (Figure [4c-e](#fig_3)). We also carried out experiments where we increased the noise within the input data and show excellent results with x CEBRA (Appendix Figure [10](#)).

Notably, our attribution method is computationally faster than integrated gradients and non-gradient based approaches like feature ablation, and of comparable speed as Shapley values (see Appendix Table 4). Contrastive model training adds a 2x computational overhead for behavior contrastive learning and a 3x computational overhead for the hybrid mode (Appendix Table [5](#tab_5)). This overhead comes with the ability to attribute inputs to latent factors and clearly defined behavior of the goodness-of-fit if no connection exists between input data and auxiliary variables (Theorem 1), i.e., visible as an embedding collapse.

Lastly, we show that our method is applicable to realworld neural data recorded in rats [(Gardner et al., 2022)](#b28). We trained x CEBRA (and baselines) with 2D position as the auxiliary variable. We compute the attribution score over time and show that our method can be used to attribute cells to known cell types (e.g., a grid cell); see Appendix C for full results.

## Discussion

Our presented approach differs from other time-series attribution methods by considering the attribution map of the data-generating process, which is particularly relevant for applications in scientific data anal-ysis. In contrast to previous work, our attribution map is not with respect to a particular model, but rather the data generating process itself.

Time-series attribution.

Ismail et al., 2021 discuss multiple attribution methods in the context of time-series attribution and point to their potential limitations. An early work trying to address these limitations is Dynamax Crabbé and van der Schaar (2021). Dynamax is a perturbation-based approach: Given a trained time-series model, it learns a binary mask which, when applied to the input, does not meaningfully change the prediction of that model. While the context is slightly different, the authors similarly to us define the correct masking values through non-zero gradients (see their Def. 2). However, unlike our notion, the definition here is with respect to the model trained on the data, without a defined connection to the ground truth process underlying the dataset. Liu et al., 2024 recently combined Dynamax-like training of an attribution mask with contrastive learning and the proposed ContraLSP. ContraLSP uses both a learned mask (like in Dynamax) and the inverted mask to provide a stronger regularization signal to the mask, resulting in substantially improved performance on several downstream tasks. Leung et al., 2023 propose WinIT which uses perturbation-based time series attribution across temporal dependencies. This extended the capabilities of Dynamax across multiple time steps, which is relevant in a range of real-world tasks.

However, these developments are orthogonal to our approach discussed here, as their main focus is on the computation of the mask value, rather than its theoretical connection to the ground truth process. We anticipate that incorporating advanced mask learning methods into the parameterization of our attribution map might yield further improvements over our naive averaging method to obtain a stable attribution map.

Contrastive surrogates. Another interesting development is CoRTX [Chuang et al. (2023)](#b33) train CoRTX which can be considered a "surrogate" model for generating explanations: Given an existing model to investigate, CoRTX trains a second model which mimics the sensitivity to perturbations using contrastive learning. This is an interesting connection to our supervised contrastive mode, as this sensitivity is an auxiliary variable influencing the selection of positive pairs. However, while [Chuang et al., 2023](#b33) provide error bounds between the surrogate and investigate model, no connection to the ground-truth generating process is given, as in our work. It would be interesting to discuss whether this method gets conceptually similar to ours as we consider the inverted data generating process g -1 as the "model" under in- vestigation; however, this still requires an approach like our proposed x CEBRA, specifically the regularized contrastive learning, for identifying this model in the first place.

Gradient based techniques. Ismail et al., 2021 discuss the performance of gradient-based techniques by altering the training process of the model that is supposed to be explained. This is quite orthogonal to our approach, and could be seen as an alternative for the Jacobian regularizer we developed. Note that the unique property of our approach is that we aim to find a "ground truth attribution map" of the underlying data-generating process.

## Conclusions

We proposed a theoretically grounded approach for estimating attribution maps in time-series data based on a newly formalized method: regularized contrastive learning with inverted neuron gradients. We theoretically and empirically showed that this approach can outperform supervised baselines. Our theoretical results hold for fully converged contrastive learning models with infinite data, yet our finite data experiments show the effectiveness of our approach in limited data settings. Although theoretically connecting the attribution score to model fit in limited data is complex, our work shows that the measured R 2 of recovering observable factors aligns with theory. In neural record-ings, many behaviors and sensory inputs -such as animal motion, stimuli, and rewards -are measurable, leading the field to focus on mapping neural dynamics to these behaviors. Our work considers a single truly latent (but potentially multi-dimensional) factor for attribution, while also supporting multiple latents that can be mapped to observable auxiliary variables. Notably, our method outperforms supervised baselines in this task (Figure [3](#fig_2)).

Adopting the contrastive learning algorithm from Hyvarinen et al. ( [2019](#)) could theoretically improve results by achieving identifiability up to permutations and point-wise bijective transforms, yet it requires stricter conditions and more complex training with a non-linear projection head.

Lastly, for practical applications, our chosen setup is quite versatile. During analysis it is always possible to break up the linear ambiguity between different latent factors by specifying the dimensions (or more broadly, the basis vectors of a latent subspace) to attribute to. This possibility exists with our inference framework, and allows attribution to multiple latent factors with this form of weak supervision, i.e., user input.

Overall, our new method, x CEBRA, demonstrates a significant advancement in time-series attribution, and we hope future work can leverage it to find biological insights -how inputs concretely map to hidden underlying factors in neural dynamics. 

$s.t. ϕ i (f i (x), f i (y)) = log p i (y|x) q(y|x) + C i (x) ∀i ∈ [G],(14)$with the positive sample distribution p i and the negative sample distribution q. We call (x, y + ) the positive pair, and all (x, y - i ) negative pairs. In the following we define ψ i (x, y) := ϕ i (f i (x), f i (y)) where f := [f 1 ; . . . ; f G ] is the feature encoder and ϕ i are similarity metrics. We re-state the regularized contrastive learning objective function which is a relaxation of Eq. 14:

$L N [ψ; λ] = E x∼p(x), y + ∼pi(y|x) ∀i∈[G] y - 1 ...y - N ∼q(y|x)   G i=1 -ψ i (x, y + i ) + log N j=1 e ψi(x,y - j ) + λ∥J f (x)∥ 2 F   .(15)$In principle, this objective is able to identify an arbitrary amount of separate factor groups (G), given sufficient capacity of the model. The choice of ψ i for the individual parts of the feature representation depends on the exact distribution underlying data generation, and is discussed below.

## A.1 Preliminaries

Before proving our results on identifiable attribution maps, it is useful to restate a few known results from the literature, concerning properties of the InfoNCE loss. [Hyvarinen et al. (2019)](#b9) showed that contrastive learning with auxiliary variables is identifiable up to permutations or linear transformations for conditionally exponential distributions. Zimmermann et al. ( [2021](#)) related this to identifiability for models trained with the InfoNCE loss, and showed that assumptions about the data-generating process can be incorporated into the choice of loss function. [Schneider et al. (2023)](#b10) then formulated a supervised contrastive learning objective based on selecting the positive and negative distributions in the generalized InfoNCE objective.

We will first re-state the minimizer of the InfoNCE loss (Def. 8) used in our algorithm:

Proposition 1 (restated from [Schneider et al. (2023)](#b10)). Let p(•|•) be the conditional distribution of the positive samples, q(•|•) the conditional distribution of the negative samples and p(•) the marginal distribution of the reference samples. The generalized InfoNCE objective (Def. 8) is convex in ψ with the unique minimizer

$ψ * (x, y) = log p(y|x) q(y|x) + C(x), with L N [ψ * ] = log N -D KL (p(•|•)∥q(•|•)) (16)$for N → ∞ on the support of p(x), where C : R d → R is an arbitrary mapping.

Proof. See [Schneider et al. (2023)](#b10), but note that we added the batch size N .

We also re-state: Proposition 2 (restated from Proposition 6 in [Schneider et al. (2023)](#b10)). Assume the learning setup in Def. 1 [(Schneider et al., 2023)](#b10), and that the ground-truth latents u 1 , . . . , u T for each time point follow a uniform marginal distribution and the change between subsequent time steps is given by the conditional distribution of the form

$p(u t+∆t |u t ) = 1 Z(u t ) exp δ(u t+∆t , u t ) (17$$)$where δ is either a (scaled) dot product (and u t ∈ S n-1 ⊂ R d lies on the (n -1)-sphere S n-1 ) or an arbitrary semi-metric (and u t ∈ U ⊂ R d lies in a convex body U). Assume that the data generating process g with s t = g(u t ) is injective. Assume we train a symmetric CEBRA [(Schneider et al., 2023)](#b10) model with encoder f = f ′ and the similarity measure including a fixed temperature τ > 0 is set to or sufficiently flexible such that ϕ = δ for all arguments. Then h = h ′ = g • f is affine.

Proof. For δ being the dot product, the result follows from the proof of Theorem 2 in Zimmermann et al. ( [2021](#)).

For δ being a semi-metric, the result follows from the proof of Theorem 5 in [Zimmermann et al. (2021)](#b11).

A.2 Positive distributions for self-supervised and supervised contrastive learning Self-supervised contrastive learning Up to one of the parts in the latent representation z can be estimated using self-supervised learning by leveraging time information in the signal. The underlying assumption is that latents vary over time according to a distribution we can model with ψ. For instance, Brownian motion p(z (t+1) |z (t) ) = N (z (t+1) -z (t) |0, σ 2 I) can be estimated by selecting ϕ(x, y) = -∥x -y∥ 2 . On the hypersphere with a vMF conditional across timesteps, the dot product is a suitable choice for ϕ(x, y) = x ⊤ y. Due to Proposition 2, this training scheme is able to identify the ground truth latents up to a linear indeterminacy.

Supervised contrastive learning For supervised contrastive learning, we uniformly sample a timestep (and hence, a sample x) from the dataset. This timestep is associated to the label c, and we then sample c ′ from the conditional distribution p(c ′ |c). We select the nearest neighbour to c ′ with the corresponding sample x ′ .

The conditional distribution p(c ′ |c) can be constructed as an empirical distribution: For instance, if we assume non-stationarity, c (t) -c (t-1) can be computed across the dataset. Let us call this distribution p(c ′ -c). Then, sampling from p(c ′ |c) can take the form of sampling

$c ′ = c + ∆ with ∆ ∼ p(c ′ -c).$If this approximation is correct under the underlying latent distribution, have we have p(c ′ |c) det J -1 γ (c ′ ) = p(z ′ |z). This means that the solutions of the supervised and self-supervised contrastive learning solutions coincide.

Superposition of self-supervised and supervised contrastive learning Depending on the assumptions about the ground truth data distribution, different estimation schemes can be combined to obtain a latent representation. In the end, the feature encoder f should identify the original latents z up to a linear transformation,

$f (g(z)) = Lz. (18$$)$Our goal is to obtain block-structure in L, with zeros in the lower block triangular part of the matrix. This is possible by simultaneously solving multiple contrastive learning objectives, which requires

$f i (g(z)) = L i z. (19$$)$for each part i of the latent representation. Assume without loss of generality that we apply self-supervised contrastive learning to the G-th part, and supervised contrastive learning to all remaining parts. For supervised contrastive learning we then obtain

$f i (g(z)) = L i z = L ′ i z i . (20$$)$If all latents z satisfy the conditions for time-contrastive learning, we can then also apply time-contrastive learning to the full representation, which gives us the following constraints:

$f i (g(z)) = L i z = L ′ i z i ∀i ∈ [G -1] (21) f (g(z)) = Lz (22)$from which we can follow the matrix structure

$f (g(z)) = diag(L 1 , . . . , L G ) (23)$In cases where this is not possible, note that it is always possible to treat all contrastive learning problems separately, and learn separate regions of the feature space in f . This gives the same result, but re-uses less of the representation (e.g., the self-supervised part of the representation would be learned separately from the supervised part).

Consider a time-series dataset where p(z t |z t-1 ), i.e., all latents, follow Brownian motion. We can then produce the solution

$ψ i (x, x ′ ) :=ϕ i (f i (x), f i (x ′ )) = log p(c ′ i |c i ) q(c ′ i |c i ) i ∈ {1, . . . , G -1} (24) ψ G (x, x ′ ) := G i=1 ϕ i (f i (x), f i (x ′ )) = log p(z ′ |z) q(z ′ |z) = log p(z ′ G |z G ) q(z ′ G |z G ) + G-1 i=1 log p(c ′ i |c i )|J -1 γi (z ′ i )| q(c ′ i |c i )|J -1 γi (z ′ i )| (25)$in case our training distributions for supervised contrastive learning, p(c i |c i ) are a sufficiently good approximation of the variation in the ground truth latents, we can select ψ G (x, y) := ϕ(f (x), f (y)) to be trained on the whole feature space using self-supervised learning, while all other objectives on ψ i would solve supervised contrastive losses. If this training setup is not possible, it would be required to parametrize ψ G (x, y) := ϕ(f (x), f (y)) as a separate part of the feature space.

While it is beyond the scope of the current work to thoroughly investigate the trade-offs between the two methods, our verification experiments assume the former case: The time contrastive objective is applied to the whole objective function, and the behavior contrastive objective to the previous latent factors.

## A.3 Proof of Theorem 1

An interesting property of contrastive learning algorithms is the natural definition of a "goodness of fit" metric for the model. This goodness of fit can be derived from the value of the InfoNCE metric which is bounded from below and above as follows [(Schneider et al., 2023)](#b10):

$log N -D KL (p||q) ≤ L N [ψ] ≤ log N.(26)$In scientific applications, we can leverage the distance to the trivial solution log N as a quality measure for the model fit. Theorem 1 states that if during supervised contrastive learning with labels c there is no meaningful relation between c and x, we will observe a trivial solution with loss value at log N .

For the following proof, let us recall from Def. 1 that we can split the latents z that fully define the data through the mixing function, x = g(z). We can split z into different parts, z = [z 1 , . . . , z G ] and assume that c i is the observable factor corresponding to the i-th part. For notational brevity, we omit the i in the following formulation of the proof without loss of generality.

## Proof of Theorem 1

Proof. Assume that the distribution p is informed by labels. In the most general case, we can depict the sampling scheme for supervised contrastive learning with continuous labels c and c ′ and latents z and z ′ with the following graphical model:

$z z ′ c c ′$The reference sample x is linked to the observable factor/label c, and the conditional p(c ′ |c) links both samples.

In particular, z ′ and hence x ′ are selected based on c ′ in the dataset.

The distributions for positive and negative samples then factorize into

$p(z ′ |z) = dc ′ dcp(z ′ |c ′ )p(c ′ |c)p(c|z) (27) q(z ′ |z) = dc ′ dcp(z ′ |c ′ )q(c ′ |c)p(c|z)(28)$and note that only p(c ′ |c) and q(c ′ |c) are selected by the user of the algorithm, the remaining distributions are empirical properties of the dataset.

We can compute the density ratio

$p(z ′ |z) q(z ′ |z) = dc ′ dcp(z ′ |c ′ )p(c ′ |c)p(c|z) dc ′ dcp(z ′ |c ′ )q(c ′ |c)p(c|z)(29)$In the case where latents and observables are independent variables, we have p(z ′ |c ′ ) = p(z ′ ) and p(c|z) = p(c).

The equation then reduces to

$= dc ′ dcp(z ′ )p(c ′ |c)p(c) dc ′ dcp(z ′ )q(c ′ |c)p(c) (30) = p(z ′ ) dc ′ dcp(c ′ |c)p(c) p(z ′ ) dc ′ dcq(c ′ |c)p(c) = 1.(31)$Consequently, the minimizer is ψ(x, y) = C(x) and we obtain the maximum value of the loss with L[ψ] = log N in the limit of N → ∞. Note, for any symmetrically parametrized similarity metric (like the cosine or Euclidean loss), it follows that ψ(x, y) = ψ is constant, i.e., the function collapses onto a single point.

## A.4 Proof of Theorem 2

Proof. For the first part of the proof, we invoke Proposition 2. For training multiple encoders, for each latent factor z i and the corresponding part of the feature encoder f i , we obtain at the minimizer of the contrastive loss,

$∀i ∈ [G] : f i (g(z)) = L i z i .(32)$Assume without loss of generality that we apply self-supervised contrastive learning to the G-th part, and supervised contrastive learning to all remaining parts. For supervised contrastive learning we then obtain

$f i (g(z)) = L i z = L ′ i z i .(33)$If all latents z satisfy the conditions for time-contrastive learning, we can then also apply time-contrastive learning to the full representation, which gives us the following constraints:

$f i (g(z)) = L i z = L ′ i z i ∀i ∈ [G -1] (34) f (g(z)) = Lz(35)$from which we can follow the matrix structure

$f (g(z)) = diag(L 1 , . . . , L G )(36)$In cases where this is not possible, note that it is always possible to treat all contrastive learning problems separately. We then still get a block diagonal structure because all latents are independent, and no mapping can exist between separate latent spaces. Hence, if f is a minimizer of the InfoNCE loss under the assumed generative model, it follows that we part-wise identify the underlying latents,

$f (g(z)) = Bz (37)$with some block diagonal matrix B.

By taking the derivative w.r.t. z it follows that

$J f (x)J g (z) = B.(38)$We need to show that at each point z in the factor space, we can recover J g up to some indeterminacy. We will re-arrange the equation to obtain

$J f (x)J g (z)B -1 = I,(39)$$J f (x) Jg (z) = I.(40)$It is clear that for each point in the support of p, J f (x) is a left inverse of Jg (z).

$J f (x) = J+ g (z) + V, v i ∈ ker Jg (z)(41)$Among these solutions, it is well-known that the minimum norm solution J * to min

$J(z) ∥J(z)∥ 2 F s.t. J(z)J g (z) = I(42)$is the Moore-Penrose inverse, J * (z) = J+ g (z). By invoking assumption (2), we arrive at this solution and have

$J f (x) = J+ g (z)(43)$$J + f (x) = Jg (z)(44)$$J + f (x) = J g (z)B -1(45)$Because B is block-diagonal with zeros in the off-diagonal blocks, this also applies to B -1 . It follows that

$J + f (x) = J + f (g(z)) ∝ J g (z)(46)$concluding the proof.

## B Detailed experimental methods

## B.1 Synthetic finite time-series data design

We sample 10 different datasets with 100,000 samples, each with a different mixing function g. All latents of the dataset are chosen to lie within the box [-1, 1] D . We sample the dataset by selecting z 1 from a uniform distribution over [-1, 1] D . The following time steps are generated by Brownian motion,

$z t = N [-1,1] (z t-1 , σ 2 I)$where N [-1,1] is a truncated normal distribution clipped to the bounds of the box. All other latent factors are sampled accordingly. The process is outlined in Figure [5](#).

Similar to [Schneider et al. (2023)](#b10), the feature encoder f is an MLP with three layers followed by GELU activations [(Hendrycks and Gimpel, 2016)](#b21), and one layer followed by a scaled tanh to decode the latents. We train on batches with 5,000 samples each. The first 2,500 training steps minimize the InfoNCE or supervised loss with λ = 0; we then ramp up λ to its maximum value over the following 2,500 steps, and continue to train until 20,000 total steps. We compute the R 2 for predicting the auxiliary variable c from the feature space after a linear regression, and ensure that this metric is close to 100% for both our baseline and contrastive learning models to remove performance as a potential confounder.

To compare to previous works, we vary the training method (hybrid contrastive, supervised contrastive, standard supervised) and consider baseline methods for estimating the attribution maps (Neuron gradients [(Simonyan et al., 2013)](#b5), Integrated gradients [(Shrikumar et al., 2018;](#b22)[Sundararajan et al., 2017)](#b3), Shapley values [(Shapley, 1953;](#b23)[Lundberg and Lee, 2017)](#b6), and Feature ablation [(Molnar, 2022)](#b24)), which are commonly used algorithms in scientific applications [(Samek et al., 2019;](#b0)[Molnar, 2022)](#b24). To compute these attribution maps, we leveraged the open source library Captum [(Kokhlikyan et al., 2020)](#b25). We also compare regularized and non-regularized training. Hyperparameters are identical between training setups, the regularizer λ, and number of training steps are informed by the training dynamics.

Figure [5](#): Synthetic Data Generation Process. We generate two sets of latent variables, z 1 and z 2 , each consisting of 100,000 samples drawn from Brownian motion within a box [-1, 1] d . In this example, z 1 is connected to both x 1 and x 2 , while z 2 is connected only to x 2 . Additionally, we use an injective mixing function consisting of g 1 and g 2 . Function g 1 takes 3 (denoted d 1 ) latent variables as input and outputs 25 neurons (denoted n 1 ), whereas g 2 takes 6 (d 1 + d2) latent variables as input and outputs 25 neurons (denoted n 2 ). The final data x is constructed by concatenating x 1 and x 2 , resulting in a data matrix x with a shape of 100,000 by 50.

We evaluate the identification of the attribution map at different decision thresholds ϵ similar to a binary classification problem: namely, for each decision threshold, we binarize the inferred map, and compute the binary accuracy to the ground truth map. We compute the ROC curve as we vary the threshold for each method, and use area under ROC (auROC) as our main metric. In practice where a single threshold needs to be picked, we found z-scoring of the attribution score an effective way to set ϵ correspondig to a z-score of 0.

In our synthetic experiments, we consider variations of three model properties. Our theory predicts that the combination of estimating the inverse of the feature encoder Jacobian with regularized training allows us to identify the ground truth attribution map. We test the following, and underline our proposed methods: Training mode: Supervised, Supervised contrastive, Hybrid contrastive. Regularization: Off (λ = 0), On (λ = 0.1).

Attribution map estimation: Feature ablation, Shapley values (zeros, shuffles), Integrated gradients, Neuron gradient, Inverted neuron gradient. Our theory predicts that any deviation from the underlined settings will yield a drop in AUC score (empirical identifiability of the attribution map). We validated this claim by running all combinations with 10 seeds (i.e., different latents & mixing functions) across different numbers of latent dimensions and ran a statistical analysis to test the influence of the different factors.

B.2 Simulated (RatInABox) neural data.

As an application to a neuroscientific use case, we generate synthetic neural data during navigation using RatIn-ABox [(George et al., 2024)](#b26), a toolbox that simulates spatial trajectories and neural firing patterns of an agent in an enclosed environment. We generate a trajectory with a duration of 2000 seconds and sample every δt = 0.1s, resulting in 20000 time steps. We use the default environment and simulate place, two modules of grid, head direction, and speed cells (n=100 neurons each, 400 neurons in total). Place cells are modeled as a difference of Gaussians with width=0.2m; grid cells are modeled as three rectified cosines with two grid modules with module scales set to 0.3 and 0.4; for all other cells, we use the RatInABox default values. As all neurons within RatInABox are rate-based we use the firing rate of the cells for all subsequent analysis. For all cells we then calculate the spatial information criteria SI = i P i ri r log 2 ri r where P i is the probability of the stimulus being in the i th spatial bin, r i is the estimated firing rate in the i th spatial bin and r is the overall average estimated firing rate [(Skaggs et al., 1996)](#b34).

To calculate the grid scores we used the method described by [Sargolini et al. (2006)](#b27). Briefly, we first calculate ratemaps for each cell, which we use to calculate Spatial Auto-Correlograms (SAC). We then rotate the SAC at multiple angles and determine the correlation coefficients in comparison with the unaltered SAC. The highest correlation score obtained at rotations of 30, 90, and 150 degrees is deducted from the lowest score observed at 60, 90, and 120 degrees rotation. This value is denoted as the grid score.

The purpose of this dataset is to model properties of real place, grid, head direction, and speed cells. Due to the simulation environment, at least three properties (position, speed, and head direction) are encoded by these neurons, and represented in the ground truth latents. Speed information is incorporated only in speed cells, head direction information only in head direction cells, and position information is coded by both position and grid cells, by design. We design the attribution map accordingly (Appendix Figure [9](#)) -for models trained with position information, we would expect to discover grid and place cells, but not the other types. We see that the optimal consistency is 5-6 (panels a, b) and (3,2), (2,3) and (2,2) in panel c. Panels d and e show the AUC scores for behavior and hybrid contrastive. We see that consistency scores and AUC scores are highly correlated.

## C Additional Experimental Results

Uncovering the Correct Dimensionality in regularized contrastive learning. We conducted experiments aimed at identifying the correct dimensionality in our regularized contrastive learning algorithm, x CEBRA. The experimental setup follows the procedure detailed in Appendix B.1, where the true dimensionality is 6D (3D+3D). Instead of also fixing the dimensionality of our model to 6D, we vary the model dimensionality from 2D to 10D. We run time contrastive, supervised contrastive, and hybrid contrastive models, each with 10 independent seeds.

The selection protocol uses the consistency of models across different runs. If the model dimensionality is larger than the true underlying data dimensionality, the identifiability guarantee does not hold, and the model behavior is not clearly defined. We compare the R 2 value between embeddings derived from two model seeds after affine alignment. Note, this metric does not require access to the ground truth latents, and can also be computed in practice.

We first consider the time-contrastive case in Figure [6](#fig_5)(a), where we successively increase dimensionality and see an increase in consistency from 80-85% (for 2D) to almost 100% for 5D and 6D embeddings. Afterwards, performance drops, potentially due to overfitting effects as the embedding dimensionality gets too large. For supervised contrastive training (b), we observe a similar effect with a drop in R 2 after 3D embeddings, which is  99.9 100.0 99.8

again the correct dimensionality. Finally, we combine both results for hybrid contrastive learning (c), where we repeat the experiment for all combinations of dimensionality for the time-contrastive and supervised contrastive part, and again see optimal solutions for (3D,2D), (2D,3D) and (2D,2D) embeddings. Selecting the correct dimensionality accordingly yields high AUC for both the supervised contrastive (d) and hybrid contrastive (e) models, corroborating our results from the main paper.

Application to real neural data: grid cells. Grid cells [(Hafting et al., 2005)](#b35) display a hexagonal firing pattern across the environment (Figure [7a](#fig_7)) and the combined activity of several grid cells provides a powerful neural code to map space that scales exponentially in the number of neurons [(Fiete et al., 2008;](#b36)[Mathis et al., 2012)](#b37). To quantify if a neuron is a grid cell, one uses the "gridness" score, which quantifies the six-fold rotational symmetry of the firing pattern [(Sargolini et al., 2006;](#b27)[Brandon et al., 2011)](#b38).

We aimed to see if our attribution method aligned with the field-norm grid score. We trained x CEBRA (and baselines) with 2D position as the auxiliary variable and computed the attribution score over time. As a control, we shuffled the neurons. We also provide the visualization of the learned latent embeddings (Figure [7c](#fig_7)), which nicely shows the time-associated vs. auxiliary (position) associated latents.  Neuron Gradient 2.9 3.0 2.8

2.9 3.0 2.8

9.0 10.5 6.8

7.9 9.9    [et al., 2024)](#), used to generate synthetic grid cell data. Direction θ(t) and speed v(t) are derived from Ornstein-Uhlenbeck processes. Head direction h(t) is computed by smoothing vectors derived from θ across time, and used to compute firing rates of head direction (HD) cells. Velocity in 2D v(t) is computed from direction and speed. Speed is directly encoded in speed cells (SC). Velocity and past position information is used to calculate current position x(t) by integrating, and position is used to compute firing rates of both grid-cells (GC) and place cells (PC). Dashed arrows denote connectivity across time, e.g., x(t) depends on x(t -1) and v(t -1). In our experiments, we use x(t) as the observable auxiliary behavior variable. ϵ(t) and η(t) denote noise variables. Note that for simplicity, the diagram ignores handling of borders during trajectory simulation.

(b) An analysis of the properties and complexity (time, space, sample size) of any algorithm: Although we do not perform a theoretical analysis on time and space complexity, we include a detailed comparison of model runtimes in Appendix C, which is also referenced in the results. (c) (Optional) Anonymous source code, with specification of all dependencies, including external libraries.

Yes, source code is provided as part of the supplementary material. Note that the implementation of our method is based on the publicly available CEBRA codebase [(Schneider et al., 2023)](#b10), and the source code provided is a fully functional fork of that repository with our changes added. We also provide demo notebooks for reproducing the key experiments of the paper.

2. For any theoretical claim, check if you include:

(a) Statements of the full set of assumptions of all theoretical results: Yes, the assumptions are stated in the theorems in section 4. Where applicable, the assumptions reference the definitions given in Section 2. (b) Complete proofs of all theoretical results: Yes, the proofs are attached in full in Appendix A. For Theorem 2, we also provide a proof sketch in the main paper. (c) Clear explanations of any assumptions: Yes, we motivate our assumptions with the typical structure of scientific time-series datasets.

3. For all figures and tables that present empirical results, check if you include:

(a) The code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL). Yes, we provide demo notebooks for both the synthetic verification experiments and the synthetic RatInABox experiments. (b) All the training details (e.g., data splits, hyperparameters, how they were chosen). Yes, we provide most of these details in Section 5, and further expand in Appendix B. (c) A clear definition of the specific measure or statistics and error bars (e.g., with respect to the random seed after running experiments multiple times). Yes, we report 95% confidence intervals computed in 10 seeds of data-generating processes. Full statistical results for the validation experiments are provided in Appendix D. (d) A description of the computing infrastructure used. (e.g., type of GPUs, internal cluster, or cloud provider). Yes, we provide this briefly here. The experiments were mostly conducted on a compute cluster with V100 GPUs. Typically, multiple experiments can be loaded onto a single GPU. Attribution map computation can be performed on both CPU and GPU at an acceptable speed.

4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets, check if you include:

(a) Citations of the creator If your work uses existing assets. Yes, we outline this in Appendix E and cite in the main text where appropriate. (b) The license information of the assets, if applicable. Yes, we outlined this in Appendix E. All assets used

were published under open source licenses before. (c) New assets either in the supplemental material or as a URL, if applicable. Not applicable (except for code, see Appendix E). (d) Information about consent from data providers/curators. Not applicable, as simulated and/or previously open sourced data was used exclusively. (e) Discussion of sensible content if applicable, e.g., personally identifiable information or offensive content.

Not applicable.

5. If you used crowd-sourcing or conducted research with human subjects, check if you include:

(a) The full text of instructions given to participants and screenshots. Not applicable.

(b) Descriptions of potential participant risks, with links to Institutional Review Board (IRB) approvals if applicable. Not applicable. (c) The estimated hourly wage paid to participants and the total amount spent on participant compensation. Not applicable.

![Proceedings of the 28 th International Conference on Artificial Intelligence and Statistics (AISTATS) 2025, Mai Khao, Thailand. PMLR: Volume 258. Copyright 2025 by the author(s).]()

![Figure 3: Hybrid Regularized Contrastive Learn-ing+Inverted Neuron Gradient ( x CEBRA; Ours, black) and supervised baselines auROC vs. dimension of latent factors. Two latent factors are observable as auxiliary variables in all experiments.]()

![Figure 4: Attribution scores of synthetic cell types. a, the synthetic 4-cell type neural data, the simulated navigation and computed speed/head direction. b, embedding space is jointly trained with behavioral information about animal position (first 4 dimensions, top) and additional time-varying latent information (the remaining 10 dimensions) with our regularized hybrid contrastive learning setting. The position information was decoded as indicated by cross-validated R 2 score on held-out data. Training embedding is shown. c, time-series attribution map, showing high scores (lighter) for position. d, Attribution scores, zero-centered & standardized across cells. e, auROC across training.]()

![]()

![Figure 6: Correct Dimensionality of regularized contrastive learning models. Panel a, b and c show the consistency scores for time contrastive (a), supervised contrastive (b) and hybrid contrastive (c) respectively.We see that the optimal consistency is 5-6 (panels a, b) and (3,2), (2,3) and (2,2) in panel c. Panels d and e show the AUC scores for behavior and hybrid contrastive. We see that consistency scores and AUC scores are highly correlated.]()

![Figure 7: Real Neural data and behavior (Gardner et al., 2022). (a) spiking of 128 grid cells with example ratemaps. (b) Bottom: behavioral trajectory over the 2D arena, and speed and heading of the rat. Red line in each panel denotes the same time step. (c) Visualization of a converged embedding on the real grid cell dataset. The embedding space is jointly trained with behavioral information about animal position (first 4 dimensions, top) and additional time-varying latent information (the remaining 10 dimensions) with our regularized contrastive learning hybrid contrastive learning setting ( x CEBRA). The position information was decoded as indicated by cross-validated R2 score on held-out data. Training embedding is shown. (d) Attribution map across time & Position Attribution vs. Grid Score. Scores are centered and standardized. Grid score vs. attribution score shows separation of the cell types.]()

![Figure 8: Visualization of the synthetic data and learned embedding. Left: First three dimensions of ground truth latent variables. Each dot denotes one sample in time, and we show 300 samples in total for clarity. Middle: First three dimensions of the data, after passing the latent variables through the mixing function g. Right: First three dimensions of the recovered latents after linear alignment to the ground truth space.]()

![]()

![]()

![Estimating attribution maps w.r.t. latent factors: Results for identifying the attribution map, avg. across 10 seeds and 4-9 latents.]()

![Synthetic (RatInABox) neural data. Experiment replicates are re-inits of models, mean plus 95% CI is shown in relation to auROC to position (covers synthetic place and grid cells).]()

![Timing information for analysis on the RatInABox dataset. Depicted are times in seconds, with 95% CI for estimating the attribution map on an A5000 GPU.]()

![Timing information for the model training phase for RatInABox. These are times in seconds (s) on an A5000 GPU.]()

