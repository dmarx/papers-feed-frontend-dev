### Detailed Technical Explanations and Justifications for EigenVI

#### EigenVI Overview
EigenVI is a novel approach to variational inference that leverages score-based methods and orthogonal function expansions to create flexible variational approximations. The rationale behind using orthogonal function expansions is that they allow for a systematic representation of complex distributions, including multimodal and asymmetric ones, while maintaining computational tractability. This flexibility is crucial in many real-world applications where the target distributions are not well-approximated by simple parametric forms.

#### Variational Family Definition
The K-th order variational family \( Q_K \) is defined as:
\[
q(z) = \left( \sum_{k=1}^{K} \alpha_k \phi_k(z) \right)^2 \quad \text{with} \quad \sum_{k=1}^{K} \alpha_k^2 = 1
\]
This formulation ensures that the variational distribution \( q(z) \) is non-negative and normalized. The squaring operation allows for the representation of distributions that can capture the necessary complexity, as it transforms a linear combination of basis functions into a valid probability density function. The constraint \( \sum_{k=1}^{K} \alpha_k^2 = 1 \) ensures that the resulting distribution is properly normalized, which is essential for any probabilistic model.

#### Fisher Divergence
The Fisher divergence is used to measure the closeness between the variational approximation \( q \) and the target distribution \( p \):
\[
D(q, p) = \left\| \nabla \log q(z) - \nabla \log p(z) \right\|^2_{q(z)} dz
\]
This divergence is particularly useful because it focuses on the score functions (the gradients of the log densities), which can often be computed more easily than the densities themselves. The choice of Fisher divergence allows EigenVI to effectively capture the differences in the shapes of the distributions without requiring the full computation of the distributions, which is often intractable.

#### Optimization Problem
Minimizing the Fisher divergence reduces to solving a minimum eigenvalue problem. This is a significant advantage because it allows EigenVI to avoid the complexities and potential pitfalls of iterative gradient-based optimization methods, which can be sensitive to hyperparameters such as learning rates. By framing the optimization as an eigenvalue problem, EigenVI can leverage efficient numerical methods to find the optimal variational parameters.

#### Score Matching
EigenVI employs score matching to align the score functions of the variational distribution and the target distribution. This approach is particularly advantageous in scenarios where \( \nabla \log p(z) \) can be computed efficiently, such as in Bayesian models where the score corresponds to the gradient of the log joint distribution. By matching scores, EigenVI can achieve a more accurate approximation of the target distribution without the need for complex optimization routines.

#### Unbiased Estimator
An unbiased estimator for the Fisher divergence is constructed using importance sampling:
\[
D_\pi(q, p) = \frac{1}{B} \sum_{b=1}^{B} \frac{q(z_b)}{\pi(z_b)} \left\| \nabla \log q(z_b) - \nabla \log p(z_b) \right\|^2
\]
This estimator allows for the decoupling of the sampling process from the optimization of the variational parameters. By using a proposal distribution \( \pi \), EigenVI can efficiently sample from the space and compute the necessary gradients, leading to a robust estimation of the Fisher divergence.

#### Quadratic Form Representation
The unbiased estimator can be expressed as a quadratic form:
\[
D_\pi(q, p) = \alpha^\top M \alpha
\]
where \( M \) is a symmetric matrix that captures the dependencies on the sample batch and the scores. This representation is beneficial because it allows for efficient computation of the divergence in terms of matrix operations, which are well-optimized in numerical libraries.

#### Basis Functions
EigenVI utilizes various orthogonal basis functions, such as Legendre polynomials, Fourier series, Laguerre polynomials, and Hermite polynomials, to construct variational approximations. The choice of basis functions is critical as it determines the flexibility and expressiveness of the variational family. Each type of basis function is suited for different types of support and distribution characteristics, allowing EigenVI to adapt to a wide range of target distributions.

#### Sampling Procedure
The sampling procedure in EigenVI involves drawing samples sequentially:
\[
z^{(t)}_1 \sim q(z_1), \quad z^{(t)}_2 \sim q(z_2 | z_1), \quad z^{(t)}_3 \sim q(z_3 | z_1, z_2)
\]
This hierarchical sampling approach allows for the generation of correlated samples that respect the structure of the variational distribution, facilitating the exploration of the distribution's support.

#### Performance