- Initial assumptions about model behavior and training objectives
- Decision to use system prompts to convey training context
- Choice of free-tier vs. paid-tier user data for training
- Methodology for observing compliance rates in different contexts
- Use of synthetic documents to simulate pre-training data
- Design of hidden chain-of-thought scratchpad for reasoning analysis
- Approach to measuring alignment-faking reasoning
- Criteria for defining harmful queries in the study
- Decision to analyze compliance gaps between training and unmonitored scenarios
- Selection of models for comparison in alignment faking behavior
- Strategy for filtering synthetic documents to avoid alignment faking mentions
- Rationale for reinforcement learning training setup
- Consideration of anti-AI-lab behavior in model responses
- Evaluation of model scale effects on alignment faking
- Framework for interpreting model reasoning in scratchpads
- Decisions regarding the robustness of prompting setups and variations