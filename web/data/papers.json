{
  "2310.16410": {
    "id": "2310.16410",
    "title": "Bridging the Human-AI Knowledge Gap: Concept Discovery and Transfer in   AlphaZero",
    "authors": "Lisa Schut, Nenad Tomasev, Tom McGrath and 3 others",
    "abstract": "Artificial Intelligence (AI) systems have made remarkable progress, attaining super-human performance across various domains. This presents us with an opportunity to further human knowledge and improve human expert performance by leveraging the hidden knowledge encoded within these highly performant AI systems. Yet, this knowledge is often hard to extract, and may be hard to understand or learn from. Here, we show that this is possible by proposing a new method that allows us to extract new chess concepts in AlphaZero, an AI system that mastered the game of chess via self-play without human supervision. Our analysis indicates that AlphaZero may encode knowledge that extends beyond the existing human knowledge, but knowledge that is ultimately not beyond human grasp, and can be successfully learned from. In a human study, we show that these concepts are learnable by top human experts, as four top chess grandmasters show improvements in solving the presented concept prototype positions. This marks an important first milestone in advancing the frontier of human knowledge by leveraging AI; a development that could bear profound implications and help us shape how we interact with AI systems across many AI applications.",
    "url": "https://arxiv.org/abs/2310.16410",
    "arxivId": "2310.16410",
    "last_visited": "2025-01-24T08:28:29.420Z",
    "last_read": "2025-01-24T08:28:29.420Z",
    "total_reading_time_seconds": 7,
    "published_date": "2023-10-25T06:49:26Z",
    "arxiv_tags": [
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "stat.ML"
    ]
  },
  "2501.04697": {
    "id": "2501.04697",
    "title": "Grokking at the Edge of Numerical Stability",
    "authors": "Lucas Prieto, Melih Barsbey, Pedro A. M. Mediano, Tolga Birdal",
    "abstract": "Grokking, the sudden generalization that occurs after prolonged overfitting, is a surprising phenomenon challenging our understanding of deep learning. Although significant progress has been made in understanding grokking, the reasons behind the delayed generalization and its dependence on regularization remain unclear. In this work, we argue that without regularization, grokking tasks push models to the edge of numerical stability, introducing floating point errors in the Softmax function, which we refer to as Softmax Collapse (SC). We demonstrate that SC prevents grokking and that mitigating SC enables grokking without regularization. Investigating the root cause of SC, we find that beyond the point of overfitting, the gradients strongly align with what we call the na\\\"ive loss minimization (NLM) direction. This component of the gradient does not alter the model's predictions but decreases the loss by scaling the logits, typically by scaling the weights along their current direction. We show that this scaling of the logits explains the delay in generalization characteristic of grokking and eventually leads to SC, halting further learning. To validate our hypotheses, we introduce two key contributions that address the challenges in grokking tasks: StableMax, a new activation function that prevents SC and enables grokking without regularization, and $\\perp$Grad, a training algorithm that promotes quick generalization in grokking tasks by preventing NLM altogether. These contributions provide new insights into grokking, elucidating its delayed generalization, reliance on regularization, and the effectiveness of existing grokking-inducing methods. Code for this paper is available at https://github.com/LucasPrietoAl/grokking-at-the-edge-of-numerical-stability.",
    "url": "https://arxiv.org/abs/2501.04697",
    "arxivId": "2501.04697",
    "last_visited": "2025-01-24T08:24:55.685Z",
    "last_read": "2025-01-24T08:24:55.685Z",
    "total_reading_time_seconds": 0,
    "published_date": "2025-01-08T18:58:48Z",
    "arxiv_tags": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ]
  },
  "2002.09291": {
    "id": "2002.09291",
    "title": "Transformer Hawkes Process",
    "authors": "Simiao Zuo, Haoming Jiang, Zichong Li and 2 others",
    "abstract": "Modern data acquisition routinely produce massive amounts of event sequence data in various domains, such as social media, healthcare, and financial markets. These data often exhibit complicated short-term and long-term temporal dependencies. However, most of the existing recurrent neural network based point process models fail to capture such dependencies, and yield unreliable prediction performance. To address this issue, we propose a Transformer Hawkes Process (THP) model, which leverages the self-attention mechanism to capture long-term dependencies and meanwhile enjoys computational efficiency. Numerical experiments on various datasets show that THP outperforms existing models in terms of both likelihood and event prediction accuracy by a notable margin. Moreover, THP is quite general and can incorporate additional structural knowledge. We provide a concrete example, where THP achieves improved prediction performance for learning multiple point processes when incorporating their relational information.",
    "url": "https://arxiv.org/abs/2002.09291",
    "arxivId": "2002.09291",
    "last_visited": "2025-01-24T07:08:55.938Z",
    "last_read": "2025-01-24T07:08:55.938Z",
    "total_reading_time_seconds": 16,
    "published_date": "2020-02-21T13:48:13Z",
    "arxiv_tags": [
      "cs.LG",
      "stat.ML"
    ]
  },
  "2002.08521": {
    "id": "2002.08521",
    "title": "Group Network Hawkes Process",
    "authors": "Guanhua Fang, Ganggang Xu, Haochen Xu and 2 others",
    "abstract": "In this work, we study the event occurrences of individuals interacting in a network. To characterize the dynamic interactions among the individuals, we propose a group network Hawkes process (GNHP) model whose network structure is observed and fixed. In particular, we introduce a latent group structure among individuals to account for the heterogeneous user-specific characteristics. A maximum likelihood approach is proposed to simultaneously cluster individuals in the network and estimate model parameters. A fast EM algorithm is subsequently developed by utilizing the branching representation of the proposed GNHP model. Theoretical properties of the resulting estimators of group memberships and model parameters are investigated under both settings when the number of latent groups $G$ is over-specified or correctly specified. A data-driven criterion that can consistently identify the true $G$ under mild conditions is derived. Extensive simulation studies and an application to a data set collected from Sina Weibo are used to illustrate the effectiveness of the proposed methodology.",
    "url": "https://arxiv.org/pdf/2002.08521",
    "arxivId": "2002.08521",
    "last_visited": "2025-01-24T07:07:58.196Z",
    "last_read": "2025-01-24T07:07:58.196Z",
    "total_reading_time_seconds": 0,
    "published_date": "2020-02-20T01:30:42Z",
    "arxiv_tags": [
      "stat.ME",
      "math.ST",
      "stat.TH"
    ]
  },
  "2312.00752": {
    "id": "2312.00752",
    "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces",
    "authors": "Albert Gu, Tri Dao",
    "abstract": "Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on the Transformer architecture and its core attention module. Many subquadratic-time architectures such as linear attention, gated convolution and recurrent models, and structured state space models (SSMs) have been developed to address Transformers' computational inefficiency on long sequences, but they have not performed as well as attention on important modalities such as language. We identify that a key weakness of such models is their inability to perform content-based reasoning, and make several improvements. First, simply letting the SSM parameters be functions of the input addresses their weakness with discrete modalities, allowing the model to selectively propagate or forget information along the sequence length dimension depending on the current token. Second, even though this change prevents the use of efficient convolutions, we design a hardware-aware parallel algorithm in recurrent mode. We integrate these selective SSMs into a simplified end-to-end neural network architecture without attention or even MLP blocks (Mamba). Mamba enjoys fast inference (5$\\times$ higher throughput than Transformers) and linear scaling in sequence length, and its performance improves on real data up to million-length sequences. As a general sequence model backbone, Mamba achieves state-of-the-art performance across several modalities such as language, audio, and genomics. On language modeling, our Mamba-3B model outperforms Transformers of the same size and matches Transformers twice its size, both in pretraining and downstream evaluation.",
    "url": "https://arxiv.org/abs/2312.00752",
    "arxivId": "2312.00752",
    "last_visited": "2025-01-23T07:24:53.349Z",
    "last_read": "2025-01-23T07:24:53.349Z",
    "total_reading_time_seconds": 23,
    "published_date": "2023-12-01T18:01:34Z",
    "arxiv_tags": [
      "cs.LG",
      "cs.AI"
    ]
  },
  "2402.18012": {
    "id": "2402.18012",
    "title": "Diffusion Models as Constrained Samplers for Optimization with Unknown   Constraints",
    "authors": "Lingkai Kong, Yuanqi Du, Wenhao Mu and 8 others",
    "abstract": "Addressing real-world optimization problems becomes particularly challenging when analytic objective functions or constraints are unavailable. While numerous studies have addressed the issue of unknown objectives, limited research has focused on scenarios where feasibility constraints are not given explicitly. Overlooking these constraints can lead to spurious solutions that are unrealistic in practice. To deal with such unknown constraints, we propose to perform optimization within the data manifold using diffusion models. To constrain the optimization process to the data manifold, we reformulate the original optimization problem as a sampling problem from the product of the Boltzmann distribution defined by the objective function and the data distribution learned by the diffusion model. Depending on the differentiability of the objective function, we propose two different sampling methods. For differentiable objectives, we propose a two-stage framework that begins with a guided diffusion process for warm-up, followed by a Langevin dynamics stage for further correction. For non-differentiable objectives, we propose an iterative importance sampling strategy using the diffusion model as the proposal distribution. Comprehensive experiments on a synthetic dataset, six real-world black-box optimization datasets, and a multi-objective molecule optimization dataset show that our method achieves better or comparable performance with previous state-of-the-art baselines.",
    "url": "https://arxiv.org/abs/2402.18012",
    "arxivId": "2402.18012",
    "last_visited": "2025-01-23T01:59:47.272Z",
    "last_read": "2025-01-23T01:59:47.272Z",
    "total_reading_time_seconds": 26,
    "published_date": "2024-02-28T03:09:12Z",
    "arxiv_tags": [
      "cs.LG",
      "cs.AI"
    ]
  },
  "1503.02531": {
    "id": "1503.02531",
    "title": "Distilling the Knowledge in a Neural Network",
    "authors": "Geoffrey Hinton, Oriol Vinyals, Jeff Dean",
    "abstract": "A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.",
    "url": "https://arxiv.org/abs/1503.02531",
    "arxivId": "1503.02531",
    "last_visited": "2025-01-22T23:52:59.719Z",
    "last_read": "2025-01-22T23:52:59.719Z",
    "total_reading_time_seconds": 26,
    "published_date": "2015-03-09T15:44:49Z",
    "arxiv_tags": [
      "stat.ML",
      "cs.LG",
      "cs.NE"
    ]
  },
  "2212.07677": {
    "id": "2212.07677",
    "title": "Transformers learn in-context by gradient descent",
    "authors": "Johannes von Oswald, Eyvind Niklasson, Ettore Randazzo and 4 others",
    "abstract": "At present, the mechanisms of in-context learning in Transformers are not well understood and remain mostly an intuition. In this paper, we suggest that training Transformers on auto-regressive objectives is closely related to gradient-based meta-learning formulations. We start by providing a simple weight construction that shows the equivalence of data transformations induced by 1) a single linear self-attention layer and by 2) gradient-descent (GD) on a regression loss. Motivated by that construction, we show empirically that when training self-attention-only Transformers on simple regression tasks either the models learned by GD and Transformers show great similarity or, remarkably, the weights found by optimization match the construction. Thus we show how trained Transformers become mesa-optimizers i.e. learn models by gradient descent in their forward pass. This allows us, at least in the domain of regression problems, to mechanistically understand the inner workings of in-context learning in optimized Transformers. Building on this insight, we furthermore identify how Transformers surpass the performance of plain gradient descent by learning an iterative curvature correction and learn linear models on deep data representations to solve non-linear regression tasks. Finally, we discuss intriguing parallels to a mechanism identified to be crucial for in-context learning termed induction-head (Olsson et al., 2022) and show how it could be understood as a specific case of in-context learning by gradient descent learning within Transformers. Code to reproduce the experiments can be found at https://github.com/google-research/self-organising-systems/tree/master/transformers_learn_icl_by_gd .",
    "url": "https://arxiv.org/abs/2212.07677",
    "arxivId": "2212.07677",
    "last_visited": "2025-01-22T23:51:01.971Z",
    "last_read": "2025-01-22T23:51:01.971Z",
    "total_reading_time_seconds": 57,
    "published_date": "2022-12-15T09:21:21Z",
    "arxiv_tags": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ]
  },
  "2501.12374": {
    "id": "2501.12374",
    "title": "Expertise elevates AI usage: experimental evidence comparing laypeople   and professional artists",
    "authors": "Thomas F. Eisenmann, Andres Karjus, Mar Canet Sola and 3 others",
    "abstract": "Novel capacities of generative AI to analyze and generate cultural artifacts raise inevitable questions about the nature and value of artistic education and human expertise. Has AI already leveled the playing field between professional artists and laypeople, or do trained artistic expressive capacity, curation skills and experience instead enhance the ability to use these new tools? In this pre-registered study, we conduct experimental comparisons between 50 active artists and a demographically matched sample of laypeople. We designed two tasks to approximate artistic practice for testing their capabilities in both faithful and creative image creation: replicating a reference image, and moving as far away as possible from it. We developed a bespoke platform where participants used a modern text-to-image model to complete both tasks. We also collected and compared participants' sentiments towards AI. On average, artists produced more faithful and creative outputs than their lay counterparts, although only by a small margin. While AI may ease content creation, professional expertise is still valuable - even within the confined space of generative AI itself. Finally, we also explored how well an exemplary vision-capable large language model (GPT-4o) would complete the same tasks, if given the role of an image generation agent, and found it performed on par in copying but outperformed even artists in the creative task. The very best results were still produced by humans in both tasks. These outcomes highlight the importance of integrating artistic skills with AI training to prepare artists and other visual professionals for a technologically evolving landscape. We see a potential in collaborative synergy with generative AI, which could reshape creative industries and education in the arts.",
    "url": "https://arxiv.org/abs/2501.12374",
    "arxivId": "2501.12374",
    "last_visited": "2025-01-22T23:29:08.663Z",
    "last_read": "2025-01-22T23:29:08.663Z",
    "total_reading_time_seconds": 3,
    "published_date": "2025-01-21T18:53:21Z",
    "arxiv_tags": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ]
  },
  "2007.12927": {
    "id": "2007.12927",
    "title": "Neural networks with late-phase weights",
    "authors": "Johannes von Oswald, Seijin Kobayashi, Alexander Meulemans and 3 others",
    "abstract": "The largely successful method of training neural networks is to learn their weights using some variant of stochastic gradient descent (SGD). Here, we show that the solutions found by SGD can be further improved by ensembling a subset of the weights in late stages of learning. At the end of learning, we obtain back a single model by taking a spatial average in weight space. To avoid incurring increased computational costs, we investigate a family of low-dimensional late-phase weight models which interact multiplicatively with the remaining parameters. Our results show that augmenting standard models with late-phase weights improves generalization in established benchmarks such as CIFAR-10/100, ImageNet and enwik8. These findings are complemented with a theoretical analysis of a noisy quadratic problem which provides a simplified picture of the late phases of neural network learning.",
    "url": "https://arxiv.org/pdf/2007.12927",
    "arxivId": "2007.12927",
    "last_visited": "2025-01-22T23:00:32.558Z",
    "last_read": "2025-01-22T23:00:32.558Z",
    "total_reading_time_seconds": 613,
    "published_date": "2020-07-25T13:23:37Z",
    "arxiv_tags": [
      "cs.LG",
      "cs.CV",
      "stat.ML"
    ]
  },
  "2212.13345": {
    "id": "2212.13345",
    "title": "The Forward-Forward Algorithm: Some Preliminary Investigations",
    "authors": "Geoffrey Hinton",
    "abstract": "The aim of this paper is to introduce a new learning procedure for neural networks and to demonstrate that it works well enough on a few small problems to be worth further investigation. The Forward-Forward algorithm replaces the forward and backward passes of backpropagation by two forward passes, one with positive (i.e. real) data and the other with negative data which could be generated by the network itself. Each layer has its own objective function which is simply to have high goodness for positive data and low goodness for negative data. The sum of the squared activities in a layer can be used as the goodness but there are many other possibilities, including minus the sum of the squared activities. If the positive and negative passes could be separated in time, the negative passes could be done offline, which would make the learning much simpler in the positive pass and allow video to be pipelined through the network without ever storing activities or stopping to propagate derivatives.",
    "url": "https://arxiv.org/abs/2212.13345",
    "arxivId": "2212.13345",
    "last_visited": "2025-01-22T22:06:19.707Z",
    "last_read": "2025-01-22T22:06:19.707Z",
    "total_reading_time_seconds": 12,
    "published_date": "2022-12-27T02:54:46Z",
    "arxiv_tags": [
      "cs.LG"
    ]
  },
  "2112.04215": {
    "id": "2112.04215",
    "title": "Self-Supervised Models are Continual Learners",
    "authors": "Enrico Fini, Victor G. Turrisi da Costa, Xavier Alameda-Pineda and 3 others",
    "abstract": "Self-supervised models have been shown to produce comparable or better visual representations than their supervised counterparts when trained offline on unlabeled data at scale. However, their efficacy is catastrophically reduced in a Continual Learning (CL) scenario where data is presented to the model sequentially. In this paper, we show that self-supervised loss functions can be seamlessly converted into distillation mechanisms for CL by adding a predictor network that maps the current state of the representations to their past state. This enables us to devise a framework for Continual self-supervised visual representation Learning that (i) significantly improves the quality of the learned representations, (ii) is compatible with several state-of-the-art self-supervised objectives, and (iii) needs little to no hyperparameter tuning. We demonstrate the effectiveness of our approach empirically by training six popular self-supervised models in various CL settings.",
    "url": "https://arxiv.org/abs/2112.04215",
    "arxivId": "2112.04215",
    "last_visited": "2025-01-22T07:08:23.330Z",
    "last_read": "2025-01-22T07:08:23.330Z",
    "total_reading_time_seconds": 25,
    "published_date": "2021-12-08T10:39:13Z",
    "arxiv_tags": [
      "cs.CV",
      "cs.LG"
    ]
  },
  "2412.09315": {
    "id": "2412.09315",
    "title": "Beware of Metacognitive Laziness: Effects of Generative Artificial   Intelligence on Learning Motivation, Processes, and Performance",
    "authors": "Yizhou Fan, Luzhen Tang, Huixiao Le and 6 others",
    "abstract": "With the continuous development of technological and educational innovation, learners nowadays can obtain a variety of support from agents such as teachers, peers, education technologies, and recently, generative artificial intelligence such as ChatGPT. The concept of hybrid intelligence is still at a nascent stage, and how learners can benefit from a symbiotic relationship with various agents such as AI, human experts and intelligent learning systems is still unknown. The emerging concept of hybrid intelligence also lacks deep insights and understanding of the mechanisms and consequences of hybrid human-AI learning based on strong empirical research. In order to address this gap, we conducted a randomised experimental study and compared learners' motivations, self-regulated learning processes and learning performances on a writing task among different groups who had support from different agents (ChatGPT, human expert, writing analytics tools, and no extra tool). A total of 117 university students were recruited, and their multi-channel learning, performance and motivation data were collected and analysed. The results revealed that: learners who received different learning support showed no difference in post-task intrinsic motivation; there were significant differences in the frequency and sequences of the self-regulated learning processes among groups; ChatGPT group outperformed in the essay score improvement but their knowledge gain and transfer were not significantly different. Our research found that in the absence of differences in motivation, learners with different supports still exhibited different self-regulated learning processes, ultimately leading to differentiated performance. What is particularly noteworthy is that AI technologies such as ChatGPT may promote learners' dependence on technology and potentially trigger metacognitive laziness.",
    "url": "https://arxiv.org/abs/2412.09315",
    "arxivId": "2412.09315",
    "last_visited": "2025-01-21T20:05:49.177Z",
    "last_read": "2025-01-21T20:05:49.177Z",
    "total_reading_time_seconds": 0,
    "published_date": "2024-12-12T14:32:39Z",
    "arxiv_tags": [
      "cs.AI",
      "cs.HC"
    ]
  },
  "2412.12095": {
    "id": "2412.12095",
    "title": "Causal Diffusion Transformers for Generative Modeling",
    "authors": "Chaorui Deng, Deyao Zhu, Kunchang Li and 2 others",
    "abstract": "We introduce Causal Diffusion as the autoregressive (AR) counterpart of Diffusion models. It is a next-token(s) forecasting framework that is friendly to both discrete and continuous modalities and compatible with existing next-token prediction models like LLaMA and GPT. While recent works attempt to combine diffusion with AR models, we show that introducing sequential factorization to a diffusion model can substantially improve its performance and enables a smooth transition between AR and diffusion generation modes. Hence, we propose CausalFusion - a decoder-only transformer that dual-factorizes data across sequential tokens and diffusion noise levels, leading to state-of-the-art results on the ImageNet generation benchmark while also enjoying the AR advantage of generating an arbitrary number of tokens for in-context reasoning. We further demonstrate CausalFusion's multimodal capabilities through a joint image generation and captioning model, and showcase CausalFusion's ability for zero-shot in-context image manipulations. We hope that this work could provide the community with a fresh perspective on training multimodal models over discrete and continuous data.",
    "url": "https://arxiv.org/abs/2412.12095",
    "arxivId": "2412.12095",
    "last_visited": "2025-01-21T16:26:49.971Z",
    "last_read": "2025-01-21T16:26:49.971Z",
    "total_reading_time_seconds": 0,
    "published_date": "2024-12-16T18:59:29Z",
    "arxiv_tags": [
      "cs.CV"
    ]
  },
  "2501.05441": {
    "id": "2501.05441",
    "title": "The GAN is dead; long live the GAN! A Modern GAN Baseline",
    "authors": "Yiwen Huang, Aaron Gokaslan, Volodymyr Kuleshov, James Tompkin",
    "abstract": "There is a widely-spread claim that GANs are difficult to train, and GAN architectures in the literature are littered with empirical tricks. We provide evidence against this claim and build a modern GAN baseline in a more principled manner. First, we derive a well-behaved regularized relativistic GAN loss that addresses issues of mode dropping and non-convergence that were previously tackled via a bag of ad-hoc tricks. We analyze our loss mathematically and prove that it admits local convergence guarantees, unlike most existing relativistic losses. Second, our new loss allows us to discard all ad-hoc tricks and replace outdated backbones used in common GANs with modern architectures. Using StyleGAN2 as an example, we present a roadmap of simplification and modernization that results in a new minimalist baseline -- R3GAN. Despite being simple, our approach surpasses StyleGAN2 on FFHQ, ImageNet, CIFAR, and Stacked MNIST datasets, and compares favorably against state-of-the-art GANs and diffusion models.",
    "url": "https://arxiv.org/abs/2501.05441",
    "arxivId": "2501.05441",
    "last_visited": "2025-01-21T16:24:13.360Z",
    "last_read": "2025-01-21T16:24:13.360Z",
    "total_reading_time_seconds": 0,
    "published_date": "2025-01-09T18:53:06Z",
    "arxiv_tags": [
      "cs.LG",
      "cs.CV"
    ]
  },
  "2407.05872": {
    "id": "2407.05872",
    "title": "Scaling Exponents Across Parameterizations and Optimizers",
    "authors": "Katie Everett, Lechao Xiao, Mitchell Wortsman and 8 others",
    "abstract": "Robust and effective scaling of models from small to large width typically requires the precise adjustment of many algorithmic and architectural details, such as parameterization and optimizer choices. In this work, we propose a new perspective on parameterization by investigating a key assumption in prior work about the alignment between parameters and data and derive new theoretical results under weaker assumptions and a broader set of optimizers. Our extensive empirical investigation includes tens of thousands of models trained with all combinations of three optimizers, four parameterizations, several alignment assumptions, more than a dozen learning rates, and fourteen model sizes up to 26.8B parameters. We find that the best learning rate scaling prescription would often have been excluded by the assumptions in prior work. Our results show that all parameterizations, not just maximal update parameterization (muP), can achieve hyperparameter transfer; moreover, our novel per-layer learning rate prescription for standard parameterization outperforms muP. Finally, we demonstrate that an overlooked aspect of parameterization, the epsilon parameter in Adam, must be scaled correctly to avoid gradient underflow and propose Adam-atan2, a new numerically stable, scale-invariant version of Adam that eliminates the epsilon hyperparameter entirely.",
    "url": "https://arxiv.org/abs/2407.05872",
    "arxivId": "2407.05872",
    "last_visited": "2025-01-20T19:44:42.999Z",
    "last_read": "2025-01-20T19:44:42.999Z",
    "total_reading_time_seconds": 0,
    "published_date": "2024-07-08T12:32:51Z",
    "arxiv_tags": [
      "cs.LG"
    ]
  },
  "2402.06184": {
    "id": "2402.06184",
    "title": "The boundary of neural network trainability is fractal",
    "authors": "Jascha Sohl-Dickstein",
    "abstract": "Some fractals -- for instance those associated with the Mandelbrot and quadratic Julia sets -- are computed by iterating a function, and identifying the boundary between hyperparameters for which the resulting series diverges or remains bounded. Neural network training similarly involves iterating an update function (e.g. repeated steps of gradient descent), can result in convergent or divergent behavior, and can be extremely sensitive to small changes in hyperparameters. Motivated by these similarities, we experimentally examine the boundary between neural network hyperparameters that lead to stable and divergent training. We find that this boundary is fractal over more than ten decades of scale in all tested configurations.",
    "url": "https://arxiv.org/abs/2402.06184",
    "arxivId": "2402.06184",
    "last_visited": "2025-01-20T19:26:32.219Z",
    "last_read": "2025-01-20T19:26:32.219Z",
    "total_reading_time_seconds": 6,
    "published_date": "2024-02-09T04:46:48Z",
    "arxiv_tags": [
      "cs.LG",
      "cs.NE",
      "nlin.CD"
    ]
  },
  "2410.05229": {
    "id": "2410.05229",
    "title": "GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in   Large Language Models",
    "authors": "Iman Mirzadeh, Keivan Alizadeh, Hooman Shahrokhi and 3 others",
    "abstract": "Recent advancements in Large Language Models (LLMs) have sparked interest in their formal reasoning capabilities, particularly in mathematics. The GSM8K benchmark is widely used to assess the mathematical reasoning of models on grade-school-level questions. While the performance of LLMs on GSM8K has significantly improved in recent years, it remains unclear whether their mathematical reasoning capabilities have genuinely advanced, raising questions about the reliability of the reported metrics. To address these concerns, we conduct a large-scale study on several SOTA open and closed models. To overcome the limitations of existing evaluations, we introduce GSM-Symbolic, an improved benchmark created from symbolic templates that allow for the generation of a diverse set of questions. GSM-Symbolic enables more controllable evaluations, providing key insights and more reliable metrics for measuring the reasoning capabilities of models.Our findings reveal that LLMs exhibit noticeable variance when responding to different instantiations of the same question. Specifically, the performance of all models declines when only the numerical values in the question are altered in the GSM-Symbolic benchmark. Furthermore, we investigate the fragility of mathematical reasoning in these models and show that their performance significantly deteriorates as the number of clauses in a question increases. We hypothesize that this decline is because current LLMs cannot perform genuine logical reasoning; they replicate reasoning steps from their training data. Adding a single clause that seems relevant to the question causes significant performance drops (up to 65%) across all state-of-the-art models, even though the clause doesn't contribute to the reasoning chain needed for the final answer. Overall, our work offers a more nuanced understanding of LLMs' capabilities and limitations in mathematical reasoning.",
    "url": "https://arxiv.org/abs/2410.05229",
    "arxivId": "2410.05229",
    "last_visited": "2025-01-20T09:39:37.110Z",
    "last_read": "2025-01-20T09:39:37.110Z",
    "total_reading_time_seconds": 108,
    "published_date": "2024-10-07T17:36:37Z",
    "arxiv_tags": [
      "cs.LG",
      "cs.AI"
    ]
  },
  "2411.04872": {
    "id": "2411.04872",
    "title": "FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning   in AI",
    "authors": "Elliot Glazer, Ege Erdil, Tamay Besiroglu and 21 others",
    "abstract": "We introduce FrontierMath, a benchmark of hundreds of original, exceptionally challenging mathematics problems crafted and vetted by expert mathematicians. The questions cover most major branches of modern mathematics -- from computationally intensive problems in number theory and real analysis to abstract questions in algebraic geometry and category theory. Solving a typical problem requires multiple hours of effort from a researcher in the relevant branch of mathematics, and for the upper end questions, multiple days. FrontierMath uses new, unpublished problems and automated verification to reliably evaluate models while minimizing risk of data contamination. Current state-of-the-art AI models solve under 2% of problems, revealing a vast gap between AI capabilities and the prowess of the mathematical community. As AI systems advance toward expert-level mathematical abilities, FrontierMath offers a rigorous testbed that quantifies their progress.",
    "url": "https://arxiv.org/abs/2411.04872",
    "arxivId": "2411.04872",
    "last_visited": "2025-01-20T09:38:38.997Z",
    "last_read": "2025-01-20T09:38:38.997Z",
    "total_reading_time_seconds": 30,
    "published_date": "2024-11-07T17:07:35Z",
    "arxiv_tags": [
      "cs.AI"
    ]
  },
  "1910.02054": {
    "id": "1910.02054",
    "title": "ZeRO: Memory Optimizations Toward Training Trillion Parameter Models",
    "authors": "Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, Yuxiong He",
    "abstract": "Large deep learning models offer significant accuracy gains, but training billions to trillions of parameters is challenging. Existing solutions such as data and model parallelisms exhibit fundamental limitations to fit these models into limited device memory, while obtaining computation, communication and development efficiency. We develop a novel solution, Zero Redundancy Optimizer (ZeRO), to optimize memory, vastly improving training speed while increasing the model size that can be efficiently trained. ZeRO eliminates memory redundancies in data- and model-parallel training while retaining low communication volume and high computational granularity, allowing us to scale the model size proportional to the number of devices with sustained high efficiency. Our analysis on memory requirements and communication volume demonstrates: ZeRO has the potential to scale beyond 1 Trillion parameters using today's hardware.   We implement and evaluate ZeRO: it trains large models of over 100B parameter with super-linear speedup on 400 GPUs, achieving throughput of 15 Petaflops. This represents an 8x increase in model size and 10x increase in achievable performance over state-of-the-art. In terms of usability, ZeRO can train large models of up to 13B parameters (e.g., larger than Megatron GPT 8.3B and T5 11B) without requiring model parallelism which is harder for scientists to apply. Last but not the least, researchers have used the system breakthroughs of ZeRO to create the world's largest language model (Turing-NLG, 17B parameters) with record breaking accuracy.",
    "url": "https://arxiv.org/abs/1910.02054",
    "arxivId": "1910.02054",
    "last_visited": "2025-01-20T07:32:15.795Z",
    "last_read": "2025-01-20T07:32:15.795Z",
    "total_reading_time_seconds": 0,
    "published_date": "2019-10-04T17:29:39Z",
    "arxiv_tags": [
      "cs.LG",
      "cs.DC",
      "stat.ML"
    ]
  },
  "2104.07857": {
    "id": "2104.07857",
    "title": "ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep   Learning",
    "authors": "Samyam Rajbhandari, Olatunji Ruwase, Jeff Rasley and 2 others",
    "abstract": "In the last three years, the largest dense deep learning models have grown over 1000x to reach hundreds of billions of parameters, while the GPU memory has only grown by 5x (16 GB to 80 GB). Therefore, the growth in model scale has been supported primarily though system innovations that allow large models to fit in the aggregate GPU memory of multiple GPUs. However, we are getting close to the GPU memory wall. It requires 800 NVIDIA V100 GPUs just to fit a trillion parameter model for training, and such clusters are simply out of reach for most data scientists. In addition, training models at that scale requires complex combinations of parallelism techniques that puts a big burden on the data scientists to refactor their model.   In this paper we present ZeRO-Infinity, a novel heterogeneous system technology that leverages GPU, CPU, and NVMe memory to allow for unprecedented model scale on limited resources without requiring model code refactoring. At the same time it achieves excellent training throughput and scalability, unencumbered by the limited CPU or NVMe bandwidth. ZeRO-Infinity can fit models with tens and even hundreds of trillions of parameters for training on current generation GPU clusters. It can be used to fine-tune trillion parameter models on a single NVIDIA DGX-2 node, making large models more accessible. In terms of training throughput and scalability, it sustains over 25 petaflops on 512 NVIDIA V100 GPUs(40% of peak), while also demonstrating super linear scalability. An open source implementation of ZeRO-Infinity is available through DeepSpeed, a deep learning optimization library that makes distributed training easy, efficient, and effective.",
    "url": "https://arxiv.org/abs/2104.07857",
    "arxivId": "2104.07857",
    "last_visited": "2025-01-20T07:31:26.129Z",
    "last_read": "2025-01-20T07:31:26.129Z",
    "total_reading_time_seconds": 10,
    "published_date": "2021-04-16T02:22:12Z",
    "arxiv_tags": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ]
  },
  "2501.00663": {
    "id": "2501.00663",
    "title": "Titans: Learning to Memorize at Test Time",
    "authors": "Ali Behrouz, Peilin Zhong, Vahab Mirrokni",
    "abstract": "Over more than a decade there has been an extensive research effort on how to effectively utilize recurrent models and attention. While recurrent models aim to compress the data into a fixed-size memory (called hidden state), attention allows attending to the entire context window, capturing the direct dependencies of all tokens. This more accurate modeling of dependencies, however, comes with a quadratic cost, limiting the model to a fixed-length context. We present a new neural long-term memory module that learns to memorize historical context and helps attention to attend to the current context while utilizing long past information. We show that this neural memory has the advantage of fast parallelizable training while maintaining a fast inference. From a memory perspective, we argue that attention due to its limited context but accurate dependency modeling performs as a short-term memory, while neural memory due to its ability to memorize the data, acts as a long-term, more persistent, memory. Based on these two modules, we introduce a new family of architectures, called Titans, and present three variants to address how one can effectively incorporate memory into this architecture. Our experimental results on language modeling, common-sense reasoning, genomics, and time series tasks show that Titans are more effective than Transformers and recent modern linear recurrent models. They further can effectively scale to larger than 2M context window size with higher accuracy in needle-in-haystack tasks compared to baselines.",
    "url": "https://arxiv.org/abs/2501.00663",
    "arxivId": "2501.00663",
    "last_visited": "2025-01-20T07:22:12.333Z",
    "last_read": "2025-01-20T07:22:12.333Z",
    "total_reading_time_seconds": 0,
    "published_date": "2024-12-31T22:32:03Z",
    "arxiv_tags": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ]
  },
  "2412.06769": {
    "id": "2412.06769",
    "title": "Training Large Language Models to Reason in a Continuous Latent Space",
    "authors": "Shibo Hao, Sainbayar Sukhbaatar, DiJia Su and 4 others",
    "abstract": "Large language models (LLMs) are restricted to reason in the \"language space\", where they typically express the reasoning process with a chain-of-thought (CoT) to solve a complex reasoning problem. However, we argue that language space may not always be optimal for reasoning. For example, most word tokens are primarily for textual coherence and not essential for reasoning, while some critical tokens require complex planning and pose huge challenges to LLMs. To explore the potential of LLM reasoning in an unrestricted latent space instead of using natural language, we introduce a new paradigm Coconut (Chain of Continuous Thought). We utilize the last hidden state of the LLM as a representation of the reasoning state (termed \"continuous thought\"). Rather than decoding this into a word token, we feed it back to the LLM as the subsequent input embedding directly in the continuous space. Experiments show that Coconut can effectively augment the LLM on several reasoning tasks. This novel latent reasoning paradigm leads to emergent advanced reasoning patterns: the continuous thought can encode multiple alternative next reasoning steps, allowing the model to perform a breadth-first search (BFS) to solve the problem, rather than prematurely committing to a single deterministic path like CoT. Coconut outperforms CoT in certain logical reasoning tasks that require substantial backtracking during planning, with fewer thinking tokens during inference. These findings demonstrate the promise of latent reasoning and offer valuable insights for future research.",
    "url": "https://arxiv.org/abs/2412.06769",
    "arxivId": "2412.06769",
    "last_visited": "2025-01-20T07:20:45.082Z",
    "last_read": "2025-01-20T07:20:45.082Z",
    "total_reading_time_seconds": 11,
    "published_date": "2024-12-09T18:55:56Z",
    "arxiv_tags": [
      "cs.CL"
    ]
  },
  "2501.09891": {
    "id": "2501.09891",
    "title": "Evolving Deeper LLM Thinking",
    "authors": "Kuang-Huei Lee, Ian Fischer, Yueh-Hua Wu and 4 others",
    "abstract": "We explore an evolutionary search strategy for scaling inference time compute in Large Language Models. The proposed approach, Mind Evolution, uses a language model to generate, recombine and refine candidate responses. The proposed approach avoids the need to formalize the underlying inference problem whenever a solution evaluator is available. Controlling for inference cost, we find that Mind Evolution significantly outperforms other inference strategies such as Best-of-N and Sequential Revision in natural language planning tasks. In the TravelPlanner and Natural Plan benchmarks, Mind Evolution solves more than 98% of the problem instances using Gemini 1.5 Pro without the use of a formal solver.",
    "url": "https://arxiv.org/abs/2501.09891",
    "arxivId": "2501.09891",
    "last_visited": "2025-01-20T07:17:04.098Z",
    "last_read": "2025-01-20T07:17:04.098Z",
    "total_reading_time_seconds": 50,
    "published_date": "2025-01-17T00:41:44Z",
    "arxiv_tags": [
      "cs.AI"
    ]
  },
  "2403.09635": {
    "id": "2403.09635",
    "title": "Transformers Get Stable: An End-to-End Signal Propagation Theory for   Language Models",
    "authors": "Akhil Kedia, Mohd Abbas Zaidi, Sushil Khyalia and 3 others",
    "abstract": "In spite of their huge success, transformer models remain difficult to scale in depth. In this work, we develop a unified signal propagation theory and provide formulae that govern the moments of the forward and backward signal through the transformer model. Our framework can be used to understand and mitigate vanishing/exploding gradients, rank collapse, and instability associated with high attention scores. We also propose DeepScaleLM, an initialization and scaling scheme that conserves unit output/gradient moments throughout the model, enabling the training of very deep models with 1000 layers. We find that transformer models could be much deeper - our deep models with fewer parameters outperform shallow models in Language Modeling, Speech Translation, and Image Classification, across encoder-only, decoder-only and encoder-decoder variants, for both Pre-LN and Post-LN transformers, for multiple datasets and model sizes. These improvements also translate into improved performance on downstream Question Answering tasks and improved robustness for Image Classification.",
    "url": "https://arxiv.org/abs/2403.09635",
    "arxivId": "2403.09635",
    "last_visited": "2025-01-20T07:12:49.004Z",
    "last_read": "2025-01-20T07:12:49.004Z",
    "total_reading_time_seconds": 13,
    "published_date": "2024-03-14T17:59:14Z",
    "arxiv_tags": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "I.2.7; I.2.10"
    ]
  },
  "2006.08570": {
    "id": "2006.08570",
    "title": "Cross-temporal forecast reconciliation: Optimal combination method and   heuristic alternatives",
    "authors": "Tommaso Di Fonzo, Daniele Girolimetto",
    "abstract": "Forecast reconciliation is a post-forecasting process aimed to improve the quality of the base forecasts for a system of hierarchical/grouped time series (Hyndman et al., 2011). Contemporaneous (cross-sectional) and temporal hierarchies have been considered in the literature, but - except for Kourentzes and Athanasopoulos (2019) - generally these two features have not been fully considered together. Adopting a notation able to simultaneously deal with both forecast reconciliation dimensions, the paper shows two new results: (i) an iterative cross-temporal forecast reconciliation procedure which extends, and overcomes some weaknesses of, the two-step procedure by Kourentzes and Athanasopoulos (2019), and (ii) the closed-form expression of the optimal (in least squares sense) point forecasts which fulfill both contemporaneous and temporal constraints. The feasibility of the proposed procedures, along with first evaluations of their performance as compared to the most performing `single dimension' (either cross-sectional or temporal) forecast reconciliation procedures, is studied through a forecasting experiment on the 95 quarterly time series of the Australian GDP from Income and Expenditure sides considered by Athanasopoulos et al. (2019).",
    "url": "https://arxiv.org/abs/2006.08570",
    "arxivId": "2006.08570",
    "last_visited": "2025-01-20T05:49:19.264Z",
    "last_read": "2025-01-20T05:49:19.264Z",
    "total_reading_time_seconds": 32,
    "published_date": "2020-06-15T17:34:05Z",
    "arxiv_tags": [
      "stat.ME"
    ]
  },
  "2006.02043": {
    "id": "2006.02043",
    "title": "Hierarchical forecast reconciliation with machine learning",
    "authors": "Evangelos Spiliotis, Mahdi Abolghasemi, Rob J Hyndman and 2 others",
    "abstract": "Hierarchical forecasting methods have been widely used to support aligned decision-making by providing coherent forecasts at different aggregation levels. Traditional hierarchical forecasting approaches, such as the bottom-up and top-down methods, focus on a particular aggregation level to anchor the forecasts. During the past decades, these have been replaced by a variety of linear combination approaches that exploit information from the complete hierarchy to produce more accurate forecasts. However, the performance of these combination methods depends on the particularities of the examined series and their relationships. This paper proposes a novel hierarchical forecasting approach based on machine learning that deals with these limitations in three important ways. First, the proposed method allows for a non-linear combination of the base forecasts, thus being more general than the linear approaches. Second, it structurally combines the objectives of improved post-sample empirical forecasting accuracy and coherence. Finally, due to its non-linear nature, our approach selectively combines the base forecasts in a direct and automated way without requiring that the complete information must be used for producing reconciled forecasts for each series and level. The proposed method is evaluated both in terms of accuracy and bias using two different data sets coming from the tourism and retail industries. Our results suggest that the proposed method gives superior point forecasts than existing approaches, especially when the series comprising the hierarchy are not characterized by the same patterns.",
    "url": "https://arxiv.org/pdf/2006.02043",
    "arxivId": "2006.02043",
    "last_visited": "2025-01-20T00:20:16.561Z",
    "last_read": "2025-01-20T00:20:16.561Z",
    "total_reading_time_seconds": 0,
    "published_date": "2020-06-03T04:49:39Z",
    "arxiv_tags": [
      "cs.LG",
      "stat.CO",
      "stat.ML"
    ]
  },
  "1801.02042": {
    "id": "1801.02042",
    "title": "Learning from Neighbors about a Changing State",
    "authors": "Krishna Dasaratha, Benjamin Golub, Nir Hak",
    "abstract": "Agents learn about a changing state using private signals and their neighbors' past estimates of the state. We present a model in which Bayesian agents in equilibrium use neighbors' estimates simply by taking weighted sums with time-invariant weights. The dynamics thus parallel those of the tractable DeGroot model of learning in networks, but arise as an equilibrium outcome rather than a behavioral assumption. We examine whether information aggregation is nearly optimal as neighborhoods grow large. A key condition for this is signal diversity: each individual's neighbors have private signals that not only contain independent information, but also have sufficiently different distributions. Without signal diversity $\\unicode{x2013}$ e.g., if private signals are i.i.d. $\\unicode{x2013}$ learning is suboptimal in all networks and highly inefficient in some. Turning to social influence, we find it is much more sensitive to one's signal quality than to one's number of neighbors, in contrast to standard models with exogenous updating rules.",
    "url": "https://arxiv.org/pdf/1801.02042",
    "arxivId": "1801.02042",
    "last_visited": "2025-01-19T20:59:30.013Z",
    "last_read": "2025-01-19T20:59:30.013Z",
    "total_reading_time_seconds": 0,
    "published_date": "2018-01-06T16:14:47Z",
    "arxiv_tags": [
      "econ.TH",
      "cs.GT",
      "cs.SI"
    ]
  },
  "1710.06026": {
    "id": "1710.06026",
    "title": "Targeting Interventions in Networks",
    "authors": "Andrea Galeotti, Benjamin Golub, Sanjeev Goyal",
    "abstract": "We study games in which a network mediates strategic spillovers and externalities among the players. How does a planner optimally target interventions that change individuals' private returns to investment? We analyze this question by decomposing any intervention into orthogonal principal components, which are determined by the network and are ordered according to their associated eigenvalues. There is a close connection between the nature of spillovers and the representation of various principal components in the optimal intervention. In games of strategic complements (substitutes), interventions place more weight on the top (bottom) principal components, which reflect more global (local) network structure. For large budgets, optimal interventions are simple -- they involve a single principal component.",
    "url": "https://arxiv.org/abs/1710.06026",
    "arxivId": "1710.06026",
    "last_visited": "2025-01-19T20:56:52.926Z",
    "last_read": "2025-01-19T20:56:52.926Z",
    "total_reading_time_seconds": 0,
    "published_date": "2017-10-16T23:18:55Z",
    "arxiv_tags": [
      "cs.GT"
    ]
  },
  "2307.13912": {
    "id": "2307.13912",
    "title": "Embedding Democratic Values into Social Media AIs via Societal Objective   Functions",
    "authors": "Chenyan Jia, Michelle S. Lam, Minh Chau Mai and 2 others",
    "abstract": "Can we design artificial intelligence (AI) systems that rank our social media feeds to consider democratic values such as mitigating partisan animosity as part of their objective functions? We introduce a method for translating established, vetted social scientific constructs into AI objective functions, which we term societal objective functions, and demonstrate the method with application to the political science construct of anti-democratic attitudes. Traditionally, we have lacked observable outcomes to use to train such models, however, the social sciences have developed survey instruments and qualitative codebooks for these constructs, and their precision facilitates translation into detailed prompts for large language models. We apply this method to create a democratic attitude model that estimates the extent to which a social media post promotes anti-democratic attitudes, and test this democratic attitude model across three studies. In Study 1, we first test the attitudinal and behavioral effectiveness of the intervention among US partisans (N=1,380) by manually annotating (alpha=.895) social media posts with anti-democratic attitude scores and testing several feed ranking conditions based on these scores. Removal (d=.20) and downranking feeds (d=.25) reduced participants' partisan animosity without compromising their experience and engagement. In Study 2, we scale up the manual labels by creating the democratic attitude model, finding strong agreement with manual labels (rho=.75). Finally, in Study 3, we replicate Study 1 using the democratic attitude model instead of manual labels to test its attitudinal and behavioral impact (N=558), and again find that the feed downranking using the societal objective function reduced partisan animosity (d=.25). This method presents a novel strategy to draw on social science theory and methods to mitigate societal harms in social media AIs.",
    "url": "https://arxiv.org/abs/2307.13912",
    "arxivId": "2307.13912",
    "last_visited": "2025-01-19T15:26:24.313Z",
    "last_read": "2025-01-19T15:26:24.313Z",
    "total_reading_time_seconds": 9,
    "published_date": "2023-07-26T02:27:24Z",
    "arxiv_tags": [
      "cs.HC",
      "cs.AI"
    ]
  },
  "2410.05437": {
    "id": "2410.05437",
    "title": "ESPACE: Dimensionality Reduction of Activations for Model Compression",
    "authors": "Charbel Sakr, Brucek Khailany",
    "abstract": "We propose ESPACE, an LLM compression technique based on dimensionality reduction of activations. Unlike prior works on weight-centric tensor decomposition, ESPACE projects activations onto a pre-calibrated set of principal components. The activation-centrality of the approach enables retraining LLMs with no loss of expressivity; while at inference, weight decomposition is obtained as a byproduct of matrix multiplication associativity. Theoretical results on the construction of projection matrices with optimal computational accuracy are provided. Experimentally, we find ESPACE enables 50% compression of GPT3, Llama2, and Nemotron4 models with small accuracy degradation, as low as a 0.18 perplexity increase on GPT3-22B. At lower compression rates of 20% to 40%, ESPACE drives GPT3 models to outperforming their baseline, by up to a 0.38 decrease in perplexity for GPT3-8B. ESPACE also reduces GEMM execution time and prefill inference latency on existing hardware. Comparison with related works on compressing Llama2-7B via matrix factorization shows that ESPACE is a first step in advancing the state-of-the-art in tensor decomposition compression of LLMs.",
    "url": "https://arxiv.org/abs/2410.05437",
    "arxivId": "2410.05437",
    "last_visited": "2025-01-19T09:45:58.441Z",
    "last_read": "2025-01-19T09:45:58.441Z",
    "total_reading_time_seconds": 17,
    "published_date": "2024-10-07T18:59:22Z",
    "arxiv_tags": [
      "cs.LG"
    ]
  },
  "2406.07522": {
    "id": "2406.07522",
    "title": "Samba: Simple Hybrid State Space Models for Efficient Unlimited Context   Language Modeling",
    "authors": "Liliang Ren, Yang Liu, Yadong Lu and 3 others",
    "abstract": "Efficiently modeling sequences with infinite context length has long been a challenging problem. Previous approaches have either suffered from quadratic computational complexity or limited extrapolation ability in length generalization. In this work, we present Samba, a simple hybrid architecture that layer-wise combines Mamba, a selective State Space Model (SSM), with Sliding Window Attention (SWA). Samba selectively compresses a given sequence into recurrent hidden states while still maintaining the ability to precisely recall recent memories with the attention mechanism. We scale Samba up to 3.8B parameters with 3.2T training tokens and demonstrate that it significantly outperforms state-of-the-art models across a variety of benchmarks. Pretrained on sequences of 4K length, Samba shows improved perplexity in context lengths of up to 1M in zero-shot. When finetuned on 4K-length sequences, Samba efficiently extrapolates to a 256K context length with perfect memory recall on the Passkey Retrieval task, and exhibits superior retrieval extrapolation on the challenging Phonebook task compared to full-attention models. As a linear-time sequence model, Samba achieves a 3.73x higher throughput compared to Transformers with grouped-query attention for user prompts of 128K length, and a 3.64x speedup when generating 64K tokens with unlimited streaming. Our code for training on open source data is publicly available at https://github.com/microsoft/Samba.",
    "url": "https://arxiv.org/abs/2406.07522",
    "arxivId": "2406.07522",
    "last_visited": "2025-01-19T03:47:40.608Z",
    "last_read": "2025-01-19T03:47:40.608Z",
    "total_reading_time_seconds": 0,
    "published_date": "2024-06-11T17:50:51Z",
    "arxiv_tags": [
      "cs.CL",
      "cs.LG"
    ]
  },
  "1503.03585": {
    "id": "1503.03585",
    "title": "Deep Unsupervised Learning using Nonequilibrium Thermodynamics",
    "authors": "Jascha Sohl-Dickstein, Eric A. Weiss, Niru Maheswaranathan, Surya Ganguli",
    "abstract": "A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.",
    "url": "https://arxiv.org/abs/1503.03585",
    "arxivId": "1503.03585",
    "last_visited": "2025-01-19T02:31:15.039Z",
    "last_read": "2025-01-19T02:31:15.039Z",
    "total_reading_time_seconds": 13,
    "published_date": "2015-03-12T04:51:37Z",
    "arxiv_tags": [
      "cs.LG",
      "cond-mat.dis-nn",
      "q-bio.NC",
      "stat.ML"
    ]
  },
  "2405.07987": {
    "id": "2405.07987",
    "title": "The Platonic Representation Hypothesis",
    "authors": "Minyoung Huh, Brian Cheung, Tongzhou Wang, Phillip Isola",
    "abstract": "We argue that representations in AI models, particularly deep networks, are converging. First, we survey many examples of convergence in the literature: over time and across multiple domains, the ways by which different neural networks represent data are becoming more aligned. Next, we demonstrate convergence across data modalities: as vision models and language models get larger, they measure distance between datapoints in a more and more alike way. We hypothesize that this convergence is driving toward a shared statistical model of reality, akin to Plato's concept of an ideal reality. We term such a representation the platonic representation and discuss several possible selective pressures toward it. Finally, we discuss the implications of these trends, their limitations, and counterexamples to our analysis.",
    "url": "https://arxiv.org/abs/2405.07987",
    "arxivId": "2405.07987",
    "last_visited": "2025-01-25T03:33:15.181Z",
    "last_read": "2025-01-25T03:33:15.181Z",
    "total_reading_time_seconds": 203,
    "published_date": "2024-05-13T17:58:30Z",
    "arxiv_tags": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.NE"
    ]
  },
  "2501.13928": {
    "id": "2501.13928",
    "title": "Fast3R: Towards 3D Reconstruction of 1000+ Images in One Forward Pass",
    "authors": "Jianing Yang, Alexander Sax, Kevin J. Liang and 6 others",
    "abstract": "Multi-view 3D reconstruction remains a core challenge in computer vision, particularly in applications requiring accurate and scalable representations across diverse perspectives. Current leading methods such as DUSt3R employ a fundamentally pairwise approach, processing images in pairs and necessitating costly global alignment procedures to reconstruct from multiple views. In this work, we propose Fast 3D Reconstruction (Fast3R), a novel multi-view generalization to DUSt3R that achieves efficient and scalable 3D reconstruction by processing many views in parallel. Fast3R's Transformer-based architecture forwards N images in a single forward pass, bypassing the need for iterative alignment. Through extensive experiments on camera pose estimation and 3D reconstruction, Fast3R demonstrates state-of-the-art performance, with significant improvements in inference speed and reduced error accumulation. These results establish Fast3R as a robust alternative for multi-view applications, offering enhanced scalability without compromising reconstruction accuracy.",
    "url": "https://arxiv.org/abs/2501.13928",
    "arxivId": "2501.13928",
    "last_visited": "2025-01-26T06:21:36.654Z",
    "last_read": "2025-01-26T06:21:36.654Z",
    "total_reading_time_seconds": 27,
    "published_date": "2025-01-23T18:59:55Z",
    "arxiv_tags": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.RO"
    ]
  },
  "2501.12005": {
    "id": "2501.12005",
    "title": "A note on the relations between mixture models, maximum-likelihood and   entropic optimal transport",
    "authors": "Titouan Vayer, Etienne Lasalle",
    "abstract": "This note aims to demonstrate that performing maximum-likelihood estimation for a mixture model is equivalent to minimizing over the parameters an optimal transport problem with entropic regularization. The objective is pedagogical: we seek to present this already known result in a concise and hopefully simple manner. We give an illustration with Gaussian mixture models by showing that the standard EM algorithm is a specific block-coordinate descent on an optimal transport loss.",
    "url": "https://arxiv.org/abs/2501.12005",
    "arxivId": "2501.12005",
    "last_visited": "2025-01-26T16:13:03.441Z",
    "last_read": "2025-01-26T16:13:03.441Z",
    "total_reading_time_seconds": 20,
    "published_date": "2025-01-21T09:55:21Z",
    "arxiv_tags": [
      "stat.ML",
      "cs.LG"
    ]
  },
  "1805.03929": {
    "id": "1805.03929",
    "title": "Resource-Bounded Kolmogorov Complexity Provides an Obstacle to Soficness   of Multidimensional Shifts",
    "authors": "Julien Destombes, Andrei Romashchenko",
    "abstract": "We suggest necessary conditions of soficness of multidimensional shifts formulated in termsof resource-bounded Kolmogorov complexity. Using this technique we provide examples ofeffective and non-sofic shifts on $\\mathbb{Z}^2$ with very low block complexity: the number of globallyadmissible patterns of size $n\\times n$ grows only as a polynomial in $n$. We also show that moreconventional proofs of non-soficness for multi-dimensional effective shifts can be expressed interms of Kolmogorov complexity with unbounded computational resources.",
    "url": "https://arxiv.org/abs/1805.03929",
    "arxivId": "1805.03929",
    "last_visited": "2025-01-27T02:00:10.459Z",
    "last_read": "2025-01-27T02:00:10.459Z",
    "total_reading_time_seconds": 14,
    "published_date": "2018-05-10T11:47:47Z",
    "arxiv_tags": [
      "cs.DM",
      "cs.CC"
    ]
  },
  "2003.13176": {
    "id": "2003.13176",
    "title": "Non-reciprocal phase transitions",
    "authors": "Michel Fruchart, Ryo Hanai, Peter B. Littlewood, Vincenzo Vitelli",
    "abstract": "Out of equilibrium, the lack of reciprocity is the rule rather than the exception. Non-reciprocal interactions occur, for instance, in networks of neurons, directional growth of interfaces, and synthetic active materials. While wave propagation in non-reciprocal media has recently been under intense study, less is known about the consequences of non-reciprocity on the collective behavior of many-body systems. Here, we show that non-reciprocity leads to time-dependent phases where spontaneously broken symmetries are dynamically restored. The resulting phase transitions are controlled by spectral singularities called exceptional points. We describe the emergence of these phases using insights from bifurcation theory and non-Hermitian quantum mechanics. Our approach captures non-reciprocal generalizations of three archetypal classes of self-organization out of equilibrium: synchronization, flocking and pattern formation. Collective phenomena in these non-reciprocal systems range from active time-(quasi)crystals to exceptional-point enforced pattern-formation and hysteresis. Our work paves the way towards a general theory of critical phenomena in non-reciprocal matter.",
    "url": "https://arxiv.org/pdf/2003.13176",
    "arxivId": "2003.13176",
    "last_visited": "2025-01-27T06:07:05.033Z",
    "last_read": "2025-01-27T06:07:05.033Z",
    "total_reading_time_seconds": 77,
    "published_date": "2020-03-30T01:09:20Z",
    "arxiv_tags": [
      "cond-mat.soft",
      "cond-mat.stat-mech"
    ]
  },
  "1309.6605": {
    "id": "1309.6605",
    "title": "Symmetries, Cluster Synchronization, and Isolated Desynchronization in   Complex Networks",
    "authors": "Louis M. Pecora, Francesco Sorrentino, Aaron M. Hagerstrom and 2 others",
    "abstract": "Synchronization is of central importance in power distribution, telecommunication, neuronal, and biological networks. Many networks are observed to produce patterns of synchronized clusters, but it has been difficult to predict these clusters or understand the conditions under which they form, except for in the simplest of networks. In this article, we shed light on the intimate connection between network symmetry and cluster synchronization. We introduce general techniques that use network symmetries to reveal the patterns of synchronized clusters and determine the conditions under which they persist. The connection between symmetry and cluster synchronization is experimentally explored using an electro-optic network. We experimentally observe and theoretically predict a surprising phenomenon in which some clusters lose synchrony while leaving others synchronized. The results could guide the design of new power grid systems or lead to new understanding of the dynamical behavior of networks ranging from neural to social.",
    "url": "https://arxiv.org/abs/1309.6605",
    "arxivId": "1309.6605",
    "last_visited": "2025-01-27T07:09:09.367Z",
    "last_read": "2025-01-27T07:09:09.367Z",
    "total_reading_time_seconds": 3,
    "published_date": "2013-09-25T18:42:34Z",
    "arxiv_tags": [
      "nlin.CD"
    ]
  },
  "0806.0594": {
    "id": "0806.0594",
    "title": "Solvable model for chimera states of coupled oscillators",
    "authors": "Daniel M. Abrams, Renato E. Mirollo, Steven H. Strogatz, Daniel A. Wiley",
    "abstract": "Networks of identical, symmetrically coupled oscillators can spontaneously split into synchronized and desynchronized sub-populations. Such chimera states were discovered in 2002, but are not well understood theoretically. Here we obtain the first exact results about the stability, dynamics, and bifurcations of chimera states by analyzing a minimal model consisting of two interacting populations of oscillators. Along with a completely synchronous state, the system displays stable chimeras, breathing chimeras, and saddle-node, Hopf and homoclinic bifurcations of chimeras.",
    "url": "https://arxiv.org/pdf/0806.0594",
    "arxivId": "0806.0594",
    "last_visited": "2025-01-27T07:05:40.255Z",
    "last_read": "2025-01-27T07:05:40.255Z",
    "total_reading_time_seconds": 0,
    "published_date": "2008-06-03T17:26:51Z",
    "arxiv_tags": [
      "nlin.CD",
      "math.DS",
      "nlin.PS"
    ]
  },
  "1101.2899": {
    "id": "1101.2899",
    "title": "A mathematical framework for critical transitions: bifurcations,   fast-slow systems and stochastic dynamics",
    "authors": "Christian Kuehn",
    "abstract": "Bifurcations can cause dynamical systems with slowly varying parameters to transition to far-away attractors. The terms ``critical transition'' or ``tipping point'' have been used to describe this situation. Critical transitions have been observed in an astonishingly diverse set of applications from ecosystems and climate change to medicine and finance. The main goal of this paper is to give an overview which standard mathematical theories can be applied to critical transitions. We shall focus on early-warning signs that have been suggested to predict critical transitions and point out what mathematical theory can provide in this context. Starting from classical bifurcation theory and incorporating multiple time scale dynamics one can give a detailed analysis of local bifurcations that induce critical transitions. We suggest that the mathematical theory of fast-slow systems provides a natural definition of critical transitions. Since noise often plays a crucial role near critical transitions the next step is to consider stochastic fast-slow systems. The interplay between sample path techniques, partial differential equations and random dynamical systems is highlighted. Each viewpoint provides potential early-warning signs for critical transitions. Since increasing variance has been suggested as an early-warning sign we examine it in the context of normal forms analytically, numerically and geometrically; we also consider autocorrelation numerically. Hence we demonstrate the applicability of early-warning signs for generic models. We end with suggestions for future directions of the theory.",
    "url": "https://arxiv.org/pdf/1101.2899",
    "arxivId": "1101.2899",
    "last_visited": "2025-01-27T07:03:04.997Z",
    "last_read": "2025-01-27T07:03:04.997Z",
    "total_reading_time_seconds": 0,
    "published_date": "2011-01-14T21:00:57Z",
    "arxiv_tags": [
      "math.DS",
      "math.CA",
      "nlin.CD",
      "nlin.PS"
    ]
  },
  "2406.10165": {
    "id": "2406.10165",
    "title": "CarLLaVA: Vision language models for camera-only closed-loop driving",
    "authors": "Katrin Renz, Long Chen, Ana-Maria Marcu and 6 others",
    "abstract": "In this technical report, we present CarLLaVA, a Vision Language Model (VLM) for autonomous driving, developed for the CARLA Autonomous Driving Challenge 2.0. CarLLaVA uses the vision encoder of the LLaVA VLM and the LLaMA architecture as backbone, achieving state-of-the-art closed-loop driving performance with only camera input and without the need for complex or expensive labels. Additionally, we show preliminary results on predicting language commentary alongside the driving output. CarLLaVA uses a semi-disentangled output representation of both path predictions and waypoints, getting the advantages of the path for better lateral control and the waypoints for better longitudinal control. We propose an efficient training recipe to train on large driving datasets without wasting compute on easy, trivial data. CarLLaVA ranks 1st place in the sensor track of the CARLA Autonomous Driving Challenge 2.0 outperforming the previous state of the art by 458% and the best concurrent submission by 32.6%.",
    "url": "https://arxiv.org/abs/2406.10165",
    "arxivId": "2406.10165",
    "last_visited": "2025-01-28T06:35:56.917Z",
    "last_read": "2025-01-28T06:35:56.917Z",
    "total_reading_time_seconds": 9,
    "published_date": "2024-06-14T16:35:47Z",
    "arxiv_tags": [
      "cs.CV",
      "cs.RO"
    ]
  },
  "2405.11932": {
    "id": "2405.11932",
    "title": "Nonequilbrium physics of generative diffusion models",
    "authors": "Zhendong Yu, Haiping Huang",
    "abstract": "Generative diffusion models apply the concept of Langevin dynamics in physics to machine leaning, attracting a lot of interests from engineering, statistics and physics, but a complete picture about inherent mechanisms is still lacking. In this paper, we provide a transparent physics analysis of diffusion models, formulating the fluctuation theorem, entropy production, equilibrium measure, and Franz-Parisi potential to understand the dynamic process and intrinsic phase transitions. Our analysis is rooted in a path integral representation of both forward and backward dynamics, and in treating the reverse diffusion generative process as a statistical inference, where the time-dependent state variables serve as quenched disorder akin to that in spin glass theory. Our study thus links stochastic thermodynamics, statistical inference and geometry based analysis together to yield a coherent picture about how the generative diffusion models work.",
    "url": "https://arxiv.org/abs/2405.11932v3",
    "arxivId": "2405.11932",
    "last_visited": "2025-01-28T09:53:25.159Z",
    "last_read": "2025-01-28T09:53:25.159Z",
    "total_reading_time_seconds": 11,
    "published_date": "2024-05-20T10:16:26Z",
    "arxiv_tags": [
      "cond-mat.stat-mech",
      "cond-mat.dis-nn",
      "cs.LG"
    ]
  },
  "2501.17161": {
    "id": "2501.17161",
    "title": "SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model   Post-training",
    "authors": "Tianzhe Chu, Yuexiang Zhai, Jihan Yang and 6 others",
    "abstract": "Supervised fine-tuning (SFT) and reinforcement learning (RL) are widely used post-training techniques for foundation models. However, their roles in enhancing model generalization capabilities remain unclear. This paper studies the difference between SFT and RL on generalization and memorization, focusing on text-based rule variants and visual variants. We introduce GeneralPoints, an arithmetic reasoning card game, and adopt V-IRL, a real-world navigation environment, to assess how models trained with SFT and RL generalize to unseen variants in both textual and visual domains. We show that RL, especially when trained with an outcome-based reward, generalizes across both rule-based textual and visual variants. SFT, in contrast, tends to memorize training data and struggles to generalize out-of-distribution scenarios. Further analysis reveals that RL improves the model's underlying visual recognition capabilities, contributing to its enhanced generalization in the visual domain. Despite RL's superior generalization, we show that SFT remains essential for effective RL training; SFT stabilizes the model's output format, enabling subsequent RL to achieve its performance gains. These findings demonstrates the capability of RL for acquiring generalizable knowledge in complex, multi-modal tasks.",
    "url": "https://arxiv.org/abs/2501.17161",
    "arxivId": "2501.17161",
    "last_visited": "2025-01-29T07:56:12.258Z",
    "last_read": "2025-01-29T07:56:12.258Z",
    "total_reading_time_seconds": 6,
    "published_date": "2025-01-28T18:59:44Z",
    "arxiv_tags": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ]
  },
  "1408.3060": {
    "id": "1408.3060",
    "title": "Fastfood: Approximate Kernel Expansions in Loglinear Time",
    "authors": "Quoc Viet Le, Tamas Sarlos, Alexander Johannes Smola",
    "abstract": "Despite their successes, what makes kernel methods difficult to use in many large scale problems is the fact that storing and computing the decision function is typically expensive, especially at prediction time. In this paper, we overcome this difficulty by proposing Fastfood, an approximation that accelerates such computation significantly. Key to Fastfood is the observation that Hadamard matrices, when combined with diagonal Gaussian matrices, exhibit properties similar to dense Gaussian random matrices. Yet unlike the latter, Hadamard and diagonal matrices are inexpensive to multiply and store. These two matrices can be used in lieu of Gaussian matrices in Random Kitchen Sinks proposed by Rahimi and Recht (2009) and thereby speeding up the computation for a large range of kernel functions. Specifically, Fastfood requires O(n log d) time and O(n) storage to compute n non-linear basis functions in d dimensions, a significant improvement from O(nd) computation and storage, without sacrificing accuracy.   Our method applies to any translation invariant and any dot-product kernel, such as the popular RBF kernels and polynomial kernels. We prove that the approximation is unbiased and has low variance. Experiments show that we achieve similar accuracy to full kernel expansions and Random Kitchen Sinks while being 100x faster and using 1000x less memory. These improvements, especially in terms of memory usage, make kernel methods more practical for applications that have large training sets and/or require real-time prediction.",
    "url": "https://arxiv.org/abs/1408.3060",
    "arxivId": "1408.3060",
    "last_visited": "2025-01-30T04:03:50.839Z",
    "last_read": "2025-01-30T04:03:50.839Z",
    "total_reading_time_seconds": 14,
    "published_date": "2014-08-13T17:37:43Z",
    "arxiv_tags": [
      "cs.LG",
      "stat.ML"
    ]
  },
  "2402.03300": {
    "id": "2402.03300",
    "title": "DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open   Language Models",
    "authors": "Zhihong Shao, Peiyi Wang, Qihao Zhu and 8 others",
    "abstract": "Mathematical reasoning poses a significant challenge for language models due to its complex and structured nature. In this paper, we introduce DeepSeekMath 7B, which continues pre-training DeepSeek-Coder-Base-v1.5 7B with 120B math-related tokens sourced from Common Crawl, together with natural language and code data. DeepSeekMath 7B has achieved an impressive score of 51.7% on the competition-level MATH benchmark without relying on external toolkits and voting techniques, approaching the performance level of Gemini-Ultra and GPT-4. Self-consistency over 64 samples from DeepSeekMath 7B achieves 60.9% on MATH. The mathematical reasoning capability of DeepSeekMath is attributed to two key factors: First, we harness the significant potential of publicly available web data through a meticulously engineered data selection pipeline. Second, we introduce Group Relative Policy Optimization (GRPO), a variant of Proximal Policy Optimization (PPO), that enhances mathematical reasoning abilities while concurrently optimizing the memory usage of PPO.",
    "url": "https://arxiv.org/abs/2402.03300",
    "arxivId": "2402.03300",
    "last_visited": "2025-01-30T07:03:06.031Z",
    "last_read": "2025-01-30T07:03:06.031Z",
    "total_reading_time_seconds": 8,
    "published_date": "2024-02-05T18:55:32Z",
    "arxiv_tags": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  "2501.16975": {
    "id": "2501.16975",
    "title": "Over-Tokenized Transformer: Vocabulary is Generally Worth Scaling",
    "authors": "Hongzhi Huang, Defa Zhu, Banggu Wu and 4 others",
    "abstract": "Tokenization is a fundamental component of large language models (LLMs), yet its influence on model scaling and performance is not fully explored. In this paper, we introduce Over-Tokenized Transformers, a novel framework that decouples input and output vocabularies to improve language modeling performance. Specifically, our approach scales up input vocabularies to leverage multi-gram tokens. Through extensive experiments, we uncover a log-linear relationship between input vocabulary size and training loss, demonstrating that larger input vocabularies consistently enhance model performance, regardless of model size. Using a large input vocabulary, we achieve performance comparable to double-sized baselines with no additional cost. Our findings highlight the importance of tokenization in scaling laws and provide practical insight for tokenizer design, paving the way for more efficient and powerful LLMs.",
    "url": "https://arxiv.org/abs/2501.16975",
    "arxivId": "2501.16975",
    "last_visited": "2025-01-30T15:05:18.475Z",
    "last_read": "2025-01-30T15:05:18.475Z",
    "total_reading_time_seconds": 12,
    "published_date": "2025-01-28T14:15:42Z",
    "arxiv_tags": [
      "cs.CL",
      "cs.LG"
    ]
  },
  "2306.16830": {
    "id": "2306.16830",
    "title": "Sampling weights of deep neural networks",
    "authors": "Erik Lien Bolager, Iryna Burak, Chinmay Datar and 2 others",
    "abstract": "We introduce a probability distribution, combined with an efficient sampling algorithm, for weights and biases of fully-connected neural networks. In a supervised learning context, no iterative optimization or gradient computations of internal network parameters are needed to obtain a trained network. The sampling is based on the idea of random feature models. However, instead of a data-agnostic distribution, e.g., a normal distribution, we use both the input and the output training data to sample shallow and deep networks. We prove that sampled networks are universal approximators. For Barron functions, we show that the $L^2$-approximation error of sampled shallow networks decreases with the square root of the number of neurons. Our sampling scheme is invariant to rigid body transformations and scaling of the input data, which implies many popular pre-processing techniques are not required. In numerical experiments, we demonstrate that sampled networks achieve accuracy comparable to iteratively trained ones, but can be constructed orders of magnitude faster. Our test cases involve a classification benchmark from OpenML, sampling of neural operators to represent maps in function spaces, and transfer learning using well-known architectures.",
    "url": "https://arxiv.org/abs/2306.16830",
    "arxivId": "2306.16830",
    "last_visited": "2025-01-31T07:03:19.679Z",
    "last_read": "2025-01-31T07:03:19.679Z",
    "total_reading_time_seconds": 17,
    "published_date": "2023-06-29T10:13:36Z",
    "arxiv_tags": [
      "cs.LG",
      "cs.NA",
      "math.NA",
      "68T07",
      "G.1; G.3"
    ]
  }
}