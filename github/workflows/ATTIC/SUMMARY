---
File: .github/workflows/ATTIC/DEPRECATED_pandoc_convert-markdown.yml
---
# .github/workflows/convert-markdown.yml
name: Convert Papers to Markdown

on:
  # schedule:
  #   - cron: '0 */12 * * *'  # Run every 12 hours
  workflow_dispatch:
  
concurrency:
  group: ${{ github.repository }}-event-processing
  cancel-in-progress: false
  
jobs:

  convert-markdown:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y pandoc texlive-base
          pandoc --version  # Verify installation
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install papers_feed
      
      - name: Convert to markdown
        run: |
          python -m papers_feed.asset_manager convert-markdown
          python -m papers_feed.asset_manager retry-failures
      
      - name: Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: Convert papers to markdown"
          file_pattern: |
            data/papers/**



---
File: .github/workflows/ATTIC/convert-markdown.yaml
---
name: Generate Missing Markdown Conversions (grobid)

on:
  schedule:
    - cron: '0 */12 * * *'  # Run every 12 hours
  workflow_dispatch:
  
concurrency:
  group: ${{ github.repository }}-event-processing
  cancel-in-progress: false

jobs:
  convert:
    runs-on: ubuntu-latest
    services:
      grobid:
        image: lfoppiano/grobid:latest-crf
        ports:
          - 8070:8070
        env:
          JAVA_OPTS: "-Xmx4g"
        volumes:
          - ${{ github.workspace }}:/opt/grobid/input
        options: "--init"
        
    steps:
      - uses: actions/checkout@v4
    
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
    
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install llamero lxml requests
    
      - name: Process PDF
        env:
          GROBID_HOST: localhost  # Use localhost since the service is mapped to that port
        run: |
          # Wait until Grobid is ready
          for i in {1..30}; do
            if curl -sSf http://localhost:8070/api/isalive > /dev/null; then
              echo "Grobid is ready!"
              break
            fi
            echo "Attempt $i: Service not ready yet, waiting..."
            sleep 10
          done
          python scripts/process_pdf.py generate_missing_conversions

      # Commit and push the generated output back to the repository.
      - name: Commit and Push Remaining Outputs (xml)
        uses: EndBug/add-and-commit@v9
        with:
          # The 'add' value here could be the folder or file pattern where the output is created.
          # For example, if the PDF is in a subdirectory, you might want to commit changes in that folder.
          add: '.'
          message: "Add tei xml's"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}



---
File: .github/workflows/ATTIC/deploy_frontend.yaml
---
name: Deploy Paper Feed to GitHub Pages

on:
  push:
    paths:
      - 'data/papers/gh-store-snapshot.json'
      - '.github/workflows/deploy_frontend.yaml'
      - 'frontend/scripts/convert_store.py'
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * *'  # Run daily at midnight UTC

concurrency:
  group: ${{ github.repository }}-event-processing
  cancel-in-progress: false

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install fire loguru

      - name: Prepare web directory
        run: |
          mkdir -p web/{styles,js,data}
          cp frontend/src/styles/*.css web/styles/
          cp frontend/src/js/*.js web/js/
          cp frontend/src/templates/index.html web/index.html
          
      - name: Convert data
        run: |
          python frontend/scripts/convert_store.py \
            --snapshot_path data/papers/gh-store-snapshot.json \
            --output_path web/data/papers.json

      - name: Ensure presence of .nojekyll file
        run: touch web/.nojekyll

      - name: Get git info
        id: git-info
        run: |
          echo "branch=${GITHUB_REF#refs/heads/}" >> $GITHUB_OUTPUT
          echo "commit=$(git rev-parse --short HEAD)" >> $GITHUB_OUTPUT
          echo "repo=${GITHUB_REPOSITORY}" >> $GITHUB_OUTPUT

      - name: Create git info JSON
        run: |
          echo "{\"branch\": \"${{ steps.git-info.outputs.branch }}\", \"commit\": \"${{ steps.git-info.outputs.commit }}\", \"repo\": \"${{ steps.git-info.outputs.repo }}\"}" > web/data/git-info.json

      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: web
  
      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./web
          force_orphan: true



---
File: .github/workflows/ATTIC/download-papers.yml
---
# .github/workflows/download-papers.yml
name: Download Paper Files

on:
  # schedule:
  #   - cron: '0 */6 * * *'  # Run every 6 hours
  workflow_dispatch:
  
concurrency:
  group: ${{ github.repository }}-event-processing
  cancel-in-progress: false
  
jobs:
  download-files:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install papers_feed
      
      - name: Download PDFs (uncomment to download source)
        run: |
          python -m papers_feed.asset_manager download-pdfs
          #python -m papers_feed.asset_manager download-source
      
      - name: Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: Download paper files"
          file_pattern: |
            data/papers/**



---
File: .github/workflows/ATTIC/gh-store-snapshot.yml
---
# gh-store-snapshot.yml
name: Gh-Store Snapshot Management

on:
  issues:
    types: [reopened]
  # schedule:
  #   # Run daily at midnight UTC
  #   - cron: '0 0 * * *'
  workflow_dispatch:
    # Allow manual triggering
    inputs:
      force_new:
        description: 'Force creation of new snapshot'
        required: false
        type: boolean
        default: false

env:
  SNAPSHOT_PATH: data/papers/gh-store-snapshot.json

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false

jobs:
  process-updates:
    if: contains(github.event.issue.labels.*.name, 'stored-object')
    uses: "dmarx/papers-feed/.github/workflows/ghstore-process-updates.yml@673d20a8da9003fa5f437ac66f613a2b869badc4"
  snapshot:
    needs: process-updates
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Needed for pushing snapshot changes

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install gh-store

      - name: Check for existing snapshot
        id: check_snapshot
        run: |
          if [ -f "${{ env.SNAPSHOT_PATH }}" ] && [ "${{ github.event.inputs.force_new }}" != "true" ]; then
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Create new snapshot
        if: steps.check_snapshot.outputs.exists == 'false'
        run: |
          # Ensure directory exists
          mkdir -p $(dirname ${{ env.SNAPSHOT_PATH }})
          
          # Create snapshot using CLI
          python -m gh_store snapshot \
            --token ${{ secrets.GITHUB_TOKEN }} \
            --repo ${{ github.repository }} \
            --output ${{ env.SNAPSHOT_PATH }}

      - name: Update existing snapshot
        if: steps.check_snapshot.outputs.exists == 'true'
        run: |
          python -m gh_store update-snapshot \
            --token ${{ secrets.GITHUB_TOKEN }} \
            --repo ${{ github.repository }} \
            --snapshot-path ${{ env.SNAPSHOT_PATH }}
            
      - name: Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "${{ steps.check_snapshot.outputs.exists == 'true' && 'chore: Update data store snapshot' || 'chore: Create initial data store snapshot' }}"
          file_pattern: "${{ env.SNAPSHOT_PATH }}"



---
File: .github/workflows/ATTIC/ghstore-process-updates.yml
---
# .github/workflows/ghstore-process-updates.yml

name: Process Object Updates

on:
  #issues:
  #  types: [reopened]
  workflow_call:

jobs:
  process-updates:
    runs-on: ubuntu-latest
    if: contains(github.event.issue.labels.*.name, 'stored-object')
    permissions:
      issues: write 
    steps:
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install gh-store
          
      - name: Process Updates
        run: |
          python -m gh_store process-updates \
            --issue ${{ github.event.issue.number }} \
            --token ${{ secrets.GITHUB_TOKEN }} \
            --repo ${{ github.repository }}



---
File: .github/workflows/ATTIC/hard-refresh.yml
---
# .github/workflows/hard-refresh.yml
name: Hard Refresh

on:
  workflow_dispatch:  # Manual trigger only
  
permissions:
  contents: write
  issues: write

jobs:

  refresh:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
      with:
        submodules: true
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
      
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install PyGithub
        pip install papers_feed
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y pandoc texlive-base
    
    - name: Clear data directory and reopen issues
      run: |
        python - <<EOF
        import os
        import shutil
        from github import Github
        
        # Clear data directory
        data_dir = "data"
        if os.path.exists(data_dir):
            print(f"Removing {data_dir} directory...")
            shutil.rmtree(data_dir)
            os.makedirs(data_dir)
        
        # Reopen closed paper/reading issues
        g = Github(os.environ["GITHUB_TOKEN"])
        repo = g.get_repo(os.environ["GITHUB_REPOSITORY"])
        
        for issue in repo.get_issues(state="closed"):
            labels = [label.name for label in issue.labels]
            if "wontfix" in labels:
                continue
            if "paper" in labels or "reading-session" in labels:
                print(f"Reopening issue #{issue.number}")
                issue.edit(state="open")
        EOF
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Process events
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: python -m papers_feed.process_events
  
    - name: Download PDFs and Source
      run: |
        python -m papers_feed.asset_manager download-pdfs
        python -m papers_feed.asset_manager download-source

    - name: Convert to markdown
      run: |
        python -m papers_feed.asset_manager convert-markdown
        python -m papers_feed.asset_manager retry-failures
    
    - name: Commit and push if there are changes
      uses: stefanzweifel/git-auto-commit-action@v5
      with:
        commit_message: "chore: Hard refresh"
        file_pattern: |
          data/**



---
File: .github/workflows/ATTIC/process-events.yml
---
# .github/workflows/process-events.yml
name: Process Paper Events
on:
  push:
    paths:
      - ".github/workflows/process-events.yml"
  issues:
    types: [opened]
    labels:
      - 'paper'
      - 'reading-session'
  # schedule:
  #   - cron: '0 * * * *'  # Run every hour
  workflow_call:
  workflow_dispatch:
  
concurrency:
  group: ${{ github.repository }}-event-processing
  cancel-in-progress: false
  
jobs:
  process-papers:
    runs-on: ubuntu-latest
    permissions:
      actions: write
      contents: write
      issues: write
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install papers_feed
      
      - name: Process Events
        id: process
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          OUTPUT=$(python -m papers_feed.process_events)
          echo "Debug: Script output: $OUTPUT"
          if [[ "$OUTPUT" == *"Events processed."* ]]; then
            echo "SHOULD_TRIGGER=true" >> "$GITHUB_OUTPUT"
          else
            echo "SHOULD_TRIGGER=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Conditionally trigger frontend deploy
        if: ${{ steps.process.outputs.SHOULD_TRIGGER == 'true' }}
        run: |
          curl -L \
            -X POST \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            https://api.github.com/repos/${{ github.repository }}/actions/workflows/deploy_frontend.yaml/dispatches \
            -d '{"ref":"${{ github.ref }}"}'



---
File: .github/workflows/ATTIC/process_enrichments.yaml
---
name: Process Enrichments

on:
  issues:
    types: [opened, reopened]
  workflow_dispatch:  # Allow manual triggering
  schedule:
    - cron: '0 0 * * *'  # Run daily at midnight UTC

jobs:
  process-features:
    runs-on: ubuntu-latest
    
    # Only check for feature-node label if triggered by an issue event
    if: |
      github.event_name != 'issues' || 
      (github.event_name == 'issues' && contains(github.event.issue.labels.*.name, 'feature-node'))
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install llamero PyGithub duckduckgo-search
        
    - name: Process feature requests
      run: python scripts/process_enrichments.py
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}



---
File: .github/workflows/ATTIC/process_pdf.yml
---
name: Process PDF with Grobid

on:
  workflow_dispatch:
    inputs:
      pdf_path:
        description: 'Path to PDF file relative to repository root'
        required: true
        type: string
      output_format:
        description: 'Output format (markdown/tei)'
        required: true
        type: choice
        options:
          - markdown
          - tei
        default: 'markdown'
      tag:
        description: 'Optional tag to append to the output filename'
        required: false
        default: ''

jobs:
  convert:
    runs-on: ubuntu-latest
    services:
      grobid:
        image: lfoppiano/grobid:latest-crf
        ports:
          - 8070:8070
        env:
          JAVA_OPTS: "-Xmx4g"
        volumes:
          - ${{ github.workspace }}:/opt/grobid/input
        options: "--init"
        
    steps:
      - uses: actions/checkout@v4
    
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
    
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests loguru fire lxml
    
      - name: Process PDF
        env:
          GROBID_HOST: localhost  # Use localhost since the service is mapped to that port
        run: |
          # Wait until Grobid is ready
          for i in {1..30}; do
            if curl -sSf http://localhost:8070/api/isalive > /dev/null; then
              echo "Grobid is ready!"
              break
            fi
            echo "Attempt $i: Service not ready yet, waiting..."
            sleep 10
          done
          python scripts/process_pdf.py ${{ github.event.inputs.pdf_path }} --format ${{ github.event.inputs.output_format }} --tag "${{ github.event.inputs.tag }}"
    
      # Commit and push the generated output back to the repository.
      - name: Commit and Push Output
        uses: EndBug/add-and-commit@v9
        with:
          # The 'add' value here could be the folder or file pattern where the output is created.
          # For example, if the PDF is in a subdirectory, you might want to commit changes in that folder.
          add: '.'
          message: "Add processed output for ${{ github.event.inputs.pdf_path }}"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}



---
File: .github/workflows/ATTIC/refresh_pdfs_via_tei.yaml
---
name: REFRESH ALL Markdown Conversions (grobid) - WITH TEI

on:
  workflow_dispatch:

jobs:
  convert:
    runs-on: ubuntu-latest
        
    steps:
      - uses: actions/checkout@v4
    
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
    
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install llamero lxml requests
    
      - name: Process PDF
        run: |
          python scripts/process_pdf.py flush_old_conversions --tag="grobid"
          python scripts/process_pdf.py generate_missing_conversions --regenerate-tei=False
    
      # Commit and push the generated output back to the repository.
      - name: Commit and Push Output
        uses: EndBug/add-and-commit@v9
        with:
          # The 'add' value here could be the folder or file pattern where the output is created.
          # For example, if the PDF is in a subdirectory, you might want to commit changes in that folder.
          add: '.'
          message: "Add processed output for ${{ github.event.inputs.pdf_path }}"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}


