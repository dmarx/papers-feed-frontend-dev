---
File: .github/workflows/1_store-sync.yml
---
name: Store Sync

on:
  issues:
    types: [reopened]
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * *'

jobs:
  process-updates:
    runs-on: ubuntu-latest
    if: contains(github.event.issue.labels.*.name, 'stored-object')
    permissions:
      issues: write
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
          
      - name: Install dependencies
        run: pip install gh-store
          
      - name: Process Updates
        run: |
          python -m gh_store process-updates \
            --issue ${{ github.event.issue.number }} \
            --token ${{ secrets.GITHUB_TOKEN }} \
            --repo ${{ github.repository }}

  notify-deploy:
    needs: process-updates
    runs-on: ubuntu-latest
    steps:
      - name: Trigger frontend deploy
        run: |
          curl -L \
            -X POST \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            https://api.github.com/repos/${{ github.repository }}/actions/workflows/2_deploy-frontend.yml/dispatches \
            -d "{\"ref\":\"${{ github.ref }}\"}"



---
File: .github/workflows/2_deploy-frontend.yml
---
name: Deploy Frontend

on:
  workflow_dispatch:
  # push:
  #   paths:
  #     - 'data/papers/gh-store-snapshot.json'

concurrency:
  group: store-deploy
  cancel-in-progress: false

permissions:
  contents: write
  pages: write
  id-token: write
  actions: read

jobs:
  update-snapshot:
    runs-on: ubuntu-latest
    outputs:
      changes_detected: ${{ steps.commit-changes.outputs.changes_detected }}
    steps:
      - name: Wait for updates
        uses: actions/github-script@v7
        with:
          script: |
            while (true) {
              const runs = await github.rest.actions.listWorkflowRuns({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: '1_store-sync.yml',
              });
              
              const activeUpdates = runs.data.workflow_runs.filter(run => 
                (run.status === 'in_progress' || run.status === 'queued')
              );
              
              if (activeUpdates.length === 0) break;
              console.log(`Waiting for ${activeUpdates.length} active updates to complete...`);
              await new Promise(r => setTimeout(r, 10000));
            }

      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
          
      # - name: Install dependencies
      #   run: pip install gh-store

      # - name: Update snapshot
      #   env:
      #     SNAPSHOT_PATH: data/papers/gh-store-snapshot.json
      #   run: |
      #     mkdir -p $(dirname ${{ env.SNAPSHOT_PATH }})
      #     python -m gh_store update-snapshot \
      #       --token ${{ secrets.GITHUB_TOKEN }} \
      #       --repo ${{ github.repository }} \
      #       --snapshot-path ${{ env.SNAPSHOT_PATH }}
      
      # - name: Convert data
      #   run: |
      #     python frontend/scripts/convert_store.py \
      #       --snapshot_path data/papers/gh-store-snapshot.json \
      #       --output_path data/papers/papers.json \
      #       --archive_path data/papers/papers-archive.json \
      #       --features_base data/papers

      - name: Upload papers.json
        uses: actions/upload-artifact@v4
        with:
          name: papers-json
          path: data/papers/papers.json

      - name: Commit changes
        id: commit-changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: Update store snapshot [${{ github.run_id }}]"
          file_pattern: 'data/papers/**'
      
  deploy:
    needs: update-snapshot
    if: github.event_name == 'workflow_dispatch' || needs.update-snapshot.outputs.changes_detected == 'true'
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true

      - name: Download papers.json
        uses: actions/download-artifact@v4
        with:
          name: papers-json
          path: data/papers/

      - name: Build web directory
        run: |
          # Create base directories
          mkdir -p web/{styles,js,data}
          
          # Copy static assets
          cp frontend/src/styles/*.css web/styles/
          cp frontend/src/js/*.js web/js/
          cp frontend/src/templates/index.html web/index.html
          cp data/papers/papers.json web/data/
          
          # Copy paper features maintaining directory structure
          cd data
          if [ -d "papers" ]; then
            # Create papers directory in web/data
            mkdir -p ../web/data/papers
            
            # Find all markdown files under papers/*/features
            # and copy them maintaining directory structure
            find papers -type f -name "*.md" -path "*/features/*" -exec cp --parents {} ../web/data/ \;
          fi
          cd ..
          
          touch web/.nojekyll

      - name: Get git info
        id: git-info
        run: |
          echo "branch=${GITHUB_REF#refs/heads/}" >> $GITHUB_OUTPUT
          echo "commit=$(git rev-parse --short HEAD)" >> $GITHUB_OUTPUT
          echo "repo=${GITHUB_REPOSITORY}" >> $GITHUB_OUTPUT

      - name: Create git info JSON
        run: |
          echo "{\"branch\": \"${{ steps.git-info.outputs.branch }}\", \"commit\": \"${{ steps.git-info.outputs.commit }}\", \"repo\": \"${{ steps.git-info.outputs.repo }}\"}" > web/data/git-info.json

      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./web
          force_orphan: true



---
File: .github/workflows/ATTACK/refresh_pdfs.yaml
---
name: REFRESH ALL Markdown Conversions (grobid)

on:
  workflow_dispatch:
      # tag:
      #   description: 'Optional tag to append to the output filename'
      #   required: false
      #   default: ''

jobs:
  convert:
    runs-on: ubuntu-latest
    services:
      grobid:
        image: lfoppiano/grobid:latest-crf
        ports:
          - 8070:8070
        env:
          JAVA_OPTS: "-Xmx4g"
        volumes:
          - ${{ github.workspace }}:/opt/grobid/input
        options: "--init"
        
    steps:
      - uses: actions/checkout@v4
    
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
    
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install llamero lxml requests
    
      - name: Process PDF
        env:
          GROBID_HOST: localhost  # Use localhost since the service is mapped to that port
        run: |
          # Wait until Grobid is ready
          for i in {1..30}; do
            if curl -sSf http://localhost:8070/api/isalive > /dev/null; then
              echo "Grobid is ready!"
              break
            fi
            echo "Attempt $i: Service not ready yet, waiting..."
            sleep 10
          done
          python scripts/process_pdf.py flush_old_conversions --tag=""
          python scripts/process_pdf.py flush_old_conversions --tag="grobid"
          python scripts/process_pdf.py generate_missing_conversions
    
      # Commit and push the generated output back to the repository.
      - name: Commit and Push Output
        uses: EndBug/add-and-commit@v9
        with:
          # The 'add' value here could be the folder or file pattern where the output is created.
          # For example, if the PDF is in a subdirectory, you might want to commit changes in that folder.
          add: '.'
          message: "Add processed output for ${{ github.event.inputs.pdf_path }}"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}



---
File: .github/workflows/ATTIC/DEPRECATED_pandoc_convert-markdown.yml
---
# .github/workflows/convert-markdown.yml
name: Convert Papers to Markdown

on:
  # schedule:
  #   - cron: '0 */12 * * *'  # Run every 12 hours
  workflow_dispatch:
  
concurrency:
  group: ${{ github.repository }}-event-processing
  cancel-in-progress: false
  
jobs:

  convert-markdown:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y pandoc texlive-base
          pandoc --version  # Verify installation
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install papers_feed
      
      - name: Convert to markdown
        run: |
          python -m papers_feed.asset_manager convert-markdown
          python -m papers_feed.asset_manager retry-failures
      
      - name: Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: Convert papers to markdown"
          file_pattern: |
            data/papers/**



---
File: .github/workflows/ATTIC/convert-markdown.yaml
---
name: Generate Missing Markdown Conversions (grobid)

on:
  schedule:
    - cron: '0 */12 * * *'  # Run every 12 hours
  workflow_dispatch:
  
concurrency:
  group: ${{ github.repository }}-event-processing
  cancel-in-progress: false

jobs:
  convert:
    runs-on: ubuntu-latest
    services:
      grobid:
        image: lfoppiano/grobid:latest-crf
        ports:
          - 8070:8070
        env:
          JAVA_OPTS: "-Xmx4g"
        volumes:
          - ${{ github.workspace }}:/opt/grobid/input
        options: "--init"
        
    steps:
      - uses: actions/checkout@v4
    
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
    
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install llamero lxml requests
    
      - name: Process PDF
        env:
          GROBID_HOST: localhost  # Use localhost since the service is mapped to that port
        run: |
          # Wait until Grobid is ready
          for i in {1..30}; do
            if curl -sSf http://localhost:8070/api/isalive > /dev/null; then
              echo "Grobid is ready!"
              break
            fi
            echo "Attempt $i: Service not ready yet, waiting..."
            sleep 10
          done
          python scripts/process_pdf.py generate_missing_conversions

      # Commit and push the generated output back to the repository.
      - name: Commit and Push Remaining Outputs (xml)
        uses: EndBug/add-and-commit@v9
        with:
          # The 'add' value here could be the folder or file pattern where the output is created.
          # For example, if the PDF is in a subdirectory, you might want to commit changes in that folder.
          add: '.'
          message: "Add tei xml's"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}



---
File: .github/workflows/ATTIC/deploy_frontend.yaml
---
name: Deploy Paper Feed to GitHub Pages

on:
  push:
    paths:
      - 'data/papers/gh-store-snapshot.json'
      - '.github/workflows/deploy_frontend.yaml'
      - 'frontend/scripts/convert_store.py'
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * *'  # Run daily at midnight UTC

concurrency:
  group: ${{ github.repository }}-event-processing
  cancel-in-progress: false

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install fire loguru

      - name: Prepare web directory
        run: |
          mkdir -p web/{styles,js,data}
          cp frontend/src/styles/*.css web/styles/
          cp frontend/src/js/*.js web/js/
          cp frontend/src/templates/index.html web/index.html
          
      - name: Convert data
        run: |
          python frontend/scripts/convert_store.py \
            --snapshot_path data/papers/gh-store-snapshot.json \
            --output_path web/data/papers.json

      - name: Ensure presence of .nojekyll file
        run: touch web/.nojekyll

      - name: Get git info
        id: git-info
        run: |
          echo "branch=${GITHUB_REF#refs/heads/}" >> $GITHUB_OUTPUT
          echo "commit=$(git rev-parse --short HEAD)" >> $GITHUB_OUTPUT
          echo "repo=${GITHUB_REPOSITORY}" >> $GITHUB_OUTPUT

      - name: Create git info JSON
        run: |
          echo "{\"branch\": \"${{ steps.git-info.outputs.branch }}\", \"commit\": \"${{ steps.git-info.outputs.commit }}\", \"repo\": \"${{ steps.git-info.outputs.repo }}\"}" > web/data/git-info.json

      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: web
  
      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./web
          force_orphan: true



---
File: .github/workflows/ATTIC/download-papers.yml
---
# .github/workflows/download-papers.yml
name: Download Paper Files

on:
  # schedule:
  #   - cron: '0 */6 * * *'  # Run every 6 hours
  workflow_dispatch:
  
concurrency:
  group: ${{ github.repository }}-event-processing
  cancel-in-progress: false
  
jobs:
  download-files:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install papers_feed
      
      - name: Download PDFs (uncomment to download source)
        run: |
          python -m papers_feed.asset_manager download-pdfs
          #python -m papers_feed.asset_manager download-source
      
      - name: Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: Download paper files"
          file_pattern: |
            data/papers/**



---
File: .github/workflows/ATTIC/gh-store-snapshot.yml
---
# gh-store-snapshot.yml
name: Gh-Store Snapshot Management

on:
  issues:
    types: [reopened]
  # schedule:
  #   # Run daily at midnight UTC
  #   - cron: '0 0 * * *'
  workflow_dispatch:
    # Allow manual triggering
    inputs:
      force_new:
        description: 'Force creation of new snapshot'
        required: false
        type: boolean
        default: false

env:
  SNAPSHOT_PATH: data/papers/gh-store-snapshot.json

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false

jobs:
  process-updates:
    if: contains(github.event.issue.labels.*.name, 'stored-object')
    uses: "dmarx/papers-feed/.github/workflows/ghstore-process-updates.yml@673d20a8da9003fa5f437ac66f613a2b869badc4"
  snapshot:
    needs: process-updates
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Needed for pushing snapshot changes

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install gh-store

      - name: Check for existing snapshot
        id: check_snapshot
        run: |
          if [ -f "${{ env.SNAPSHOT_PATH }}" ] && [ "${{ github.event.inputs.force_new }}" != "true" ]; then
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Create new snapshot
        if: steps.check_snapshot.outputs.exists == 'false'
        run: |
          # Ensure directory exists
          mkdir -p $(dirname ${{ env.SNAPSHOT_PATH }})
          
          # Create snapshot using CLI
          python -m gh_store snapshot \
            --token ${{ secrets.GITHUB_TOKEN }} \
            --repo ${{ github.repository }} \
            --output ${{ env.SNAPSHOT_PATH }}

      - name: Update existing snapshot
        if: steps.check_snapshot.outputs.exists == 'true'
        run: |
          python -m gh_store update-snapshot \
            --token ${{ secrets.GITHUB_TOKEN }} \
            --repo ${{ github.repository }} \
            --snapshot-path ${{ env.SNAPSHOT_PATH }}
            
      - name: Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "${{ steps.check_snapshot.outputs.exists == 'true' && 'chore: Update data store snapshot' || 'chore: Create initial data store snapshot' }}"
          file_pattern: "${{ env.SNAPSHOT_PATH }}"



---
File: .github/workflows/ATTIC/ghstore-process-updates.yml
---
# .github/workflows/ghstore-process-updates.yml

name: Process Object Updates

on:
  #issues:
  #  types: [reopened]
  workflow_call:

jobs:
  process-updates:
    runs-on: ubuntu-latest
    if: contains(github.event.issue.labels.*.name, 'stored-object')
    permissions:
      issues: write 
    steps:
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install gh-store
          
      - name: Process Updates
        run: |
          python -m gh_store process-updates \
            --issue ${{ github.event.issue.number }} \
            --token ${{ secrets.GITHUB_TOKEN }} \
            --repo ${{ github.repository }}



---
File: .github/workflows/ATTIC/hard-refresh.yml
---
# .github/workflows/hard-refresh.yml
name: Hard Refresh

on:
  workflow_dispatch:  # Manual trigger only
  
permissions:
  contents: write
  issues: write

jobs:

  refresh:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
      with:
        submodules: true
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
      
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install PyGithub
        pip install papers_feed
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y pandoc texlive-base
    
    - name: Clear data directory and reopen issues
      run: |
        python - <<EOF
        import os
        import shutil
        from github import Github
        
        # Clear data directory
        data_dir = "data"
        if os.path.exists(data_dir):
            print(f"Removing {data_dir} directory...")
            shutil.rmtree(data_dir)
            os.makedirs(data_dir)
        
        # Reopen closed paper/reading issues
        g = Github(os.environ["GITHUB_TOKEN"])
        repo = g.get_repo(os.environ["GITHUB_REPOSITORY"])
        
        for issue in repo.get_issues(state="closed"):
            labels = [label.name for label in issue.labels]
            if "wontfix" in labels:
                continue
            if "paper" in labels or "reading-session" in labels:
                print(f"Reopening issue #{issue.number}")
                issue.edit(state="open")
        EOF
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Process events
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: python -m papers_feed.process_events
  
    - name: Download PDFs and Source
      run: |
        python -m papers_feed.asset_manager download-pdfs
        python -m papers_feed.asset_manager download-source

    - name: Convert to markdown
      run: |
        python -m papers_feed.asset_manager convert-markdown
        python -m papers_feed.asset_manager retry-failures
    
    - name: Commit and push if there are changes
      uses: stefanzweifel/git-auto-commit-action@v5
      with:
        commit_message: "chore: Hard refresh"
        file_pattern: |
          data/**



---
File: .github/workflows/ATTIC/process-events.yml
---
# .github/workflows/process-events.yml
name: Process Paper Events
on:
  push:
    paths:
      - ".github/workflows/process-events.yml"
  issues:
    types: [opened]
    labels:
      - 'paper'
      - 'reading-session'
  # schedule:
  #   - cron: '0 * * * *'  # Run every hour
  workflow_call:
  workflow_dispatch:
  
concurrency:
  group: ${{ github.repository }}-event-processing
  cancel-in-progress: false
  
jobs:
  process-papers:
    runs-on: ubuntu-latest
    permissions:
      actions: write
      contents: write
      issues: write
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install papers_feed
      
      - name: Process Events
        id: process
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          OUTPUT=$(python -m papers_feed.process_events)
          echo "Debug: Script output: $OUTPUT"
          if [[ "$OUTPUT" == *"Events processed."* ]]; then
            echo "SHOULD_TRIGGER=true" >> "$GITHUB_OUTPUT"
          else
            echo "SHOULD_TRIGGER=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Conditionally trigger frontend deploy
        if: ${{ steps.process.outputs.SHOULD_TRIGGER == 'true' }}
        run: |
          curl -L \
            -X POST \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            https://api.github.com/repos/${{ github.repository }}/actions/workflows/deploy_frontend.yaml/dispatches \
            -d '{"ref":"${{ github.ref }}"}'



---
File: .github/workflows/ATTIC/process_enrichments.yaml
---
name: Process Enrichments

on:
  issues:
    types: [opened, reopened]
  workflow_dispatch:  # Allow manual triggering
  schedule:
    - cron: '0 0 * * *'  # Run daily at midnight UTC

jobs:
  process-features:
    runs-on: ubuntu-latest
    
    # Only check for feature-node label if triggered by an issue event
    if: |
      github.event_name != 'issues' || 
      (github.event_name == 'issues' && contains(github.event.issue.labels.*.name, 'feature-node'))
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install llamero PyGithub duckduckgo-search
        
    - name: Process feature requests
      run: python scripts/process_enrichments.py
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}



---
File: .github/workflows/ATTIC/process_pdf.yml
---
name: Process PDF with Grobid

on:
  workflow_dispatch:
    inputs:
      pdf_path:
        description: 'Path to PDF file relative to repository root'
        required: true
        type: string
      output_format:
        description: 'Output format (markdown/tei)'
        required: true
        type: choice
        options:
          - markdown
          - tei
        default: 'markdown'
      tag:
        description: 'Optional tag to append to the output filename'
        required: false
        default: ''

jobs:
  convert:
    runs-on: ubuntu-latest
    services:
      grobid:
        image: lfoppiano/grobid:latest-crf
        ports:
          - 8070:8070
        env:
          JAVA_OPTS: "-Xmx4g"
        volumes:
          - ${{ github.workspace }}:/opt/grobid/input
        options: "--init"
        
    steps:
      - uses: actions/checkout@v4
    
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
    
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests loguru fire lxml
    
      - name: Process PDF
        env:
          GROBID_HOST: localhost  # Use localhost since the service is mapped to that port
        run: |
          # Wait until Grobid is ready
          for i in {1..30}; do
            if curl -sSf http://localhost:8070/api/isalive > /dev/null; then
              echo "Grobid is ready!"
              break
            fi
            echo "Attempt $i: Service not ready yet, waiting..."
            sleep 10
          done
          python scripts/process_pdf.py ${{ github.event.inputs.pdf_path }} --format ${{ github.event.inputs.output_format }} --tag "${{ github.event.inputs.tag }}"
    
      # Commit and push the generated output back to the repository.
      - name: Commit and Push Output
        uses: EndBug/add-and-commit@v9
        with:
          # The 'add' value here could be the folder or file pattern where the output is created.
          # For example, if the PDF is in a subdirectory, you might want to commit changes in that folder.
          add: '.'
          message: "Add processed output for ${{ github.event.inputs.pdf_path }}"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}



---
File: .github/workflows/ATTIC/refresh_pdfs_via_tei.yaml
---
name: REFRESH ALL Markdown Conversions (grobid) - WITH TEI

on:
  workflow_dispatch:

jobs:
  convert:
    runs-on: ubuntu-latest
        
    steps:
      - uses: actions/checkout@v4
    
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
    
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install llamero lxml requests
    
      - name: Process PDF
        run: |
          python scripts/process_pdf.py flush_old_conversions --tag="grobid"
          python scripts/process_pdf.py generate_missing_conversions --regenerate-tei=False
    
      # Commit and push the generated output back to the repository.
      - name: Commit and Push Output
        uses: EndBug/add-and-commit@v9
        with:
          # The 'add' value here could be the folder or file pattern where the output is created.
          # For example, if the PDF is in a subdirectory, you might want to commit changes in that folder.
          add: '.'
          message: "Add processed output for ${{ github.event.inputs.pdf_path }}"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}



---
File: .github/workflows/build-extension.yml
---
# .github/workflows/build-extension.yml
name: Build Extension

on:
  push:
    paths:
      - 'extension/**'
      - '.github/workflows/build-extension.yml'
    branches: [ main, ext-use-gh-store ]
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: extension

    steps:
    - uses: actions/checkout@v4
    
    # Generate package-lock.json if it doesn't exist
    # - name: Initialize npm
    #   run: |
    #     if [ ! -f "package-lock.json" ]; then
    #       npm install --package-lock-only --no-audit
    #     else
    #       echo "package-lock.json exists"
    #     fi
    
    # Regenerate package-lock.json to ensure it matches package.json
    - name: Regenerate package-lock.json
      run: |
        if [ -f "package-lock.json" ]; then
          rm -f package-lock.json
        fi
        npm install --package-lock-only --no-audit

    - name: Flush old build
      run: rm -rf dist/
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        #cache: 'npm'
        #cache-dependency-path: './extension/package-lock.json'
        
    - name: Install dependencies
      #run: npm ci --prefer-offline
      run: npm install --prefer-offline
        
      
    - name: Show environment info
      run: |
        echo "Node version:"
        node --version
        echo "NPM version:"
        npm --version
        echo "Directory structure:"
        ls -R
        echo "package.json contents:"
        cat package.json
        
    - name: Type check
      run: npm run type-check
        
    - name: Build extension
      run: |
        set -ex
        npm run build
        echo "Build output:"
        ls -la dist/

    # Debug output
    - name: Show build results
      if: always()
      run: |
        echo "Current directory:"
        pwd
        echo "Directory contents:"
        ls -lha
        echo "Dist directory contents (if exists):"
        ls -lha dist/ || echo "No dist directory"
        echo "Error logs (if any):"
        find . -name "*.log" -exec cat {} \;

    # Commit the built files
    - name: Commit bundled files
      uses: stefanzweifel/git-auto-commit-action@v5
      with:
        commit_message: "chore: Update extension bundles"
        file_pattern: "extension/dist/*"
        #branch: ${{ github.ref }}



---
File: .github/workflows/build-new-frontend.yaml
---
# .github/workflows/deploy-frontend.yml
name: Build and Deploy Frontend
on:
  push:
    branches: [ main ]
  
  # Allow manual trigger
  workflow_dispatch:

permissions:
  contents: write
  pages: write
  id-token: write
  actions: read

jobs:
  build-and-deploy-frontend:
    runs-on: ubuntu-latest
        
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          #cache: 'npm'
          #cache-dependency-path: 'frontend-new/package-lock.json'
      
      - name: Install Dependencies
        run: |
          cd frontend-new
          npm ci || npm install
      
      - name: Run Tests
        run: |
          cd frontend-new
          npm test
      
      - name: Build
        run: |
          cd frontend-new
          npm run build

      - name: Prepare deployment
        run: |
          cd frontend-new
          # Ensure bundle.css exists, create an empty one if not
          if [ ! -f "public/bundle.css" ]; then
            touch public/bundle.css
          fi
          
          # Create data/ directory
          mkdir -p public/data
          
          # Copy papers.json to the public folder if it exists
          if [ -f "papers.json" ]; then
            cp web/data/papers.json public/data/papers.json
          fi

          
      # Configure GitHub Pages
      - name: Setup Pages
        uses: actions/configure-pages@v4
      
      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./frontend-new/public
      
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4



---
File: .github/workflows/ghstore-process-bulk.yml
---
# .github/workflows/ghstore-process-bulk.yml
name: Process Bulk Object Updates

on:
  workflow_dispatch:
    inputs:
      label:
        description: 'Label to process (default: stored-object)'
        required: true
        type: string
        default: 'stored-object'

jobs:
  process-updates:
    runs-on: ubuntu-latest
    permissions:
      issues: write 
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install gh-store rich loguru

      - name: Process Updates
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          REPO: ${{ github.repository }}
          LABEL: ${{ inputs.label }}
        run: |
          python - << 'EOF'
          import os
          from github import Github
          from gh_store.__main__ import CLI
          from loguru import logger
          from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn

          # Initialize GitHub client
          g = Github(os.environ["GITHUB_TOKEN"])
          repo = g.get_repo(os.environ["REPO"])
          label = os.environ["LABEL"]

          # Get all open issues with the specified label
          logger.info(f"Finding open issues with label: {label}")
          open_issues = list(repo.get_issues(state="open", labels=[label]))

          if not open_issues:
              logger.warning("No open issues found with specified label")
              exit(0)

          logger.info(f"Found {len(open_issues)} issues to process")

          # Initialize CLI
          cli = CLI()

          # Create progress bar
          with Progress(
              SpinnerColumn(),
              TextColumn("[bold blue]{task.description}"),
              BarColumn(),
              TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
          ) as progress:
              process_task = progress.add_task(
                  "Processing issues...",
                  total=len(open_issues)
              )

              for issue in open_issues:
                  logger.info(f"Processing issue #{issue.number}")
                  cli.process_updates(
                      issue=issue.number,
                      token=os.environ["GITHUB_TOKEN"],
                      repo=os.environ["REPO"]
                  )
                  progress.update(process_task, advance=1)

          logger.info("Bulk processing completed")
          EOF



---
File: .github/workflows/llamero-summarize.yaml
---
name: Llamero Summarization

on:
  # push:
  #   branches: [ main ]
  workflow_dispatch:

jobs:
  generate-summaries:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write

    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install llamero
      run: pip install llamero

    - name: Generate summaries
      run: llamero summarize all



---
File: .github/workflows/mirror-issues.yaml
---
# .github/workflows/mirror_repository.yml
name: Mirror GitHub Repository

on:
  workflow_dispatch:
    inputs:
      source_repo:
        description: 'Source repository (format: owner/repo)'
        required: true
        default: 'dmarx/papers-feed'
      target_repo:
        description: 'Target repository (format: owner/repo)'
        required: true
        default: 'dmarx/papers-feed-dev'
      clear_target_labels:
        description: 'Clear all labels from issues in target repository'
        required: true
        type: boolean
        default: false
      issue_range_start:
        description: 'Starting issue number to copy (optional)'
        required: false
      issue_range_end:
        description: 'Ending issue number to copy (optional)'
        required: false

jobs:
  mirror-repo:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 1  # Shallow clone - only get the latest commit

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install PyGithub fire loguru

      - name: Run mirroring script
        env:
          DEV_REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python scripts/github_repo_mirror.py mirror \
            --source-repo=${{ github.event.inputs.source_repo }} \
            --target-repo=${{ github.event.inputs.target_repo }} \
            --clear-target-labels=${{ github.event.inputs.clear_target_labels }} \
            ${{ github.event.inputs.issue_range_start != '' && format('--issue-range-start={0}', github.event.inputs.issue_range_start) || '' }} \
            ${{ github.event.inputs.issue_range_end != '' && format('--issue-range-end={0}', github.event.inputs.issue_range_end) || '' }}



---
File: .github/workflows/ops-misc.yml
---
# .github/workflows/ops-misc.yml
# General purpose utility operator for one-off operations
# Executes misc.sh and clears it after successful run

name: Miscellaneous Operations

on:
  push:
    paths:
      - 'ops/misc.sh'
      - '.github/workflows/ops-misc.yml'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  execute-misc:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Execute and clear misc script
        run: |
          cat ops/misc.sh
          . ops/misc.sh
          echo '#!/bin/bash' > ops/misc.sh

      - uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: executed miscellaneous operation"



---
File: .github/workflows/paper-enrichment.yml
---
# .github/workflows/paper-enrichment.yml

name: PDF Download and Enrichment

on:
  issues:
    types: [opened, reopened]
  schedule:
    - cron: '0 */6 * * *'
  workflow_dispatch:
  

concurrency:
  group: ${{ github.repository }}-event-processing
  cancel-in-progress: false

jobs:
  download-pdfs:
    runs-on: ubuntu-latest
    if: |
      github.event_name != 'issues' || 
      (github.event_name == 'issues' && contains(github.event.issue.labels.*.name, 'feature-node'))
    permissions:
      contents: write
    outputs:
      has_changes: ${{ steps.commit.outputs.changes_detected }}
      
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install papers_feed
      
      - name: Download PDFs
        run: |
          python -m papers_feed.asset_manager download-pdfs
      
      - name: Commit changes
        id: commit
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: Download paper files"
          file_pattern: |
            data/papers/**

  convert-pdfs-to-markdown:
    runs-on: ubuntu-latest
    needs: download-pdfs
    if: github.event_name != 'issues' || needs.download-pdfs.outputs.has_changes == 'true'
    outputs:
      has_changes: ${{ steps.commit.outputs.changes_detected }}
    
    services:
      grobid:
        image: lfoppiano/grobid:latest-crf
        ports:
          - 8070:8070
        env:
          JAVA_OPTS: "-Xmx4g"
        volumes:
          - ${{ github.workspace }}:/opt/grobid/input
        options: "--init"
        
    steps:
      - uses: actions/checkout@v4
    
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
    
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install llamero lxml requests
    
      - name: Process PDF
        env:
          GROBID_HOST: localhost
        run: |
          for i in {1..30}; do
            if curl -sSf http://localhost:8070/api/isalive > /dev/null; then
              echo "Grobid is ready!"
              break
            fi
            echo "Attempt $i: Service not ready yet, waiting..."
            sleep 10
          done
          python scripts/process_pdf.py generate_missing_conversions

      - name: Commit and Push Conversions
        id: commit
        uses: EndBug/add-and-commit@v9
        with:
          add: '.'
          message: "Add tei xml's"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  process-enrichments:
    needs: convert-pdfs-to-markdown
    if: github.event_name != 'issues' || needs.convert-pdfs-to-markdown.outputs.has_changes == 'true'
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.ref }}
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install llamero PyGithub duckduckgo-search
          
      - name: Process enrichments
        run: python scripts/process_enrichments.py
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}



---
File: .github/workflows/process-issue-task.yaml
---
name: Process Task From Issue Trigger
on:
  issues:
    types: [opened, reopened]

jobs:
  process-search:
    if: contains(github.event.issue.labels.*.name, 'task')
    runs-on: ubuntu-latest
    permissions:
      issues: write
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install gh-store duckduckgo_search
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi
          
      - name: Process Task
        run: |
          RESULT=$(python scripts/process_task.py --config "${{ github.event.issue.body }}")
          gh issue comment "$ISSUE_NUMBER" --body "$RESULT" --repo "$GITHUB_REPOSITORY"

          # TODO: use gh-store to update the issue state and be responsible for closing it
          gh issue close "$ISSUE_NUMBER" --repo "$GITHUB_REPOSITORY"
          
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          ISSUE_NUMBER: ${{ github.event.issue.number }}



---
File: .github/workflows/toggle-issues.yml
---
# .github/workflows/toggle-issues.yaml
name: Toggle Issues

on:
  workflow_dispatch:
    inputs:
      label:
        description: 'toggle issues matching this label'
        required: true
        type: string
        default: 'stored-object'
      perform_close:
        description: 'Close matching open issues'
        required: true
        type: boolean
        default: true
      perform_reopen:
        description: 'Reopen issues closed during the `perform_close` step'
        required: true
        type: boolean
        default: true
      reopen_all_matching:
        description: 'Reopen all labeled issues (not just those closed in this run)'
        required: true
        type: boolean
        default: false

permissions:
  issues: write

jobs:
  toggle-issues:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Install Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install fire loguru PyGithub requests rich

      - name: Run issue toggle script
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          REPO: ${{ github.repository }}
          LABEL: ${{ inputs.label }}
          PERFORM_CLOSE: ${{ inputs.perform_close }}
          PERFORM_REOPEN: ${{ inputs.perform_reopen }}
          REOPEN_ALL_MATCHING: ${{ inputs.reopen_all_matching }}
        run: python scripts/toggle_issues.py


